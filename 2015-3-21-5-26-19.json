[{"urllink": "http://arxiv.org/abs/1501.00001", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00001", "title": "\nAn OFDM Signal Identification Method for Wireless Communications Systems", "abstract": "Distinction of OFDM signals from single carrier signals is highly important for adaptive receiver algorithms and signal identification applications. OFDM signals exhibit Gaussian characteristics in time domain and fourth order cumulants of Gaussian distributed signals vanish in contrary to the cumulants of other signals. Thus fourth order cumulants can be utilized for OFDM signal identification. In this paper, first, formulations of the estimates of the fourth order cumulants for OFDM signals are provided. Then it is shown these estimates are affected significantly from the wireless channel impairments, frequency offset, phase offset and sampling mismatch. To overcome these problems, a general chi-square constant false alarm rate Gaussianity test which employs estimates of cumulants and their covariances is adapted to the specific case of wireless OFDM signals. Estimation of the covariance matrix of the fourth order cumulants are greatly simplified peculiar to the OFDM signals. A measurement setup is developed to analyze the performance of the identification method and for comparison purposes. A parametric measurement analysis is provided depending on modulation order, signal to noise ratio, number of symbols, and degree of freedom of the underlying test. The proposed method outperforms statistical tests which are based on fixed thresholds or empirical values, while a priori information requirement and complexity of the proposed method are lower than the coherent identification techniques.", "subjects": "Information Theory (cs.IT)", "authors": "Ali Gorcin, Huseyin Arslan,", "date": "2014-12-29"}, 
{"urllink": "http://arxiv.org/abs/1501.00014", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00014", "title": "\nOptimal rounding under integer constraints", "abstract": "Given real numbers whose sum is an integer, we study the problem of finding integers which match these real numbers as closely as possible, in the sense of L^p norm, while preserving the sum. We describe the structure of solutions for this integer optimization problem and propose an algorithm with complexity O(N log N) for solving it. In contrast to fractional rounding and randomized rounding, which yield biased estimators of the solution when applied to this problem, our method yields an exact solution which minimizes the relative rounding error across the set of all solutions for any value of p greater than 1, while avoiding the complexity of exhaustive search. The proposed algorithm also solves a class of integer optimization problems with integer constraints and may be used as the rounding step of relaxed integer programming problems, for rounding real-valued solutions. We give several examples of applications for the proposed algorithm.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Rama Cont, Massoud Heidari,", "date": "2014-12-30"}, 
{"urllink": "http://arxiv.org/abs/1501.00027", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00027", "title": "\nTime-Symmetric Physics: A Radical Approach to the Decoherence Problem", "abstract": "The most powerful form of quantum learning system possible would somehow learn the parameters W of a quantum system f(X, W), for f representing the largest, most powerful set of possible input-output relations. This paper addresses the issue of how to enlarge the set represented by f, by using a new formulation of time-symmetric physics to model analog quantum computers based on spin and by exploring possible sources of backwards-time free energy so as to address problems of decoherence and dissipation.", "subjects": "Other Computer Science (cs.OH)", "authors": "Paul J. Werbos,", "date": "2014-12-23"}, 
{"urllink": "http://arxiv.org/abs/1501.00029", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00029", "title": "\nLIVEIA: A Light-based Immersive Visualization Environment for  Imaginative Actualization", "abstract": "This paper describes an immersive and interactive visualization environment that uses light as a metaphor for psychological phenomena. Creative life force is portrayed as ambient light, and peoples' psyches are represented by spheres that amplify and transform light. Personality characteristics, situations, and relationships are systematically depicted using a systematic visual language based on the properties of light and how it interacts with physical objects. The technology enables users to visualize and creatively experiment with light-based representations of themselves and others, including patterns of interaction and how they have come about, and how they could change and unfold in the future.", "subjects": "Computers and Society (cs.CY)", "authors": "Liane Gabora,", "date": "2014-12-30"}, 
{"urllink": "http://arxiv.org/abs/1501.00035", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00035", "title": "\nMassive MIMO testbed - Implementation and Initial Results in System  Model Validation", "abstract": "This paper presents the design and implementation of a novel SDR based massive MIMO testbed with up to 70 nodes built at Tennessee Technological University. The deployment can reach a antenna MIMO scheme. With this testbed, we are able to measure the channel matrix and compute the achievable rate of the massive MIMO system using experimental data. The measured channel capacity is linearly increasing with the number of antennas of the base station. We also demonstrate the channel reciprocity including the circuits impact from the transmitter and receiver. We show that the Vandermonde channel model is more realistic to describe the massive MIMO architecture than the widely used Gaussian channel model, in terms of capacity. By adjusting the range for angle of arrival and the base station antenna distance during the simulation, we find out the Vandermonde model agrees with our measured capacity at a certain for each selected and the is very close to that of the experiment deployment. It is the first time that the feasibility of Vandermonde channel model is demonstrated by the experiment for massive MIMO.", "subjects": "Information Theory (cs.IT)", "authors": "Changchun Zhang, Robert C. Qiu,", "date": "2014-12-30"}, 
{"urllink": "http://arxiv.org/abs/1501.00037", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00037", "title": "\nDiscriminative Clustering with Relative Constraints", "abstract": "We study the problem of clustering with relative constraints, where each constraint specifies relative similarities among instances. In particular, each constraint is acquired by posing a query: is instance more similar to than to ? We consider the scenario where answers to such queries are based on an underlying (but unknown) class concept, which we aim to discover via clustering. Different from most existing methods that only consider constraints derived from yes and no answers, we also incorporate don't know responses. We introduce a Discriminative Clustering method with Relative Constraints (DCRC) which assumes a natural probabilistic relationship between instances, their underlying cluster memberships, and the observed constraints. The objective is to maximize the model likelihood given the constraints, and in the meantime enforce cluster separation and cluster balance by also making use of the unlabeled instances. We evaluated the proposed method using constraints generated from ground-truth class labels, and from (noisy) human judgments from a user study. Experimental results demonstrate: 1) the usefulness of relative constraints, in particular when don't know answers are considered; 2) the improved performance of the proposed method over state-of-the-art methods that utilize either relative or pairwise constraints; and 3) the robustness of our method in the presence of noisy constraints, such as those provided by human judgement.", "subjects": "Learning (cs.LG)", "authors": "Yuanli Pei, Xiaoli Z. Fern, R\u00f3mer Rosales, Teresa Vania Tjahja,", "date": "2014-12-30"}, 
{"urllink": "http://arxiv.org/abs/1501.00046", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00046", "title": "\nLifting for Blind Deconvolution in Random Mask Imaging: Identifiability  and Convex Relaxation", "abstract": "In this paper we analyze the blind deconvolution of an image and an unknown blur in a coded imaging system. The measurements consist of a subsampled convolution of an unknown blurring kernel with multiple random binary modulations (coded masks) of the image. To perform the deconvolution, we consider a standard lifting of the image and the blurring kernel that transforms the measurements into a set of linear equations of the matrix formed by their outer product. Any rank-one solution to this system of equation provides a valid pair of an image and a blur. We first express the necessary and sufficient conditions for the uniqueness of a rank-1 solution under some additional assumptions (uniform subsampling and no limit on the number of coded masks). These conditions are special case of a previously established result regarding identifiability in the matrix completion problem. We also characterize a low-dimensional subspace model for the blur kernel that is sufficient to guarantee identifiability, including the interesting instance of \"bandpass\" blur kernels. Next, we show that for the bandpass model for the blur kernel, the image and the blur kernel can be found using nuclear norm minimization. Our main results show that recovery is achieved (with high probability) when the number of masks is on the order of where is the emph of the blur, is the dimension of the image, and is the number of measured samples per mask.", "subjects": "Information Theory (cs.IT)", "authors": "Sohail Bahmani, Justin Romberg,", "date": "2014-12-30"}, 
{"urllink": "http://arxiv.org/abs/1501.00048", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00048", "title": "\nMethods and Metrics for Fair Server Assessment under Real-Time Financial  Workloads", "abstract": "Energy efficiency has been a daunting challenge for datacenters. The financial industry operates some of the largest datacenters in the world. With increasing energy costs and the financial services sector growth, emerging financial analytics workloads may incur extremely high operational costs, to meet their latency targets. Microservers have recently emerged as an alternative to high-end servers, promising scalable performance and low energy consumption in datacenters via scale-out. Unfortunately, stark differences in architectural features, form factor and design considerations make a fair comparison between servers and microservers exceptionally challenging. In this paper we present a rigorous methodology and new metrics for fair comparison of server and microserver platforms. We deploy our methodology and metrics to compare a microserver with ARM cores against two servers with x86 cores, running the same real-time financial analytics workload. We define workload-specific but platform-independent performance metrics for platform comparison, targeting both datacenter operators and end users. Our methodology establishes that a server based the Xeon Phi processor delivers the highest performance and energy-efficiency. However, by scaling out energy-efficient microservers, we achieve competitive or better energy-efficiency than a power-equivalent server with two Sandy Bridge sockets despite the microserver's slower cores. Using a new iso-QoS (iso-Quality of Service) metric, we find that the ARM microserver scales enough to meet market throughput demand, i.e. a 100% QoS in terms of timely option pricing, with as little as 55% of the energy consumed by the Sandy Bridge server.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Giorgis Georgakoudis, Charles J. Gillan, Ahmed Sayed, Ivor Spence, Richard Faloon, Dimitrios S. Nikolopoulos,", "date": "2014-12-30"}, 
{"urllink": "http://arxiv.org/abs/1501.00067", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00067", "title": "\nA Feasible Graph Partition Framework for Random Walks Implemented by  Parallel Computing in Big Graph", "abstract": "Graph partition is a fundamental problem of parallel computing for big graph data. Many graph partition algorithms have been proposed to solve the problem in various applications, such as matrix computations and PageRank, etc., but none has pay attention to random walks. Random walks is a widely used method to explore graph structure in lots of fields. The challenges of graph partition for random walks include the large number of times of communication between partitions, lots of replications of the vertices, unbalanced partition, etc. In this paper, we propose a feasible graph partition framework for random walks implemented by parallel computing in big graph. The framework is based on two optimization functions to reduce the bandwidth, memory and storage cost in the condition that the load balance is guaranteed. In this framework, several greedy graph partition algorithms are proposed. We also propose five metrics from different perspectives to evaluate the performance of these algorithms. By running the algorithms on the big graph data set of real world, the experimental results show that these algorithms in the framework are capable of solving the problem of graph partition for random walks for different needs, e.g. the best result is improved more than 70 times in reducing the times of communication.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Xiaoming Liu, Yadong Zhou, Xiaohong Guan,", "date": "2014-12-31"}, 
{"urllink": "http://arxiv.org/abs/1501.00077", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00077", "title": "\nIndex Coding with Coded Side-Information", "abstract": "This letter investigates a new class of index coding problems. One sender broadcasts packets to multiple users, each desiring a subset, by exploiting prior knowledge of linear combinations of packets. We refer to this class of problems as index coding with coded side-information. Our aim is to characterize the minimum index code length that the sender needs to transmit to simultaneously satisfy all user requests. We show that the optimal binary vector index code length is equal to the minimum rank (minrank) of a matrix whose elements consist of the sets of desired packet indices and side- information encoding matrices. This is the natural extension of matrix minrank in the presence of coded side information. Using the derived expression, we propose a greedy randomized algorithm to minimize the rank of the derived matrix.", "subjects": "Information Theory (cs.IT)", "authors": "Namyoon Lee, Alexandros G. Dimakis, Robert W. Heath Jr,", "date": "2014-12-31"}, 
{"urllink": "http://arxiv.org/abs/1501.00078", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00078", "title": "\nJoint Downlink Cell Association and Bandwidth Allocation for Wireless  Backhauling in Two-Tier HetNets with Large-Scale Antenna Arrays", "abstract": "The problem of joint downlink cell association (CA) and wireless backhaul bandwidth allocation (WBBA) in two-tier cellular heterogeneous networks (HetNets) is considered. Large-scale antenna array is implemented at the macro base station (BS), while the small cells within the macro cell range are single-antenna BSs and they rely on over-the-air links to the macro BS for backhauling. A sum logarithmic user rate maximization problem is investigated considering wireless backhauling constraints. A duplex and spectrum sharing scheme based on co-channel reverse time-division duplex (TDD) and dynamic soft frequency reuse (SFR) is proposed for interference management in two-tier HetNets with large-scale antenna arrays at the macro BS and wireless backhauling for small cells. Two in-band WBBA scenarios, namely, unified bandwidth allocation and per-small-cell bandwidth allocation scenarios, are investigated for joint CA-WBBA in the HetNet. A two-level hierarchical decomposition method for relaxed optimization is employed to solve the mixed-integer nonlinear program (MINLP). Solutions based on the General Algorithm Modeling System (GAMS) optimization solver and fast heuristics are also proposed for cell association in the per-small-cell WBBA scenario. It is shown that when all small cells have to use in-band wireless backhaul, the system load has more impact on both the sum log-rate and per-user rate performance than the number of small cells deployed within the macro cell range. The proposed joint CA-WBBA algorithms have an optimal load approximately equal to the size of the large-scale antenna array at the macro BS. The cell range expansion (CRE) strategy, which is an efficient cell association scheme for HetNets with perfect backhauling, is shown to be inefficient when in-band wireless backhauling for small cells comes into play.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Ning Wang, Ekram Hossain, Vijay K. Bhargava,", "date": "2014-12-31"}, 
{"urllink": "http://arxiv.org/abs/1501.00080", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00080", "title": "\nAdvanced Interference Management Technique: Potential and Limitations", "abstract": "Interference management has the potential to improve spectrum efficiency in current and next generation wireless systems (e.g. 3GPP LTE and IEEE 802.11). Recently, new paradigms for interference management have emerged to tackle interference in a general class of wireless networks: interference shaping and interference exploitation. Both approaches offer better performance in interference-limited communication regimes than traditionally thought possible. This article provides a high-level overview of several different interference shaping and exploitation techniques for single-hop, multi-hop, and multi-way network architectures. Graphical illustrations that explain the intuition behind each strategy are provided. The article concludes with a discussion of practical challenges associated with adopting sophisticated interference management strategies in the future.", "subjects": "Information Theory (cs.IT)", "authors": "Namyoon Lee, Robert W. Heath Jr,", "date": "2014-12-31"}, 
{"urllink": "http://arxiv.org/abs/1501.00092", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00092", "title": "\nImage Super-Resolution Using Deep Convolutional Networks", "abstract": "We propose a deep learning method for single image super-resolution (SR). Our method directly learns an end-to-end mapping between the low/high-resolution images. The mapping is represented as a deep convolutional neural network (CNN) that takes the low-resolution image as the input and outputs the high-resolution one. We further show that traditional sparse-coding-based SR methods can also be viewed as a deep convolutional network. But unlike traditional methods that handle each component separately, our method jointly optimizes all layers. Our deep CNN has a lightweight structure, yet demonstrates state-of-the-art restoration quality, and achieves fast speed for practical on-line usage. We explore different network structures and parameter settings to achieve trade-offs between performance and speed. Moreover, we extend our network to cope with three color channels simultaneously, and show better overall reconstruction quality.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Chao Dong, Chen Change Loy, Kaiming He, Xiaoou Tang,", "date": "2014-12-31"}, 
{"urllink": "http://arxiv.org/abs/1501.00178", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00178", "title": "\nLattices with Symmetry", "abstract": "For large ranks, there is no good algorithm that decides whether a given lattice has an orthonormal basis. But when the lattice is given with enough symmetry, we can construct a provably deterministic polynomial-time algorithm to accomplish this, based on the work of Gentry and Szydlo. The techniques involve algorithmic algebraic number theory, analytic number theory, commutative algebra, and lattice basis reduction.", "subjects": "Number Theory (math.NT)", "authors": "H. W. Lenstra Jr., A. Silverberg,", "date": "2014-12-31"}, 
{"urllink": "http://arxiv.org/abs/1502.02558", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02558", "title": "\nK2-ABC: Approximate Bayesian Computation with Infinite Dimensional  Summary Statistics via Kernel Embeddings", "abstract": "Complicated generative models often result in a situation where computing the likelihood of observed data is intractable, while simulating from the conditional density given a parameter value is relatively easy. Approximate Bayesian Computation (ABC) is a paradigm that enables simulation-based posterior inference in such cases by measuring the similarity between simulated and observed data in terms of a chosen set of summary statistics. However, there is no general rule to construct sufficient summary statistics for complex models. Insufficient summary statistics will \"leak\" information, which leads to ABC algorithms yielding samples from an incorrect (partial) posterior. In this paper, we propose a fully nonparametric ABC paradigm which circumvents the need for manually selecting summary statistics. Our approach, K2-ABC, uses maximum mean discrepancy (MMD) as a dissimilarity measure between the distributions over observed and simulated data. MMD is easily estimated as the squared difference between their empirical kernel embeddings. Experiments on a simulated scenario and a real-world biological problem illustrate the effectiveness of the proposed algorithm.", "subjects": "Machine Learning (stat.ML)", "authors": "Mijung Park, Wittawat Jitkrittum, Dino Sejdinovic,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1503.05872", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05872", "title": "\nHeavy-Traffic Behavior of the MaxWeight Algorithm in a Switch with  Uniform Traffic", "abstract": "We consider a switch with uniform traffic operating under the MaxWeight scheduling algorithm. This traffic pattern is interesting to study in the heavy-traffic regime since the queue lengths exhibit a multi-dimensional state-space collapse. We use a Lyapunov-type drift technique to characterize the heavy-traffic behavior of the expectation of the sum queue lengths in steady-state. Specifically, in the case of Bernoulli arrivals, we show that the heavy-traffic scaled queue length is Our result implies that the MaxWeight algorithm has optimal queue-length scaling behavior in the heavy-traffic regime with respect to the size of a switch with a uniform traffic pattern. This settles the heavy-traffic version of an open conjecture.", "subjects": "Probability (math.PR)", "authors": "Siva Theja Maguluri, R Srikant,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05858", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05858", "title": "\nMerit factors of polynomials derived from difference sets", "abstract": "The problem of constructing polynomials with all coefficients or and large merit factor (equivalently with small norm on the unit circle) arises naturally in complex analysis, condensed matter physics, and digital communications engineering. Most known constructions arise (sometimes in a subtle way) from difference sets, in particular from Paley and Singer difference sets. We consider the asymptotic merit factor of polynomials constructed from other difference sets, providing the first essentially new examples since 1991. In particular we prove a general theorem on the asymptotic merit factor of polynomials arising from cyclotomy, which includes results on Hall and Paley difference sets as special cases. In addition, we establish the asymptotic merit factor of polynomials derived from Gordon-Mills-Welch difference sets and Sidelnikov almost difference sets, proving two recent conjectures.", "subjects": "Combinatorics (math.CO)", "authors": "Christian G\u00fcnther, Kai-Uwe Schmidt,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05857", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05857", "title": "\nModels of Quantum Algorithms in Sets and Relations", "abstract": "In this paper we construct abstract models of black-box quantum algorithms using a model of quantum computation in sets and relations, a setting that is usually considered as a model for nondeterministic classical computation. This work provides an alternative model of quantum computation (QCRel) that, though unphysical, nevertheless faithfully models its computational structure. The main results of this paper are models of the Deutsch-Jozsa, single-shot Grovers, and GroupHomID algorithms in QCRel. Such results provide new tools to analyze the semantics of quantum computation and improve our understanding of the relationship between computational speedups and the structure of physical theories. They also exemplify a method of extending physical/computational intuition into new mathematical settings.", "subjects": "Quantum Physics (quant-ph)", "authors": "William Zeng,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05826", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05826", "title": "\nRespondent-driven sampling bias induced by clustering and community  structure in social networks", "abstract": "Sampling hidden populations is particularly challenging using standard sampling methods mainly because of the lack of a sampling frame. Respondent-driven sampling (RDS) is an alternative methodology that exploits the social contacts between peers to reach and weight individuals in these hard-to-reach populations. It is a snowball sampling procedure where the weight of the respondents is adjusted for the likelihood of being sampled due to differences in the number of contacts. In RDS, the structure of the social contacts thus defines the sampling process and affects its coverage, for instance by constraining the sampling within a sub-region of the network. In this paper we study the bias induced by network structures such as social triangles, community structure, and heterogeneities in the number of contacts, in the recruitment trees and in the RDS estimator. We simulate different scenarios of network structures and response-rates to study the potential biases one may expect in real settings. We find that the prevalence of the estimated variable is associated with the size of the network community to which the individual belongs. Furthermore, we observe that low-degree nodes may be under-sampled in certain situations if the sample and the network are of similar size. Finally, we also show that low response-rates lead to reasonably accurate average estimates of the prevalence but generate relatively large biases.", "subjects": "Applications (stat.AP)", "authors": "Luis Enrique Correa Rocha, Anna Ekeus Thorson, Renaud Lambiotte, Fredrik Liljeros,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05724", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05724", "title": "\nA Neural Transfer Function for a Smooth and Differentiable Transition  Between Additive and Multiplicative Interactions", "abstract": "Existing approaches to combine both additive and multiplicative neural units either use a fixed assignment of operations or require discrete optimization to determine what function a neuron should perform. This leads either to an inefficient distribution of computational resources or an extensive increase in the computational complexity of the training procedure. We present a novel, parameterizable transfer function based on the mathematical concept of non-integer functional iteration that allows the operation each neuron performs to be smoothly and, most importantly, differentiablely adjusted between addition and multiplication. This allows the decision between addition and multiplication to be integrated into the standard backpropagation training procedure.", "subjects": "Machine Learning (stat.ML)", "authors": "Sebastian Urban, Patrick van der Samgt,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05641", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05641", "title": "\nCommunity detection in directed acyclic graphs", "abstract": "Some temporal networks, most notably citation networks, are naturally represented as directed acyclic graphs (DAGs). To detect communities in DAGs, we propose a modularity for DAGs by defining an appropriate null model (i.e., randomized network) respecting the order of nodes. We implement a spectral method to approximately maximize the proposed modularity measure and test the method on citation networks and other DAGs. We find that the attained values of the modularity for DAGs are similar for partitions that we obtain by maximizing the proposed modularity (designed for DAGs), the modularity for undirected networks and that for general directed networks. In other words, if we neglect the order imposed on nodes (and the direction of links) in a given DAG and maximize the conventional modularity measure, the obtained partition is close to the optimal one in the sense of the modularity for DAGs.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Leo Speidel, Taro Takaguchi, Naoki Masuda,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05570", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05570", "title": "\nA Data Science Course for Undergraduates: Thinking with Data", "abstract": "Data science is an emerging interdisciplinary field that combines elements of mathematics, statistics, computer science, and knowledge in a particular application domain for the purpose of extracting meaningful information from the increasingly sophisticated array of data available in many settings. These data tend to be non-traditional, in the sense that they are often live, large, complex, and/or messy. A first course in statistics at the undergraduate level typically introduces students with a variety of techniques to analyze small, neat, and clean data sets. However, whether they pursue more formal training in statistics or not, many of these students will end up working with data that is considerably more complex, and will need facility with statistical computing techniques. More importantly, these students require a framework for thinking structurally about data. We describe an undergraduate course in a liberal arts environment that provides students with the tools necessary to apply data science. The course emphasizes modern, practical, and useful skills that cover the full data analysis spectrum, from asking an interesting question to acquiring, managing, manipulating, processing, querying, analyzing, and visualizing data, as well communicating findings in written, graphical, and oral forms.", "subjects": "Other Statistics (stat.OT)", "authors": "Ben Baumer,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05567", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05567", "title": "\nThe Knowledge Gradient Policy Using A Sparse Additive Belief Model", "abstract": "We propose a sequential learning policy for noisy discrete global optimization and ranking and selection (R &amp;S) problems with high dimensional sparse belief functions, where there are hundreds or even thousands of features, but only a small portion of these features contain explanatory power. We aim to identify the sparsity pattern and select the best alternative before the finite budget is exhausted. We derive a knowledge gradient policy for sparse linear models (KGSpLin) with group Lasso penalty. This policy is a unique and novel hybrid of Bayesian R &amp;S with frequentist learning. Particularly, our method naturally combines B-spline basis expansion and generalizes to the nonparametric additive model (KGSpAM) and functional ANOVA model. Theoretically, we provide the estimation error bounds of the posterior mean estimate and the functional estimate. Controlled experiments show that the algorithm efficiently learns the correct set of nonzero parameters even when the model is imbedded with hundreds of dummy parameters. Also it outperforms the knowledge gradient for a linear model.", "subjects": "Machine Learning (stat.ML)", "authors": "Yan Li, Han Liu, Warren Powell,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05526", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05526", "title": "\nInterpretable Aircraft Engine Diagnostic via Expert Indicator  Aggregation", "abstract": "Detecting early signs of failures (anomalies) in complex systems is one of the main goal of preventive maintenance. It allows in particular to avoid actual failures by (re)scheduling maintenance operations in a way that optimizes maintenance costs. Aircraft engine health monitoring is one representative example of a field in which anomaly detection is crucial. Manufacturers collect large amount of engine related data during flights which are used, among other applications, to detect anomalies. This article introduces and studies a generic methodology that allows one to build automatic early signs of anomaly detection in a way that builds upon human expertise and that remains understandable by human operators who make the final maintenance decision. The main idea of the method is to generate a very large number of binary indicators based on parametric anomaly scores designed by experts, complemented by simple aggregations of those scores. A feature selection method is used to keep only the most discriminant indicators which are used as inputs of a Naive Bayes classifier. This give an interpretable classifier based on interpretable anomaly detectors whose parameters have been optimized indirectly by the selection process. The proposed methodology is evaluated on simulated data designed to reproduce some of the anomaly types observed in real world engines.", "subjects": "Machine Learning (stat.ML)", "authors": "Tsirizo Rabenoro, J\u00e9r\u00f4me Lacaille, Marie Cottrell, Fabrice Rossi,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05252", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05252", "title": "\nCircuit diameter and Klee-Walkup constructions", "abstract": "Consider a variant of the graph diameter of a polyhedron where each step in a walk between two vertices travels maximally in a circuit direction instead of along incident edges. Here circuit directions are non-trivial solutions to minimally-dependent subsystems of the presentation of the polyhedron. These can be understood as the set of all possible edge directions, including edges that may arise from translation of the facets. It is appealing to consider a circuit analogue of the Hirsch conjecture for graph diameter, as suggested by Borgwardt et al. [BFH15]. They ask whether the known counterexamples to the Hirsch conjecture give rise to counterexamples for this relaxed notion of circuit diameter. We show that the most basic counterexample to the unbounded Hirsch conjecture, the Klee-Walkup polyhedron, does have a circuit diameter that satisfies the Hirsch bound, regardless of representation. We also examine the circuit diameter of the bounded Klee-Walkup polytope.", "subjects": "Combinatorics (math.CO)", "authors": "Tamon Stephen, Timothy Yusun,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05180", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05180", "title": "\nHyperbolic Graph Generator", "abstract": "Networks representing many complex systems in nature and society share some common structural properties like heterogeneous degree distributions and strong clustering. Recent research on network geometry has shown that those real networks can be adequately modeled as random geometric graphs in hyperbolic spaces. In this paper, we present a computer program to generate such graphs. Besides real-world-like networks, the program can generate random graphs from other well-known graph ensembles, such as the soft configuration model, random geometric graphs on a circle, or Erd Hs-R 'enyi random graphs. The simulations show a good match between the expected values of different network structural properties and the corresponding empirical values measured in generated graphs, confirming the accurate behavior of the program.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Rodrigo Aldecoa, Chiara Orsini, Dmitri Krioukov,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05140", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05140", "title": "\nProtVec: A Continuous Distributed Representation of Biological Sequences", "abstract": "We propose a new approach for representing biological sequences. This method, named protein-vectors or ProtVec for short, can be utilized in bioinformatics applications such as family classification, protein visualization, structure prediction, disordered protein identification, and protein-protein interaction prediction. Using the Skip-gram neural networks, protein sequences are represented with a single dense n-dimensional vector. This method was evaluated by classifying protein sequences obtained from Swiss-Prot belonging to 7,027 protein families where an average family classification accuracy of was obtained, outperforming existing family classification methods. In addition, our model was used to predict disordered proteins from structured proteins. Two databases of disordered sequences were used: the DisProt database as well as a database featuring the disordered regions of nucleoporins rich with phenylalanine-glycine repeats (FG-Nups). Using support vector machine classifiers, FG-Nup sequences were distinguished from structured Protein Data Bank (PDB) sequences with 99.81 % accuracy, and unstructured DisProt sequences from structured DisProt sequences with 100.0 % accuracy. These results indicate that by only providing sequence data for various proteins into this model, information about protein structure can be determined with high accuracy. This so-called embedding model needs to be trained only once and can then be used to ascertain a diverse set of information regarding the proteins of interest. In addition, this representation can be considered as pre-training for various applications of deep learning in bioinformatics.", "subjects": "Quantitative Methods (q-bio.QM)", "authors": "Ehsaneddin Asgari, Mohammad R.K. Mofrad,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05085", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05085", "title": "\nStronger Error Disturbance Relations for Incompatible Quantum  Measurements", "abstract": "We formulate three new error disturbance relations, one of which is free from explicit dependence upon intrinsic fluctuations of observables. The first error-disturbance relation is tighter than the one provided by the Branciard inequality and the Ozawa inequality for some initial states. Other two error disturbance relations provide a tighter bound to Ozawa's error disturbance relation and one of them is in fact tighter than the bound provided by Branciard's inequality for a small number of states.", "subjects": "Quantum Physics (quant-ph)", "authors": "Chiranjib Mukhopadhyay, Namrata Shukla, Arun Kumar Pati,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05081", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05081", "title": "\nThe Configuration Model for Partially Directed Graphs", "abstract": "The configuration model was originally defined for undirected networks and has recently been extended to directed networks. Many empirical networks are however neither undirected nor completely directed, but instead usually partially directed meaning that certain edges are directed and others are undirected. In the paper we define a configuration model for such networks where nodes have in-, out-, and undirected degrees that may be dependent. We prove conditions under which the resulting degree distributions converge to the intended degree distributions. The new model is shown to better approximate several empirical networks compared to undirected and completely directed networks.", "subjects": "Probability (math.PR)", "authors": "Kristoffer Spricer, Tom Britton,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04991", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04991", "title": "\nDyck algebras, interval temporal logic and posets of intervals", "abstract": "We investigate a natural Heyting algebra structure on the set of Dyck paths of the same length. We provide a geometrical description of the operations of pseudocomplement and relative pseudocomplement, as well as of regular elements. We also find a logic-theoretic interpretation of such Heyting algebras, which we call Dyck algebras, by showing that they are the algebraic counterpart of a certain fragment of a classical interval temporal logic (also known as Halpern-Shoham logic). Finally, we propose a generalization of our approach, suggesting a similar study of the Heyting algebra arising from the poset of intervals of a finite poset using Birkh \"off duality. In order to illustrate this, we show how several combinatorial parameters of Dyck paths can be expressed in terms of the Heyting algebra structure of Dyck algebras together with a certain total order on the set of atoms of each Dyck algebra.", "subjects": "Combinatorics (math.CO)", "authors": "Luca Ferrari,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04885", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04885", "title": "\nOptimal control of the state statistics for a linear stochastic system", "abstract": "We consider a variant of the classical linear quadratic Gaussian regulator (LQG) in which penalties on the endpoint state are replaced by the specification of the terminal state distribution. The resulting theory considerably differs from LQG as well as from formulations that bound the probability of violating state constraints. We develop results for optimal state-feedback control in the two cases where i) steering of the state distribution is to take place over a finite window of time with minimum energy, and ii) the goal is to maintain the state at a stationary distribution over an infinite horizon with minimum power. For both problems the distribution of noise and state are Gaussian. In the first case, we show that provided the system is controllable, the state can be steered to any terminal Gaussian distribution over any specified finite time-interval. In the second case, we characterize explicitly the covariance of admissible stationary state distributions that can be maintained with constant state-feedback control. The conditions for optimality are expressed in terms of a system of dynamically coupled Riccati equations in the finite horizon case and in terms of algebraic conditions for the stationary case. In the case where the noise and control share identical input channels, the Riccati equations for finite-horizon steering become homogeneous and can be solved in closed form. The present paper is largely based on our recent work in arxiv.org/abs/1408.2222, arxiv.org/abs/1410.3447 and presents an overview of certain key results.", "subjects": "Optimization and Control (math.OC)", "authors": "Yongxin Chen, Tryphon Georgiou, Michele Pavon,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04784", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04784", "title": "\nForecasting the Israeli 2015 elections using a smartphone application", "abstract": "We developed a smartphone application, Ha'Midgam, to poll and forecast the results of the 2015 Israeli elections. The application was downloaded by over 7,500 people. We present the method used to control bias in our sample and our forecasts. We discuss limitations of our approach and suggest possible solutions to control bias in similar applications.", "subjects": "Applications (stat.AP)", "authors": "Yoav Ram, Ofer Moshaioff, Idan Cohen, Omri Dor,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04776", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04776", "title": "\nPhase and TV Based Convex Sets for Blind Deconvolution of Microscopic  Images", "abstract": "In this article, two closed and convex sets for blind deconvolution problem are proposed. Most blurring functions in microscopy are symmetric with respect to the origin. Therefore, they do not modify the phase of the Fourier transform (FT) of the original image. As a result blurred image and the original image have the same FT phase. Therefore, the set of images with a prescribed FT phase can be used as a constraint set in blind deconvolution problems. Another convex set that can be used during the image reconstruction process is the epigraph set of Total Variation (TV) function. This set does not need a prescribed upper bound on the total variation of the image. The upper bound is automatically adjusted according to the current image of the restoration process. Both of these two closed and convex sets can be used as a part of any blind deconvolution algorithm. Simulation examples are presented.", "subjects": "Optimization and Control (math.OC)", "authors": "Mohammad Tofighi, Onur Yorulmaz, A. Enis Cetin,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04748", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04748", "title": "\nAsymmetric coloring games on incomparability graphs", "abstract": "Consider the following game on a graph : Alice and Bob take turns coloring the vertices of properly from a fixed set of colors; Alice wins when the entire graph has been colored, while Bob wins when some uncolored vertices have been left. The game chromatic number of is the minimum number of colors that allows Alice to win the game. The game Grundy number of is defined similarly except that the players color the vertices according to the first-fit rule and they only decide on the order in which it is applied. The -game chromatic and Grundy numbers are defined likewise except that Alice colors vertices and Bob colors vertices in each round. We study the behavior of these parameters for incomparability graphs of posets with bounded width. We conjecture a complete characterization of the pairs for which the -game chromatic and Grundy numbers are bounded in terms of the width of the poset; we prove that it gives a necessary condition and provide some evidence for its sufficiency. We also show that the game chromatic number is not bounded in terms of the Grundy number, which answers a question of Havet and Zhu.", "subjects": "Combinatorics (math.CO)", "authors": "Tomasz Krawczyk, Bartosz Walczak,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04717", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04717", "title": "\nOn the existence of compact \u03b5-approximated formulations for  knapsack in the original space", "abstract": "We show that there exists a family of Knapsack polytopes such that, for each polytope P from this family and each &gt; 0, any -approximated formulation of P in the original space R^n requires a number of inequalities that is super-polynomial in n. This answers a question by Bienstock and McClosky (2012). We also prove that, for any down-monotone polytope, an -approximated formulation in the original space can be obtained with inequalities using at most O(min),n/) different coefficients.", "subjects": "Optimization and Control (math.OC)", "authors": "Yuri Faenza, Laura Sanit\u00e0,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04682", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04682", "title": "\nInformation Content in Data Sets for a Nucleated-Polymerization Model", "abstract": "We illustrate the use of tools (asymptotic theories of standard error quantification using appropriate statistical models, bootstrapping, model comparison techniques) in addition to sensitivity that may be employed to determine the information content in data sets. We do this in the context of recent models [23] for nucleated polymerization in proteins, about which very little is known regarding the underlying mechanisms; thus the methodology we develop here may be of great help to experimentalists.", "subjects": "Analysis of PDEs (math.AP)", "authors": "H. T. Banks, M Doumic, C Kruse, S Prigent, H Rezaei,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04645", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04645", "title": "\nEvaluating kernels on Xeon Phi to accelerate Gysela application", "abstract": "This work describes the challenges presented by porting parts ofthe Gysela code to the Intel Xeon Phi coprocessor, as well as techniques used for optimization, vectorization and tuning that can be applied to other applications. We evaluate the performance of somegeneric micro-benchmark on Phi versus Intel Sandy Bridge. Several interpolation kernels useful for the Gysela application are analyzed and the performance are shown. Some memory-bound and compute-bound kernels are accelerated by a factor 2 on the Phi device compared to Sandy architecture. Nevertheless, it is hard, if not impossible, to reach a large fraction of the peek performance on the Phi device,especially for real-life applications as Gysela. A collateral benefit of this optimization and tuning work is that the execution time of Gysela (using 4D advections) has decreased on a standard architecture such as Intel Sandy Bridge.", "subjects": "Computational Physics (physics.comp-ph)", "authors": "G. Latu, M. Haefele, J. Bigot, V. Grandgirard, T. Cartier-Michaud, F. Rozar,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04610", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04610", "title": "\nInfinitely generated semigroups and polynomial complexity", "abstract": "This paper continues the functional approach to the P-versus-NP problem, begun in [1]. Here we focus on the monoid RM_2^P of right-ideal morphisms of the free monoid, that have polynomial input balance and polynomial time-complexity. We construct a machine model for the functions in RM_2^P, and evaluation functions. We prove that RM_2^P is not finitely generated, and use this to show separation results for time-complexity.", "subjects": "Group Theory (math.GR)", "authors": "J.C. Birget,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04585", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04585", "title": "\nStatistical Analysis of Loopy Belief Propagation based on Replica  Cluster Variation Method", "abstract": "The estimation of the statistical performances of signal processing systems that use Bayesian frameworks and Markov random fields (MRFs), such as Bayesian image restoration, is often reduced to the statistical mechanical analysis of spin models in random fields. Since many such systems have been implemented using the loopy belief propagation (LBP), which is equivalent to the Bethe approximation in statistical mechanics, in order to estimate their practical performances, we have to evaluate the statistical behavior of LBP in random fields. In this paper, we propose a message-passing type of method that allows quenched averages over random fields of Bethe free energies in general pair-wise MRFs to be analytically evaluated by using the replica cluster variation method. In the latter part of this paper, we describe the application of the proposed method to Bayesian image restoration, in which we observed that our theoretical results are in good agreement with numerical results.", "subjects": "Machine Learning (stat.ML)", "authors": "Muneki Yasuda, Shun Kataoka, Kazuyuki Tanaka,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04566", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04566", "title": "\nThe Kinematic Image of 2R Dyads and Exact Synthesis of 5R Linkages", "abstract": "We characterise the kinematic image of the constraint variety of a 2R dyad as a regular ruled quadric in a 3-space that contains a \"null quadrilateral\". Three prescribed poses determine, in general, two such quadrics. This allows us to modify a recent algorithm for the synthesis of 6R linkages in such a way that two consecutive revolute axes coincide, thus producing a 5R linkage. Using the classical geometry of twisted cubics on a quadric, we explain some of the peculiar properties of the the resulting synthesis procedure for 5R linkages.", "subjects": "Metric Geometry (math.MG)", "authors": "Tudor-Dan Rad, Hans-Peter Schr\u00f6cker,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04501", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04501", "title": "\nComputer Assisted Parallel Program Generation", "abstract": "Parallel computation is widely employed in scientific researches, engineering activities and product development. Parallel program writing itself is not always a simple task depending on problems solved. Large-scale scientific computing, huge data analyses and precise visualizations, for example, would require parallel computations, and the parallel computing needs the parallelization techniques. In this Chapter a parallel program generation support is discussed, and a computer-assisted parallel program generation system P-NCAS is introduced. Computer assisted problem solving is one of key methods to promote innovations in science and engineering, and contributes to enrich our society and our life toward a programming-free environment in computing science. Problem solving environments (PSE) research activities had started to enhance the programming power in 1970's. The P-NCAS is one of the PSEs; The PSE concept provides an integrated human-friendly computational software and hardware system to solve a target class of problems", "subjects": "Computational Physics (physics.comp-ph)", "authors": "Shigeo Kawata,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04500", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04500", "title": "\nA Residual Based Sparse Approximate Inverse Preconditioning Procedure  for Large Sparse Linear Systems", "abstract": "We investigate sparse approximate inverse preconditioning for large nonsymmetric linear systems. We revisit the SPAI algorithm proposed by Grote and Huckle [SIAM J. Sci. Comput., 18 (1997), pp.~838--853.], which is based on the F-norm minimization and updates approximate sparsity patterns adaptively. We show that SPAI may be costly and even impractical to implement, especially when a given coefficient matrix is irregular sparse, i.e., it has at least one relatively dense column. In this paper, we propose a residual based SPAI (RSAI) algorithm, which, in a different way from the SPAI algorithm, augments the sparsity pattern of an approximate inverse dynamically. The new procedure can be much less time consuming and more effective than SPAI to capture good approximate sparsity patterns of the inverse of a given sparse matrix. To control the sparsity of , we develop a practical RSAI() algorithm which drops small entries in magnitude generated during the setup process of . Numerical experiments are reported to verify the effectiveness of the RSAI algorithm, and numerical comparisons are made for the RSAI algorithm, the SPAI algorithm and the PSAI() algorithm. The results indicate that the RSAI algorithm is at least competitive to the SPAI algorithm and comparably as effective as the PSAI() for general problems.", "subjects": "Numerical Analysis (math.NA)", "authors": "Zhongxiao Jia, Wenjie Kang,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04468", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04468", "title": "\nOrdered Median Hub Location Problems with Capacity Constraints", "abstract": "The Single Allocation Ordered Median Hub Location problem is a recent hub model introduced in Puerto et al. (2011) that provides a unifying analysis of a wide class of hub location mod- els. In this paper, we deal with the capacitated version of this problem, presenting two formulations as well as some preprocessing phases for fixing variables. In addition, a strengthening of one of these formulations is also studied through the use of some fami- lies of valid inequalities. A battery of test problems with data taken from the AP library are solved where it is shown that the running times have been significantly reduced with the improvements presented in the paper.", "subjects": "Optimization and Control (math.OC)", "authors": "J. Puerto, A.B. Ramos, A.M. Rodriguez-Chia, M.C. Sanchez-Gil,", "date": "2015-3-15"}, 
{"urllink": "http://arxiv.org/abs/1503.04400", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04400", "title": "\nSeparable and non-separable data representation for pattern  discrimination", "abstract": "We provide a complete work-flow, based on the language of quantum information theory, suitable for processing data for the purpose of pattern recognition. The main advantage of the introduced scheme is that it can be easily implemented and applied to process real-world data using modest computation resources. At the same time it can be used to investigate the difference in the pattern recognition resulting from the utilization of the tensor product structure of the space of quantum states. We illustrate this difference by providing a simple example based on the classification of 2D data.", "subjects": "Quantum Physics (quant-ph)", "authors": "Jaros\u0142aw Adam Miszczak,", "date": "2015-3-15"}, 
{"urllink": "http://arxiv.org/abs/1503.04360", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04360", "title": "\nQuadratic Multi-Dimensional Signaling Games and Affine Equilibria", "abstract": "This paper studies the decentralized signaling problem when the encoder and the decoder, viewed as two decision makers, have misaligned objective functions. In particular, the study investigates extensions of the quadratic cheap talk and signaling game problem, which has been introduced in the economics literature. Two main contributions of this study are the extension of Crawford and Sobel's cheap talk formulation to multi-dimensional sources, and the extension to noisy channel setups as a signaling game problem. We show that, in the presence of misalignment, the quantized nature of all equilibrium policies holds for any scalar random source. It is shown that for multi-dimensional setups, unlike the scalar case, equilibrium policies may be of non-quantized nature, and even linear. In the noisy setup, a Gaussian source is to be transmitted over an additive Gaussian channel. The goals of the encoder and the decoder are misaligned by a bias term and encoder's cost also includes a power term scaled by a multiplier. Conditions for the existence of affine equilibrium policies as well as general informative equilibria are presented for both the scalar and multi-dimensional setups. Our findings provide further conditions on when affine policies may be optimal in decentralized multi-criteria control problems and lead to conditions for the presence of active information transmission in strategic environments.", "subjects": "Optimization and Control (math.OC)", "authors": "Serkan Sar\u0131ta\u015f, Serdar Y\u00fcksel, Sinan Gezici,", "date": "2015-3-14"}, 
{"urllink": "http://arxiv.org/abs/1503.04338", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04338", "title": "\nTowards radio astronomical imaging using an arbitrary basis", "abstract": "The new generation of radio telescopes, such as the Square Kilometer Array (SKA), requires dramatic advances in computer hardware and software, in order to process the large amounts of produced data efficiently. In this document, we explore a new approach to wide-field imaging. By generalizing the image reconstruction, which is performed by an inverse Fourier transform, to arbitrary transformations, we gain enormous new possibilities. In particular, we outline an approach that might allow to obtain a sky image of size P times Q in (optimal) O(PQ) time. This could be a step in the direction of real-time, wide-field sky imaging for future telescopes.", "subjects": "Instrumentation and Methods for Astrophysics (astro-ph.IM)", "authors": "Matthias Petschow,", "date": "2015-3-14"}, 
{"urllink": "http://arxiv.org/abs/1503.04337", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04337", "title": "\nCommunication-efficient sparse regression: a one-shot approach", "abstract": "We devise a one-shot approach to distributed sparse regression in the high-dimensional setting. The key idea is to average \"debiased\" lasso estimators. We show the approach converges at the same rate as the lasso when the dataset is not split across too many machines.", "subjects": "Machine Learning (stat.ML)", "authors": "Jason D. Lee, Yuekai Sun, Qiang Liu, Jonathan E. Taylor,", "date": "2015-3-14"}, 
{"urllink": "http://arxiv.org/abs/1503.04238", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04238", "title": "\nA Knapsack-Like Code Using Recurrence Sequence Representations", "abstract": "We had recently shown that every positive integer can be represented uniquely using a recurrence sequence, when certain restrictions on the digit strings are satisfied. We present the details of how such representations can be used to build a knapsack-like public key cryptosystem. We also present new disguising methods, and provide arguments for the security of the code against known methods of attack.", "subjects": "Number Theory (math.NT)", "authors": "Nathan Hamlin, Bala Krishnamoorthy, William Webb,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04213", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04213", "title": "\nEntropy power inequalities for qudits", "abstract": "Shannon's entropy power inequality (EPI) can be viewed as a statement of concavity of an entropic function of a continuous random variable under a scaled addition rule: f( sqrt ,X + sqrt ,Y) geq a f(X) + (1-a) f(Y) quad forall , a in [0,1]. Here, and are continuous random variables and the function is either the differential entropy or, for , the entropy power. Konig and Smith [IEEE Trans. Inf. Theory. 60(3):1536--1548, 2014] obtained quantum analogues of these inequalities for continuous-variable quantum systems, where and are replaced by bosonic fields and the addition rule is the action of a beamsplitter with transmissivity on those fields. In this paper, we similarly establish a class of EPI analogues for -level quantum systems (i.e. qudits). The underlying addition rule for which these inequalities hold is given by a quantum channel that depends on the parameter and acts like a finite-dimensional analogue of a beamsplitter with transmissivity , converting a two-qudit product state into a single qudit state. We refer to this channel as a partial swap channel because of the particular way its output interpolates between the states of the two qudits in the input as is changed from zero to one. We obtain analogues of Shannon's EPI, not only for the von Neumann entropy and the entropy power for the output of such channels, but for a much larger class of functions as well. This class includes the Renyi entropies and the subentropy. We also prove a qudit analogue of the entropy photon number inequality (EPnI). Finally, for the subclass of partial swap channels for which one of the qudit states in the input is fixed, our EPIs and EPnI yield lower bounds on the minimum output entropy and upper bounds on the Holevo capacity.", "subjects": "Quantum Physics (quant-ph)", "authors": "Koenraad Audenaert, Nilanjana Datta, Maris Ozols,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04194", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04194", "title": "\nADS: The Next Generation Search Platform", "abstract": "Four years after the last LISA meeting, the NASA Astrophysics Data System (ADS) finds itself in the middle of major changes to the infrastructure and contents of its database. In this paper we highlight a number of features of great importance to librarians and discuss the additional functionality that we are currently developing. Starting in 2011, the ADS started to systematically collect, parse and index full-text documents for all the major publications in Physics and Astronomy as well as many smaller Astronomy journals and arXiv e-prints, for a total of over 3.5 million papers. Our citation coverage has doubled since 2010 and now consists of over 70 million citations. We are normalizing the affiliation information in our records and, in collaboration with the CfA library and NASA, we have started collecting and linking funding sources with papers in our system. At the same time, we are undergoing major technology changes in the ADS platform which affect all aspects of the system and its operations. We have rolled out and are now enhancing a new high-performance search engine capable of performing full-text as well as metadata searches using an intuitive query language which supports fielded, unfielded and functional searches. We are currently able to index acknowledgments, affiliations, citations, funding sources, and to the extent that these metadata are available to us they are now searchable under our new platform. The ADS private library system is being enhanced to support reading groups, collaborative editing of lists of papers, tagging, and a variety of privacy settings when managing one's paper collection. While this effort is still ongoing, some of its benefits are already available through the ADS Labs user interface and API at this http URL", "subjects": "Instrumentation and Methods for Astrophysics (astro-ph.IM)", "authors": "Alberto Accomazzi, Michael J. Kurtz, Edwin A. Henneken, Roman Chyla, James Luker, Carolyn S. Grant, Donna M. Thompson, Alexandra Holachek, Rahul Dave, Stephen S. Murray,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04135", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04135", "title": "\nTransitive reasoning with imprecise probabilities", "abstract": "We study probabilistically informative (weak) versions of transitivity, by using suitable definitions of defaults and negated defaults, in the setting of coherence and imprecise probabilities. We represent p-consistent sequences of defaults and/or negated defaults by g-coherent imprecise probability assessments on the respective sequences of conditional events. Finally, we prove the coherent probability propagation rules for Weak Transitivity and the validity of selected inference patterns by proving the p-entailment for the associated knowledge bases.", "subjects": "Probability (math.PR)", "authors": "Angelo Gilio, Niki Pfeifer, Giuseppe Sanfilippo,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04127", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04127", "title": "\nImage patch analysis of sunspots and active regions. I. Intrinsic  dimension and correlation analysis", "abstract": "Complexity of an active region is related to its flare-productivity. Mount Wilson or McIntosh sunspot classifications measure such complexity but in a categorical way, and may therefore not use all the information present in the observations. Moreover, such categorical schemes hinder a systematic study of an active region's evolution for example. We propose fine-scale quantitative descriptors for an active region's complexity and relate them to the Mount Wilson classification. We analyze the local correlation structure within continuum and magnetogram data, as well as the cross-correlation between continuum and magnetogram data. We compute the intrinsic dimension, partial correlation, and canonical correlation analysis (CCA) of image patches of continuum and magnetogram active region images taken from the SOHO-MDI instrument. We use masks of sunspots derived from continuum as well as larger masks of magnetic active regions derived from the magnetogram to analyze separately the core part of an active region from its surrounding part. We find the relationship between complexity of an active region as measured by Mount Wilson and the intrinsic dimension of its image patches. Partial correlation patterns exhibit approximately a third-order Markov structure. CCA reveals different patterns of correlation between continuum and magnetogram within the sunspots and in the region surrounding the sunspots. These results also pave the way for patch-based dictionary learning with a view towards automatic clustering of active regions.", "subjects": "Solar and Stellar Astrophysics (astro-ph.SR)", "authors": "Kevin R. Moon, Jimmy J. Li, Veronique Delouille, Ruben De Visscher, Fraser Watson, Alfred O. Hero III,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04099", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04099", "title": "\nAlgorithms and complexity for Turaev-Viro invariants", "abstract": "The Turaev-Viro invariants are a powerful family of topological invariants for distinguishing between different 3-manifolds. They are invaluable for mathematical software, but current algorithms to compute them require exponential time. The invariants are parameterised by an integer . We resolve the question of complexity for and , giving simple proofs that computing Turaev-Viro invariants for is polynomial time, but for is #P-hard. Moreover, we give an explicit fixed-parameter tractable algorithm for arbitrary , and show through concrete implementation and experimentation that this algorithm is practical---and indeed preferable---to the prior state of the art for real computation.", "subjects": "Geometric Topology (math.GT)", "authors": "Benjamin A. Burton, Cl\u00e9ment Maria, Jonathan Spreer,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04085", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04085", "title": "\nUnwinding the \"hairball\" graph: a pruning algorithm for weighted complex  networks", "abstract": "Empirical networks of weighted dyadic relations often contain \"noisy\" edges that alter the global characteristics of the network and obfuscate the most important structures therein. Graph pruning is the process of identifying the most significant edges according to a generative null model, and extracting the subgraph consisting of those edges. Here we introduce a simple and intuitive null model based on the configuration model of network generation, and derive a significance filter from it. We apply the filter to the network of air traffic volume between US airports and recover a geographically faithful representation of the graph. Furthermore, compared with thresholding based on edge weight, we show that our filter extracts a larger giant component that is nevertheless significantly sparser.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Navid Dianati,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.04066", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04066", "title": "\nCompensating for population sampling in simulations of epidemic spread  on temporal contact networks", "abstract": "Data describing human interactions often suffer from incomplete sampling of the underlying population. As a consequence, the study of contagion processes using data-driven models can lead to a severe underestimation of the epidemic risk. Here we present a systematic method to correct this bias and obtain an accurate estimation of the risk in the context of epidemic models informed by high-resolution time-resolved contact data. We consider several such data sets collected in various contexts and perform controlled resampling experiments. We show that the statistical information contained in the resampled data allows us to build surrogate versions of the unknown contacts and that simulations of epidemic processes using these surrogate data sets yield good estimates of the outcome of simulations performed using the complete data set. We discuss limitations and potential improvements of our method.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Mathieu G\u00e9nois, Christian L. Vestergaard, Ciro Cattuto, Alain Barrat,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04058", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04058", "title": "\nOptimal redundancy against disjoint vulnerabilities in networks", "abstract": "Redundancy is commonly used to guarantee continued functionality in networked systems. However, often many nodes are vulnerable to the same failure or adversary. A \"backup\" path is not sufficient if both paths depend on nodes which share a vulnerability.For example, if two nodes of the Internet cannot be connected without using routers belonging to a given untrusted entity, then all of their communication-regardless of the specific paths utilized-will be intercepted by the controlling entity.In this and many other cases, the vulnerabilities affecting the network are disjoint: each node has exactly one vulnerability but the same vulnerability can affect many nodes. To discover optimal redundancy in this scenario, we describe each vulnerability as a color and develop a \"color-avoiding percolation\" which uncovers a hidden color-avoiding connectivity. We present algorithms for color-avoiding percolation of general networks and an analytic theory for random graphs with uniformly distributed colors including critical phenomena. We demonstrate our theory by uncovering the hidden color-avoiding connectivity of the Internet. We find that less well-connected countries are more likely able to communicate securely through optimally redundant paths than highly connected countries like the US. Our results reveal a new layer of hidden structure in complex systems and can enhance security and robustness through optimal redundancy in a wide range of systems including biological, economic and communications networks.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Sebastian M. Krause, Michael M. Danziger, Vinko Zlati\u0107,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04003", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04003", "title": "\nA tropical optimization approach in the analysis of pairwise comparison  matrices", "abstract": "We propose a new approach to solve the problem of rating alternatives based on their pairwise comparison. The problem is formulated in terms of tropical algebra, and then reduced to the approximation of pairwise comparison matrices by reciprocal matrices of unit rank. We represent the approximation problem in a common form for both multiplicative and additive comparison scales. To solve the problem obtained, tropical optimization techniques are applied to provide new complete direct solutions to the rating problems in a compact vector form, which extend known solutions and involve less computational efforts. The results are illustrated with numerical examples.", "subjects": "Optimization and Control (math.OC)", "authors": "N. Krivulin,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.03923", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03923", "title": "\nExtremal Cuts of Sparse Random Graphs", "abstract": "For Erd Hs-R 'enyi random graphs with average degree , and uniformly random -regular graph on vertices, we prove that with high probability the size of both the Max-Cut and maximum bisection are while the size of the minimum bisection is . Our derivation relates the free energy of the anti-ferromagnetic Ising model on such graphs to that of the Sherrington-Kirkpatrick model, with standing for the ground state energy of the latter, expressed analytically via Parisi's formula.", "subjects": "Probability (math.PR)", "authors": "Amir Dembo, Andrea Montanari, Subhabrata Sen,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.03893", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03893", "title": "\nCompact Nonlinear Maps and Circulant Extensions", "abstract": "Kernel approximation via nonlinear random feature maps is widely used in speeding up kernel machines. There are two main challenges for the conventional kernel approximation methods. First, before performing kernel approximation, a good kernel has to be chosen. Picking a good kernel is a very challenging problem in itself. Second, high-dimensional maps are often required in order to achieve good performance. This leads to high computational cost in both generating the nonlinear maps, and in the subsequent learning and prediction process. In this work, we propose to optimize the nonlinear maps directly with respect to the classification objective in a data-dependent fashion. The proposed approach achieves kernel approximation and kernel learning in a joint framework. This leads to much more compact maps without hurting the performance. As a by-product, the same framework can also be used to achieve more compact kernel maps to approximate a known kernel. We also introduce Circulant Nonlinear Maps, which uses a circulant-structured projection matrix to speed up the nonlinear maps for high-dimensional data.", "subjects": "Machine Learning (stat.ML)", "authors": "Felix X. Yu, Sanjiv Kumar, Henry Rowley, Shih-Fu Chang,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03888", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03888", "title": "\nLogspace and compressed-word computations in nilpotent groups", "abstract": "For finitely generated nilpotent groups, we employ Mal'cev coordinates to solve several classical algorithmic problems efficiently. Computation of normal forms, the membership problem, the conjugacy problem, and computation of presentations for subgroups are solved using only logarithmic space and, simultaneously, in quasilinear time. Compressed-word versions of these problems, in which each input word is provided as a straight-line program, are solved in polynomial time.", "subjects": "Group Theory (math.GR)", "authors": "Jeremy Macdonald, Alexei Myasnikov, Andrey Nikolaev, Svetla Vassileva,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03769", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03769", "title": "\nDistributed Computation Particle PHD filter", "abstract": "Particle probability hypothesis density filtering has become a promising means for multi-target tracking due to its capability of handling an unknown and time-varying number of targets in non-linear non-Gaussian system. However, its computational complexity grows linearly with the number of measurements and particles assigned to each target, and this can be very time consuming especially when numerous targets and clutter exist in the surveillance region. Addressing this issue, we present a distributed computation particle PHD filter for target tracking. Its framework consists of several local particle PHD filters at each processing element and a central unit. Each processing element takes responsibility for part particles but full measurements and provides local estimates; central unit controls particle exchange between processing elements and specifies a fusion rule to match and fuse the estimates from different local filters. The proposed framework is suitable for parallel implementation and maintains the tracking accuracy. Simulations verify the proposed method can provide comparative accuracy as well as a significant speedup with the standard particle PHD filter.", "subjects": "Computation (stat.CO)", "authors": "Wang Junjie, Zhao Lingling, Su Xiaohong, Ma Peijun,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.03746", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03746", "title": "\nDivision of labor, skill complementarity, and heterophily in  socioeconomic networks", "abstract": "Constituents of complex systems interact with each other and self-organize to form complex networks. Empirical results show that the link formation process of many real networks follows either the global principle of popularity or the local principle of similarity or a tradeoff between the two. In particular, it has been shown that in social networks individuals exhibit significant homophily when choosing their collaborators. We demonstrate, however, that in populations in which there is a division of labor, skill complementarity is an important factor in the formation of socioeconomic networks and an individual's choice of collaborators is strongly affected by heterophily. We analyze 124 evolving virtual worlds of a popular \"massively multiplayer online role-playing game\" (MMORPG) in which people belong to three different professions and are allowed to work and interact with each other in a somewhat realistic manner. We find evidence of heterophily in the formation of collaboration networks, where people prefer to forge social ties with people who have professions different from their own. We then construct an economic model to quantify the heterophily by assuming that individuals in socioeconomic systems choose collaborators that are of maximum utility. The results of model calibration confirm the presence of heterophily. Both empirical analysis and model calibration show that the heterophilous feature is persistent along the evolution of virtual worlds. We also find that the degree of complementarity in virtual societies is positively correlated with their economic output. Our work sheds new light on the scientific research utility of virtual worlds for studying human behaviors in complex socioeconomic systems.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Wen-Jie Xie, Ming-Xia Li, Zhi-Qiang Jiang, Qun-Zhao Tan, Boris Podobnik, Wei-Xing Zhou, H. Eugene Stanley,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03715", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03715", "title": "\nFeedback Refinement Relations for the Synthesis of Symbolic Controllers", "abstract": "We present an abstraction and refinement methodology for the automated controller synthesis to enforce general predefined specifications. The designed controllers require quantized (or symbolic) state information only and can be interfaced with the system via a static quantizer. Both features are particularly important with regard to any practical implementation of the designed controller and, as we prove, are characterized by the existence of a feedback refinement relation between plant and abstraction. Feedback refinement relations are a novel concept of system relations introduced in this paper. Our work builds on a general notion of system with set-valued dynamics and possibly non-deterministic quantizers to permit the synthesis of controllers that robustly, and provably, enforce the specification in the presence of various types of uncertainties and disturbances. We identify a class of abstractions that is canonical in a well-defined sense, and provide a method to efficiently compute canonical abstractions of perturbed nonlinear sampled systems. We demonstrate the practicality of our approach on two examples -- a path planning problem for a mobile robot and an aircraft landing maneuver.", "subjects": "Optimization and Control (math.OC)", "authors": "Gunther Reissig, Alexander Weber, Matthias Rungger,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03701", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03701", "title": "\nHierarchical learning of grids of microtopics", "abstract": "The counting grid is a grid of sparse word/feature distributions, called microtopics. A generative model does not use these microtopics individually, rather it groups them in overlapping rectangular windows and uses these grouped microtopics as either mixture or admixture components. This paper builds upon the basic counting grid model and it shows that hierarchical reasoning helps avoid local minima, produces better classification accuracy and, most interestingly, allows for extraction of large numbers of coherent microtopics from small datasets. We evaluate this in terms of consistency, diversity and clarity of the indexed content, as well as in a user study on word intrusion tasks. Finally, we also discuss interesting parallels between these models and other deep architectures.", "subjects": "Machine Learning (stat.ML)", "authors": "Nebojsa Jojic, Alessandro Perina, Dongwoo Kim,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03669", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03669", "title": "\nThe Vietoris-Rips complexes of a circle", "abstract": "Given a metric space X and a distance threshold r&gt;0, the Vietoris-Rips simplicial complex has as its simplices the finite subsets of X of diameter less than r. A theorem of Jean-Claude Hausmann states that if X is a Riemannian manifold and r is sufficiently small, then the Vietoris-Rips complex is homotopy equivalent to the original manifold. Little is known about the behavior of Vietoris-Rips complexes for larger values of r, even though these complexes arise naturally in applications using persistent homology. We show that as r increases, the Vietoris-Rips complex of the circle obtains the homotopy types of the circle, the 3-sphere, the 5-sphere, the 7-sphere, ..., until finally it is contractible. As our main tool we introduce a directed graph invariant, the winding fraction, which in some sense is dual to the circular chromatic number. Using the winding fraction we classify the homotopy types of the Vietoris-Rips complex of an arbitrary (possibly infinite) subset of the circle, and we study the expected homotopy type of the Vietoris-Rips complex of a uniformly random sample from the circle. Moreover, we show that as the distance parameter increases, the ambient Cech complex of the circle also obtains the homotopy types of the circle, the 3-sphere, the 5-sphere, the 7-sphere, ..., until finally it is contractible.", "subjects": "Algebraic Topology (math.AT)", "authors": "Michal Adamaszek, Henry Adams,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03613", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03613", "title": "\nOn the Impossibility of Learning the Missing Mass", "abstract": "This paper shows that one cannot learn the probability of rare events without imposing further structural assumptions. The event of interest is that of obtaining an outcome outside the coverage of an i.i.d. sample from a discrete distribution. The probability of this event is referred to as the \"missing mass\". The impossibility result can then be stated as: the missing mass is not distribution-free PAC-learnable in relative error. The proof is semi-constructive and relies on a coupling argument using a dithered geometric distribution. This result formalizes the folklore that in order to predict rare events, one necessarily needs distributions with \"heavy tails\".", "subjects": "Machine Learning (stat.ML)", "authors": "Elchanan Mossel, Mesrob I. Ohannessian,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03528", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03528", "title": "\nStudy of decoherence of entangled states made up of two basic states in  a linear chain of three qubits", "abstract": "Using Lindblad approach to study decoherence of quantum systems, we study the decoherence and decay of entangled states, formed by two basic states of a chain of thee qubits. We look on these states for a possible regular dependence on their decay as a function of their energy separation between the basic states under different type of environments. We found not regular or significant dependence on this energy separation for the type of environment considered .", "subjects": "Quantum Physics (quant-ph)", "authors": "Gustavo V. Lopez, Gustavo Montes,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03524", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03524", "title": "\nDescribing and Understanding Neighborhood Characteristics through Online  Social Media", "abstract": "Geotagged data can be used to describe regions in the world and discover local themes. However, not all data produced within a region is necessarily specifically descriptive of that area. To surface the content that is characteristic for a region, we present the geographical hierarchy model (GHM), a probabilistic model based on the assumption that data observed in a region is a random mixture of content that pertains to different levels of a hierarchy. We apply the GHM to a dataset of 8 million Flickr photos in order to discriminate between content (i.e., tags) that specifically characterizes a region (e.g., neighborhood) and content that characterizes surrounding areas or more general themes. Knowledge of the discriminative and non-discriminative terms used throughout the hierarchy enables us to quantify the uniqueness of a given region and to compare similar but distant regions. Our evaluation demonstrates that our model improves upon traditional Naive Bayes classification by 47% and hierarchical TF-IDF by 27%. We further highlight the differences and commonalities with human reasoning about what is locally characteristic for a neighborhood, distilled from ten interviews and a survey that covered themes such as time, events, and prior regional knowledge", "subjects": "Machine Learning (stat.ML)", "authors": "Mohamed Kafsi, Henriette Cramer, Bart Thomee, David A. Shamma,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03492", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03492", "title": "\nParallel Statistical Multi-resolution Estimation", "abstract": "We discuss several strategies to implement Dykstra's projection algorithm on NVIDIA's compute unified device architecture (CUDA). Dykstra's algorithm is the central step in and the computationally most expensive part of statistical multi-resolution methods. It projects a given vector onto the intersection of convex sets. Compared with a CPU implementation our CUDA implementation is one order of magnitude faster. For a further speed up and to reduce memory consumption we have developed a new variant, which we call incomplete Dykstra's algorithm. Implemented in CUDA it is one order of magnitude faster than the CUDA implementation of the standard Dykstra algorithm. As sample application we discuss using the incomplete Dykstra's algorithm as preprocessor for the recently developed super-resolution optical fluctuation imaging (SOFI) method (Dertinger et al. 2009). We show that statistical multi-resolution estimation can enhance the resolution improvement of the plain SOFI algorithm just as the Fourier-reweighting of SOFI. The results are compared in terms of their power spectrum and their Fourier ring correlation (Saxton and Baumeister 1982). The Fourier ring correlation indicates that the resolution for typical second order SOFI images can be improved by about 30 per cent. Our results show that a careful parallelization of Dykstra's algorithm enables its use in large-scale statistical multi-resolution analyses.", "subjects": "Computational Physics (physics.comp-ph)", "authors": "Jan Lebert, Lutz K\u00fcnneke, Johannes Hagemann, Stephan C. Kramer,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.03467", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03467", "title": "\nMulti-grid with rough coefficients and Multiresolution operator  decomposition from Hierarchical Information Games", "abstract": "We introduce a -complexity (geometric and meshless/algebraic) multigrid method for PDEs with rough () coefficients with rigorous a-priori accuracy and performance estimates. The method is discovered through a decision theory/information game formulation of the problems of (1) identifying restriction and interpolation operators (2) recovering a signal from incomplete measurements based on norm constraints on its image under a linear operator (3) gambling on the value of the solution of the PDE based on a hierarchy of nested measurements of its solution or source term. The resulting elementary gambles form a hierarchy of (deterministic) basis functions of (gamblets) that (1) are orthogonal across subscales/subband with respect to the scalar product induced by the energy norm of the PDE (2) enable sparse compression of the solution space in (3) induce a orthogonal multiresolution operator decomposition. The operating diagram of the multigrid method is that of an inverted pyramid in which gamblets are computed locally (by virtue of their exponential decay), hierarchically (from fine to coarse scales) and the PDE is decomposed into a hierarchy of independent linear systems with uniformly bounded condition numbers. The resulting algorithm is parallelizable both in space (via localization) and in bandwith/subscale (subscales can be computed independently from each other). Although the method is deterministic it has a natural Bayesian interpretation under the measure of probability emerging (as a mixed strategy) from the information game formulation and multiresolution approximations form a martingale with respect to the filtration induced by the hierarchy of nested measurements.", "subjects": "Numerical Analysis (math.NA)", "authors": "Houman Owhadi,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03383", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03383", "title": "\nAn Explicit SOS Decomposition of A Fourth Order Four Dimensional Hankel  Tensor with A Symmetric Generating Vector", "abstract": "In this note, we construct explicit SOS decomposition of A Fourth Order Four Dimensional Hankel Tensor with A Symmetric Generating Vector, at the critical value. This is a supplementary note to Paper [3].", "subjects": "Optimization and Control (math.OC)", "authors": "Yannan Chen, Liqun Qi, Qun Wang,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.03355", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03355", "title": "\nAutomatic Unsupervised Tensor Mining with Quality Assessment", "abstract": "A popular tool for unsupervised modelling and mining multi-aspect data is tensor decomposition. In an exploratory setting, where and no labels or ground truth are available how can we automatically decide how many components to extract? How can we assess the quality of our results, so that a domain expert can factor this quality measure in the interpretation of our results? In this paper, we introduce AutoTen, a novel automatic unsupervised tensor mining algorithm with minimal user intervention, which leverages and improves upon heuristics that assess the result quality. We extensively evaluate AutoTen's performance on synthetic data, outperforming existing baselines on this very hard problem. Finally, we apply AutoTen on a variety of real datasets, providing insights and discoveries. We view this work as a step towards a fully automated, unsupervised tensor mining tool that can be easily adopted by practitioners in academia and industry.", "subjects": "Machine Learning (stat.ML)", "authors": "Evangelos E. Papalexakis,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03314", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03314", "title": "\nRelaxed Logarithmic Barrier Function Based Model Predictive Control of  Linear Systems", "abstract": "In this paper, we investigate the use of relaxed logarithmic barrier functions in the context of linear model predictive control. We present results that allow to guarantee asymptotic stability of the corresponding closed-loop system, and discuss further properties like performance and constraint satisfaction in dependence of the underlying relaxation. The proposed stabilizing MPC schemes are not necessarily based on an explicit terminal set or state constraint and allow to characterize the stabilizing control input sequence as the minimizer of a globally defined, continuously differentiable, and strongly convex function. The results are illustrated by means of a numerical example.", "subjects": "Optimization and Control (math.OC)", "authors": "Christian Feller, Christian Ebenbauer,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03231", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03231", "title": "\nAdaptive-Rate Sparse Signal Reconstruction With Application in  Compressive Background Subtraction", "abstract": "We propose and analyze an online algorithm for reconstructing a sequence of signals from a limited number of linear measurements. The signals are assumed sparse, with unknown support, and evolve over time according to a generic nonlinear dynamical model. Our algorithm, based on recent theoretical results for - minimization, is recursive and computes the number of measurements to be taken at each time on-the-fly. As an example, we apply the algorithm to compressive video background subtraction, a problem that can be stated as follows: given a set of measurements of a sequence of images with a static background, simultaneously reconstruct each image while separating its foreground from the background. The performance of our method is illustrated on sequences of real images: we observe that it allows a dramatic reduction in the number of measurements with respect to state-of-the-art compressive background subtraction schemes.", "subjects": "Optimization and Control (math.OC)", "authors": "Joao F. C. Mota, Nikos Deligiannis, Aswin C. Sankaranarayanan, Volkan Cevher, Miguel R. D. Rodrigues,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03199", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03199", "title": "\nPersistence of activity on Twitter triggered by a natural disaster: A  data analysis", "abstract": "In this note, we list the results of a simple analysis of a Twitter dataset: the complete dataset of Japanese tweets in the 1-week period after the Great East Japan earthquake, which occurred on March 11, 2011. Our data analysis shows how people reacted to the earthquake on Twitter and how some users went inactive in the long-term.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Tatsuro Kawamoto,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03132", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03132", "title": "\nL_1-regularized Boltzmann machine learning using majorizer minimization", "abstract": "We propose an inference method to estimate sparse interactions and biases according to Boltzmann machine learning. The basis of this method is regularization, which is often used in compressed sensing, a technique for reconstructing sparse input signals from undersampled outputs. regularization impedes the simple application of the gradient method, which optimizes the cost function that leads to accurate estimations, owing to the cost function's lack of smoothness. In this study, we utilize the majorizer minimization method, which is a well-known technique implemented in optimization problems, to avoid the non-smoothness of the cost function. By using the majorizer minimization method, we elucidate essentially relevant biases and interactions from given data with seemingly strongly-correlated components.", "subjects": "Machine Learning (stat.ML)", "authors": "Masayuki Ohzeki,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03061", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03061", "title": "\nHyperbolicity Measures \"Democracy\" in Real-World Networks", "abstract": "We analyze the hyperbolicity of real-world networks, a geometric quantity that measures if a space is negatively curved. In our interpretation, a network with small hyperbolicity is \"aristocratic\", because it contains a small set of vertices involved in many shortest paths, so that few elements \"connect\" the systems, while a network with large hyperbolicity has a more \"democratic\" structure with a larger number of crucial elements. We prove mathematically the soundness of this interpretation, and we derive its consequences by analyzing a large dataset of real-world networks. We confirm and improve previous results on hyperbolicity, and we analyze them in the light of our interpretation. Moreover, we study (for the first time in our knowledge) the hyperbolicity of the neighborhood of a given vertex. This allows to define an \"influence area\" for the vertices in the graph. We show that the influence area of the highest degree vertex is small in what we define \"local\" networks, like most social or peer-to-peer networks. On the other hand, if the network is built in order to reach a \"global\" goal, as in metabolic networks or autonomous system networks, the influence area is much larger, and it can contain up to half the vertices in the graph. In conclusion, our newly introduced approach allows to distinguish the topology and the structure of various complex networks.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Michele Borassi, Alessandro Chessa, Guido Caldarelli,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.03049", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03049", "title": "\nOn a conjecture of Tsfasman and an inequality of Serre for the number of  points on hypersurfaces over finite fields", "abstract": "We give a short proof of an inequality, conjectured by Tsfasman and proved by Serre, for the maximum number of points on hypersurfaces over finite fields. Further, we consider a conjectural extension, due to Tsfasman and Boguslavsky, of this inequality to an explicit formula for the maximum number of common solutions of a system of linearly independent multivariate homogeneous polynomials of the same degree with coefficients in a finite field. This conjecture is shown to be false, in general, but is also shown to hold in the affirmative in a special case. Applications to generalized Hamming weights of projective Reed-Muller codes are outlined and a comparison with an older conjecture of Lachaud and a recent result of Couvreur is given.", "subjects": "Algebraic Geometry (math.AG)", "authors": "Mrinmoy Datta, Sudhir R. Ghorpade,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.03022", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03022", "title": "\nA novel method based on cross correlation maximization, for pattern  matching by means of a single parameter. Application to the human voice", "abstract": "This work develops a cross correlation maximization technique, based on statistical concepts, for pattern matching purposes in time series. The technique analytically quantifies the extent of similitude between a known signal within a group of data, by means of a single parameter. Specifically, the method was applied to voice recognition problem, by selecting samples from a given individual recordings of the 5 vowels, in Spanish. The frequency of acquisition of the data was 11.250 Hz. A certain distinctive interval was established from each vowel time series as a representative test function and it was compared both to itself and to the rest of the vowels by means of an algorithm, for a subsequent graphic illustration of the results. We conclude that for a minimum distinctive length, the method meets resemblance between every vowel with itself, and also an irrefutable difference with the rest of the vowels for an estimate length of 30 points (~2 10-3 s).", "subjects": "Applications (stat.AP)", "authors": "Felipe Quiero, Fabian Quintana, Leonardo Bennun,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.03016", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03016", "title": "\nRemarks on pointed digital homotopy", "abstract": "We show that homotopy equivalent digital images have isomorphic fundamental groups, even when the homotopy equivalence does not preserve the basepoint. This assertion appeared in~ cite, but there was an error in the proof; here, we correct the error. We present and explore in detail a pair of digital images with -adjacencies that are homotopic but not pointed homotopic. For two digital loops with the same basepoint, we introduce the notion of tight at the basepoint (TAB) pointed homotopy, which is more restrictive than ordinary pointed homotopy and yields some different results.", "subjects": "Combinatorics (math.CO)", "authors": "Laurence Boxer, P. Christopher Staecker,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.03009", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03009", "title": "\nEquivalence of topological color codes (without translational symmetry)  to surface codes", "abstract": "In a recent work, Bombin, Duclos-Cianci, and Poulin showed that every local translationally invariant 2D topological stabilizer code is locally equivalent to a finite number of copies of Kitaev's toric code. In this paper, we focus on color codes and relax the constraint on translation invariance. We show that any color code can be mapped to exactly two copies of a related surface code. The surface code in our map is induced by the color code and easily derived from the color code. Furthermore, our map does not require any ancilla qubits for the surface codes. We also indicate the various degrees of freedom in constructing the map and the consequent variations.", "subjects": "Quantum Physics (quant-ph)", "authors": "Arjun Bhagoji, Pradeep Sarvepalli,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.03008", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03008", "title": "\nReversibility in the Extended Measurement-based Quantum Computation", "abstract": "When applied on some particular quantum entangled states, measurements are universal for quantum computing. In particular, despite the fondamental probabilistic evolution of quantum measurements, any unitary evolution can be simulated by a measurement-based quantum computer (MBQC). We consider the extended version of the MBQC where each measurement can occur not only in the (X,Y)-plane of the Bloch sphere but also in the (X,Z)- and (Y,Z)-planes. The existence of a gflow in the underlying graph of the computation is a necessary and sufficient condition for a certain kind of determinism. We extend the focused gflow (a gflow in a particular normal form) defined for the (X,Y)-plane to the extended case, and we provide necessary and sufficient conditions for the existence of such normal forms.", "subjects": "Quantum Physics (quant-ph)", "authors": "Nidhal Hamrit, Simon Perdrix,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02974", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02974", "title": "\nModelling Computational Resources for Next Generation Sequencing  Bioinformatics Analysis of 16S rRNA Samples", "abstract": "In the rapidly evolving domain of next generation sequencing and bioinformatics analysis, data generation is one aspect that is increasing at a concomitant rate. The burden associated with processing large amounts of sequencing data has emphasised the need to allocate sufficient computing resources to complete analyses in the shortest possible time with manageable and predictable costs. A novel method for predicting time to completion for a popular bioinformatics software (QIIME), was developed using key variables characteristic of the input data assumed to impact processing time. Multiple Linear Regression models were developed to determine run time for two denoising algorithms and a general bioinformatics pipeline. The models were able to accurately predict clock time for denoising sequences from a naturally assembled community dataset, but not an artificial community. Speedup and efficiency tests for AmpliconNoise also highlighted that caution was needed when allocating resources for parallel processing of data. Accurate modelling of computational processing time using easily measurable predictors can assist NGS analysts in determining resource requirements for bioinformatics software and pipelines. Whilst demonstrated on a specific group of scripts, the methodology can be extended to encompass other packages running on multiple architectures, either in parallel or sequentially.", "subjects": "Genomics (q-bio.GN)", "authors": "Matthew J. Wade, Thomas P. Curtis, Russell J. Davenport,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02905", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02905", "title": "\nVoluntary rewards mediate the evolution of pool punishment for  maintaining public goods in large populations", "abstract": "Punishment is a popular tool when governing commons in situations where free riders would otherwise take over. It is well known that sanctioning systems, such as the police and courts, are costly and thus can suffer from those who free ride on other's efforts to maintain the sanctioning systems (second-order free riders). Previous game-theory studies showed that if populations are very large, pool punishment rarely emerges in public good games, even when participation is optional, because of second-order free riders. Here we show that a matching fund for rewarding cooperation leads to the emergence of pool punishment, despite the presence of second-order free riders. We demonstrate that reward funds can pave the way for a transition from a population of free riders to a population of pool punishers. A key factor in promoting the transition is also to reward those who contribute to pool punishment, yet not abstaining from participation. Reward funds eventually vanish in raising pool punishment, which is sustainable by punishing the second-order free riders. This suggests that considering the interdependence of reward and punishment may help to better understand the origins and transitions of social norms and institutions.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Tatsuya Sasaki, Satoshi Uchida, Xiaojie Chen,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02903", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02903", "title": "\nTwo-step Input Spatial Auditory BCI for Japanese Kana Characters", "abstract": "We present an auditory stimulus optimization and a pilot study of a two-step input speller application combined with a spatial auditory brain-computer interface (saBCI) for paralyzed users. The application has been developed for 45, out of 48 defining the full set, Japanese kana characters in a two-step input procedure setting for an easy-to-use BCI-speller interface. The user first selects the representative letter of a subset, defining the second step. In the second step, the final choice is made. At each interfacing step, the choices are classified based on the P300 event related potential (ERP) responses captured in the EEG, as in the classic oddball paradigm. The BCI online experiment and EEG responses classification results of the pilot study confirm the effectiveness of the proposed spelling method.", "subjects": "Neurons and Cognition (q-bio.NC)", "authors": "Moonjeong Chang, Tomasz M. Rutkowski,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02872", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02872", "title": "\nAccuracy Test for Link Prediction in terms of Similarity Index: The Case  of WS and BA Models", "abstract": "Link prediction is a technique that uses the topological information in a given network to infer the missing links in it. Since past research on link prediction has primarily focused on enhancing performance for given empirical systems, negligible attention has been devoted to link prediction with regard to network models. In this paper, we thus apply link prediction to two network models: The Watts-Strogatz (WS) model and Barab 'asi-Albert (BA) model. We attempt to gain a better understanding of the relation between accuracy and each network parameter (mean degree, the number of nodes and the rewiring probability in the WS model) through network models. Six similarity indices are used, with precision and area under the ROC curve (AUC) value as the accuracy metrics. We observe a positive correlation between mean degree and accuracy, and size independence of the AUC value.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Min-Woo Ahn, Woo-Sung Jung,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02868", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02868", "title": "\nQuantum Algorithm for Monotonicity Testing on the Hypercube", "abstract": "In this note, we develop a bounded-error quantum algorithm that makes queries to a Boolean function , accepts a monotone function, and rejects a function that is -far from being monotone. This gives a super-quadratic improvement compared to the best known randomized algorithm for all . The improvement is cubic when .", "subjects": "Quantum Physics (quant-ph)", "authors": "Aleksandrs Belovs, Eric Blais,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02859", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02859", "title": "\nDimension of the Lisbon voting rules in the EU Council: a challenge and  new world record", "abstract": "The new voting system of the Council of the European Union cannot be represented as the intersection of six or fewer weighted games, i.e., its dimension is at least 7. This sets a new record for real-world voting bodies. A heuristic combination of different discrete optimization methods yields a representation as the intersection of 13368 weighted games. Determination of the exact dimension is posed as a challenge to the community. The system's Boolean dimension is proven to be 3.", "subjects": "Optimization and Control (math.OC)", "authors": "Sascha Kurz, Stefan Napel,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02834", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02834", "title": "\nDoubly Robust Policy Evaluation and Optimization", "abstract": "We study sequential decision making in environments where rewards are only partially observed, but can be modeled as a function of observed contexts and the chosen action by the decision maker. This setting, known as contextual bandits, encompasses a wide variety of applications such as health care, content recommendation and Internet advertising. A central task is evaluation of a new policy given historic data consisting of contexts, actions and received rewards. The key challenge is that the past data typically does not faithfully represent proportions of actions taken by a new policy. Previous approaches rely either on models of rewards or models of the past policy. The former are plagued by a large bias whereas the latter have a large variance. In this work, we leverage the strengths and overcome the weaknesses of the two approaches by applying the doubly robust estimation technique to the problems of policy evaluation and optimization. We prove that this approach yields accurate value estimates when we have either a good (but not necessarily consistent) model of rewards or a good (but not necessarily consistent) model of past policy. Extensive empirical comparison demonstrates that the doubly robust estimation uniformly improves over existing techniques, achieving both lower variance in value estimation and better policies. As such, we expect the doubly robust approach to become common practice in policy evaluation and optimization.", "subjects": "Methodology (stat.ME)", "authors": "Miroslav Dud\u00edk, Dumitru Erhan, John Langford, Lihong Li,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02817", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02817", "title": "\nMinimax Optimal Rates of Estimation in High Dimensional Additive Models:  Universal Phase Transition", "abstract": "We establish minimax optimal rates of convergence for estimation in a high dimensional additive model assuming that it is approximately sparse. Our results reveal an interesting phase transition behavior universal to this class of high dimensional problems. In the when the components are sufficiently smooth or the dimensionality is sufficiently large, the optimal rates are identical to those for high dimensional linear regression, and therefore there is no additional cost to entertain a nonparametric model. Otherwise, in the so-called , the rates coincide with the optimal rates for estimating a univariate function, and therefore they are immune to the \"curse of dimensionality\".", "subjects": "Statistics Theory (math.ST)", "authors": "Ming Yuan, Ding-Xuan Zhou,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02779", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02779", "title": "\nOn metric properties of maps between Hamming spaces and related graph  homomorphisms", "abstract": "A mapping of -bit strings into -bit strings is called an -map if -bit strings which are more than apart are mapped to -bit strings that are more than apart. This is a relaxation of the classical error-correcting codes problem (). The question is equivalent to existence of graph homomorphisms between certain graphs on the hypercube. Tools based on Schrijver's -function are developed for testing when such homomorphisms are possible. For the non-existence results on are proved by invoking the asymptotic results on -function of McEliece, Rodemich, Rumsey and Welch (1977), Samorodnitsky (2001) as well as an exact solution of Delsarte's linear program for . Among other things, these bounds show that for and -- integer, the repetition map achieving is best possible. For a quantitative version of the no-homomorphism lemma is used together with Kleitman's theorem, which precisely characterizes the diameter-volume tradeoff in Hamming space. Finally, the question of constructing good linear maps is shown to be equivalent to finding certain extremal configurations of points in (finite) projective spaces. Consequently, implications of our results for projective geometry over is given.", "subjects": "Combinatorics (math.CO)", "authors": "Yury Polyanskiy,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02746", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02746", "title": "\nAsymptotic Delsarte cliques in distance-regular graphs", "abstract": "We give a new bound on the parameter (number of common neighbors of a pair of adjacent vertices) in a distance-regular graph , improving and generalizing bounds for strongly regular graphs by Spielman (1996) and Pyber (2014). The new bound is one of the ingredients of recent progress on the complexity of testing isomorphism of strongly regular graphs (Babai, Chen, Sun, Teng, Wilmes 2013). The proof is based on a clique geometry found by Metsch (1991) under certain constraints on the parameters. We also give a simplified proof of the following asymptotic consequence of Metsch's result: if then each edge of belongs to a unique maximal clique of size asymptotically equal to , and all other cliques have size . Here denotes the degree and the number of common neighbors of a pair of vertices at distance 2. We point out that Metsch's cliques are \"asymptotically Delsarte\" when , so families of distance-regular graphs with parameters satisfying are \"asymptotically Delsarte-geometric.\"", "subjects": "Combinatorics (math.CO)", "authors": "L\u00e1szl\u00f3 Babai, John Wilmes,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02705", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02705", "title": "\nA Mechanism Design Approach for Coordination of Thermostatically  Controlled Loads with User Preferences", "abstract": "This paper focuses on the coordination of a population of thermostatically controlled loads (TCLs) with unknown parameters to achieve group objectives. The problem involves designing the device bidding and market clearing strategies to motivate self-interested users to realize efficient energy allocation subject to a feeder capacity constraint. This coordination problem is formulated as a mechanism design problem, and we propose a mechanism to implement the social choice function in dominant strategy equilibrium. The proposed mechanism consists of a novel bidding and clearing strategy that incorporates the internal dynamics of TCLs in the market mechanism design, and we show it can realize the team optimal solution. This paper is divided into two parts. Part I presents a mathematical formulation of the problem and develops a coordination framework using the mechanism design approach. Part II presents a learning scheme to account for the unknown load model parameters, and evaluates the proposed framework through realistic simulations.", "subjects": "Optimization and Control (math.OC)", "authors": "Sen Li, Wei Zhang, Jianming Lian, Karanjit Kalsi,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02596", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02596", "title": "\nA Characterization of Deterministic Sampling Patterns for Low-Rank  Matrix Completion", "abstract": "Low-rank matrix completion (LRMC) problems arise in a wide variety of applications. Previous theory mainly provides conditions for completion under missing-at-random samplings. An incomplete matrix is if there are at most finitely many rank- matrices that agree with all its observed entries. Finite completability is the tipping point in LRMC, as a few additional samples of a finitely completable matrix guarantee its completability. The main contribution of this paper is a full characterization of finitely completable observation sets. We use this characterization to derive sufficient deterministic sampling conditions for unique completability. We also show that under uniform random sampling schemes, these conditions are satisfied with high probability if at least entries per column are observed.", "subjects": "Machine Learning (stat.ML)", "authors": "Daniel L. Pimentel-Alarc\u00f3n, Nigel Boston, Robert D. Nowak,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02574", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02574", "title": "\nCongestion phenomena caused by matching pennies in evolutionary games", "abstract": "Evolutionary social dilemma games are extended by an additional matching-pennies game that modifies the collected payoffs. In a spatial version players are distributed on a square lattice and interact with their neighbors. Firstly, we show that the matching-pennies game can be considered as the microscopic force of the Red Queen effect that breaks the detailed balance and induces eddies in the microscopic probability currents if the strategy update is analogous to the Glauber dynamics for the kinetic Ising models. The resulting loops in probability current breaks symmetry between the chessboard-like arrangements of strategies via a bottleneck effect occurring along the four-edge loops in the microscopic states. The impact of this congestion is analogous to the application of a staggered magnetic field in the Ising model, that is, the order-disorder critical transition is wiped out by noise. It is illustrated that the congestion induced symmetry breaking can be beneficial for the whole community within a certain region of parameters.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Gy\u00f6rgy Szab\u00f3, Attila Szolnoki,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.02570", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02570", "title": "\nThe Genetic Code revisited: Inner-to-outer map, 2D-Gray map, and  World-map Genetic Representations", "abstract": "How to represent the genetic code? Despite the fact that it is extensively known, the DNA mapping into proteins remains as one of the relevant discoveries of genetics. However, modern genomic signal processing usually requires converting symbolic-DNA strings into complex-valued signals in order to take full advantage of a broad variety of digital processing techniques. The genetic code is revisited in this paper, addressing alternative representations for it, which can be worthy for genomic signal processing. Three original representations are discussed. The inner-to-outer map builds on the unbalanced role of nucleotides of a 'codon' and it seems to be suitable for handling information-theory-based matter. The two-dimensional-Gray map representation is offered as a mathematically structured map that can help interpreting spectrograms or scalograms. Finally, the world-map representation for the genetic code is investigated, which can particularly be valuable for educational purposes -besides furnishing plenty of room for application of distance-based algorithms.", "subjects": "Other Quantitative Biology (q-bio.OT)", "authors": "H.M. de Oliveira, N.S. Santos-Magalhaes,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.02557", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02557", "title": "\nOn Monotonicity and Propagation of Order Properties", "abstract": "In this paper, a link between monotonicity of deterministic dynamical systems and propagation of order by Markov processes is established. The order propagation has received considerable attention in the literature, however, this notion is still not fully understood. The main contribution of this paper is a study of the order propagation in the deterministic setting, which potentially can provide new techniques for analysis in the stochastic one. We take a close look at the propagation of the so-called increasing and increasing convex orders. Infinitesimal characterisations of these orders are derived, which resemble the well-known Kamke conditions for monotonicity. It is shown that increasing order is equivalent to the standard monotonicity, while the class of systems propagating the increasing convex order is equivalent to the class of monotone systems with convex vector fields. The paper is concluded by deriving a novel result on order propagating diffusion processes and an application of this result to biological processes.", "subjects": "Optimization and Control (math.OC)", "authors": "Aivar Sootla,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02551", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02551", "title": "\nKernel-Based Just-In-Time Learning for Passing Expectation Propagation  Messages", "abstract": "We propose an efficient nonparametric strategy for learning a message operator in expectation propagation (EP), which takes as input the set of incoming messages to a factor node, and produces an outgoing message as output. This learned operator replaces the multivariate integral required in classical EP, which may not have an analytic expression. We use kernel-based regression, which is trained on a set of probability distributions representing the incoming messages, and the associated outgoing messages. The kernel approach has two main advantages: first, it is fast, as it is implemented using a novel two-layer random feature representation of the input message distributions; second, it has principled uncertainty estimates, and can be cheaply updated online, meaning it can request and incorporate new training data when it encounters inputs on which it is uncertain. In experiments, our approach is able to solve learning problems where a single message operator is required for multiple, substantially different data sets (logistic regression for a variety of classification problems), where the ability to accurately assess uncertainty and to efficiently and robustly update the message operator are essential.", "subjects": "Machine Learning (stat.ML)", "authors": "Wittawat Jitkrittum, Arthur Gretton, Nicolas Heess, S. M. Ali Eslami, Balaji Lakshminarayanan, Dino Sejdinovic, Zolt\u00e1n Szab\u00f3,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02536", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02536", "title": "\nGenomic Imaging Based on Codongrams and a^2grams", "abstract": "This paper introduces new tools for genomic signal processing, which can assist for genomic attribute extracting or describing biologically meaningful features embedded in a DNA. The codongrams and a2grams are offered as an alternative to spectrograms and scalograms. Twenty different a^2grams are defined for a genome, one for each amino acid (valgram is an a^2gram for valine; alagram is an a^2gram for alanine and so on). They provide information about the distribution and occurrence of the investigated amino acid. In particular, the metgram can be used to find out potential start position of genes within a genome. This approach can help implementing a new diagnosis test for genetic diseases by providing a type of DNA-medical imaging.", "subjects": "Other Quantitative Biology (q-bio.OT)", "authors": "E.A. Bouton, H.M. de Oliveira, R.M. Campello de Souza, N.S. Santos-Magalhaes,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.02531", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02531", "title": "\nDistilling the Knowledge in a Neural Network", "abstract": "A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.", "subjects": "Machine Learning (stat.ML)", "authors": "Geoffrey Hinton, Oriol Vinyals, Jeff Dean,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02519", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02519", "title": "\nA Testbed of Magnetic Induction-based Communication System for  Underground Applications", "abstract": "Wireless underground sensor networks (WUSNs) can enable many important applications such as intelligent agriculture, pipeline fault diagnosis, mine disaster rescue, concealed border patrol, crude oil exploration, among others. The key challenge to realize WUSNs is the wireless communication in underground environments. Most existing wireless communication systems utilize the dipole antenna to transmit and receive propagating electromagnetic (EM) waves, which do not work well in underground environments due to the very high material absorption loss. The Magnetic Induction (MI) technique provides a promising alternative solution that could address the current problem in underground. Although the MI-based underground communication has been intensively investigated theoretically, to date, seldom effort has been made in developing a testbed for the MI-based underground communication that can validate the theoretical results. In this paper, a testbed of MI-based communication system is designed and implemented in an in-lab underground environment. The testbed realizes and tests not only the original MI mechanism that utilizes single coil but also recent developed techniques that use the MI waveguide and the 3-directional (3D) MI coils. The experiments are conducted in an in-lab underground environment with reconfigurable environmental parameters such as soil composition and water content. This paper provides the principles and guidelines for developing the MI underground communications testbed, which is very complicated and time-consuming due to the new communication mechanism and the new wireless transmission medium.", "subjects": "Instrumentation and Detectors (physics.ins-det)", "authors": "Xin Tan, Zhi Sun, Ian F. Akyildiz,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02372", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02372", "title": "\nThe Road From Classical to Quantum Codes: A Hashing Bound Approaching  Design Procedure", "abstract": "Powerful Quantum Error Correction Codes (QECCs) are required for stabilizing and protecting fragile qubits against the undesirable effects of quantum decoherence. Similar to classical codes, hashing bound approaching QECCs may be designed by exploiting a concatenated code structure, which invokes iterative decoding. Therefore, in this paper we provide an extensive step-by-step tutorial for designing EXtrinsic Information Transfer (EXIT) chart aided concatenated quantum codes based on the underlying quantum-to-classical isomorphism. These design lessons are then exemplified in the context of our proposed Quantum Irregular Convolutional Code (QIRCC), which constitutes the outer component of a concatenated quantum code. The proposed QIRCC can be dynamically adapted to match any given inner code using EXIT charts, hence achieving a performance close to the hashing bound. It is demonstrated that our QIRCC-based optimized design is capable of operating within 0.4 dB of the noise limit.", "subjects": "Quantum Physics (quant-ph)", "authors": "Zunaira Babar, Panagiotis Botsinis, Dimitrios Alanis, Soon Xin Ng, Lajos Hanzo,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02349", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02349", "title": "\nArithmetic in Metamath, Case Study: Bertrand's Postulate", "abstract": "Unlike some other formal systems, the proof system Metamath has no built-in concept of \"decimal number\" in the sense that arbitrary digit strings are not recognized by the system without prior definition. We present a system of theorems and definitions and an algorithm to apply these as basic operations to perform arithmetic calculations with a number of steps proportional to an arbitrary-precision arithmetic calculation. We consider as case study the formal proof of Bertrand's postulate, which required the calculation of many small primes. Using a Mathematica implementation, we were able to complete the first formal proof in Metamath using numbers larger than 10. Applications to the mechanization of Metamath proofs are discussed, and in particular we argue that the asymptotic length, and hence also the asymptotic running time for verification, of a large formal proof such as Tom Hales' proof of the Kepler conjecture is proportional to the running time of the original proof verifier. This implies that although proof length may be exponentially shorter for proof languages with an ATP component, verification time is comparable, and maintaining a Metamath-like library of proofs based directly on a faithful ZFC interpretation is asymptotically feasible.", "subjects": "Logic (math.LO)", "authors": "Mario Carneiro,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02346", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02346", "title": "\nOne Scan 1-Bit Compressed Sensing", "abstract": "Based on -stable random projections with small , we develop a simple algorithm for compressed sensing (sparse signal recovery) by using only 1-bit (i.e., the sign) of the measurements. The method of -stable random projections has become popular in data stream computations. Using only 1-bit of the measurements results in substantial cost reduction in collection, storage, communication, and decoding for compressed sensing. The proposed algorithm is efficient in that the decoding procedure requires only one scan of the coordinates. For a -sparse signal of length , a conservative version of our algorithm requires measurements to recover the support and the signs of the signal. A more practical version needs fewer measurements, as validated by experiments. A closely-related issue is the estimation of , i.e., the size of the support. It turns out that, the harmonic mean estimator developed in the prior work for -stable random projections already provides a very accurate estimate of for the task of sparse recovery, using merely (e.g.,) 5 or 10 measurements. Since this is an important practical problem, a separate technical note is provided to introduce very efficient estimators based on 1-bit or multi-bit measurements, for estimating as well as the scale parameter of the -stable distribution family for .", "subjects": "Methodology (stat.ME)", "authors": "Ping Li,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.02339", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02339", "title": "\nSingle and multiple snapshot compressive beamforming", "abstract": "For a sound field observed on a sensor array, compressive sensing (CS) reconstructs the direction-of-arrivals (DOAs) of multiple sources using a sparsity constraint. The DOA estimation is posed as an underdetermined problem expressing the acoustic pressure at each sensor as a phase-lagged superposition of source amplitudes at all hypothetical DOAs. Regularizing with an -norm constraint renders the problem solvable with convex optimization, while promoting sparsity resulting in high-resolution DOA maps. Here, the sparse source distribution is derived using maximum a posteriori estimates for both single and multiple snapshots. CS does not require inversion of the data covariance matrix and thus works well even for a single snapshot resulting in higher resolution than conventional beamforming. For multiple snapshots, CS outperforms conventional high-resolution methods, even with coherent arrivals and at low signal-to-noise ratio. The superior resolution of CS is demonstrated with vertical array data from the SWellEx96 experiment for coherent multi-paths.", "subjects": "Statistics Theory (math.ST)", "authors": "Peter Gerstoft, Angeliki Xenaki, Christoph F. Mecklenbr\u00e4uker,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.02302", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02302", "title": "\nDESAT: an SSW tool for SDO/AIA image de-saturation", "abstract": "Saturation affects a significant rate of images recorded by the Atmospheric Imaging Assembly on the Solar Dynamics Observatory. This paper describes a computational method and a technological pipeline for the de-saturation of such images, based on several mathematical ingredients like Expectation Maximization, image correlation and interpolation. An analysis of the computational properties and demands of the pipeline, together with an assessment of its reliability are performed against a set of data recorded from the Feburary 25 2014 flaring event.", "subjects": "Instrumentation and Methods for Astrophysics (astro-ph.IM)", "authors": "Richard A Schwartz, Gabriele Torre, Anna Maria Massone, Michele Piana,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.02298", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02298", "title": "\nCyclically five-connected cubic graphs", "abstract": "A cubic graph is cyclically 5-connected if is simple, 3-connected, has at least 10 vertices and for every set of edges of size at most four, at most one component of contains circuits. We prove that if and are cyclically 5-connected cubic graphs and topologically contains , then either and are isomorphic, or (modulo well-described exceptions) there exists a cyclically 5-connected cubic graph such that topologically contains and is obtained from in one of the following two ways. Either is obtained from by subdividing two distinct edges of and joining the two new vertices by an edge, or is obtained from by subdividing each edge of a circuit of length five and joining the new vertices by a matching to a new circuit of length five disjoint from in such a way that the cyclic orders of the two circuits agree. We prove a companion result, where by slightly increasing the connectivity of we are able to eliminate the second construction. We also prove versions of both of these results when is almost cyclically 5-connected in the sense that it satisfies the definition except for 4-edge cuts such that one side is a circuit of length four. In this case is required to be almost cyclically 5-connected and to have fewer circuits of length four than . In particular, if has at most one circuit of length four, then is required to be cyclically 5-connected. However, in this more general setting the operations describing the possible graphs are more complicated.", "subjects": "Combinatorics (math.CO)", "authors": "Neil Robertson, P. D. Seymour, Robin Thomas,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.02244", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02244", "title": "\nAsymptotic Optimality of Finite Approximations to Markov Decision  Processes with General State and Action Spaces", "abstract": "Calculating optimal policies is known to be computationally difficult for Markov decision processes with Borel state and action spaces and for partially observed Markov decision processes even with finite state and action spaces. This paper studies finite-state approximations of discrete time Markov decision processes with discounted and average costs and Borel state and action spaces. The stationary policies thus obtained are shown to approximate the optimal stationary policy with arbitrary precision under mild technical conditions. Under further assumptions, we obtain explicit rates of convergence bounds quantifying how the approximation improves as the size of the approximating finite state space increases. Using information theoretic arguments, the order optimality of the obtained rates of convergence is established for a large class of problems.", "subjects": "Optimization and Control (math.OC)", "authors": "Naci Saldi, Serdar Y\u00fcksel, Tam\u00e1s Linder,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.02233", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02233", "title": "\nStratOS: A Big Data Framework for Scientific Computing", "abstract": "We introduce StratOS, a Big Data platform for general computing that allows a datacenter to be treated as a single computer. With StratOS, the process of writing a massively parallel program for a datacenter is no more complicated than writing a Python script for a desktop computer. Users can run pre-existing analysis software on data distributed over thousands of machines with just a few keystrokes. This greatly reduces the time required to develop distributed data analysis pipelines. The platform is built upon industry-standard, open-source Big Data technologies, from which it inherits fast data throughput and fault tolerance. StratOS enhances these technologies by adding an intuitive user interface, automated task monitoring, and other usability features.", "subjects": "Instrumentation and Methods for Astrophysics (astro-ph.IM)", "authors": "Nathaniel R. Stickley, Miguel A. Aragon-Calvo,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.02216", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02216", "title": "\nHigher order Matching Pursuit for Low Rank Tensor Learning", "abstract": "Low rank tensor learning, such as tensor completion and multilinear multitask learning, has received much attention in recent years. In this paper, we propose higher order matching pursuit for low rank tensor learning problems with a convex or a nonconvex cost function, which is a generalization of the matching pursuit type methods. At each iteration, the main cost of the proposed methods is only to compute a rank-one tensor, which can be done efficiently, making the proposed methods scalable to large scale problems. Moreover, storing the resulting rank-one tensors is of low storage requirement, which can help to break the curse of dimensionality. The linear convergence rate of the proposed methods is established in various circumstances. Along with the main methods, we also provide a method of low computational complexity for approximately computing the rank-one tensors, with provable approximation ratio, which helps to improve the efficiency of the main methods and to analyze the convergence rate. Experimental results on synthetic as well as real datasets verify the efficiency and effectiveness of the proposed methods.", "subjects": "Machine Learning (stat.ML)", "authors": "Yuning Yang, Siamak Mehrkanoon, Johan A.K. Suykens,", "date": "2015-3-7"}, 
{"urllink": "http://arxiv.org/abs/1503.02207", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02207", "title": "\nLinear Codes associated to Determinantal Varieties", "abstract": "We consider a class of linear codes associated to projective algebraic varieties defined by the vanishing of minors of a fixed size of a generic matrix. It is seen that the resulting code has only a small number of distinct weights. The case of varieties defined by the vanishing of 2 x 2 minors is considered in some detail. Here we obtain the complete weight distribution. Moreover, several generalized Hamming weights are determined explicitly and it is shown that the first few of them coincide with the distinct nonzero weights. One of the tools used is to determine the maximum possible number of matrices of rank 1 in a linear space of matrices of a given dimension over a finite field. In particular, we determine the structure and the maximum possible dimension of linear spaces of matrices in which every nonzero matrix has rank 1.", "subjects": "Combinatorics (math.CO)", "authors": "Peter Beelen, Sudhir R. Ghorpade, Sartaj Ul Hasan,", "date": "2015-3-7"}, 
{"urllink": "http://arxiv.org/abs/1503.02173", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02173", "title": "\nAlgebraic curves, rich points, and doubly-ruled surfaces", "abstract": "We study the structure of collections of algebraic curves in three dimensions that have many curve-curve incidences. In particular, let be a field and let be a collection of space curves in , with or . Then either A) there are at most points in hit by at least two curves, or B) at least curves from must lie on a bounded-degree surface, and many of the curves must form two \"rulings\" of this surface. We also develop several new tools including a generalization of the classical flecnode polynomial of Salmon and new algebraic techniques for dealing with this generalized flecnode polynomial.", "subjects": "Algebraic Geometry (math.AG)", "authors": "Larry Guth, Joshua Zahl,", "date": "2015-3-7"}, 
{"urllink": "http://arxiv.org/abs/1503.02122", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02122", "title": "\nRobust Mean Square Stability of Open Quantum Stochastic Systems with  Hamiltonian Perturbations in a Weyl Quantization Form", "abstract": "This paper is concerned with open quantum systems whose dynamic variables satisfy canonical commutation relations and are governed by quantum stochastic differential equations. The latter are driven by quantum Wiener processes which represent external boson fields. The system-field coupling operators are linear functions of the system variables. The Hamiltonian consists of a nominal quadratic function of the system variables and an uncertain perturbation which is represented in a Weyl quantization form. Assuming that the nominal linear quantum system is stable, we develop sufficient conditions on the perturbation of the Hamiltonian which guarantee robust mean square stability of the perturbed system. Examples are given to illustrate these results for a class of Hamiltonian perturbations in the form of trigonometric polynomials of the system variables.", "subjects": "Quantum Physics (quant-ph)", "authors": "Arash Kh. Sichani, Igor G. Vladimirov, Ian R. Petersen,", "date": "2015-3-7"}, 
{"urllink": "http://arxiv.org/abs/1503.02118", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02118", "title": "\nParameterization of Stabilizing Linear Coherent Quantum Controllers", "abstract": "This paper is concerned with application of the classical Youla-Ku vera parameterization to finding a set of linear coherent quantum controllers that stabilize a linear quantum plant. The plant and controller are assumed to represent open quantum harmonic oscillators modelled by linear quantum stochastic differential equations. The interconnections between the plant and the controller are assumed to be established through quantum bosonic fields. In this framework, conditions for the stabilization of a given linear quantum plant via linear coherent quantum feedback are addressed using a stable factorization approach. The class of stabilizing quantum controllers is parameterized in the frequency domain. Also, this approach is used in order to formulate coherent quantum weighted and control problems for linear quantum systems in the frequency domain. Finally, a projected gradient descent scheme is proposed to solve the coherent quantum weighted control problem.", "subjects": "Quantum Physics (quant-ph)", "authors": "Arash Kh. Sichani, Ian R. Petersen, Igor G. Vladimirov,", "date": "2015-3-7"}, 
{"urllink": "http://arxiv.org/abs/1503.01919", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01919", "title": "\nConvolutional LSTM Networks for Subcellular Localization of Proteins", "abstract": "Machine learning is widely used to analyze biological sequence data. Non-sequential models such as SVMs or feed-forward neural networks are often used although they have no natural way of handling sequences of varying length. Recurrent neural networks such as the long short term memory (LSTM) model on the other hand are designed to handle sequences. In this study we demonstrate that LSTM networks predict the subcellular location of proteins given only the protein sequence with high accuracy (0.902) outperforming current state of the art algorithms. We further improve the performance by introducing convolutional filters and experiment with an attention mechanism which lets the LSTM focus on specific parts of the protein. Lastly we introduce new visualizations of both the convolutional filters and the attention mechanisms and show how they can be used to extract biological relevant knowledge from the LSTM networks.", "subjects": "Quantitative Methods (q-bio.QM)", "authors": "S\u00f8ren Kaae S\u00f8nderby, Casper Kaae S\u00f8nderby, Henrik Nielsen, Ole Winther,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01916", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01916", "title": "\nHamiltonian ABC", "abstract": "Approximate Bayesian computation (ABC) is a powerful and elegant framework for performing inference in simulation-based models. However, due to the difficulty in scaling likelihood estimates, ABC remains useful for relatively low-dimensional problems. We introduce Hamiltonian ABC (HABC), a set of likelihood-free algorithms that apply recent advances in scaling Bayesian learning using Hamiltonian Monte Carlo (HMC) and stochastic gradients. We find that a small number forward simulations can effectively approximate the ABC gradient, allowing Hamiltonian dynamics to efficiently traverse parameter spaces. We also describe a new simple yet general approach of incorporating random seeds into the state of the Markov chain, further reducing the random walk behavior of HABC. We demonstrate HABC on several typical ABC problems, and show that HABC samples comparably to regular Bayesian inference using true gradients on a high-dimensional problem from machine learning.", "subjects": "Machine Learning (stat.ML)", "authors": "Edward Meeds, Robert Leenders, Max Welling,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01890", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01890", "title": "\nCoupling models of cattle and farms with models of badgers for  predicting the dynamics of bovine tuberculosis (TB)", "abstract": "Bovine TB is a major problem for the agricultural industry in several countries. TB can be contracted and spread by species other than cattle and this can cause a problem for disease control. In the UK and Ireland, badgers are a recognised reservoir of infection and there has been substantial discussion about potential control strategies. We present a coupling of individual based models of bovine TB in badgers and cattle, which aims to capture the key details of the natural history of the disease and of both species at approximately county scale. The model is spatially explicit it follows a very large number of cattle and badgers on a different grid size for each species and includes also winter housing. We show that the model can replicate the reported dynamics of both cattle and badger populations as well as the increasing prevalence of the disease in cattle. Parameter space used as input in simulations was swept out using Latin hypercube sampling and sensitivity analysis to model outputs was conducted using mixed effect models. By exploring a large and computationally intensive parameter space we show that of the available control strategies it is the frequency of TB testing and whether or not winter housing is practised that have the most significant effects on the number of infected cattle, with the effect of winter housing becoming stronger as farm size increases. Whether badgers were culled or not explained about 5%, while the accuracy of the test employed to detect infected cattle explained less than 3% of the variance in the number of infected cattle.", "subjects": "Populations and Evolution (q-bio.PE)", "authors": "Aristides Moustakas, Matthew R. Evans,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01889", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01889", "title": "\nParallelizing the dual revised simplex method", "abstract": "This paper introduces the design and implementation of two parallel dual simplex solvers for general large scale sparse linear programming problems. One approach, called PAMI, extends a relatively unknown pivoting strategy called suboptimization and exploits parallelism across multiple iterations. The other, called SIP, exploits purely single iteration parallelism by overlapping computational components when possible. Computational results show that the performance of PAMI is superior to that of the leading open-source simplex solver, and that SIP complements PAMI in achieving speedup when PAMI results in slowdown. One of the authors has implemented the techniques underlying PAMI within the FICO Xpress simplex solver and this paper presents computational results demonstrating their value. This performance increase is sufficiently valuable for the achievement to be used as the basis of promotional material by FICO. In developing the first parallel revised simplex solver of general utility and commercial importance, this work represents a significant achievement in computational optimization.", "subjects": "Optimization and Control (math.OC)", "authors": "Q. Huangfu, J. A. J. Hall,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01881", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01881", "title": "\nAttention decay in science", "abstract": "The exponential growth in the number of scientific papers makes it increasingly difficult for researchers to keep track of all the publications relevant to their work. Consequently, the attention that can be devoted to individual papers, measured by their citation counts, is bound to decay rapidly. In this work we make a thorough study of the life-cycle of papers in different disciplines. Typically, the citation rate of a paper increases up to a few years after its publication, reaches a peak and then decreases rapidly. This decay can be described by an exponential or a power law behavior, as in ultradiffusive processes, with exponential fitting better than power law for the majority of cases. The decay is also becoming faster over the years, signaling that nowadays papers are forgotten more quickly. However, when time is counted in terms of the number of published papers, the rate of decay of citations is fairly independent of the period considered. This indicates that the attention of scholars depends on the number of published items, and not on real time.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Pietro Della Briotta Parolo, Raj Kumar Pan, Rumi Ghosh, Bernardo A. Huberman, Kimmo Kaski, Santo Fortunato,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01839", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01839", "title": "\nThe combinatorial algorithm for computing $\u03c0(x)$", "abstract": "This paper describes recent advances in the combinatorial method for computing , the number of primes . In particular, the memory usage has been reduced by a factor of , and modifications for shared- and distributed-memory parallelism have been incorporated. The resulting method computes with complexity in time and in space. The algorithm has been implemented and used to compute for and for . The mathematics presented here is consistent with and builds on that of previous authors.", "subjects": "Number Theory (math.NT)", "authors": "Douglas B. Staple,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01806", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01806", "title": "\nRestricted linear congruences and an authenticated encryption scheme", "abstract": "In this paper, using properties of Ramanujan sums and of the finite Fourier transform of arithmetic functions, we give an explicit formula for the number of solutions of the linear congruence , with (), where () are arbitrary integers. Some special cases of this problem have been studied in many papers, and have found very interesting applications in number theory, combinatorics, and cryptography, among other areas. We also propose an authenticated encryption scheme, and using our explicit formula, analyze the integrity of this scheme.", "subjects": "Number Theory (math.NT)", "authors": "Khodakhast Bibak, Bruce M. Kapron, Venkatesh Srinivasan, Roberto Tauraso, L\u00e1szl\u00f3 T\u00f3th,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01737", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01737", "title": "\nMin-Max Kernels", "abstract": "The min-max kernel is a generalization of the popular resemblance kernel (which is designed for binary data). In this paper, we demonstrate, through an extensive classification study using kernel machines, that the min-max kernel often provides an effective measure of similarity for nonnegative data. As the min-max kernel is nonlinear and might be difficult to be used for industrial applications with massive data, we show that the min-max kernel can be linearized via hashing techniques. This allows practitioners to apply min-max kernel to large-scale applications using well matured linear algorithms such as linear SVM or logistic regression. The previous remarkable work on consistent weighted sampling (CWS) produces samples in the form of () where the records the location (and in fact also the weights) information analogous to the samples produced by classical minwise hashing on binary data. Because the is theoretically unbounded, it was not immediately clear how to effectively implement CWS for building large-scale linear classifiers. In this paper, we provide a simple solution by discarding (which we refer to as the \"0-bit\" scheme). Via an extensive empirical study, we show that this 0-bit scheme does not lose essential information. We then apply the \"0-bit\" CWS for building linear classifiers to approximate min-max kernel classifiers, as extensively validated on a wide range of publicly available classification datasets. We expect this work will generate interests among data mining practitioners who would like to efficiently utilize the nonlinear information of non-binary and nonnegative data.", "subjects": "Machine Learning (stat.ML)", "authors": "Ping Li,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01673", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01673", "title": "\nHigh Dimensional Bayesian Optimisation and Bandits via Additive Models", "abstract": "Bayesian Optimisation (BO) is a technique used in optimising a -dimensional function which is typically expensive to evaluate. While there have been many successes for BO in low dimensions, scaling it to high dimensions has been a notoriously difficult problem. Existing literature on the subject are under very restrictive settings. In this paper, we identify two key challenges in this endeavour. We tackle these challenges by assuming an additive structure for the function. This setting is substantially more expressive and contains a richer class of functions than previous work. In our theoretical analysis we prove that for additive functions the regret has only linear (as opposed to exponential) dependence on even though the function depends on all dimensions. We also demonstrate several other statistical and computational benefits in our framework. Empirically via synthetic examples, a scientific simulation and a face detection problem we demonstrate that our method outperforms naive BO on additive functions and on several examples when the function is not additive.", "subjects": "Machine Learning (stat.ML)", "authors": "Kirthevasan Kandasamy, Jeff Schneider, Barnabas Poczos,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01669", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01669", "title": "\nMore on Decomposing Coverings by Octants", "abstract": "In this note we improve our upper bound given earlier by showing that every 9-fold covering of a point set in the space by finitely many translates of an octant decomposes into two coverings, and our lower bound by a construction for a 4-fold covering that does not decompose into two coverings. We also prove that certain dynamic interval coloring problems are equivalent to the above question. The same bounds also hold for coverings of points in by finitely many homothets or translates of a triangle.", "subjects": "Combinatorics (math.CO)", "authors": "Bal\u00e1zs Keszegh, D\u00f6m\u00f6t\u00f6r P\u00e1lv\u00f6lgyi,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01643", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01643", "title": "\nMosaics of Combinatorial Designs", "abstract": "Looking at incidence matrices of - designs as matrices with possible entries, each of which indicates incidences of a -design, we introduce the notion of a -mosaic of designs, having the same number of points and blocks, as a matrix with different entries, such that each entry defines incidences of a design. In fact, a matrix is decomposed in incidence matrices of designs, each denoted by a different colour, hence this decomposition might be seen as a tiling of a matrix with incidence matrices of designs as well. These mosaics have applications in experiment design when considering a simultaneous run of several different experiments. We have constructed infinite series of examples of mosaics and state some probably non-trivial open problems.", "subjects": "Combinatorics (math.CO)", "authors": "Oliver W. Gnilke, Marcus Greferath, Mario Osvin Pav\u010devi\u0107,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01628", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01628", "title": "\nMinimal Classes of Graphs of Unbounded Clique-width and  Well-quasi-ordering", "abstract": "Daligault, Rao and Thomass 'e proposed in 2010 a fascinating conjecture connecting two seemingly unrelated notions: clique-width and well-quasi-ordering. They asked if the clique-width of graphs in a hereditary class which is well-quasi-ordered under labelled induced subgraphs is bounded by a constant. This is equivalent to asking whether every hereditary class of unbounded clique-width has a labelled infinite antichain. We believe the answer to this question is positive and propose a stronger conjecture stating that every minimal hereditary class of graphs of unbounded clique-width has a canonical labelled infinite antichain. To date, only two hereditary classes are known to be minimal with respect to clique-width and each of them is known to contain a canonical antichain. In the present paper, we discover two more minimal hereditary classes of unbounded clique-width and show that both of them contain canonical antichains.", "subjects": "Combinatorics (math.CO)", "authors": "A. Atminas, R. Brignall, V. Lozin, J. Stacho,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01626", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01626", "title": "\nInference of hidden structures in complex physical systems by  multi-scale clustering", "abstract": "We survey the application of a relatively new branch of statistical physics--\"community detection\"-- to data mining. In particular, we focus on the diagnosis of materials and automated image segmentation. Community detection describes the quest of partitioning a complex system involving many elements into optimally decoupled subsets or communities of such elements. We review a multiresolution variant which is used to ascertain structures at different spatial and temporal scales. Significant patterns are obtained by examining the correlations between different independent solvers. Similar to other combinatorial optimization problems in the NP complexity class, community detection exhibits several phases. Typically, illuminating orders are revealed by choosing parameters that lead to extremal information theory correlations.", "subjects": "Materials Science (cond-mat.mtrl-sci)", "authors": "Z. Nussinov, P. Ronhovde, Dandan Hu, S. Chakrabarty, M. Sahu, Bo Sun, N. A. Mauro, K. K. Sahu,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01603", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01603", "title": "\nExternal Validity: From Do-Calculus to Transportability Across  Populations", "abstract": "The generalizability of empirical findings to new environments, settings or populations, often called \"external validity,\" is essential in most scientific explorations. This paper treats a particular problem of generalizability, called \"transportability,\" defined as a license to transfer causal effects learned in experimental studies to a new population, in which only observational studies can be conducted. We introduce a formal representation called \"selection diagrams\" for expressing knowledge about differences and commonalities between populations of interest and, using this representation, we reduce questions of transportability to symbolic derivations in the do-calculus. This reduction yields graph-based procedures for deciding, prior to observing any data, whether causal effects in the target population can be inferred from experimental findings in the study population. When the answer is affirmative, the procedures identify what experimental and observational findings need be obtained from the two populations, and how they can be combined to ensure bias-free transport.", "subjects": "Methodology (stat.ME)", "authors": "Judea Pearl, Elias Bareinboim,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01592", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01592", "title": "\nBounding connected tree-width", "abstract": "Diestel and M \"uller showed that the connected tree-width of a graph , i.e., the minimum width of any tree-decomposition with connected parts, can be bounded in terms of the tree-width of and the largest length of a geodesic cycle in . We improve their bound to one that is of correct order of magnitude.", "subjects": "Combinatorics (math.CO)", "authors": "Matthias Hamann, Daniel Wei\u00dfauer,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01570", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01570", "title": "\nA proof of the Shepp-Olkin entropy concavity conjecture", "abstract": "We prove the Shepp--Olkin conjecture, which states that the entropy of the sum of independent Bernoulli random variables is concave in the parameters of the individual random variables. Our proof is a refinement of an argument previously presented by the same authors, which resolved the conjecture in the monotonic case (where all the parameters are simultaneously increasing). In fact, we show that the monotonic case is the worst case, using a careful analysis of concavity properties of the derivatives of the probability mass function. We propose a generalization of Shepp and Olkin's original conjecture, to consider Renyi and Tsallis entropies.", "subjects": "Probability (math.PR)", "authors": "Erwan Hillion, Oliver Johnson,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01538", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01538", "title": "\nPyrcca: regularized kernel canonical correlation analysis in Python and  its applications to neuroimaging", "abstract": "Canonical correlation analysis (CCA) is a valuable method for interpreting cross-covariance across related datasets of different dimensionality. There are many potential applications of CCA to neuroimaging data analysis. For instance, CCA can be used for finding functional similarities across fMRI datasets collected from multiple subjects without resampling individual datasets to a template anatomy. In this paper, we introduce Pyrcca, an open-source Python module for executing CCA between two or more datasets. Pyrcca can be used to implement CCA with or without regularization, and with or without linear or a Gaussian kernelization of the datasets. We demonstrate an application of CCA implemented with Pyrcca to neuroimaging data analysis. We use CCA to find a data-driven set of functional response patterns that are similar across individual subjects in a natural movie experiment. We then demonstrate how this set of response patterns discovered by CCA can be used to accurately predict subject responses to novel natural movie stimuli.", "subjects": "Quantitative Methods (q-bio.QM)", "authors": "Natalia Y. Bilenko, Jack L. Gallant,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01521", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01521", "title": "\nJointly Learning Multiple Perceptual Similarities", "abstract": "Perceptual similarity between objects is multi-faceted and it is easier to judge similarity when the focus is on a specific aspect. We consider the problem of mapping objects into view specific embeddings where the distance between them is consistent with the similarity comparisons of the form \"from the t-th perspective, object A is more similar to B than to C\". Our framework jointly learns view specific embeddings and can exploit correlations between views if they exist. Experiments on a number of datasets, including a large dataset of multi-view crowdsourced comparison on bird images, show the proposed method achieves lower triplet generalization error and better grouping of classes in most cases, when compared to learning embeddings independently for each view. The improvements are especially large in the realistic setting when there is limited triplet data for each view.", "subjects": "Machine Learning (stat.ML)", "authors": "Liwen Zhang, Subhransu Maji, Ryota Tomioka,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01457", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01457", "title": "\nTime Averaged Consensus in a Direct Coupled Distributed Coherent Quantum  Observer", "abstract": "This paper considers the problem of constructing a distributed direct coupling quantum observer for a closed linear quantum system. The proposed distributed observer consists of a network of quantum harmonic oscillators and it is shown that the distributed observer converges to a consensus in a time averaged sense in which each component of the observer estimates the specified output of the quantum plant. An example and simulations are included to illustrate the properties of the distributed observer.", "subjects": "Quantum Physics (quant-ph)", "authors": "Ian R. Petersen,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01445", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01445", "title": "\nToxicity Prediction using Deep Learning", "abstract": "Everyday we are exposed to various chemicals via food additives, cleaning and cosmetic products and medicines -- and some of them might be toxic. However testing the toxicity of all existing compounds by biological experiments is neither financially nor logistically feasible. Therefore the government agencies NIH, EPA and FDA launched the Tox21 Data Challenge within the \"Toxicology in the 21st Century\" (Tox21) initiative. The goal of this challenge was to assess the performance of computational methods in predicting the toxicity of chemical compounds. State of the art toxicity prediction methods build upon specifically-designed chemical descriptors developed over decades. Though Deep Learning is new to the field and was never applied to toxicity prediction before, it clearly outperformed all other participating methods. In this application paper we show that deep nets automatically learn features resembling well-established toxicophores. In total, our Deep Learning approach won both of the panel-challenges (nuclear receptors and stress response) as well as the overall Grand Challenge, and thereby sets a new standard in tox prediction.", "subjects": "Machine Learning (stat.ML)", "authors": "Thomas Unterthiner, Andreas Mayr, G\u00fcnter Klambauer, Sepp Hochreiter,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01404", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01404", "title": "\nComplete intersection vanishing ideals on sets of clutter type over  finite fields", "abstract": "In this paper we give a classification of complete intersection vanishing ideals on parameterized sets of clutter type over finite fields.", "subjects": "Commutative Algebra (math.AC)", "authors": "Azucena Tochimani, Rafael H. Villarreal,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01397", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01397", "title": "\nBethe Projections for Non-Local Inference", "abstract": "Many inference problems in structured prediction are naturally solved by augmenting a tractable dependency structure with complex, non-local auxiliary objectives. This includes the mean field family of variational inference algorithms, soft- or hard-constrained inference using Lagrangian relaxation or linear programming, collective graphical models, and forms of semi-supervised learning such as posterior regularization. We present a method to discriminatively learn broad families of inference objectives, capturing powerful non-local statistics of the latent variables, while maintaining tractable and provably fast inference using non-Euclidean projected gradient descent with a distance-generating function given by the Bethe entropy. We demonstrate the performance and flexibility of our method by (1) extracting structured citations from research papers by learning soft global constraints, (2) achieving state-of-the-art results on a widely-used handwriting recognition task using a novel learned non-convex inference procedure, and (3) providing a fast and highly scalable algorithm for the challenging problem of inference in a collective graphical model applied to bird migration.", "subjects": "Machine Learning (stat.ML)", "authors": "Luke Vilnis, David Belanger, Daniel Sheldon, Andrew McCallum,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01375", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01375", "title": "\nSymmetric Orthogonal Tensor Decomposition is Trivial", "abstract": "We consider the problem of decomposing a real-valued symmetric tensor as the sum of outer products of real-valued, pairwise orthogonal vectors. Such decompositions do not generally exist, but we show that some symmetric tensor decomposition problems can be converted to orthogonal problems following the whitening procedure proposed by Anandkumar et al. (2012). If an orthogonal decomposition of an -way -dimensional symmetric tensor exists, we propose a novel method to compute it that reduces to an symmetric matrix eigenproblem. We provide numerical results demonstrating the effectiveness of the method.", "subjects": "Numerical Analysis (math.NA)", "authors": "Tamara G. Kolda,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01334", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01334", "title": "\nSequential quantum mixing for slowly evolving sequences of Markov chains", "abstract": "In this work we consider the problem of preparation of the stationary distribution of irreducible, time-reversible Markov chains, which is a fundamental task in algorithmic Markov chain theory. For the classical setting, this task has a complexity lower bound of , where is the spectral gap of the Markov chain, and other dependencies contribute only logarithmically. In the quantum case, the conjectured complexity is (with other dependencies contributing only logarithmically). However, this bound has only been achieved for a few special classes of Markov chains. In this work, we provide a method for the sequential preparation of stationary distributions for sequences of general time-reversible state Markov chains, akin to the setting of simulated annealing methods. The complexity of preparation we achieve is , neglecting logarithmic factors. While this result falls short of the conjectured optimal time, it still provides at least a quadratic improvement over other straightforward approaches for quantum mixing applied in this setting.", "subjects": "Quantum Physics (quant-ph)", "authors": "Vedran Dunjko, Hans J. Briegel,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01322", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01322", "title": "\nFaster unfolding of communities: speeding up the Louvain algorithm", "abstract": "Many complex networks exhibit a modular structure of densely connected groups of nodes. Usually, such a modular structure is uncovered by the optimisation of some quality function. Although flawed, Modularity remains one of the most popular quality functions. The Louvain algorithm was originally developed for optimising Modularity, but has been applied to a variety of methods. As such, speeding up the Louvain algorithm, enables the analysis of larger graphs in a shorter time for various methods. We here suggest to consider moving nodes to the community of a random neighbour, instead of the best neighbouring community. Although incredibly simple, it reduces the theoretical runtime complexity from to in networks with a clear community structure. In benchmark networks, resembling real networks more closely, it speeds up the algorithm roughly 2-3 times. This is due to two factors: (1) a random neighbour is likely to be in a \"good\" community; and (2) random neighbours are likely to be hubs, helping the convergence. Finally, the performance gain only slightly diminishes the quality, thus providing an excellent quality-performance ratio. However, these gains do not seem to hold up when detecting small communities in large graphs.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "V.A. Traag,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01245", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01245", "title": "\nLarge Dimensional Analysis of Robust M-Estimators of Covariance with  Outliers", "abstract": "A large dimensional characterization of robust M-estimators of covariance (or scatter) is provided under the assumption that the dataset comprises independent (essentially Gaussian) legitimate samples as well as arbitrary deterministic samples, referred to as outliers. Building upon recent random matrix advances in the area of robust statistics, we specifically show that the so-called Maronna M-estimator of scatter asymptotically behaves similar to well-known random matrices when the population and sample sizes grow together to infinity. The introduction of outliers leads the robust estimator to behave asymptotically as the weighted sum of the sample outer products, with a constant weight for all legitimate samples and different weights for the outliers. A fine analysis of this structure reveals importantly that the propensity of the M-estimator to attenuate (or enhance) the impact of outliers is mostly dictated by the alignment of the outliers with the inverse population covariance matrix of the legitimate samples. Thus, robust M-estimators can bring substantial benefits over more simplistic estimators such as the per-sample normalized version of the sample covariance matrix, which is not capable of differentiating the outlying samples. The analysis shows that, within the class of Maronna's estimators of scatter, the Huber estimator is most favorable for rejecting outliers. On the contrary, estimators more similar to Tyler's scale invariant estimator (often preferred in the literature) run the risk of inadvertently enhancing some outliers.", "subjects": "Statistics Theory (math.ST)", "authors": "David Morales-Jimenez, Romain Couillet, Matthew R. McKay,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01183", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01183", "title": "\nA General Hybrid Clustering Technique", "abstract": "Here, we propose a clustering technique for general clustering problems including those that have non-convex clusters. For a given desired number of clusters , we use three stages to find a clustering. The first stage uses a hybrid clustering technique to produce a series of clusterings of various sizes (randomly selected). They key steps are to find a -means clustering using clusters where and then joins these small clusters by using single linkage clustering. The second stage stabilizes the result of stage one by reclustering via the `membership matrix' under Hamming distance to generate a dendrogram. The third stage is to cut the dendrogram to get clusters where and then prune back to to give a final clustering. A variant on our technique also gives a reasonable estimate for , the true number of clusters. We provide a series of arguments to justify the steps in the stages of our methods and we provide numerous examples involving real and simulated data to compare our technique with other related techniques.", "subjects": "Machine Learning (stat.ML)", "authors": "Saeid Amiri, Bertrand Clarke, Jennifer Clarke, Hoyt A. Koepke,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01179", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01179", "title": "\nTime Averaged Consensus in a Direct Coupled Coherent Quantum Observer  Network for a Single Qubit Finite Level Quantum System", "abstract": "This paper considers the problem of constructing a direct coupled quantum observer network for a single qubit quantum system. The proposed observer consists of a network of quantum harmonic oscillators and it is shown that the observer network output converges to a consensus in a time averaged sense in which each component of the observer estimates a specified output of the quantum plant. An example and simulations are included.", "subjects": "Quantum Physics (quant-ph)", "authors": "Ian R. Petersen,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01170", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01170", "title": "\nInteger Addition and Hamming Weight", "abstract": "We study the effect of addition on the Hamming weight of a positive integer. Consider the first positive integers, and fix an alpha among them. We show that if the binary representation of alpha consists of blocks of zeros and ones, then addition by alpha causes a constant fraction of low Hamming weight integers to become high Hamming weight integers. This result has applications in complexity theory to the hardness of computing powering maps using arithmetic circuits over . Our result implies that powering by alpha composed of many blocks require exponential-size arithmetic circuits over .", "subjects": "Combinatorics (math.CO)", "authors": "John Y. Kim,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01161", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01161", "title": "\nThe Bayesian Case Model: A Generative Approach for Case-Based Reasoning  and Prototype Classification", "abstract": "We present the Bayesian Case Model (BCM), a general framework for Bayesian case-based reasoning (CBR) and prototype classification and clustering. BCM brings the intuitive power of CBR to a Bayesian generative framework. The BCM learns prototypes, the \"quintessential\" observations that best represent clusters in a dataset, by performing joint inference on cluster labels, prototypes and important features. Simultaneously, BCM pursues sparsity by learning subspaces, the sets of features that play important roles in the characterization of the prototypes. The prototype and subspace representation provides quantitative benefits in interpretability while preserving classification accuracy. Human subject experiments verify statistically significant improvements to participants' understanding when using explanations produced by BCM, compared to those given by prior art.", "subjects": "Machine Learning (stat.ML)", "authors": "Been Kim, Cynthia Rudin, Julie Shah,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01095", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01095", "title": "\nlibRoadRunner: A High Performance SBML Simulation and Analysis Library", "abstract": "This paper presents libRoadRunner, an extensible, high-performance, cross-platform, open-source software library for the simulation and analysis of models expressed using Systems Biology Markup Language (SBML). SBML is the most widely used standard for representing dynamic networks, especially biochemical networks. libRoadRunner supports solution of both large models and multiple replicas of a single model on desktop, mobile and cluster computers. libRoadRunner is a self-contained library, able to run both as a component inside other tools via its C++ and C bindings andnteractively through its Python interface. The Python Application Programming Interface (API) is similar to the APIs of Matlab and SciPy, making it fast and easy to learn, even for new users. libRoadRunner uses a custom Just-In-Time (JIT) compiler built on the widely-used LLVM JIT compiler framework to compile SBML-specified models directly into very fast native machine code for a variety of processors, making it appropriate for solving very large models or multiple replicas of smaller models. libRoadRunner is flexible, supporting the bulk of the SBML specification (except for delay and nonlinear algebraic equations) and several of its extensions. It offers multiple deterministic and stochastic integrators, as well as tools for steady-state, stability analyses and flux balance analysis. We regularly update libRoadRunner binary distributions for Mac OS X, Linux and Windows and license them under Apache License Version 2.0. this http URL provides online documentation, full build instructions, binaries and a git source repository.", "subjects": "Subcellular Processes (q-bio.SC)", "authors": "Endre T. Somogyi, Jean-Marie Bouteiller, James A. Glazier, Matthias K\u00f6nig, Kyle Medley, Maciej H. Swat, Herbert M. Sauro,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00855", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00855", "title": "\nHow to speed up R code: an introduction", "abstract": "Most calculations performed by the average R user are unremarkable in the sense that nowadays, any computer can crush the related code in a matter of seconds. But more and more often, heavy calculations are also performed using R, something especially true in some fields such as statistics. The user then faces total execution times of his codes that are hard to work with: hours, days, even weeks. In this paper, how to reduce the total execution time of various codes will be shown and typical bottlenecks will be discussed. As a last resort, how to run your code on a cluster of computers (most workplaces have one) in order to make use of a larger processing power than the one available on an average computer will also be discussed through two examples.", "subjects": "Computation (stat.CO)", "authors": "Nathan Uyttendaele,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00840", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00840", "title": "\nOn the quantum discord of general X states", "abstract": "Quantum discord Q is a function of density matrix elements. The domain of such a function in the case of two-qubit system with X density matrix may consist of three subdomains at most: two ones where the quantum discord is expressed in closed analytical forms (Q_ and Q_0) and an intermediate subdomain for which, to extract the quantum discord Q_ theta, it is required to solve in general numerically a one-dimensional minimization problem to find the optimal measurement angle theta in(0, pi/2). Hence the quantum discord is given by a piecewise-analytic-numerical formula Q= min, Q_ theta, Q_0. Equations for determining the boundaries between these subdomains are obtained. The boundaries consist of bifurcation points. The Q_ subdomains are discovered in the generalized Horodecki states, in the dynamical phase flip channel model, in the anisotropic spin systems at thermal equilibrium, in the heteronuclear dimers in an external magnetic field. We found that transitions between Q_ subdomain and Q_ and Q_0 ones occur suddenly but continuously and smoothly, i.e., nonanalyticity is hidden and can be observed in higher derivatives of discord function.", "subjects": "Quantum Physics (quant-ph)", "authors": "M. A. Yurischev,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00759", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00759", "title": "\nA Review of Relational Machine Learning for Knowledge Graphs: From  Multi-Relational Link Prediction to Automated Knowledge Graph Construction", "abstract": "Relational machine learning studies methods for the statistical analysis of relational, or graph-structured, data. In this paper, we provide a review of how such statistical models can be \"trained\" on large knowledge graphs, and then used to predict new facts about the world (which is equivalent to predicting new edges in the graph). In particular, we discuss two different kinds of statistical relational models, both of which can scale to massive datasets. The first is based on tensor factorization methods and related latent variable models. The second is based on mining observable patterns in the graph. We also show how to combine these latent and observable models to get improved modeling power at decreased computational cost. Finally, we discuss how such statistical models of graphs can be combined with text-based information extraction methods for automatically constructing knowledge graphs from the Web. In particular, we discuss Google's Knowledge Vault project.", "subjects": "Machine Learning (stat.ML)", "authors": "Maximilian Nickel, Kevin Murphy, Volker Tresp, Evgeniy Gabrilovich,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00757", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00757", "title": "\nControlling the deformation map in diffeomorphic image registration", "abstract": "We propose regularization schemes for deformable registration and efficient algorithms for its numerical approximation. We treat image registration as a variational optimal control problem. The deformation map is parametrized by a velocity field. Quadratic Tikhonov regularization ensures well-posedness of the problem. Our scheme augments standard smoothness vectorial operators based on - and -seminorms with a constraint on the divergence of the velocity field. Our formulation is motivated from Stokes flows in fluid mechanics. We invert for a stationary velocity field as well as a mass source map. This allows us to explicitly control the compressibility of the deformation map and by that the determinant of the deformation gradient. In addition, we design a novel regularization model that allows us to control shear. We use a globalized, preconditioned, matrix-free (Gauss-)Newton-Krylov scheme. We exploit variable elimination techniques to reduce the number of unknowns of our system: we only iterate on the reduced space of the velocity field. Our scheme can be used for problems in which the deformation map is expected to be nearly incompressible, as is often the case in medical imaging. Numerical experiments demonstrate that we can explicitly control the determinant of the deformation gradient without compromising registration quality. This additional control allows us to avoid over-smoothing of the deformation map. We demonstrate that our new formulation allows us to promote or penalize shear whilst controlling the determinant of the deformation gradient.", "subjects": "Optimization and Control (math.OC)", "authors": "Andreas Mang, George Biros,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00713", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00713", "title": "\nThe ideal energy of classical lattice dynamics", "abstract": "We define, as local quantities, the least energy and momentum allowed by quantum mechanics and special relativity for physical realizations of some classical lattice dynamics. These definitions amount to counting rates of local finite-state change. In two example dynamics, we see that these counts evolve like classical mechanical energies.", "subjects": "Cellular Automata and Lattice Gases (nlin.CG)", "authors": "Norman Margolus,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00698", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00698", "title": "\nFault Analysis Using Gegenbauer Multiresolution Analysis", "abstract": "This paper exploits the multiresolution analysis in the fault analysis on transmission lines. Faults were simulated using the ATP (Alternative Transient Program), considering signals at 128/cycle. A nonorthogonal multiresolution analysis was provided by Gegenbauer scaling and wavelet filters. In the cases where the signal reconstruction is not required, orthogonality may be immaterial. Gegenbauer filter banks are thereby offered in this paper as a tool for analyzing fault signals on transmission lines. Results are compared to those ones derived from a 4-coefficient Daubechies filter. The main advantages in favor of Gegenbauer filters are their smaller computational effort and their constant group delay, as they are symmetric filters.", "subjects": "Classical Analysis and ODEs (math.CA)", "authors": "L.R. Soares, H.M. de Oliveira,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1503.00690", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00690", "title": "\nA Hebbian/Anti-Hebbian Network for Online Sparse Dictionary Learning  Derived from Symmetric Matrix Factorization", "abstract": "Olshausen and Field (OF) proposed that neural computations in the primary visual cortex (V1) can be partially modeled by sparse dictionary learning. By minimizing the regularized representation error they derived an online algorithm, which learns Gabor-filter receptive fields from a natural image ensemble in agreement with physiological experiments. Whereas the OF algorithm can be mapped onto the dynamics and synaptic plasticity in a single-layer neural network, the derived learning rule is nonlocal - the synaptic weight update depends on the activity of neurons other than just pre- and postsynaptic ones - and hence biologically implausible. Here, to overcome this problem, we derive sparse dictionary learning from a novel cost-function - a regularized error of the symmetric factorization of the input's similarity matrix. Our algorithm maps onto a neural network of the same architecture as OF but using only biologically plausible local learning rules. When trained on natural images our network learns Gabor-filter receptive fields and reproduces the correlation among synaptic weights hard-wired in the OF network. Therefore, online symmetric matrix factorization may serve as an algorithmic theory of neural computation.", "subjects": "Neurons and Cognition (q-bio.NC)", "authors": "Tao Hu, Cengiz Pehlevan, Dmitri B. Chklovskii,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00680", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00680", "title": "\nA Hebbian/Anti-Hebbian Network Derived from Online Non-Negative Matrix  Factorization Can Cluster and Discover Sparse Features", "abstract": "Despite our extensive knowledge of biophysical properties of neurons, there is no commonly accepted algorithmic theory of neuronal function. Here we explore the hypothesis that single-layer neuronal networks perform online symmetric nonnegative matrix factorization (SNMF) of the similarity matrix of the streamed data. By starting with the SNMF cost function we derive an online algorithm, which can be implemented by a biologically plausible network with local learning rules. We demonstrate that such network performs soft clustering of the data as well as sparse feature discovery. The derived algorithm replicates many known aspects of sensory anatomy and biophysical properties of neurons including unipolar nature of neuronal activity and synaptic weights, local synaptic plasticity rules and the dependence of learning rate on cumulative neuronal activity. Thus, we make a step towards an algorithmic theory of neuronal function, which should facilitate large-scale neural circuit simulations and biologically inspired artificial intelligence.", "subjects": "Neurons and Cognition (q-bio.NC)", "authors": "Cengiz Pehlevan, Dmitri B. Chklovskii,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00669", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00669", "title": "\nA Hebbian/Anti-Hebbian Neural Network for Linear Subspace Learning: A  Derivation from Multidimensional Scaling of Streaming Data", "abstract": "Neural network models of early sensory processing typically reduce the dimensionality of streaming input data. Such networks learn the principal subspace, in the sense of principal component analysis (PCA), by adjusting synaptic weights according to activity-dependent learning rules. When derived from a principled cost function these rules are nonlocal and hence biologically implausible. At the same time, biologically plausible local rules have been postulated rather than derived from a principled cost function. Here, to bridge this gap, we derive a biologically plausible network for subspace learning on streaming data by minimizing a principled cost function. In a departure from previous work, where cost was quantified by the representation, or reconstruction, error, we adopt a multidimensional scaling (MDS) cost function for streaming data. The resulting algorithm relies only on biologically plausible Hebbian and anti-Hebbian local learning rules. In a stochastic setting, synaptic weights converge to a stationary state which projects the input data onto the principal subspace. If the data are generated by a nonstationary distribution, the network can track the principal subspace. Thus, our result makes a step towards an algorithmic theory of neural computation.", "subjects": "Neurons and Cognition (q-bio.NC)", "authors": "Cengiz Pehlevan, Tao Hu, Dmitri B. Chklovskii,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00609", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00609", "title": "\nCommunity detection in general stochastic block models: fundamental  limits and efficient recovery algorithms", "abstract": "New phase transition phenomena have recently been discovered for the stochastic block model, for the special case of two non-overlapping symmetric communities. This paper investigates whether a general phenomenon takes place for multiple communities without imposing symmetry. In the general stochastic block model , vertices are split into communities of relative size , and vertices in community and connect independently with probability . This paper investigates the partial and exact recovery of communities in the general SBM (in the constant and logarithmic degree regimes), and uses the generality of the results to tackle overlapping communities. It is shown that exact recovery in is solvable if and only if , where is the -th column of and is a generalization of the Chernoff and Hellinger divergence defined by dd(x,y):= max_ sum_ (tx_i + (1-t)y_i - x_i^t y_i^). This gives an operational meaning to , related to the operational meaning of the KL-divergence in the channel coding theorem. Moreover, an algorithm is developed that runs in quasi-linear time and recovers the communities in the general SBM all the way down to the optimal threshold, showing that exact recovery is efficiently solvable whenever it is information-theoretically solvable (the entries of are assumed to be nonzero). This is the first algorithm with such performance guarantees for multiple communities. To obtain this algorithm, a first-stage algorithm is developed that recovers communities in the constant degree regime with an accuracy guarantee that can be made arbitrarily close to 1 when a prescribed signal-to-noise ratio (defined in term of the spectrum of ) tends to infinity.", "subjects": "Probability (math.PR)", "authors": "Emmanuel Abbe, Colin Sandon,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00540", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00540", "title": "\nThe edge-disjoint path problem on random graphs by message-passing", "abstract": "We present a message-passing algorithm to solve the edge disjoint path problem (EDP) on graphs incorporating under a unique framework both traffic optimization and path length minimization. The min-sum equations for this problem present an exponential computational cost in the number of paths. To overcome this obstacle we propose an efficient implementation by mapping the equations onto a weighted combinatorial matching problem over an auxiliary graph. We perform extensive numerical simulations on random graphs of various types to test the performance both in terms of path length minimization and maximization of the number of accommodated paths. In addition, we test the performance on benchmark instances on various graphs by comparison with state-of-the-art algorithms and results found in the literature. Our message-passing algorithm always outperforms the others in terms of the number of accommodated paths when considering non trivial instances (otherwise it gives the same trivial results). Remarkably, the largest improvement in performance with respect to the other methods employed is found in the case of benchmarks with meshes, where the validity hypothesis behind message-passing is expected to worsen. In these cases, even though the exact message-passing equations do not converge, by introducing a reinforcement parameter to force convergence towards a sub optimal solution, we were able to always outperform the other algorithms with a peak of 27% performance improvement in terms of accommodated paths. On random graphs, we numerically observe two separated regimes: one in which all paths can be accommodated and one in which this is not possible. We also investigate the behaviour of both the number of paths to be accommodated and their minimum total length.", "subjects": "Disordered Systems and Neural Networks (cond-mat.dis-nn)", "authors": "Fabrizio Altarelli, Alfredo Braunstein, Luca Dall'Asta, Caterina De Bacco, Silvio Franz,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00445", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00445", "title": "\nDetecting communities using asymptotical Surprise", "abstract": "Nodes in real-world networks are repeatedly observed to form dense clusters, often referred to as communities. Methods to detect these groups of nodes usually maximize an objective function, which implicitly contains the definition of a community. We here analyze a recently proposed measure called Surprise, which assesses the quality of the partition of a network into communities. Given that, in its current form, its formulation is rather difficult to analyze, we develop an accurate asymptotic approximation. This allows for the development of an efficient algorithm for optimizing Surprise. Incidentally, this leads to a straightforward extension of Surprise to weighted graphs. Finally, we analytically compare it to previous methods, which makes clear that Surprise is more discriminative than ER Modularity. Furthermore, we show that it is especially suited for detecting relatively small communities in large graphs, an area where some earlier methods fail.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "V.A. Traag, R. Aldecoa, J-C. Delvenne,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00411", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00411", "title": "\nVector Fitting for Matrix-valued Rational Approximation", "abstract": "Vector Fitting (VF) is a popular method of constructing rational approximants that provides a least squares fit to frequency response measurements. In an earlier work, we provided an analysis of VF for scalar-valued rational functions and established a connection with optimal approximation. We build on this work and extend the previous framework to include the construction of effective rational approximations to matrix-valued functions, a problem which presents significant challenges that do not appear in the scalar case. Transfer functions associated with multi-input/multi-output (MIMO) dynamical systems typify the class of functions that we consider here. Others have also considered extensions of VF to matrix-valued functions and related numerical implementations are readily available. However to our knowledge, a detailed analysis of numerical issues that arise does not yet exist. We offer such an analysis including critical implementation details here. One important issue that arises for VF on matrix-valued functions that has remained largely unaddressed is the control of the McMillan degree of the resulting rational approximant; the McMillan degree can grow very high in the case of large input/output dimensions. We introduce two new mechanisms for controlling the McMillan degree of the final approximant, one based on alternating least-squares minimization and one based on ancillary system-theoretic reduction methods. Motivated in part by our earlier work on the scalar VF problem as well as by recent innovations for computing optimal approximation, we establish a connection with optimal approximation, and are able to improve significantly the fidelity of VF through numerical quadrature, with virtually no increase in cost or complexity. We provide several numerical examples to support the theoretical discussion and proposed algorithms.", "subjects": "Numerical Analysis (math.NA)", "authors": "Zlatko Drmac, Serkan Gugercin, Christopher Beattie,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00360", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00360", "title": "\nOptical encryption for large-sized images using random phase-free method", "abstract": "We propose an optical encryption framework that can encrypt and decrypt large-sized images beyond the size of the encrypted image using our two methods: random phase-free method and scaled diffraction. In order to record the entire image information on the encrypted image, the large-sized images require the random phase to widely diffuse the object light over the encrypted image; however, the random phase gives rise to the speckle noise on the decrypted images, and it may be difficult to recognize the decrypted images. In order to reduce the speckle noise, we apply our random phase-free method to the framework. In addition, we employ scaled diffraction that calculates light propagation between planes with different sizes by changing the sampling rates.", "subjects": "Optics (physics.optics)", "authors": "Tomoyoshi Shimobaba, Takashi Kakue, Yutaka Endo, Ryuji Hirayama, Daisuke Hiyama, Satoki Hasegawa, Yuki Nagahama, Marie Sano, Takashige Sugie, Tomoyoshi Ito,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00332", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00332", "title": "\nJUMP-Means: Small-Variance Asymptotics for Markov Jump Processes", "abstract": "Markov jump processes (MJPs) are used to model a wide range of phenomena from disease progression to RNA path folding. However, maximum likelihood estimation of parametric models leads to degenerate trajectories and inferential performance is poor in nonparametric models. We take a small-variance asymptotics (SVA) approach to overcome these limitations. We derive the small-variance asymptotics for parametric and nonparametric MJPs for both directly observed and hidden state models. In the parametric case we obtain a novel objective function which leads to non-degenerate trajectories. To derive the nonparametric version we introduce the gamma-gamma process, a novel extension to the gamma-exponential process. We propose algorithms for each of these formulations, which we call emph. Our experiments demonstrate that JUMP-means is competitive with or outperforms widely used MJP inference approaches in terms of both speed and reconstruction accuracy.", "subjects": "Machine Learning (stat.ML)", "authors": "Jonathan H. Huggins, Karthik Narasimhan, Ardavan Saeedi, Vikash K. Mansinghka,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00323", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00323", "title": "\nSparse Approximation of a Kernel Mean", "abstract": "Kernel means are frequently used to represent probability distributions in machine learning problems. In particular, the well known kernel density estimator and the kernel mean embedding both have the form of a kernel mean. Unfortunately, kernel means are faced with scalability issues. A single point evaluation of the kernel density estimator, for example, requires a computation time linear in the training sample size. To address this challenge, we present a method to efficiently construct a sparse approximation of a kernel mean. We do so by first establishing an incoherence-based bound on the approximation error, and then noticing that, for the case of radial kernels, the bound can be minimized by solving the -center problem. The outcome is a linear time construction of a sparse kernel mean, which also lends itself naturally to an automatic sparsity selection scheme. We show the computational gains of our method by looking at three problems involving kernel means: Euclidean embedding of distributions, class proportion estimation, and clustering using the mean-shift algorithm.", "subjects": "Machine Learning (stat.ML)", "authors": "E. Cruz Cort\u00e9s, C. Scott,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00269", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00269", "title": "\nContrastive Pessimistic Likelihood Estimation for Semi-Supervised  Classification", "abstract": "Improvement guarantees for semi-supervised classifiers can currently only be given under restrictive conditions on the data. We propose a general way to perform semi-supervised parameter estimation for likelihood-based classifiers for which, on the full training set, the estimates are never worse than the supervised solution in terms of the log-likelihood. We argue, moreover, that we may expect these solutions to really improve upon the supervised classifier in particular cases. In a worked-out example for LDA, we take it one step further and essentially prove that its semi-supervised version is strictly better than its supervised counterpart. The two new concepts that form the core of our estimation principle are contrast and pessimism. The former refers to the fact that our objective function takes the supervised estimates into account, enabling the semi-supervised solution to explicitly control the potential improvements over this estimate. The latter refers to the fact that our estimates are conservative and therefore resilient to whatever form the true labeling of the unlabeled data takes on. Experiments demonstrate the improvements in terms of both the log-likelihood and the classification error rate on independent test sets.", "subjects": "Machine Learning (stat.ML)", "authors": "Marco Loog,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00233", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00233", "title": "\nCrossover transition in the Fluctuation of Internet", "abstract": "Gibrat's law predicts that the standard deviation of the growth rate of a node's degree is constant. On the other hand, the preferential attachment(PA) indicates that such standard deviation decreases with initial degree as a power law of exponent . While both models have been applied to Internet modeling, this inconsistency requires the verification of their validation. Therefore we empirically study the fluctuation of Internet of three different time intervals(daily, monthly and yearly). We find a crossover transition from PA model to Gibrat's law, which has never been reported. Specifically Gibrat-law starts from small degree region and extends gradually with the increase of the observed period. We determine the validated periods for both models and find that the correlation between internal links has large contribution to the emergence of Gibrat law. These findings indicate neither PA nor Gibrat law is applicable to the actual Internet, which requires a more complete model theory.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Jiang-Hai Qian, Qu Chen, Ding-Ding Han, Yu-Gang Ma,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00215", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00215", "title": "\nOptimal mass transport over bridges", "abstract": "We present an overview of our recent work on implementable solutions to the Schroedinger bridge problem and their potential application to optimal transport and various generalizations.", "subjects": "Optimization and Control (math.OC)", "authors": "Yongxin Chen, Tryphon Georgiou, Michele Pavon,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00164", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00164", "title": "\nAnalysis of Crowdsourced Sampling Strategies for HodgeRank with Sparse  Random Graphs", "abstract": "Crowdsourcing platforms are now extensively used for conducting subjective pairwise comparison studies. In this setting, a pairwise comparison dataset is typically gathered via random sampling, either emph or emph replacement. In this paper, we use tools from random graph theory to analyze these two random sampling methods for the HodgeRank estimator. Using the Fiedler value of the graph as a measurement for estimator stability (informativeness), we provide a new estimate of the Fiedler value for these two random graph models. In the asymptotic limit as the number of vertices tends to infinity, we prove the validity of the estimate. Based on our findings, for a small number of items to be compared, we recommend a two-stage sampling strategy where a greedy sampling method is used initially and random sampling emph replacement is used in the second stage. When a large number of items is to be compared, we recommend random sampling with replacement as this is computationally inexpensive and trivially parallelizable. Experiments on synthetic and real-world datasets support our analysis.", "subjects": "Machine Learning (stat.ML)", "authors": "Braxton Osting, Jiechao Xiong, Qianqian Xu, Yuan Yao,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00149", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00149", "title": "\nSuppressing traffic-driven epidemic spreading by edge-removal strategies", "abstract": "The interplay between traffic dynamics and epidemic spreading on complex networks has received increasing attention in recent years. However, the control of traffic-driven epidemic spreading remains to be a challenging problem. In this Brief Report, we propose a method to suppress traffic-driven epidemic outbreak by properly removing some edges in a network. We find that the epidemic threshold can be enhanced by the targeted cutting of links among large-degree nodes or edges with the largest algorithmic betweeness. In contrast, the epidemic threshold will be reduced by the random edge removal. These findings are robust with respect to traffic-flow conditions, network structures and routing strategies. Moreover, we find that the shutdown of targeted edges can effectively release traffic load passing through large-degree nodes, rendering a relatively low probability of infection to these nodes.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Han-Xin Yang, Zhi-Xi Wu, Bing-Hong Wang,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00146", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00146", "title": "\nDisassortative mixing accelerates consensus in the naming game", "abstract": "In this paper, we study the role of degree mixing in the naming game. It is found that consensus can be accelerated on disassortative networks. We provide a qualitative explanation of this phenomenon based on clusters statistics. Compared with assortative mixing, disassortative mixing can promote the merging of different clusters, thus resulting in a shorter convergence time. Other quantities, including the evolutions of the success rate, the number of total words and the number of different words, are also studied.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Han-Xin Yang, Bing-Hong Wang,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00145", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00145", "title": "\nSuppressing traffic-driven epidemic spreading by use of the efficient  routing protocol", "abstract": "Despite extensive work on the interplay between traffic dynamics and epidemic spreading, the control of epidemic spreading by routing strategies has not received adequate attention. In this paper, we study the impact of efficient routing protocol on epidemic spreading. In the case of infinite node-delivery capacity, where the traffic is free of congestion, we find that that there exists optimal values of routing parameter, leading to the maximal epidemic threshold. This means that epidemic spreading can be effectively controlled by fine tuning the routing scheme. Moreover, we find that an increase in the average network connectivity and the emergence of traffic congestion can suppress the epidemic outbreak.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Han-Xin Yang, Zhi-Xi Wu,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00138", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00138", "title": "\nOn the isotypic decomposition of cohomology modules of symmetric  semi-algebraic sets: polynomial bounds on multiplicities", "abstract": "We consider symmetric (as well as multi-symmetric) real algebraic varieties and semi-algebraic sets, as well as symmetric complex varieties in affine and projective spaces, defined by polynomials of fixed degrees. We give polynomial (in the dimension of the ambient space) bounds on the number of irreducible representations of the symmetric group which acts on these sets, as well as their multiplicities, appearing in the isotypic decomposition of their cohomology modules with coefficients in a field of characteristic . We also give some applications of our methods in proving lower bounds on the degrees of defining polynomials of certain symmetric semi-algebraic sets, as well as better bounds on the Betti numbers of the images under projections of (not necessarily symmetric) bounded real algebraic sets. Finally, we conjecture that the multiplicities of the irreducible representations of the symmetric group in the cohomology modules of symmetric semi-algebraic sets are computable with polynomial complexity, which would imply that the Betti numbers of such sets are also computable with polynomial complexity. This is in contrast with general semi-algebraic sets, for which this problem is provably hard (-hard).", "subjects": "Algebraic Geometry (math.AG)", "authors": "Saugata Basu, Cordian Riener,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00080", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00080", "title": "\nMinimax Optimum Estimators for Phase Synchronization in IEEE 1588", "abstract": "The IEEE 1588 protocol has received recent interest as a means of delivering sub-microsecond level clock phase synchronization over packet-switched mobile backhaul networks. Due to the randomness of the end-to-end delays in packet networks, the recovery of clock phase from packet timestamps in IEEE 1588 must be treated as a statistical estimation problem. A number of estimators for this problem have been suggested in the literature, but little is known about the best achievable performance. In this paper, we describe new minimax estimators for this problem, that are optimum in terms of minimizing the maximum mean squared error over all possible values of the unknown parameters. Minimax estimators that utilize information from past timestamps to improve accuracy are also introduced. Simulation results indicate that significant performance gains over conventional estimators can be obtained via such optimum processing techniques. These minimax estimators also provide fundamental limits on the performance of phase offset estimation schemes.", "subjects": "Applications (stat.AP)", "authors": "Anand Guruswamy, Rick S. Blum, Shalinee Kishore, Mark Bordogna,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00034", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00034", "title": "\nRadial Basis Function (RBF)-based Parametric Models for Closed and Open  Curves within the Method of Regularized Stokeslets", "abstract": "The method of regularized Stokeslets (MRS) is a numerical approach using regularized fundamental solutions to compute the flow due to an object in a viscous fluid where inertial effects can be neglected. The elastic object is represented as a Lagrangian structure, exerting point forces on the fluid. The forces on the structure are often determined by a bending or tension model, previously calculated using finite difference approximations. In this paper, we study Spherical Basis Function (SBF), Radial Basis Function (RBF) and Lagrange-Chebyshev parametric models to represent and calculate forces on elastic structures that can be represented by an open curve, motivated by the study of cilia and flagella. The evaluation error for static open curves for the different interpolants, as well as errors for calculating normals and second derivatives using different types of clustered parametric nodes, are given for the case of an open planar curve. We determine that SBF and RBF interpolants built on clustered nodes are competitive with Lagrange-Chebyshev interpolants for modeling twice-differentiable open planar curves. We propose using SBF and RBF parametric models within the MRS for evaluating and updating the elastic structure. Results for open and closed elastic structures immersed in a 2D fluid are presented, showing the efficacy of the RBF-Stokeslets method.", "subjects": "Numerical Analysis (math.NA)", "authors": "Varun Shankar, Sarah D. Olson,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1503.05913", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05913", "title": "\nLeader selection and weight redesign problems for multi-agent systems", "abstract": "For an uncontrollable system, adding leaders and adjusting edge weights are two methods to improve controllability. In this paper, controllability of multi-agent systems under directed topologies is studied, especially on leader selection problem and weight redesign problem. For the former one, necessary and sufficient algebraic conditions of single leader controllability are given. When a system cannot be controlled by only one leader, necessary and sufficient conditions for controllability with fewest leaders are proposed. To improve controllability by redesigning weights, the system is supposed to be structurally controllable, which holds if and only if the communication topology contains a spanning tree. It is proved that the number of fewest edges needed to adjust weights equals the rank deficiency of controllability matrix. An algorithm on how to perform weight redesign is presented. Simulation examples are provided to illustrate the theoretical results.", "subjects": "Systems and Control (cs.SY)", "authors": "Bin Zhao, Yongqiang Guan, Long Wang,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05908", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05908", "title": "\nAchieving Multiple Goals via Voluntary Efforts and Motivation Asymmetry", "abstract": "The achievement of common goals through voluntary efforts of members of a group can be challenged by the high temptation of individual defection. Here, two-person one-goal assurance games are generalized to N-person, M-goal achievement games in which group members can have different motivations with respect to the achievement of the different goals. The theoretical performance of groups faced with the challenge of multiple simultaneous goals is analyzed mathematically and computationally. For two-goal scenarios one finds that \"polarized\" as well as \"biased\" groups perform well in the presence of defectors. A special case, called individual purpose games (N-person, N-goal achievements games where there is a one-to-one mapping between actors and goals for which they have a high achievement motivation) is analyzed in more detail in form of the \"importance of being different theorem\". It is shown that in some individual purpose games, groups of size N can successfully accomplish N goals, such that each group member is highly motivated towards the achievement of one unique goal. The game-theoretic results suggest that multiple goals as well as differences in motivations can, in some cases, correspond to highly effective groups.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Eckart Bindewald,", "date": "2015-3-15"}, 
{"urllink": "http://arxiv.org/abs/1503.05907", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05907", "title": "\nSyntagma Lexical Database", "abstract": "This paper discusses the structure of Syntagma's Lexical Database (focused on Italian). The basic database consists in four tables. Table Forms contains word inflections, used by the POS-tagger for the identification of input-words. Forms is related to Lemma. Table Lemma stores all kinds of grammatical features of words, word-level semantic data and restrictions. In the table Meanings meaning-related data are stored: definition, examples, domain, and semantic information. Table Valency contains the argument structure of each meaning, with syntactic and semantic features for each argument. The extended version of SLD contains the links to Syntagma's Semantic Net and to the WordNet synsets of other languages.", "subjects": "Computation and Language (cs.CL)", "authors": "Daniel Christen,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05904", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05904", "title": "\nGames Without Frontiers: Investigating Video Games as a Covert Channel", "abstract": "The Internet has become a critical communication infrastructure for citizens to organize protests and express dissatisfaction with their governments. This fact has not gone unnoticed, with governments clamping down on this medium via censorship, and circumvention researchers working tirelessly to stay one step ahead. In this paper, we explore a promising new avenue for covert channels: using video games as a cover protocol. The popularity of platforms like Steam have given rise to a rich population of video games for use as cover. The common properties of games in the same genre simplify the process of adapting channels to evade detection. We demonstrate the feasibility of this approach using two real time strategy games (including a popular closed-source game). We show how common properties of these games can be used to design a coding scheme to translate data into game commands in a way that is general across games and requires little per-game customizations. We evaluate the security of Castle by quantifying its resilience to a censor-adversary, its similarity to real game traffic, and its ability to avoid common pitfalls in covert channel design. We use our prototype to demonstrate that Castle can provide throughput which is amenable to transfer of textual data ( eg e-mail, short articles, etc.).", "subjects": "Cryptography and Security (cs.CR)", "authors": "Bridger Hahn, Rishab Nithyanand, Phillipa Gill, Rob Johnson,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05897", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05897", "title": "\nIncentivizing High Quality Crowdwork", "abstract": "We study the causal effects of financial incentives on the quality of crowdwork. We focus on performance-based payments (PBPs), bonus payments awarded to workers for producing high quality work. We design and run randomized behavioral experiments on the popular crowdsourcing platform Amazon Mechanical Turk with the goal of understanding when, where, and why PBPs help, identifying properties of the payment, payment structure, and the task itself that make them most effective. We provide examples of tasks for which PBPs do improve quality. For such tasks, the effectiveness of PBPs is not too sensitive to the threshold for quality required to receive the bonus, while the magnitude of the bonus must be large enough to make the reward salient. We also present examples of tasks for which PBPs do not improve quality. Our results suggest that for PBPs to improve quality, the task must be effort-responsive: the task must allow workers to produce higher quality work by exerting more effort. We also give a simple method to determine if a task is effort-responsive a priori. Furthermore, our experiments suggest that all payments on Mechanical Turk are, to some degree, implicitly performance-based in that workers believe their work may be rejected if their performance is sufficiently poor. Finally, we propose a new model of worker behavior that extends the standard principal-agent model from economics to include a worker's subjective beliefs about his likelihood of being paid, and show that the predictions of this model are in line with our experimental findings. This model may be useful as a foundation for theoretical studies of incentives in crowdsourcing markets.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Chien-Ju Ho, Aleksandrs Slivkins, Siddharth Suri, Jennifer Wortman Vaughan,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05882", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05882", "title": "\nDivisible Load Scheduling in Mobile Grid based on Stackelberg Pricing  Game", "abstract": "Nowadays, it has become feasible to use mobile nodes as contributing entities in computing systems. In this paper, we consider a computational grid in which the mobile devices can share their idle resources to realize parallel processing. The overall computing task can be arbitrarily partitioned into multiple subtasks to be distributed to mobile resource providers (RPs). In this process, the computation load scheduling problem is highlighted. Based on the optimization objective, i.e., minimizing the task makespan, a buyer-seller model in which the task sponsor can inspire the SPs to share their computing resources by paying certain profits, is proposed. The Stackelberg Pricing Game (SPG) is employed to obtain the optimal price and shared resource amount of each SP. Finally, we evaluate the performance of the proposed algorithm by system simulation and the results indicate that the SPG-based load scheduling algorithm can significantly improve the time gain in mobile grid systems.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Jiadi Chen, Qiang Zheng, Hang Long, Wenbo Wang,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05881", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05881", "title": "\nADS 2.0: new architecture, API and services", "abstract": "The ADS platform is undergoing the biggest rewrite of its 20-year history. While several components have been added to its architecture over the past couple of years, this talk will concentrate on the underpinnings of ADS's search layer and its API. To illustrate the design of the components in the new system, we will show how the new ADS user interface is built exclusively on top of the API using RESTful web services. Taking one step further, we will discuss how we plan to expose the treasure trove of information hosted by ADS (10 million records and fulltext for much of the Astronomy and Physics refereed literature) to partners interested in using this API. This will provide you (and your intelligent applications) with access to ADS's underlying data to enable the extraction of new knowledge and the ingestion of these results back into the ADS. Using this framework, researchers could run controlled experiments with content extraction, machine learning, natural language processing, etc. In this talk, we will discuss what is already implemented, what will be available soon, and where we are going next.", "subjects": "Digital Libraries (cs.DL)", "authors": "Roman Chyla, Alberto Accomazzi, Alexandra Holachek, Carolyn S. Grant, Jonathan Elliott, Edwin A. Henneken, Donna M. Thompson, Michael J. Kurtz, Stephen S. Murray, Vladimir Sudilovsky,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05879", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05879", "title": "\nRegular realizability problems and regular languages", "abstract": "We investigate regular realizability (RR) problems, which are the problems of verifying whether intersection of a regular language -- the input of the problem -- and fixed language called filter is non-empty. We consider two kind of problems depending on representation of regular language. If a regular language on input is represented by a DFA, then we obtain (deterministic) regular realizability problem and we show that in this case the complexity of regular realizability problem for an arbitrary regular filter is either L-complete or NL-complete. We also show that in case of representation regular language on input by NFA the problem is always NL-complete.", "subjects": "Formal Languages and Automata Theory (cs.FL)", "authors": "Alexander A. Rubtsov,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05860", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05860", "title": "\nBuilding Statistical Shape Spaces for 3D Human Modeling", "abstract": "Statistical models of 3D human shape and pose learned from scan databases have developed into valuable tools to solve a variety of vision and graphics problems. Unfortunately, most publicly available models are of limited expressiveness as they were learned on very small databases that hardly reflect the true variety in human body shapes. In this paper, we contribute by rebuilding a widely used statistical body representation from the largest commercially available scan database, and making the resulting model available to the community (visit this http URL). As preprocessing several thousand scans for learning the model is a challenge in itself, we contribute by developing robust best practice solutions for scan alignment that quantitatively lead to the best learned models. We make implementations of these preprocessing steps also publicly available. We extensively evaluate the improved accuracy and generality of our new model, and show its improved performance for human body reconstruction from sparse input data.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Leonid Pishchulin, Stefanie Wuhrer, Thomas Helten, Christian Theobalt, Bernt Schiele,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05849", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05849", "title": "\nDeep Transform: Time-Domain Audio Error Correction via Probabilistic  Re-Synthesis", "abstract": "In the process of recording, storage and transmission of time-domain audio signals, errors may be introduced that are difficult to correct in an unsupervised way. Here, we train a convolutional deep neural network to re-synthesize input time-domain speech signals at its output layer. We then use this abstract transformation, which we call a deep transform (DT), to perform probabilistic re-synthesis on further speech (of the same speaker) which has been degraded. Using the convolutive DT, we demonstrate the recovery of speech audio that has been subject to extreme degradation. This approach may be useful for correction of errors in communications devices.", "subjects": "Sound (cs.SD)", "authors": "Andrew J.R. Simpson,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05847", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05847", "title": "\nHypercomputation, Frege, Deleuze: Solving Thomson's Lamp", "abstract": "We present the first known solution to the original supertask, the Thomson Lamp Paradox. We also offer preliminary resources for classifying computational complexity of various supertasks. In so doing we consider a newly apparent paradox between the metrical limit and the ordinal limit. We use this distinction between the metrical and ordinal limits to explain the shortcomings both of Thomson's original formulation of the Lamp Paradox and Benacerraf's consequent critique. We resolve this paradox through a careful consideration of transfinite ordinals and locate its ambiguity as inherent to the identity relation under logic with a close reading of Frege's Begriffsschrift. With this close reading in hand we expose how the identity relation is counter-intuitively polyvalent and, with supertasks, how the logico-mathematical field operates on the basis of Deleuzian point-folds. Our results combine resources from philosophy, mathematics, and computer science to ground the field of hypercomputation for logically rigorous study.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Abhishek Bose-Kolanu,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05832", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05832", "title": "\nConstant-complexity Stochastic Simulation Algorithm with Optimal Binning", "abstract": "At the cellular scale, biochemical processes are governed by random interactions between reactant molecules with small copy counts, leading to behavior that is inherently stochastic. Such systems are often modeled as continuous-time Markov jump processes that can be described by the Chemical Master Equation. Gillespie's Stochastic Simulation Algorithm (SSA) generates exact trajectories of these systems. The amount of computational work required for each step of the original SSA is proportional to the number of reaction channels, leading to computational complexity that scales linearly as the problem size increases. The original SSA is therefore inefficient for large problems, which has prompted the development of several alternative formulations with improved scaling properties. We describe an exact SSA that uses a table data structure with event time binning to achieve constant computational complexity. Optimal algorithm parameters and binning strategies are discussed. We compare the computational efficiency of the algorithm to existing methods and demonstrate excellent scaling for large problems. This method is well suited for generating exact trajectories of large models that can be described by the Reaction-Diffusion Master Equation arising from spatially discretized reaction-diffusion processes.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Kevin R. Sanft, Hans G. Othmer,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05831", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05831", "title": "\nNeural Network-Based Active Learning in Multivariate Calibration", "abstract": "In chemometrics, data from infrared or near-infrared (NIR) spectroscopy are often used to identify a compound or to analyze the composition of amaterial. This involves the calibration of models that predict the concentration ofmaterial constituents from the measured NIR spectrum. An interesting aspect of multivariate calibration is to achieve a particular accuracy level with a minimum number of training samples, as this reduces the number of laboratory tests and thus the cost of model building. In these chemometric models, the input refers to a proper representation of the spectra and the output to the concentrations of the sample constituents. The search for a most informative new calibration sample thus has to be performed in the output space of the model, rather than in the input space as in conventionalmodeling problems. In this paper, we propose to solve the corresponding inversion problem by utilizing the disagreements of an ensemble of neural networks to represent the prediction error in the unexplored component space. The next calibration sample is then chosen at a composition where the individual models of the ensemble disagree most. The results obtained for a realistic chemometric calibration example show that the proposed active learning can achieve a given calibration accuracy with less training samples than random sampling.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "A. Ukil, J. Bernasconi,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05830", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05830", "title": "\nSign Language Fingerspelling Classification from Depth and Color Images  using a Deep Belief Network", "abstract": "Automatic sign language recognition is an open problem that has received a lot of attention recently, not only because of its usefulness to signers, but also due to the numerous applications a sign classifier can have. In this article, we present a new feature extraction technique for hand pose recognition using depth and intensity images captured from a Microsoft Kinect sensor. We applied our technique to American Sign Language fingerspelling classification using a Deep Belief Network, for which our feature extraction technique is tailored. We evaluated our results on a multi-user data set with two scenarios: one with all known users and one with an unseen user. We achieved 99% recall and precision on the first, and 77% recall and 79% precision on the second. Our method is also capable of real-time sign classification and is adaptive to any environment or lightning intensity.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Lucas Rioux-Maldague, Philippe Gigu\u00e8re,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05829", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05829", "title": "\nOptimum Fusion of Possibly Corrupted Reports for Distributed Detection  in Multi-Sensor Networks", "abstract": "The most common approach to mitigate the impact that the presence of malicious nodes has on the accuracy of decision fusion schemes consists in observing the behavior of the nodes over a time interval T and then removing the reports of suspect nodes from the fusion process. By assuming that some a-priori information about the presence of malicious nodes and their behavior is available, we show that the information stemming from the suspect nodes can be exploited to further improve the decision fusion accuracy. Specifically, we derive the optimum fusion rule and analyze the achievable performance for two specific cases. In the first case, the states of the nodes (corrupted or honest) are independent of each other and the fusion center knows only the probability that a node is malicious. In the second case, the exact number of corrupted nodes is fixed and known to the fusion center. We also investigate the optimum corruption strategy for the malicious nodes, showing that always reverting the local decision does not necessarily maximize the loss of performance at the fusion center.", "subjects": "Systems and Control (cs.SY)", "authors": "Andrea Abrardo, Mauro Barni, Kassem Kallas, Benedetta Tondi,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05819", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05819", "title": "\nAnalysis and Throughput Optimization of Selective Chase Combining for  OFDM Systems", "abstract": "In this paper, we present throughput analysis and optimization of bandwidth efficient selective retransmission method at modulation layer for conventional Chase Combining (CC) method under orthogonal frequency division multiplexing (OFDM) signaling. Most of the times, there are fewer errors in a failed packet and receiver can recover from errors receiving partial copy of original frame. The proposed selective retransmission method at modulation layer for OFDM modulation requests retransmission of information corresponding to the poor quality subcarriers. In this work, we propose cross-layer multiple selective Chase combining (MSCC) method and Chase combining with selective retransmission (CCWS) at modulation level. We also present bit-error rate (BER) and throughput analysis of the proposed MSCC and CCWS methods. In order to maximize throughput of the proposed methods under OFDM signaling, we formulate optimization problem with respect to amount of information to be retransmitted in selective retransmission in the event of packet failure. We present tight BER upper bounds and tight throughput lower bounds for the proposed selective Chase combining methods. The simulation results demonstrate significant throughput gain of the optimized selective retransmission methods over conventional retransmission methods. The throughput gain of the proposed selective retransmission atmodulation layer are also holds for conventional for hybrid automatic repeat request (HARQ) methods.", "subjects": "Information Theory (cs.IT)", "authors": "Taniya Shafique, Muhammad Zia, Huy Dung Han,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05816", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05816", "title": "\nTraffic Characterization of LTI Event-triggered Control Systems: a  Formal Approach", "abstract": "Unnecessary communication and computation in the periodic execution of control tasks lead to over-provisioning in hardware design (or underexploitation in hardware utilization) in control applications, such as networked control systems. To address these issues, researchers have proposed a new class of strategies, named event-driven strategies. Despite of their beneficiary effects, matters like task scheduling and appropriate dimensioning of communication components have become more complicated with respect to traditional periodic strategies. In this paper, we present a formal approach to derive an abstracted system that captures the sampling behavior of a family of event-triggered strategies for the case of LTI systems. This structure, termed power quotient system, approximately simulates the sampling behavior of the aperiodic control system. Furthermore, the resulting quotient system is equivalent to a timed automaton. %The construction of this abstraction consists of a two-step abstraction followed by a reachability analysis. In the construction of the abstraction, the state space is confined to a finite number of convex regions, each of which represents a mode in the quotient system. An LMI-based technique is deployed to derive a sampling time interval associated to each region. Finally, a reachability analysis is leveraged to find the transitions of the quotient system.", "subjects": "Systems and Control (cs.SY)", "authors": "Arman Sharifi Kolarijani, Manuel Mazo Jr,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05812", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05812", "title": "\nCounting hypergraph matchings up to uniqueness threshold", "abstract": "We study the problem of approximate counting of weighted matchings in hypergraphs of bounded maximum edge size and maximum degree. The problem is expressed as evaluating the partition function, which is the weighted sum of all macthings in a hypergraph where each macthing is assigned a weight in terms of a fixed activity parameter . The problem unifies the two most important statistical physics models in approximate counting: the hardcore model for weighted independent set and the monomer-dimer model for weighted matching. We show that for hypergraph matchings, the critical activity is the uniqueness threshold for the Gibbs measure on -uniform -regular hypertree. We give an FPTAS for the hypergraphs of maximum edge size at most and maximum degree at most , whenever the activity . This is the first time that a result of this kind is established for a model other than spin systems. We prove this by constructing a hypergraph version of Weitz's self-avoiding walk tree, and verifying the strong spatial mixing (decay of correlation) of the Gibbs measure. By a folklore reduction from the hardcore model, there is no FPRAS for the family of hypergraphs as described above if , unless NP=RP. We also point out a barrier in the existing scheme for proving inapproximability which makes it insufficient to prove the inapproximability approaching the uniqueness threshold for hypergraphs.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Yitong Yin, Jinman Zhao,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05807", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05807", "title": "\nDSpot: Test Amplification for Automatic Assessment of Computational  Diversity", "abstract": "In this work, we characterize a new form of software diver- sity: the existence of a set of variants that (i) all share the same API, (ii) all behave the same according to an input- output based specification and (iii) exhibit observable dif- ferences when they run outside the specified input space. We quantify computational diversity as the dissimilarity be- tween execution traces on inputs that are outside the speci- fied domain. Our technique relies on test amplification. We propose source code transformations on test cases to explore the input domain and systematically sense the observation domain. We run our experiments on 472 variants of 7 classes from open-source, large and thoroughly tested Java classes. Our test amplification multiplies by ten the number of input points in the test suite and is effective at detecting software diversity.", "subjects": "Software Engineering (cs.SE)", "authors": "Benoit Baudry, Simon Allier, Marcelino Rodriguez-Cancio, Martin Monperrus,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05787", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05787", "title": "\nInteractive Illustrative Line Styles and Line Style Transfer Functions  for Flow Visualization", "abstract": "We present a flexible illustrative line style model for the visualization of streamline data. Our model partitions view-oriented line strips into parallel bands whose basic visual properties can be controlled independently. We thus extend previous line stylization techniques specifically for visualization purposes by allowing the parametrization of these bands based on the local line data attributes. Moreover, our approach supports emphasis and abstraction by introducing line style transfer functions that map local line attribute values to complete line styles. With a flexible GPU implementation of this line style model we enable the interactive exploration of visual representations of streamlines. We demonstrate the effectiveness of our model by applying it to 3D flow field datasets.", "subjects": "Graphics (cs.GR)", "authors": "Maarten H. Everts, Henk Bekker, Jos B.T.M. Roerdink, Tobias Isenberg,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05786", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05786", "title": "\nA General Framework for Multi-focal Image Classification and  Authentication: Application to Microscope Pollen Images", "abstract": "In this article, we propose a general framework for multi-focal image classification and authentication, the methodology being demonstrated on microscope pollen images. The framework is meant to be generic and based on a brute force-like approach aimed to be efficient not only on any kind, and any number, of pollen images (regardless of the pollen type), but also on any kind of multi-focal images. All stages of the framework's pipeline are designed to be used in an automatic fashion. First, the optimal focus is selected using the absolute gradient method. Then, pollen grains are extracted using a coarse-to-fine approach involving both clustering and morphological techniques (coarse stage), and a snake-based segmentation (fine stage). Finally, features are extracted and selected using a generalized approach, and their classification is tested with four classifiers: Weighted Neighbor Distance, Neural Network, Decision Tree and Random Forest. The latter method, which has shown the best and more robust classification accuracy results (above 97 % for any number of pollen types), is finally used for the authentication stage.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Fran\u00e7ois Chung, Tom\u00e1s Rodr\u00edguez,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05784", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05784", "title": "\nIdentifying Relevant Messages in a Twitter-based Citizen Channel for  Natural Disaster Situations", "abstract": "During recent years the online social networks (in particular Twitter) have become an important alternative information channel to traditional media during natural disasters, but the amount and diversity of messages poses the challenge of information overload to end users. The goal of our research is to develop an automatic classifier of tweets to feed a mobile application that reduces the difficulties that citizens face to get relevant information during natural disasters. In this paper, we present in detail the process to build a classifier that filters tweets relevant and non-relevant to an earthquake. By using a dataset from the Chilean earthquake of 2010, we first build and validate a ground truth, and then we contribute by presenting in detail the effect of class imbalance and dimensionality reduction over 5 classifiers. We show how the performance of these models is affected by these variables, providing important considerations at the moment of building these systems.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Alfredo Cobo, Denis Parra, Jaime Nav\u00f3n,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05782", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05782", "title": "\nLearning Hypergraph-regularized Attribute Predictors", "abstract": "We present a novel attribute learning framework named Hypergraph-based Attribute Predictor (HAP). In HAP, a hypergraph is leveraged to depict the attribute relations in the data. Then the attribute prediction problem is casted as a regularized hypergraph cut problem in which HAP jointly learns a collection of attribute projections from the feature space to a hypergraph embedding space aligned with the attribute space. The learned projections directly act as attribute classifiers (linear and kernelized). This formulation leads to a very efficient approach. By considering our model as a multi-graph cut task, our framework can flexibly incorporate other available information, in particular class label. We apply our approach to attribute prediction, Zero-shot and -shot learning tasks. The results on AWA, USAA and CUB databases demonstrate the value of our methods in comparison with the state-of-the-art approaches.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Sheng Huang, Mohamed Elhoseiny, Ahmed Elgammal, Dan Yang,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05781", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05781", "title": "\nMemantic: A Medical Knowledge Discovery Engine", "abstract": "We present a system that constructs and maintains an up-to-date co-occurrence network of medical concepts based on continuously mining the latest biomedical literature. Users can explore this network visually via a concise online interface to quickly discover important and novel relationships between medical entities. This enables users to rapidly gain contextual understanding of their medical topics of interest, and we believe this constitutes a significant user experience improvement over contemporary search engines operating in the biomedical literature domain.", "subjects": "Information Retrieval (cs.IR)", "authors": "Alexei Yavlinsky,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05768", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05768", "title": "\nOn learning optimized reaction diffusion processes for effective image  restoration", "abstract": "For several decades, image restoration remains an active research topic in low-level computer vision and hence new approaches are constantly emerging. However, many recently proposed algorithms achieve state-of-the-art performance only at the expense of very high computation time, which clearly limits their practical relevance. In this work, we propose a simple but effective approach with both high computational efficiency and high restoration quality. We extend conventional nonlinear reaction diffusion models by several parametrized linear filters as well as several parametrized influence functions. We propose to train the parameters of the filters and the influence functions through a loss based approach. Experiments show that our trained nonlinear reaction diffusion models largely benefit from the training of the parameters and finally lead to the best reported performance on common test datasets for image restoration. Due to their structural simplicity, our trained models are highly efficient and are also well-suited for parallel computation on GPUs.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Yunjin Chen, Wei Yu, Thomas Pock,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05767", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05767", "title": "\nAutomatic Pollen Grain and Exine Segmentation from Microscope Images", "abstract": "In this article, we propose an automatic method for the segmentation of pollen grains from microscope images, followed by the automatic segmentation of their exine. The objective of exine segmentation is to separate the pollen grain in two regions of interest: exine and inner part. A coarse-to-fine approach ensures a smooth and accurate segmentation of both structures. As a rough stage, grain segmentation is performed by a procedure involving clustering and morphological operations, while the exine is approximated by an iterative procedure consisting in consecutive cropping steps of the pollen grain. A snake-based segmentation is performed to refine the segmentation of both structures. Results have shown that our segmentation method is able to deal with different pollen types, as well as with different types of exine and inner part appearance. The proposed segmentation method aims to be generic and has been designed as one of the core steps of an automatic pollen classification framework.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Fran\u00e7ois Chung, Tom\u00e1s Rodr\u00edguez,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05761", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05761", "title": "\nEfficient Frequency-Domain Decoding Algorithms for Reed-Solomon Codes", "abstract": "In this paper, we proposed frequency-domain decoding algorithms for systematic Reed-Solomon (RS) codes over fields , where is a power of two. The proposed algorithms are based on the new polynomial basis with fast Fourier transform of computational complexity order . First, we reformulate the basis of syndrome polynomials in the decoding procedure such that the new transforms can be applied on the decoding procedures. Furthermore, a fast extended Euclidean algorithm is proposed to determine the error locator polynomial. The computational complexity of the proposed decoding algorithm is . This improves the best existing decoding complexity and reaches the best known complexity bound established by Justesen in 1976, where Justesen's approach is for RS codes only operating on some specified finite fields. As shown by the computer simulations, the proposed decoding algorithm is times faster than the typical one for the RS code.", "subjects": "Information Theory (cs.IT)", "authors": "Sian-Jheng Lin, Tareq Y. Al-Naffouri, Yunghsiang S. Han,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05743", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05743", "title": "\nImplementation of a Practical Distributed Calculation System with  Browsers and JavaScript, and Application to Distributed Deep Learning", "abstract": "Deep learning can achieve outstanding results in various fields. However, it requires so significant computational power that graphics processing units (GPUs) and/or numerous computers are often required for the practical application. We have developed a new distributed calculation framework called \"Sashimi\" that allows any computer to be used as a distribution node only by accessing a website. We have also developed a new JavaScript neural network framework called \"Sukiyaki\" that uses general purpose GPUs with web browsers. Sukiyaki performs 30 times faster than a conventional JavaScript library for deep convolutional neural networks (deep CNNs) learning. The combination of Sashimi and Sukiyaki, as well as new distribution algorithms, demonstrates the distributed deep learning of deep CNNs only with web browsers on various devices. The libraries that comprise the proposed methods are available under MIT license at this http URL", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Ken Miura, Tatsuya Harada,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05733", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05733", "title": "\nA software controlled voltage tuning system using multi-purpose ring  oscillators", "abstract": "This paper presents a novel software driven voltage tuning method that utilises multi-purpose Ring Oscillators (ROs) to provide process variation and environment sensitive energy reductions. The proposed technique enables voltage tuning based on the observed frequency of the ROs, taken as a representation of the device speed and used to estimate a safe minimum operating voltage at a given core frequency. A conservative linear relationship between RO frequency and silicon speed is used to approximate the critical path of the processor. Using a multi-purpose RO not specifically implemented for critical path characterisation is a unique approach to voltage tuning. The parameters governing the relationship between RO and silicon speed are obtained through the testing of a sample of processors from different wafer regions. These parameters can then be used on all devices of that model. The tuning method and software control framework is demonstrated on a sample of XMOS XS1-U8A-64 embedded microprocessors, yielding a dynamic power saving of up to 25% with no performance reduction and no negative impact on the real-time constraints of the embedded software running on the processor.", "subjects": "Other Computer Science (cs.OH)", "authors": "Steve Kerrison, Kerstin Eder,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05704", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05704", "title": "\nOn Various Parameters of $Z_q$-Simplex codes for an even integer q", "abstract": "In this paper, we defined the -linear codes and discussed its various parameters. We constructed -Simplex code and -MacDonald code and found its parameters. We have given a lower and an upper bounds of its covering radius for q is an even integer.", "subjects": "Information Theory (cs.IT)", "authors": "P. Chella Pandian, C. Durairajan,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05702", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05702", "title": "\nThe Open Access Advantage Considering Citation, Article Usage and Social  Media Attention", "abstract": "In this study, we compare the difference in the impact between open access (OA) and non-open access (non-OA) articles. 1761 Nature Communications articles published from 1 Jan. 2012 to 31 Aug. 2013 are selected as our research objects, including 587 OA articles and 1174 non-OA articles. Citation data and daily updated article-level metrics data are harvested directly from the platform of nature.com. Data is analyzed from the static versus temporal-dynamic perspectives. The OA citation advantage is confirmed, and the OA advantage is also applicable when extending the comparing from citation to article views and social media attention. More important, we find that OA papers not only have the great advantage of total downloads, but also have the feature of keeping sustained and steady downloads for a long time. For article downloads, non-OA papers only have a short period of attention, when the advantage of OA papers exists for a much longer time.", "subjects": "Digital Libraries (cs.DL)", "authors": "Xianwen Wang, Chen Liu, Wenli Mao, Zhichao Fang,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05698", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05698", "title": "\nThe Lock-free $k$-LSM Relaxed Priority Queue", "abstract": "Priority queues are data structures which store keys in an ordered fashion to allow efficient access to the minimal (maximal) key. Priority queues are essential for many applications, e.g., Dijkstra's single-source shortest path algorithm, branch-and-bound algorithms, and prioritized schedulers. Efficient multiprocessor computing requires implementations of basic data structures that can be used concurrently and scale to large numbers of threads and cores. Lock-free data structures promise superior scalability by avoiding blocking synchronization primitives, but the emph operation is an inherent scalability bottleneck in concurrent priority queues. Recent work has focused on alleviating this obstacle either by batching operations, or by relaxing the requirements to the emph operation. We present a new, lock-free priority queue that relaxes the emph operation so that it is allowed to delete emph of the smallest keys, where is a runtime configurable parameter. Additionally, the behavior is identical to a non-relaxed priority queue for items added and removed by the same thread. The priority queue is built from a logarithmic number of sorted arrays in a way similar to log-structured merge-trees. We experimentally compare our priority queue to recent state-of-the-art lock-free priority queues, both with relaxed and non-relaxed semantics, showing high performance and good scalability of our approach.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Martin Wimmer, Jakob Gruber, Jesper Larsson Tr\u00e4ff, Philippas Tsigas,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05696", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05696", "title": "\nPerformance Analysis of Random Linear Network Coding in Two-Source  Single-Relay Networks", "abstract": "This paper considers the multiple-access relay channel in a setting where two source nodes transmit packets to a destination node, both directly and via a relay node, over packet erasure channels. Intra-session network coding is used at the source nodes and inter-session network coding is employed at the relay node to combine the recovered source packets of both source nodes. In this work, we investigate the performance of the network-coded system in terms of the probability that the destination node will successfully recover the source packets of the two source nodes. We build our analysis on fundamental probability expressions for random matrices over finite fields and we derive upper bounds on the system performance for the case of systematic and non-systematic network coding. Simulation results show that the upper bounds are very tight and accurately predict the decoding probability at the destination node. Our analysis also exposes the clear benefits of systematic network coding at the source nodes compared to non-systematic transmission.", "subjects": "Information Theory (cs.IT)", "authors": "Amjad Saeed Khan, Ioannis Chatzigeorgiou,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05694", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05694", "title": "\nThe More We Share, The More We Have: Improving GPU performance through  Register Sharing", "abstract": "Graphics Processing Units (GPUs) consisting of Streaming Multiprocessors (SMs) achieve high throughput by running a large number of threads and context switching among them to hide execution latencies. The amount of thread level parallelism that can be utilized depends on the number of resident threads on each of the SMs. The threads are typically structured into a grid of thread blocks with each thread block containing a large number of threads. The number of thread blocks, and hence the number of threads that can be launched on an SM, depends on the resource usage--e.g. number of registers, amount of shared memory--of the thread blocks. Since the allocation of threads to an SM is at the thread block granularity, some of the resources may not be used up completely and hence will be wasted. We propose an approach, Register Sharing, that utilizes the wasted registers in SMs to launch more thread blocks and hence increases the number of resident threads. We further propose three optimizations that make effective use of these extra thread blocks to hide long execution latencies and hence reduce the number of stall cycles. We experimentally validated our approach using GPGPU-Sim simulator on several applications from 3 different benchmark suites: GPGPU-Sim, Rodinia, and Parboil. We observed a maximum improvement of 24% and an average improvement of 11% with a very small hardware overhead.", "subjects": "Hardware Architecture (cs.AR)", "authors": "Vishwesh Jatala, Jayvant Anantpur, Amey Karkare,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05692", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05692", "title": "\nAn approach to improving edge detection for facial and remotely sensed  images using vector order statistics", "abstract": "This paper presents an improved edge detection algorithm for facial and remotely sensed images using vector order statistics. The developed algorithm processes colored images directly without been converted to gray scale. A number of the existing algorithms converts the colored images into gray scale before detection of edges. But this process leads to inaccurate precision of recognized edges, thus producing false and broken edges in the output edge map. Facial and remotely sensed images consist of curved edge lines which have to be detected continuously to prevent broken edges. In order to deal with this, a collection of pixel approach is introduced with a view to minimizing the false and broken edges that exists in the generated output edge map of facial and remotely sensed images.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "B O. Sadiq, S.M. Sani, S. Garba,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05689", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05689", "title": "\nEdge Detection: A Collection of Pixel based Approach for Colored Images", "abstract": "The existing traditional edge detection algorithms process a single pixel on an image at a time, thereby calculating a value which shows the edge magnitude of the pixel and the edge orientation. Most of these existing algorithms convert the coloured images into gray scale before detection of edges. However, this process leads to inaccurate precision of recognized edges, thus producing false and broken edges in the image. This paper presents a profile modelling scheme for collection of pixels based on the step and ramp edges, with a view to reducing the false and broken edges present in the image. The collection of pixel scheme generated is used with the Vector Order Statistics to reduce the imprecision of recognized edges when converting from coloured to gray scale images. The Pratt Figure of Merit (PFOM) is used as a quantitative comparison between the existing traditional edge detection algorithm and the developed algorithm as a means of validation. The PFOM value obtained for the developed algorithm is 0.8480, which showed an improvement over the existing traditional edge detection algorithms.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "B.O Sadiq, S.M Sani, S Garba,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05681", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05681", "title": "\nCombinatorics and complexity of guarding polygons with edge and point  2-transmitters", "abstract": "We consider a generalization of the classical Art Gallery Problem, where instead of a light source, the guards, called -transmitters, model a wireless device with a signal that can pass through at most walls. We show it is NP-hard to compute a minimum cover of point 2-transmitters, point -transmitters, and edge 2-transmitters in a simple polygon. The point 2-transmitter result extends to orthogonal polygons. In addition, we give necessity and sufficiency results for the number of edge 2-transmitters in general, monotone, orthogonal monotone, and orthogonal polygons.", "subjects": "Computational Geometry (cs.CG)", "authors": "Sarah Cannon, Thomas G. Fai, Justin Iwerks, Undine Leopold, Christiane Schmidt,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05671", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05671", "title": "\nOptimizing Neural Networks with Kronecker-factored Approximate Curvature", "abstract": "We propose an efficient method for approximating natural gradient descent in neural networks which we call Kronecker-factored Approximate Curvature (K-FAC). K-FAC is based on an efficiently invertible approximation of a neural network's Fisher information matrix which is neither diagonal nor low-rank, and in some cases is completely non-sparse. It is derived by approximating various large blocks of the Fisher (corresponding to entire layers) as factoring as Kronecker products between two much smaller matrices. While only several times more expensive to compute than the plain stochastic gradient, the updates produced by K-FAC make much more progress optimizing the objective, which results in an algorithm that can be much faster than stochastic gradient descent with momentum in practice. And unlike some previously proposed approximate natural-gradient/Newton methods such as Hessian-free methods, K-FAC works very well in highly stochastic optimization regimes.", "subjects": "Learning (cs.LG)", "authors": "James Martens, Roger Grosse,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05670", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05670", "title": "\nTime and Space Efficient Algorithms for RNA Folding with the  Four-Russians Technique", "abstract": "In this paper, we develop new algorithms for the basic RNA folding problem. Given an RNA sequence that contains nucleotides, the goal of the problem is to compute a pseudoknot-free secondary structure that maximizes the number of base pairs in the sequence. We show that there exists a dynamic programming algorithm that can solve the problem in time while using only memory space. In addition, we show that the time complexity of this algorithm can be further improved to at the expense of a slightly increased space complexity. To the best of our knowledge, this is the first algorithm that can solve the problem with traditional dynamic programming techniques in time . In addition, our results improve the best known upper bound of the space complexity of both this problem and the context-free language recognition problem.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Yinglei Song,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05667", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05667", "title": "\nBitSim: An Algebraic Similarity Measure for Description Logics Concepts", "abstract": "In this paper, we propose an algebraic similarity measure BS (BS stands for BitSim) for assigning semantic similarity score to concept definitions in ALCH+ an expressive fragment of Description Logics (DL). We define an algebraic interpretation function, I_B, that maps a concept definition to a unique string (_B) called bit-code) over an alphabet _B of 11 symbols belonging to L_B - the language over P B. IB has semantic correspondence with conventional model-theoretic interpretation of DL. We then define _BS on L_B. A detailed analysis of I_B and _BS has been given.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Sourish Dasgupta, Gaurav Maheshwari, Priyansh Trivedi,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05656", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05656", "title": "\nCost-Effective Conceptual Design Using Taxonomies", "abstract": "It is known that annotating named entities in unstructured and semi-structured data sets by their concepts improves the effectiveness of answering queries over these data sets. As every enterprise has a limited budget of time or computational resources, it has to annotate a subset of concepts in a given domain whose costs of annotation do not exceed the budget. We call such a subset of concepts a for the annotated data set. We focus on finding a conceptual design that provides the most effective answers to queries over the annotated data set, i.e., a . Since, it is often less time-consuming and costly to annotate general concepts than specific concepts, we use information on superclass/subclass relationships between concepts in taxonomies to find a cost-effective conceptual design. We quantify the amount by which a conceptual design with concepts from a taxonomy improves the effectiveness of answering queries over an annotated data set. If the taxonomy is a tree, we prove that the problem is NP-hard and propose an efficient approximation and pseudo-polynomial time algorithms for the problem. We further prove that if the taxonomy is a directed acyclic graph, given some generally accepted hypothesis, it is not possible to find any approximation algorithm with reasonably small approximation ratio for the problem. Our empirical study using real-world data sets, taxonomies, and query workloads shows that our framework effectively quantifies the amount by which a conceptual design improves the effectiveness of answering queries. It also indicates that our algorithms are efficient for a design-time task with pseudo-polynomial algorithm being generally more effective than the approximation algorithm.", "subjects": "Databases (cs.DB)", "authors": "Ali Vakilian, Yodsawalai Chodpathumwan, Arash Termehchy, Amir Nayyeri,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05650", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05650", "title": "\nBinary sequences with three-valued cross correlations of different  lengths", "abstract": "In this paper, new pairs of binary sequences with three cross correlation values are presented. The cross correlation values are shown to be low. Finally we present some numerical results and some open problems.", "subjects": "Information Theory (cs.IT)", "authors": "Jinquan Luo,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05646", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05646", "title": "\nRule Optimization for Real-Time Query Service in Software-Defined  Internet of Vehicles", "abstract": "Internet of Vehicles (IoV) has recently gained considerable attentions from both industry and research communities since the development of communication technology and smart city. However, a proprietary and closed way of operating hardwares in network equipments slows down the progress of new services deployment and extension in IoV. Moreover, the tightly coupled control and data planes in traditional networks significantly increase the complexity and cost of network management. By proposing a novel architecture, called Software-Defined Internet of Vehicles (SDIV), we adopt the software-defined network (SDN) architecture to address these problems by leveraging its separation of the control plane from the data plane and a uniform way to configure heterogeneous switches. However, the characteristics of IoV introduce the very challenges in rule installation due to the limited size of Flow Tables at OpenFlow-enabled switches which are the main component of SDN. It is necessary to build compact Flow Tables for the scalability of IoV. Accordingly, we develop a rule optimization approach for real-time query service in SDIV. Specifically, we separate wired data plane from wireless data plane and use multicast address in wireless data plane. Furthermore, we introduce a destination-driven model in wired data plane for reducing the number of rules at switches. Experiments show that our rule optimization strategy reduces the number of rules while keeping the performance of data transmission.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Xin Wang, Cheng Wang, Changjun Jiang, Lei Yang, Zhong Li, Xiaobo Zhou,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05642", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05642", "title": "\nHybrid Social Networking Application for a University Community", "abstract": "A hybrid social network for building social communities for a university community is presented. The system employed the semantic ontology for an offline/online social network site (SNS). It captures the core features of an SNS including profile creation, friend invite/search, group formation, chatting/messaging, blogging and voting. Three core frameworks - the peer2me framework, SMSN semantic mobile social network and Peoplepods framework were considered in the implementation phase. The results show remarkable matching performance for prosumers with similar interests with relevance close to unity. The social network was able to capture the needs of the university students by serving as a handy direction to popular locations within the campus.", "subjects": "Social and Information Networks (cs.SI)", "authors": "O. Chigozie, P. Williams, N. E. Osegi,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05638", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05638", "title": "\nEntropy-scaling search of massive biological data", "abstract": "The continual onslaught of new omics data has forced upon scientists the fortunate problem of having too much data to analyze. Luckily, it turns out that many datasets exhibit well-defined structure that can be exploited for the design of smarter analysis tools. We introduce an entropy-scaling data structure---which given a low fractal dimension database, scales in both time and space with the entropy of that underlying database---to perform similarity search, a fundamental operation in data science. Using these ideas, we present accelerated versions of standard tools for use by practitioners in the three domains of high-throughput drug screening, metagenomics, and protein structure search, none of which have any loss in specificity or significant loss in sensitivity: Ammolite, 12x speedup of small molecule similarity search with less than 4% loss in sensitivity; CaBLASTX, 673x speedup of BLASTX with less than 5% loss in sensitivity; and esFragBag, 10x speedup of FragBag with less than 0.2% loss in sensitivity.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Y. William Yu, Noah M. Daniels, David Christian Danko, Bonnie Berger,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05637", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05637", "title": "\nCompute-Compress-and-Forward: Exploiting Asymmetry of Wireless Relay  Networks", "abstract": "Compute-and-forward (CF) harnesses interference in a wireless networkby allowing relays to compute combinations of source messages. The computed message combinations at relays are correlated, and so directly forwarding these combinations to a destination generally incurs information redundancy and spectrum inefficiency. To address this issue, we propose a novel relay strategy, termed compute-compress-and-forward (CCF). In CCF, source messages are encoded using nested lattice codes constructed on a chain of nested coding and shaping lattices. A key difference of CCF from CF is an extra compressing stage inserted in between the computing and forwarding stages of a relay, so as to reduce the forwarding information rate of the relay. The compressing stage at each relay consists of two operations: first to quantize the computed message combination on an appropriately chosen lattice (referred to as a quantization lattice), and then to take modulo on another lattice (referred to as a modulo lattice). We study the design of the quantization and modulo lattices and propose successive recovering algorithms to ensure the recoverability of source messages at destination. Based on that, we formulate a sum-rate maximization problem that is in general an NP-hard mixed integer program. A low-complexity algorithm is proposed to give a suboptimal solution. Numerical results are presented to demonstrate the superiority of CCF over the existing CF schemes.", "subjects": "Information Theory (cs.IT)", "authors": "Yihua Tan, Xiaojun Yuan,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05626", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05626", "title": "\nPhrase database Approach to structural and semantic disambiguation in  English-Korean Machine Translation", "abstract": "In machine translation it is common phenomenon that machine-readable dictionaries and standard parsing rules are not enough to ensure accuracy in parsing and translating English phrases into Korean language, which is revealed in misleading translation results due to consequent structural and semantic ambiguities. This paper aims to suggest a solution to structural and semantic ambiguities due to the idiomaticity and non-grammaticalness of phrases commonly used in English language by applying bilingual phrase database in English-Korean Machine Translation (EKMT). This paper firstly clarifies what the phrase unit in EKMT is based on the definition of the English phrase, secondly clarifies what kind of language unit can be the target of the phrase database for EKMT, thirdly suggests a way to build the phrase database by presenting the format of the phrase database with examples, and finally discusses briefly the method to apply this bilingual phrase database to the EKMT for structural and semantic disambiguation.", "subjects": "Computation and Language (cs.CL)", "authors": "Myong-Chol Pak,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05619", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05619", "title": "\n3-D Statistical Channel Model for Millimeter-Wave Outdoor Mobile  Broadband Communications", "abstract": "This paper presents an omnidirectional spatial and temporal 3-dimensional statistical channel model for 28 GHz dense urban non-line of sight environments. The channel model is developed from 28 GHz ultrawideband propagation measurements obtained with a 400 megachips per second broadband sliding correlator channel sounder and highly directional, steerable horn antennas in New York City. A 3GPP-like statistical channel model that is easy to implement in software or hardware is developed from measured power delay profiles and a synthesized method for providing absolute propagation delays recovered from 3-D ray-tracing, as well as measured angle of departure and angle of arrival power spectra. The extracted statistics are used to implement a MATLAB-based statistical simulator that generates 3-D millimeter-wave temporal and spatial channel coefficients that reproduce realistic impulse responses of measured urban channels. The methods and model presented here can be used for millimeter-wave system-wide simulations, and air interface design and capacity analyses.", "subjects": "Information Theory (cs.IT)", "authors": "Mathew K. Samimi, Theodore S. Rappaport,", "date": "2015-3-19"}, 
{"urllink": "http://arxiv.org/abs/1503.05615", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05615", "title": "\nLearning to Search for Dependencies", "abstract": "We create a transition-based dependency parser using a general purpose learning to search system. The result is a fast and accurate parser for many languages. Compared to other transition-based dependency parsing approaches, our parser provides similar statistical and computational performance with best-known approaches while avoiding various downsides including randomization, extra feature requirements, and custom learning algorithms. We show that it is possible to implement a dependency parser with an open-source learning to search library in about 300 lines of C++ code, while existing systems often requires several thousands of lines.", "subjects": "Computation and Language (cs.CL)", "authors": "Kai-Wei Chang, He He, Hal Daum\u00e9 III, John Langford,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05608", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05608", "title": "\nGreedy Algorithms make Efficient Mechanisms", "abstract": "We study mechanisms that use greedy allocation rules and pay-your-bid pricing to allocate resources subject to a matroid constraint. We show that all such mechanisms obtain a constant fraction of the optimal welfare at any equilibrium of bidder behavior, via a smoothness argument. This unifies numerous recent results on the price of anarchy of simple auctions. Our results extend to polymatroid and matching constraints, and we discuss extensions to more general matroid intersections.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Brendan Lucier, Vasilis Syrgkanis,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05571", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05571", "title": "\nGSNs : Generative Stochastic Networks", "abstract": "We introduce a novel training principle for probabilistic models that is an alternative to maximum likelihood. The proposed Generative Stochastic Networks (GSN) framework is based on learning the transition operator of a Markov chain whose stationary distribution estimates the data distribution. Because the transition distribution is a conditional distribution generally involving a small move, it has fewer dominant modes, being unimodal in the limit of small moves. Thus, it is easier to learn, more like learning to perform supervised function approximation, with gradients that can be obtained by back-propagation. The theorems provided here generalize recent work on the probabilistic interpretation of denoising auto-encoders and provide an interesting justification for dependency networks and generalized pseudolikelihood (along with defining an appropriate joint distribution and sampling mechanism, even when the conditionals are not consistent). We study how GSNs can be used with missing inputs and can be used to sample subsets of variables given the rest. Successful experiments are conducted, validating these theoretical results, on two image datasets and with a particular architecture that mimics the Deep Boltzmann Machine Gibbs sampler but allows training to proceed with backprop, without the need for layerwise pretraining.", "subjects": "Learning (cs.LG)", "authors": "Guillaume Alain, Yoshua Bengio, Li Yao, Jason Yosinski, Eric Thibodeau-Laufer, Saizheng Zhang, Pascal Vincent,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05543", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05543", "title": "\nText Segmentation based on Semantic Word Embeddings", "abstract": "We explore the use of semantic word embeddings in text segmentation algorithms, including the C99 segmentation algorithm and new algorithms inspired by the distributed word vector representation. By developing a general framework for discussing a class of segmentation objectives, we study the effectiveness of greedy versus exact optimization approaches and suggest a new iterative refinement technique for improving the performance of greedy strategies. We compare our results to known benchmarks, using known metrics. We demonstrate state-of-the-art performance for an untrained method with our Content Vector Segmentation (CVS) on the Choi test set. Finally, we apply the segmentation procedure to an in-the-wild dataset consisting of text extracted from scholarly articles in the arXiv.org database.", "subjects": "Computation and Language (cs.CL)", "authors": "Alexander A Alemi, Paul Ginsparg,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05533", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05533", "title": "\nFundamental Analysis of a Developer Support Chat Log for Identifying  Process Improvement Opportunities", "abstract": "In this report analysis of a support chat log of a development team is shown. Developer support chat is used to provide internal support to other development teams. The report shows how a fundamental data analysis helped to identify gaps and action items to boost performance of a development team by reducing time spent on developer support chat and minimizing interrupts from other developer teams. The report also shows an example of how a root cause analysis can be supported by simple data analysis in finding process improvement opportunities.", "subjects": "Software Engineering (cs.SE)", "authors": "Z\u00e1dor D\u00e1niel Kelemen,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05530", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05530", "title": "\nExploration of the scalability of LocFaults", "abstract": "A model checker can produce a trace of counterexample, for an erroneous program, which is often long and difficult to understand. In general, the part about the loops is the largest among the instructions in this trace. This makes the location of errors in loops critical, to analyze errors in the overall program. In this paper, we explore the scalability capabilities of LocFaults, our error localization approach exploiting paths of CFG(Control Flow Graph) from a counterexample to calculate the MCDs (Minimal Correction Deviations), and MCSs (Minimal Correction Subsets) from each found MCD. We present the times of our approach on programs with While-loops unfolded b times, and a number of deviated conditions ranging from 0 to n. Our preliminary results show that the times of our approach, constraint-based and flow-driven, are better compared to BugAssist which is based on SAT and transforms the entire program to a Boolean formula, and further the information provided by LocFaults is more expressive for the user.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Mohammed Bekkouche,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05528", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05528", "title": "\nVideo Inpainting of Complex Scenes", "abstract": "We propose an automatic video inpainting algorithm which relies on the optimisation of a global, patch-based functional. Our algorithm is able to deal with a variety of challenging situations which naturally arise in video inpainting, such as the correct reconstruction of dynamic textures, multiple moving objects and moving background. Furthermore, we achieve this in an order of magnitude less execution time with respect to the state-of-the-art. We are also able to achieve good quality results on high definition videos. Finally, we provide specific algorithmic details to make implementation of our algorithm as easy as possible. The resulting algorithm requires no segmentation or manual input other than the definition of the inpainting mask, and can deal with a wider variety of situations than is handled by previous work. 1. Introduction. Advanced image and video editing techniques are increasingly common in the image processing and computer vision world, and are also starting to be used in media entertainment. One common and difficult task closely linked to the world of video editing is image and video \"inpainting\". Generally speaking, this is the task of replacing the content of an image or video with some other content which is visually pleasing. This subject has been extensively studied in the case of images, to such an extent that commercial image inpainting products destined for the general public are available, such as Photoshop's \"Content Aware fill\" [1]. However, while some impressive results have been obtained in the case of videos, the subject has been studied far less extensively than image inpainting. This relative lack of research can largely be attributed to high time complexity due to the added temporal dimension. Indeed, it has only very recently become possible to produce good quality inpainting results on high definition videos, and this only in a semi-automatic manner. Nevertheless, high-quality video inpainting has many important and useful applications such as film restoration, professional post-production in cinema and video editing for personal use. For this reason, we believe that an automatic, generic video inpainting algorithm would be extremely useful for both academic and professional communities.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Alasdair Newson, Andr\u00e9s Almansa, Matthieu Fradet, Yann Gousseau, Patrick P\u00e9rez,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05522", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05522", "title": "\nQuantifying national information interests using the activity of  Wikipedia editors", "abstract": "We live in a \"global village\" where electronic communication has eliminated the geographical barriers of information exchange. With global information exchange, the road is open to worldwide convergence of opinions and interests. However, it remains unknown to what extent interests actually have become global. To address how interests differ between countries, we analyze the information exchange in Wikipedia, the largest online collaborative encyclopedia. From the editing activity in Wikipedia, we extract the interest profiles of editors from different countries. Based on a statistical null model for interest profiles, we create a network of significant links between countries with similar interests. We show that countries are divided into 18 clusters with similar interest profiles in which language, geography, and historical background polarize the interests. Despite the opportunities of global communication, the results suggest that people nevertheless care about local information.", "subjects": "Computers and Society (cs.CY)", "authors": "Fariba Karimi, Ludvig Bohlin, Ann Samoilenko, Martin Rosvall, Andrea Lancichinetti,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05521", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05521", "title": "\nNonparametric Detection of Nonlinearly Mixed Pixels and Endmember  Estimation in Hyperspectral Images", "abstract": "Mixing phenomena in hyperspectral images depend on a variety of factors such as the resolution of observation devices, the properties of materials, and how these materials interact with incident light in the scene. Different parametric and nonparametric models have been considered to address hyperspectral unmixing problems. The simplest one is the linear mixing model. Nevertheless, it has been recognized that mixing phenomena can also be nonlinear. The corresponding nonlinear analysis techniques are necessarily more challenging and complex than those employed for linear unmixing. Within this context, it makes sense to detect the nonlinearly mixed pixels in an image prior to its analysis, and then employ the simplest possible unmixing technique to analyze each pixel. In this paper, we propose a technique for detecting nonlinearly mixed pixels. The detection approach is based on the comparison of the reconstruction errors using both a Gaussian process regression model and a linear regression model. The two errors are combined into a detection statistics for which a probability density function can be reasonably approximated. We also propose an iterative endmember extraction algorithm to be employed in combination with the detection algorithm. The proposed Detect-then-Unmix strategy, which consists of extracting endmembers, detecting nonlinearly mixed pixels and unmixing, is tested with synthetic and real images.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Tales Imbiriba, Jos\u00e9 Carlos Moreira Bermudez, C\u00e9dric Richard, Jean-Yves Tourneret,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05508", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05508", "title": "\nExploration of the scalability of LocFaults approach for error  localization with While-loops programs", "abstract": "A model checker can produce a trace of counterexample, for an erroneous program, which is often long and difficult to understand. In general, the part about the loops is the largest among the instructions in this trace. This makes the location of errors in loops critical, to analyze errors in the overall program. In this paper, we explore the scala-bility capabilities of LocFaults, our error localization approach exploiting paths of CFG(Control Flow Graph) from a counterexample to calculate the MCDs (Minimal Correction Deviations), and MCSs (Minimal Correction Subsets) from each found MCD. We present the times of our approach on programs with While-loops unfolded b times, and a number of deviated conditions ranging from 0 to n. Our preliminary results show that the times of our approach, constraint-based and flow-driven, are better compared to BugAssist which is based on SAT and transforms the entire program to a Boolean formula, and further the information provided by LocFaults is more expressive for the user.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Mohammed Bekkouche,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05502", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05502", "title": "\nUrban Magnetism Through The Lens of Geo-tagged Photography", "abstract": "There is an increasing trend of people leaving digital traces through social media. This reality opens new horizons for urban studies. With this kind of data, researchers and urban planners can detect many aspects of how people live in cities and can also suggest how to transform cities into more efficient and smarter places to live in. In particular, their digital trails can be used to investigate tastes of individuals, and what attracts them to live in a particular city or to spend their vacation there. In this paper we propose an unconventional way to study how people experience the city, using information from geotagged photographs that people take at different locations. We compare the spatial behavior of residents and tourists in 10 most photographed cities all around the world. The study was conducted on both a global and local level. On the global scale we analyze the 10 most photographed cities and measure how attractive each city is for people visiting it from other cities within the same country or from abroad. For the purpose of our analysis we construct the users mobility network and measure the strength of the links between each pair of cities as a level of attraction of people living in one city (i.e., origin) to the other city (i.e., destination). On the local level we study the spatial distribution of user activity and identify the photographed hotspots inside each city. The proposed methodology and the results of our study are a low cost mean to characterize a touristic activity within a certain location and can help in urban organization to strengthen their touristic potential.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Silvia Paldino, Iva Bojic, Stanislav Sobolevsky, Carlo Ratti, Marta C. Gonz\u00e1lez,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05501", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05501", "title": "\nProbabilistic Argumentation. An Equational Approach", "abstract": "There is a generic way to add any new feature to a system. It involves 1) identifying the basic units which build up the system and 2) introducing the new feature to each of these basic units. In the case where the system is argumentation and the feature is probabilistic we have the following. The basic units are: a. the nature of the arguments involved; b. the membership relation in the set S of arguments; c. the attack relation; and d. the choice of extensions. Generically to add a new aspect (probabilistic, or fuzzy, or temporal, etc) to an argumentation network &lt;S,R&gt; can be done by adding this feature to each component a-d. This is a brute-force method and may yield a non-intuitive or meaningful result. A better way is to meaningfully translate the object system into another target system which does have the aspect required and then let the target system endow the aspect on the initial system. In our case we translate argumentation into classical propositional logic and get probabilistic argumentation from the translation. Of course what we get depends on how we translate. In fact, in this paper we introduce probabilistic semantics to abstract argumentation theory based on the equational approach to argumentation networks. We then compare our semantics with existing proposals in the literature including the approaches by M. Thimm and by A. Hunter. Our methodology in general is discussed in the conclusion.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "D. M. Gabbay, O. Rodrigues,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05496", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05496", "title": "\nIMP with exceptions over decorated logic", "abstract": "In this paper, we separately design the decorated logic with respect to the state and the exception effects. Then, we combine two logics to be able to establish small-step semantics of IMP imperative language with exceptional abilities, in a decorated setting. We implement the decorated framework in Coq and certify program equivalence proofs written in that context.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Burak Ekici,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05493", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05493", "title": "\nTestability Measurement Model for Object Oriented Design (TMMOOD)", "abstract": "Measuring testability early in the development life cycle especially at design phase is a criterion of crucial importance to software designers, developers, quality controllers and practitioners. However, most of the mechanism available for testability measurement may be used in the later phases of development life cycle. Early estimation of testability, absolutely at design phase helps designers to improve their designs before the coding starts. Practitioners regularly advocate that testability should be planned early in design phase. Testability measurement early in design phase is greatly emphasized in this study; hence, considered significant for the delivery of quality software. As a result, it extensively reduces rework during and after implementation, as well as facilitate for design effective test plans, better project and resource planning in a practical manner, with a focus on the design phase. An effort has been put forth in this paper to recognize the key factors contributing in testability measurement at design phase. Additionally, testability measurement model is developed to quantify software testability at design phase. Furthermore, the relationship of Testability with these factors has been tested and justified with the help of statistical measures. The developed model has been validated using experimental tryout. Finally, it incorporates the empirical validation of the testability measurement model as the authors most important contribution.", "subjects": "Software Engineering (cs.SE)", "authors": "M.H. Khan Abdullah, Reena Srivastava,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05479", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05479", "title": "\nInterpolating Convex and Non-Convex Tensor Decompositions via the  Subspace Norm", "abstract": "We consider the problem of recovering a low-rank tensor from a noisy observation. Previous work has shown recovery guarantee for recovering a th order rank one tensor of size by an algorithm called recursive unfolding. In this paper, we first improve this to by a much simpler approach but with a more careful analysis. Then we propose a new norm based on the Kronecker products of factors obtained by the proposed simple estimator. The imposed Kronecker structure of the new norm allows us to show a nearly ideal bound for the proposed subspace norm, in which the parameter controls the blend from the non-convex estimator to mode-wise nuclear norm minimization. Furthermore we empirically demonstrate that with , the proposed norm achieves near ideal denoising performance.", "subjects": "Learning (cs.LG)", "authors": "Qinqing Zheng, Ryota Tomioka,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05477", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05477", "title": "\nReplacing the Soft FEC Limit Paradigm in the Design of Optical  Communication Systems", "abstract": "The FEC limit paradigm is the prevalent practice for designing optical communication systems to attain a certain bit-error rate (BER) without forward error correction (FEC). This practice assumes that there is an FEC code that will reduce the BER after decoding to the desired level. In this paper, we challenge this practice and show that the concept of a channel-independent FEC limit is invalid for soft-decision bit-wise decoding. It is shown that for low code rates and high order modulation formats, the use of the soft FEC limit paradigm can underestimate the spectral efficiencies by up to 20%. A better predictor for the BER after decoding is the generalized mutual information, which is shown to give consistent post-FEC BER predictions across different channel conditions and modulation formats. Extensive optical full-field simulations and experiments are carried out in both the linear and nonlinear transmission regimes to confirm the theoretical analysis.", "subjects": "Information Theory (cs.IT)", "authors": "Alex Alvarado, Erik Agrell, Domanic Lavery, Robert Maher, Polina Bayvel,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05471", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05471", "title": "\nShared latent subspace modelling within Gaussian-Binary Restricted  Boltzmann Machines for NIST i-Vector Challenge 2014", "abstract": "This paper presents a novel approach to speaker subspace modelling based on Gaussian-Binary Restricted Boltzmann Machines (GRBM). The proposed model is based on the idea of shared factors as in the Probabilistic Linear Discriminant Analysis (PLDA). GRBM hidden layer is divided into speaker and channel factors, herein the speaker factor is shared over all vectors of the speaker. Then Maximum Likelihood Parameter Estimation (MLE) for proposed model is introduced. Various new scoring techniques for speaker verification using GRBM are proposed. The results for NIST i-vector Challenge 2014 dataset are presented.", "subjects": "Learning (cs.LG)", "authors": "Danila Doroshin, Alexander Yamshinin, Nikolay Lubimov, Marina Nastasenko, Mikhail Kotov, Maxim Tkachenko,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05464", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05464", "title": "\nA distributed-memory package for dense Hierarchically Semi-Separable  matrix computations using randomization", "abstract": "We present a distributed-memory library for computations with dense structured matrices. A matrix is considered structured if its off-diagonal blocks can be approximated by a rank-deficient matrix with low numerical rank. Here, we use Hierarchically Semi-Separable representations (HSS). Such matrices appear in many applications, e.g., finite element methods, boundary element methods, etc. Exploiting this structure allows for fast solution of linear systems and/or fast computation of matrix-vector products, which are the two main building blocks of matrix computations. The compression algorithm that we use, that computes the HSS form of an input dense matrix, relies on randomized sampling with a novel adaptive sampling mechanism. We discuss the parallelization of this algorithm and also present the parallelization of structured matrix-vector product, structured factorization and solution routines. The efficiency of the approach is demonstrated on large problems from different academic and industrial applications, on up to 8,000 cores. This work is part of a more global effort, the STRUMPACK (STRUctured Matrices PACKage) software package for computations with sparse and dense structured matrices. Hence, although useful on their own right, the routines also represent a step in the direction of a distributed-memory sparse solver.", "subjects": "Mathematical Software (cs.MS)", "authors": "Fran\u00e7ois-Henry Rouet, Xiaoye S. Li, Pieter Ghysels, Artem Napov,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05458", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05458", "title": "\nDeception by Design: Evidence-Based Signaling Games for Network Defense", "abstract": "Deception plays a critical role in the financial industry, online markets, national defense, and countless other important areas. Understanding and harnessing deception, especially in cyberspace, is both crucial and difficult. Recent efforts have studied deception through the lens of game theory, which enables studying the roles of incentives and rationality, and making verifiable predictions. In this paper, we go beyond equilibrium analysis and use a mechanism design perspective in order to engineer solutions to realistic problems. Specifically, we study how the use of honeypots for network defense changes when adversaries gain the ability to detect evidence of honeypots. We analyze two game models: cheap-talk games and an augmented version of those games which we call cheap-talk games with evidence. Using those models, we show how network defenders can design exogenous factors such as the number of honeypots in a system and the cost at which compromised network computers in order to respond to the advent of honeypot-detecting technology and continue to achieve desired levels of utility. Our first contribution is the model that we develop for evidence-based signaling games, and the analysis of how this model includes models of traditional signaling games and complete information games as special cases. The other contributions include a numerical demonstration showing that deception detection causes pure-strategy equilibria to fail to be supported under certain conditions, and a surprising result that the development by the receiver of the ability to detect deception could actually increase the utility of a possibly-deceptive sender. These results have concrete implications for network defense through honeypot deployment. But they are also general enough to apply to the large and critical body of strategic interactions that involve deception.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Jeffrey Pawlick, Quanyan Zhu,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.05456", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05456", "title": "\nMinimum distance of Symplectic Grassmann codes", "abstract": "We introduce the Symplectic Grassmann codes as projective codes defined by symplectic Grassmannians, in analogy with the orthogonal Grassmann codes introduced in [4]. Note that the Lagrangian-Grassmannian codes are a special class of Symplectic Grassmann codes. We describe the weight enumerator of the Lagrangian--Grassmannian codes of rank and and we determine the minimum distance of the line Symplectic Grassmann codes.", "subjects": "Information Theory (cs.IT)", "authors": "Ilaria Cardinali, Luca Giuzzi,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05451", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05451", "title": "\nAutonomy Infused Teleoperation with Application to BCI Manipulation", "abstract": "Robot teleoperation systems introduce a unique set of challenges including latency, intermittency, and asymmetry in control inputs. User control with Brain-Computer Interfaces (BCIs) exacerbates these problems through especially noisy and even erratic low-dimensional motion commands due to the difficulty in decoding neural activity. We introduce a general framework to address these challenges through a combination of Machine Vision, User Intent Inference, and Human-Robot Autonomy Control Arbitration. Adjustable levels of assistance allow the system to balance the operator's capabilities and feelings of comfort and control while compensating for a task's difficulty. We present experimental results demonstrating significant performance improvement using the shared-control assistance framework on adapted rehabilitation benchmarks with two subjects implanted with intracortical brain-computer interfaces controlling a high degree-of-freedom robotic manipulator as a prosthetic. Our results further indicate shared assistance mitigates perceived user difficulty and even enables successful performance on previously infeasible tasks. We showcase the extensibility of our architecture with applications to quality-of-life tasks such as opening a door with a BCI, pouring liquids from a container with a dual-joystick game controller, and manipulation in dense clutter with a 6-DoF motion controller.", "subjects": "Robotics (cs.RO)", "authors": "Katharina Muelling, Arun Venkatraman, Jean-Sebastien Valois, John Downey, Jeffrey Weiss, Shervin Javdani, Martial Hebert, Andrew B. Schwartz, Jennifer L. Collinger, J. Andrew Bagnell,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05448", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05448", "title": "\nA Transfer Learning Approach for Cache-Enabled Wireless Networks", "abstract": "Locally caching contents at the network edge constitutes one of the most disruptive approaches in G wireless networks. Reaping the benefits of edge caching hinges on solving a myriad of challenges such as how, what and when to strategically cache contents subject to storage constraints, traffic load, unknown spatio-temporal traffic demands and data sparsity. Motivated by this, we propose a novel transfer learning-based caching procedure carried out at each small cell base station. This is done by exploiting the rich contextual information (i.e., users' content viewing history, social ties, etc.) extracted from device-to-device (D2D) interactions, referred to as source domain. This prior information is incorporated in the so-called target domain where the goal is to optimally cache strategic contents at the small cells as a function of storage, estimated content popularity, traffic load and backhaul capacity. It is shown that the proposed approach overcomes the notorious data sparsity and cold-start problems, yielding significant gains in terms of users' quality-of-experience (QoE) and backhaul offloading, with gains reaching up to in a setting consisting of four small cell base stations.", "subjects": "Information Theory (cs.IT)", "authors": "Ejder Ba\u015ftu\u011f, Mehdi Bennis, M\u00e9rouane Debbah,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05445", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05445", "title": "\nDanger Invariants", "abstract": "Static analysers search for overapproximating proofs of safety commonly known as safety invariants. Fundamentally, such analysers summarise traces into sets of states, thus trading the ability to distinguish traces for computational tractability. Conversely, static bug finders (e.g. Bounded Model Checking) give evidence for the failure of an assertion in the form of a counterexample, which can be inspected by the user. However, static bug finders fail to scale when analysing programs with bugs that require many iterations of a loop as the computational effort grows exponentially with the depth of the bug. We propose a novel approach for finding bugs, which delivers the performance of abstract interpretation together with the concrete precision of BMC. To do this, we introduce the concept of danger invariants -- the dual to safety invariants. Danger invariants summarise sets of traces that are guaranteed to reach an error state. This summarisation allows us to find deep bugs without false alarms and without explicitly unwinding loops. We present a second-order formulation of danger invariants and use the Second-Order SAT solver described in previous work to compute danger invariants for intricate programs taken from the literature.", "subjects": "Programming Languages (cs.PL)", "authors": "Cristina David, Daniel Kroening, Matt Lewis,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05443", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05443", "title": "\nCan we track the geography of surnames based on bibliographic data?", "abstract": "In this paper we explore the possibility of using bibliographic databases for tracking the geographic origin of surnames. Surnames are used as a proxy to determine the ethnic, genetic or geographic origin of individuals in many fields such as Genetics or Demography; however they could also be used for bibliometric purposes such as the analysis of scientific migration flows. Here we present two relevant methodologies for determining the most probable country to which a surname could be assigned. The first methodology assigns surnames based on the most common country that can be assigned to a surname and the Kullback-Liebler divergence measure. The second method uses the Gini Index to evaluate the assignment of surnames to countries. We test both methodologies with control groups and conclude that, despite needing further analysis on its validity; these methodologies already show promising results.", "subjects": "Digital Libraries (cs.DL)", "authors": "Nicolas Robinson-Garcia, Ed Noyons, Rodrigo Costas,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.05434", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05434", "title": "\nCompressed Differential Erasure Codes for Efficient Archival of  Versioned Data", "abstract": "In this paper, we study the problem of storing an archive of versioned data in a reliable and efficient manner in distributed storage systems. We propose a new storage technique called differential erasure coding (DEC) where the differences (deltas) between subsequent versions are stored rather than the whole objects, akin to a typical delta encoding technique. However, unlike delta encoding techniques, DEC opportunistically exploits the sparsity (i.e., when the differences between two successive versions have few non-zero entries) in the updates to store the deltas using compressed sensing techniques applied with erasure coding. We first show that DEC provides significant savings in the storage size for versioned data whenever the update patterns are characterized by in-place alterations. Subsequently, we propose a practical DEC framework so as to reap storage size benefits against not just in-place alterations but also real-world update patterns such as insertions and deletions that alter the overall data sizes. We conduct experiments with several synthetic workloads to demonstrate that the practical variant of DEC provides significant reductions in storage overhead (up to 60 % depending on the workload) compared to baseline storage system which incorporates concepts from Rsync, a delta encoding technique to store and synchronize data across a network.", "subjects": "Information Theory (cs.IT)", "authors": "J. Harshan, Anwitaman Datta, Fr\u00e9d\u00e9rique Oggier,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05432", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05432", "title": "\nDiscrete Signal Processing on Graphs: Sampling Theory", "abstract": "We propose a sampling theory for signals that are supported on either directed or undirected graphs. The theory follows the same paradigm as classical sampling theory. We show that the perfect recovery is possible for graph signals bandlimited under the graph Fourier transform, and the sampled signal coefficients form a new graph signal, whose corresponding graph structure is constructed from the original graph structure, preserving frequency contents. By imposing a specific structure on the graph, graph signals reduce to finite discrete-time signals and the proposed sampling theory works reduces to classical signal processing. We further establish the connection to frames with maximal robustness to erasures as well as compressed sensing, and show how to choose the optimal sampling operator, how random sampling works on circulant graphs and Erd Hs-R 'enyi graphs, and how to handle full-band graph signals by using graph filter banks. We validate the proposed sampling theory on the simulated datasets of Erd Hs-R 'enyi graphs and small-world graphs, and a real-world dataset of online blogs. We show that for each case, the proposed sampling theory achieves perfect recovery with high probability. Finally, we apply the proposed sampling theory to semi-supervised classification of online blogs and digit images, where we achieve similar or better performance with fewer labeled samples compared to the previous work.", "subjects": "Information Theory (cs.IT)", "authors": "Siheng Chen, Rohan Varma, Aliaksei Sandryhaila, Jelena Kova\u010devi\u0107,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.05430", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05430", "title": "\nWhat Properties are Desirable from an Electron Microscopy Segmentation  Algorithm", "abstract": "This study proposes a novel efficient training method for predictors required for segmentation in semi-automated neural reconstruction. The proposed method was designed to achieve some of the properties desired from an Electron Microscopy (EM) segmentation algorithm. Instead of using an exhaustive pixel level groundtruth, an active semi-supervised algorithm is developed for efficient labeling of pixel and superpixel boundaries for accurate segmentation. As an attempt to minimize human effort necessary for segmentation error correction, the proposed algorithm is designed to prioritize minimization of false-merges over false-split errors. The results on both 2D and 3D segmentation problems suggest the proposed method can achieve comparable or better results than the current state of the art techniques.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Toufiq Parag,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05426", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05426", "title": "\nYouLighter: An Unsupervised Methodology to Unveil YouTube CDN Changes", "abstract": "YouTube relies on a massively distributed Content Delivery Network (CDN) to stream the billions of videos in its catalogue. Unfortunately, very little information about the design of such CDN is available. This, combined with the pervasiveness of YouTube, poses a big challenge for Internet Service Providers (ISPs), which are compelled to optimize end-users' Quality of Experience (QoE) while having no control on the CDN decisions. This paper presents YouLighter, an unsupervised technique to identify changes in the YouTube CDN. YouLighter leverages only passive measurements to cluster co-located identical caches into edge-nodes. This automatically unveils the structure of YouTube's CDN. Further, we propose a new metric, called Constellation Distance, that compares the clustering obtained from two different time snapshots, to pinpoint sudden changes. While several approaches allow comparison between the clustering results from the same dataset, no technique allows to measure the similarity of clusters from different datasets. Hence, we develop a novel methodology, based on the Constellation Distance, to solve this problem. By running YouLighter over 10-month long traces obtained from two ISPs in different countries, we pinpoint both sudden changes in edge-node allocation, and small alterations to the cache allocation policies which actually impair the QoE that the end-users perceive.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Danilo Giordano, Stefano Traverso, Luigi Grimaudo, Marco Mellia, Elena Baralis, Alok Tongaonkar, Sabyasachi Saha,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05423", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05423", "title": "\nRank logic is dead, long live rank logic!", "abstract": "Motivated by the search for a logic for polynomial time, we study rank logic (FPR) which extends fixed-point logic with counting (FPC) by operators that determine the rank of matrices over finite fields. While FPR can express most of the known queries that separate FPC from PTIME, nearly nothing was known about the limitations of its expressive power. In our first main result we show that the extensions of FPC by rank operators over different prime fields are incomparable. This solves an open question posed by Dawar and Holm and also implies that rank logic, in its original definition with a distinct rank operator for every field, fails to capture polynomial time. In particular we show that the variant of rank logic FPR* with an operator that uniformly expresses the matrix rank over finite fields is more expressive than FPR. One important step in our proof is to consider solvability logic FPS which is the analogous extension of FPC by quantifiers which express the solvability problem for linear equation systems over finite fields. Solvability logic can easily be embedded into rank logic, but it is open whether it is a strict fragment. In our second main result we give a partial answer to this question: in the absence of counting, rank operators are strictly more expressive than solvability quantifiers.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Erich Gr\u00e4del, Wied Pakusa,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05414", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05414", "title": "\nDoes \"Like\" Really Mean Like? A Study of the Facebook Fake Like  Phenomenon and an Efficient Countermeasure", "abstract": "Social networks help to bond people who share similar interests all over the world. As a complement, the Facebook \"Like\" button is an efficient tool that bonds people with the online information. People click on the \"Like\" button to express their fondness of a particular piece of information and in turn tend to visit webpages with high \"Like\" count. The important fact of the Like count is that it reflects the number of actual users who \"liked\" this information. However, according to our study, one can easily exploit the defects of the \"Like\" button to counterfeit a high \"Like\" count. We provide a proof-of-concept implementation of these exploits, and manage to generate 100 fake Likes in 5 minutes with a single account. We also reveal existing counterfeiting techniques used by some online sellers to achieve unfair advantage for promoting their products. To address this fake Like problem, we study the varying patterns of Like count and propose an innovative fake Like detection method based on clustering. To evaluate the effectiveness of our algorithm, we collect the Like count history of more than 9,000 websites. Our experiments successfully uncover 16 suspicious fake Like buyers that show abnormal Like count increase patterns.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Xinye Lin, Mingyuan Xia, Xue Liu,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.05377", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05377", "title": "\nDownlink Coverage Probability in a Cellular Network with Ginibre  Deployed Base Stations and Nakagami-m Fading Channels", "abstract": "Recently, spatial stochastic models based on determinantal point processes (DPP) are studied as promising models for analysis of cellular wireless networks. Indeed, the DPPs can express the repulsive nature of the macro base station (BS) configuration observed in a real cellular network and have many desirable mathematical properties to analyze the network performance. However, almost all the prior works on the DPP based models assume the Rayleigh fading while the spatial models based on Poisson point processes have been developed to allow arbitrary distributions of fading/shadowing propagation effects. In order for the DPP based model to be more promising, it is essential to extend it to allow non-Rayleigh propagation effects. In the present paper, we propose the downlink cellular network model where the BSs are deployed according to the Ginibre point process, which is one of the main examples of the DPPs, over Nakagami-m fading. For the proposed model, we derive a numerically computable form of the coverage probability and reveal some properties of it numerically and theoretically.", "subjects": "Information Theory (cs.IT)", "authors": "Naoto Miyoshi, Tomoyuki Shirai,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05367", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05367", "title": "\nThe Application of MIMO to Non-Orthogonal Multiple Access", "abstract": "This paper considers the application of multiple-input multiple-output (MIMO) techniques to non-orthogonal multiple access (NOMA) systems. A new design of precoding and detection matrices for MIMO-NOMA is proposed and its performance is analyzed for the case with a fixed set of power allocation coefficients. To further improve the performance gap between MIMO-NOMA and conventional orthogonal multiple access schemes, user pairing is applied to NOMA and its impact on the system performance is characterized. More sophisticated choices of power allocation coefficients are also proposed to meet various quality of service requirements. Finally computer simulation results are provided to facilitate the performance evaluation of MIMO-NOMA and also demonstrate the accuracy of the developed analytical results.", "subjects": "Information Theory (cs.IT)", "authors": "Zhiguo Ding, Fumiyuki Adachi, H. Vincent Poor,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05366", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05366", "title": "\nProject portfolio selection: Multi-criteria analysis and interactions  between projects", "abstract": "In the project portfolio management, the project selection phase presents the greatest interest. In this article, we focus on this important phase by proposing a new method of projects selection consisting of several steps. We propose as a first step, a classification of projects based on the three most important criteria namely the value maximization, risk minimization and strategic alignment. The second step is building alternatives portfolio by the portfolio managers taking into account the classification of projects already completed in the first step. The third and final step enables the identification of the alternative portfolio to consider the contribution of projects to achieve the organization objectives as well as interactions between projects.", "subjects": "Software Engineering (cs.SE)", "authors": "Khadija BENAIJA, Laila KJIRI,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05365", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05365", "title": "\nCaching at the Edge: a Green Perspective for 5G Networks", "abstract": "Endowed with context-awareness and proactive capabilities, caching users' content locally at the edge of the network is able to cope with increasing data traffic demand in 5G wireless networks. In this work, we focus on the energy consumption aspects of cache-enabled wireless cellular networks, specifically in terms of area power consumption (APC) and energy efficiency (EE). We assume that both base stations (BSs) and mobile users are distributed according to homogeneous Poisson point processes (PPPs) and we introduce a detailed power model that takes into account caching. We study the conditions under which the area power consumption is minimized with respect to BS transmit power, while ensuring a certain quality of service (QoS) in terms of coverage probability. Furthermore, we provide the optimal BS transmit power that maximizes the area spectral efficiency per unit total power spent. The main takeaway of this paper is that caching seems to be an energy efficient solution.", "subjects": "Information Theory (cs.IT)", "authors": "Bhanukiran Perabathini, Ejder Ba\u015ftu\u011f, Marios Kountouris, M\u00e9rouane Debbah, Alberto Conte,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05358", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05358", "title": "\nA Volume Correlation Subspace Detector for signals buried in unknown  clutter", "abstract": "Detecting the presence of target subspace signals with unknown clutters is a well-known hard problem encountered in various signal processing applications. Traditional methods fails to solve this problem because prior knowledge of clutter subspace is required, which can not be obtained when target and clutter are intimately mixed. In this paper, we propose a novel subspace detector that can detect target signal buried in clutter without knowledge of clutter subspace. This detector makes use of the geometrical relation between target and clutter subspaces and is derived based upon the calculation of volume of high dimensional geometrical objects. Moreover, the proposed detector can accomplish the detection simultaneously with the learning processes of clutter, a property called \"detecting while learning\". The performance of detector was showed by theoretical analysis and numerical simulation.", "subjects": "Information Theory (cs.IT)", "authors": "Hailong Shi, Hao Zhang, Xiqin Wang,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05352", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05352", "title": "\nBarrier Coverage in Mobile Camera Sensor Networks with Grid-Based  Deployment", "abstract": "Barrier coverage is a critical issue in wireless sensor networks for many practical applications,e.g., national border monitoring, security surveillance and intruder detection, etc. Its aim is to detect intruders that attempt to cross the protected region. In this paper, we study how to efficiently improve barrier coverage using mobile camera sensors, where camera sensors are deployed by a grid-based strategy.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Xiao-Lan Liu, Bin Yang, Gui-Lin Chen,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05338", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05338", "title": "\nTimeTrader: Exploiting Latency Tail to Save Datacenter Energy for  On-line Data-Intensive Applications", "abstract": "Datacenters running on-line, data-intensive applications (OLDIs) consume significant amounts of energy. However, reducing their energy is challenging due to their tight response time requirements. A key aspect of OLDIs is that each user query goes to all or many of the nodes in the cluster, so that the overall time budget is dictated by the tail of the replies' latency distribution; replies see latency variations both in the network and compute. Previous work proposes to achieve load-proportional energy by slowing down the computation at lower datacenter loads based directly on response times (i.e., at lower loads, the proposal exploits the average slack in the time budget provisioned for the peak load). In contrast, we propose TimeTrader to reduce energy by exploiting the latency slack in the sub- critical replies which arrive before the deadline (e.g., 80% of replies are 3-4x faster than the tail). This slack is present at all loads and subsumes the previous work's load-related slack. While the previous work shifts the leaves' response time distribution to consume the slack at lower loads, TimeTrader reshapes the distribution at all loads by slowing down individual sub-critical nodes without increasing missed deadlines. TimeTrader exploits slack in both the network and compute budgets. Further, TimeTrader leverages Earliest Deadline First scheduling to largely decouple critical requests from the queuing delays of sub- critical requests which can then be slowed down without hurting critical requests. A combination of real-system measurements and at-scale simulations shows that without adding to missed deadlines, TimeTrader saves 15-19% and 41-49% energy at 90% and 30% loading, respectively, in a datacenter with 512 nodes, whereas previous work saves 0% and 31-37%.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Balajee Vamanan, Hamza Bin Sohail, Jahangir Hasan, T. N. Vijaykumar,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05317", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05317", "title": "\nModel Checking AORTA: Verification of Organization-Aware Agents", "abstract": "As agent systems grow larger and more complex, there is an increasing need to formally verify them. Furthermore, it is often suggested that complex systems can be regulated using organizational models, imposing constraints on the agents in the systems. Agents that can understand the organizational model and constraints in a system is said to be organization-aware. This paper is concerned with verification of organization-aware agents. We show how agents using AORTA, a framework for making agents organization-aware, can be formally verified using an extended version of the Agent Java PathFinder (AJPF), a model checking system designed specifically for agent programming languages. We integrate AORTA with the Agent Infrastructure Layer (AIL), which is an intermediate layer on top of which APLs can be implemented, and use our extension of AJPF to verify a system of agents aiming to write a paper together by using an organization for coordination.", "subjects": "Multiagent Systems (cs.MA)", "authors": "Andreas Schmidt Jensen,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05314", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05314", "title": "\nOn the Performance of Turbo Signal Recovery with Partial DFT Sensing  Matrices", "abstract": "This letter is on the performance of the turbo signal recovery (TSR) algorithm for partial discrete Fourier transform (DFT) matrices based compressed sensing. Based on state evolution analysis, we prove that TSR with a partial DFT sensing matrix outperforms the well-known approximate message passing (AMP) algorithm with an independent identically distributed (IID) sensing matrix.", "subjects": "Information Theory (cs.IT)", "authors": "Junjie Ma, Xiaojun Yuan, Li Ping,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05299", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05299", "title": "\nDiscrete Signal Reconstruction by Sum of Absolute Values", "abstract": "In this letter, we consider a problem of reconstructing an unknown discrete signal taking values in a finite alphabet from incomplete linear measurements. The difficulty of this problem is that the computational complexity of the reconstruction is exponential as it is. To overcome this difficulty, we extend the idea of compressed sensing, and propose to solve the problem by minimizing the sum of weighted absolute values. We assume that the probability distribution defined on an alphabet is known, and formulate the reconstruction problem as linear programming. Examples are shown to illustrate that the proposed method is effective.", "subjects": "Information Theory (cs.IT)", "authors": "Masaaki Nagahara,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05298", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05298", "title": "\nDistributed on-line multidimensional scaling for self-localization in  wireless sensor networks", "abstract": "The present work considers the localization problem in wireless sensor networks formed by fixed nodes. Each node seeks to estimate its own position based on noisy measurements of the relative distance to other nodes. In a centralized batch mode, positions can be retrieved (up to a rigid transformation) by applying Principal Component Analysis (PCA) on a so-called similarity matrix built from the relative distances. In this paper, we propose a distributed on-line algorithm allowing each node to estimate its own position based on limited exchange of information in the network. Our framework encompasses the case of sporadic measurements and random link failures. We prove the consistency of our algorithm in the case of fixed sensors. Finally, we provide numerical and experimental results from both simulated and real data. Simulations issued to real data are conducted on a wireless sensor network testbed.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Gemma Morral, Pascal Bianchi,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05297", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05297", "title": "\nThe AWGN BC with MAC Feedback: A Reduction to Noiseless Feedback via  Interaction", "abstract": "We consider the problem of communication over a two-user Additive White Gaussian Noise Broadcast Channel (AWGN-BC) with an AWGN Multiple Access (MAC) active feedback. We describe a constructive reduction from this setup to the well-studied setup of linear-feedback coding over the AWGN-BC with noiseless feedback (and different parameters). This reduction facilitates the design of linear-feedback coding schemes in the (passive) noiseless feedback regime, which can then be easily and constructively transformed into coding schemes in the MAC feedback regime that attain the exact same rates. Our construction introduces an element of interaction into the coding protocol, and is based on modulo-lattice operations. As an example, we apply our method to the Ozarow-Leung scheme, and demonstrate how MAC feedback can be used to increase the capacity region of the AWGN-BC.", "subjects": "Information Theory (cs.IT)", "authors": "Assaf Ben-Yishai, Ofer Shayevitz,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05296", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05296", "title": "\nEfficient Machine Learning for Big Data: A Review", "abstract": "With the emerging technologies and all associated devices, it is predicted that massive amount of data will be created in the next few years, in fact, as much as 90% of current data were created in the last couple of years,a trend that will continue for the foreseeable future. Sustainable computing studies the process by which computer engineer/scientist designs computers and associated subsystems efficiently and effectively with minimal impact on the environment. However, current intelligent machine-learning systems are performance driven, the focus is on the predictive/classification accuracy, based on known properties learned from the training samples. For instance, most machine-learning-based nonparametric models are known to require high computational cost in order to find the global optima. With the learning task in a large dataset, the number of hidden nodes within the network will therefore increase significantly, which eventually leads to an exponential rise in computational complexity. This paper thus reviews the theoretical and experimental data-modeling literature, in large-scale data-intensive fields, relating to: (1) model efficiency, including computational requirements in learning, and data-intensive areas structure and design, and introduces (2) new algorithmic approaches with the least memory requirements and processing to minimize computational cost, while maintaining/improving its predictive/classification accuracy and stability.", "subjects": "Learning (cs.LG)", "authors": "O. Y. Al-Jarrah, P. D. Yoo, S Muhaidat, G. K. Karagiannidis, K. Taha,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05294", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05294", "title": "\nEasy and Fast Design and Implementation of PostgreSQL based image  handling application", "abstract": "In modern computing, RDBMS are great to store different types of data. To a developer, one of the major objectives is to provide a very low cost and easy to use solution to an existing problem. While commercial databases are more easy to use along with their new as well as documented features come with complicated licensing cost, free open source databases are not that straightforward under many situations. This paper shows how a completely free advanced open source RDBMS like PostgreSQL could be designed and modified to store and retrieve high quality images in order to use them along with a frontend application.", "subjects": "Databases (cs.DB)", "authors": "Kisor Ray, Sourav Bag, Saumen Sarkar,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05287", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05287", "title": "\nAdjusted Haar Wavelet for Application in the Power Systems Disturbance  Analysis", "abstract": "Abrupt change detection based on the wavelet transform and threshold method is very effective in detecting the abrupt changes and hence segmenting the signals recorded during disturbances in the electrical power network. The wavelet method estimates the time-instants of the changes in the signal model parameters during the pre-fault condition, after initiation of fault, after circuit-breaker opening and auto-reclosure. Certain kinds of disturbance signals do not show distinct abrupt changes in the signal parameters. In those cases, the standard mother wavelets fail to achieve correct event-specific segmentations. A new adjustment technique to the standard Haar wavelet is proposed in this paper, by introducing 2n adjusting zeros in the Haar wavelet scaling filter, n being a positive integer. This technique is quite effective in segmenting those fault signals into pre- and post-fault segments, and it is an improvement over the standard mother wavelets for this application. This paper presents many practical examples where recorded signals from the power network in South Africa have been used.", "subjects": "Other Computer Science (cs.OH)", "authors": "A. Ukil, R. Zivanovic,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05280", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05280", "title": "\nNFV Based Gateways for Virtualized Wireless Sensors Networks: A Case  Study", "abstract": "Virtualization enables the sharing of a same wireless sensor network (WSN) by multiple applications. However, in heterogeneous environments, virtualized wireless sensor networks (VWSN) raises new challenges such as the need for on-the-fly, dynamic, elastic and scalable provisioning of gateways. Network Functions Virtualization (NFV) is an emerging paradigm that can certainly aid in tackling these new challenges. It leverages standard virtualization technology to consolidate special-purpose network elements on top of commodity hardware. This article presents a case study on NFV based gateways for VWSNs. In the study, a VWSN gateway provider, operates and manages an NFV based infrastructure. We use two different brands of wireless sensors. The NFV infrastructure makes possible the dynamic, elastic and scalable deployment of gateway modules in this heterogeneous VWSN environment. The prototype built with Openstack as platform is described.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Carla Mouradian, Tonmoy Saha, Jagruti Sahoo, Roch Glitho, Monique Morrow, Paul Polakos,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05276", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05276", "title": "\nDesign and Implementation of a GUI based Offline GIFT Tool to exchange  data between different systems", "abstract": "Multiple Choice Questions or MCQs are very important for e-learning. Many MCQ Tools allow us to generate MCQs very easily. However, in most of the cases they are not portable. That means MCQs generated for one system cannot be used for other unless a common format is used. So, collaboration and/or up gradation becomes a time consuming tedious task. In this paper, we will examine how tool could be designed which can produce portable MCQs and that too generating in the laptop and/or desktop without any need for going online.", "subjects": "Computers and Society (cs.CY)", "authors": "Kisor Ray, Partha Pratim deb,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05275", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05275", "title": "\nAbrupt Change Detection in Power System Fault Analysis using Adaptive  Whitening Filter and Wavelet Transform", "abstract": "This paper describes the application of the adaptive whitening filter and the wavelet transform used to detect the abrupt changes in the signals recorded during disturbances in the electrical power network in South Africa. Main focus has been to estimate exactly the time-instants of the changes in the signal model parameters during the pre-fault condition and following events like initiation of fault, circuit-breaker opening, auto-reclosure of the circuit-breakers. The key idea is to decompose the fault signals, de-noised using the adaptive whitening filter, into effective detailed and smoothed version using the multiresolution signal decomposition technique based on discrete wavelet transform. Then we apply the threshold method on the decomposed signals to estimate the change time-instants, segmenting the fault signals into the event-specific sections for further signal processing and analysis. This paper presents application on the recorded signals in the power transmission network of South Africa.", "subjects": "Computational Engineering, Finance, and Science (cs.CE)", "authors": "A. Ukil, R. Zivanovic,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05273", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05273", "title": "\nFeeder Load Balancing using Fuzzy Logic and Combinatorial  Optimization-based Implementation", "abstract": "The distribution system problems, such as planning, loss minimization, and energy restoration, usually involve the phase balancing or network reconfiguration procedures. The determination of an optimal phase balance is, in general, a combinatorial optimization problem. This paper proposes a novel reconfiguration of the phase balancing using the fuzzy logic and the combinatorial optimization-based implementation step back to back. Input to the fuzzy step is the total load per phase of the feeders. Output of the fuzzy step is the load change values, negative value for load releasing and positive value for load receiving. The output of the fuzzy step is the input to the load changing system. The load changing system uses combinatorial optimization techniques to translate the change values (kW) into number of load points and then selects the specific load points. It also performs the inter-changing of the load points between the releasing and the receiving phases in an optimal fashion. Application results using the distribution feeder network of South Africa are presented in this paper.", "subjects": "Other Computer Science (cs.OH)", "authors": "A. Ukil, W. Siti,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05272", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05272", "title": "\nImproved Calibration of Near-Infrared Spectra by Using Ensembles of  Neural Network Models", "abstract": "IR or near-infrared (NIR) spectroscopy is a method used to identify a compound or to analyze the composition of a material. Calibration of NIR spectra refers to the use of the spectra as multivariate descriptors to predict concentrations of the constituents. To build a calibration model, state-of-the-art software predominantly uses linear regression techniques. For nonlinear calibration problems, neural network-based models have proved to be an interesting alternative. In this paper, we propose a novel extension of the conventional neural network-based approach, the use of an ensemble of neural network models. The individual neural networks are obtained by resampling the available training data with bootstrapping or cross-validation techniques. The results obtained for a realistic calibration example show that the ensemble-based approach produces a significantly more accurate and robust calibration model than conventional regression methods.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "A. Ukil, J. Bernasconi, H. Braendle, H. Buijs, S. Bonenfant,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05271", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05271", "title": "\nAn SMDP-based Resource Management Scheme for Distributed Cloud Systems", "abstract": "In this paper, the resource management problem in geographically distributed cloud systems is considered. The Follow Me Cloud concept which enables service migration across federated data centers (DCs) is adopted. Therefore, there are two types of service requests to the DC, i.e., new requests (NRs) initiated in the local service area and migration requests (MRs) generated when mobile users move across service areas. A novel resource management scheme is proposed to help the resource manager decide whether to accept the service requests (NRs or MRs) or not and determine how much resources should be allocated to each service (if accepted). The optimization objective is to maximize the average system reward and keep the rejection probability of service requests under a certain threshold. Numerical results indicate that the proposed scheme can significantly improve the overall system utility as well as the user experience compared with other resource management schemes.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Jiadi Chen, Hang Long, Qiang Zheng, Minyao Xing, Wenbo Wang,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05269", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05269", "title": "\nCoverage in mmWave Cellular Networks with Base station Cooperation", "abstract": "The presence of signal outage, due to shadowing and blockage, is expected to be the main bottleneck in millimeter wave (mmWave) networks. Moreover, with the anticipated vision that mmWave networks would have a dense deployment of base stations, interference from strong line-of-sight base stations increases too, thus further increasing the probability of outage. To address the issue of reducing outage, this paper explores the possibility of base station cooperation in the downlink of a mmWave heterogenous network. The main focus of this work is showing that, in a stochastic geometry framework, cooperation from randomly located base stations decreases outage probability. With the presumed vision that less severe fading will be experienced due to highly directional transmissions, one might expect that cooperation would increase the coverage probability; our numerical examples suggest that is in fact the case. Coverage probabilities are derived accounting for: different fading distributions, antenna directionality and blockage. Numerical results suggest that coverage with base station cooperation in dense mmWave systems and with no small scale fading considerably exceeds coverage with no cooperation. In contrast, an insignificant increase is reported when mmWave networks are less dense with a high probability of signal blockage and with Rayleigh fading.", "subjects": "Information Theory (cs.IT)", "authors": "Diana Maamari, Natasha Devroye, Daniela Tuninetti,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05265", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05265", "title": "\nExploiting Directionality for Millimeter-Wave Wireless System  Improvement", "abstract": "This paper presents directional and omnidirectional RMS delay spread statistics obtained from 28 GHz and 73 GHz ultrawideband propagation measurements carried out in New York City using a 400 Megachips per second broadband sliding correlator channel sounder and highly directional steerable horn antennas. The 28 GHz measurements did not systematically seek the optimum antenna pointing angles and resulted in 33% outage for 39 T-R separation distances within 200 m. The 73 GHz measurements systematically found the best antenna pointing angles and resulted in 14.3% outage for 35 T-R separation distances within 200 m, all for mobile height receivers. Pointing the antennas to yield the strongest received power is shown to significantly reduce RMS delay spreads in line-of-sight (LOS) environments. A new term, distance extension exponent (DEE) is defined, and used to mathematically describe the increase in coverage distance that results by combining beams from angles with the strongest received power at a given location. These results suggest that employing directionality in millimeter-wave communications systems will reduce inter-symbol interference, improve link margin at cell edges, and enhance overall system performance.", "subjects": "Information Theory (cs.IT)", "authors": "George R. MacCartney Jr., Mathew K. Samimi, Theodore S. Rappaport,", "date": "2015-3-18"}, 
{"urllink": "http://arxiv.org/abs/1503.05241", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05241", "title": "\nOn the Matrix Inversion Approximation Based on Neumann Series in Massive  MIMO Systems", "abstract": "Zero-Forcing (ZF) has been considered as one of the potential practical precoding and detection method for massive MIMO systems. One of the most important advantages of massive MIMO is the capability of supporting a large number of users in the same time-frequency resource, which requires much larger dimensions of matrix inversion for ZF than conventional multi-user MIMO systems. In this case, Neumann Series (NS) has been considered for the Matrix Inversion Approximation (MIA), because of its suitability for massive MIMO systems and its advantages in hardware implementation. The performance-complexity trade-off and the hardware implementation of NS-based MIA in massive MIMO systems have been discussed. In this paper, we analyze the effects of the ratio of the number of massive MIMO antennas to the number of users on the performance of NS-based MIA. In addition, we derive the approximation error estimation formulas for different practical numbers of terms of NS-based MIA. These results could offer useful guidelines for practical massive MIMO systems.", "subjects": "Information Theory (cs.IT)", "authors": "Dengkui Zhu, Boyu Li, Ping Liang,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05225", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05225", "title": "\nSketching, Embedding, and Dimensionality Reduction for Information  Spaces", "abstract": "Information distances like the Hellinger distance and the Jensen-Shannon divergence have deep roots in information theory and machine learning. They are used extensively in data analysis especially when the objects being compared are high dimensional empirical probability distributions built from data. However, we lack common tools needed to actually use information distances in applications efficiently and at scale with any kind of provable guarantees. We can't sketch these distances easily, or embed them in better behaved spaces, or even reduce the dimensionality of the space while maintaining the probability structure of the data. In this paper, we build these tools for information distances---both for the Hellinger distance and Jensen--Shannon divergence, as well as related measures, like the divergence. We first show that they can be sketched efficiently (i.e. up to multiplicative error in sublinear space) in the aggregate streaming model. This result is exponentially stronger than known upper bounds for sketching these distances in the strict turnstile streaming model. Second, we show a finite dimensionality embedding result for the Jensen-Shannon and divergences that preserves pair wise distances. Finally we prove a dimensionality reduction result for the Hellinger, Jensen--Shannon, and divergences that preserves the information geometry of the distributions (specifically, by retaining the simplex structure of the space). While our second result above already implies that these divergences can be explicitly embedded in Euclidean space, retaining the simplex structure is important because it allows us to continue doing inference in the reduced space. In essence, we preserve not just the distance structure but the underlying geometry of the space.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Amirali Abdullah, Ravi Kumar, Andrew McGregor, Sergei Vassilvitskii, Suresh Venkatasubramanian,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05224", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05224", "title": "\nLeast Squares Estimation-Based Synchronous Generator Parameter  Estimation Using PMU Data", "abstract": "In this paper, least square estimation (LSE)-based dynamic generator model parameter identification is investigated. Electromechanical dynamics related parameters such as inertia constant and primary frequency control droop for a synchronous generator are estimated using Phasor Measurement Unit (PMU) data obtained at the generator terminal bus. The key idea of applying LSE for dynamic parameter estimation is to have a discrete underlineuto underlineegression with e underlineogenous input (ARX) model. With an ARX model, a linear estimation problem can be formulated and the parameters of the ARX model can be found. This paper gives the detailed derivation of converting a generator model with primary frequency control into an ARX model. The generator parameters will be recovered from the estimated ARX model parameters afterwards. Two types of conversion methods are presented: zero-order hold (ZOH) method and Tustin method. Numerical results are presented to illustrate the proposed LSE application in dynamic system parameter identification using PMU data.", "subjects": "Systems and Control (cs.SY)", "authors": "Bander Mogharbel, Lingling Fan, Zhixin Miao,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05214", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05214", "title": "\nsPCA: Scalable Principal Component Analysis for Big Data on Distributed  Platforms", "abstract": "Web sites, social networks, sensors, and scientific experiments currently generate massive amounts of data. Owners of this data strive to obtain insights from it, often by applying machine learning algorithms. Many machine learning algorithms, however, do not scale well to cope with the ever increasing volumes of data. To address this problem, we identify several optimizations that are crucial for scaling various machine learning algorithms in distributed settings. We apply these optimizations to the popular Principal Component Analysis (PCA) algorithm. PCA is an important tool in many areas including image processing, data visualization, information retrieval, and dimensionality reduction. We refer to the proposed optimized PCA algorithm as scalable PCA, or sPCA. sPCA achieves scalability via employing efficient large matrix operations, effectively leveraging matrix sparsity, and minimizing intermediate data. We implement sPCA on the widely-used MapReduce platform and on the memory-based Spark platform. We compare sPCA against the closest PCA implementations, which are the ones in Mahout/MapReduce and MLlib/Spark. Our experiments show that sPCA outperforms both Mahout-PCA and MLlib-PCA by wide margins in terms of accuracy, running time, and volume of intermediate data generated during the computation.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Tarek Elgamal, Maysam Yabandeh, Ashraf Aboulnaga, Mohamed Hefeeda,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05187", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05187", "title": "\nAn Outlier Detection-based Tree Selection Approach to Extreme Pruning of  Random Forests", "abstract": "Random Forest (RF) is an ensemble classification technique that was developed by Breiman over a decade ago. Compared with other ensemble techniques, it has proved its accuracy and superiority. Many researchers, however, believe that there is still room for enhancing and improving its performance in terms of predictive accuracy. This explains why, over the past decade, there have been many extensions of RF where each extension employed a variety of techniques and strategies to improve certain aspect(s) of RF. Since it has been proven empirically that ensembles tend to yield better results when there is a significant diversity among the constituent models, the objective of this paper is twofolds. First, it investigates how an unsupervised learning technique, namely, Local Outlier Factor (LOF) can be used to identify diverse trees in the RF. Second, trees with the highest LOF scores are then used to produce an extension of RF termed LOFB-DRF that is much smaller in size than RF, and yet performs at least as good as RF, but mostly exhibits higher performance in terms of accuracy. The latter refers to a known technique called ensemble pruning. Experimental results on 10 real datasets prove the superiority of our proposed extension over the traditional RF. Unprecedented pruning levels reaching 99% have been achieved at the time of boosting the predictive accuracy of the ensemble. The notably high pruning level makes the technique a good candidate for real-time applications.", "subjects": "Learning (cs.LG)", "authors": "Khaled Fawagreh, Mohamad Medhat Gaber, Eyad Elyan,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05172", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05172", "title": "\nHow Retailers at different Stages of E-Commerce Maturity Evaluate Their  Entry to E-Commerce Activities?", "abstract": "This paper investigates how retailers at different stages of e-commerce maturity evaluate their entry to e-commerce activities. The study was conducted using qualitative approach interviewing 16 retailers in Saudi Arabia. It comes up with 22 factors that are believed the most influencing factors for retailers in Saudi Arabia. Interestingly, there seem to be differences between retailers in companies at different maturity stages in terms of having different attitudes regarding the issues of using e-commerce. The businesses that have reached a high stage of e-commerce maturity provide practical evidence of positive and optimistic attitudes and practices regarding use of e-commerce, whereas the businesses that have not reached higher levels of maturity provide practical evidence of more negative and pessimistic attitudes and practices. The study, therefore, should contribute to efforts leading to greater e-commerce development in Saudi Arabia and other countries with similar context.", "subjects": "Computers and Society (cs.CY)", "authors": "Rayed AlGhamdi, Osama Abdulaziz Alfarraj, Adel A. Bahaddad,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05171", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05171", "title": "\nModeling and Analyzing Release Trajectory based on the Process of Issue  Tracking", "abstract": "Software release development process, that we refer to as \"release trajectory\", involves development activities that are usually sorted in different categories, such as incorporating new features, improving software, or fixing bugs, and associated to \"issues\". Release trajectory management is a difficult and crucial task. Managers must be aware of every aspect of the development process for managing the software-related issues. Issue Tracking Systems (ITS) play a central role in supporting the management of release trajectory. These systems, which support reporting and tracking issues of different kinds (such as \"bug\", \"feature\", \"improvement\", etc.), record rich data about the software development process. Yet, recorded historical data in ITS are still not well-modeled for supporting practical needs of release trajectory management. In this paper, we describe a sequence analysis approach for modeling and analyzing releases' trajectories, using the tracking process of reported issues. Release trajectory analysis is based on the categories of tracked issues and their temporal changing, and aims to address important questions regarding the co-habitation of unresolved issues, the transitions between different statuses in release trajectory, the recurrent patterns of release trajectories, and the properties of a release trajectory.", "subjects": "Software Engineering (cs.SE)", "authors": "Hani Abdeen, Houari Sahraoui,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05157", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05157", "title": "\nQuality Assessment of Linked Datasets using Probabilistic Approximation", "abstract": "With the increasing application of Linked Open Data, assessing the quality of datasets by computing quality metrics becomes an issue of crucial importance. For large and evolving datasets, an exact, deterministic computation of the quality metrics is too time consuming or expensive. We employ probabilistic techniques such as Reservoir Sampling, Bloom Filters and Clustering Coefficient estimation for implementing a broad set of data quality metrics in an approximate but sufficiently accurate way. Our implementation is integrated in the comprehensive data quality assessment framework Luzzu. We evaluated its performance and accuracy on Linked Open Datasets of broad relevance.", "subjects": "Databases (cs.DB)", "authors": "Jeremy Debattista, Santiago Londo\u00f1o, Christoph Lange, S\u00f6ren Auer,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05146", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05146", "title": "\nAccurate Impedance Calculation for Underground and Submarine Power  Cables using MoM-SO and a Multilayer Ground Model", "abstract": "An accurate knowledge of the per-unit length impedance of power cables is necessary to correctly predict electromagnetic transients in power systems. In particular, skin, proximity, and ground return effects must be properly estimated. In many applications, the medium that surrounds the cable is not uniform and can consist of multiple layers of different conductivity, such as dry and wet soil, water, or air. We introduce a multilayer ground model for the recently-proposed MoM-SO method, suitable to accurately predict ground return effects in such scenarios. The proposed technique precisely accounts for skin, proximity, ground and tunnel effects, and is applicable to a variety of cable configurations, including underground and submarine cables. Numerical results show that the proposed method is more accurate than analytic formulas typically employed for transient analyses, and delivers an accuracy comparable to the finite element method (FEM). With respect to FEM, however, MoM-SO is over 1000 times faster, and can calculate the impedance of a submarine cable inside a three-layer medium in 0.10~s per frequency point.", "subjects": "Computational Engineering, Finance, and Science (cs.CE)", "authors": "Utkarsh R. Patel, Piero Triverio,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05144", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05144", "title": "\nPiecewise Function Approximation with Private Data", "abstract": "We present two Secure Two Party Computation (STPC) protocols for piecewise function approximation on private data. The protocols rely on a piecewise approximation of the to-be-computed function easing the implementation in a STPC setting. The first protocol relies entirely on Garbled Circuit (GC) theory, while the second one exploits a hybrid construction where GC and Homomorphic Encryption (HE) are used together. In addition to piecewise constant and linear approximation, polynomial interpolation is also considered. From a communication complexity perspective, the full-GC implementation is preferable when the input and output variables can be represented with a small number of bits, while the hybrid solution is preferable otherwise. With regard to computational complexity, the full-GC solution is generally more convenient.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Riccardo Lazzeretti, Tommaso Pignata, Mauro Barni,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05141", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05141", "title": "\nMobility-Induced Service Migration in Mobile Micro-Clouds", "abstract": "Mobile micro-cloud is an emerging technology in distributed computing, which is aimed at providing seamless computing/data access to the edge of the network when a centralized service may suffer from poor connectivity and long latency. Different from the traditional cloud, a mobile micro-cloud is smaller and deployed closer to users, typically attached to a cellular basestation or wireless network access point. Due to the relatively small coverage area of each basestation or access point, when a user moves across areas covered by different basestations or access points which are attached to different micro-clouds, issues of service performance and service migration become important. In this paper, we consider such migration issues. We model the general problem as a Markov decision process (MDP), and show that, in the special case where the mobile user follows a one-dimensional asymmetric random walk mobility model, the optimal policy for service migration is a threshold policy. We obtain the analytical solution for the cost resulting from arbitrary thresholds, and then propose an algorithm for finding the optimal thresholds. The proposed algorithm is more efficient than standard mechanisms for solving MDPs.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Shiqiang Wang, Rahul Urgaonkar, Ting He, Murtaza Zafer, Kevin Chan, Kin K. Leung,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05133", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05133", "title": "\nConstant Composition Distribution Matching", "abstract": "Distribution matching transforms independent and Bernoulli(1/2) distributed input bits into a sequence of output symbols with a desired distribution. Fixed-to-fixed length, invertible, and low complexity encoders and decoders based on constant composition and arithmetic coding are presented. Asymptotically in the blocklength, the encoder achieves the maximum rate, namely the entropy of the desired distribution. Furthermore, the normalized divergence of the encoder output and the desired distribution goes to zero in the blocklength.", "subjects": "Information Theory (cs.IT)", "authors": "Patrick Schulte, Georg B\u00f6cherer,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05124", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05124", "title": "\nA representation theorem for stratified complete lattices", "abstract": "We consider complete lattices equipped with preorderings indexed by the ordinals less than a given (limit) ordinal subject to certain axioms. These structures, called stratified complete lattices, and weakly monotone functions over them, provide a framework for solving fixed point equations involving non-monotone operations such as negation or complement, and have been used to give semantics to logic programs with negation. More precisely, we consider stratified complete lattices subject to two slightly different systems of axioms defining `models' and `strong models'. We prove that a stratified complete lattice is a model iff it is isomorphic to the stratified complete lattice determined by the limit of an inverse system of complete lattices with `locally completely additive' projections. Moreover, we prove that a stratified complete lattice is a strong model iff it is isomorphic to the stratified complete lattice determined by the limit of an inverse system of complete lattices with completely additive projections. We use the inverse limit representation to give alternative proofs of some recent results and to derive some new ones for models and strong models. In particular, we use the representation theorem to prove that every model gives rise to another complete lattice structure, which in limit models corresponds to the lexicographic order. Moreover, we prove that the set of all fixed points of a weakly monotone function over a model, equipped with the new ordering, is a complete lattice. We also consider symmetric models that satisfy, together with each axiom, the dual axiom, and use the inverse limit representation to prove that every strong model is symmetric.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Zoltan Esik,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05123", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05123", "title": "\nPrediction Using Note Text: Synthetic Feature Creation with word2vec", "abstract": "word2vec affords a simple yet powerful approach of extracting quantitative variables from unstructured textual data. Over half of healthcare data is unstructured and therefore hard to model without involved expertise in data engineering and natural language processing. word2vec can serve as a bridge to quickly gather intelligence from such data sources. In this study, we ran 650 megabytes of unstructured, medical chart notes from the Providence Health &amp; Services electronic medical record through word2vec. We used two different approaches in creating predictive variables and tested them on the risk of readmission for patients with COPD (Chronic Obstructive Lung Disease). As a comparative benchmark, we ran the same test using the LACE risk model (a single score based on length of stay, acuity, comorbid conditions, and emergency department visits). Using only free text and mathematical might, we found word2vec comparable to LACE in predicting the risk of readmission of COPD patients.", "subjects": "Computation and Language (cs.CL)", "authors": "Manuel Amunategui, Tristan Markwell, Yelena Rozenfeld,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05113", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05113", "title": "\nQuantifying Morphological Computation based on an Information  Decomposition of the Sensorimotor Loop", "abstract": "The question how an agent is affected by its embodiment has attracted growing attention in recent years. A new field of artificial intelligence has emerged, which is based on the idea that intelligence cannot be understood without taking into account embodiment. We believe that a formal approach to quantifying the embodiment's effect on the agent's behaviour is beneficial to the fields of artificial life and artificial intelligence. The contribution of an agent's body and environment to its behaviour is also known as morphological computation. Therefore, in this work, we propose a quantification of morphological computation, which is based on an information decomposition of the sensorimotor loop into shared, unique and synergistic information. In numerical simulation based on a formal representation of the sensorimotor loop, we show that the unique information of the body and environment is a good measure for morphological computation. The results are compared to our previously derived quantification of morphological computation.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Keyan Ghazi-Zahedi, Johannes Rauh,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05110", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05110", "title": "\nThe parameterized complexity of Graph Motif relatively to the structure  of the input graph", "abstract": "The Graph Motif problem was introduced in 2006 in the context of biological networks. It consists of deciding whether or not a multiset of colors occurs in a connected subgraph of a vertex-colored graph. Graph Motif has been analyzed from the standpoint of parameterized complexity. The main parameters which came into consideration were the size of the multiset and the number of colors. Though, in the many applications of Graph Motif, the input graph originates from real-life and has structure. Motivated by this prosaic observation, we systematically study its complexity relatively to graph structural parameters. For a wide range of parameters, we give an FPT algorithm close to the best possible running time under standard complexity assumptions, or show that the problem remains intractable when the parameter is bounded by a constant. We notice that the problem seems slightly easier on very dense graphs than on very sparse ones, the connectivity constraint being tamed on the former family.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "\u00c9douard Bonnet, Florian Sikora,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05096", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05096", "title": "\nExploring Coverage and Distribution of Identifiers on the Scholarly Web", "abstract": "In a scientific publishing environment that is increasingly moving online, identifiers of scholarly work are gaining in importance. In this paper, we analysed identifier distribution and coverage of articles from the discipline of quantitative biology using arXiv, Mendeley and CrossRef as data sources. The results show that when retrieving arXiv articles from Mendeley, we were able to find more papers using the DOI than the arXiv ID. This indicates that DOI may be a better identifier with respect to findability. We also find that coverage of articles on Mendeley decreases in the most recent years, whereas the coverage of DOIs does not decrease in the same order of magnitude. This hints at the fact that there is a certain time lag involved, before articles are covered in crowd-sourced services on the scholarly web.", "subjects": "Digital Libraries (cs.DL)", "authors": "Peter Kraker, Asura Enkhbayar, Elisabeth Lex,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05087", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05087", "title": "\nImportance weighting without importance weights: An efficient algorithm  for combinatorial semi-bandits", "abstract": "We propose a sample-efficient alternative for importance weighting for situations where one only has sample access to the probability distribution that generates the observations. Our new method, called Recurrence Weighting (RW), is described and analyzed in the context of online combinatorial optimization under semi-bandit feedback, where a learner sequentially selects its actions from a combinatorial decision set so as to minimize its cumulative loss. In particular, we show that the well-known Follow-the-Perturbed-Leader (FPL) prediction method coupled with Recurrence Weighting yields the first computationally efficient reduction from offline to online optimization in this setting. We provide a thorough theoretical analysis for the resulting algorithm, showing that its performance is on par with previous, inefficient solutions. Our main contribution is showing that, despite the relatively large variance induced by the RW procedure, our performance guarantees hold with high probability rather than only in expectation. As a side result, we also improve the best known regret bounds for FPL in online combinatorial optimization with full feedback, closing the perceived performance gap between FPL and exponential weights in this setting.", "subjects": "Learning (cs.LG)", "authors": "Gergely Neu, G\u00e1bor Bart\u00f3k,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05079", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05079", "title": "\nLearning Models for Following Natural Language Directions in Unknown  Environments", "abstract": "Natural language offers an intuitive and flexible means for humans to communicate with the robots that we will increasingly work alongside in our homes and workplaces. Recent advancements have given rise to robots that are able to interpret natural language manipulation and navigation commands, but these methods require a prior map of the robot's environment. In this paper, we propose a novel learning framework that enables robots to successfully follow natural language route directions without any previous knowledge of the environment. The algorithm utilizes spatial and semantic information that the human conveys through the command to learn a distribution over the metric and semantic properties of spatially extended environments. Our method uses this distribution in place of the latent world model and interprets the natural language instruction as a distribution over the intended behavior. A novel belief space planner reasons directly over the map and behavior distributions to solve for a policy using imitation learning. We evaluate our framework on a voice-commandable wheelchair. The results demonstrate that by learning and performing inference over a latent environment model, the algorithm is able to successfully follow natural language route directions within novel, extended environments.", "subjects": "Robotics (cs.RO)", "authors": "Sachithra Hemachandra, Felix Duvallet, Thomas M. Howard, Nicholas Roy, Anthony Stentz, Matthew R. Walter,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05070", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05070", "title": "\nEnergy Efficient Precoder Design for MIMO-OFDM with Rate-dependent  Circuit Power", "abstract": "This paper studies an energy efficient design of precoders for point-to-point multiple-input-multiple-output (MIMO) orthogonal frequency-division multiplexing (OFDM) systems. Differently from traditional approaches, the optimal power allocation strategy is studied by modelling the circuit power as a rate-dependent function. We show that if the circuit power is a constant plus an increasing and convex function of the transmission rate, the problem of minimizing the consumed energy per bit received can be reformulated as a convex fractional program and solved by means of a bisection algorithm. The impact of the some system parameters is investigated either analytically or by means of computational results.", "subjects": "Information Theory (cs.IT)", "authors": "Zijian Wang, Ivan Stupia, Luc Vandendorpe,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05067", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05067", "title": "\nLow Autocorrelation Binary Sequences: Number Theory-based Analysis for  Minimum Energy Level, Barker codes", "abstract": "Low autocorrelation binary sequences (LABS) are very important for communication applications. And it is a notoriously difficult computational problem to find binary sequences with low aperiodic autocorrelations. The problem can also be stated in terms of finding binary sequences with minimum energy levels or maximum merit factor defined by M.J.E. Golay, F=N^2/2E, N and E being the sequence length and energy respectively. Conjectured asymptotic value of F is 12.32 for very long sequences. In this paper, a theorem has been proved to show that there are finite number of possible energy levels, spaced at an equal interval of 4, for the binary sequence of a particular length. Two more theorems are proved to derive the theoretical minimum energy level of a binary sequence of even and odd length of N to be N/2, and N-1/2 respectively, making the merit factor equal to N and N^2/N-1 respectively. The derived theoretical minimum energy level successfully explains the case of N =13, for which the merit factor (F =14.083) is higher than the conjectured value. Sequence of lengths 4, 5, 7, 11, 13 are also found to be following the theoretical minimum energy level. These sequences are exactly the Barker sequences which are widely used in direct-sequence spread spectrum and pulse compression radar systems because of their low autocorrelation properties. Further analysis shows physical reasoning in support of the conjecture that Barker sequences exists only when N &lt;= 13 (this has been proven for all odd N).", "subjects": "Information Theory (cs.IT)", "authors": "A. Ukil,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05062", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05062", "title": "\nModem Illumination of Monotone Polygons", "abstract": "We study a generalization of the classical problem of the illumination of polygons. Instead of modeling a light source we model a wireless device whose radio signal can penetrate a given number of walls. We call these objects -modems and study the minimum number of -modems sufficient and sometimes necessary to illuminate monotone and monotone orthogonal polygons. We show that every monotone polygon with vertices can be illuminated with -modems. In addition, we exhibit examples of monotone polygons requiring at least -modems to be illuminated. For monotone orthogonal polygons with vertices we show that for and for even , every such polygon can be illuminated with -modems, while for odd , -modems are always sufficient. Further, by presenting according examples of monotone orthogonal polygons, we show that both bounds are tight.", "subjects": "Computational Geometry (cs.CG)", "authors": "Oswin Aichholzer, Ruy Fabila-Monroy, David Flores-Pe\u00f1aloza, Thomas Hackl, Jorge Urrutia, Birgit Vogtenhuber,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05055", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05055", "title": "\nCombining partially independent belief functions", "abstract": "The theory of belief functions manages uncertainty and also proposes a set of combination rules to aggregate opinions of several sources. Some combination rules mix evidential information where sources are independent; other rules are suited to combine evidential information held by dependent sources. In this paper we have two main contributions: First we suggest a method to quantify sources' degree of independence that may guide the choice of the more appropriate set of combination rules. Second, we propose a new combination rule that takes consideration of sources' degree of independence. The proposed method is illustrated on generated mass functions.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Mouna Chebbah, Arnaud Martin, Boutheina Ben Yaghlane,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05038", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05038", "title": "\n3D Object Class Detection in the Wild", "abstract": "Object class detection has been a synonym for 2D bounding box localization for the longest time, fueled by the success of powerful statistical learning techniques, combined with robust image representations. Only recently, there has been a growing interest in revisiting the promise of computer vision from the early days: to precisely delineate the contents of a visual scene, object by object, in 3D. In this paper, we draw from recent advances in object detection and 2D-3D object lifting in order to design an object class detector that is particularly tailored towards 3D object class detection. Our 3D object class detection method consists of several stages gradually enriching the object detection output with object viewpoint, keypoints and 3D shape estimates. Following careful design, in each stage it constantly improves the performance and achieves state-ofthe-art performance in simultaneous 2D bounding box and viewpoint estimation on the challenging Pascal3D+ dataset.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Bojan Pepik, Michael Stark, Peter Gehler, Tobias Ritschel, Bernt Schiele,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05034", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05034", "title": "\n$gen$CNN: A Convolutional Architecture for Word Sequence Prediction", "abstract": "We propose a novel convolutional architecture, named CNN, for word sequence prediction. Different from previous work on neural network-based language modeling and generation (e.g., RNN or LSTM), we choose not to greedily summarize the history of words as a fixed length vector. Instead, we use a convolutional neural network to predict the next word with the history of words of variable length. Also different from the existing feedforward networks for language modeling, our model can effectively fuse the local correlation and global correlation in the word sequence, with a convolution-gating strategy specifically designed for the task. We argue that our model can give adequate representation of the history, and therefore can naturally exploit both the short and long range dependencies. Our model is fast, easy to train, and readily parallelized. Our extensive experiments on text generation and -best re-ranking in machine translation show that CNN outperforms the state-of-the-arts with big margins.", "subjects": "Computation and Language (cs.CL)", "authors": "Mingxuan Wang, Zhengdong Lu, Hang Li, Wenbin Jiang, Qun Liu,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05032", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05032", "title": "\nCSR5: An Efficient Storage Format for Cross-Platform Sparse  Matrix-Vector Multiplication", "abstract": "Sparse matrix-vector multiplication (SpMV) is a fundamental building block for numerous applications. In this paper, we propose CSR5 (Compressed Sparse Row 5), a new storage format, which offers high-throughput SpMV on various platforms including CPUs, GPUs and Xeon Phi. First, the CSR5 format is insensitive to the sparsity structure of the input matrix. Thus the single format can support a SpMV algorithm that is efficient both for regular matrices and for irregular matrices. Furthermore, we show that the overhead of the format conversion from the CSR to the CSR5 can be as low as cost of a few SpMV operations. We compare the CSR5-based SpMV algorithm with 11 state-of-the-art formats/algorithms on four mainstream processors using 14 regular and 10 irregular matrices as a benchmark suite. For the 14 regular matrices in the suite, we achieve comparable or better performance over the previous work. For the 10 irregular matrices, the CSR5 obtains average performance improvement of 17.6%, 28.5%, 173.0% and 293.3% (up to 213.3%, 153.6%, 405.1% and 943.3%) over the best existing work on dual-socket Intel CPUs, an nVidia GPU, an AMD GPU and an Intel Xeon Phi, respectively. For real-world applications with only tens of iterations, the CSR5 format can be more practical because of its low-overhead for format conversion. The source code of this work is downloadable at this https URL", "subjects": "Mathematical Software (cs.MS)", "authors": "Weifeng Liu, Brian Vinter,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05025", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05025", "title": "\nA Rice-like theorem for primitive recursive functions", "abstract": "We provide an explicit characterization of the properties of primitive recursive functions that are decidable or semi-decidable, given a primitive recursive index for the function. The result is much more general as it applies to any c.e. class of total computable functions. This is an analog of Rice and Rice-Shapiro theorem, for restricted classes of total computable functions.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Mathieu Hoyrup,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.05018", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.05018", "title": "\nUltra-Fast Shapelets for Time Series Classification", "abstract": "Time series shapelets are discriminative subsequences and their similarity to a time series can be used for time series classification. Since the discovery of time series shapelets is costly in terms of time, the applicability on long or multivariate time series is difficult. In this work we propose Ultra-Fast Shapelets that uses a number of random shapelets. It is shown that Ultra-Fast Shapelets yield the same prediction quality as current state-of-the-art shapelet-based time series classifiers that carefully select the shapelets by being by up to three orders of magnitudes. Since this method allows a ultra-fast shapelet discovery, using shapelets for long multivariate time series classification becomes feasible. A method for using shapelets for multivariate time series is proposed and Ultra-Fast Shapelets is proven to be successful in comparison to state-of-the-art multivariate time series classifiers on 15 multivariate time series datasets from various domains. Finally, time series derivatives that have proven to be useful for other time series classifiers are investigated for the shapelet-based classifiers. It is shown that they have a positive impact and that they are easy to integrate with a simple preprocessing step, without the need of adapting the shapelet discovery algorithm.", "subjects": "Learning (cs.LG)", "authors": "Martin Wistuba, Josif Grabocka, Lars Schmidt-Thieme,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04999", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04999", "title": "\nQuickest Change Detection in Adaptive Censoring Sensor Networks", "abstract": "The problem of quickest change detection with communication rate constraints is studied. A network of wireless sensors with limited computation capability monitors the environment and sends observations to a fusion center via wireless channels. At an unknown time instant, the distributions of observations at all the sensor nodes change simultaneously. Due to limited communication bandwidth, the sensors cannot transmit at all the time instants. The objective is to detect the change at the fusion center as quickly as possible, subject to constraints on false detection and average communication rate between the sensors and the fusion center. Two minimax formulations are proposed. The cumulative sum (CuSum) algorithm is used at the fusion center and censoring strategies adaptive to the CuSum statistic are used at the sensor nodes. The sensors only send observations that fall into prescribed sets to the fusion center. This CuSum adaptive censoring (CuSum-AC) algorithm is proved to be an equalizer rule for Lorden's criterion and to be globally asymptotically optimal for any positive communication rate constraint for both formulations we propose, as the average run length to false alarm goes to infinity. It is also shown, by numerical examples, that the CuSum-AC algorithm has a good trade-off between the detection performance and the communication rate.", "subjects": "Systems and Control (cs.SY)", "authors": "Xiaoqiang Ren, Karl H. Johansson, Dawei Shi, Ling Shi,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04996", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04996", "title": "\nOn Extreme Pruning of Random Forest Ensembles for Real-time Predictive  Applications", "abstract": "Random Forest (RF) is an ensemble supervised machine learning technique that was developed by Breiman over a decade ago. Compared with other ensemble techniques, it has proved its accuracy and superiority. Many researchers, however, believe that there is still room for enhancing and improving its performance accuracy. This explains why, over the past decade, there have been many extensions of RF where each extension employed a variety of techniques and strategies to improve certain aspect(s) of RF. Since it has been proven empiricallthat ensembles tend to yield better results when there is a significant diversity among the constituent models, the objective of this paper is twofold. First, it investigates how data clustering (a well known diversity technique) can be applied to identify groups of similar decision trees in an RF in order to eliminate redundant trees by selecting a representative from each group (cluster). Second, these likely diverse representatives are then used to produce an extension of RF termed CLUB-DRF that is much smaller in size than RF, and yet performs at least as good as RF, and mostly exhibits higher performance in terms of accuracy. The latter refers to a known technique called ensemble pruning. Experimental results on 15 real datasets from the UCI repository prove the superiority of our proposed extension over the traditional RF. Most of our experiments achieved at least 95% or above pruning level while retaining or outperforming the RF accuracy.", "subjects": "Learning (cs.LG)", "authors": "Khaled Fawagreh, Mohamad Medhat Gaber, Eyad Elyan,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04994", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04994", "title": "\nA Linear-Time Algorithm for Finding All Double-Vertex Dominators of a  Given Vertex", "abstract": "Dominators provide a general mechanism for identifying reconverging paths in graphs. This is useful for a number of applications in Computer-Aided Design (CAD) including signal probability computation in biased random simulation, switching activity estimation in power and noise analysis, and cut points identification in equivalence checking. However, traditional single-vertex dominators are too rare in circuit graphs. In order to handle reconverging paths more efficiently, we consider the case of double-vertex dominators which occur more frequently. First, we derive a number of specific properties of double-vertex dominators. Then, we describe a data structure for representing all double-vertex dominators of a given vertex in linear space. Finally, we present an algorithm for finding all double-vertex dominators of a given vertex in linear time. Our results provide an efficient systematic way of partitioning large graphs along the reconverging points of the signal flow.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Maxim Teslenko, Elena Dubrova,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04990", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04990", "title": "\nThe Book Thickness of 1-Planar Graphs is Constant", "abstract": "In a book embedding, the vertices of a graph are placed on the spine of a book and the edges are assigned to pages, so that edges on the same page do not cross. In this paper, we prove that every -planar graph (that is, a graph that can be drawn on the plane such that no edge is crossed more than once) admits an embedding in a book with constant number of pages. To the best of our knowledge, the best non-trivial previous upper-bound is , where is the number of vertices of the graph.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Michael A. Bekos, Till Bruckdorfer, Michael Kaufmann, Chrysanthi N. Raftopoulou,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04988", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04988", "title": "\nPerfect Consistent Hashing", "abstract": "Consistent Hashing functions are widely used for load balancing across a variety of applications. However, the original presentation and typical implementations of Consistent Hashing rely on randomised allocation of hash codes to keys which results in a flawed and approximately-uniform allocation of keys to hash codes. We analyse the desired properties and present an algorithm that perfectly achieves them without resorting to any random distributions. The algorithm is simple and adds to our understanding of what is necessary to create a consistent hash function.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Matthew Sackman,", "date": "2015-3-7"}, 
{"urllink": "http://arxiv.org/abs/1503.04973", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04973", "title": "\nRecent Advances and Challenges in Ubiquitous Sensing", "abstract": "Ubiquitous sensing is tightly coupled with activity recognition. This survey reviews recent advances in Ubiquitous sensing and looks ahead on promising future directions. In particular, Ubiquitous sensing crosses new barriers giving us new ways to interact with the environment or to inspect our psyche. Through sensing paradigms that parasitically utilise stimuli from the noise of environmental, third-party pre-installed systems, sensing leaves the boundaries of the personal domain. Compared to previous environmental sensing approaches, these new systems mitigate high installation and placement cost by providing a robustness towards process noise. On the other hand, sensing focuses inward and attempts to capture mental activities such as cognitive load, fatigue or emotion through advances in, for instance, eye-gaze sensing systems or interpretation of body gesture or pose. This survey summarises these developments and discusses current research questions and promising future directions.", "subjects": "Human-Computer Interaction (cs.HC)", "authors": "Stephan Sigg, Kai Kunze, Xiaoming Fu,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04967", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04967", "title": "\nImplementation and Evaluation of multimodal input/output channels for  task-based industrial robot programming", "abstract": "Programming industrial robots is not very intuitive, and the programmer has to be a domain expert for e.g. welding and programming to know how the task is optimally executed. For SMEs such employees are not affordable, nor cost-effective. Therefore a new system is needed where domain experts from a specific area, like welding or assembly, can easily program a robot without knowing anything about programming languages or how to use TeachPads. Such a system needs to be flexible to adapt to new tasks and functions. These requirements can be met by using a task based programming approach where the robot program is built up using a hierarchical structure of process, tasks and skills. It also needs to be intuitive so that domain experts don't need much training time on handling the system. Intuitive interaction is achieved by using different input and output modalities like gesture input, speech input, or touch input which are suitable for the current task. This master thesis focuses on the implementation of a user interface (GUI) for task based industrial robot programming and evaluates different input modalities (gesture, speech, touch, pen input) for the interaction with the system. The evaluation is based on a user study conducted with 30 participants as a Wizard-Of-Oz experiment, where non expert users had to program assembly and welding tasks to an industrial robot, using the previously developed GUI and various input and output modalities. The findings of the task analysis and user study are then used for creating a semantic description which will be used in the cognitive robotics-worker cell for automatically inferring required system components, and to provide the best suited input modality.", "subjects": "Robotics (cs.RO)", "authors": "Stefan Profanter,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04964", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04964", "title": "\nEnergy Sharing for Multiple Sensor Nodes with Finite Buffers", "abstract": "We consider the problem of finding optimal energy sharing policies that maximize the network performance of a system comprising of multiple sensor nodes and a single energy harvesting (EH) source. Sensor nodes periodically sense the random field and generate data, which is stored in the corresponding data queues. The EH source harnesses energy from ambient energy sources and the generated energy is stored in an energy buffer. Sensor nodes receive energy for data transmission from the EH source. The EH source has to efficiently share the stored energy among the nodes in order to minimize the long-run average delay in data transmission. We formulate the problem of energy sharing between the nodes in the framework of average cost infinite-horizon Markov decision processes (MDPs). We develop efficient energy sharing algorithms, namely Q-learning algorithm with exploration mechanisms based on the -greedy method as well as upper confidence bound (UCB). We extend these algorithms by incorporating state and action space aggregation to tackle state-action space explosion in the MDP. We also develop a cross entropy based method that incorporates policy parameterization in order to find near optimal energy sharing policies. Through simulations, we show that our algorithms yield energy sharing policies that outperform the heuristic greedy method.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Sindhu Padakandla, Prabuchandran K.J, Shalabh Bhatnagar,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04963", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04963", "title": "\nAlgebraic Methods in the Congested Clique", "abstract": "In this work, we use algebraic methods for studying distance computation and subgraph detection tasks in the congested clique model. Specifically, we adapt parallel matrix multiplication implementations to the congested clique, obtaining an round matrix multiplication algorithm, where is the exponent of matrix multiplication. In conjunction with known techniques from centralised algorithmics, this gives significant improvements over previous best upper bounds in the congested clique model. The highlight results include: -- triangle and 4-cycle counting in rounds, improving upon the triangle detection algorithm of Dolev et al. [DISC 2012], -- a -approximation of all-pairs shortest paths in rounds, improving upon the -round -approximation algorithm of Nanongkai [STOC 2014], and -- computing the girth in rounds, which is the first non-trivial solution in this model. In addition, we present a novel constant-round combinatorial algorithm for detecting 4-cycles.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Keren Censor-Hillel, Petteri Kaski, Janne H. Korhonen, Christoph Lenzen, Ami Paz, Jukka Suomela,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04958", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04958", "title": "\nThe blind detection for palette image watermarking without changing the  color", "abstract": "To hide a binary pattern in the palette image a steganographic scheme with blind detection is considered. The embedding algorithm uses the Lehmer code by palette color permutations for which the cover image palette is generally required. The found transformation between the palette and RGB images allows to extract the hidden data without any cover work.", "subjects": "Multimedia (cs.MM)", "authors": "V.N. Gorbachev, E.M. Kaynarova, I.K. Metelev, O.V. Pavlovskaya,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04957", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04957", "title": "\nConformance Checking Based on Multi-Perspective Declarative Process  Models", "abstract": "Process mining is a family of techniques that aim at analyzing business process execution data recorded in event logs. Conformance checking is a branch of this discipline embracing approaches for verifying whether the behavior of a process, as recorded in a log, is in line with some expected behaviors provided in the form of a process model. The majority of these approaches require the input process model to be procedural (e.g., a Petri net). However, in turbulent environments, characterized by high variability, the process behavior is less stable and predictable. In these environments, procedural process models are less suitable to describe a business process. Declarative specifications, working in an open world assumption, allow the modeler to express several possible execution paths as a compact set of constraints. Any process execution that does not contradict these constraints is allowed. One of the open challenges in the context of conformance checking with declarative models is the capability of supporting multi-perspective specifications. In this paper, we close this gap by providing a framework for conformance checking based on MP-Declare, a multi-perspective version of the declarative process modeling language Declare. The approach has been implemented in the process mining tool ProM and has been experimented in three real life case studies.", "subjects": "Software Engineering (cs.SE)", "authors": "Andrea Burattin, Fabrizio Maria Maggi, Alessandro Sperduti,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04955", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04955", "title": "\nFast Multiplication of Large Integers: Implementation and Analysis of  the DKSS Algorithm", "abstract": "The Sch \"onhage-Strassen algorithm (SSA) is the de-facto standard for multiplication of large integers. For -bit numbers it has a time bound of . De, Kurur, Saha and Saptharishi (DKSS) presented an asymptotically faster algorithm with a better time bound of . In this diploma thesis, results of an implementation of DKSS multiplication are presented: run-time is about 30 times larger than SSA, while memory requirements are about 3.75 times higher than SSA. A possible crossover point is estimated to be out of reach even if we utilized the whole universe for computer memory.", "subjects": "Mathematical Software (cs.MS)", "authors": "Christoph L\u00fcders,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04949", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04949", "title": "\nSparse Convolutional Networks using the Permutohedral Lattice", "abstract": "This paper introduces an efficient, non-linear image adaptive filtering as a generalization of the standard spatial convolution of convolutional neural networks (CNNs). We build on the bilateral filtering operation, a commonly used edge-aware image processing technique. Our implementation of bilateral filters uses specialized data structures, and in this paper we demonstrate how these lead to generalizations and make the filters amendable to learning. This development enriches the convolutional operation found in CNNs, which becomes image adaptive, can process sparse input data, and produce continuous output. Our result also generalizes a class of densely connected graphical models with tractable mean field inference. It has previously been shown that mean field approximations in the subclass of models with Gaussian edge potentials reduce to a bilateral filtering operation. Here, we generalize this to the non-Gaussian case and allow highly parameterized potential functions. A diverse set of experiments validates the empirical performance and highlights the different aspects of the proposed operation.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Martin Kiefel, Varun Jampani, Peter V. Gehler,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04941", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04941", "title": "\nHow the symbol grounding of living organisms can be realized in  artificial agents", "abstract": "A system with artificial intelligence usually relies on symbol manipulation, at least partly and implicitly. However, the interpretation of the symbols - what they represent and what they are about - is ultimately left to humans, as designers and users of the system. How symbols can acquire meaning for the system itself, independent of external interpretation, is an unsolved problem. Some grounding of symbols can be obtained by embodiment, that is, by causally connecting symbols (or sub-symbolic variables) to the physical environment, such as in a robot with sensors and effectors. However, a causal connection as such does not produce representation and aboutness of the kind that symbols have for humans. Here I present a theory that explains how humans and other living organisms have acquired the capability to have symbols and sub-symbolic variables that represent, refer to, and are about something else. The theory shows how reference can be to physical objects, but also to abstract objects, and even how it can be misguided (errors in reference) or be about non-existing objects. I subsequently abstract the primary components of the theory from their biological context, and discuss how and under what conditions the theory could be implemented in artificial agents. A major component of the theory is the strong nonlinearity associated with (potentially unlimited) self-reproduction. The latter is likely not acceptable in artificial systems. It remains unclear if goals other than those inherently serving self-reproduction can have aboutness and if such goals could be stabilized.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "J.H. van Hateren,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04937", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04937", "title": "\nInteractive MCQs as a tool for Knowledge Acquisition", "abstract": "Multiple Choice Questions or MCQs are very important for e-learning. Generally, MCQs are used as a tool for the assessment of student performance at the end of their learning sessions. Can MCQs become an important tool in the process of knowledge acquisition while attending a course? This paper intends to find out how MCQs could be used as a tool for the better understanding, coverage as well as knowledge acquisition.", "subjects": "Computers and Society (cs.CY)", "authors": "Kisor Ray, Saumen Sarkar,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04928", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04928", "title": "\nHybrid Automata for Formal Modeling and Verification of Cyber-Physical  Systems", "abstract": "The presence of a tight integration between the discrete control (the \"cyber\") and the analog environment (the \"physical\")---via sensors and actuators over wired or wireless communication networks---is the defining feature of cyber-physical systems. Hence, the functional correctness of a cyber- physical system is crucially dependent not only on the dynamics of the analog physical environment, but also on the decisions taken by the discrete control that alter the dynamics of the environment. The framework of Hybrid automata---introduced by Alur, Courcoubetis, Henzinger, and Ho---provides a formal modeling and specification environment to analyze the interaction between the discrete and continuous parts of a cyber-physical system. Hybrid automata can be considered as generalizations of finite state automata augmented with a finite set of real-valued variables whose dynamics in each state is governed by a system of ordinary differential equations. Moreover, the discrete transitions of hybrid automata are guarded by constraints over the values of these real-valued variables, and enable discontinuous jumps in the evolution of these variables. Considering the richness of the dynamics in a hybrid automaton, it is perhaps not surprising that the fundamental verification questions, like reachability and schedulability, for the general model are undecidable. In this article we present a review of hybrid automata as modeling and verification framework for cyber-physical systems, and survey some of the key results related to practical verification questions related to hybrid automata.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Shankara Narayanan Krishna, Ashutosh Trivedi,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04927", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04927", "title": "\nCENI: a Hybrid Framework for Efficiently Inferring Information Networks", "abstract": "Nowadays, the message diffusion links among users or websites drive the development of countless innovative applications. However, in reality, it is easier for us to observe the timestamps when different nodes in the network react on a message, while the connections empowering the diffusion of the message remain hidden. This motivates recent extensive studies on the network inference problem: unveiling the edges from the records of messages disseminated through them. Existing solutions are computationally expensive, which motivates us to develop an efficient two-step general framework, Clustering Embedded Network Inference (CENI). CENI integrates clustering strategies to improve the efficiency of network inference. By clustering nodes directly on the timelines of messages, we propose two naive implementations of CENI: Infection-centric CENI and Cascade-centric CENI. Additionally, we point out the critical dimension problem of CENI: instead of one-dimensional timelines, we need to first project the nodes to an Euclidean space of certain dimension before clustering. A CENI adopting clustering method on the projected space can better preserve the structure hidden in the cascades, and generate more accurately inferred links. This insight sheds light on other related work attempting to discover or utilize the latent cluster structure in the disseminated messages. By addressing the critical dimension problem, we propose the third implementation of the CENI framework: Projection-based CENI. Through extensive experiments on two real datasets, we show that the three CENI models only need around 20% 50% of the running time of state-of-the-art methods. Moreover, the inferred edges of Projection-based CENI preserves or even outperforms the effectiveness of state-of-the-art methods.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Qingbo Hu, Sihong Xie, Shuyang Lin, Senzhang Wang, Philip Yu,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04921", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04921", "title": "\nMolecular MIMO Communication Link", "abstract": "In this demonstration, we will present the world's first molecular multiple-input multiple-output (MIMO) communication link to deliver two data streams in a spatial domain. We show that chemical signals such as concentration gradients could be used in MIMO fashion to transfer sequential data. Until now it was unclear whether MIMO techniques, which are used extensively in modern radio communication, could be applied to molecular communication. In the demonstration, using our devised MIMO apparatus and carefully designed detection algorithm, we will show that we can achieve about 1.7 times higher data rate than single input single output (SISO) molecular communication systems.", "subjects": "Emerging Technologies (cs.ET)", "authors": "Changmin Lee, Bonhong Koo, Na-Rae Kim, Birkan Yilmaz, Nariman Farsard, Andrew Eckford, Chan-Byoung Chae,", "date": "2015-3-7"}, 
{"urllink": "http://arxiv.org/abs/1503.04918", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04918", "title": "\nLucretia - intersection type polymorphism for scripting languages", "abstract": "Scripting code may present maintenance problems in the long run. There is, then, the call for methodologies that make it possible to control the properties of programs written in dynamic languages in an automatic fashion. We introduce Lucretia, a core language with an introspection primitive. Lucretia is equipped with a (retrofitted) static type system based on local updates of types that describe the structure of objects being used. In this way, we deal with one of the most dynamic features of scripting languages, that is, the runtime modification of object interfaces. Judgements in our systems have a Hoare-like shape, as they have a precondition and a postcondition part. Preconditions describe static approximations of the interfaces of visible objects before a certain expression has been executed and postconditions describe them after its execution. The field update operation complicates the issue of aliasing in the system. We cope with it by introducing intersection types in method signatures.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Marcin Benke, Viviana Bono, Aleksy Schubert,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04917", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04917", "title": "\nA Formal Approach based on Fuzzy Logic for the Specification of  Component-Based Interactive Systems", "abstract": "Formal methods are widely recognized as a powerful engineering method for the specification, simulation, development, and verification of distributed interactive systems. However, most formal methods rely on a two-valued logic, and are therefore limited to the axioms of that logic: a specification is valid or invalid, component behavior is realizable or not, safety properties hold or are violated, systems are available or unavailable. Especially when the problem domain entails uncertainty, impreciseness, and vagueness, the appliance of such methods becomes a challenging task. In order to overcome the limitations resulting from the strict modus operandi of formal methods, the main objective of this work is to relax the boolean notion of formal specifications by using fuzzy logic. The present approach is based on Focus theory, a model-based and strictly formal method for componentbased interactive systems. The contribution of this work is twofold: i) we introduce a specification technique based on fuzzy logic which can be used on top of Focus to develop formal specifications in a qualitative fashion; ii) we partially extend Focus theory to a fuzzy one which allows the specification of fuzzy components and fuzzy interactions. While the former provides a methodology for approximating I/O behaviors under imprecision, the latter enables to capture a more quantitative view of specification properties such as realizability.", "subjects": "Software Engineering (cs.SE)", "authors": "Vasileios Koutsoumpas,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04916", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04916", "title": "\nA Model of Layered Architectures", "abstract": "Architectural styles and patterns play an important role in software engineering. One of the most known ones is the layered architecture style. However, this style is usually only stated informally, which may cause problems such as ambiguity, wrong conclusions, and difficulty when checking the conformance of a system to the style. We address these problems by providing a formal, denotational semantics of the layered architecture style. Mainly, we present a sufficiently abstract and rigorous description of layered architectures. Loosely speaking, a layered architecture consists of a hierarchy of layers, in which services communicate via ports. A layer is modeled as a relation between used and provided services, and layer composition is defined by means of relational composition. Furthermore, we provide a formal definition for the notions of syntactic and semantic dependency between the layers. We show that these dependencies are not comparable in general. Moreover, we identify sufficient conditions under which, in an intuitive sense which we make precise in our treatment, the semantic dependency implies, is implied by, or even coincides with the reflexive-transitive closure of the syntactic dependency. Our results provide a technology-independent characterization of the layered architecture style, which may be used by software architects to ensure that a system is indeed built according to that style.", "subjects": "Software Engineering (cs.SE)", "authors": "Diego Marmsoler, Alexander Malkis, Jonas Eckhardt,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04915", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04915", "title": "\nUsing Model-Checking Techniques for Component-Based Systems with  Reconfigurations", "abstract": "Within a component-based approach allowing dynamic reconfigurations, sequences of successive reconfiguration operations are expressed by means of reconfiguration paths, possibly infinite. We show that a subclass of such paths can be modelled by finite state automata. This feature allows us to use techniques related to model-checking to prove some architectural, event, and temporal properties related to dynamic reconfiguration. Our method is proved correct w.r.t. these properties' definition.", "subjects": "Software Engineering (cs.SE)", "authors": "Jean-Michel Hufflen,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04914", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04914", "title": "\nPath-Based Program Repair", "abstract": "We propose a path-based approach to program repair for imperative programs. Our repair framework takes as input a faulty program, a logic specification that is refuted, and a hint where the fault may be located. An iterative abstraction refinement loop is then used to repair the program: in each iteration, the faulty program part is re-synthesized considering a symbolic counterexample, where the control-flow is kept concrete but the data-flow is symbolic. The appeal of the idea is two-fold: 1) the approach lazily considers candidate repairs and 2) the repairs are directly derived from the logic specification. In contrast to prior work, our approach is complete for programs with finitely many control-flow paths, i.e., the program is repaired if and only if it can be repaired at the specified fault location. Initial results for small programs indicate that the approach is useful for debugging programs in practice.", "subjects": "Programming Languages (cs.PL)", "authors": "Heinz Riener, R\u00fcdiger Ehlers, G\u00f6rschwin Fey,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04913", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04913", "title": "\nA Denotational Semantics for Communicating Unstructured Code", "abstract": "An important property of programming language semantics is that they should be compositional. However, unstructured low-level code contains goto-like commands making it hard to define a semantics that is compositional. In this paper, we follow the ideas of Saabas and Uustalu to structure low-level code. This gives us the possibility to define a compositional denotational semantics based on least fixed points to allow for the use of inductive verification methods. We capture the semantics of communication using finite traces similar to the denotations of CSP. In addition, we examine properties of this semantics and give an example that demonstrates reasoning about communication and jumps. With this semantics, we lay the foundations for a proof calculus that captures both, the semantics of unstructured low-level code and communication.", "subjects": "Programming Languages (cs.PL)", "authors": "Nils J\u00e4hnig, Thomas G\u00f6thel, Sabine Glesner,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04912", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04912", "title": "\nImproving Runtime Overheads for detectEr", "abstract": "We design monitor optimisations for detectEr, a runtime-verification tool synthesising systems of concurrent monitors from correctness properties for Erlang programs. We implement these optimisations as part of the existing tool and show that they yield considerably lower runtime overheads when compared to the unoptimised monitor synthesis.", "subjects": "Software Engineering (cs.SE)", "authors": "Ian Cassar, Adrian Francalanza, Simon Said,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04911", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04911", "title": "\nTyping Classes and Mixins with Intersection Types", "abstract": "We study an assignment system of intersection types for a lambda-calculus with records and a record-merge operator, where types are preserved both under subject reduction and expansion. The calculus is expressive enough to naturally represent mixins as functions over recursively defined classes, whose fixed points, the objects, are recursive records. In spite of the double recursion that is involved in their definition, classes and mixins can be meaningfully typed without resorting to neither recursive nor F-bounded polymorphic types. We then adapt mixin construct and composition to Java and C#, relying solely on existing features in such a way that the resulting code remains typable in the respective type systems. We exhibit some example code, and study its typings in the intersection type system via interpretation into the lambda-calculus with records we have proposed.", "subjects": "Programming Languages (cs.PL)", "authors": "Jan Bessai, Boris D\u00fcdder, Andrej Dudenhefner, Tzu-Chun Chen, Ugo de'Liguoro,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04910", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04910", "title": "\nOn Isomorphism of \"Functional\" Intersection and Union Types", "abstract": "Type isomorphism is useful for retrieving library components, since a function in a library can have a type different from, but isomorphic to, the one expected by the user. Moreover type isomorphism gives for free the coercion required to include the function in the user program with the right type. The present paper faces the problem of type isomorphism in a system with intersection and union types. In the presence of intersection and union, isomorphism is not a congruence and cannot be characterised in an equational way. A characterisation can still be given, quite complicated by the interference between functional and non functional types. This drawback is faced in the paper by interpreting each atomic type as the set of functions mapping any argument into the interpretation of the type itself. This choice has been suggested by the initial projection of Scott's inverse limit lambda-model. The main result of this paper is a condition assuring type isomorphism, based on an isomorphism preserving reduction.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Mario Coppo, Mariangiola Dezani-Ciancaglini, Ines Margaria, Maddalena Zacchi,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04909", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04909", "title": "\nIndexed linear logic and higher-order model checking", "abstract": "In recent work, Kobayashi observed that the acceptance by an alternating tree automaton A of an infinite tree T generated by a higher-order recursion scheme G may be formulated as the typability of the recursion scheme G in an appropriate intersection type system associated to the automaton A. The purpose of this article is to establish a clean connection between this line of work and Bucciarelli and Ehrhard's indexed linear logic. This is achieved in two steps. First, we recast Kobayashi's result in an equivalent infinitary intersection type system where intersection is not idempotent anymore. Then, we show that the resulting type system is a fragment of an infinitary version of Bucciarelli and Ehrhard's indexed linear logic. While this work is very preliminary and does not integrate key ingredients of higher-order model-checking like priorities, it reveals an interesting and promising connection between higher-order model-checking and linear logic.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Charles Grellois, Paul-Andr\u00e9 Melli\u00e8s,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04908", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04908", "title": "\nLiquid Intersection Types", "abstract": "We present a new type system combining refinement types and the expressiveness of intersection type discipline. The use of such features makes it possible to derive more precise types than in the original refinement system. We have been able to prove several interesting properties for our system (including subject reduction) and developed an inference algorithm, which we proved to be sound.", "subjects": "Programming Languages (cs.PL)", "authors": "M\u00e1rio Pereira, Sandra Alves, M\u00e1rio Florido,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04907", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04907", "title": "\nUniform Proofs of Normalisation and Approximation for Intersection Types", "abstract": "We present intersection type systems in the style of sequent calculus, modifying the systems that Valentini introduced to prove normalisation properties without using the reducibility method. Our systems are more natural than Valentini's ones and equivalent to the usual natural deduction style systems. We prove the characterisation theorems of strong and weak normalisation through the proposed systems, and, moreover, the approximation theorem by means of direct inductive arguments. This provides in a uniform way proofs of the normalisation and approximation theorems via type systems in sequent calculus style.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Kentaro Kikuchi,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04906", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04906", "title": "\nA Finite Model Property for Intersection Types", "abstract": "We show that the relational theory of intersection types known as BCD has the finite model property; that is, BCD is complete for its finite models. Our proof uses rewriting techniques which have as an immediate by-product the polynomial time decidability of the preorder &lt;= (although this also follows from the so called beta soundness of BCD).", "subjects": "Programming Languages (cs.PL)", "authors": "Rick Statman,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04904", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04904", "title": "\nDistributed Continuous-time Approximate Projection Protocols for  Shortest Distance Optimization Problems", "abstract": "In this paper, we investigate the distributed shortest distance optimization problem for a multi-agent network to cooperatively minimize the sum of the quadratic distances from some convex sets, where each set is only associated with one agent. To deal with the optimization problem with projection uncertainties, we propose a distributed continuous-time dynamical protocol based on a new concept of approximate projection. Here each agent can only obtain an approximate projection point on the boundary of its convex set, and communicate with its neighbors over a time-varying communication graph. First, we show that no matter how large the approximate angle is, the system states are always bounded for any initial condition, and uniformly bounded with respect to all initial conditions if the inferior limit of the stepsize is greater than zero. Then, in the two cases, nonempty intersection and empty intersection of convex sets, we provide stepsize and approximate angle conditions to ensure the optimal convergence, respectively. Moreover, we give some characterizations about the optimal solutions for the empty intersection case and also present the convergence error between agents' estimates and the optimal point in the case of constant stepsizes and approximate angles.", "subjects": "Systems and Control (cs.SY)", "authors": "Youcheng Lou, Yiguang Hong, Shouyang Wang,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04903", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04903", "title": "\nDecision-theoretic rough sets based on time-dependent loss function", "abstract": "A fundamental notion of decision-theoretic rough sets is the concept of loss functions, which provides a powerful tool of calculating a pair of thresholds for making a decision with a minimum cost. In this paper, time-dependent loss functions which are variations of the time are of interest because such functions are frequently encountered in practical situations, we present the relationship between the pair of thresholds and loss functions satisfying time-dependent uniform distributions and normal processes in light of bayesian decision procedure. Subsequently, with the aid of bayesian decision procedure, we provide the relationship between the pair of thresholds and loss functions which are time-dependent interval sets and fuzzy numbers. Finally, we employ several examples to illustrate that how to calculate the thresholds for making a decision by using time-dependent loss functions-based decision-theoretic rough sets.", "subjects": "Information Theory (cs.IT)", "authors": "Guangming Lang,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04899", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04899", "title": "\nA Multi-Tier Wireless Spectrum Sharing System Leveraging Secure Spectrum  Auctions", "abstract": "Secure spectrum auctions can revolutionize the spectrum utilization of cellular networks and satisfy the ever increasing demand for resources. In this paper, a multi-tier dynamic spectrum sharing system is studied for efficient sharing of spectrum with commercial wireless system providers (WSPs), with an emphasis on federal spectrum sharing. The proposed spectrum sharing system optimizes usage of spectrum resources, manages intra-WSP and inter-WSP interference and provides essential level of security, privacy, and obfuscation to enable the most efficient and reliable usage of the shared spectrum. It features an intermediate spectrum auctioneer responsible for allocating resources to commercial WSPs by running secure spectrum auctions. The proposed secure spectrum auction, MTSSA, leverages Paillier cryptosystem to avoid possible fraud and bid-rigging. Numerical simulations are provided to compare the performance of MTSSA, in the considered spectrum sharing system, with other spectrum auction mechanisms for realistic cellular systems.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Ahmed Abdelhadi, Haya Shajaiah, Charles Clancy,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04896", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04896", "title": "\nIdentifying a Criminal's Network of Trust", "abstract": "Tracing criminal ties and mining evidence from a large network to begin a crime case analysis has been difficult for criminal investigators due to large numbers of nodes and their complex relationships. In this paper, trust networks using blind carbon copy (BCC) emails were formed. We show that our new shortest paths network search algorithm combining shortest paths and network centrality measures can isolate and identify criminals' connections within a trust network. A group of BCC emails out of 1,887,305 Enron email transactions were isolated for this purpose. The algorithm uses two central nodes, most influential and middle man, to extract a shortest paths trust network.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Pritheega Magalingam, Asha Rao, Stephen Davis,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04894", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04894", "title": "\nBiomimetic Algorithms for Coordinated Motion: Theory and Implementation", "abstract": "Drawing inspiration from flight behavior in biological settings (e.g. territorial battles in dragonflies, and flocking in starlings), this paper demonstrates two strategies for coverage and flocking. Using earlier theoretical studies on mutual motion camouflage, an appropriate steering control law for area coverage has been implemented in a laboratory test-bed equipped with wheeled mobile robots and a Vicon high speed motion capture system. The same test-bed is also used to demonstrate another strategy (based on local information), termed topological velocity alignment, which serves to make agents move in the same direction. The present work illustrates the applicability of biological inspiration in the design of multi-agent robotic collectives.", "subjects": "Robotics (cs.RO)", "authors": "Udit Halder, Biswadip Dey,", "date": "2015-3-17"}, 
{"urllink": "http://arxiv.org/abs/1503.04881", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04881", "title": "\nLong Short-Term Memory Over Tree Structures", "abstract": "The chain-structured long short-term memory (LSTM) has showed to be effective in a wide range of problems such as speech recognition and machine translation. In this paper, we propose to extend it to tree structures, in which a memory cell can reflect the history memories of multiple child cells or multiple descendant cells in a recursive process. We call the model S-LSTM, which provides a principled way of considering long-distance interaction over hierarchies, e.g., language or image parse structures. We leverage the models for semantic composition to understand the meaning of text, a fundamental problem in natural language understanding, and show that it outperforms a state-of-the-art recursive model by replacing its composition layers with the S-LSTM memory blocks. We also show that utilizing the given structures is helpful in achieving a performance better than that without considering the structures.", "subjects": "Computation and Language (cs.CL)", "authors": "Xiaodan Zhu, Parinaz Sobhani, Hongyu Guo,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04877", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04877", "title": "\nAn Automated System for Discovering Neighborhood Patterns in Ego  Networks", "abstract": "Generally, social network analysis has often focused on the topology of the network without considering the characteristics of individuals involved in them. Less attention is given to study the behavior of individuals, considering they are the basic entity of a graph. Given a mobile social network graph, what are good features to extract key information from the nodes?How many distinct neighborhood patterns exist for ego nodes? What clues does such information provide to study nodes over a long period of time? In this report, we develop an automated system in order to discover the occurrences of prototypical ego-centric patterns from data. We aim to provide a data-driven instrument to be used in behavioral sciences for graph interpretations. We analyze social networks derived from real-world data collected with smart-phones. We select 13 well-known network measures, especially those concerned with ego graphs. We form eight feature subsets and then assess their performance using unsupervised clustering techniques to discover distinguishing ego-centric patterns. From clustering analysis, we discover that eight distinct neighborhood patterns have emerged. This categorization allows concise analysis of users' data as they change over time. The results provide a fine-grained analysis for the contribution of different feature sets to detect unique clustering patterns. Last, as a case study, two datasets are studied over long periods to demonstrate the utility of this method. The study shows the effectiveness of the proposed approach in discovering important trends from data.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Syed Agha Muhammad, Kristof Van Laerhoven,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04871", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04871", "title": "\nStrong Matching of Points with Geometric Shapes", "abstract": "Let be a set of points in general position in the plane. Given a convex geometric shape , a geometric graph on is defined to have an edge between two points if and only if there exists an empty homothet of having the two points on its boundary. A matching in is said to be , if the homothests of representing the edges of the matching, are pairwise disjoint, i.e., do not share any point in the plane. We consider the problem of computing a strong matching in , where is a diametral-disk, an equilateral-triangle, or a square. We present an algorithm which computes a strong matching in ; if is a diametral-disk, then it computes a strong matching of size at least , and if is an equilateral-triangle, then it computes a strong matching of size at least . If can be a downward or an upward equilateral-triangle, we compute a strong matching of size at least in . When is an axis-aligned square we compute a strong matching of size in , which improves the previous lower bound of .", "subjects": "Computational Geometry (cs.CG)", "authors": "Ahmad Biniaz, Anil Maheshwari, Michiel Smid,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04867", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04867", "title": "\nVarlets: Additive Decomposition, Topological Total Variation, and  Filtering of Scalar Fields", "abstract": "Continuous interpolation of real-valued data is characterized by piecewise monotone functions on a compact metric space. Topological total variation of piecewise monotone function f:X-&gt;R is a homeomorphism-invariant generalization of 1D total variation. A varlet basis is a collection of piecewise monotone functions , called varlets, such that every linear combination has topological total variation . A varlet transform for is a varlet basis for which . Filtered versions of result from altering the coefficients .", "subjects": "Computational Geometry (cs.CG)", "authors": "Martin Brooks,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.04864", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04864", "title": "\nGeomRDF: A Geodata Converter with a Fine-Grained Structured  Representation of Geometry in the Web", "abstract": "In recent years, with the advent of the web of data, a growing number of national mapping agencies tend to publish their geospatial data as Linked Data. However, differences between traditional GIS data models and Linked Data model can make the publication process more complicated. Besides, it may require, to be done, the setting of several parameters and some expertise in the semantic web technologies. In addition, the use of standards like GeoSPARQL (or ad hoc predicates) is mandatory to perform spatial queries on published geospatial data. In this paper, we present GeomRDF, a tool that helps users to convert spatial data from traditional GIS formats to RDF model easily. It generates geometries represented as GeoSPARQL WKT literal but also as structured geometries that can be exploited by using only the RDF query language, SPARQL. GeomRDF was implemented as a module in the RDF publication platform Datalift. A validation of GeomRDF has been realized against the French administrative units dataset (provided by IGN France).", "subjects": "Databases (cs.DB)", "authors": "Fay\u00e7al Hamdi, Nathalie Abadie, B\u00e9n\u00e9dicte Bucher, Abdelfettah Feliachi,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04843", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04843", "title": "\nMore General Queries and Less Generalization Error in Adaptive Data  Analysis", "abstract": "Adaptivity is an important feature of data analysis---typically the choice of questions asked about a dataset depends on previous interactions with the same dataset. However, generalization error is typically bounded in a non-adaptive model, where all questions are specified before the dataset is drawn. Recent work by Dwork et al. (STOC '15) and Hardt and Ullman (FOCS '14) initiated the formal study of this problem, and gave the first upper and lower bounds on the achievable generalization error for adaptive data analysis. Specifically, suppose there is an unknown distribution and a set of independent samples is drawn from . We seek an algorithm that, given as input, \"accurately\" answers a sequence of adaptively chosen \"queries\" about the unknown distribution . How many samples must we draw from the distribution, as a function of the type of queries, the number of queries, and the desired level of accuracy? In this work we make two new contributions towards resolving this question: *We give upper bounds on the number of samples that are needed to answer statistical queries that improve over the bounds of Dwork et al. *We prove the first upper bounds on the number of samples required to answer more general families of queries. These include arbitrary low-sensitivity queries and the important class of convex risk minimization queries. As in Dwork et al., our algorithms are based on a connection between differential privacy and generalization error, but we feel that our analysis is simpler and more modular, which may be useful for studying these questions in the future.", "subjects": "Learning (cs.LG)", "authors": "Raef Bassily, Adam Smith, Thomas Steinke, Jonathan Ullman,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04837", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04837", "title": "\nUse of Effective Audio in E-learning Courseware", "abstract": "E-Learning uses electronic media, information &amp; communication technologies to provide education to the masses. E-learning deliver hypertext, text, audio, images, animation and videos using desktop standalone computer, local area network based intranet and internet based contents. While producing an e-learning content or course-ware, a major decision making factor is whether to use audio for the benefit of the end users. Generally, three types of audio can be used in e-learning: narration, music and sound effect. This paper shows that the use of proper audio based on contents type and subject can make the content more interesting as well as help the end users to better understand the contents.", "subjects": "Computers and Society (cs.CY)", "authors": "Kisor Ray,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04831", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04831", "title": "\nA Context-Based Semantics for SPARQL Property Paths over the Web  (Extended Version)", "abstract": "As of today, there exists no standard language for querying Linked Data on the Web, where navigation across distributed data sources is a key feature. A natural candidate seems to be SPARQL, which recently has been enhanced with navigational capabilities thanks to the introduction of property paths (PPs). However, the semantics of SPARQL restricts the scope of navigation via PPs to single RDF graphs. This restriction limits the applicability of PPs on the Web. To fill this gap, in this paper we provide formal foundations for evaluating PPs on the Web, thus contributing to the definition of a query language for Linked Data. In particular, we introduce a query semantics for PPs that couples navigation at the data level with navigation on the Web graph. Given this semantics we find that for some PP-based SPARQL queries a complete evaluation on the Web is not feasible. To enable systems to identify queries that can be evaluated completely, we establish a decidable syntactic property of such queries.", "subjects": "Databases (cs.DB)", "authors": "Olaf Hartig, Giuseppe Pirro,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04796", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04796", "title": "\nEvolution of an Emerging Symmetric Quantum Cryptographic Algorithm", "abstract": "With the rapid evolution of data exchange in network environments, information security has been the most important process for data storage and communication. In order to provide such information security, the confidentiality, data integrity, and data origin authentication must be verified based on cryptographic encryption algorithms. This paper presents a new emerging trend of modern symmetric encryption algorithm by development of the advanced encryption standard (AES) algorithm. The new development focuses on the integration between Quantum Key Distribution (QKD) and an enhanced version of AES. A new quantum symmetric encryption algorithm, which is abbreviated as Quantum-AES (QAES), is the output of such integration. QAES depends on generation of dynamic quantum S-Boxes (DQS-Boxes) based quantum cipher key, instead of the ordinary used static S-Boxes. Furthermore, QAES exploits the specific selected secret key generated from the QKD cipher using two different modes (online and off-line).", "subjects": "Cryptography and Security (cs.CR)", "authors": "Omer K. Jasim, Safia Abbas, El-Sayed M. Horbaty, Abdel-Badeeh M. Salem,", "date": "2015-3-14"}, 
{"urllink": "http://arxiv.org/abs/1503.04794", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04794", "title": "\nA Polynomial Time Algorithm For Solving Clique Problems", "abstract": "I present a single algorithm which solves the clique problems, \"What is the largest size clique?\", \"What are all the maximal cliques?\" and the decision problem, \"Does a clique of size k exist?\" for any given graph in polynomial time. The existence of this algorithm proves that P = NP.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Michael LaPlante,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.04779", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04779", "title": "\nCryptanalysis of some protocols using matrices over group rings", "abstract": "We address a cryptanalysis of two protocols based on the supposed difficulty of discrete logarithm problem on (semi) groups of matrices over a group ring. We can find the secret key and break entirely the protocols.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Mohammad Eftekhari,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04768", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04768", "title": "\nSelf-organizing Networks of Information Gathering Cognitive Agents", "abstract": "In many scenarios, networks emerge endogenously as cognitive agents establish links in order to exchange information. Network formation has been widely studied in economics, but only on the basis of simplistic models that assume that the value of each additional piece of information is constant. In this paper we present a first model and associated analysis for network formation under the much more realistic assumption that the value of each additional piece of information depends on the type of that piece of information and on the information already possessed: information may be complementary or redundant. We model the formation of a network as a non-cooperative game in which the actions are the formation of links and the benefit of forming a link is the value of the information exchanged minus the cost of forming the link. We characterize the topologies of the networks emerging at a Nash equilibrium (NE) of this game and compare the efficiency of equilibrium networks with the efficiency of centrally designed networks. To quantify the impact of information redundancy and linking cost on social information loss, we provide estimates for the Price of Anarchy (PoA); to quantify the impact on individual information loss we introduce and provide estimates for a measure we call Maximum Information Loss (MIL). Finally, we consider the setting in which agents are not endowed with information, but must produce it. We show that the validity of the well-known \"law of the few\" depends on how information aggregates; in particular, the \"law of the few\" fails when information displays complementarities.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Ahmed M. Alaa, Kartik Ahuja, Mihaela Van der Schaar,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04755", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04755", "title": "\nThe Price of Anarchy in Large Games", "abstract": "Game-theoretic models relevant for computer science applications usually feature a large number of players. The goal of this paper is to develop an analytical framework for bounding the price of anarchy in such models. We demonstrate the wide applicability of our framework through instantiations for several well-studied models, including simultaneous single-item auctions, greedy combinatorial auctions, and routing games. In all cases, we identify conditions under which the POA of large games is much better than that of worst-case instances. Our results also give new senses in which simple auctions can perform almost as well as optimal ones in realistic settings.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Michal Feldman, Nicole Immorlica, Brendan Lucier, Tim Roughgarden, Vasilis Syrgkanis,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04753", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04753", "title": "\nMinimum Equivalent Precedence Relation Systems", "abstract": "In this paper two related simplification problems for systems of linear inequalities describing precedence relation systems are considered. Given a precedence relation system, the first problem seeks a minimum subset of the precedence relations (i.e., inequalities) which has the same solution set as that of the original system. The second problem is the same as the first one except that the ``subset restriction'' in the first problem is removed. This paper establishes that the first problem is NP-hard. However, a sufficient condition is provided under which the first problem is solvable in polynomial-time. In addition, a decomposition of the first problem into independent tractable and intractable subproblems is derived. The second problem is shown to be solvable in polynomial-time, with a full parameterization of all solutions described. The results in this paper generalize those in [Moyles and Thompson 1969, Aho, Garey, and Ullman 1972] for the minimum equivalent graph problem and transitive reduction problem, which are applicable to unweighted directed graphs.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Kin Cheong Sou,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04752", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04752", "title": "\nApproaching the Gaussian channel capacity with APSK constellations", "abstract": "We consider the Gaussian channel with power constraint P. A gap exists between the channel capacity and the highest achievable rate of equiprobable uniformly spaced signal. Several approaches enable to overcome this limitation such as constellations with non-uniform probability or constellation shaping. In this letter, we focus on constellation shaping. We give a construction of amplitude and phase-shift keying (APSK) constellations with equiprobable signaling that achieve the Gaussian capacity as the number of constellation points goes to infinity.", "subjects": "Information Theory (cs.IT)", "authors": "Hugo Meric,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04729", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04729", "title": "\nSkilled Impostor Attacks Against Fingerprint Verification Systems And  Its Remedy", "abstract": "Fingerprint verification systems are becoming ubiquitous in everyday life. This trend is propelled especially by the proliferation of mobile devices with fingerprint sensors such as smartphones and tablet computers, and fingerprint verification is increasingly applied for authenticating financial transactions. In this study we describe a novel attack vector against fingerprint verification systems which we coin skilled impostor attack. We show that existing protocols for performance evaluation of fingerprint verification systems are flawed and as a consequence of this, the system's real vulnerability is systematically underestimated. We examine a scenario in which a fingerprint verification system is tuned to operate at false acceptance rate of 0.1% using the traditional verification protocols with random impostors (zero-effort attacks). We demonstrate that an active and intelligent attacker can achieve a chance of success in the area of 89% or more against this system by performing skilled impostor attacks. We describe a new protocol for evaluating fingerprint verification performance in order to improve the assessment of potential and limitations of fingerprint recognition systems. This new evaluation protocol enables a more informed decision concerning the operating threshold in practical applications and the respective trade-off between security (low false acceptance rates) and usability (low false rejection rates). The skilled impostor attack is a general attack concept which is independent of specific databases or comparison algorithms. The proposed protocol relying on skilled impostor attacks can directly be applied for evaluating the verification performance of other biometric modalities such as e.g. iris, face, ear, finger vein, gait or speaker recognition.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Carsten Gottschlich,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04723", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04723", "title": "\nDeep Feelings: A Massive Cross-Lingual Study on the Relation between  Emotions and Virality", "abstract": "This article provides a comprehensive investigation on the relations between virality of news articles and the emotions they are found to evoke. Virality, in our view, is a phenomenon with many facets, i.e. under this generic term several different effects of persuasive communication are comprised. By exploiting a high-coverage and bilingual corpus of documents containing metrics of their spread on social networks as well as a massive affective annotation provided by readers, we present a thorough analysis of the interplay between evoked emotions and viral facets. We highlight and discuss our findings in light of a cross-lingual approach: while we discover differences in evoked emotions and corresponding viral effects, we provide preliminary evidence of a generalized explanatory model rooted in the deep structure of emotions: the Valence-Arousal-Dominance (VAD) circumplex. We find that viral facets appear to be consistently affected by particular VAD configurations, and these configurations indicate a clear connection with distinct phenomena underlying persuasive communication.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Marco Guerini, Jacopo Staiano,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04718", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04718", "title": "\nIdentification of Image Operations Based on Steganalytic Features", "abstract": "Image forensics have attracted wide attention during the past decade. Though many forensic methods have been proposed to identify image forgeries, most of them are targeted ones, since their proposed features are highly dependent on the image operation under investigation. The performance of the well-designed features for detecting the targeted operation usually degrades significantly for other operations. On the other hand, a wise attacker can perform anti-forensics to fool the existing forensic methods, making countering anti-forensics become an urgent need. In this paper, we try to find a universal feature to detect various image processing and anti-forensic operations. Based on our extensive experiments and analysis, we find that any image processing/anti-forensic operations would inevitably modify many image pixels. This would change some inherent statistics within original images, which is similar to the case of steganography. Therefore, we model image processing/anti-forensic operations as steganography problems, and propose a detection strategy by applying steganalytic features. With some advanced steganalytic features, we are able to detect various image operations and further identify their types. In our experiments, we have tested several steganalytic features on 11 different kinds of typical image processing operations and 4 kinds of anti-forensic operations. The experimental results have shown that the proposed strategy significantly outperforms the existing forensic methods in both effectiveness and universality.", "subjects": "Multimedia (cs.MM)", "authors": "Haodong Li, Weiqi Luo, Xiaoqing Qiu, Jiwu Huang,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.04706", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04706", "title": "\nThere are no finite partial cubes of girth more than six and minimum  degree at least three", "abstract": "Partial cubes are graphs isometrically embeddable into hypercubes. We analyze how isometric cycles in partial cubes behave and derive that every partial cube of girth more than six must have vertices of degree less than three. As a direct corollary we get that every regular partial cube of girth more than six is an even cycle. Along the way we prove that every partial cube with girth more than six is the so-called zone graph and therefore holds, where is the isometric dimension of and its convex excess.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Tilen Marc,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04702", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04702", "title": "\nMinimum Degree up to Local Complementation: Bounds, Parameterized  Complexity, and Exact Algorithms", "abstract": "The local minimum degree of a graph is the minimum degree that can be reached by means of local complementation. For any n, there exist graphs of order n which have a local minimum degree at least 0.189n, or at least 0.110n when restricted to bipartite graphs. Regarding the upper bound, we show that for any graph of order n, its local minimum degree is at most 3n/8+o(n) and n/4+o(n) for bipartite graphs, improving the known n/2 upper bound. We also prove that the local minimum degree is smaller than half of the vertex cover number (up to a logarithmic term). The local minimum degree problem is NP-Complete and hard to approximate. We show that this problem, even when restricted to bipartite graphs, is in W[2] and FPT-equivalent to the EvenSet problem, which W[1]-hardness is a long standing open question. Finally, we show that the local minimum degree is computed by a O*(1.938^n)-algorithm, and a O*(1.466^n)-algorithm for the bipartite graphs.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "David Cattan\u00e9o, Simon Perdrix,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04694", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04694", "title": "\nControlled Label Propagation: Preventing Over-Propagation through  Gradual Expansion", "abstract": "Identifying communities has always been a fundamental task in analysis of complex networks. Many methods have been devised over the last decade for detection of communities. Amongst them, the label propagation algorithm brings great scalability together with high accuracy. However, it has one major flaw; when the community structure in the network is not clear enough, it will assign every node the same label, thus detecting the whole graph as one giant community. We have addressed this issue by setting a capacity for communities, starting from a small value and gradually increasing it over time. Preliminary results show that not only our extension improves the detection capability of classic label propagation algorithm when communities are not clearly detectable, but also improves the overall quality of the identified clusters in complex networks with a clear community structure.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Aria Rezaei, Saeed Mahlouji Far, Mahdieh Soleymani,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04693", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04693", "title": "\nMinimal Actuator Placement with Optimal Control Constraints", "abstract": "We introduce the problem of minimal actuator placement in a linear control system so that a bound on the minimum control effort for a given state transfer is satisfied while controllability is ensured. We first show that this is an NP-hard problem following the recent work of Olshevsky. Next, we prove that this problem has a supermodular structure. Afterwards, we provide an efficient algorithm that approximates up to a multiplicative factor of O(logn), where n is the size of the multi-agent network, any optimal actuator set that meets the specified energy criterion. Moreover, we show that this is the best approximation factor one can achieve in polynomial-time for the worst case. Finally, we test this algorithm over large Erdos-Renyi random networks to further demonstrate its efficiency.", "subjects": "Systems and Control (cs.SY)", "authors": "Vasileios Tzoumas, Mohammad Amin Rahimian, George J. Pappas, Ali Jadbabaie,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04688", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04688", "title": "\nSimple dynamics on graphs", "abstract": "Does the interaction graph of a finite dynamical system can force this system to have a \"complex\" dynamics ? In other words, given a finite interval of integers , which are the signed digraphs such that every finite dynamical system with as interaction graph has a \"complex\" dynamics ? If we prove that no such signed digraph exists. More precisely, we prove that for every signed digraph there exists a system with as interaction graph such that is a constant. The boolean case is more difficult, and we provide partial answers instead. We exhibit large classes of unsigned digraphs which admit boolean dynamical systems which converge in linear time. We also prove that any symmetric digraph, and any graph with a loop on each vertex admits a boolean dynamical system which converges in constant time.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Maximilien Gadouleau, Adrien Richard,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04673", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04673", "title": "\nA Memcomputing Pascaline", "abstract": "The original Pascaline was a mechanical calculator able to sum and subtract integers. It encodes information in the angles of mechanical wheels and through a set of gears, and aided by gravity, could perform the calculations. Here, we show that such a concept can be realized in electronics using memory elements such as memristive systems. By using memristive emulators we have demonstrated experimentally the memcomputing version of the mechanical Pascaline, capable of processing and storing the numerical results in the multiple levels of each memristive element. Our result is the first experimental demonstration of multidigit arithmetics with multi-level memory devices that further emphasizes the versatility and potential of memristive systems for future massively-parallel high-density computing architectures.", "subjects": "Emerging Technologies (cs.ET)", "authors": "Y. V. Pershin, L. K. Castelano, F. Hartmann, V. Lopez-Richard, M. Di Ventra,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04668", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04668", "title": "\nMode Selection in MU-MIMO Downlink Networks: A Physical Layer Security  Perspective", "abstract": "In this paper, we consider a homogenous multi-antenna downlink network where a passive eavesdropper intends to intercept the communication between a base station (BS) and multiple secure users (SU) over Rayleigh fading channels. In order to guarantee the security of information transfer, physical layer security is employed accordingly. For such a multiple user (MU) secure network, the number of accessing SUs, namely transmission mode, has a great impact on the secrecy performance. Specifically, on the one hand, a large number of accessing SUs will arise high inter-user interference at SUs, resulting in a reduction of the capacity of the legitimate channel. On the other hand, high inter-user interference will interfere with the eavesdropper and thus degrades the performance of the eavesdropper channel. Generally speaking, the harmful inter-user interference may be transformed as a useful tool of anti-eavesdropping. The focus of this paper is on selecting the optimal transmission mode according to channel conditions and system parameters, so as to maximize the sum secrecy outage capacity. Moreover, through asymptotic analysis, we present several simple mode selection schemes in some extreme cases. Finally, simulation results validate the effectiveness of the proposed mode selection schemes in MU secure communications.", "subjects": "Information Theory (cs.IT)", "authors": "Xiaoming Chen, Yu Zhang,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04643", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04643", "title": "\nTemplate-based Monocular 3D Shape Recovery using Laplacian Meshes", "abstract": "We show that by extending the Laplacian formalism, which was first introduced in the Graphics community to regularize 3D meshes, we can turn the monocular 3D shape reconstruction of a deformable surface given correspondences with a reference image into a much better-posed problem. This allows us to quickly and reliably eliminate outliers by simply solving a linear least squares problem. This yields an initial 3D shape estimate, which is not necessarily accurate, but whose 2D projections are. The initial shape is then refined by a constrained optimization problem to output the final surface reconstruction. Our approach allows us to reduce the dimensionality of the surface reconstruction problem without sacrificing accuracy, thus allowing for real-time implementations.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Dat Tien Ngo, Jonas Ostlund, Pascal Fua,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04628", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04628", "title": "\nLogic BIST: State-of-the-Art and Open Problems", "abstract": "Many believe that in-field hardware faults are too rare in practice to justify the need for Logic Built-In Self-Test (LBIST) in a design. Until now, LBIST was primarily used in safety-critical applications. However, this may change soon. First, even if costly methods like burn-in are applied, it is no longer possible to get rid of all latent defects in devices at leading-edge technology. Second, demands for high reliability spread to consumer electronics as smartphones replace our wallets and IDs. However, today many ASIC vendors are reluctant to use LBIST. In this paper, we describe the needs for successful deployment of LBIST in the industrial practice and discuss how these needs can be addressed. Our work is hoped to attract a wider attention to this important research topic.", "subjects": "Hardware Architecture (cs.AR)", "authors": "Nan Li, Gunnar Carlsson, Elena Dubrova, Kim Petersen,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04624", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04624", "title": "\nImage Watermaking With Biometric Data For Copyright Protection", "abstract": "In this paper, we deal with the proof of ownership or legitimate usage of a digital content, such as an image, in order to tackle the illegitimate copy. The proposed scheme based on the combination of the watermark-ing and cancelable biometrics does not require a trusted third party, all the exchanges are between the provider and the customer. The use of cancelable biometrics permits to provide a privacy compliant proof of identity. We illustrate the robustness of this method against intentional and unintentional attacks of the watermarked content.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Morgan Barbier, Jean-Marie Le Bars, Christophe Rosenberger,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04609", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04609", "title": "\nEnergy-Efficient Power Control: A Look at 5G Wireless Technologies", "abstract": "This work develops power control algorithms for bit/Joule energy efficiency (EE) maximization in wireless networks. Unlike previous related works, minimum-rate constraints are imposed and the signal-to-interference-plus-noise ratio takes a more general expression which encompasses some of the most promising 5G candidate technologies. Both network-centric and user-centric EE maximizations are considered. In the first scenario, the maximization of the global EE and of the minimum EE of the network are performed. Unlike previous contributions, centralized algorithms are developed which are guaranteed to converge with limited computational complexity to Karush-Kuhn-Tucker points of the considered, non-convex optimization problems. Moreover, closed-form feasibility conditions are derived. In the user-centric scenario, game theory is used to study the equilibria of the network and to derive convergent power control algorithms, which can be implemented in a fully decentralized fashion. Both scenarios above are studied under the assumption that single or multiple resource blocks are employed for data transmission. Numerical results are provided to assess the performance of the proposed solutions and to make comparisons in different settings.", "subjects": "Information Theory (cs.IT)", "authors": "Alessio Zappone, Luca Sanguinetti, Giacomo Bacci, Eduard Jorswieck, M\u00e9rouane Debbah,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04608", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04608", "title": "\nVariability Abstractions: Trading Precision for Speed in Family-Based  Analyses (Extended Version)", "abstract": "Family-based (lifted) data-flow analysis for Software Product Lines (SPLs) is capable of analyzing all valid products (variants) without generating any of them explicitly. It takes as input only the common code base, which encodes all variants of a SPL, and produces analysis results corresponding to all variants. However, the computational cost of the lifted analysis still depends inherently on the number of variants (which is exponential in the number of features, in the worst case). For a large number of features, the lifted analysis may be too costly or even infeasible. In this paper, we introduce variability abstractions defined as Galois connections and use abstract interpretation as a formal method for the calculational-based derivation of approximate (abstracted) lifted analyses of SPL programs, which are sound by construction. Moreover, given an abstraction we define a syntactic transformation that translates any SPL program into an abstracted version of it, such that the analysis of the abstracted SPL coincides with the corresponding abstracted analysis of the original SPL. We implement the transformation in a tool, reconfigurator that works on Object-Oriented Java program families, and evaluate the practicality of this approach on three Java SPL benchmarks.", "subjects": "Programming Languages (cs.PL)", "authors": "Aleksandar S. Dimovski, Claus Brabrand, Andrzej W\u0105sowski,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04604", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04604", "title": "\nMulti-Antenna Wireless Energy Transfer for Backscatter Communication  Systems", "abstract": "We study RF-enabled wireless energy transfer (WET) via energy beamforming, from a multi-antenna energy transmitter (ET) to multiple energy receivers (ERs) in a backscatter communication system, such as RFID, where each ER (or RFID tag) reflects back a portion of the incident signal to the ET (or RFID reader). For such a system, the acquisition of the forward-channel (i.e., ET-to-ER) state information (F-CSI) at the ET is challenging, since the ERs are typically too energy-and-hardware-constrained to estimate or feed back the F-CSI. The ET leverages its observed backscatter signals to estimate the backscatter-channel (i.e., ET-to-ER-to-ET) state information (BS-CSI) directly. We first analyze the harvested energy obtained by using the estimated BS-CSI. Furthermore, we optimize the channel-training energy and the energy allocation weights for different energy beams, for weighted-sum-energy (WSE) maximization and proportional-fair-energy (PFE) maximization. For WET to single ER, we obtain the optimal channel-training energy in a semi-closed form. For WET to multiple ERs, the optimal WET scheme for WSE maximization is shown to use only one energy beam. For PFE maximization, we show it is a biconvex problem, and propose a block-coordinate-descent based algorithm to find the close-to-optimal solution. Numerical results show that with the optimized solutions, the harvested energy suffers slight reduction of less than 10%, compared to that obtained by using the perfect F-CSI. Hence, energy beamforming by using the estimated BS-CSI is promising, as the complexity and energy requirement is shifted from the ERs to the ET.", "subjects": "Information Theory (cs.IT)", "authors": "Gang Yang, Chin Keong Ho, Yong Liang Guan,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04599", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04599", "title": "\nUsing Twitter to Predict Sales: A Case Study", "abstract": "This paper studies the relation between activity on Twitter and sales. While research exists into the relation between Tweets and movie and book sales, this paper shows that the same relations do not hold for products that receive less attention on social media. For such products, classification of Tweets is far more important to determine a relation. Also, for such products advanced statistical relations, in addition to correlation, are required to relate Twitter activity and sales. In a case study that involves Tweets and sales from a company in four countries, the paper shows how, by classifying Tweets, such relations can be identified. In particular, the paper shows evidence that positive Tweets by persons (as opposed to companies) can be used to forecast sales and that peaks in positive Tweets by persons are strongly related to an increase in sales. These results can be used to improve sales forecasts and to increase sales in marketing campaigns.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Remco Dijkman, Panagiotis Ipeirotis, Freek Aertsen, Roy van Helden,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04598", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04598", "title": "\nPiMPeR: Piecewise Dense 3D Reconstruction from Multi-View and  Multi-Illumination Images", "abstract": "In this paper, we address the problem of dense 3D reconstruction from multiple view images subject to strong lighting variations. In this regard, a new piecewise framework is proposed to explicitly take into account the change of illumination across several wide-baseline images. Unlike multi-view stereo and multi-view photometric stereo methods, this pipeline deals with wide-baseline images that are uncalibrated, in terms of both camera parameters and lighting conditions. Such a scenario is meant to avoid use of any specific imaging setup and provide a tool for normal users without any expertise. To the best of our knowledge, this paper presents the first work that deals with such unconstrained setting. We propose a coarse-to-fine approach, in which a coarse mesh is first created using a set of geometric constraints and, then, fine details are recovered by exploiting photometric properties of the scene. Augmenting the fine details on the coarse mesh is done via a final optimization step. Note that the method does not provide a generic solution for multi-view photometric stereo problem but it relaxes several common assumptions of this problem. The approach scales very well in size given its piecewise nature, dealing with large scale optimization and with severe missing data. Experiments on a benchmark dataset Robot data-set show the method performance against 3D ground truth.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Reza Sabzevari, Vittori Murino, Alessio Del Bue,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.04596", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04596", "title": "\nEnhanced Image Classification With a Fast-Learning Shallow Convolutional  Neural Network", "abstract": "We present a neural network architecture and training method designed to enable very rapid training and low implementation complexity. Due to its training speed and very few tunable parameters, the method has strong potential for embedded hardware applications requiring frequent retraining or online training. The approach is characterized by (a) convolutional filters based on biologically inspired visual processing filters, (b) randomly-valued classifier-stage input weights, (c) use of least squares regression to train the classifier output weights in a single batch, and (d) linear classifier-stage output units. We demonstrate the efficacy of the method as an image classifier, obtaining state-of-the-art results on the MNIST (0.37% error) and NORB-small (2.2%) image classification databases, with very fast training times compared to standard deep network approaches. The network's performance on the Google Street View House Number (SVHN) (4%) database is also competitive with state-of-the art methods.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "Mark D. McDonnell, Tony Vladusich,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04593", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04593", "title": "\nComparing Distance Bounding Protocols: a Critical Mission Supported by  Decision Theory", "abstract": "Distance bounding protocols are security countermeasures designed to thwart relay attacks. Such attacks consist in relaying messages exchanged between two parties, making them believe they communicate directly with each other. Although distance bounding protocols have existed since the early nineties, this research topic resurrected with the deployment of contactless systems, against which relay attacks are particularly impactful. Given the impressive number of distance bounding protocols that are designed every year, it becomes urgent to provide researchers and engineers with a methodology to fairly compare the protocols in spite of their various properties. This paper introduces such a methodology based on concepts from the decision making field. The methodology allows for a multi-criteria comparison of distance bounding protocols, thereby identifying the most appropriate protocols once the context is provided. As a side effect, this paper clearly identifies the protocols that should no longer be considered, regardless of the considered scenario.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Gildas Avoine, Sjouke Mauw, Rolando Trujillo-Rasua,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04576", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04576", "title": "\nAutonomic Resource Management in Virtual Networks", "abstract": "Virtualization enables the building of multiple virtual networks over a shared substrate. One of the challenges to virtualisation is efficient resource allocation. This problem has been found to be NP hard. Therefore, most approaches to it have not only proposed static solutions, but have also made many assumptions to simplify it. In this paper, we propose a distributed, autonomic and artificial intelligence based solution to resource allocation. Our aim is to obtain self-configuring, selfoptimizing, self-healing and context aware virtual networks", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Rashid Mijumbi, Joan Serrat, Juan-Luis Gorricho,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04575", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04575", "title": "\nThe Least-core and Nucleolus of Path Cooperative Games", "abstract": "Cooperative games provide an appropriate framework for fair and stable profit distribution in multiagent systems. In this paper, we study the algorithmic issues on path cooperative games that arise from the situations where some commodity flows through a network. In these games, a coalition of edges or vertices is successful if it enables a path from the source to the sink in the network, and lose otherwise. Based on dual theory of linear programming and the relationship with flow games, we provide the characterizations on the CS-core, least-core and nucleolus of path cooperative games. Furthermore, we show that the least-core and nucleolus are polynomially solvable for path cooperative games defined on both directed and undirected network.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Qizhi Fang, Bo Li, Xiaohan Shan, Xiaoming Sun,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04567", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04567", "title": "\nLearning Mixed Membership Community Models in Social Tagging Networks  through Tensor Methods", "abstract": "Community detection in graphs has been extensively studied both in theory and in applications. However, detecting communities in hypergraphs is more challenging. In this paper, we propose a tensor decomposition approach for guaranteed learning of communities in a special class of hypergraphs modeling social tagging systems or folksonomies. A folksonomy is a tripartite 3-uniform hypergraph consisting of (user, tag, resource) hyperedges. We posit a probabilistic mixed membership community model, and prove that the tensor method consistently learns the communities under efficient sample complexity and separation requirements.", "subjects": "Learning (cs.LG)", "authors": "Anima Anandkumar, Hanie Sedghi,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04533", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04533", "title": "\nRadio Co-location Aware Channel Assignment for Interference Mitigation  in Wireless Mesh Networks", "abstract": "Designing high performance channel assignment schemes to harness the potential of multi-radio multi-channel deployments in wireless mesh networks (WMNs) is an active research domain. A pragmatic channel assignment approach strives to maximize network capacity by restraining the endemic interference and mitigating its adverse impact on network performance metrics. Interference prevalent in WMNs is multi-dimensional, radio co-location interference being a crucial aspect that is seldom addressed in research endeavors. In this effort we propose a set of intelligent channel assignment algorithms, which focus primarily on alleviating it. These graph theoretic schemes are structurally inspired by the spatio-statistical characteristics of interference. We present the theoretical design foundations for each of the proposed algorithms, and demonstrate their potential to significantly enhance network capacity, by over 175% in comparison to some existing well-known schemes. We also demonstrate the adverse impact of radio co-location interference on the network, and the efficacy of the proposed schemes in successfully mitigating it. The experimental results to validate the proposed theoretical notions were obtained by running an exhaustive set of NS-3 simulations on an IEEE 802.11 testbed.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Srikant Manas Kala, M Pavan Kumar Reddy, Ranadheer Musham, Bheemarjuna Reddy Tamma,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.04522", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04522", "title": "\nReally Natural Linear Indexed Type Checking", "abstract": "Recent works have shown the power of linear indexed type systems for enforcing complex program properties. These systems combine linear types with a language of type-level indices, allowing more fine-grained analyses. Such systems have been fruitfully applied in diverse domains, including implicit complexity and differential privacy. A natural way to enhance the expressiveness of this approach is by allowing the indices to depend on runtime information, in the spirit of dependent types. This approach is used in DFuzz, a language for differential privacy. The DFuzz type system relies on an index language supporting real and natural number arithmetic over constants and variables. Moreover, DFuzz uses a subtyping mechanism to make types more flexible. By themselves, linearity, dependency, and subtyping each require delicate handling when performing type checking or type inference; their combination increases this challenge substantially, as the features can interact in non-trivial ways. In this paper, we study the type-checking problem for DFuzz. We show how we can reduce type checking for (a simple extension of) DFuzz to constraint solving over a first-order theory of naturals and real numbers which, although undecidable, can often be handled in practice by standard numeric solvers.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Arthur Azevedo de Amorim, Emilio Jes\u00fas Gallego Arias, Marco Gaboardi, Justin Hsu,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04502", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04502", "title": "\nThe Simulation Powers and Limitations of Higher Temperature Hierarchical  Self-Assembly Systems", "abstract": "In this paper, we extend existing results about simulation and intrinsic universality in a model of tile-based self-assembly. Namely, we work within the 2-Handed Assembly Model (2HAM), which is a model of self-assembly in which assemblies are formed by square tiles that are allowed to combine, using glues along their edges, individually or as pairs of arbitrarily large assemblies in a hierarchical manner, and we explore the abilities of these systems to simulate each other when the simulating systems have a higher \"temperature\" parameter, which is a system wide threshold dictating how many glue bonds must be formed between two assemblies to allow them to combine. It has previously been shown that systems with lower temperatures cannot simulate arbitrary systems with higher temperatures, and also that systems at some higher temperatures can simulate those at particular lower temperatures, creating an infinite set of infinite hierarchies of 2HAM systems with strictly increasing simulation power within each hierarchy. These previous results relied on two different definitions of simulation, one (strong simulation) seemingly more restrictive than the other (standard simulation), but which have previously not been proven to be distinct. Here we prove distinctions between them by first fully characterizing the set of pairs of temperatures such that the high temperature systems are intrinsically universal for the lower temperature systems (i.e. one tile set at the higher temperature can simulate any at the lower) using strong simulation. This includes the first impossibility result for simulation downward in temperature. We then show that lower temperature systems which cannot be simulated by higher temperature systems using the strong definition, can in fact be simulated using the standard definition, proving the distinction between the types of simulation.", "subjects": "Computational Geometry (cs.CG)", "authors": "Jacob Hendricks, Matthew J. Patitz, Trent A. Rogers,", "date": "2015-3-16"}, 
{"urllink": "http://arxiv.org/abs/1503.04486", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04486", "title": "\nThe complexity of computing the minimum rank of a sign pattern matrix", "abstract": "We show that computing the minimum rank of a sign pattern matrix is NP hard. Our proof is based on a simple but useful connection between minimum ranks of sign pattern matrices and the stretchability problem for pseudolines arrangements. In fact, our hardness result shows that it is already hard to determine if the minimum rank of a sign pattern matrix is . We complement this by giving a polynomial time algorithm for determining if a given sign pattern matrix has minimum rank . Our result answers one of the open problems from Linial et al. [Combinatorica, 27(4):439--463, 2007].", "subjects": "Computational Complexity (cs.CC)", "authors": "Amey Bhangale, Swastik Kopparty,", "date": "2015-3-15"}, 
{"urllink": "http://arxiv.org/abs/1503.04476", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04476", "title": "\nStructural Cohesion: Visualization and Heuristics for Fast Computation", "abstract": "The structural cohesion model is a powerful theoretical conception of cohesion in social groups, but its diffusion in empirical literature has been hampered by operationalization and computational problems. In this paper we start from the classic definition of structural cohesion as the minimum number of actors who need to be removed in a network in order to disconnect it, and extend it by using average node connectivity as a finer grained measure of cohesion. We present useful heuristics for computing structural cohesion that allow a speed-up of one order of magnitude over the algorithms currently available. We analyze three large collaboration networks (co-maintenance of Debian packages, co-authorship in Nuclear Theory and High-Energy Theory) and show how our approach can help researchers measure structural cohesion in relatively large networks. We also introduce a novel graphical representation of the structural cohesion analysis to quickly spot differences across networks.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Jordi Torrents, Fabrizio Ferraro,", "date": "2015-3-15"}, 
{"urllink": "http://arxiv.org/abs/1503.04475", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04475", "title": "\nSimulation of Genetic Algorithm: Traffic Light Efficiency", "abstract": "Traffic is a problem in many urban areas worldwide. Traffic flow is dictated by certain devices such as traffic lights. The traffic lights signal when each lane is able to pass through the intersection. Often, static schedules interfere with ideal traffic flow. The purpose of this project was to find a way to make intersections controlled with traffic lights more efficient. This goal was accomplished through the creation of a genetic algorithm, which enhances an input algorithm through genetic principles to produce the fittest algorithm. The program was comprised of two major elements: coding in Java and coding in Simulation of Urban Mobility (SUMO), which is an environment that simulates real traffic. The Java code called upon the SUMO simulation via a command prompt which ran the simulation, received the output, altered the algorithm, and looped. The SUMO component initialized a simulation in which a 1 x 1 street layout was created, each intersection with its own traffic light. Each loop enhanced the input algorithm by altering the scheduling string (dictates the light changes). After the looped simulations were executed, the data was then analyzed. This was accomplished by creating an algorithm based upon regular practice, timed traffic lights, and comparing the output which was comprised of the total time it took for all vehicles to exit the system and the average time it took each individual vehicle to exit the system. These different variables: the time it took the average vehicle to exit the system and total time for all vehicles to exit the system, where then graphed together to provide a visual aid. The genetic algorithm did improve traffic light and traffic flow efficiency in comparison to traditional scheduling methods.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "Eric Lienert,", "date": "2015-3-15"}, 
{"urllink": "http://arxiv.org/abs/1503.04473", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04473", "title": "\nGuarding Networks Through Heterogeneous Mobile Guards", "abstract": "In this article, the issue of guarding multi-agent systems against a sequence of intruder attacks through mobile heterogeneous guards (guards with different ranges) is discussed. The article makes use of graph theoretic abstractions of such systems in which agents are the nodes of a graph and edges represent interconnections between agents. Guards represent specialized mobile agents on specific nodes with capabilities to successfully detect and respond to an attack within their guarding range. Using this abstraction, the article addresses the problem in the context of eternal security problem in graphs. Eternal security refers to securing all the nodes in a graph against an infinite sequence of intruder attacks by a certain minimum number of guards. This paper makes use of heterogeneous guards and addresses all the components of the eternal security problem including the number of guards, their deployment and movement strategies. In the proposed solution, a graph is decomposed into clusters and a guard with appropriate range is then assigned to each cluster. These guards ensure that all nodes within their corresponding cluster are being protected at all times, thereby achieving the eternal security in the graph.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Waseem Abbas, Sajal Bhatia, Xenofon Koutsoukos,", "date": "2015-3-15"}, 
{"urllink": "http://arxiv.org/abs/1503.04444", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04444", "title": "\nPattern Recognition of Bearing Faults using Smoother Statistical  Features", "abstract": "A new diagnostic scheme is presented for ball bearing localized faults, which utilizes preprocessed time domain features based pattern recognition (PR). Vibration data is acquired from faulty bearings using a test rig, and the features are extracted from the data segments that are preprocessed prior to use in the fault classification process. The preprocessing involves smoothing of the features, which reduces the undesired impact of noise and vibration randomness on the PR process, and thus enhances the diagnostic accuracy. The results are compared with a similar scheme in terms of minimum features requirement to achieve an optimum classification accuracy, and the feature processing based proposed scheme provides better results.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Muhammad Masood Tahir, Ayyaz Hussain,", "date": "2015-3-15"}, 
{"urllink": "http://arxiv.org/abs/1503.04426", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04426", "title": "\nAn Improved Pseudo-Polynomial Upper Bound for the Value Problem and  Optimal Strategy Synthesis in Mean Payoff Games", "abstract": "We prove the existence of a pseudo-polynomial O(|V |^2 |E| W) time algorithm for the Value Problem and Optimal Strategy Synthesis in Mean Payoff Games. This improves by a factor log(|V | W) over the best previously known pseudo-polynomial upper bound due to Brim et al. (2011). The result is achieved by providing a suitable characterization of values and optimal strategies in terms of reweighted arenas and Farey sequences.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Carlo Comin, Romeo Rizzi,", "date": "2015-3-15"}, 
{"urllink": "http://arxiv.org/abs/1503.04424", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04424", "title": "\nBridging Social Media via Distant Supervision", "abstract": "Microblog classification has received a lot of attention in recent years. Different classification tasks have been investigated, most of them focusing on classifying microblogs into a small number of classes (five or less) using a training set of manually annotated tweets. Unfortunately, labelling data is tedious and expensive, and finding tweets that cover all the classes of interest is not always straightforward, especially when some of the classes do not frequently arise in practice. In this paper we study an approach to tweet classification based on distant supervision, whereby we automatically transfer labels from one social medium to another for a single-label multi-class classification task. In particular, we apply YouTube video classes to tweets linking to these videos. This provides for free a virtually unlimited number of labelled instances that can be used as training data. The classification experiments we have run show that training a tweet classifier via these automatically labelled data achieves substantially better performance than training the same classifier with a limited amount of manually labelled data; this is advantageous, given that the automatically labelled data come at no cost. Further investigation of our approach shows its robustness when applied with different numbers of classes and across different languages.", "subjects": "Information Retrieval (cs.IR)", "authors": "Walid Magdy, Hassan Sajjad, Tarek El-Ganainy, Fabrizio Sebastiani,", "date": "2015-3-15"}, 
{"urllink": "http://arxiv.org/abs/1503.04422", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04422", "title": "\nMaking Availability as a Service in the Clouds", "abstract": "Cloud computing has achieved great success in modern IT industry as an excellent computing paradigm due to its flexible management and elastic resource sharing. To date, cloud computing takes an irrepalceable position in our socioeconomic system and influences almost every aspect of our daily life. However, it is still in its infancy, many problems still exist.Besides the hotly-debated security problem, availability is also an urgent issue.With the limited power of availability mechanisms provided in present cloud platform, we can hardly get detailed availability information of current applications such as the root causes of availability problem,mean time to failure, etc. Thus a new mechanism based on deep avaliability analysis is neccessary and benificial.Following the prevalent terminology 'XaaS',this paper proposes a new win-win concept for cloud users and providers in term of 'Availability as a Service' (abbreviated as 'AaaS').The aim of 'AaaS' is to provide comprehensive and aimspecific runtime avaliabilty analysis services for cloud users by integrating plent of data-driven and modeldriven approaches. To illustrate this concept, we realize a prototype named 'EagleEye' with all features of 'AaaS'. By subscribing corresponding services in 'EagleEye', cloud users could get specific availability information of their applications deployed in cloud platform. We envision this new kind of service will be merged into the cloud management mechanism in the near future.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Pengfei Chen, Yong Qi, Peipei Wang, Li Su, Xinyi Li,", "date": "2015-3-15"}, 
{"urllink": "http://arxiv.org/abs/1503.04404", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04404", "title": "\nPredicting Item Popularity: Analysing Local Clustering Behaviour of  Users", "abstract": "Predicting the popularity of items in rating networks is an interesting but challenging problem. This is especially so when an item has first appeared and has received very few ratings. In this paper, we propose a novel approach to predicting the future popularity of new items in rating networks, defining a new bipartite clustering coefficient to predict the popularity of movies in the MovieLens network. We show that the clustering behaviour of the first user who rates a new item gives insight into the future popularity of that item. Our method predicts, with a success rate of over 60 %, how popular a movie will become in the future.", "subjects": "Social and Information Networks (cs.SI)", "authors": "J. Liebig, A. Rao,", "date": "2015-3-15"}, 
{"urllink": "http://arxiv.org/abs/1503.04385", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04385", "title": "\nDesign and Implementation of Database Independent Auto Sequence Numbers", "abstract": "Developers across the world use autonumber or auto sequences field of the backend databases for developing both the desktop and web based data centric applications which is easier to use at the development and deployment purpose but can create a lot of problems under varied situations. This paper examines how a database independent autonumber could be developed and reused solving all the problems as well as providing the same degree of easy to use features of autonumber offered by modern Relational Database Systems.", "subjects": "Databases (cs.DB)", "authors": "Kisor Ray,", "date": "2015-3-15"}, 
{"urllink": "http://arxiv.org/abs/1503.04381", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04381", "title": "\nRelay Control for Full-Duplex Relaying with Wireless Information and  Energy Transfer", "abstract": "This paper investigates the wireless information and energy transfer for the dual-hop amplify-and-forward full-duplex relaying system. By considering the time switching relay transceiver architecture, the full duplex information relaying is powered via the energy harvested from the source-emitted radio frequency signal. The throughput performances of three relay control schemes, namely, the maximum relay gain, the optimal relay gain, and the target relay gain are investigated. The analytical expressions for the outage probability and the ergodic capacity are presented for all the three relay control schemes. The time switching factors for the optimal relay gain and the target relay gain are, respectively, presented in closed-form. The analytical and numerical results show that the optimal relay gain and the target relay gain achieve better outage performances than the maximum relay gain. The optimal relay gain achieves a higher ergodic capacity than that of the maximum relay gain in high signal-to-noise ratios, while the target relay gain achieves a competitive ergodic capacity without requiring the second-hop channel condition. Compared with the maximum relay gain employing the numerically optimized time switching, the competitive throughput performances are achieved by the optimal relay gain and the target relay gain, respectively. It also observes that when the relay is placed in the middle of the source and the destination, the maximum relay gain and the optimal relay gain achieve the relatively worse throughput performance, while the throughput decreases dramatically for the target relay gain when the relay moves from the source towards the destination.", "subjects": "Information Theory (cs.IT)", "authors": "Hongwu Liu, Kyeong Jin Kim, Kyung Sup Kwak,", "date": "2015-3-15"}, 
{"urllink": "http://arxiv.org/abs/1503.04380", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04380", "title": "\nA Triangular Decomposition Algorithm for Differential Polynomial Systems  with Elementary Computation Complexity", "abstract": "In this paper, a new triangular decomposition algorithm is proposed for ordinary differential polynomial systems, which has triple exponential computational complexity. The key idea is to eliminate one algebraic variable from a set of polynomials in one step using the theory of multivariate resultant. This seems to be the first differential triangular decomposition algorithm with elementary computation complexity.", "subjects": "Symbolic Computation (cs.SC)", "authors": "Wei Zhu, Xiao-Shan Gao,", "date": "2015-3-15"}, 
{"urllink": "http://arxiv.org/abs/1503.04378", "category": "Computer Science ", "pdflink": "http://arxiv.org/html/1503.04378", "title": "\nProceedings 12th International Workshop on Formal Engineering approaches  to Software Components and Architectures", "abstract": "The aim of the FESCA workshop is to bring together junior researchers from formal methods, software engineering, and industry interested in the development and application of formal modelling approaches as well as associated analysis and reasoning techniques with practical benefits for software engineering. In recent years, the growing importance of functional correctness and the increased relevance of system quality properties (e.g. performance, reliability, security) have stimulated the emergence of analytical and modelling techniques for the design and development of software systems. With the increasing complexity of today's software systems, FESCA aims at addressing two research questions: (1) what role the software architecture can play in systematic addressing of the analytical and modelling challenges, and (2) how formal and semi-formal techniques can be applied effectively to make the issues easier to address automatically, with lower human intervention.", "subjects": "Software Engineering (cs.SE)", "authors": "Bara Buhnova, Lucia Happe, Jan Kofro\u0148,", "date": "2015-3-15"}, 
{"urllink": "http://arxiv.org/abs/1503.04377", "category": "Computer Science ", "pdflink": "http://arxiv.org/html/1503.04377", "title": "\nProceedings Seventh Workshop on Intersection Types and Related Systems", "abstract": "This volume contains a final and revised selection of papers presented at the Seventh Workshop on Intersection Types and Related Systems (ITRS 2014), held in Vienna (Austria) on July 18th, affiliated with TLCA 2014, Typed Lambda Calculi and Applications (held jointly with RTA, Rewriting Techniques and Applications) as part of FLoC and the Vienna Summer of Logic (VSL) 2014. Intersection types have been introduced in the late 1970s as a language for describing properties of lambda calculus which were not captured by all previous type systems. They provided the first characterisation of strongly normalising lambda terms and have become a powerful syntactic and semantic tool for analysing various normalisation properties as well as lambda models. Over the years the scope of research on intersection types has broadened. Recently, there have been a number of breakthroughs in the use of intersection types and similar technology for practical purposes such as program analysis, verification and concurrency, and program synthesis. The aim of the ITRS workshop series is to bring together researchers working on both the theory and practical applications of systems based on intersection types and related approaches (e.g., union types, refinement types, behavioral types).", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Jakob Rehof,", "date": "2015-3-15"}, 
{"urllink": "http://arxiv.org/abs/1503.04375", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04375", "title": "\nOptimization of Switch Keyboards", "abstract": "Patients with motor control difficulties often \"type\" on a computer using a switch keyboard to guide a scanning cursor to text elements. We show how to optimize some parts of the design of switch keyboards by casting the design problem as mixed integer programming. A new algorithm to find an optimized design solution is approximately 3600 times faster than a previous algorithm, which was also susceptible to finding a non-optimal solution. The optimization requires a model of the probability of an entry error, and we show how to build such a model from experimental data. Example optimized keyboards are demonstrated.", "subjects": "Human-Computer Interaction (cs.HC)", "authors": "Xiao Zhang, Kan Fang, Gregory Francis,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.04374", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04374", "title": "\nScience Bots: a Model for the Future of Scientific Computation?", "abstract": "As a response to the trends of the increasing importance of computational approaches and the accelerating pace in science, I propose in this position paper to establish the concept of \"science bots\" that autonomously perform programmed tasks on input data they encounter and immediately publish the results. We can let such bots participate in a reputation system together with human users, meaning that bots and humans get positive or negative feedback by other participants. Positive reputation given to these bots would also shine on their owners, motivating them to contribute to this system, while negative reputation will allow us to filter out low-quality data, which is inevitable in an open and decentralized system.", "subjects": "Computers and Society (cs.CY)", "authors": "Tobias Kuhn,", "date": "2015-3-15"}, 
{"urllink": "http://arxiv.org/abs/1503.04371", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04371", "title": "\nUniform Random Number Generation from Markov Chains: Non-Asymptotic and  Asymptotic Analyses", "abstract": "In this paper, we derive non-asymptotic achievability and converse bounds on the random number generation with/without side-information. Our bounds are efficiently computable in the sense that the computational complexity does not depend on the block length. We also characterize the asymptotic behaviors of the large deviation regime and the moderate deviation regime by using our bounds, which implies that our bounds are asymptotically tight in those regimes. We also show the second order rates of those problems, and derive single letter forms of the variances characterizing the second order rates. Further, we address the equivocation rates for these problems.", "subjects": "Information Theory (cs.IT)", "authors": "Masahito Hayashi, Shun Watanabe,", "date": "2015-3-15"}, 
{"urllink": "http://arxiv.org/abs/1503.04359", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04359", "title": "\nAccelerating Direction-Optimized Breadth First Search on Hybrid  Architectures", "abstract": "Large scale-free graphs are famously difficult to process efficiently: the highly skewed vertex degree distribution makes it difficult to obtain balanced workload partitions for parallel processing. Our research instead aims to take advantage of vertex degree heterogeneity by partitioning the workload to match the strength of the individual computing elements in a hybrid architecture. This paper extends the direction-optimized breadth first search algorithm to work efficiently on hybrid, GPU-accelerated platforms. We present the key graph partitioning, workload allocation, and communication strategies required for massive concurrency and good overall performance. We show that exploiting specialization enables gains as high as 2.4x in terms of time-to-solution and 2.0x in terms of energy efficiency by adding 2 GPUs to a 2 CPU-only baseline, for synthetic graphs with up to 16 Billion undirected edges as well as for real-world graphs. We also show that, for a capped energy envelope, it is more efficient to add a GPU than an additional CPU.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Scott Sallinen, Abdullah Gharaibeh, Matei Ripeanu,", "date": "2015-3-14"}, 
{"urllink": "http://arxiv.org/abs/1503.04358", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04358", "title": "\nAriadne's Thread - Interactive Navigation in a World of Networked  Information", "abstract": "This work-in-progress paper introduces an interface for the interactive visual exploration of the context of queries using the ArticleFirst database, a product of OCLC. We describe a workflow which allows the user to browse live entities associated with 65 million articles. In the on-line interface, each query leads to a specific network representation of the most prevailing entities: topics (words), authors, journals and Dewey decimal classes linked to the set of terms in the query. This network represents the context of a query. Each of the network nodes is clickable: by clicking through, a user traverses a large space of articles along dimensions of authors, journals, Dewey classes and words simultaneously. We present different use cases of such an interface. This paper provides a link between the quest for maps of science and on-going debates in HCI about the use of interactive information visualisation to empower users in their search.", "subjects": "Digital Libraries (cs.DL)", "authors": "Rob Koopman, Shenghui Wang, Andrea Scharnhorst, Gwenn Englebienne,", "date": "2015-3-14"}, 
{"urllink": "http://arxiv.org/abs/1503.04347", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04347", "title": "\nMutual Visibility by Luminous Robots Without Collisions", "abstract": "Consider a finite set of identical computational entities that can move freely in the Euclidean plane operating in Look-Compute-Move cycles. Let p(t) denote the location of entity p at time t; entity p can see entity q at time t if at that time no other entity lies in the line segment p(t)q(t). We consider the basic problem called Mutual Visibility: starting from arbitrary distinct locations, within finite time the entities must reach, without collisions, a configuration where they all see each other. This problem must be solved by each entity autonomously executing the same algorithm. We study this problem in the \"luminous robots\" model; in this generalization of the standard model of oblivious robots, each entity, called \"robot\", has an externally visible persistent light which can assume colors from a fixed set. The case where the number of colors is c=1 corresponds to the classical model without lights. In this paper we investigate under what conditions luminous robots can solve Mutual Visibility without collisions and at what cost (i.e., with how many colors). We establish a spectrum of results, depending on the power of the adversary, on the number c of colors, and on the a-priori knowledge the robots have about the system. Among such results, we prove that Mutual Visibility can always be solved without collisions in SSynch with c=2 colors and in ASynch with c=3 colors. If an adversary can interrupt and stop a robot moving to its computed destination, Mutual Visibility is still always solvable without collisions in SSynch with c=3 colors, and, if the robots agree on the direction of one axis, also in ASynch. All the results are obtained constructively by means of novel protocols. As a byproduct of our solutions, we provide the first obstructed-visibility solutions to two classical problems for oblivious robots: Collision-less Convergence to a point and Circle Formation.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "G.A. Di Luna, P. Flocchini, S. Gan Chaudhuri, F. Poloni, N. Santoro, G. Viglietta,", "date": "2015-3-14"}, 
{"urllink": "http://arxiv.org/abs/1503.04344", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04344", "title": "\nDeposit subscribe Prediction using Data Mining Techniques based Real  Marketing Dataset", "abstract": "Recently, economic depression, which scoured all over the world, affects business organizations and banking sectors. Such economic pose causes a severe attrition for banks and customer retention becomes impossible. Accordingly, marketing managers are in need to increase marketing campaigns, whereas organizations evade both expenses and business expansion. In order to solve such riddle, data mining techniques is used as an uttermost factor in data analysis, data summarizations, hidden pattern discovery, and data interpretation. In this paper, rough set theory and decision tree mining techniques have been implemented, using a real marketing data obtained from Portuguese marketing campaign related to bank deposit subscription [Moro et al., 2011]. The paper aims to improve the efficiency of the marketing campaigns and helping the decision makers by reducing the number of features, that describes the dataset and spotting on the most significant ones, and predict the deposit customer retention criteria based on potential predictive rules.", "subjects": "Databases (cs.DB)", "authors": "Safia Abbas,", "date": "2015-3-14"}, 
{"urllink": "http://arxiv.org/abs/1503.04334", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04334", "title": "\nQuantum Decoding with Venn Diagrams", "abstract": "The quantum error correction theory is as a rule formulated in a rather convoluted way, in comparison to classical algebraic theory. This work revisits the error correction in a noisy quantum channel so as to make it intelligible to engineers. An illustrative example is presented of a naive perfect quantum code (Hamming-like code) with five-qubits for transmitting a single qubit of information. Also the (9,1)-Shor codes is addressed.", "subjects": "Information Theory (cs.IT)", "authors": "C.M.F. Barros, Francisco Marcos de Assis, H.M. de Oliveira,", "date": "2015-3-14"}, 
{"urllink": "http://arxiv.org/abs/1503.04333", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04333", "title": "\nDynamic Move Chains and Move Tables in Computer Chess", "abstract": "The idea of dynamic move chains has been described in a preceding paper [6]. It allows the search tree to be forward-pruned, which is known to be dangerous, because that can remove important moves which would only be evaluated through a more exhaustive search process. This paper has added to the forward-pruning technique, through the use of 'Move Tables' that can act in the same way as Transposition Tables, but for moves not positions. They use an efficient memory structure and have put the design into the context of short or long-term memories. These can allow the search to be broadened, making it more reliable and are relatively independent, allowing some configuration as to how much to use. It has advanced some of the future work theory of the earlier paper and made more explicit where logical plans or more knowledge-based approaches might be applied.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Kieran Greer,", "date": "2015-3-14"}, 
{"urllink": "http://arxiv.org/abs/1503.04320", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04320", "title": "\nUsing models to model-check recursive schemes", "abstract": "We propose a model-based approach to the model checking problem for recursive schemes. Since simply typed lambda calculus with the fixpoint operator, lambda-Y-calculus, is equivalent to schemes, we propose the use of a model of lambda-Y-calculus to discriminate the terms that satisfy a given property. If a model is finite in every type, this gives a decision procedure. We provide a construction of such a model for every property expressed by automata with trivial acceptance conditions and divergence testing. Such properties pose already interesting challenges for model construction. Moreover, we argue that having models capturing some class of properties has several other virtues in addition to providing decidability of the model-checking problem. As an illustration, we show a very simple construction transforming a scheme to a scheme reflecting a property captured by a given model.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Sylvain Salvati, Igor Walukiewicz,", "date": "2015-3-14"}, 
{"urllink": "http://arxiv.org/abs/1503.04317", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04317", "title": "\nHybridTE: Traffic Engineering for Very Low-Cost Software-Defined  Data-Center Networks", "abstract": "The size of modern data centers is constantly increasing. As it is not economic to interconnect all machines in the data center using a full-bisection-bandwidth network, techniques have to be developed to increase the efficiency of data-center networks. The Software-Defined Network paradigm opened the door for centralized traffic engineering (TE) in such environments. Up to now, there were already a number of TE proposals for SDN-controlled data centers that all work very well. However, these techniques either use a high amount of flow table entries or a high flow installation rate that overwhelms available switching hardware, or they require custom or very expensive end-of-line equipment to be usable in practice. We present HybridTE, a TE technique that uses (uncertain) information about large flows. Using this extra information, our technique has very low hardware requirements while maintaining better performance than existing TE techniques. This enables us to build very low-cost, high performance data-center networks.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Philip Wette, Holger Karl,", "date": "2015-3-14"}, 
{"urllink": "http://arxiv.org/abs/1503.04315", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04315", "title": "\nDesigning and Building a Three-dimensional Projective Scanner for  Smartphones", "abstract": "One of the frustrating things in the digital fabrication era is that its media are neither affordable nor easily accessible and usable. Three-dimensional (3D) fabrication media (DFM) such as 3D Printers and 3D Scanners have experienced an upsurge in popularity, while the latter remain expensive and hard to function. With this paper, we aim to present you the RhoScanner Project - a an affordable and efficient Three-dimensional Projective Scanner for Smart-phones, hence shedding light on the extended capabilities of digital fabrication media on popular use.", "subjects": "Other Computer Science (cs.OH)", "authors": "Marios Papachristou,", "date": "2015-3-14"}, 
{"urllink": "http://arxiv.org/abs/1503.04304", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04304", "title": "\nLaplace's rule of succession in information geometry", "abstract": "Laplace's \"add-one\" rule of succession modifies the observed frequencies in a sequence of heads and tails by adding one to the observed counts. This improves prediction by avoiding zero probabilities and corresponds to a uniform Bayesian prior on the parameter. The canonical Jeffreys prior corresponds to the \"add-one-half\" rule. We prove that, for exponential families of distributions, such Bayesian predictors can be approximated by taking the average of the maximum likelihood predictor and the emph predictor from information theory. Thus in this case it is possible to approximate Bayesian predictors without the cost of integrating or sampling in parameter space.", "subjects": "Information Theory (cs.IT)", "authors": "Yann Ollivier,", "date": "2015-3-14"}, 
{"urllink": "http://arxiv.org/abs/1503.04288", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04288", "title": "\nA Proposal for a Nationwide Student Gradebook Information Network", "abstract": "Todays students are encouraged to study and develop expertise in more than one national academic environment. As a matter of fact, their educational activities inevitably occur in a variety of academic settings and even span several years. Consequently students academic results and progress are expected to be easily monitored and accessed nationally. The authors of the present paper have devised a student gradebook information network to be nationally employed by all public and private universities and colleges. The papers deals with the architectural principles underlying the system and discusses aspects related to data collection, data analysis and data storage across multiple machines while providing a seamless view of entire infrastructure and service delivery system from a single Web access point. The utility of the architectural system is discussed in relationship with its major advantages: user-friendliness, security access, flexibility, transparency, distributional power, and scalability. The major beneficiary of the system is the Romanian higher education system.", "subjects": "Computers and Society (cs.CY)", "authors": "Cristina Turcu, Cornel Turcu, Evelina Graur,", "date": "2015-3-14"}, 
{"urllink": "http://arxiv.org/abs/1503.04287", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04287", "title": "\nMetric Localization using Google Street View", "abstract": "Accurate metrical localization is one of the central challenges in mobile robotics. Many existing methods aim at localizing after building a map with the robot. In this paper, we present a novel approach that instead uses geotagged panoramas from the Google Street View as a source of global positioning. We model the problem of localization as a non-linear least squares estimation in two phases. The first estimates the 3D position of tracked feature points from short monocular camera sequences. The second computes the rigid body transformation between the Street View panoramas and the estimated points. The only input of this approach is a stream of monocular camera images and odometry estimates. We quantified the accuracy of the method by running the approach on a robotic platform in a parking lot by using visual fiducials as ground truth. Additionally, we applied the approach in the context of personal localization in a real urban scenario by using data from a Google Tango tablet.", "subjects": "Robotics (cs.RO)", "authors": "Pratik Agarwal, Wolfram Burgard, Luciano Spinello,", "date": "2015-3-14"}, 
{"urllink": "http://arxiv.org/abs/1503.04286", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04286", "title": "\nICT and RFID in Education: Some Practical Aspects in Campus Life", "abstract": "The paper summarizes our preliminary findings regarding the development and implementation of a newly proposed system based on ICT and RFID (Radio Frequency Identification) technologies for campus access and facility usage. It is generally acknowledged that any educational environment is highly dependent upon a wide range of resources or variables such as teaching staff, research and study areas, meeting and accommodation facilities, library services, restaurant and leisure facilities, etc. The system we have devised using ICT and RFID technologies supports not only authentic transactions among all university departments, but also interconnects all levels of academic life and activity. Thus, the utility of the system ranges from access control (student/ staff/ visitor identification), attendance tracking, library check-out services and voting to grade book consulting, inventory, cashless vending, parking, laundry and copying services. Physically, the system consists of several RFID gates/readers, a data server and some network stations, all of them requiring specific structuring and integration solutions. The system is quite different from already existing ones in that it proposes an innovative access solution. Thus, the search of the ID card holder in a database has been replaced by local processing. Since one and the same card is employed to perform a variety of operations, the system has immediate and numerous utilizations.", "subjects": "Computers and Society (cs.CY)", "authors": "Cristina Turcu, Cornel Turcu, Valentin Popa, Vasile Gaitan,", "date": "2015-3-14"}, 
{"urllink": "http://arxiv.org/abs/1503.04277", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04277", "title": "\nApproximate Discovery of Service Nodes by Duplicate Detection in Flows", "abstract": "Knowledge about which nodes provide services is of critical importance for network administrators. Discovery of service nodes can be done by making full use of duplicate element detection in flows. Because the amount of traffic across network is massive, especially in large ISPs or campus networks, we propose an approximate algorithm with Round-robin Buddy Bloom Filters(RBBF) for service detection using NetFlow data solely. The properties and analysis of RBBF data structure are also given. Our method has better time/space efficiency than conventional algorithm with a small false positive rate.%portion of false positive. We also demonstrate the contributions through a prototype system by real world case studies.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Zhou Changling, Xiao Jianguo, Cui Jian, Zhang Bei, Li Feng,", "date": "2015-3-14"}, 
{"urllink": "http://arxiv.org/abs/1503.04269", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04269", "title": "\nAn Emphatic Approach to the Problem of Off-policy Temporal-Difference  Learning", "abstract": "In this paper we introduce the idea of improving the performance of parametric temporal-difference (TD) learning algorithms by selectively emphasizing or de-emphasizing their updates on different time steps. In particular, we show that varying the emphasis of linear TD()'s updates in a particular way causes its expected update to become stable under off-policy training. The only prior model-free TD methods to achieve this with per-step computation linear in the number of function approximation parameters are the gradient-TD family of methods including TDC, GTD(), and GQ(). Compared to these methods, our _emphatic TD()_ is simpler and easier to use; it has only one learned parameter vector and one step-size parameter. On the other hand, the range of problems for which it is stable but does not converge with probability one is larger than for gradient-TD methods. Our treatment includes general state-dependent discounting and bootstrapping functions, and a way of specifying varying degrees of interest in accurately valuing different states.", "subjects": "Learning (cs.LG)", "authors": "Richard S. Sutton, A. Rupam Mahmood, Martha White,", "date": "2015-3-14"}, 
{"urllink": "http://arxiv.org/abs/1503.04267", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04267", "title": "\nLiSens --- A Scalable Architecture for Video Compressive Sensing", "abstract": "The measurement rate of cameras that take spatially multiplexed measurements by using spatial light modulators (SLM) is often limited by the switching speed of the SLMs. This is especially true for single-pixel cameras where the photodetector operates at a rate that is many orders-of-magnitude greater than the SLM. We study the factors that determine the measurement rate for such spatial multiplexing cameras (SMC) and show that increasing the number of pixels in the device improves the measurement rate, but there is an optimum number of pixels (typically, few thousands) beyond which the measurement rate does not increase. This motivates the design of LiSens, a novel imaging architecture, that replaces the photodetector in the single-pixel camera with a 1D linear array or a line-sensor. We illustrate the optical architecture underlying LiSens, build a prototype, and demonstrate results of a range of indoor and outdoor scenes. LiSens delivers on the promise of SMCs: imaging at a megapixel resolution, at video rate, using an inexpensive low-resolution sensor.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Jian Wang, Mohit Gupta, Aswin C. Sankaranarayanan,", "date": "2015-3-14"}, 
{"urllink": "http://arxiv.org/abs/1503.04265", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04265", "title": "\nA Dictionary-based Approach for Estimating Shape and Spatially-Varying  Reflectance", "abstract": "We present a technique for estimating the shape and reflectance of an object in terms of its surface normals and spatially-varying BRDF. We assume that multiple images of the object are obtained under fixed view-point and varying illumination, i.e, the setting of photometric stereo. Assuming that the BRDF at each pixel lies in the non-negative span of a known BRDF dictionary, we derive a per-pixel surface normal and BRDF estimation framework that requires neither iterative optimization techniques nor careful initialization, both of which are endemic to most state-of-the-art techniques. We showcase the performance of our technique on a wide range of simulated and real scenes where we outperform competing methods.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Zhuo Hui, Aswin C. Sankaranarayanan,", "date": "2015-3-14"}, 
{"urllink": "http://arxiv.org/abs/1503.04263", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04263", "title": "\nUser Centric Content Management System for Open IPTV Over SNS (ICTC2012)", "abstract": "Coupled schemes between service-oriented architecture (SOA) and Web 2.0 have recently been researched. Web-based content providers and telecommunications company (Telecom) based Internet protocol television (IPTV) providers have struggled against each other to accommodate more three-screen service subscribers. Since the advent of Web 2.0, more abundant reproduced content can be circulated. However, because according to increasing device's resolution and content formats IPTV providers transcode content in advance, network bandwidth, storage and operation costs for content management systems (CMSs) are wasted. In this paper, we present a user centric CMS for open IPTV, which integrates SOA and Web 2.0. Considering content popularity based on a Zipf-like distribution to solve these problems, we analyze the performance between the user centric CMS and the conventional Web syndication system for normalized costs. Based on the user centric CMS, we implement a social Web TV with device-aware function, which can aggregate, transcode, and deploy content over social networking service (SNS) independently.", "subjects": "Multimedia (cs.MM)", "authors": "Seung Hyun Jeon, Sanghong An, Changwoo Yoon, Hyun-woo Lee, Junkyun Choi,", "date": "2015-3-14"}, 
{"urllink": "http://arxiv.org/abs/1503.04260", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04260", "title": "\nQuantum Structure of Negation and Conjunction in Human Thought", "abstract": "We analyse in this paper the data collected in a set of experiments performed on human subjects on the combination of natural concepts. We investigate the mutual influence of conceptual conjunction and negation by measuring the membership weights of a list of exemplars with respect to two concepts, e.g., 'Fruits' and 'Vegetables', and their conjunction 'Fruits And Vegetables', but also their conjunction when one or both concepts are negated, namely, 'Fruits And Not Vegetables', 'Not Fruits And Vegetables' and 'Not Fruits And Not Vegetables'. Our findings sharpen existing analysis on conceptual combinations, revealing systematic and remarkable deviations from classical (fuzzy set) logic and probability theory. And, more important, our results give further considerable evidence to the validity of our quantum-theoretic framework for the combination of two concepts. Indeed, the representation of conceptual negation naturally arises from the general assumptions of our two-sector Fock space model, and this representation faithfully agrees with the collected data. In addition, we find a further significant deviation and a priori unexpected from classicality, which can exactly be explained by assuming that human reasoning is the superposition of an 'emergent reasoning' and a 'logical reasoning', and that these two processes can be successfully represented in a Fock space algebraic structure.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Diederik Aerts, Sandro Sozzo, Tomas Veloz,", "date": "2015-3-14"}, 
{"urllink": "http://arxiv.org/abs/1503.04256", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04256", "title": "\nRadar Precoder Design for Spectral Coexistence with Coordinated  Multi-point (CoMP) System", "abstract": "This paper details the design of precoders for a MIMO radar spectrally coexistent with a MIMO cellular network. We focus on a coordinated multi-point (CoMP) system where a cluster of base stations (BSs) coordinate their transmissions to the intended user. The radar operates in two modes, interference-mitigation mode when it avoids interference with the CoMP system and cooperation mode when it exchanges information with it. Using either the conventional Switched Null Space Projection (SNSP) or the newly proposed Switched Small Singular Value Space Projection (SSSVSP), the radar beam sweeps across the BS clusters focusing on the optimal ones, optimal in either nullity or difference between the precoded and original radar signal. Taking the channel estimation error into account, the design of precoder is pivoted on the minimal radar interference at the BS clusters during interference-mitigation mode and minimal bit-error-rate at the BSs during cooperation mode while interfering minimally with the radar target detection capability. Our investigation shows that loss in radar performance can be compensated using SSSVSP instead of SNSP to some extent but increasing the number of radar antenna elements goes a long way to serve the purpose. Simulations verify our theoretical predictions about the proposed SSSVSP.", "subjects": "Information Theory (cs.IT)", "authors": "Jasmin A. Mahal, Awais Khawar, Ahmed Abdelhadi, T. Charles Clancy,", "date": "2015-3-14"}, 
{"urllink": "http://arxiv.org/abs/1503.04255", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04255", "title": "\nOutage Minimization for a Fading Wireless Link with Energy Harvesting  Transmitter and Receiver", "abstract": "This paper studies online power control policies for outage minimization in a fading wireless link with energy harvesting transmitter and receiver. The outage occurs when either the transmitter or the receiver does not have enough energy, or the channel is in outage, where the transmitter only has the channel distribution information. Under infinite battery capacity and without retransmission, we prove that threshold-based power control policies are optimal. We thus propose disjoint/joint threshold-based policies with and without battery state sharing between the transmitter and receiver, respectively. We also analyze the impact of practical receiver detection and processing on the outage performance. When retransmission is considered, policy with linear power levels is adopted to adapt the power thresholds per retransmission. With finite battery capacity, a three dimensional finite state Markov chain is formulated to calculate the optimal parameters and corresponding performance of proposed policies. The energy arrival correlation between the transmitter and receiver is addressed for both finite and infinite battery cases. Numerical results show the impact of battery capacity, energy arrival correlation and detection cost on the outage performance of the proposed policies, as well as the tradeoff between the outage probability and the average transmission times.", "subjects": "Information Theory (cs.IT)", "authors": "Sheng Zhou, Tingjun Chen, Wei Chen, Zhisheng Niu,", "date": "2015-3-14"}, 
{"urllink": "http://arxiv.org/abs/1503.04254", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04254", "title": "\nGreenDelivery: Proactive Content Caching and Push with Energy Harvesting  based Small Cells", "abstract": "The explosive growth of mobile multimedia traffic calls for scalable wireless access with high quality of service and low energy cost. Motivated by the emerging energy harvesting communications, and the trend of caching multimedia contents at the access edge and user terminals, we propose a paradigm-shift framework, namely GreenDelivery, enabling efficient content delivery with energy harvesting based small cells. To resolve the two-dimensional randomness of energy harvesting and content request arrivals, proactive caching and push are jointly optimized, with respect to the content popularity distribution and battery states. We thus develop a novel way of understanding the interplay between content and energy over time and space. Case studies are provided to show the substantial reduction of macro BS activities, and thus the related energy consumption from the power grid is reduced. Research issues of the proposed GreenDelivery framework are also discussed.", "subjects": "Information Theory (cs.IT)", "authors": "Sheng Zhou, Jie Gong, Zhenyu Zhou, Wei Chen, Zhisheng Niu,", "date": "2015-3-14"}, 
{"urllink": "http://arxiv.org/abs/1503.04253", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04253", "title": "\nSuper-Resolution Generalizing Nonlocal-Means and Kernel Regression", "abstract": "Super-resolution without subpixel motion estimation is a promising branch of image reconstruction from general motion. The Non-Local Means (NLM) method is a simple, but powerful video denoising method that does not require explicit motion estimation. In ths paper we show that NLM method can be generalized via kernel regression to higher orders and can be applied to super-resolution reconstruction. The performance of the generalized method is shown with the help of various super-resolution experiments. Keywords: super-resolution, kernel regression, nonlocal-means, denoising, image reconstruction", "subjects": "Information Theory (cs.IT)", "authors": "Kang Yong-Rim, Kim Yong-Jin,", "date": "2015-3-14"}, 
{"urllink": "http://arxiv.org/abs/1503.04251", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04251", "title": "\nPerformance Impact of LoS and NLoS Transmissions in Small Cell Networks", "abstract": "In this paper, we introduce a sophisticated path loss model incorporating both line-of-sight (LoS) and non-line-of-sight (NLoS) transmissions to study their performance impact in small cell networks (SCNs). Analytical results are obtained on the coverage probability and the area spectral efficiency (ASE) for two user association strategies (UASs) assuming both a general path loss model and two special cases of path loss models recommended by the 3GPP standards. The performance impact of LoS and NLoS transmissions in SCNs in terms of the coverage probability and the ASE is shown to be significant both quantitatively and qualitatively, compared with previous work that does not differentiate LoS and NLoS transmissions. Particularly, our analysis demonstrates when the density of small cells is larger than a threshold, the network coverage probability will decrease as small cells become denser, which in turn makes the ASE suffer from a slow growth or even a notable decrease. For practical regime of small cell density, the performance results derived from our analysis are distinctively different from previous results, and show that small cell density matters. Therefore, our results shed new insights on the design and deployment of future SCNs.", "subjects": "Information Theory (cs.IT)", "authors": "Ming Ding, Peng Wang, David Lopez-Perez, Guoqiang Mao, Zihuai Lin,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04250", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04250", "title": "\nThe YLI-MED Corpus: Characteristics, Procedures, and Plans", "abstract": "The YLI Multimedia Event Detection corpus is a public-domain index of videos with annotations and computed features, specialized for research in multimedia event detection (MED), i.e., automatically identifying what's happening in a video by analyzing the audio and visual content. The videos indexed in the YLI-MED corpus are a subset of the larger YLI feature corpus, which is being developed by the International Computer Science Institute and Lawrence Livermore National Laboratory based on the Yahoo Flickr Creative Commons 100 Million (YFCC100M) dataset. The videos in YLI-MED are categorized as depicting one of ten target events, or no target event, and are annotated for additional attributes like language spoken and whether the video has a musical score. The annotations also include degree of annotator agreement and average annotator confidence scores for the event categorization of each video. Version 1.0 of YLI-MED includes 1823 \"positive\" videos that depict the target events and 48,138 \"negative\" videos, as well as 177 supplementary videos that are similar to event videos but are not positive examples. Our goal in producing YLI-MED is to be as open about our data and procedures as possible. This report describes the procedures used to collect the corpus; gives detailed descriptive statistics about the corpus makeup (and how video attributes affected annotators' judgments); discusses possible biases in the corpus introduced by our procedural choices and compares it with the most similar existing dataset, TRECVID MED's HAVIC corpus; and gives an overview of our future plans for expanding the annotation effort.", "subjects": "Multimedia (cs.MM)", "authors": "Julia Bernd, Damian Borth, Benjamin Elizalde, Gerald Friedland, Heather Gallagher, Luke Gottlieb, Adam Janin, Sara Karabashlieva, Jocelyn Takahashi, Jennifer Won,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04244", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04244", "title": "\nSecurity in Locally Repairable Storage", "abstract": "In this paper we extend the notion of codes to schemes. The main problem that we consider is to find optimal ways to distribute shares of a secret among a set of storage-nodes (participants) such that the content of each node (share) can be recovered by using contents of only few other nodes, and at the same time the secret can be reconstructed by only some allowable subsets of nodes. As a special case, an eavesdropper observing some set of specific nodes (such as less than certain number of nodes) does not get any information. In other words, we propose to study a locally repairable distributed storage system that is secure against a that can observe some subsets of nodes. We provide a number of results related to such systems including upper-bounds and achievability results on the number of bits that can be securely stored with these constraints.", "subjects": "Information Theory (cs.IT)", "authors": "Abhishek Agarwal, Arya Mazumdar,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04222", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04222", "title": "\nFuzzy Mixed Integer Linear Programming for Air Vehicles Operations  Optimization", "abstract": "Multiple Air Vehicles (AVs) to prosecute geographically dispersed targets is an important optimization problem. Associated multiple tasks viz., target classification, attack and verification are successively performed on each target. The optimal minimum time performance of these tasks requires cooperation among vehicles such that critical time constraints are satisfied i.e. target must be classified before it can be attacked and AV is sent to target area to verify its destruction after target has been attacked. Here, optimal task scheduling problem from Indian Air Force is formulated as Fuzzy Mixed Integer Linear Programming (FMILP) problem. The solution assigns all tasks to vehicles and performs scheduling in an optimal manner including scheduled staged departure times. Coupled tasks involving time and task order constraints are addressed. When AVs have sufficient endurance, existence of optimal solution is guaranteed. The solution developed can serve as an effective heuristic for different categories of AV optimization problems.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Arindam Chaudhuri, Dipak Chatterjee, Ritesh Rajput,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04220", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04220", "title": "\nFuzzy Mixed Integer Optimization Model for Regression Approach", "abstract": "Mixed Integer Optimization has been a topic of active research in past decades. It has been used to solve Statistical problems of classification and regression involving massive data. However, there is an inherent degree of vagueness present in huge real life data. This impreciseness is handled by Fuzzy Sets. In this Paper, Fuzzy Mixed Integer Optimization Method (FMIOM) is used to find solution to Regression problem. The methodology exploits discrete character of problem. In this way large scale problems are solved within practical limits. The data points are separated into different polyhedral regions and each region has its own distinct regression coefficients. In this attempt, an attention is drawn to Statistics and Data Mining community that Integer Optimization can be significantly used to revisit different Statistical problems. Computational experimentations with generated and real data sets show that FMIOM is comparable to and often outperforms current leading methods. The results illustrate potential for significant impact of Fuzzy Integer Optimization methods on Computational Statistics and Data Mining.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Arindam Chaudhuri, Dipak Chatterjee,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04215", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04215", "title": "\nSpreadsheets for Stream Partitions and Windows", "abstract": "We discuss the suitability of spreadsheet processors as tools for programming streaming systems. We argue that, while spreadsheets can function as powerful models for stream operators, their fundamental boundedness limits their scope of application. We propose two extensions to the spreadsheet model and argue their utility in the context of programming streaming systems.", "subjects": "Software Engineering (cs.SE)", "authors": "Martin Hirzel, Rodric Rabbah, Philippe Suter, Olivier Tardieu, Mandana Vaziri,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04208", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04208", "title": "\nMining Missing Hyperlinks from Human Navigation Traces: A Case Study of  Wikipedia", "abstract": "Hyperlinks are an essential feature of the World Wide Web. They are especially important for online encyclopedias such as Wikipedia: an article can often only be understood in the context of related articles, and hyperlinks make it easy to explore this context. But important links are often missing, and several methods have been proposed to alleviate this problem by learning a linking model based on the structure of the existing links. Here we propose a novel approach to identifying missing links in Wikipedia. We build on the fact that the ultimate purpose of Wikipedia links is to aid navigation. Rather than merely suggesting new links that are in tune with the structure of existing links, our method finds missing links that would immediately enhance Wikipedia's navigability. We leverage data sets of navigation paths collected through a Wikipedia-based human-computation game in which users must find a short path from a start to a target article by only clicking links encountered along the way. We harness human navigational traces to identify a set of candidates for missing links and then rank these candidates. Experiments show that our procedure identifies missing links of high quality.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Robert West, Ashwin Paranjape, Jure Leskovec,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04193", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04193", "title": "\nNon-normal modalities in variants of Linear Logic", "abstract": "This note presents modal versions of resource-conscious logics. We concentrate on extensions of variants of Linear Logic with one minimal non-normal modality. In earlier work, where we investigated agency in multi-agent systems, we have shown that the results scale up to logics with multiple non-minimal modalities. Here, we start with the language of propositional intuitionistic Linear Logic without the additive disjunction, to which we add a modality. We provide an interpretation of this language on a class of Kripke resource models extended with a neighbourhood function: modal Kripke resource models. We propose a Hilbert-style axiomatization and a Gentzen-style sequent calculus. We show that the proof theories are sound and complete with respect to the class of modal Kripke resource models. We show that the sequent calculus allows cut elimination and that proof-search is in PSPACE. We then show how to extend the results when non-commutative connectives are added to the language. Finally, we put the logical framework to use by instantiating it as logics of agency. In particular, we propose a logic to reason about the resource-sensitive use of artefacts and illustrate it with a variety of examples.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Daniele Porello, Nicolas Troquard,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04187", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04187", "title": "\nA Minimal Active Inference Agent", "abstract": "Research on the so-called \"free-energy principle'' (FEP) in cognitive neuroscience is becoming increasingly high-profile. To date, introductions to this theory have proved difficult for many readers to follow, but it depends mainly upon two relatively simple ideas: firstly that normative or teleological values can be expressed as probability distributions (active inference), and secondly that approximate Bayesian reasoning can be effectively performed by gradient descent on model parameters (the free-energy principle). The notion of active inference is of great interest for a number of disciplines including cognitive science and artificial intelligence, as well as cognitive neuroscience, and deserves to be more widely known. This paper attempts to provide an accessible introduction to active inference and informational free-energy, for readers from a range of scientific backgrounds. In this work introduce an agent-based model with an agent trying to make predictions about its position in a one-dimensional discretized world using methods from the FEP.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Simon McGregor, Manuel Baltieri, Christopher L. Buckley,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04177", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04177", "title": "\nSome Comments on the Stochastic Eulerian Tour Problem", "abstract": "The Stochastic Eulerian Tour Problem was introduced in 2008 as a stochastic variant of the well-known Eulerian Tour Problem. In a follow-up paper the same authors investigated some heuristics for solving the Stochastic Eulerian Tour Problem. After a thorough study of these two publications a few issues emerged. In this short research commentary we would like to discuss these issues.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Dennis Weyland,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04169", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04169", "title": "\nJoin Processing for Graph Patterns: An Old Dog with New Tricks", "abstract": "Join optimization has been dominated by Selinger-style, pairwise optimizers for decades. But, Selinger-style algorithms are asymptotically suboptimal for applications in graphic analytics. This suboptimality is one of the reasons that many have advocated supplementing relational engines with specialized graph processing engines. Recently, new join algorithms have been discovered that achieve optimal worst-case run times for any join or even so-called beyond worst-case (or instance optimal) run time guarantees for specialized classes of joins. These new algorithms match or improve on those used in specialized graph-processing systems. This paper asks can these new join algorithms allow relational engines to close the performance gap with graph engines? We examine this question for graph-pattern queries or join queries. We find that classical relational databases like Postgres and MonetDB or newer graph databases/stores like Virtuoso and Neo4j may be orders of magnitude slower than these new approaches compared to a fully featured RDBMS, LogicBlox, using these new ideas. Our results demonstrate that an RDBMS with such new algorithms can perform as well as specialized engines like GraphLab -- while retaining a high-level interface. We hope this adds to the ongoing debate of the role of graph accelerators, new graph systems, and relational systems in modern workloads.", "subjects": "Databases (cs.DB)", "authors": "Dung Nguyen, Molham Aref, Martin Bravenboer, George Kollias, Hung Q. Ngo, Christopher R\u00e9, Atri Rudra,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.04144", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04144", "title": "\nExploiting Image-trained CNN Architectures for Unconstrained Video  Classification", "abstract": "We conduct an in-depth exploration of different strategies for doing event detection and action recognition in videos using convolutional neural networks (CNNs) trained for image classification. We study different ways of performing frame calibration, spatial and temporal pooling, feature normalization, choice of CNN layer as well as choice of classifiers. Making judicious choices along these dimensions led to a very significant increase in performance over more naive approaches that have been used till now. We illustrate our procedure with two popular CNN architectures which got excellent results in the ILSVRC-2012 and 2014 competitions. We test our methods on the challenging TRECVID MED'14 dataset which contains a heterogeneous set of videos that vary in terms of resolution, quality, camera motion and illumination conditions. On this dataset, our methods, based entirely on image-trained CNN features, can already outperform state-of-the-art non-CNN models based on the best motion-based Fisher vector approach. We further show that late fusion of CNN- and motion-based features brings a tremendous improvement, increasing the mean average precision (mAP) from 34.95% to 38.74%. The fusion approach also matches the state-of-the-art classification performance on UCF-101 dataset.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Shengxin Zha, Florian Luisier, Walter Andrews, Nitish Srivastava, Ruslan Salakhutdinov,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.04118", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04118", "title": "\nEvent-Triggered Observers and Observer-Based Controllers for a Class of  Nonlinear Systems", "abstract": "In this paper, we investigate the stabilization of a nonlinear plant subject to network constraints, under the assumption of partial knowledge of the plant state. The event triggered paradigm is used for the observation and the control of the system. Necessary conditions, making use of the ISS property, are given to guarantee the existence of a triggering mechanism, leading to asymptotic convergence of the observer and system states. The proposed triggering mechanism is illustrated in the stabilization of a robot with a flexible link robot.", "subjects": "Systems and Control (cs.SY)", "authors": "L. Etienne, S. Di Gennaro, J.-P. Barbot,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04115", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04115", "title": "\nSparse Code Formation with Linear Inhibition", "abstract": "Sparse code formation in the primary visual cortex (V1) has been inspiration for many state-of-the-art visual recognition systems. To stimulate this behavior, networks are trained networks under mathematical constraint of sparsity or selectivity. In this paper, the authors exploit another approach which uses lateral interconnections in feature learning networks. However, instead of adding direct lateral interconnections among neurons, we introduce an inhibitory layer placed right after normal encoding layer. This idea overcomes the challenge of computational cost and complexity on lateral networks while preserving crucial objective of sparse code formation. To demonstrate this idea, we use sparse autoencoder as normal encoding layer and apply inhibitory layer. Early experiments in visual recognition show relative improvements over traditional approach on CIFAR-10 dataset. Moreover, simple installment and training process using Hebbian rule allow inhibitory layer to be integrated into existing networks, which enables further analysis in the future.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Nam Do-Hoang Le,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04108", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04108", "title": "\nAsymptotic Capacity of a Random Channel", "abstract": "We consider discrete memoryless channels with input alphabet size and output alphabet size , where ceil for some constant . The channel transition matrix consists of entries that, before being normalised, are independent and identically distributed nonnegative random variables and such that . We prove that in the limit as the capacity of such a channel converges to almost surely and in , where denotes the entropy of . We further show that the capacity of these random channels converges to this asymptotic value exponentially in . Finally, we present an application in the context of Bayesian optimal experiment design.", "subjects": "Information Theory (cs.IT)", "authors": "Tobias Sutter, David Sutter, John Lygeros,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04069", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04069", "title": "\nLSTM: A Search Space Odyssey", "abstract": "Several variants of the Long Short-Term Memory (LSTM) architecture for recurrent neural networks have been proposed since its inception in 1995. In recent years, these networks have become the state-of-the-art models for a variety of machine learning problems. This has led to a renewed interest in understanding the role and utility of various computational components of typical LSTM variants. In this paper, we present the first large-scale analysis of eight LSTM variants on three representative tasks: speech recognition, handwriting recognition, and polyphonic music modeling. The hyperparameters of all LSTM variants for each task were optimized separately using random search and their importance was assessed using the powerful fANOVA framework. In total, we summarize the results of 5400 experimental runs (about 15 years of CPU time), which makes our study the largest of its kind on LSTM networks. Our results show that none of the variants can improve upon the standard LSTM architecture significantly, and demonstrate the forget gate and the output activation function to be its most critical components. We further observe that the studied hyperparameters are virtually independent and derive guidelines for their efficient adjustment.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "Klaus Greff, Rupesh Kumar Srivastava, Jan Koutn\u00edk, Bas R. Steunebrink, J\u00fcrgen Schmidhuber,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04067", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04067", "title": "\nVirtual sectorization: design and self-optimization", "abstract": "Virtual Sectorization (ViSn) aims at covering a confined area such as a traffic hot-spot using a narrow beam. The beam is generated by a remote antenna array located at-or close to the Base Station (BS). This paper develops the ViSn model and provides the guidelines for designing the Virtual Sector (ViS) antenna. In order to mitigate interference between the ViS and the traditional macro sector covering the rest of the area, a Dynamic Spectrum Allocation (DSA) algorithm that self-optimizes the frequency bandwidth split between the macro cell and the ViS is also proposed. The Self-Organizing Network (SON) algorithm is constructed to maximize the proportional fair utility of all the users throughputs. Numerical simulations show the interest in deploying ViSn, and the significant capacity gain brought about by the self-optimized bandwidth sharing with respect to a full reuse of the bandwidth by the ViS.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Abdoulaye TALL, Zwi Altman, Eitan Altman,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04065", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04065", "title": "\nHybrid multi-layer Deep CNN/Aggregator feature for image classification", "abstract": "Deep Convolutional Neural Networks (DCNN) have established a remarkable performance benchmark in the field of image classification, displacing classical approaches based on hand-tailored aggregations of local descriptors. Yet DCNNs impose high computational burdens both at training and at testing time, and training them requires collecting and annotating large amounts of training data. Supervised adaptation methods have been proposed in the literature that partially re-learn a transferred DCNN structure from a new target dataset. Yet these require expensive bounding-box annotations and are still computationally expensive to learn. In this paper, we address these shortcomings of DCNN adaptation schemes by proposing a hybrid approach that combines conventional, unsupervised aggregators such as Bag-of-Words (BoW), with the DCNN pipeline by treating the output of intermediate layers as densely extracted local descriptors. We test a variant of our approach that uses only intermediate DCNN layers on the standard PASCAL VOC 2007 dataset and show performance significantly higher than the standard BoW model and comparable to Fisher vector aggregation but with a feature that is 150 times smaller. A second variant of our approach that includes the fully connected DCNN layers significantly outperforms Fisher vector schemes and performs comparably to DCNN approaches adapted to Pascal VOC 2007, yet at only a small fraction of the training and testing cost.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Praveen Kulkarni, Joaquin Zepeda, Frederic Jurie, Patrick Perez, Louis Chevallier,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04063", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04063", "title": "\nOn the Application of Multiuser Detection in Multibeam Satellite Systems", "abstract": "We study the achievable rates by a single user in multibeam satellite scenarios. We show alternatives to the conventional symbol-by-symbol detection applied at user terminals. Single user detection is known to suffer from strong degradation when the terminal is located near the edge of the coverage area, and when aggressive frequency reuse is adopted. For this reason, we consider multiuser detection, and take into account the strongest interfering signal. Moreover, we analyze a different transmission strategy, where the signals from two adjacent beams jointly serve two users in a time division multiplexing fashion. We describe an information-theoretic framework to compare different transmission/detection strategies by computing the information rate of the user in the reference beam.", "subjects": "Information Theory (cs.IT)", "authors": "Giulio Colavolpe, Andrea Modenini, Amina Piemontese, Alessandro Ugolini,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04055", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04055", "title": "\nEnron versus EUSES: A Comparison of Two Spreadsheet Corpora", "abstract": "Spreadsheets are widely used within companies and often form the basis for business decisions. Numerous cases are known where incorrect information in spreadsheets has lead to incorrect decisions. Such cases underline the relevance of research on the professional use of spreadsheets. Recently a new dataset became available for research, containing over 15.000 business spreadsheets that were extracted from the Enron E-mail Archive. With this dataset, we 1) aim to obtain a thorough understanding of the characteristics of spreadsheets used within companies, and 2) compare the characteristics of the Enron spreadsheets with the EUSES corpus which is the existing state of the art set of spreadsheets that is frequently used in spreadsheet studies. Our analysis shows that 1) the majority of spreadsheets are not large in terms of worksheets and formulas, do not have a high degree of coupling, and their formulas are relatively simple; 2) the spreadsheets from the EUSES corpus are, with respect to the measured characteristics, quite similar to the Enron spreadsheets.", "subjects": "Software Engineering (cs.SE)", "authors": "Bas Jansen,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04045", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04045", "title": "\nDiverse Palindromic Factorization is NP-Complete", "abstract": "We prove it NP-complete to decide whether a given string can be factored into palindromes that each appear only once in the factorization.", "subjects": "Formal Languages and Automata Theory (cs.FL)", "authors": "Travis Gagie, Shunsuke Inenaga, Juha Karkkainen, Dominik Kempa, Marcin Piatkowski, Simon J. Puglisi, Shiho Sugimoto,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04036", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04036", "title": "\nCharacterizing driving behavior using automatic visual analysis", "abstract": "In this work, we present the problem of rash driving detection algorithm using a single wide angle camera sensor, particularly useful in the Indian context. To our knowledge this rash driving problem has not been addressed using Image processing techniques (existing works use other sensors such as accelerometer). Car Image processing literature, though rich and mature, does not address the rash driving problem. In this work-in-progress paper, we present the need to address this problem, our approach and our future plans to build a rash driving detector.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Mrinal Haloi, Dinesh Babu Jayagopi,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04034", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04034", "title": "\nBounding linear head reduction and visible interaction through skeletons", "abstract": "In this paper, we study the complexity of execution in higher-order programming languages. Our study has two facets: on the one hand we give an upper bound to the length of interactions between bounded P-visible strategies in Hyland-Ong game semantics. This result covers models of programming languages with access to computational effects like non-determinism, state or control operators, but its semantic formulation causes a loose connection to syntax. On the other hand we give a syntactic counterpart of our semantic study: a non-elementary upper bound to the length of the linear head reduction sequence (a low-level notion of reduction, close to the actual implementation of the reduction of higher-order programs by abstract machines) of simply-typed lambda-terms. In both cases our upper bounds are proved optimal by giving matching lower bounds. These two results, although different in scope, are proved using the same method: we introduce a simple reduction on finite trees of natural numbers, hereby called interaction skeletons. We study this reduction and give upper bounds to its complexity. We then apply this study by giving two simulation results: a semantic one measuring progress in game-theoretic interaction via interaction skeletons, and a syntactic one establishing a correspondence between linear head reduction of terms satisfying a locality condition called local scope and the reduction of interaction skeletons. This result is then generalized to arbitrary terms by a local scopization transformation.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Pierre Clairambault,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04030", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04030", "title": "\nTotally Distributed Energy-Efficient Transmission in MIMO Interference  Channels", "abstract": "In this paper, we consider the problem of maximizing the energy efficiency (EE) for multi-input multi-output (MIMO) interference channels, subject to the per-link power constraint. To avoid extensive information exchange among all links, the optimization problem is formulated as a noncooperative game, where each link maximizes its own EE. We show that this game always admits a Nash equilibrium (NE) and the sufficient condition for the uniqueness of the NE is derived for the case of arbitrary channel matrices, which can be checked in practice. To reach the NE of this game, we develop a totally distributed EE algorithm, in which each link updates its own transmit covariance matrix in a completely distributed and asynchronous way: Some players may update their solutions more frequently than others or even use the outdated interference information. The sufficient conditions that guarantee the global convergence of the proposed algorithm to the NE of the game have been given as well. We also study the impact of the circuit power consumption on the sum-EE performance of the proposed algorithm in the case when the links are separated sufficiently far away. Moreover, the tradeoff between the sum-EE and the sum-spectral efficiency (SE) is investigated with the proposed algorithm under two special cases: 1) low transmit power constraint regime; 2) high transmit power constraint regime. Finally, extensive simulations are conducted to evaluate the impact of various system parameters on the system performance.", "subjects": "Information Theory (cs.IT)", "authors": "Cunhua Pan, Wei Xu, Jiangzhou Wang, Hong Ren, Wence Zhang, Nuo Huang, Ming Chen,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04018", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04018", "title": "\nOn the Coverability Problem for Pushdown Vector Addition Systems in One  Dimension", "abstract": "Does the trace language of a given vector addition system (VAS) intersect with a given context-free language? This question lies at the heart of several verification questions involving recursive programs with integer parameters. In particular, it is equivalent to the coverability problem for VAS that operate on a pushdown stack. We show decidability in dimension one, based on an analysis of a new model called grammar-controlled vector addition systems.", "subjects": "Formal Languages and Automata Theory (cs.FL)", "authors": "J\u00e9r\u00f4me Leroux, Gr\u00e9goire Sutre, Patrick Totzke,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.04006", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04006", "title": "\nSynthesis of all Maximum Length Cellular Automata of Cell Size up to 12", "abstract": "Maximum length CA has wide range of applications in design of linear block code, cryptographic primitives and VLSI testing particularly in Built-In-Self-Test. In this paper, an algorithm to compute all -cell maximum length CA-rule vectors is proposed. Also rule vectors for each primitive polynomial in GF(2^2) to GF(2^ have been computed by simulation and they have been listed.Programmable rule vectors based maximum length CA can be used to design cryptographic primitives.", "subjects": "Other Computer Science (cs.OH)", "authors": "Jaydeb Bhaumik,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.04005", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.04005", "title": "\nDominance and Deficiency for Petri Nets and Chemical Reaction Networks", "abstract": "Inspired by Anderson et al. [J. R. Soc. Interface, 2014] we study the long-term behavior of discrete chemical reaction networks (CRNs). In particular, using techniques from both Petri net theory and CRN theory, we provide a powerful and computationally-efficient sufficient condition for a structurally-bounded CRN to have the property that none of the non-terminal reactions can be applied for all its recurrent configurations. We compare this result and its proof with a related result of Anderson et al. and show its consequences for the case of CRNs with deficiency one.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Robert Brijder,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03997", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03997", "title": "\nGeneralized Spatial Modulation in Large-Scale Multiuser MIMO Systems", "abstract": "Generalized spatial modulation (GSM) uses transmit antenna elements but fewer transmit radio frequency (RF) chains, . Spatial modulation (SM) and spatial multiplexing are special cases of GSM with and , respectively. In GSM, in addition to conveying information bits through conventional modulation symbols (for example, QAM), the indices of the active transmit antennas also convey information bits. In this paper, we investigate . Our contributions in this paper include: () an average bit error probability (ABEP) analysis for maximum-likelihood detection in multiuser GSM-MIMO on the uplink, where we derive an upper bound on the ABEP, and () low-complexity algorithms for GSM-MIMO signal detection and channel estimation at the base station receiver based on message passing. The analytical upper bounds on the ABEP are found to be tight at moderate to high signal-to-noise ratios (SNR). The proposed receiver algorithms are found to scale very well in complexity while achieving near-optimal performance in large dimensions. Simulation results show that, for the same spectral efficiency, multiuser GSM-MIMO can outperform multiuser SM-MIMO as well as conventional multiuser MIMO, by about 2 to 9 dB at a bit error rate of . Such SNR gains in GSM-MIMO compared to SM-MIMO and conventional MIMO can be attributed to the fact that, because of a larger number of spatial index bits, GSM-MIMO can use a lower-order QAM alphabet which is more power efficient.", "subjects": "Information Theory (cs.IT)", "authors": "T. Lakshmi Narasimhan, P. Raviteja, A. Chockalingam,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.03989", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03989", "title": "\nAn implementation of Apertium based Assamese morphological analyzer", "abstract": "Morphological Analysis is an important branch of linguistics for any Natural Language Processing Technology. Morphology studies the word structure and formation of word of a language. In current scenario of NLP research, morphological analysis techniques have become more popular day by day. For processing any language, morphology of the word should be first analyzed. Assamese language contains very complex morphological structure. In our work we have used Apertium based Finite-State-Transducers for developing morphological analyzer for Assamese Language with some limited domain and we get 72.7% accuracy", "subjects": "Computation and Language (cs.CL)", "authors": "Mirzanur Rahman, Shikhar Kumar Sarma,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.03974", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03974", "title": "\nHyper Temporal Networks", "abstract": "Simple Temporal Networks (STNs) provide a powerful and general tool for representing conjunctions of maximum delay constraints over ordered pairs of temporal variables. In this paper we introduce Hyper Temporal Networks (HyTNs), a strict generalization of STNs, to overcome the limitation of considering only conjunctions of constraints but maintaining a practical efficiency in the consistency check of the instances. In a Hyper Temporal Network a single temporal hyperarc constraint may be defined as a set of two or more maximum delay constraints which is satisfied when at least one of these delay constraints is satisfied. HyTNs are meant as a light generalization of STNs offering an interesting compromise. On one side, there exist practical pseudo-polynomial time algorithms for checking consistency and computing feasible schedules for HyTNs. On the other side, HyTNs offer a more powerful model accommodating natural constraints that cannot be expressed by STNs like Trigger off exactly delta min before (after) the occurrence of the first (last) event in a set., which are used to represent synchronization events in some process aware information systems/workflow models proposed in the literature.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Carlo Comin, Roberto Posenato, Romeo Rizzi,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.03964", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03964", "title": "\nInteractive Restless Multi-armed Bandit Game and Swarm Intelligence  Effect", "abstract": "We obtain the conditions for the emergence of the swarm intelligence effect in an interactive game of restless multi-armed bandit (rMAB). A player competes with multiple agents. Each bandit has a payoff that changes with a probability per round. The agents and player choose one of three options: (1) Exploit (a good bandit), (2) Innovate (asocial learning for a good bandit among randomly chosen bandits), and (3) Observe (social learning for a good bandit). Each agent has two parameters to specify the decision: (i) , the threshold value for Exploit, and (ii) , the probability for Observe in learning. The parameters are uniformly distributed. We determine the optimal strategies for the player using complete knowledge about the rMAB. We show whether or not social or asocial learning is more optimal in the space and define the swarm intelligence effect. We conduct a laboratory experiment (67 subjects) and observe the swarm intelligence effect only if are chosen so that social learning is far more optimal than asocial learning.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Shunsuke Yoshida, Masato Hisakado, Shintaro Mori,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.03961", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03961", "title": "\nKnowledge-based Query Expansion in Real-Time Microblog Search", "abstract": "Since the length of microblog texts, such as tweets, is strictly limited to 140 characters, traditional Information Retrieval techniques suffer from the vocabulary mismatch problem severely and cannot yield good performance in the context of microblogosphere. To address this critical challenge, in this paper, we propose a new language modeling approach for microblog retrieval by inferring various types of context information. In particular, we expand the query using knowledge terms derived from Freebase so that the expanded one can better reflect users' search intent. Besides, in order to further satisfy users' real-time information need, we incorporate temporal evidences into the expansion method, which can boost recent tweets in the retrieval results with respect to a given topic. Experimental results on two official TREC Twitter corpora demonstrate the significant superiority of our approach over baseline methods.", "subjects": "Information Retrieval (cs.IR)", "authors": "Runwei Qiang, Feifan Fan, Chao Lv, Jianwu Yang,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.03957", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03957", "title": "\nImplementation of an efficient Fuzzy Logic based Information Retrieval  System", "abstract": "This paper exemplifies the implementation of an efficient Information Retrieval (IR) System to compute the similarity between a dataset and a query using Fuzzy Logic. TREC dataset has been used for the same purpose. The dataset is parsed to generate keywords index which is used for the similarity comparison with the user query. Each query is assigned a score value based on its fuzzy similarity with the index keywords. The relevant documents are retrieved based on the score value. The performance and accuracy of the proposed fuzzy similarity model is compared with Cosine similarity model using Precision-Recall curves. The results prove the dominance of Fuzzy Similarity based IR system.", "subjects": "Information Retrieval (cs.IR)", "authors": "Prabhjot Singh, Sumit Dhawan, Shubham Agarwal, Narina Thakur,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.03954", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03954", "title": "\nFull-Duplex Cognitive Radio: A New Design Paradigm for Enhancing  Spectrum Usage", "abstract": "With the rapid growth of demand for ever-increasing data rate, spectrum resources have become more and more scarce. As a promising technique to increase the efficiency of the spectrum utilization, cognitive radio (CR) technique has the great potential to meet such a requirement by allowing un-licensed users to coexist in licensed bands. In conventional CR systems, the spectrum sensing is performed at the beginning of each time slot before the data transmission. This unfortunately results in two major problems: 1) transmission time reduction due to sensing, and 2) sensing accuracy impairment due to data transmission. To tackle these problems, in this paper we present a new design paradigm for future CR by exploring the full-duplex (FD) techniques to achieve the simultaneous spectrum sensing and data transmission. With FD radios equipped at the secondary users (SUs), SUs can simultaneously sense and access the vacant spectrum, and thus, significantly improve sensing performances and meanwhile increase data transmission efficiency. The aim of this article is to transform the promising conceptual framework into the practical wireless network design by addressing a diverse set of challenges such as protocol design and theoretical analysis. Several application scenarios with FD enabled CR are elaborated, and key open research directions and novel algorithms in these systems are discussed.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Yun Liao, Lingyang Song, Zhu Han, Yonghui Li,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.03952", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03952", "title": "\nA Switched Dynamical System Framework for Analysis of Massively Parallel  Asynchronous Numerical Algorithms", "abstract": "In the near future, massively parallel computing systems will be necessary to solve computation intensive applications. The key bottleneck in massively parallel implementation of numerical algorithms is the synchronization of data across processing elements (PEs) after each iteration, which results in significant idle time. Thus, there is a trend towards relaxing the synchronization and adopting an asynchronous model of computation to reduce idle time. However, it is not clear what is the effect of this relaxation on the stability and accuracy of the numerical algorithm. In this paper we present a new framework to analyze such algorithms. We treat the computation in each PE as a dynamical system and model the asynchrony as stochastic switching. The overall system is then analyzed as a switched dynamical system. However, modeling of massively parallel numerical algorithms as switched dynamical systems results in a very large number of modes, which makes current analysis tools available for such systems computationally intractable. We develop new techniques that circumvent this scalability issue. The framework is presented on a one-dimensional heat equation as a case study and the proposed analysis framework is verified by solving the partial differential equation (PDE) in a GPU machine, with asynchronous communication between cores.", "subjects": "Systems and Control (cs.SY)", "authors": "Kooktae Lee, Raktim Bhattacharya, Vijay Gupta,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.03942", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03942", "title": "\nOn Minimizing the Average Packet Decoding Delay in Wireless Network  Coded Broadcast", "abstract": "We consider a setting in which a sender wishes to broadcast a block of K data packets to a set of wireless receivers, where each of the receivers has a subset of the data packets already available to it (e.g., from prior transmissions) and wants the rest of the packets. Our goal is to find a linear network coding scheme that yields the minimum average packet decoding delay (APDD), i.e., the average time it takes for a receiver to decode a data packet. Our contributions can be summarized as follows. First, we prove that this problem is NP-hard by presenting a reduction from the hypergraph coloring problem. Next, we show that % alexn a random linear network coding (RLNC) provides an approximate solution to this problem with approximation ratio with high probability. Next, we present a methodology for designing specialized approximation algorithms for this problem that outperform RLNC solutions while maintaining the same throughput. In a special case of practical interest with a small number of wanted packets our solution can achieve an approximation ratio (4-2/K)/3. Finally, we conduct an experimental study that demonstrates the advantages of the presented methodology.", "subjects": "Information Theory (cs.IT)", "authors": "Mingchao Yu, Alex Sprintson, Parastoo Sadeghi,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.03940", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03940", "title": "\nRAPTOR: Routing Attacks on Privacy in Tor", "abstract": "The Tor network is a widely used system for anonymous communication. However, Tor is known to be vulnerable to attackers who can observe traffic at both ends of the communication path. In this paper, we show that prior attacks are just the tip of the iceberg. We present a suite of new attacks, called Raptor, that can be launched by Autonomous Systems (ASes) to compromise user anonymity. First, AS-level adversaries can exploit the asymmetric nature of Internet routing to increase the chance of observing at least one direction of user traffic at both ends of the communication. Second, AS-level adversaries can exploit natural churn in Internet routing to lie on the BGP paths for more users over time. Third, strategic adversaries can manipulate Internet routing via BGP hijacks (to discover the users using specific Tor guard nodes) and interceptions (to perform traffic analysis). We demonstrate the feasibility of Raptor attacks by analyzing historical BGP data and Traceroute data as well as performing real-world attacks on the live Tor network, while ensuring that we do not harm real users. In addition, we outline the design of two monitoring frameworks to counter these attacks: BGP monitoring to detect control-plane attacks, and Traceroute monitoring to detect data-plane anomalies. Overall, our work motivates the design of anonymity systems that are aware of the dynamics of Internet routing.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Yixin Sun, Anne Edmundson, Laurent Vanbever, Oscar Li, Jennifer Rexford, Mung Chiang, Prateek Mittal,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.03920", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03920", "title": "\nFusing Text and Image for Event Detection in Twitter", "abstract": "In this contribution, we develop an accurate and effective event detection method to detect events from a Twitter stream, which uses visual and textual information to improve the performance of the mining process. The method monitors a Twitter stream to pick up tweets having texts and images and stores them into a database. This is followed by applying a mining algorithm to detect an event. The procedure starts with detecting events based on text only by using the feature of the bag-of-words which is calculated using the term frequency-inverse document frequency (TF-IDF) method. Then it detects the event based on image only by using visual features including histogram of oriented gradients (HOG) descriptors, grey-level cooccurrence matrix (GLCM), and color histogram. K nearest neighbours (Knn) classification is used in the detection. The final decision of the event detection is made based on the reliabilities of text only detection and image only detection. The experiment result showed that the proposed method achieved high accuracy of 0.94, comparing with 0.89 with texts only, and 0.86 with images only.", "subjects": "Information Retrieval (cs.IR)", "authors": "Samar M. Alqhtani, Suhuai Luo, Brian Regan,", "date": "2015-3-13"}, 
{"urllink": "http://arxiv.org/abs/1503.03913", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03913", "title": "\nDiagnosing Heterogeneous Dynamics for CT Scan Images of Human Brain in  Wavelet and MFDFA domain", "abstract": "CT scan images of human brain of a particular patient in different cross sections are taken, on which wavelet transform and multi-fractal analysis are applied. The vertical and horizontal unfolding of images are done before analyzing these images. A systematic investigation of de-noised CT scan images of human brain in different cross-sections are carried out through wavelet normalized energy and wavelet semi-log plots, which clearly points out the mismatch between results of vertical and horizontal unfolding. The mismatch of results confirms the heterogeneity in spatial domain. Using the multi-fractal de-trended fluctuation analysis (MFDFA), the mismatch between the values of Hurst exponent and width of singularity spectrum by vertical and horizontal unfolding confirms the same.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Sabyasachi Mukhopadhyay, Soham Mandal, Nandan K Das, Subhadip Dey, Asish Mitra, Nirmalya Ghosh, Prasanta K Panigrahi,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03912", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03912", "title": "\nTowards 1 Gbps/UE in Cellular Systems: Understanding Ultra-Dense Small  Cell Deployments", "abstract": "Todays heterogeneous networks comprised of mostly macrocells and indoor small cells will not be able to meet the upcoming traffic demands. Indeed, it is forecasted that at least a 100x network capacity increase will be required to meet the traffic demands in 2020. As a result, vendors and operators are now looking at using every tool at hand to improve network capacity. In this epic campaign, three paradigms are noteworthy, i.e., network densification, the use of higher frequency bands and spectral efficiency enhancement techniques. This paper aims at bringing further common understanding and analysing the potential gains and limitations of these three paradigms, together with the impact of idle mode capabilities at the small cells as well as the user equipment density and distribution in outdoor scenarios. Special attention is paid to network densification and its implications when transitioning to ultra-dense small cell deployments. Simulation results show that network densification with an average inter site distance of 35 m can increase the cell- edge UE throughput by up to 48x, while the use of the 10GHz band with a 500MHz bandwidth can increase the network capacity up to 5x. The use of beamforming with up to 4 antennas per small cell base station lacks behind with cell-edge throughput gains of up to 1.49x. Our study also shows how network densifications reduces multi-user diversity, and thus proportional fair alike schedulers start losing their advantages with respect to round robin ones. The energy efficiency of these ultra-dense small cell deployments is also analysed, indicating the need for energy harvesting approaches to make these deployments energy- efficient. Finally, the top ten challenges to be addressed to bring ultra-dense small cell deployments to reality are also discussed.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "David Lopez-Perez, Ming Ding, Holger Claussen, Amir H. Jafari,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03909", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03909", "title": "\nDetection of Cyberbullying Incidents on the Instagram Social Network", "abstract": "Cyberbullying is a growing problem affecting more than half of all American teens. The main goal of this paper is to investigate fundamentally new approaches to understand and automatically detect incidents of cyberbullying over images in Instagram, a media-based mobile social network. To this end, we have collected a sample Instagram data set consisting of images and their associated comments, and designed a labeling study for cyberbullying as well as image content using human labelers at the crowd-sourced Crowdflower Web site. An analysis of the labeled data is then presented, including a study of correlations between different features and cyberbullying as well as cyberaggression. Using the labeled data, we further design and evaluate the accuracy of a classifier to automatically detect incidents of cyberbullying.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Homa Hosseinmardi, Sabrina Arredondo Mattson, Rahat Ibn Rafiq, Richard Han, Qin Lv, Shivakant Mishra,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03905", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03905", "title": "\nLocal Distribution and the Symmetry Gap: Approximability of Multiway  Partitioning Problems", "abstract": "We study the approximability of multiway partitioning problems, examples of which include Multiway Cut, Node-weighted Multiway Cut, and Hypergraph Multiway Cut. We investigate these problems from the point of view of two possible generalizations: as Min-CSPs, and as Submodular Multiway Partition problems. These two generalizations lead to two natural relaxations, the Basic LP, and the Lovasz relaxation. We show that the Lovasz relaxation gives a (2-2/k)-approximation for Submodular Multiway Partition with terminals, improving a recent 2-approximation. We prove that this factor is optimal in two senses: (1) A (2-2/k- epsilon)-approximation for Submodular Multiway Partition with k terminals would require exponentially many value queries. (2) For Hypergraph Multiway Cut and Node-weighted Multiway Cut with k terminals, both special cases of Submodular Multiway Partition, we prove that a (2-2/k- epsilon)-approximation is NP-hard, assuming the Unique Games Conjecture. Both our hardness results are more general: (1) We show that the notion of symmetry gap, previously used for submodular maximization problems, also implies hardness results for submodular minimization problems. (2) Assuming the Unique Games Conjecture, we show that the Basic LP gives an optimal approximation for every Min-CSP that includes the Not-Equal predicate. Finally, we connect the two hardness techniques by proving that the integrality gap of the Basic LP coincides with the symmetry gap of the multilinear relaxation (for a related instance). This shows that the appearance of the same hardness threshold for a Min-CSP and the related submodular minimization problem is not a coincidence.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Alina Ene, Jan Vondrak, Yi Wu,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03903", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03903", "title": "\nApproximating Sparse PCA from Incomplete Data", "abstract": "We study how well one can recover sparse principal components of a data matrix using a sketch formed from a few of its elements. We show that for a wide class of optimization problems, if the sketch is close (in the spectral norm) to the original data matrix, then one can recover a near optimal solution to the optimization problem by using the sketch. In particular, we use this approach to obtain sparse principal components and show that for math data points in math dimensions, math tilde k max ) elements gives an math-additive approximation to the sparse PCA problem ( math is the stable rank of the data matrix). We demonstrate our algorithms extensively on image, text, biological and financial data. The results show that not only are we able to recover the sparse PCAs from the incomplete data, but by using our sparse sketch, the running time drops by a factor of five or more.", "subjects": "Learning (cs.LG)", "authors": "Abhisek Kundu, Petros Drineas, Malik Magdon-Ismail,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03887", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03887", "title": "\nIntelligent Device Used by an Infotmation System for Identifying and  Monitoring of Patients", "abstract": "The aim of this paper consists in defining the hardware and software architecture of an embedded system, based on RFID technology, in order to identify patients and to achieve real time information concerning the patients biometric data, which might be used in different points of the health system (laboratory, family physician, etc.).", "subjects": "Computers and Society (cs.CY)", "authors": "Ioan Ungureanu, Cristina Elena Turcu, Cornel Turcu, Vasile Gheorghita Gaitan,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03884", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03884", "title": "\nAn RFID-based Clinical Information System for Identification and  Monitoring of Patients", "abstract": "Managing health-care records and information is an imperative necessity. Most patient health records are stored in separate systems and there are still huge paper trails of records that health-care providers must keep to comply with different regulations. This paper proposes an RFID-based system, named SIMOPAC, that integrate RFID technology in health care in order to make patient emergency care as efficient and risk-free as possible, by providing doctors with as much information about a patient as quickly as possible. Every hospital could use SIMOPAC with their existing system in order to promote patient safety and optimize hospital workflow. We will concentrate on the RFID technology and how it could be used in emergency care. We describe a general purpose architecture and data model that is designed for collecting ambulatory data from various existing devices and systems, as well as for storing and presenting clinically significant information to the emergency care physician.", "subjects": "Computers and Society (cs.CY)", "authors": "Turcu Cristina, Cerlinca Tudor, Cerlinca Marius, Prodan Remus, Turcu Cornel, G\u00eeza Felicia,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03880", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03880", "title": "\nModeling and Energy Optimization of LDPC Decoder Circuits with Timing  Violations", "abstract": "This paper proposes a quasi-synchronous design approach for signal processing circuits, in which timing violations are permitted, but without the need for a hardware compensation mechanism. The error-correction performance of low-density parity-check (LDPC) code ensembles is evaluated using density evolution while taking into account the effect of timing faults, and a method for accurately modeling the effect of faults at a high level of abstraction is presented. Following this, several quasi-synchronous LDPC decoder circuits are designed based on the offset min-sum algorithm, providing a 27%-38% reduction in energy consumption or energy-delay product, while achieving the same performance and occupying the same area as conventional synchronous circuits.", "subjects": "Information Theory (cs.IT)", "authors": "Fran\u00e7ois Leduc-Primeau, Frank R. Kschischang, Warren J. Gross,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03877", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03877", "title": "\nConstructing and Employing Tree Alignment Graphs for Phylogenetic  Synthesis", "abstract": "Tree alignment graphs (TAGs) provide an intuitive data structure for storing phylogenetic trees that exhibits the relationships of the individual input trees and can potentially account for nested taxonomic relationships. This paper provides a theoretical foundation for the use of TAGs in phylogenetics. We provide a formal definition of TAG that - unlike previous definition - does not depend on the order in which input trees are provided. In the consensus case, when all input trees have the same leaf labels, we describe algorithms for constructing majority-rule and strict consensus trees using the TAG. When the input trees do not have identical sets of leaf labels, we describe how to determine if the input trees are compatible and, if they are compatible, to construct a supertree that contains the input trees.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Ruchi Chaudhary, David Fernandez-Baca, J. Gordon Burleigh,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03851", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03851", "title": "\nSatisfiability of Ordering CSPs Above Average", "abstract": "We study the satisfiability of ordering constraint satisfaction problems (CSPs) above average. We show that for every k, the satisfiability above average of ordering CSPs of arity at most k is fixed-parameter tractable.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Konstantin Makarychev, Yury Makarychev, Yuan Zhou,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03832", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03832", "title": "\nFaceNet: A Unified Embedding for Face Recognition and Clustering", "abstract": "Despite significant recent advances in the field of face recognition, implementing face verification and recognition efficiently at scale presents serious challenges to current approaches. In this paper we present a system, called FaceNet, that directly learns a mapping from face images to a compact Euclidean space where distances directly correspond to a measure of face similarity. Once this space has been produced, tasks such as face recognition, verification and clustering can be easily implemented using standard techniques with FaceNet embeddings as feature vectors. Our method uses a deep convolutional network trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches. To train, we use triplets of roughly aligned matching / non-matching face patches generated using a novel online triplet mining method. The benefit of our approach is much greater representational efficiency: we achieve state-of-the-art face recognition performance using only 128-bytes per face. On the widely used Labeled Faces in the Wild (LFW) dataset, our system achieves a new record accuracy of 99.63%. On YouTube Faces DB it achieves 95.12%. Our system cuts the error rate in comparison to the best published result by 30% on both datasets.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Florian Schroff, Dmitry Kalenichenko, James Philbin,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03821", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03821", "title": "\nA Class of Random Sequences for Key Generation", "abstract": "This paper investigates randomness properties of sequences derived from Fibonacci and Gopala-Hemachandra sequences modulo m for use in key distribution applications. We show that for sequences modulo a prime a binary random sequence B(n) is obtained based on whether the period is p-1 (or a divisor) or 2p+2 (or a divisor). For the more general case of arbitrary m, we use the property if the period is a multiple of 8 or not. The sequences for prime modulo have much better autocorrelation properties. These are good candidates for key distribution since the generation process is not computationally complex.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Krishnamurthy Kirthi, Subhash Kak,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03818", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03818", "title": "\nPractical Realization of the Self-Balancing Robot Using Infrared Sensors", "abstract": "The idea of a two wheel self-balancing robot has become very popular among control system researchers worldwide over the last decade. This paper presents a one variant of the implementation of the self-balancing robot using the VEX Robotics Kit.", "subjects": "Robotics (cs.RO)", "authors": "Bauyrzhan Aubakir, Zhanat Kappasov, Almas Shintemirov,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.03794", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03794", "title": "\nRadix-2 Fast Hartley Transform Revisited", "abstract": "A Fast algorithm for the Discrete Hartley Transform (DHT) is presented, which resembles radix-2 fast Fourier Transform (FFT). Although fast DHTs are already known, this new approach bring some light about the deep relationship between fast DHT algorithms and a multiplication-free fast algorithm for the Hadamard Transform.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "H.M. de Oliveira, V.L. Sousa, H.A.N., R.M. Campello de Souza,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03791", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03791", "title": "\nLifting of Multicuts", "abstract": "For every simple, undirected graph , a one-to-one relation exists between the decompositions and the multicuts of . A decomposition of is a partition of such that, for every , the subgraph of is connected. A multicut of is a subset of edges, , such that, for every (chordless) cycle of , . The characteristic function of a multicut of makes explicit, for every , whether and are in distinct components. In order to make explicit, for every with , whether and are in distinct components, we define a lifting of the multicuts of to multicuts of . We show that, if is connected, the convex hull, in , of the characteristic functions of those multicuts of that are lifted from is a full, -dimensional 01-polytope.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Bjoern Andres,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03790", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03790", "title": "\nSound-Proof: Usable Two-Factor Authentication Based on Ambient Sound", "abstract": "Two-factor authentication protects online accounts even if passwords are leaked. Most users, however, still prefer password-only authentication. One of the reasons behind two-factor authentication being unpopular is the extra steps that the user must complete in order to log in. Current two-factor authentication mechanisms require the user to interact with his phone, and e.g., copy a verification code to the browser. In this paper we propose Sound-Proof, a two-factor authentication mechanism that does not require interaction between the user and his phone. In Sound-Proof the second authentication factor is the proximity of the user's phone to the device being used to log in. The proximity of the two devices is verified by comparing the ambient noise recorded by their microphones. Audio recording and comparison are transparent to the user. Sound-Proof can be easily deployed as it works with major browsers without plugins. We build a prototype for both Android and iOS. We provide empirical evidence that ambient noise is a robust discriminant to determine the proximity of two devices both indoors and outdoors, and even if the phone is in a pocket or purse. We further conduct a user study designed to compare the perceived usability of Sound-Proof with Google 2-Step Verification. Participants ranked Sound-Proof as more usable and the majority would be willing to use Sound-Proof even for scenarios in which two-factor authentication is optional.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Nikolaos Karapanos, Claudio Marforio, Claudio Soriente, Srdjan Capkun,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.03787", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03787", "title": "\nAre there intelligent Turing machines?", "abstract": "This paper introduces a new computing model based on the cooperation among Turing machines called orchestrated machines. Like universal Turing machines, orchestrated machines are also designed to simulate Turing machines but they can also modify the original operation of the included Turing machines to create a new layer of some kind of collective behavior. Using this new model we can define some interested notions related to cooperation ability of Turing machines such as the intelligence quotient or the emotional intelligence quotient for Turing machines.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Norbert B\u00e1tfai,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03771", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03771", "title": "\nLearning to Detect Vehicles by Clustering Appearance Patterns", "abstract": "This paper studies efficient means for dealing with intra-category diversity in object detection. Strategies for occlusion and orientation handling are explored by learning an ensemble of detection models from visual and geometrical clusters of object instances. An AdaBoost detection scheme is employed with pixel lookup features for fast detection. The analysis provides insight into the design of a robust vehicle detection system, showing promise in terms of detection performance and orientation estimation accuracy.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Eshed Ohn-Bar, Mohan M. Trivedi,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03767", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03767", "title": "\nExploiting Near Time Forecasting From Social Network To Decongest  Traffic", "abstract": "Preventing traffic congestion by forecasting near time traffic flows is an important problem as it leads to effective use of transport resources. Social network provides information about activities of humans and social events. Thus, with the help of social network, we can extract which humans will attend a particular event (in near time) and can estimate flow of traffic based on it. This opens up a wide area of research which poses need to have a framework for traffic management that can capture essential parameters of real-life behaviour and provide a way to iterate upon and evaluate new ideas. In this paper, we present building blocks of a framework and a system to simulate a city with its transport system, humans and their social network. We emphasize on relevant parameters selected and modular design of the framework. Our framework defines metrics to evaluate congestion avoidance strategies. To show utility of the framework, we present experimental studies of few strategies on a public transport system.", "subjects": "Multiagent Systems (cs.MA)", "authors": "Deepika Pathania, Kamalakar Karlapalem,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03763", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03763", "title": "\nThe Discrete Cosine Transform over Prime Finite Fields", "abstract": "This paper examines finite field trigonometry as a tool to construct trigonometric digital transforms. In particular, by using properties of the k-cosine function over GF(p), the Finite Field Discrete Cosine Transform (FFDCT) is introduced. The FFDCT pair in GF(p) is defined, having blocklengths that are divisors of (p+1)/2. A special case is the Mersenne FFDCT, defined when p is a Mersenne prime. In this instance blocklengths that are powers of two are possible and radix-2 fast algorithms can be used to compute the transform.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "M.M. Campello de Souza, H.M. de Oliveira, R.M. Campello de Souza, M.M. Vasconcelos,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03753", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03753", "title": "\nFrom Group Recommendations to Group Formation", "abstract": "There has been significant recent interest in the area of group recommendations, where, given groups of users of a recommender system, one wants to recommend top-k items to a group that maximize the satisfaction of the group members, according to a chosen semantics of group satisfaction. Examples semantics of satisfaction of a recommended itemset to a group include the so-called least misery (LM) and aggregate voting (AV). We consider the complementary problem of how to form groups such that the users in the formed groups are most satisfied with the suggested top-k recommendations. We assume that the recommendations will be generated according to one of the two group recommendation semantics - LM or AV. Rather than assuming groups are given, or rely on ad hoc group formation dynamics, our framework allows a strategic approach for forming groups of users in order to maximize satisfaction. We show that the problem is NP-hard to solve optimally under both semantics. Furthermore, we develop two efficient algorithms for group formation under LM and show that they achieve bounded absolute error. We develop efficient heuristic algorithms for group formation under AV. We validate our results and demonstrate the scalability and effectiveness of our group formation algorithms on two large real data sets.", "subjects": "Information Retrieval (cs.IR)", "authors": "Senjuti Basu Roy, Laks V. S. Lakshmanan, Rui Liu,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03752", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03752", "title": "\nManipulation and abuse on social media", "abstract": "The computer science research community has became increasingly interested in the study of social media due to their pervasiveness in the everyday life of millions of individuals. Methodological questions and technical challenges abound as more and more data from social platforms become available for analysis. This data deluge not only yields the unprecedented opportunity to unravel questions about online individuals' behavior at scale, but also allows to explore the potential perils that the massive adoption of social media brings to our society. These communication channels provide plenty of incentives (both economical and social) and opportunities for abuse. As social media activity became increasingly intertwined with the events in the offline world, individuals and organizations have found ways to exploit these platforms to spread misinformation, to attack and smear others, or to deceive and manipulate. During crises, social media have been effectively used for emergency response, but fear-mongering actions have also triggered mass hysteria and panic. Criminal gangs and terrorist organizations like ISIS adopt social media for propaganda and recruitment. Synthetic activity and social bots have been used to coordinate orchestrated astroturf campaigns, to manipulate political elections and the stock market. The lack of effective content verification systems on many of these platforms, including Twitter and Facebook, rises concerns when younger users become exposed to cyber-bulling, harassment, or hate speech, inducing risks like depression and suicide. This article illustrates some of the recent advances facing these issues and discusses what it remains to be done, including the challenges to address in the future to make social media a more useful and accessible, safer and healthier environment for all users.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Emilio Ferrara,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.03741", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03741", "title": "\n2D Face Recognition System Based on Selected Gabor Filters and Linear  Discriminant Analysis LDA", "abstract": "We present a new approach for face recognition system. The method is based on 2D face image features using subset of non-correlated and Orthogonal Gabor Filters instead of using the whole Gabor Filter Bank, then compressing the output feature vector using Linear Discriminant Analysis (LDA). The face image has been enhanced using multi stage image processing technique to normalize it and compensate for illumination variation. Experimental results show that the proposed system is effective for both dimension reduction and good recognition performance when compared to the complete Gabor filter bank. The system has been tested using CASIA, ORL and Cropped YaleB 2D face images Databases and achieved average recognition rate of 98.9 %.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Samir F. Hafez, Mazen M. Selim, Hala H. Zayed,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03739", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03739", "title": "\nPrice of Stability in Games of Incomplete Information", "abstract": "We address the question of whether price of stability results (existence of equilibria with low social cost) are robust to incomplete information. We show that this is the case in potential games, if the underlying algorithmic social cost minimization problem admits a constant factor approximation algorithm via strict cost-sharing schemes. Roughly, if the existence of an -approximate equilibrium in the complete information setting was proven via the potential method, then there also exists a -approximate Bayes-Nash equilibrium in the incomplete information setting, where is the approximation factor of the strict-cost sharing scheme algorithm. We apply our approach to Bayesian versions of the archetypal, in the price of stability analysis, network design models and show the existence of -approximate Bayes-Nash equilibria in several games whose complete information counterparts have been well-studied, such as undirected network design games, multi-cast games and covering games.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Vasilis Syrgkanis,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03732", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03732", "title": "\nStarting engagement detection towards a companion robot using multimodal  features", "abstract": "Recognition of intentions is a subconscious cognitive process vital to human communication. This skill enables anticipation and increases the quality of interactions between humans. Within the context of engagement, non-verbal signals are used to communicate the intention of starting the interaction with a partner. In this paper, we investigated methods to detect these signals in order to allow a robot to know when it is about to be addressed. Originality of our approach resides in taking inspiration from social and cognitive sciences to perform our perception task. We investigate meaningful features, i.e. human readable features, and elicit which of these are important for recognizing someone's intention of starting an interaction. Classically, spatial information like the human position and speed, the human-robot distance are used to detect the engagement. Our approach integrates multimodal features gathered using a companion robot equipped with a Kinect. The evaluation on our corpus collected in spontaneous conditions highlights its robustness and validates the use of such a technique in a real environment. Experimental validation shows that multimodal features set gives better precision and recall than using only spatial and speed features. We also demonstrate that 7 selected features are sufficient to provide a good starting engagement detection score. In our last investigation, we show that among our full 99 features set, the space reduction is not a solved task. This result opens new researches perspectives on multimodal engagement detection.", "subjects": "Robotics (cs.RO)", "authors": "Dominique Vaufreydaz, Wafa Johal, Claudine Combe,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03712", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03712", "title": "\nOn Graduated Optimization for Stochastic Non-Convex Problems", "abstract": "The graduated optimization approach, also known as the continuation method, is a popular heuristic to solving non-convex problems that has received renewed interest over the last decade. Despite its popularity, very little is known in terms of theoretical convergence analysis. In this paper we describe a new first-order algorithm based on graduated optimiza- tion and analyze its performance. We characterize a parameterized family of non- convex functions for which this algorithm provably converges to a global optimum. In particular, we prove that the algorithm converges to an -approximate solution within O(1/ epsilon^2) gradient-based steps. We extend our algorithm and analysis to the setting of stochastic non-convex optimization with noisy gradient feedback, attaining the same convergence rate. Additionally, we discuss the setting of zero-order optimization, and devise a a variant of our algorithm which converges at rate of O(d^2/ epsilon^4).", "subjects": "Learning (cs.LG)", "authors": "Elad Hazan, Kfir Y. Levy, Shai Shalev-Swartz,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03674", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03674", "title": "\nA novel hash based least significant bit (2-3-3) image steganography in  spatial domain", "abstract": "This paper presents a novel 2-3-3 LSB insertion method. The image steganography takes the advantage of human eye limitation. It uses color image as cover media for embedding secret message.The important quality of a steganographic system is to be less distortive while increasing the size of the secret message. In this paper a method is proposed to embed a color secret image into a color cover image. A 2-3-3 LSB insertion method has been used for image steganography. Experimental results show an improvement in the Mean squared error (MSE) and Peak Signal to Noise Ratio (PSNR) values of the proposed technique over the base technique of hash based 3-3-2 LSB insertion.", "subjects": "Multimedia (cs.MM)", "authors": "G. R. Manjula, Ajit Danti,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03660", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03660", "title": "\nCapturing, Documenting and Visualizing Search Contexts for building  Multimedia Corpora", "abstract": "In Social Science research, multimedia documents are often collected to answer particular research questions like: \"Which of the aesthetic properties of a photo are considered important on the web\" or \"How has Street Art developed over the past 50 years\". Therefore, a researcher generally issues multiple queries to a number of search engines. This activity may span over long time intervals and results in a collection which can be further analyzed. Documenting the collection building process which includes the context of the carried out searches is imperative for social scientists to reproduce their research. Such context documentation consists of several user actions and search attributes like: the issued queries; the results clicked and saved; duration a particular result was viewed for; the set of results that was displayed but neither clicked, nor saved; as well as user annotations like comments or tags. In this work we will describe a search process tracking module and a search history visualization module. These modules can be integrated into keyword based search systems through a REST API which was developed to help capture, document and revisit past search contexts while building a web corpora. Finally, we detail the implementation of how the module was integrated into the LearnWeb2.0 platform - a multimedia web2.0 search and sharing application which can obtain resources from various web2.0 tools such as Youtube, Bing, Flickr, etc using keyword search.", "subjects": "Information Retrieval (cs.IR)", "authors": "Zeon Trevor Fernando,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03653", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03653", "title": "\nAdaptive Logging for Distributed In-memory Databases", "abstract": "By maintaining the data in main memory, in-memory databases dramatically reduce the I/O cost of transaction processing. However, for recovery purpose, those systems still need to flush the logs to disk, generating a significant number of I/Os. A new type of logs, the command log, is being employed to replace the traditional data log (e.g., ARIES log). A command log only tracks the transactions being executed, thereby effectively reducing the size of the log and improving the performance. Command logging on the other hand increases the cost of recovery, because all the transactions in the log after the last checkpoint must be completely redone when there is a failure. For distributed database systems with many processing nodes, failures cannot be assumed as exceptions, and as such, the long recovery time incurred by command logging may compromise the objective of providing efficient support for OLTP. In this paper, we first extend the command logging to a distributed system, where all the nodes can perform their recovery in parallel. Showing that the synchronisation cost caused by dependency is the bottleneck for command logging in a distributed system, We consequently propose an adaptive logging approach by combining data logging and command logging. The intuition is to use data logging to break the dependency, while applying command logging for most transactions to reduce I/O costs. The percentage of data logging versus command logging becomes an optimization between the performance of transaction processing and recovery to suit different OLTP applications. Our experimental study compares the performance of our proposed adaptive logging, ARIES style data logging and command logging on top of H-Store. The results show that adaptive logging can achieve a 10x boost for recovery and a transaction throughput that is comparable to that of command logging.", "subjects": "Databases (cs.DB)", "authors": "Chang Yao, Divyakant Agrawal, Gang Chen, Beng Chin Ooi, Sai Wu,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03650", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03650", "title": "\nGeo-SAGE: A Geographical Sparse Additive Generative Model for Spatial  Item Recommendation", "abstract": "With the rapid development of location-based social networks (LBSNs), spatial item recommendation has become an important means to help people discover attractive and interesting venues and events, especially when users travel out of town. However, this recommendation is very challenging compared to the traditional recommender systems. A user can visit only a limited number of spatial items, leading to a very sparse user-item matrix. Most of the items visited by a user are located within a short distance from where he/she lives, which makes it hard to recommend items when the user travels to a far away place. Moreover, user interests and behavior patterns may vary dramatically across different geographical regions. In light of this, we propose Geo-SAGE, a geographical sparse additive generative model for spatial item recommendation in this paper. Geo-SAGE considers both user personal interests and the preference of the crowd in the target region, by exploiting both the co-occurrence pattern of spatial items and the content of spatial items. To further alleviate the data sparsity issue, Geo-SAGE exploits the geographical correlation by smoothing the crowd's preferences over a well-designed spatial index structure called spatial pyramid. We conduct extensive experiments to evaluate the performance of our Geo-SAGE model on two real large-scale datasets. The experimental results clearly demonstrate our Geo-SAGE model outperforms the state-of-the-art in the two tasks of both out-of-town and home-town recommendations.", "subjects": "Information Retrieval (cs.IR)", "authors": "Weiqing Wang, Hongzhi Yin, Ling Chen, Yizhou Sun, Shazia Sadiq, Xiaofang Zhou,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03642", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03642", "title": "\nDGCC:A New Dependency Graph based Concurrency Control Protocol for  Multicore Database Systems", "abstract": "Multicore CPUs and large memories are increasingly becoming the norm in modern computer systems. However, current database management systems (DBMSs) are generally ineffective in exploiting the parallelism of such systems. In particular, contention can lead to a dramatic fall in performance. In this paper, we propose a new concurrency control protocol called DGCC (Dependency Graph based Concurrency Control) that separates concurrency control from execution. DGCC builds dependency graphs for batched transactions before executing them. Using these graphs, contentions within the same batch of transactions are resolved before execution. As a result, the execution of the transactions does not need to deal with contention while maintaining full equivalence to that of serialized execution. This better exploits multicore hardware and achieves higher level of parallelism. To facilitate DGCC, we have also proposed a system architecture that does not have certain centralized control components yielding better scalability, as well as supports a more efficient recovery mechanism. Our extensive experimental study shows that DGCC achieves up to four times higher throughput compared to that of state-of-the-art concurrency control protocols for high contention workloads.", "subjects": "Databases (cs.DB)", "authors": "Chang Yao, Divyakant Agrawal, Pengfei Chang, Gang Chen, Beng Chin Ooi, Weng-Fai Wong, Meihui Zhang,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03639", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03639", "title": "\nQoS Guaranteed Intelligent Routing Using Hybrid PSO-GA in Wireless Mesh  Networks", "abstract": "In Multi-Channel Multi-Radio Wireless Mesh Networks (MCMR-WMN), finding the optimal routing by satisfying the Quality of Service (QoS) constraints is an ambitious task. Multiple paths are available from the source node to the gateway for reliability, and sometimes it is necessary to deal with failures of the link in WMN. A major challenge in a MCMR-WMN is finding the routing with QoS satisfied and an interference free path from the redundant paths, in order to transmit the packets through this path. The Particle Swarm Optimization (PSO) is an optimization technique to find the candidate solution in the search space optimally, and it applies artificial intelligence to solve the routing problem. On the other hand, the Genetic Algorithm (GA) is a population based meta-heuristic optimization algorithm inspired by the natural evolution, such as selection,mutation and crossover. PSO can easily fall into a local optimal solution, at the same time GA is not suitable for dynamic data due to the underlying dynamic network. In this paper we propose an optimal intelligent routing, using a Hybrid PSO-GA, which also meets the QoS constraints. Moreover, it integrates the strength of PSO and GA. The QoS constraints, such as bandwidth, delay, jitter and interference are transformed into penalty functions. The simulation results show that the hybrid approach outperforms PSO and GA individually, and it takes less convergence time comparatively, keeping away from converging prematurely. Keywords: Wireless mesh networks, Multi-radio, Multi-channel, Particle swarm optimization, Genetic algorithm, Quality of service.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "V. Sarasvathi, N. Ch. S. N. Iyengar, Snehanshu Saha,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03637", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03637", "title": "\nOn Computing the Translations Norm in the Epipolar Graph", "abstract": "This paper deals with the problem of recovering the unknown norm of relative translations between cameras based on the knowledge of relative rotations and translation directions. We provide and demonstrate theoretical conditions that guarantee solvability of such a problem, and propose an efficient two-stage method to solve it. First, a suitable set of cycles for the epipolar graph is computed, then all the scaling factors are recovered simultaneously by solving a homogeneous linear system. Moreover, we have successfully embedded our technique into a method for computing the absolute translations which is linear and takes as input the relative orientations only. The accuracy of both our solution for computing the scaling factors and the derived method for the absolute translations has been demonstrated by means of synthetic and real experiments.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Federica Arrigoni, Beatrice Rossi, Andrea Fusiello,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03635", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03635", "title": "\nScalable Facility Location for Massive Graphs on Pregel-like Systems", "abstract": "We propose a new scalable algorithm for facility location. Facility location is a classic problem, where the goal is to select a subset of facilities to open, from a set of candidate facilities F , in order to serve a set of clients C. The objective is to minimize the total cost of opening facilities plus the cost of serving each client from the facility it is assigned to. In this work, we are interested in the graph setting, where the cost of serving a client from a facility is represented by the shortest-path distance on the graph. This setting allows to model natural problems arising in the Web and in social media applications. It also allows to leverage the inherent sparsity of such graphs, as the input is much smaller than the full pairwise distances between all vertices. To obtain truly scalable performance, we design a parallel algorithm that operates on clusters of shared-nothing machines. In particular, we target modern Pregel-like architectures, and we implement our algorithm on Apache Giraph. Our solution makes use of a recent result to build sketches for massive graphs, and of a fast parallel algorithm to find maximal independent sets, as building blocks. In so doing, we show how these problems can be solved on a Pregel-like architecture, and we investigate the properties of these algorithms. Extensive experimental results show that our algorithm scales gracefully to graphs with billions of edges, while obtaining values of the objective function that are competitive with a state-of-the-art sequential algorithm.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Kiran Garimella, Gianmarco De Francisci Morales, Aristides Gionis, Mauro Sozio,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03630", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03630", "title": "\nSingle image super-resolution by approximated Heaviside functions", "abstract": "Image super-resolution is a process to enhance image resolution. It is widely used in medical imaging, satellite imaging, target recognition, etc. In this paper, we conduct continuous modeling and assume that the unknown image intensity function is defined on a continuous domain and belongs to a space with a redundant basis. We propose a new iterative model for single image super-resolution based on an observation: an image is consisted of smooth components and non-smooth components, and we use two classes of approximated Heaviside functions (AHFs) to represent them respectively. Due to sparsity of the non-smooth components, a model is employed. In addition, we apply the proposed iterative model to image patches to reduce computation and storage. Comparisons with some existing competitive methods show the effectiveness of the proposed method.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Liang-Jian Deng, Weihong Guo, Ting-Zhu Huang,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03621", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03621", "title": "\nDesigning A Composite Dictionary Adaptively From Joint Examples", "abstract": "We propose a novel composite dictionary design framework. The composite dictionary consists of global and sample-specific parts, learned from external and internal examples, respectively. We explicitly formulate the metric weights that adaptively correlate sparse codes with base dictionary atoms. The contrasting behaviors of external and internal examples are studied for different modelings. Experiments demonstrate that the joint utilization of external and internal examples outperforms either stand-alone. The proposed method is successfully applied to image denoising and image super resolution.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Zhangyang Wang, Yingzhen Yang, Jianchao Yang, Thomas S. Huang,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03614", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03614", "title": "\nAndroid based Portable Hand Sign Recognition System", "abstract": "These days mobile devices like phones or tablets are very common among people of all age. They are connected with network and provide seamless communications through internet or cellular services. These devices can be a big help for the people who are not able to communicate properly and even in emergency conditions. A disabled person who is not able to speak or a person who speak a different language, these devices can be a boon for them as understanding, translating and speaking systems for these people. This chapter discusses a portable android based hand sign recognition system which can be used by disabled people. This chapter shows a part of on-going project. Computer Vision based techniques were used for image analysis and PCA was used after image tokenizer for recognition. This method was tested with webcam results to make system more robust.", "subjects": "Human-Computer Interaction (cs.HC)", "authors": "Jagdish L. Raheja, A. Singhal, A. Chaudhary,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03608", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03608", "title": "\nRegularization Parameter Selection Method for Sign LMS with Reweighted  L1-Norm Constriant Algorithm", "abstract": "Broadband frequency-selective fading channels usually have the inherent sparse nature. By exploiting the sparsity, adaptive sparse channel estimation (ASCE) algorithms, e.g., least mean square with reweighted L1-norm constraint (LMS-RL1) algorithm, could bring a considerable performance gain under assumption of additive white Gaussian noise (AWGN). In practical scenario of wireless systems, however, channel estimation performance is often deteriorated by unexpected non-Gaussian mixture noises which include AWGN and impulsive noises. To design stable communication systems, sign LMS-RL1 (SLMS-RL1) algorithm is proposed to remove the impulsive noise and to exploit channel sparsity simultaneously. It is well known that regularization parameter (REPA) selection of SLMS-RL1 is a very challenging issue. In the worst case, inappropriate REPA may even result in unexpected instable convergence of SLMS-RL1 algorithm. In this paper, Monte Carlo based selection method is proposed to select suitable REPA so that SLMS-RL1 can achieve two goals: stable convergence as well as usage sparsity information. Simulation results are provided to corroborate our studies.", "subjects": "Information Theory (cs.IT)", "authors": "Guan Gui, Hongyun Wei, Nobuhiro Shimoi, Li Xu,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03607", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03607", "title": "\nA divisive hierarchical clustering-based method for indexing image  information", "abstract": "In most practical applications of image retrieval, high-dimensional feature vectors are required, but current multi-dimensional indexing structures lose their efficiency with growth of dimensions. Our goal is to propose a divisive hierarchical clustering-based multi-dimensional indexing structure which is efficient in high-dimensional feature spaces. A projection pursuit method has been used for finding a component of the data, which data's projections onto it maximizes the approximation of negentropy for preparing essential information in order to partitioning of the data space. Various tests and experimental results on high-dimensional datasets indicate the performance of proposed method in comparison with others.", "subjects": "Information Retrieval (cs.IR)", "authors": "Najva Izadpanah,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03606", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03606", "title": "\nLow-Level Features for Image Retrieval Based on Extraction of  Directional Binary Patterns and Its Oriented Gradients Histogram", "abstract": "In this paper, we present a novel approach for image retrieval based on extraction of low level features using techniques such as Directional Binary Code, Haar Wavelet transform and Histogram of Oriented Gradients. The DBC texture descriptor captures the spatial relationship between any pair of neighbourhood pixels in a local region along a given direction, while Local Binary Patterns descriptor considers the relationship between a given pixel and its surrounding neighbours. Therefore, DBC captures more spatial information than LBP and its variants, also it can extract more edge information than LBP. Hence, we employ DBC technique in order to extract grey level texture feature from each RGB channels individually and computed texture maps are further combined which represents colour texture features of an image. Then, we decomposed the extracted colour texture map and original image using Haar wavelet transform. Finally, we encode the shape and local features of wavelet transformed images using Histogram of Oriented Gradients for content based image retrieval. The performance of proposed method is compared with existing methods on two databases such as Wang's corel image and Caltech 256. The evaluation results show that our approach outperforms the existing methods for image retrieval.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Nagaraja S., Prabhakar C.J.,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03605", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03605", "title": "\nSimplified numerical realization of elastoplastic constitutive problems:  PART I - criteria given by Haigh-Westergaard coordinates", "abstract": "The paper is devoted to numerical realization of elastoplastic problems. The main goal is to improve implementation of the related constitutive problems. This can be done if plastic flow rules are defined by subdifferentials of plastic potentials. Then just one plastic multiplier is used even if the plastic potentials are nondifferentiable for unknown stress tensors. Further, the implicit Euler time discretization scheme is considered and the standard elastic predictor - plastic corrector method is used to find the discretized constitutive solution. Due to the presence of the one multiplier, it is possible to construct a unique system of nonlinear equations within the plastic correction regardless the unknown stress tensor lies on the smooth portion of the yield surface or not. Plastic criteria given by the Haigh-Westergaard coordinates are investigated in this paper (PART I). The suggested method is in detail studied on the problem containing the Drucker-Prager criterion, a nonassociative plastic flow rule and a nonlinear isotropic hardening. It is shown that for this problem, one can a priori decide whether the unknown stress tensor will lie on the smooth portion or at the apex of the yield surface. The corresponding tangential (consistent) stiffness matrix is constructed and the elastoplastic problem is solved by the semismooth Newton method. The new method is implemented within the in house software SIFEL and several numerical experiments are introduced.", "subjects": "Computational Engineering, Finance, and Science (cs.CE)", "authors": "Martin Cermak, Jaroslav Kruis, Tomas Koudelka, Stanislav Sysala, Jan Zeman,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03600", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03600", "title": "\nDetection Algorithms for Molecular MIMO", "abstract": "In this paper, we propose a novel design for molecular communication in which both the transmitter and the receiver have, in a 3-dimensional environment, multiple bulges (in RF communication this corresponds to antenna). The proposed system consists of a fluid medium, information molecules, a transmitter, and a receiver. We simulate the system with a one-shot signal to obtain the channel's finite impulse response. We then incorporate this result within our mathematical analysis to determine interference. Molecular communication has a great need for low complexity, hence, the receiver may have incomplete information regarding the system and the channel state. Thus, for the cases of limited information set at the receiver, we propose three detection algorithms, namely adaptive thresholding, practical zero forcing, and Genie-aided zero forcing.", "subjects": "Emerging Technologies (cs.ET)", "authors": "Bonhong Koo, H. Birkan Yilmaz, Andrew Eckford, Chan-Byoung Chae,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03597", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03597", "title": "\nNonadaptive group testing with random set of defectives via  constant-weight codes", "abstract": "In a group testing scheme, set of tests are designed to identify a small number of defective items that are present among a large number of items. Each test takes as input a group of items and produces a binary output indicating whether any defective item is present in the group. In this paper we consider the nonadaptive scenario where defective items are random and follow simple probability distributions. In particular we consider the cases where 1) each item can be defective independently with probability and 2) each -set of items can be defective with uniform probability. In both cases our aim is to design a testing matrix that successfully identifies the set of defectives with high probability. Both of these models have been studied in the literature before and it is known that tests are necessary as well as sufficient (via random coding) in both cases. Our main focus is explicit deterministic construction of the test matrices amenable to above scenarios. One of the most popular ways of constructing test matrices relies on constant-weight error-correcting codes and their minimum distance. In particular, it is known that codes result in test matrices with rows that identify any defectives. With our relaxed requirements, we show that using an explicit constant-weight code we may achieve a number of tests equal to for the first case and for the second case. While still away by a factor of and respectively from the optimal number of tests, one may note that our constructions are deterministic and the main contribution lies in relating the group testing properties to parameters of constant-weight codes.", "subjects": "Information Theory (cs.IT)", "authors": "Arya Mazumdar,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03594", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03594", "title": "\nEfficient Learning of Linear Separators under Bounded Noise", "abstract": "We study the learnability of linear separators in in the presence of bounded (a.k.a Massart) noise. This is a realistic generalization of the random classification noise model, where the adversary can flip each example with probability . We provide the first polynomial time algorithm that can learn linear separators to arbitrarily small excess error in this noise model under the uniform distribution over the unit ball in , for some constant value of . While widely studied in the statistical learning theory community in the context of getting faster convergence rates, computationally efficient algorithms in this model had remained elusive. Our work provides the first evidence that one can indeed design algorithms achieving arbitrarily small excess error in polynomial time under this realistic noise model and thus opens up a new and exciting line of research. We additionally provide lower bounds showing that popular algorithms such as hinge loss minimization and averaging cannot lead to arbitrarily small excess error under Massart noise, even under the uniform distribution. Our work instead, makes use of a margin based technique developed in the context of active learning. As a result, our algorithm is also an active learning algorithm with label complexity that is only a logarithmic the desired excess error .", "subjects": "Learning (cs.LG)", "authors": "Pranjal Awasthi, Maria-Florina Balcan, Nika Haghtalab, Ruth Urner,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03593", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03593", "title": "\nState of the art parallel approaches for RSA public key based  cryptosystem", "abstract": "RSA is one of the most popular Public Key Cryptography based algorithm mainly used for digital signatures, encryption/decryption etc. It is based on the mathematical scheme of factorization of very large integers which is a compute-intensive process and takes very long time as well as power to perform. Several scientists are working throughout the world to increase the speedup and to decrease the power consumption of RSA algorithm while keeping the security of the algorithm intact. One popular technique which can be used to enhance the performance of RSA is parallel programming. In this paper we are presenting the survey of various parallel implementations of RSA algorithm involving variety of hardware and software implementations.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Sapna Saxena, Bhanu Kapoor,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03585", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03585", "title": "\nDeep Unsupervised Learning using Nonequilibrium Thermodynamics", "abstract": "A central unsolved problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Previous approaches to this problem are subject to tradeoffs between flexibility and tractability. We develop a promising approach that simultaneously achieves both. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps.", "subjects": "Learning (cs.LG)", "authors": "Jascha Sohl-Dickstein, Eric A. Weiss, Niru Maheswaranathan, Surya Ganguli,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03584", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03584", "title": "\nHuman Factors in Software Reliability Engineering", "abstract": "In this paper, we present our vision of the integration of human factors engineering into the software development process. The aim of this approach is to improve the quality of software and to deal with human errors in a systematic way.", "subjects": "Software Engineering (cs.SE)", "authors": "Maria Spichkova, Huai Liu, Mohsen Laali, Heinz W. Schmidt,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03579", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03579", "title": "\nA Study on Optimized Resource Provisioning in Federated Cloud", "abstract": "Cloud computing changed the way of computing as utility services offered through public network. Selecting multiple providers for various computational requirements improves performance and minimizes cost of cloud services than choosing a single cloud provider. Federated cloud improves scalability, cost minimization, performance maximization, collaboration with other providers, multi-site deployment for fault tolerance and recovery, reliability and less energy consumption. Both providers and consumers could benefit from federated cloud where providers serve the consumers by satisfying Service Level Agreement, minimizing overall management and infrastructure cost; consumers get best services with less deployment cost and high availability. Efficient provisioning of resources to consumers in federated cloud is a challenging task. In this paper, the benefits of utilizing services from federated cloud, architecture with various coupling levels, different optimized resource provisioning methods and challenges associated with it are discussed and a comparative study is carried out over these aspects.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Thiruselvan Subramanian, Nickolas Savarimuthu,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03578", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03578", "title": "\nLINE: Large-scale Information Network Embedding", "abstract": "This paper studies the problem of embedding very large information networks into low-dimensional vector spaces, which is useful in many tasks such as visualization, node classification, and link prediction. Most existing graph embedding methods do not scale for real world information networks which usually contain millions of nodes. In this paper, we propose a novel network embedding method called the \"LINE,\" which is suitable for arbitrary types of information networks: undirected, directed, and/or weighted. The method optimizes a carefully designed objective function that preserves both the local and global network structures. An edge-sampling algorithm is proposed that addresses the limitation of the classical stochastic gradient descent and improves both the effectiveness and the efficiency of the inference. Empirical experiments prove the effectiveness of the LINE on a variety of real-world information networks, including language networks, social networks, and citation networks. The algorithm is very efficient, which is able to learn the embedding of a network with millions of vertices and billions of edges in a few hours on a typical single machine. The source code of the LINE is available online.", "subjects": "Learning (cs.LG)", "authors": "Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, Qiaozhu Mei,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03576", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03576", "title": "\nOptimal Resource Allocation in Multicast Device-to-Device Communications  Underlaying LTE Networks", "abstract": "In this paper, we present a framework for resource allocations for multicast device-to-device (D2D) communications underlaying a cellular network. The objective is to maximize the sum throughput of active cellular users (CUs) and feasible D2D groups in a cell, while meeting a certain signal-to-interferenceplus- noise ratio (SINR) constraint for both the CUs and D2D groups. We formulate the problem of power and channel allocation as a mixed integer nonlinear programming (MINLP) problem where one D2D group can reuse the channels of multiple CUs and the channel of each CU can be reused by multiple D2D groups. Distinct from existing approaches in the literature, our formulation and solution methods provide an effective and flexible means to utilize radio resources in cellular networks and share them with multicast groups without causing harmful interference to each other. A variant of the generalized bender decomposition (GBD) is applied to optimally solve the MINLP problem. A greedy algorithm and a low-complexity heuristic solution are then devised. The performance of all schemes is evaluated through extensive simulations. Numerical results demonstrate that the proposed greedy algorithm can achieve closeto- optimal performance, and the heuristic algorithm provides good performance, though inferior than that of the greedy, with much lower complexity.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Hadi Meshgi, Dongmei Zhao, Rong Zheng,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03573", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03573", "title": "\nThree-coloring graphs with no induced seven-vertex path II : using a  triangle", "abstract": "In this paper, we give a polynomial time algorithm which determines if a given graph containing a triangle and no induced seven-vertex path is 3-colorable, and gives an explicit coloring if one exists. In previous work, we gave a polynomial time algorithm for three-coloring triangle-free graphs with no induced seven-vertex path. Combined, our work shows that three-coloring a graph with no induced seven-vertex path can be done in polynomial time.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Maria Chudnovsky, Peter Maceli, Mingxian Zhong,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03571", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03571", "title": "\nA Purely Equational Formalism for Functorial Data Migration", "abstract": "In this paper we describe a simple equational formalism for expressing functorial data migration. A graphical IDE and implementation of this formalism are available at categoricaldata.net/fql.html.", "subjects": "Databases (cs.DB)", "authors": "David I. Spivak, Patrick Schultz, Ryan Wisnesky,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03562", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03562", "title": "\nTraining Binary Multilayer Neural Networks for Image Classification  using Expectation Backpropgation", "abstract": "Compared to Multilayer Neural Networks with real weights, Binary Multilayer Neural Networks (BMNNs) can be implemented more efficiently on dedicated hardware. BMNNs have been demonstrated to be effective on binary classification tasks with Expectation BackPropagation (EBP) algorithm on high dimensional text datasets. In this paper, we investigate the capability of BMNNs using the EBP algorithm on multiclass image classification tasks. The performances of binary neural networks with multiple hidden layers and different numbers of hidden units are examined on MNIST. We also explore the effectiveness of image spatial filters and the dropout technique in BMNNs. Experimental results on MNIST dataset show that EBP can obtain 2.12% test error with binary weights and 1.66% test error with real weights, which is comparable to the results of standard BackPropagation algorithm on fully connected MNNs.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "Zhiyong Cheng, Daniel Soudry, Zexi Mao, Zhenzhong Lan,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.03553", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03553", "title": "\nAccelerating DEM simulations on GPUs by reducing the impact of warp  divergences", "abstract": "A way to accelerate DEM calculations on the GPUs is developed. We examined how warp divergences take place in the contact detection and the force calculations taking account of the GPU architecture. Then we showed a strategy to reduce the impact of the warp divergences on the runtime of the DEM force calculations.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Yasuhiro Nakahara, Teruyoshi Washizawa,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03537", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03537", "title": "\nBio-Inspired Framework for Allocation of Protection Resources in  Cyber-Physical Networks", "abstract": "In this chapter, we consider the problem of designing protection strategies to contain spreading processes in complex cyber-physical networks. We illustrate our ideas using a family of bio-motivated spreading models originally proposed in the epidemiological literature, e.g., the Susceptible-Infected-Susceptible (SIS) model. We first introduce a framework in which we are allowed to distribute two types of resources in order to contain the spread, namely, (i) preventive resources able to reduce the spreading rate, and (ii) corrective resources able to increase the recovery rate of nodes in which the resources are allocated. In practice, these resources have an associated cost that depends on either the resiliency level achieved by the preventive resource, or the restoration efficiency of the corrective resource. We present a mathematical framework, based on dynamic systems theory and convex optimization, to find the cost-optimal distribution of protection resources in a network to contain the spread. We also present two extensions to this framework in which (i) we consider generalized epidemic models, beyond the simple SIS model, and (ii) we assume uncertainties in the contact network in which the spreading is taking place. We compare these protection strategies with common heuristics previously proposed in the literature and illustrate our results with numerical simulations using the air traffic network.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Victor M. Preciado, Michael Zargham, Cameron Nowzari, Shuo Han, Masaki Ogura, George Pappas,", "date": "2015-3-12"}, 
{"urllink": "http://arxiv.org/abs/1503.03535", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03535", "title": "\nOn Using Monolingual Corpora in Neural Machine Translation", "abstract": "Recent work on end-to-end neural network-based architectures for machine translation has shown promising results for English-French and English-German translation. Unlike these language pairs, however, in the majority of scenarios, there is a lack of high quality parallel corpora. In this work, we focus on applying neural machine translation to challenging/low-resource languages such as Chinese and Turkish. In particular, we investigate how to leverage abundant monolingual data for these low-resource translation tasks. Without the use of external alignment tools, we obtained up to a BLEU score improvement with our proposed method compared to the previous best result in Turkish-to-English translation on the IWLST 2014 dataset. On Chinese-to-English translation by using the OpenMT 2015 dataset, we were able to obtain up to a BLEU score improvement over phrase-based and hierarchical phrase-based baselines.", "subjects": "Computation and Language (cs.CL)", "authors": "Caglar Gulcehre, Orhan Firat, Kelvin Xu, Kyunghyun Cho, Loic Barrault, Huei-Chi Lin, Fethi Bougares, Holger Schwenk, Yoshua Bengio,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03525", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03525", "title": "\nOnline Matrix Completion and Online Robust PCA", "abstract": "This work studies two interrelated problems - online robust PCA (RPCA) and online low-rank matrix completion (MC). In recent work by Cand `s et al., RPCA has been defined as a problem of separating a low-rank matrix (true data), and a sparse matrix (outliers), from their sum, . Our work uses this definition of RPCA. An important application where both these problems occur is in video analytics in trying to separate sparse foregrounds (e.g., moving objects) and slowly changing backgrounds. While there has been a large amount of recent work on both developing and analyzing batch RPCA and batch MC algorithms, the online problem is largely open. In this work, we develop a practical modification of our recently proposed algorithm to solve both the online RPCA and online MC problems. The main contribution of this work is that we obtain correctness results for the proposed algorithms under mild assumptions. The assumptions that we need are: (a) a good estimate of the initial subspace is available (easy to obtain using a short sequence of background-only frames in video surveillance); (b) the 's obey a `slow subspace change' assumption; (c) the basis vectors for the subspace from which is generated are dense (non-sparse); (d) the support of changes by at least a certain amount at least every so often; and (e) algorithm parameters are appropriately set", "subjects": "Information Theory (cs.IT)", "authors": "Brian Lois, Namrata Vaswani,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03517", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03517", "title": "\nSwitching to Learn", "abstract": "A network of agents attempt to learn some unknown state of the world drawn by nature from a finite set. Agents observe private signals conditioned on the true state, and form beliefs about the unknown state accordingly. Each agent may face an identification problem in the sense that she cannot distinguish the truth in isolation. However, by communicating with each other, agents are able to benefit from side observations to learn the truth collectively. Unlike many distributed algorithms which rely on all-time communication protocols, we propose an efficient method by switching between Bayesian and non-Bayesian regimes. In this model, agents exchange information only when their private signals are not informative enough; thence, by switching between the two regimes, agents efficiently learn the truth using only a few rounds of communications. The proposed algorithm preserves learnability while incurring a lower communication cost. We also verify our theoretical findings by simulation examples.", "subjects": "Learning (cs.LG)", "authors": "Shahin Shahrampour, Mohammad Amin Rahimian, Ali Jadbabaie,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03514", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03514", "title": "\nAppearance-based indoor localization: A comparison of patch descriptor  performance", "abstract": "Vision is one of the most important of the senses, and humans use it extensively during navigation. We evaluated different types of image and video frame descriptors that could be used to determine distinctive visual landmarks for localizing a person based on what is seen by a camera that they carry. To do this, we created a database containing over 3 km of video-sequences with ground-truth in the form of distance travelled along different corridors. Using this database, the accuracy of localization - both in terms of knowing which route a user is on - and in terms of position along a certain route, can be evaluated. For each type of descriptor, we also tested different techniques to encode visual structure and to search between journeys to estimate a user's position. The techniques include single-frame descriptors, those using sequences of frames, and both colour and achromatic descriptors. We found that single-frame indexing worked better within this particular dataset. This might be because the motion of the person holding the camera makes the video too dependent on individual steps and motions of one particular journey. Our results suggest that appearance-based information could be an additional source of navigational data indoors, augmenting that provided by, say, radio signal strength indicators (RSSIs). Such visual information could be collected by crowdsourcing low-resolution video feeds, allowing journeys made by different users to be associated with each other, and location to be inferred without requiring explicit mapping. This offers a complementary approach to methods based on simultaneous localization and mapping (SLAM) algorithms.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Jose Rivera-Rubio, Ioannis Alexiou, Anil A. Bharath,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03512", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03512", "title": "\nIs language evolution grinding to a halt?: Exploring the life and death  of words in English fiction", "abstract": "The Google Books corpus contains millions of books in a variety of languages. Due to its incredible volume and its free availability, it is a treasure trove for linguistic research. In a previous work, we found the unfiltered English data sets from both the 2009 and 2012 versions of the corpus are both heavily saturated with scientific literature, as is the 2009 version of the English Fiction data set. Fortunately, the 2012 version of English Fiction is consistent with fiction and shows promise as an indicator of the evolution of the English language as used by the general public. In this paper, we first critique a method used by authors of an earlier work to determine the birth and death rates of words in a given linguistic data set. We show that this earlier method produces an artificial surge in the death rate at the end of the observed period of time. In order to avoid this boundary effect in our own analysis of asymmetries in language dynamics, we examine the volume of word flux across various relative frequency thresholds for the 2012 English Fiction data set. We then use the contributions of the words crossing these thresholds to the Jensen-Shannon divergence between consecutive decades to resolve the major driving factors behind the flux.", "subjects": "Computation and Language (cs.CL)", "authors": "Eitan Adam Pechenick, Christopher M. Danforth, Peter Sheridan Dodds,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03511", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03511", "title": "\nCross platform app: a comparative study", "abstract": "The use of mobile applications is now so common that users now expect companies whose services which they consume already have an application to provide these services or a mobile version of your site, but this is not always simple to do or cheap. Thus, the hybrid development has emerged as a potential alternative to this need. The evolution of this new paradigm has taken the attention of researchers and companies as viable alternative to the mobile development. This paper shows how hybrid development can be an alternative for companies provide their services with a low investment and still offer a great service to their clients.", "subjects": "Software Engineering (cs.SE)", "authors": "Paulo R. M. de Andrade, Adriano B. Albuquerque, Ot\u00e1vio F. Frota, Robson V Silveira, F\u00e1tima A. da Silva,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03506", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03506", "title": "\nDiverse Landmark Sampling from Determinantal Point Processes for  Scalable Manifold Learning", "abstract": "High computational costs of manifold learning prohibit its application for large point sets. A common strategy to overcome this problem is to perform dimensionality reduction on selected landmarks and to successively embed the entire dataset with the Nystr \"om method. The two main challenges that arise are: (i) the landmarks selected in non-Euclidean geometries must result in a low reconstruction error, (ii) the graph constructed from sparsely sampled landmarks must approximate the manifold well. We propose the sampling of landmarks from determinantal distributions on non-Euclidean spaces. Since current determinantal sampling algorithms have the same complexity as those for manifold learning, we present an efficient approximation running in linear time. Further, we recover the local geometry after the sparsification by assigning each landmark a local covariance matrix, estimated from the original point set. The resulting neighborhood selection based on the Bhattacharyya distance improves the embedding of sparsely sampled manifolds. Our experiments show a significant performance improvement compared to state-of-the-art landmark selection techniques.", "subjects": "Learning (cs.LG)", "authors": "Christian Wachinger, Polina Golland,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03491", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03491", "title": "\nProperties of simple sets in digital spaces. Contractions of simple sets  preserving the homotopy type of a digital space", "abstract": "A point of a digital space is called simple if it can be deleted from the space without altering topology. This paper introduces the notion simple set of points of a digital space. The definition is based on contractible spaces and contractible transformations. A set of points in a digital space is called simple if it can be contracted to a point without changing topology of the space. It is shown that contracting a simple set of points does not change the homotopy type of a digital space, and the number of points in a digital space without simple points can be reduces by contracting simple sets. Using the process of contracting, we can substantially compress a digital space while preserving the topology. The paper proposes a method for thinning a digital space which shows that this approach can contribute to computer science such as medical imaging, computer graphics and pattern analysis.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Alexander V. Evako,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03488", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03488", "title": "\nEstimating the Mean Number of K-Means Clusters to Form", "abstract": "Utilizing the sample size of a dataset, the random cluster model is employed in order to derive an estimate of the mean number of K-Means clusters to form during classification of a dataset.", "subjects": "Learning (cs.LG)", "authors": "Robert A. Murphy,", "date": "2015-3-7"}, 
{"urllink": "http://arxiv.org/abs/1503.03468", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03468", "title": "\nAlgorithms and Properties for Positive Symmetrizable Matrices", "abstract": "Matrices are the most common representations of graphs. They are also used for the representation of algebras and cluster algebras. This paper shows some properties of matrices in order to facilitate the understanding and locating symmetrizable matrices with specific characteristics, called positive quasi-Cartan companion matrices. Here, symmetrizable matrix are those which are symmetric when multiplied by a diagonal matrix with positive entries called symmetrizer matrix. Four algorithms are developed: one to decide whether there is a symmetrizer matrix; second to find such symmetrizer matrix; another to decide whether the matrix is positive or not; and the last to find a positive quasi-Cartan companion matrix, if there exists. The third algorithm is used to prove that the problem to decide if a matrix has a positive quasi-Cartan companion is NP.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Elis\u00e2ngela Silva Dias, Diane Castonguay, Mitre Costa Dourado,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03465", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03465", "title": "\nFaster 64-bit universal hashing using carry-less multiplications", "abstract": "Intel and AMD support the Carry-less Multiplication (CLMUL) instruction set in their x64 processors. We use CLMUL to implement an almost universal 64-bit hash family (CLHASH). We compare this new family with what might be the fastest almost universal family on x64 processors (VHASH). We find that CLHASH is at least 60% faster. We also compared CLHASH with a popular hash function designed for speed (Google's CityHash). We find that CLHASH is 40% faster than CityHash on inputs larger than 64 bytes and nearly as fast otherwise.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Daniel Lemire, Owen Kaser,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.03463", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03463", "title": "\nTowards the Design and Implementation of Aspect-Oriented Programming for  Spreadsheets", "abstract": "A spreadsheet usually starts as a simple and single-user software artifact, but, as frequent as in other software systems, quickly evolves into a complex system developed by many actors. Often, different users work on different aspects of the same spreadsheet: while a secretary may be only involved in adding plain data to the spreadsheet, an accountant may define new business rules, while an engineer may need to adapt the spreadsheet content so it can be used by other software systems. Unfortunately, spreadsheet systems do not offer modular mechanisms, and as a consequence, some of the previous tasks may be defined by adding intrusive \"code\" to the spreadsheet. In this paper we go through the design and implementation of an aspect-oriented language for spreadsheets so that users can work on different aspects of a spreadsheet in a modular way. For example, aspects can be defined in order to introduce new business rules to an existing spreadsheet, or to manipulate the spreadsheet data to be ported to another system. Aspects are defined as aspect-oriented program specifications that are dynamically woven into the underlying spreadsheet by an aspect weaver. In this aspect-oriented style of spreadsheet development, different users develop, or reuse, aspects without adding intrusive code to the original spreadsheet. Such code is added/executed by the spreadsheet weaving mechanism proposed in this paper.", "subjects": "Software Engineering (cs.SE)", "authors": "Pedro Maia, Jorge Mendes, J\u00e1come Cunha, Henrique Reb\u00ealo, Jo\u00e3o Saraiva,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03462", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03462", "title": "\nOn the zone of a circle in an arrangement of lines", "abstract": "Let be a set of lines in the plane, and let be a convex curve in the plane, like a circle or a parabola. The \"zone\" of in , denoted , is defined as the set of all faces in the arrangement that are intersected by . Edelsbrunner et al. (1992) showed that the complexity (total number of edges or vertices) of is at most , where is the inverse Ackermann function, by translating the sequence of edges of into a Davenport-Schinzel sequence of order . Whether the worst-case complexity of is only linear is a longstanding open problem. Here we show that if is a parabola, then avoids not only the pattern , but another pattern as well. Hence, if (the maximum length of a sequence with distinct symbols that avoids the subsequences , , and the reversal of , and contains no adjacent repetitions) could be shown to be , that would settle the problem for a parabola (and almost certainly also for a circle).", "subjects": "Computational Geometry (cs.CG)", "authors": "Gabriel Nivasch,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03460", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03460", "title": "\nEfficient Service Broker Policy For Large-Scale Cloud Environments", "abstract": "Algorithms, policies, and methodologies are necessary to achieve high user satisfaction and practical utilization in cloud computing by ensuring the efficient and fair allocation of every computing resource. Whenever a new job arrives in cloud environments, the service broker is responsible for selecting the data center that will execute that job. Selecting data centers serves an important function in enhancing the performance of a cloud environment. This study proposes a new service broker policy for large-scale cloud applications based on the round-robin algorithm. The proposed policy is implemented and evaluated using a CloudAnalyst simulator. It is then compared with three existing policies in terms of overall average response time by using different virtual machine load balancing algorithms. Simulation results show that the proposed policy improves the overall average response time relative to that of the other policies.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Mohammed Radi,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03452", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03452", "title": "\nDesign and implementation of an Android application (MobilitApp+) to  analyze the mobility patterns of citizens in the Metropolitan Region of  Barcelona", "abstract": "In our project we have designed an Android application to obtain mobility data of the citizens in the metropolitan area of Barcelona. Our implementation synchronously obtains in background on the one hand, periodic location updates and, on the other hand, the type of activity citizens are doing. At the end of the day, all this data is processed and sent to a server where are stored to obtain mobility patterns from citizens that could help to improve the current transportation infrastructure. MobilitApp is fully functional and stable although the results can be improved in some situations. In future releases we will implement machine learning technics to obtain significant improvements, especially in the activity recognition modules.", "subjects": "Computers and Society (cs.CY)", "authors": "Sergi Casanova Fouce, Silvia Puglisi, Monica Aguilar Igartua,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03449", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03449", "title": "\nThe Value of Local Delayed CSIT", "abstract": "We study the capacity region of the two-user interference channel with local delayed channel state information at the transmitters. In our model, transmitters have local mismatched outdated knowledge of the channel gains. We propose a transmission strategy that only relies on the delayed knowledge of the outgoing links at each transmitter and achieves the outer-bound for the scenario in which transmitters learn the entire channel state with delay. Our result reveals the subset of the channel state information that affects the capacity region the most. We also identify cases in which local delayed knowledge of the channel state does not provide any gain over the zero knowledge assumption. To do so, we revisit a long-known intuition about interference channels that as long as the marginal distributions at the receivers are conserved, the capacity remains the same. We take this intuition and impose a certain spatial correlation among channel gains such that the marginal distributions remain unchanged. Then we provide an outer-bound on the capacity region of the channel with correlation that matches the capacity region when transmitters do not have access to channel state information.", "subjects": "Information Theory (cs.IT)", "authors": "Alireza Vahid, Robert Calderbank,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03438", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03438", "title": "\nA theoretical argument for complex-valued convolutional networks", "abstract": "A complex-valued convolutional network (convnet) implements the repeated application of the following composition of three operations, recursively applying the composition to an input vector of nonnegative real numbers: (1) convolution with several complex-valued vectors followed by (2) taking the absolute value of every entry of the resulting vectors followed by (3) local averaging. For processing real-valued random vectors, complex-valued convnets can be viewed as \"data-driven multiscale windowed power spectra,\" \"data-driven multiscale windowed absolute spectra,\" \"data-driven multiwavelet absolute values,\" or (in their most general configuration) \"data-driven nonlinear multiwavelet packets.\" Indeed, complex-valued convnets can calculate multiscale windowed spectra when the convnet filters are windowed complex-valued exponentials. Standard real-valued convnets, using rectified linear units (ReLUs), sigmoidal (for example, logistic or tanh) nonlinearities, max. pooling, etc., do not obviously exhibit the same exact correspondence with data-driven wavelets (whereas for complex-valued convnets, the correspondence is much more than just a vague analogy).", "subjects": "Learning (cs.LG)", "authors": "Joan Bruna, Soumith Chintala, Yann LeCun, Serkan Piantino, Arthur Szlam, Mark Tygert,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03430", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03430", "title": "\nKempe Equivalence of Colourings of Cubic Graphs", "abstract": "Given a graph and a proper vertex colouring of , a Kempe chain is a subset of that induces a maximal connected subgraph of in which every vertex has one of two colours. To make a Kempe change is to obtain one colouring from another by exchanging the colours of vertices in a Kempe chain. Two colourings are Kempe equivalent if each can be obtained from the other by a series of Kempe changes. A conjecture of Mohar asserts that, for , all -colourings of -regular graphs that are not complete are Kempe equivalent. We address the case by showing that all -colourings of a cubic graph are Kempe equivalent unless is the complete graph or the triangular prism.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Carl Feghali, Matthew Johnson, Daniel Paulusma,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03429", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03429", "title": "\nHandling Occlusions and Sparse Textures in a Deformable Surface Tracking  Framework", "abstract": "Deformable surface tracking from monocular images is a well-known under-constrained problem. Occlusions often make the task even more challenging, and can lead current methods to fail if the surface is not sufficiently textured. In this work, we explicitly address the problem of 3D reconstruction of poorly textured, occluded surfaces, proposing a framework based on a template-matching approach that scales dense robust features by a relevancy score. Our approach is extensively compared to current methods employing both local feature matching and dense template alignment. We test on standard datasets as well as on a new dataset (that will be made publicly available) of a sparsely textured, occluded surface. Our framework achieves state-of-the-art results for both well and poorly textured, occluded surfaces.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Dat Tien Ngo, Sanghuyk Park, Anne Jorstad, Alberto Crivellaro, Chang Yoo, Pascal Fua,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03417", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03417", "title": "\nAn Improved Reverse Pinsker Inequality for Probability Distributions on  a Finite Set", "abstract": "A new upper bound on the relative entropy is derived for arbitrary probability distributions that are defined on a common finite set. The bound is expressed in terms of the total variation distance, and it improves a previously reported bound by Csiszar and Talata. It is further extended to Renyi divergences of an arbitrary non-negative order (including ).", "subjects": "Information Theory (cs.IT)", "authors": "Igal Sason,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.03403", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03403", "title": "\nBublz! : Playing with Bubbles to Develop Mathematical Thinking", "abstract": "We encounter mathematical problems in various forms in our lives, thus making mathematical thinking an important human ability. Of these problems, optimization problems are an important subset: Wall Street traders often have to take instantaneous, strategic decisions to buy and sell shares, with the goal of maximizing their profits at the end of a day's trade. Continuous research on game-based learning and its value led us to ask: can we develop and improve the ability of mathematical thinking in children by guising an optimization problem as a game? In this paper, we present Bublz!, a simple, click-driven game we developed as a first step towards answering our question.", "subjects": "Human-Computer Interaction (cs.HC)", "authors": "Dhruv Chand, Karthik Gopalakrishnan, Nisha KK, Mudit Sinha, Shreya Sriram,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03401", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03401", "title": "\nToward Reverse Engineering of VBA Based Excel Spreadsheet Applications", "abstract": "Modern spreadsheet systems can be used to implement complex spreadsheet applications including data sheets, customized user forms and executable procedures written in a scripting language. These applications are often developed by practitioners that do not follow any software engineering practice and do not produce any design documentation. Thus, spreadsheet applications may be very difficult to be maintained or restructured. In this position paper we present in a nutshell two reverse engineering techniques and a tool that we are currently realizing for the abstraction of conceptual data models and business logic models.", "subjects": "Software Engineering (cs.SE)", "authors": "Domenico Amalfitano, Nicola Amatucci, Vincenzo De Simone, Anna Rita Fasolino, Porfirio Tramontana,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03400", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03400", "title": "\nGet 'em Moles! : Improved Spelling and Pronunciation through an  Educational Game", "abstract": "Get 'em Moles! is a single-player educational game inspired by the classic arcade game Whac-A-Mole. Primarily designed for touchscreen devices, Get 'em Moles! aims to improve English spelling and pronunciation in players by supporting learning with engaging game play. This paper describes the game, design decisions in the form of elements that support learning and engagement, preliminary results, and future work.", "subjects": "Human-Computer Interaction (cs.HC)", "authors": "Dhruv Chand, Karthik Gopalakrishnan, Nisha KK, Mudit Sinha, Shreya Sriram,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03394", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03394", "title": "\nNew upper bounds on binary linear codes and a \\$\\mathbb Z_4\\$-code with  a better-than-linear Gray image", "abstract": "Using integer linear programming and table-lookups we prove that there is no binary linear [1988,12,992] code. As a byproduct, the non-existence of binary linear [324,10,160], [356,10,176], [772,11,384], and [836,11,416] codes is shown. On the other hand, there exists a linear (994,4^6,992) code over Z_4. Its Gray image is a binary non-linear (1988,2^12,992) code. Therefore, we can add one more code to the small list of Z_4-codes for which it is known that the Gray image is better than any binary linear code.", "subjects": "Information Theory (cs.IT)", "authors": "Michael Kiermaier, Alfred Wassermann, Johannes Zwanzger,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.03392", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03392", "title": "\nUniversal Network Cost-Sharing Design", "abstract": "We propose a model to design network cost-sharing protocols with good equilibria under uncertainty. The underlying game is a multicast game in a rooted undirected graph with nonnegative edge costs. A set of k terminal vertices or players wants to establish connectivity with the root. The social optimum is the well-studied Minimum Steiner Tree problem. We assume that the designer has full knowledge of the underlying metric, (given by the graph G and the shortest path metric induced by the costs c_e), but does not know which subset of players will appear. Her goal is to choose a single, universal cost-sharing protocol that has low Price of Anarchy (PoA) for all possible requested subsets of players. The main question we address is: to what extent can prior knowledge of the underlying metric help in the design? We first demonstrate that there exist classes of graphs where knowledge of the underlying metric can dramatically improve the performance of good network cost-sharing design. For outerplanar graph metrics, we provide a universal cost-sharing protocol with constant PoA, in contrast to protocols that, by ignoring the graph metric, cannot achieve PoA better than Omega(log k). Then, in our main technical result, we show that there exist graph metrics, for which knowing the underlying metric does not help and any universal protocol has PoA of Omega(log k), which is tight. We attack this problem by developing new techniques that employ powerful tools from extremal combinatorics, and more specifically Ramsey Theory in high dimensional hypercubes.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "George Christodoulou, Alkmini Sgouritsa,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03388", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03388", "title": "\nStation Keeping through Beacon-referenced Cyclic Pursuit", "abstract": "This paper investigates a modification of cyclic constant bearing (CB) pursuit in a multi-agent system in which each agent pays attention to a neighbor and a beacon. The problem admits shape equilibria with collective circling about the beacon, with the circling radius and angular separation of agents determined by choice of parameters in the feedback law. Stability of circling shape equilibria is shown for a 2-agent system, and the results are demonstrated on a collective of mobile robots tracked by a motion capture system.", "subjects": "Systems and Control (cs.SY)", "authors": "Kevin S. Galloway, Biswadip Dey,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03378", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03378", "title": "\nBrowserbite: Cross-Browser Testing via Image Processing", "abstract": "Cross-browser compatibility testing is concerned with identifying perceptible differences in the way a Web page is rendered across different browsers or configurations thereof. Existing automated cross-browser compatibility testing methods are generally based on Document Object Model (DOM) analysis, or in some cases, a combination of DOM analysis with screenshot capture and image processing. DOM analysis however may miss incompatibilities that arise not during DOM construction, but rather during rendering. Conversely, DOM analysis produces false alarms because different DOMs may lead to identical or sufficiently similar renderings. This paper presents a novel method for cross-browser testing based purely on image processing. The method relies on image segmentation to extract regions from a Web page and computer vision techniques to extract a set of characteristic features from each region. Regions extracted from a screenshot taken on a baseline browser are compared against regions extracted from the browser under test based on characteristic features. A machine learning classifier is used to determine if differences between two matched regions should be classified as an incompatibility. An evaluation involving 140 pages shows that the proposed method achieves an F-score exceeding 0.9, outperforming a state-of-the-art cross-browser testing tool based on DOM analysis.", "subjects": "Software Engineering (cs.SE)", "authors": "T\u00f5nis Saar, Marlon Dumas, Marti Kaljuve, Nataliia Semenenko,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03366", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03366", "title": "\nAre Heterogeneous Cloud-Based Radio Access Networks Cost Effective?", "abstract": "Mobile networks of the future are predicted to be much denser than today's networks in order to cater to increasing user demands. In this context, cloud based radio access networks have garnered significant interest as a cost effective solution to the problem of coping with denser networks and providing higher data rates. However, to the best knowledge of the authors, a quantitative analysis of the cost of such networks is yet to be undertaken. This paper develops a theoretic framework that enables computation of the deployment cost of a network (modeled using various spatial point processes) to answer the question posed by the paper's title. Then, the framework obtained is used along with a complexity model, which enables computing the information processing costs of a network, to compare the deployment cost of a cloud based network against that of a traditional LTE network, and to analyze why they are more economical. Using this framework and an exemplary budget, this paper shows that cloud-based radio access networks require approximately 10 to 15% less capital expenditure per square kilometer than traditional LTE networks. It also demonstrates that the cost savings depend largely on the costs of base stations and the mix of backhaul technologies used to connect base stations with data centers.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Vinay Suryaprakash, Peter Rost, Gerhard Fettweis,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03361", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03361", "title": "\nJoint Link Adaptation and User Scheduling with HARQ in Multi-Cell  Environments", "abstract": "Inter-cell interference (ICI) is one of the most critical factors affecting performance of cellular networks. In this paper, we investigate a joint link adaptation and user scheduling problem for multi-cell downlink employing HARQ techniques, where the ICI exists among cells. We first propose an approximation method on aggregated ICI for analyzing an effective signal-to-interference-and-noise ratio (SINR) with the HARQ technique at users, named identical path-loss approximation (IPLA). Based on the proposed IPLA, we propose a transmission rate selection algorithm maximizing an expected throughput at each user. We also propose a simple but effective cross-layer framework jointly combining transmission rate adaptation and user scheduling techniques, considering both HARQ and ICI. It is shown that statistical distribution of the effective SINR at users based on the IPLA agrees well with the empirical distribution, while the conventional Gaussian approximation (GA) does not work well in the case that dominant ICIs exist. Thus, IPLA enables base stations to choose more accurate transmission rates. Furthermore, the proposed IPLA-based cross-layer policy outperforms existing policies in terms of both system throughput and user fairness.", "subjects": "Information Theory (cs.IT)", "authors": "Su Min Kim, Bang Chul Jung, Dan Keun Sung,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03359", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03359", "title": "\nThe Feedback Capacity of the $(1,\\infty)$-RLL Input-Constrained Erasure  Channel", "abstract": "The input-constrained erasure channel with feedback is considered, where the binary input sequence contains no consecutive ones, i.e., it satisfies the -RLL constraint. We derive the capacity for this setting, which can be expressed as , where is the erasure probability and is the binary entropy function. Moreover, we prove that a-priori knowledge of the erasure at the encoder does not increase the feedback capacity. The feedback capacity was calculated using an equivalent dynamic programming (DP) formulation with an optimal average-reward that is equal to the capacity. Furthermore, we obtained an optimal encoding procedure from the solution of the DP, leading to a capacity-achieving, zero-error coding scheme for our setting. DP is thus shown to be a tool not only for solving optimization problems such as capacity calculation, but also for constructing optimal coding schemes. The derived capacity expression also serves as the only non-trivial upper bound known on the capacity of the input-constrained erasure channel without feedback, a problem that is still open.", "subjects": "Information Theory (cs.IT)", "authors": "Oron Sabag, Haim H. Permuter, Navin Kashyap,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03354", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03354", "title": "\nNew Method for Public Key Distribution Based on Social Networks", "abstract": "The security of communication in everyday life becomes very important. On the other hand, all existing encryption protocols require from user additional knowledge end resources. In this paper we discuss the problem of public key distribution between interested parties. We propose to use a popular social media as a channel to publish public keys. This way of key distribution allows also easily connect owner of the key with real person institution (what is not always easy). Recognizing that the mobile devices become the main tool of communication, we present description of mobile application that uses proposed security methods.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Krzysztof Podlaski, Artur H\u0142oba\u017c, Piotr Milczarski,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03351", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03351", "title": "\nSampling colorings almost uniformly in sparse random graphs", "abstract": "The problem of sampling proper -colorings from uniform distribution has been extensively studied. Most of existing samplers require for some constants and , where is the maximum degree of the graph. The problem becomes more challenging when the underlying graph has unbounded degree since even the decision of -colorability becomes nontrivial in this situation. The Erd Hs-R 'nyi random graph is a typical class of such graphs and has received a lot of recent attention. In this case, the performance of a sampler is usually measured by the relation between and the average degree . We are interested in the fully polynomial-time almost uniform sampler (FPAUS) and the state-of-the-art with such sampler for proper -coloring on requires that . In this paper, we design an FPAUS for proper -colorings on by requiring that , which improves the best bound for the problem so far. Our sampler is based on the spatial mixing property of -coloring on random graphs. The core of the sampler is a deterministic algorithm to estimate the marginal probability on blocks, which is computed by a novel block version of recursion for -coloring on unbounded degree graphs.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Yitong Yin, Chihao Zhang,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03349", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03349", "title": "\nLocal variation of hashtag spike trains and popularity in Twitter", "abstract": "We draw a parallel between hashtag time series and neuron spike trains. In each case, the process presents complex dynamic patterns including temporal correlations, burstiness, and all other types of nonstationarity. We propose the adoption of the so-called local variation in order to uncover salient dynamics, while properly detrending for the time-dependent features of a signal. The methodology is tested on both real and randomized hashtag spike trains, and identifies that popular hashtags present regular and so less bursty behavior, suggesting its potential use for predicting online popularity in social media.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Ceyda Sanl\u0131, Renaud Lambiotte,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03345", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03345", "title": "\nTwo-Player Tower of Hanoi", "abstract": "The Tower of Hanoi game is a classical puzzle in recreational mathematics, which also has a strong record in pure mathematics. In a borderland between these two areas we find the characterization of the minimal number of moves, which is 2n--1, to transfer a tower of n disks. But there are also other variations to the game, involving for example move edges weighted by real numbers. This gives rise to a similar type of problem, but where the final score seeks to be optimized. We study extensions of the one-player setting to two players, invoking classical winning conditions in combinatorial game theory such as the player who moves last wins, or the highest score wins. Here we solve both these winning conditions on three heaps.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Jonathan Chappelon, Urban Larsson, Akihiro Matsuura,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03324", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03324", "title": "\nOn definite program answers and least Herbrand models", "abstract": "The paper shows that when an answer of a definite logic program contains symbols not occurring in the program then a more general answer exists. Also a new sufficient condition is given under which least Herbrand models exactly characterize the answers of programs. It is shown that, under a reasonable assumption, the sufficient condition is also necessary.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "W\u0142odzimierz Drabent,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03321", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03321", "title": "\nThe Kinetic Basis of Morphogenesis", "abstract": "It has been shown recently (Shalygo, 2014) that stationary and dynamic patterns can arise in the proposed one-component model of the analog (continuous state) kinetic automaton, or a kinon for short, defined as a reflexive dynamical system with active transport. This paper presents the extensions of the model, which increase further its complexity and tunability, and shows that the extended kinon model can produce spatio-temporal patterns pertaining not only to pattern formation but also to morphogenesis in real physical and biological systems. It indicates the possible applicability of the model to morphogenetic engineering and robotics.", "subjects": "Formal Languages and Automata Theory (cs.FL)", "authors": "Yuri Shalygo,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03318", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03318", "title": "\nOn the decomposition of stochastic cellular automata", "abstract": "In this paper we present two interesting properties of stochastic cellular automata that can be helpful in analyzing the dynamical behavior of such automata. The first property allows calculating cell-wise probability distributions over the state set of a stochastic cellular automaton, i.e. mages that show the average state of each cell during the stochastic cellular automaton evolution. The second property shows that stochastic cellular automata are equivalent to so-called stochastic mixtures of deterministic cellular automata. By means of this property, any stochastic cellular automaton can be decomposed into a set of deterministic systems, each of which contributes to the behavior of the stochastic system.", "subjects": "Formal Languages and Automata Theory (cs.FL)", "authors": "Witold Bo\u0142t, Jan M. Baetens, Bernard DeBaets,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03309", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03309", "title": "\nDynamic Backhaul Network Configuration in SDN-based Cloud RANs", "abstract": "The coordination of base stations in mobile access networks is an important approach to reduce harmful interference and to deliver high data rates to the users. Such coordination mechanisms, like Coordinated Multi-Point (CoMP) where multiple BSs transmit data to a user equipment, can be easily implemented when centralizing the data processing of the base stations, known as Cloud RAN. This centralization also imposes significant requirements on the backhaul network for high capacities and low latencies for the connections to the base stations. These requirements can be mitigated by (a) a flexible placement of the base station data processing functionality and by (b) dynamically assigning backhaul network resources. We show how these two techniques increase the feasibility of base station coordination in dense mobile access networks by using a heuristic algorithm. We furthermore present a prototype implementation of our approach based on software defined networking (SDN) with OpenDaylight and Maxinet.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Martin Dr\u00e4xler, Holger Karl,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03308", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03308", "title": "\nGeneralized Spatial Modulation in Indoor Wireless Visible Light  Communication", "abstract": "In this paper, we investigate the performance of generalized spatial modulation (GSM) in indoor wireless visible light communication (VLC) systems. GSM uses light emitting diodes (LED), but activates only of them at a given time. Spatial modulation and spatial multiplexing are special cases of GSM with and , respectively. We first derive an analytical upper bound on the bit error rate (BER) for maximum likelihood (ML) detection of GSM in VLC systems. Analysis and simulation results show that the derived upper bound is very tight at medium to high signal-to-noise ratios (SNR). The channel gains and channel correlations influence the GSM performance such that the best BER is achieved at an optimum LED spacing. Also, for a fixed transmission efficiency, the performance of GSM in VLC improves as the half-power semi-angle of the LEDs is decreased. We then compare the performance of GSM in VLC systems with those of other MIMO schemes such as spatial multiplexing (SMP), space shift keying (SSK), generalized space shift keying (GSSK), and spatial modulation (SM). Analysis and simulation results show that GSM in VLC outperforms the other considered MIMO schemes at moderate to high SNRs; for example, for 8 bits per channel use, GSM outperforms SMP and GSSK by about 21 dB, and SM by about 10 dB at BER.", "subjects": "Information Theory (cs.IT)", "authors": "S. P. Alaka, T. Lakshmi Narasimhan, A. Chockalingam,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03293", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03293", "title": "\nFourier Codes", "abstract": "A new family of error-correcting codes, called Fourier codes, is introduced. The code parity-check matrix, dimension and an upper bound on its minimum distance are obtained from the eigenstructure of the Fourier number theoretic transform. A decoding technique for such codes is proposed.", "subjects": "Information Theory (cs.IT)", "authors": "R.M. Campello de Souza, E.S.V. Freire, H.M. de Oliveira,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03292", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03292", "title": "\nImproving GGH Public Key Scheme Using Low Density Lattice Codes", "abstract": "Goldreich-Goldwasser-Halevi (GGH) public key cryptosystem is an instance of lattice-based cryptosystems whose security is based on the hardness of lattice problems. In fact, GGH cryptosystem is the lattice version of the first code-based cryptosystem, proposed by McEliece. However, it has a number of drawbacks such as; large public key length and low security level. On the other hand, Low Density Lattice Codes (LDLCs) are the practical classes of linear codes which can achieve capacity on the additive white Gaussian noise (AWGN) channel with low complexity decoding algorithm. This paper introduces a public key cryptosystem based on LDLCs to withdraw the drawbacks of GGH cryptosystem. To reduce the key length, we employ the generator matrix of the used LDLC in Hermite normal form (HNF) as the public key. Also, by exploiting the linear decoding complexity of the used LDLC, the decryption complexity is decreased compared to GGH cryptosystem. These increased efficiencies allow us to use the bigger values of security parameters. Moreover, we exploit the special Gaussian vector whose variance is upper bounded by the Poltyrev limit as the perturbation vector. These techniques can resist the proposed scheme against the most efficient attacks to the GGH-like cryptosystems.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Reza Hooshmand, Taraneh Eghlidos, Mohammad Reza Aref,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03291", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03291", "title": "\nToward An Uncertainty Principle For Weighted Graphs", "abstract": "The uncertainty principle states that a signal cannot be localized both in time and frequency. With the aim of extending this result to signals on graphs, Agaskar&amp;Lu introduce notions of graph and spectral spreads. They show that a graph uncertainty principle holds for some families of unweighted graphs. This principle states that a signal cannot be simultaneously localized both in graph and spectral domains. In this paper, we aim to extend their work to weighted graphs. We show that a naive extension of their definitions leads to inconsistent results such as discontinuity of the graph spread when regarded as a function of the graph structure. To circumvent this problem, we propose another definition of graph spread that relies on an inverse similarity matrix. We also discuss the choice of the distance function that appears in this definition. Finally, we compute and plot uncertainty curves for families of weighted graphs.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Bastien Pasdeloup, R\u00e9da Alami, Vincent Gripon, Michael Rabbat,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03289", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03289", "title": "\nAn Exploration of Rotating Leadership in a Knowledge Building Community", "abstract": "This study aims to investigate the COINs concept of rotating leadership within a Knowledge Building context. Individual and group level leadership patterns in a grade 4 science class were explored through temporal visualization of betweenness centrality. Results indicate that the student network was relatively decentralized, with almost all students leading the group at different points in time. Rotating leadership appears to be an emergent phenomenon of Knowledge Building, and we suggest that it has the potential to be an indicator of collective cognitive responsibility.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Leanne Ma, Yoshiaki Matsuzawa, Derya Kici, Marlene Scardamalia,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03287", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03287", "title": "\nModelling the Structure and Dynamics of Science Using Books", "abstract": "Scientific research is a major driving force in a knowledge based economy. Income, health and wellbeing depend on scientific progress. The better we understand the inner workings of the scientific enterprise, the better we can prompt, manage, steer, and utilize scientific progress. Diverse indicators and approaches exist to evaluate and monitor research activities, from calculating the reputation of a researcher, institution, or country to analyzing and visualizing global brain circulation. However, there are very few predictive models of science that are used by key decision makers in academia, industry, or government interested to improve the quality and impact of scholarly efforts. We present a novel 'bibliographic bibliometric' analysis which we apply to a large collection of books relevant for the modelling of science. We explain the data collection together with the results of the data analyses and visualizations. In the final section we discuss how the analysis of books that describe different modelling approaches can inform the design of new models of science.", "subjects": "Digital Libraries (cs.DL)", "authors": "Michael Ginda, Andrea Scharnhorst, Katy Borner,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03284", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03284", "title": "\nTools and Models for High Level Parallel and Grid Programming", "abstract": "When algorithmic skeletons were first introduced by Cole in late 1980 the idea had an almost immediate success. The skeletal approach has been proved to be effective when application algorithms can be expressed in terms of skeletons composition. However, despite both their effectiveness and the progress made in skeletal systems design and implementation, algorithmic skeletons remain absent from mainstream practice. Cole and other researchers, focused the problem. They recognized the issues affecting skeletal systems and stated a set of principles that have to be tackled in order to make them more effective and to take skeletal programming into the parallel mainstream. In this thesis we propose tools and models for addressing some among the skeletal programming environments issues. We describe three novel approaches aimed at enhancing skeletons based systems from different angles. First, we present a model we conceived that allows algorithmic skeletons customization exploiting the macro data-flow abstraction. Then we present two results about the exploitation of meta-programming techniques for the run-time generation and optimization of macro data-flow graphs. In particular, we show how to generate and how to optimize macro data-flow graphs accordingly both to programmers provided non-functional requirements and to execution platform features. The last result we present are the Behavioural Skeletons, an approach aimed at addressing the limitations of skeletal programming environments when used for the development of component-based Grid applications. We validated all the approaches conducting several test, performed exploiting a set of tools we developed.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Patrizio Dazzi,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03283", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03283", "title": "\nOn Acyclic Edge-Coloring of Complete Bipartite Graphs", "abstract": "An acyclic edge-coloring of a graph is a proper edge-coloring without bichromatic (-colored) cycles. The acyclic chromatic index of a graph , denoted by , is the least integer such that admits an acyclic edge-coloring using colors. Let denote the maximum degree of a vertex in a graph . A complete bipartite graph with vertices on each side is denoted by . Basavaraju, Chandran and Kummini proved that when is odd. Basavaraju and Chandran provided an acyclic edge-coloring of using colors and thus establishing when is an odd prime. The main tool in their approach is perfect -factorization of . Recently, following their approach, Venkateswarlu and Sarkar have shown that admits an acyclic edge-coloring using colors which implies that , where is an odd prime. In this paper, we generalize this approach and present a general framework to possibly get an acyclic edge-coloring of which possess a perfect -factorization using colors. In this general framework, we show that admits an acyclic edge-coloring using colors and thus establishing when is an odd prime.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Ayineedi Venkateswarlu, Santanu Sarkar, A. Sai Mali,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03278", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03278", "title": "\nMultiscale Image Analysis with Stochastic Texture Differences", "abstract": "This article introduces a new low-level boundary detector, sensitive to either small data changes or large gradients. The method relies on constrained random walks around each pixel, describing how nearby image values typically evolve on each side of this pixel. Textures are represented as probability distributions of such random walks, so a texture difference operator is statistically defined as a distance between these distributions in a suitable reproducing kernel Hilbert space. The method is thus not limited to scalar pixel values: any data type for which a kernel is available may be considered, including but not limited to color triplets. By adjusting the size of the neighborhoods that are compared, the method is implicitly scale-dependent, and we demonstrate how it can be used to infer characteristic scales in measured data.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Nicolas Brodu, Hussein Yahia,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03275", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03275", "title": "\n\"Roles for the boys?\" Mining cast lists for gender and role  distributions over time", "abstract": "Film and television play an important role in popular culture, however studies that require watching and annotating video are time-consuming and expensive to run at scale. We explore information mined from media database cast lists to explore onscreen gender depictions and how they change over time. We find differences between web-mediated onscreen gender proportions and those from US Census data. We propose these methodologies are a useful adjunct to traditional analysis that allow researchers to explore the relationship between online and onscreen gender depictions.", "subjects": "Computers and Society (cs.CY)", "authors": "William Radford, Matthias Gall\u00e9,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03270", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03270", "title": "\nA Novel Hybrid CNN-AIS Visual Pattern Recognition Engine", "abstract": "Machine learning methods are used today for most recognition problems. Convolutional Neural Networks (CNN) have time and again proved successful for many image processing tasks primarily for their architecture. In this paper we propose to apply CNN to small data sets like for example, personal albums or other similar environs where the size of training dataset is a limitation, within the framework of a proposed hybrid CNN-AIS model. We use Artificial Immune System Principles to enhance small size of training data set. A layer of Clonal Selection is added to the local filtering and max pooling of CNN Architecture. The proposed Architecture is evaluated using the standard MNIST dataset by limiting the data size and also with a small personal data sample belonging to two different classes. Experimental results show that the proposed hybrid CNN-AIS based recognition engine works well when the size of training data is limited in size", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Vandna Bhalla, Santanu Chaudhury, Arihant Jain,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03267", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03267", "title": "\nUsing Calculation Fragments for Spreadsheet Testing and Debugging", "abstract": "A number of automated techniques and tools were proposed in the research literature over the years which aim to support the spreadsheet developer in the process of testing and debugging a faulty spreadsheet. One underlying assumption of many of these approaches is that the spreadsheet developer is capable of providing test cases or is at least reliably able to determine whether a calculated value in a certain cell is correct given the current set of inputs. Since real-world spreadsheets can be complex, we argue that these assumptions might be too strong in some situations. We therefore propose to support the user during testing and debugging by automatically computing spreadsheet fragments of manageable size. The spreadsheet developer can then verify the correctness of a smaller set of formulas for which the calculated output can be more easily validated.", "subjects": "Software Engineering (cs.SE)", "authors": "Dietmar Jannach, Thomas Schmitz,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03266", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03266", "title": "\nA New Coding Scheme for Discrete Memoryless MACs with Common  Rate-Limited Feedback", "abstract": "We propose a new coding scheme for the discrete memoryless two-user multi-access channel (MAC) with rate-limited feedback. Our scheme combines ideas from the Venkataramanan-Pradhan scheme for perfect feedback with ideas from the Shaviv-Steinberg scheme for rate-limited feedback. Our achievable region includes the Shaviv-Steinberg achievable region and this inclusion can be strict. For general MACs and for sufficiently large feedback rates, our scheme outperforms the Shaviv-Steinberg scheme as it achieves the same rate region as the Venkataramanan-Pradhan scheme for perfect feedback (which cannot be achieved by the Shaviv-Steinberg scheme). Furthermore, we numerically evaluate our achievable region with a specific (Gaussian) choice of random variables for the memoryless two-user Gaussian MAC. Our simulation results show that for some parameters of the Gaussian MAC and the feedback rate, our scheme achieves a strictly larger sum-rate than the Shaviv-Steinberg scheme.", "subjects": "Information Theory (cs.IT)", "authors": "Selma Belhadj Amor,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03265", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03265", "title": "\nA Morphological Adaptation Approach to Path Planning Inspired by Slime  Mould", "abstract": "Using a particle model of slime mould we demonstrate scoping experiments which explore how path planning may be performed by morphological adaptation. We initially demonstrate simple path planning by a shrinking blob of virtual plasmodium between two attractant sources within a polygonal arena. We examine the case where multiple paths are required and the subsequent selection of a single path from multiple options. Collision-free paths are implemented via repulsion from the borders of the arena. Finally, obstacle avoidance is implemented by repulsion from obstacles as they are uncovered by the shrinking blob. These examples show proof-of-concept results of path planning by morphological adaptation which complement existing research on path planning in novel computing substrates.", "subjects": "Emerging Technologies (cs.ET)", "authors": "Jeff Jones,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03264", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03264", "title": "\nMaterial Approximation of Data Smoothing and Spline Curves Inspired by  Slime Mould", "abstract": "Using a particle model of Physarum displaying emer- gent morphological adaptation behaviour we demonstrate how a minimal approach to collective material computation may be used to transform and summarise properties of spatially represented datasets. We find that the virtual material relaxes more strongly to high-frequency changes in data which can be used for the smoothing (or filtering) of data by ap- proximating moving average and low-pass filters in 1D datasets. The relaxation and minimisation properties of the model enable the spatial computation of B-spline curves (approximating splines) in 2D datasets. Both clamped and unclamped spline curves, of open and closed shapes, can be represented and the degree of spline curvature corresponds to the relaxation time of the material. The material computation of spline curves also includes novel quasi-mechanical properties including unwind- ing of the shape between control points and a preferential adhesion to longer, straighter paths. Interpolating splines could not directly be ap- proximated due to the formation and evolution of Steiner points at nar- row vertices, but were approximated after rectilinear pre-processing of the source data. This pre-processing was further simplified by transform- ing the original data to contain the material inside the polyline. These exemplar results expand the repertoire of spatially represented uncon- ventional computing devices by demonstrating a simple, collective and distributed approach to data and curve smoothing.", "subjects": "Emerging Technologies (cs.ET)", "authors": "Jeff Jones, Andrew Adamatzky,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03261", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03261", "title": "\nApproximation of Statistical Analysis and Estimation by Morphological  Adaptation in a Model of Slime Mould", "abstract": "True slime mould Physarum polycephalum approximates a range of complex computations via growth and adaptation of its proto- plasmic transport network, stimulating a large body of recent research into how such a simple organism can perform such complex feats. The properties of networks constructed by slime mould are known to be in- fluenced by the local distribution of stimuli within its environment. But can the morphological adaptation of slime mould yield any information about the global statistical properties of its environment? We explore this possibility using a particle based model of slime mould. We demonstrate how morphological adaptation in blobs of virtual slime mould may be used as a simple computational mechanism that can coarsely approx- imate statistical analysis, estimation and tracking. Preliminary results include the approximation of the geometric centroid of 2D shapes, ap- proximation of arithmetic mean from spatially represented sorted and unsorted data distributions, and the estimation and dynamical tracking of moving object position in the presence of noise contaminated input stimuli. The results suggest that it is possible to utilise collectives of very simple components with limited individual computational ability (for ex- ample swarms of simple robotic devices) to extract statistical features from complex datasets by means of material adaptation and sensorial fusion.", "subjects": "Emerging Technologies (cs.ET)", "authors": "Jeff Jones, Andrew Adamatzky,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03256", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03256", "title": "\nAn information system for integrated land and water resources management  in the Kara River basin (Togo and Benin)", "abstract": "A prerequisite for integrated land and water resources management (ILWRM) is a holistic river basin assessment. The latter requires information and data from different scientific disciplines but also appropriate data management systems to store and manage historical and real time data, set up protocols that facilitate data and information access and sharing among different stakeholders, and triggering further collaboration among different institutions in support of watershed-based assessment, management and planning. In West Africa in general and especially in the transboundary Volta River basin where different environmental data are collected and managed by different agencies in different countries and also where data access and dissemination are very challenging and difficult tasks, comprehensive river basin information systems are required. This paper presents the Oti River Basin Information System (OtiRBIS), a web-based data storage, management andanalysis platform that addresses these needs and facilitates ILWRM implementation in the Kara river basin.", "subjects": "Computers and Society (cs.CY)", "authors": "H\u00e8ou Mal\u00e9ki Badjana, Franziska Zander, Sven Kralisch, J\u00f6rg Helmschrot, Wolfgang-Albert Fl\u00fcgel,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03250", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03250", "title": "\nEpidemic Information Diffusion: A Simple Solution to Support  Community-based Recommendations in P2P Overlays", "abstract": "Epidemic protocols proved to be very efficient solutions for supporting dynamic and complex information diffusion in highly dis- tributed computing infrastructures, like P2P environments. They are useful bricks for building and maintaining virtual network topologies, in the form of overlay networks as well as to support pervasive diffusion of information when it is injected into the network. This paper proposes a simple architecture exploiting the features of epidemic approaches to foster a collaborative percolation of information between computing nodes belonging to the network aimed at building a system that groups similar users and spread useful information among them.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Patrizio Dazzi, Matteo Mordacchini,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03244", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03244", "title": "\nConvolutional Neural Network Architectures for Matching Natural Language  Sentences", "abstract": "Semantic matching is of central importance to many natural language tasks cite. A successful matching algorithm needs to adequately model the internal structures of language objects and the interaction between them. As a step toward this goal, we propose convolutional neural network models for matching two sentences, by adapting the convolutional strategy in vision and speech. The proposed models not only nicely represent the hierarchical structures of sentences with their layer-by-layer composition and pooling, but also capture the rich matching patterns at different levels. Our models are rather generic, requiring no prior knowledge on language, and can hence be applied to matching tasks of different nature and in different languages. The empirical study on a variety of matching tasks demonstrates the efficacy of the proposed model on a variety of matching tasks and its superiority to competitor models.", "subjects": "Computation and Language (cs.CL)", "authors": "Baotian Hu, Zhengdong Lu, Hang Li, Qingcai Chen,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03238", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03238", "title": "\nScalable Discovery of Time-Series Shapelets", "abstract": "Time-series classification is an important problem for the data mining community due to the wide range of application domains involving time-series data. A recent paradigm, called shapelets, represents patterns that are highly predictive for the target variable. Shapelets are discovered by measuring the prediction accuracy of a set of potential (shapelet) candidates. The candidates typically consist of all the segments of a dataset, therefore, the discovery of shapelets is computationally expensive. This paper proposes a novel method that avoids measuring the prediction accuracy of similar candidates in Euclidean distance space, through an online clustering pruning technique. In addition, our algorithm incorporates a supervised shapelet selection that filters out only those candidates that improve classification accuracy. Empirical evidence on 45 datasets from the UCR collection demonstrate that our method is 3-4 orders of magnitudes faster than the fastest existing shapelet-discovery method, while providing better prediction accuracy.", "subjects": "Learning (cs.LG)", "authors": "Josif Grabocka, Martin Wistuba, Lars Schmidt-Thieme,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03233", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03233", "title": "\nSecurity challenges in mobile ad hoc networks:a survey", "abstract": "MANET is a kind of Ad hoc network with mobile, wireless nodes. Because of its special characteristics like dynamic topology, hop-by-hop communications and easy and quick setup, MANET faced lots of challenges allegorically routing, security and clustering. The security challenges arise due to MANETs self-configuration and self-maintenance capabilities. In this paper, we present an elaborate view of issues in MANET security. Based on MANETs special characteristics, we define three security parameters for MANET. In addition we divided MANET security into two different aspects and discussed each one in details. A comprehensive analysis in security aspects of MANET and defeating approaches is presented. In addition, defeating approaches against attacks have been evaluated in some important metrics. After analyses and evaluations, future scopes of work have been presented.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Ali Dorri, Seyed Reza Kamel, Esmaeil Kheirkhah,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03223", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03223", "title": "\nLower Bound on the Capacity of Continuous-Time Wiener Phase Noise  Channels", "abstract": "A continuous-time Wiener phase noise channel with an integrate-and-dump multi-sample receiver is studied. A lower bound to the capacity with an average input power constraint is derived, and a high signal-to-noise ratio (SNR) analysis is performed. The capacity pre-log depends on the oversampling factor, and amplitude and phase modulation do not equally contribute to capacity at high SNR.", "subjects": "Information Theory (cs.IT)", "authors": "Luca Barletta, Gerhard Kramer,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03215", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03215", "title": "\nEnvironment Based Secure Transfer of Data in Wireless Sensor Networks", "abstract": "Most critical sensor readings (Top-k Monitoring) in environment monitoring system are important to many wireless sensor applications. In such applications, sensor nodes transmit the data continuously for a specific time period to the storage nodes. It is responsible for transferring the received results to the Authority on Top-k Query request from them. Dummy data's were added into the original text data to secure the data against adversary in case of hacking the sensor and storage nodes. If storage node gets hacked by adversary, false details will be sent to the authority. An effective technique named aggregate signature to validate the source of the message and also to protect the data against latest security attacks, cryptography technique combined with steganography has been introduced. Indexed based scheme for the database access has also been proposed, to validate the resources against availability before forwarding the data fetch request to storage nodes from Authority.", "subjects": "Cryptography and Security (cs.CR)", "authors": "B. Vidhya, Mary Joseph, D. Rajini Girinath, A. Malathi,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03211", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03211", "title": "\nA Multi-Gene Genetic Programming Application for Predicting Students  Failure at School", "abstract": "Several efforts to predict student failure rate (SFR) at school accurately still remains a core problem area faced by many in the educational sector. The procedure for forecasting SFR are rigid and most often times require data scaling or conversion into binary form such as is the case of the logistic model which may lead to lose of information and effect size attenuation. Also, the high number of factors, incomplete and unbalanced dataset, and black boxing issues as in Artificial Neural Networks and Fuzzy logic systems exposes the need for more efficient tools. Currently the application of Genetic Programming (GP) holds great promises and has produced tremendous positive results in different sectors. In this regard, this study developed GPSFARPS, a software application to provide a robust solution to the prediction of SFR using an evolutionary algorithm known as multi-gene genetic programming. The approach is validated by feeding a testing data set to the evolved GP models. Result obtained from GPSFARPS simulations show its unique ability to evolve a suitable failure rate expression with a fast convergence at 30 generations from a maximum specified generation of 500. The multi-gene system was also able to minimize the evolved model expression and accurately predict student failure rate using a subset of the original expression", "subjects": "Computers and Society (cs.CY)", "authors": "J.O. Orove, N.E. Osegi, B.O. Eke,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03208", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03208", "title": "\nFraudulent Electronic transaction detection using KDA Model", "abstract": "Clustering analysis and Datamining methodologies were applied to the problem of identifying illegal and fraud transactions. The researchers independently developed model and software using data provided by a bank and using Rapidminer modeling tool. The research objectives are to propose dynamic model and mechanism to cover fraud detection system limitations. KDA model as proposed model can detect 68.75% of fraudulent transactions with online dynamic modeling and 81.25% in offline mode and the Fraud Detection System &amp; Decision Support System. Software propose a good supporting procedure to detect fraudulent transaction dynamically.", "subjects": "Databases (cs.DB)", "authors": "M.Vadoodparast, A. Razak Hamdan, Hafiz,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03202", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03202", "title": "\nProiectarea si implementarea unui portal HL7", "abstract": "This paper introduces some techniques used in developing and implementing an HL7 clinical data portal used in client-server architecture. The HL7 portal is used by nonHL7 applications that need medical data from HL7 servers. Also, the portal can translate a large number of HL7 terms between an indefinite number of languages.", "subjects": "Software Engineering (cs.SE)", "authors": "Marius Cristian Cerlinca, Tudor Ioan Cerlinca, Cristina Elena Turcu, Remus Catalin Prodan, Felicia Florentina Giza-Belciug,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.03195", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03195", "title": "\nReconciling a component and process view", "abstract": "In many cases we need to represent on the same abstraction level not only system components but also processes within the system, and if for both representation different frameworks are used, the system model becomes hard to read and to understand. We suggest a solution how to cover this gap and to reconcile component and process views on system representation: a formal framework that gives the advantage of solving design problems for large-scale component systems.", "subjects": "Software Engineering (cs.SE)", "authors": "Maria Spichkova, Heinz Schmidt,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03191", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03191", "title": "\nA model-based approach to recovering the structure of a plant from  images", "abstract": "We present a method for recovering the structure of a plant directly from a small set of widely-spaced images. Structure recovery is more complex than shape estimation, but the resulting structure estimate is more closely related to phenotype than is a 3D geometric model. The method we propose is applicable to a wide variety of plants, but is demonstrated on wheat. Wheat is made up of thin elements with few identifiable features, making it difficult to analyse using standard feature matching techniques. Our method instead analyses the structure of plants using only their silhouettes. We employ a generate-and-test method, using a database of manually modelled leaves and a model for their composition to synthesise plausible plant structures which are evaluated against the images. The method is capable of efficiently recovering accurate estimates of plant structure in a wide variety of imaging scenarios, with no manual intervention.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Ben Ward, John Bastian, Anton van den Hengel, Daniel Pooley, Rajendra Bari, Bettina Berger, Mark Tester,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.03187", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03187", "title": "\nSimple, Accurate, and Robust Nonparametric Blind Super-Resolution", "abstract": "This paper proposes a simple, accurate, and robust approach to single image nonparametric blind Super-Resolution (SR). This task is formulated as a functional to be minimized with respect to both an intermediate super-resolved image and a nonparametric blur-kernel. The proposed approach includes a convolution consistency constraint which uses a non-blind learning-based SR result to better guide the estimation process. Another key component is the unnatural bi-l0-l2-norm regularization imposed on the super-resolved, sharp image and the blur-kernel, which is shown to be quite beneficial for estimating the blur-kernel accurately. The numerical optimization is implemented by coupling the splitting augmented Lagrangian and the conjugate gradient (CG). Using the pre-estimated blur-kernel, we finally reconstruct the SR image by a very simple non-blind SR method that uses a natural image prior. The proposed approach is demonstrated to achieve better performance than the recent method by Michaeli and Irani [2] in both terms of the kernel estimation accuracy and image SR quality.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Wen-Ze Shao, Michael Elad,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.03185", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03185", "title": "\nTesting randomness by Matching Pennies", "abstract": "In the game of Matching Pennies, Alice and Bob each hold a penny, and at every tick of the clock they simultaneously display the head or the tail sides of their coins. If they both display the same side, then Alice wins Bob's penny; if they display different sides, then Bob wins Alice's penny. To avoid giving the opponent a chance to win, both players seem to have nothing else to do but to randomly play heads and tails with equal frequencies. However, while not losing in this game is easy, not missing an opportunity to win is not. Randomizing your own moves can be made easy. Recognizing when the opponent's moves are not random can be arbitrarily hard. The notion of randomness is central in game theory, but it is usually taken for granted. The notion of outsmarting is not central in game theory, but it is central in the practice of gaming. We pursue the idea that these two notions can be usefully viewed as two sides of the same coin.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Dusko Pavlovic,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03184", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03184", "title": "\nFundamental Limits of Blind Deconvolution Part II: Sparsity-Ambiguity  Trade-offs", "abstract": "Blind deconvolution is an ubiquitous non-linear inverse problem in applications like wireless communications and image processing. This problem is generally ill-posed since signal identifiability is a key concern, and there have been efforts to use sparse models for regularizing blind deconvolution to promote signal identifiability. Part I of this two-part paper establishes a measure theoretically tight characterization of the ambiguity space for blind deconvolution and unidentifiability of this inverse problem under unconstrained inputs. Part II of this paper analyzes the identifiability of the canonical-sparse blind deconvolution problem and establishes surprisingly strong negative results on the sparsity-ambiguity trade-off scaling laws. Specifically, the ill-posedness of canonical-sparse blind deconvolution is quantified by exemplifying the dimension of the unidentifiable signal sets. An important conclusion of the paper is that canonical sparsity occurring naturally in applications is insufficient and that coding is necessary for signal identifiability in blind deconvolution. The methods developed herein are applied to a second-hop channel estimation problem to show that a family of subspace coded signals (including repetition coding and geometrically decaying signals) are unidentifiable under blind deconvolution.", "subjects": "Information Theory (cs.IT)", "authors": "Sunav Choudhary, Urbashi Mitra,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03176", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03176", "title": "\nTowards a Science of Trust", "abstract": "The diverse views of science of security have opened up several alleys towards applying the methods of science to security. We pursue a different kind of connection between science and security. This paper explores the idea that security is not just a suitable subject for science, but that the process of security is also similar to the process of science. This similarity arises from the fact that both science and security depend on the methods of inductive inference. Because of this dependency, a scientific theory can never be definitely proved, but can only be disproved by new evidence, and improved into a better theory. Because of the same dependency, every security claim and method has a lifetime, and always eventually needs to be improved. In this general framework of security-as-science, we explore the ways to apply the methods of scientific induction in the process of trust. The process of trust building and updating is viewed as hypothesis testing. We propose to formulate the trust hypotheses by the methods of algorithmic learning, and to build more robust trust testing and vetting methodologies on the solid foundations of statistical inference.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Dusko Pavlovic,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03175", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03175", "title": "\nBenchmarking NLopt and state-of-art algorithms for Continuous Global  Optimization via Hybrid IACO$_\\mathbb{R}$", "abstract": "This paper presents a comparative analysis of the performance of the Incremental Ant Colony algorithm for continuous optimization (), with different algorithms provided in the NLopt library. The key objective is to understand how the various algorithms in the NLopt library perform in combination with the Multi Trajectory Local Search (Mtsls1) technique. A hybrid approach has been introduced in the local search strategy by the use of a parameter which allows for probabilistic selection between Mtsls1 and a NLopt algorithm. In case of stagnation, the algorithm switch is made based on the algorithm being used in the previous iteration. The paper presents an exhaustive comparison on the performance of these approaches on Soft Computing (SOCO) and Congress on Evolutionary Computation (CEC) 2014 benchmarks. For both benchmarks, we conclude that the best performing algorithm is a hybrid variant of Mtsls1 with BFGS for local search.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "Udit Kumar, Sumit Soman, Jayadeva,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03170", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03170", "title": "\nMin Morse: Approximability & Applications", "abstract": "We resolve an open problem posed by Joswig et al. by providing an time, -factor approximation algorithm for the min-Morse unmatched problem (MMUP) Let be the no. of critical cells of the optimal discrete Morse function and be the total no. of cells of a regular cell complex K. The goal of MMUP is to find for a given complex K. To begin with, we apply an approx. preserving graph reduction on MMUP to obtain a new problem namely the min-partial order problem (min-POP)(a strict generalization of the min-feedback arc set problem). The reduction involves introduction of rigid edges which are edges that demand strict inclusion in output solution. To solve min-POP, we use the Leighton- Rao divide-&amp;-conquer paradigm that provides solutions to SDP-formulated instances of min-directed balanced cut with rigid edges (min-DBCRE). Our first algorithm for min-DBCRE extends Agarwal et al.'s rounding procedure for digraph formulation of ARV-algorithm to handle rigid edges. Our second algorithm to solve min-DBCRE SDP, adapts Arora et al.'s primal dual MWUM. In terms of applications, under the mild assumption1 of the size of topological features being significantly smaller compared to the size of the complex, we obtain an (a) algorithm for computing homology groups of a simplicial complex K, (where A is an arbitrary Abelian group.) (b) an algorithm for computing persistent homology and (c) an algorithm for computing the optimal discrete Morse-Witten function compatible with input scalar function as simple consequences of our approximation algorithm for MMUP thereby giving us the best known complexity bounds for each of these applications under the aforementioned assumption. Such an assumption is realistic in applied settings, and often a characteristic of modern massive datasets.", "subjects": "Computational Geometry (cs.CG)", "authors": "Abhishek Rathore,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03169", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03169", "title": "\nDynamic Partitioning of Physical Memory Among Virtual Machines,  ASMI:Architectural Support for Memory Isolation", "abstract": "Cloud computing relies on secure and efficient virtualization. Software level security solutions compromise the performance of virtual machines (VMs), as a large amount of computational power would be utilized for running the security modules. Moreover, software solutions are only as secure as the level that they work on. For example a security module on a hypervisor cannot provide security in the presence of an infected hypervisor. It is a challenge for virtualization technology architects to enhance the security of VMs without degrading their performance. Currently available server machines are not fully equipped to support a secure VM environment without compromising on performance. A few hardware modifications have been introduced by manufactures like Intel and AMD to provide a secure VM environment with low performance degradation. In this paper we propose a novel memory architecture model named textit, that can achieve a true isolated physical memory region to each VM without degrading performance. Along with true memory isolation, ASMI is designed to provide lower memory access times, better utilization of available memory, support for DMA isolation and support for platform independence for users of VMs.", "subjects": "Hardware Architecture (cs.AR)", "authors": "Jithin R, Priya Chandran,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.03168", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03168", "title": "\nExperimental Estimation of Number of Clusters Based on Cluster Quality", "abstract": "Text Clustering is a text mining technique which divides the given set of text documents into significant clusters. It is used for organizing a huge number of text documents into a well-organized form. In the majority of the clustering algorithms, the number of clusters must be specified apriori, which is a drawback of these algorithms. The aim of this paper is to show experimentally how to determine the number of clusters based on cluster quality. Since partitional clustering algorithms are well-suited for clustering large document datasets, we have confined our analysis to a partitional clustering algorithm.", "subjects": "Information Retrieval (cs.IR)", "authors": "G. Hannah Grace, Kalyani Desikan,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.03167", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03167", "title": "\nDeep Convolutional Inverse Graphics Network", "abstract": "This paper presents the Deep Convolution Inverse Graphics Network (DC-IGN) that aims to learn an interpretable representation of images that is disentangled with respect to various transformations such as object out-of-plane rotations, lighting variations, and texture. The DC-IGN model is composed of multiple layers of convolution and de-convolution operators and is trained using the Stochastic Gradient Variational Bayes (SGVB) algorithm. We propose training procedures to encourage neurons in the graphics code layer to have semantic meaning and force each group to distinctly represent a specific transformation (pose,light,texture,shape etc.). Given a static face image, our model can re-generate the input image with different pose, lighting or even texture and shape variations from the base face. We present qualitative and quantitative results of the model's efficacy to learn a 3D rendering engine. Moreover, we also utilize the learnt representation for two important visual recognition tasks: (1) an invariant face recognition task and (2) using the representation as a summary statistic for generative modeling.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Tejas D. Kulkarni, Will Whitney, Pushmeet Kohli, Joshua B. Tenenbaum,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.03166", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03166", "title": "\nDesign of High Performance MIPS Cryptography Processor Based on T-DES  Algorithm", "abstract": "The paper describes the design of high performance MIPS Cryptography processor based on triple data encryption standard. The organization of pipeline stages in such a way that pipeline can be clocked at high frequency. Encryption and Decryption blocks of triple data encryption standard (T-DES) crypto system and dependency among themselves are explained in detail with the help of block diagram. In order to increase the processor functionality and performance, especially for security applications we include three new 32-bit instructions LKLW, LKUW and CRYPT. The design has been synthesized at 40nm process technology targeting using Xilinx Virtex-6 device. The overall MIPS Crypto processor works at 209MHz.", "subjects": "Hardware Architecture (cs.AR)", "authors": "Kirat Pal Singh, Shivani Parmar,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.03165", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03165", "title": "\nIterative Merging Algorithm for Cooperative Data Exchange", "abstract": "This paper considers the problem of finding the minimum sum-rate strategy in cooperative data exchange (CDE) systems. In a CDE system, there are a number of geographically close cooperative clients who send packets to help the others recover a packet set. A minimum sum-rate strategy is the strategy that achieves universal recovery (the situation when all the clients recover the whole packet set) with the the minimal sum-rate (the total number of transmissions). We propose an iterative merging (IM) algorithm that recursively merges client sets based on an estimate of the minimum sum-rate and achieves local recovery until the universal recovery is achieved. We prove that the minimum sum-rate and a corresponding strategy can be found by starting the IM algorithm with an initial lower estimate of the minimum sum-rate. We run an experiment to show that the complexity of the IM algorithm is lower than the complexity of existing deterministic algorithms.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Ni Ding, Rodney A. Kennedy, Parastoo Sadeghi,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03163", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03163", "title": "\nLearning Classifiers from Synthetic Data Using a Multichannel  Autoencoder", "abstract": "We propose a method for using synthetic data to help learning classifiers. Synthetic data, even is generated based on real data, normally results in a shift from the distribution of real data in feature space. To bridge the gap between the real and synthetic data, and jointly learn from synthetic and real data, this paper proposes a Multichannel Autoencoder(MCAE). We show that by suing MCAE, it is possible to learn a better feature representation for classification. To evaluate the proposed approach, we conduct experiments on two types of datasets. Experimental results on two datasets validate the efficiency of our MCAE model and our methodology of generating synthetic data.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Xi Zhang, Yanwei Fu, Andi Zang, Leonid Sigal, Gady Agam,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03157", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03157", "title": "\nSolving Local Linear Systems with Boundary Conditions Using Heat Kernel  Pagerank", "abstract": "We present an efficient algorithm for solving local linear systems with a boundary condition using the Green's function of a connected induced subgraph related to the system. We introduce the method of using the Dirichlet heat kernel pagerank vector to approximate local solutions to linear systems in the graph Laplacian satisfying given boundary conditions over a particular subset of vertices. With an efficient algorithm for approximating Dirichlet heat kernel pagerank, our local linear solver algorithm computes an approximate local solution with multiplicative and additive error by performing random walk steps, where is the number of vertices in the full graph and is the size of the local system on the induced subgraph.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Fan Chung, Olivia Simpson,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03155", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03155", "title": "\nComputing Heat Kernel Pagerank and a Local Clustering Algorithm", "abstract": "Heat kernel pagerank is a variation of Personalized PageRank given in an exponential formulation. In this work, we present a sublinear time algorithm for approximating the heat kernel pagerank of a graph. The algorithm works by simulating random walks of bounded length and runs in time , assuming performing a random walk step and sampling from a distribution with bounded support take constant time. The quantitative ranking of vertices obtained with heat kernel pagerank can be used for local clustering algorithms. We present an efficient local clustering algorithm that finds cuts by performing a sweep over a heat kernel pagerank vector, using the heat kernel pagerank approximation algorithm as a subroutine. Specifically, we show that for a subset of Cheeger ratio , many vertices in may serve as seeds for a heat kernel pagerank vector which will find a cut of conductance .", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Fan Chung, Olivia Simpson,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03148", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03148", "title": "\nA Neurodynamical System for finding a Minimal VC Dimension Classifier", "abstract": "The recently proposed Minimal Complexity Machine (MCM) finds a hyperplane classifier by minimizing an exact bound on the Vapnik-Chervonenkis (VC) dimension. The VC dimension measures the capacity of a learning machine, and a smaller VC dimension leads to improved generalization. On many benchmark datasets, the MCM generalizes better than SVMs and uses far fewer support vectors than the number used by SVMs. In this paper, we describe a neural network based on a linear dynamical system, that converges to the MCM solution. The proposed MCM dynamical system is conducive to an analogue circuit implementation on a chip or simulation using Ordinary Differential Equation (ODE) solvers. Numerical experiments on benchmark datasets from the UCI repository show that the proposed approach is scalable and accurate, as we obtain improved accuracies and fewer number of support vectors (upto 74.3% reduction) with the MCM dynamical system.", "subjects": "Learning (cs.LG)", "authors": "Jayadeva, Sumit Soman, Amit Bhaya,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03144", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03144", "title": "\nControl Contraction Metrics: Convex and Intrinsic Criteria for Nonlinear  Feedback Design", "abstract": "Contraction analysis uses differential dynamics and appropriate metrics to show that all solutions of a particular system converge exponentially. In this paper we generalize this approach to problems in control design, giving sufficient conditions for exponential stabilizability of all trajectories of a nonlinear control system. The conditions can be expressed in terms of a dual metric as (convex) pointwise linear matrix inequalities. We show that for feedback linearizable systems the conditions are necessary as well as sufficient. We also show how computation can be greatly simplified through the use of a virtual dynamical system admitting any solution of the actual system as a particular trajectory. The results on virtual systems are used to derive novel convex criteria for exponential convergence to a flow-invariant nonlinear manifold. Extensions to approximate optimal and robust control are straightforward, and generalize well-known linear results. The proposed techniques are illustrated with several example problems.", "subjects": "Systems and Control (cs.SY)", "authors": "Ian R. Manchester, Jean-Jacques E. Slotine,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03137", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03137", "title": "\nComparing Network Structures of Commercial and Non-commercial Biohacking  Online-communities", "abstract": "This paper compares two biohacking groups, Bulletproof Executive and DIYbio, whose distinct goals result in differences in social network structures, activities and entry points.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Sipra Bihani, Michael Hartman, Florian Sobiegalla, Amanda Rosenberg,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03131", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03131", "title": "\nDiscovering functional zones using bus smart card data and points of  interest in Beijing", "abstract": "Cities comprise various functional zones, including residential, educational, commercial zones, etc. It is important for urban planners to identify different functional zones and understand their spatial structure within the city in order to make better urban plans. In this research, we used 77976010 bus smart card records of Beijing City in one week in April 2008 and converted them into two-dimensional time series data of each bus platform, Then, through data mining in the big database system and previous studies on citizens' trip behavior, we established the DZoF (discovering zones of different functions) model based on SCD (smart card Data) and POIs (points of interest), and pooled the results at the TAZ (traffic analysis zone) level. The results suggested that DzoF model and cluster analysis based on dimensionality reduction and EM (expectation-maximization) algorithm can identify functional zones that well match the actual land uses in Beijing. The methodology in the present research can help urban planners and the public understand the complex urban spatial structure and contribute to the academia of urban geography and urban planning.", "subjects": "Computers and Society (cs.CY)", "authors": "Haoying Han, Xiang Yu, Ying Long,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03130", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03130", "title": "\nModels and Information Rates for Wiener Phase Noise Channels", "abstract": "A waveform channel is considered where the transmitted signal is corrupted by Wiener phase noise and additive white Gaussian noise. A discrete-time channel model that takes into account the effect of filtering on the phase noise is developed. The model is based on a multi-sample receiver, i.e., an integrate-and-dump filter whose output is sampled at a rate higher than the signaling rate. It is shown that, at high signal-to-noise ratio (SNR), the multi-sample receiver achieves a rate that grows logarithmically with the SNR if the number of samples per symbol (oversampling factor) grows with the cubic root of the SNR. Moreover, the pre-log factor is at least 1/2 and can be achieved by amplitude modulation. Numerical simulations are used to compute lower bounds on the information rates achieved by the multi-sample receiver. The simulations show that oversampling is beneficial for both strong and weak phase noise at high SNR. In fact, the information rates are sometimes substantially larger than when using commonly-used approximate discrete-time models. Finally, for an approximate discrete-time model of the multi-sample receiver, the capacity pre-log at high SNR is at least 3/4 if the number of samples per symbol grows with the square root of the SNR. The analysis shows that phase modulation achieves a pre-log of at least 1/4 while amplitude modulation achieves a pre-log of 1/2. This is strictly greater than the capacity pre-log of the (approximate) discrete-time Wiener phase noise channel with only one sample per symbol, which is 1/2.", "subjects": "Information Theory (cs.IT)", "authors": "Hassan Ghozlan, Gerhard Kramer,", "date": "2015-3-11"}, 
{"urllink": "http://arxiv.org/abs/1503.03128", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03128", "title": "\nUsing Straggler Replication to Reduce Latency in Large-scale Parallel  Computing (Extended Version)", "abstract": "Users expect fast and fluid response from today's cloud infrastructure. Large-scale computing frameworks such as MapReduce divide jobs into many parallel tasks and execute them on different machines to enable faster processing. But the tasks on the slowest machines (straggling tasks) become the bottleneck in the completion of the job. One way to combat the variability in machine response time, is to add replicas of straggling tasks and wait for one copy to finish. In this paper we analyze how task replication strategies can be used to reduce latency, and their impact on the cost of computing resources. We use extreme value theory to show that the tail of the execution time distribution is the key factor in characterizing the trade-off between latency and computing cost. From this trade-off we can determine which task replication strategies reduce latency, without a large increase in computing cost. We also propose a heuristic algorithm to search for the best replication strategies when it is difficult to fit a simple distribution to model the empirical behavior of task execution time, and use the proposed analysis techniques. Evaluation of the heuristic policies on Google Trace data shows a significant latency reduction compared to the replication strategy used in MapReduce.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Da Wang, Gauri Joshi, Gregory Wornell,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.03124", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03124", "title": "\nModels and Information Rates for Multiuser Optical Fiber Channels with  Nonlinearity and Dispersion", "abstract": "Discrete-time interference channel models are developed for information transmission over optical fiber using wavelength-division multiplexing. A set of coupled nonlinear Schroedinger equations forms the basis of the models. The first model is memoryless and captures the nonlinear phenomena of cross-phase modulation but ignores dispersion. For the case of two carriers, a new technique called interference focusing is proposed where each carrier achieves the capacity pre-log 1, thereby doubling the pre-log of 1/2 achieved by using conventional methods. For more than two carriers, interference focusing is also useful under certain conditions. The second model captures the nonlinear phenomena of cross-phase modulation in addition to dispersion due to group velocity mismatch. Moreover, the model captures the effect of filtering at the receivers. In a 3-user system, it is shown that all users can achieve the maximum pre-log factor 1 simultaneously by using interference focusing, a time-limited pulse and a bank of filters at the receivers.", "subjects": "Information Theory (cs.IT)", "authors": "Hassan Ghozlan, Gerhard Kramer,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.03122", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03122", "title": "\nStructured Spreadsheet Modeling and Implementation", "abstract": "Developing an error-free spreadsheet has been a problem since the beginning of end-user computing. In this paper, we present a methodology that separates the modeling from the implementation. Using proven techniques from Information Systems and Software Engineering, we present strict, but simple, rules governing the implementation from the model. The resulting spreadsheet should be easier to understand, audit and maintain.", "subjects": "Software Engineering (cs.SE)", "authors": "Paul Mireault,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.03113", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03113", "title": "\nHardware Probing Interface and Test Robustness", "abstract": "Computerized integrity test of an electronic product hardware interface and product probing validation are considered. Integrity testing is based on a current voltage characteristic measurement, when a small voltage and/or current stimuli are applied to the product pads including power supply circuitry pads, so that the product is not normally powered on. Test fixture needles validation is a part of a self test maintenance scenario designed to predict deterioration of product probing.", "subjects": "Other Computer Science (cs.OH)", "authors": "A. M. Dorman,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.03105", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03105", "title": "\nA Global Geometric View of Splaying", "abstract": "Splay trees (Sleator and Tarjan) satisfy the so-called access lemma. Many of the nice properties of splay trees follow from it. What makes self-adjusting binary search trees (BSTs) satisfy the access lemma? We propose a global view of BST algorithms, which allows us to identify general structural properties of algorithms that satisfy the access lemma. As an application of our techniques, we present: (i) Unified and simpler proofs that capture all known BST algorithms satisfying the access lemma including splay trees and their generalization to the class of local algorithms (Subramanian, Georgakopoulos and McClurkin), as well as Greedy BST, introduced by Demaine et al. and shown to satisfy the access lemma by Fox. (ii) A new family of algorithms based on \"strict\" depth-halving, shown to satisfy the access lemma. (iii) An extremely short proof for the O(log n log log n) amortized access cost for the path-balance heuristic (proposed by Sleator), matching the best known bound (Balasubramanian and Raman) to a lower-order factor. Key to our results is a geometric view of how BST algorithms rearrange the search path, which reveals the underlying features that make the amortized cost logarithmic w.r.t. the sum-of-logs (SOL) potential. We obtain further structural results from this insight: for instance, we prove that locality is necessary for satisfying the access lemma, as long as the SOL potential is used. We believe that our work makes a step towards a full characterization of efficient self-adjusting BST algorithms, in particular, it shows the limitations of the SOL potential as a tool for analysis.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Parinya Chalermsook, Mayank Goswami, Laszlo Kozma, Kurt Mehlhorn, Thatchaphol Saranurak,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.03047", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03047", "title": "\nStability Analysis of Large-Scale Distributed Networked Control Systems  with Random Communication Delays: A Switched System Approach", "abstract": "In this paper, we consider the stability analysis of large-scale distributed networked control systems with random communication delays between linearly interconnected subsystems. The stability analysis is performed in the Markov jump linear system framework. There have been considerable researches on stability analysis of Markov jump systems, however, these methods are not applicable to large-scale systems because large numbers of subsystems result in an extremely large number of the switching modes. To avoid this scalability issue, we propose a new reduced mode model for stability analysis, which is computationally efficient. We also consider the case in which the transition probabilities for the Markov jump process contain uncertainties. We provide a new method that estimates bounds for uncertain Markov transition probability matrix to guarantee the system stability. The efficiency and the usefulness of the proposed methods are verified through examples.", "subjects": "Systems and Control (cs.SY)", "authors": "Kooktae Lee, Raktim Bhattacharya,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.03021", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03021", "title": "\nOpenStreetCab: Exploiting Taxi Mobility Patterns in New York City to  Reduce Commuter Costs", "abstract": "The rise of Uber as the global alternative taxi operator has attracted a lot of interest recently. Aside from the media headlines which discuss the new phenomenon, e.g. on how it has disrupted the traditional transportation industry, policy makers, economists, citizens and scientists have engaged in a discussion that is centred around the means to integrate the new generation of the sharing economy services in urban ecosystems. In this work, we aim to shed new light on the discussion, by taking advantage of a publicly available longitudinal dataset that describes the mobility of yellow taxis in New York City. In addition to movement, this data contains information on the fares paid by the taxi customers for each trip. As a result we are given the opportunity to provide a first head to head comparison between the iconic yellow taxi and its modern competitor, Uber, in one of the world's largest metropolitan centres. We identify situations when Uber X, the cheapest version of the Uber taxi service, tends to be more expensive than yellow taxis for the same journey. We also demonstrate how Uber's economic model effectively takes advantage of well known patterns in human movement. Finally, we take our analysis a step further by proposing a new mobile application that compares taxi prices in the city to facilitate traveller's taxi choices, hoping to ultimately to lead to a reduction of commuter costs. Our study provides a case on how big datasets that become public can improve urban services for consumers by offering the opportunity for transparency in economic sectors that lack up to date regulations.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Vsevolod Salnikov, Renaud Lambiotte, Anastasios Noulas, Cecilia Mascolo,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.03012", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03012", "title": "\nOn the role of the plasmodial cytoskeleton in facilitating intelligent  behaviour in slime mould Physarum polycephalum", "abstract": "The plasmodium of slime mould Physarum polycephalum behaves as an amorphous reaction-diffusion computing substrate and is capable of apparently intelligent behaviour. But how does intelligence emerge in an acellular organism? Through a range of laboratory experiments, we visualise the plasmodial cytoskeleton, a ubiquitous cellular protein scaffold whose functions are manifold and essential to life, and discuss its putative role as a network for transducing, transmitting and structuring data streams within the plasmodium. Through a range of computer modelling techniques, we demonstrate how emergent behaviour, and hence computational intelligence, may occur in cytoskeletal communications networks. Specifically, we model the topology of both the actin and tubulin cytoskeletal networks and discuss how computation may occur therein. Furthermore, we present bespoke cellular automata and particle swarm models for the computational process within the cytoskeleton and observe the incidence of emergent patterns in both. Our work grants unique insight into the origins of natural intelligence; the results presented here are therefore readily transferable to the fields of natural computation, cell biology and biomedical science. We conclude by discussing how our results may alter our biological, computational and philosophical understanding of intelligence and consciousness.", "subjects": "Emerging Technologies (cs.ET)", "authors": "Richard Mayne, Andrew Adamatzky, Jeff Jones,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.03011", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03011", "title": "\nTechnical Analysis on Financial Forecasting", "abstract": "Financial forecasting is an estimation of future financial outcomes for a company, industry, country using historical internal accounting and sales data. We may predict the future outcome of BSE_SENSEX practically by some soft computing techniques and can also optimized using PSO (Particle Swarm Optimization), EA (Evolutionary Algorithm) or DEA (Differential Evolutionary Algorithm) etc. PSO is a biologically inspired computational search &amp; optimization method developed in 1995 by Dr. Eberhart and Dr. Kennedy based on the social behaviors of fish schooling or birds flocking. PSO is a promising method to train Artificial Neural Network (ANN). It is easy to implement then Genetic Algorithm except few parameters are adjusted. PSO is a random &amp; pattern search technique based on populating of particle. In PSO, the particles are having some position and velocity in the search space. Two terms are used in PSO one is Local Best and another one is Global Best. To optimize problems that are like Irregular, Noisy, Change over time, Static etc. PSO uses a classic optimization method such as Gradient Decent &amp; Quasi-Newton Methods. The observation and review of few related studies in the last few years, focusing on function of PSO, modification of PSO and operation that have implemented using PSO like function optimization, ANN Training &amp; Fuzzy Control etc. Differential Evolution is an efficient EA technique for optimization of numerical problems, financial problems etc. PSO technique is introduced due to the swarming behavior of animals which is the collective behavior of similar size that aggregates together.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "S. Gopal Krishna Patro, Pragyan Parimita Sahoo, Ipsita Panda, Kishore Kumar Sahu,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.03004", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.03004", "title": "\nFast and Robust Fixed-Rank Matrix Recovery", "abstract": "We address the problem of efficient sparse fixed-rank (S-FR) matrix decomposition, i.e., splitting a corrupted matrix into an uncorrupted matrix of rank and a sparse matrix of outliers . Fixed-rank constraints are usually imposed by the physical restrictions of the system under study. Here we propose a method to perform accurate and very efficient S-FR decomposition that is more suitable for large-scale problems than existing approaches. Our method is a grateful combination of geometrical and algebraical techniques, which avoids the bottleneck caused by the Truncated SVD (TSVD). Instead, a polar factorization is used to exploit the manifold structure of fixed-rank problems as the product of two Stiefel and an SPD manifold, leading to a better convergence and stability. Then, closed-form projectors help to speed up each iteration of the method. We introduce a novel and fast projector for the manifold and a proof of its validity. Further acceleration is achieved using a Nystrom scheme. Extensive experiments with synthetic and real data in the context of robust photometric stereo and spectral clustering show that our proposals outperform the state of the art.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "German Ros, Julio Guerrero,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02997", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02997", "title": "\nSpreadsheets in an ERP environment: not what the doctor ordered", "abstract": "Modern ERP systems contain flexible report generators but the tendency exists for users to export data to spreadsheets for manipulation, reporting and decision making. A purported reason for this is that some users are more familiar with personal reporting tools (spreadsheets) as opposed to enterprise reporting tools. The author's doctoral research intends to measure the extent of spreadsheet usage in ERP environments and to determine which factors facilitate this.", "subjects": "Software Engineering (cs.SE)", "authors": "No'am Newman,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02994", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02994", "title": "\nQuantum Structure in Cognition, Origins, Developments, Successes and  Expectations", "abstract": "We provide an overview of the results we have attained in the last decade on the identification of quantum structures in cognition and, more specifically, in the formalization and representation of natural concepts. We firstly discuss the quantum foundational reasons that led us to investigate the mechanisms of formation and combination of concepts in human reasoning, starting from the empirically observed deviations from classical logical and probabilistic structures. We then develop our quantum-theoretic perspective in Fock space which allows successful modeling of various sets of cognitive experiments collected by different scientists, including ourselves. In addition, we formulate a unified explanatory hypothesis for the presence of quantum structures in cognitive processes, and discuss our recent discovery of further quantum aspects in concept combinations, namely, 'entanglement' and 'indistinguishability'. We finally illustrate perspectives for future research.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Diederik Aerts, Sandro Sozzo,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02985", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02985", "title": "\nSybilFrame: A Defense-in-Depth Framework for Structure-Based Sybil  Detection", "abstract": "Sybil attacks are becoming increasingly widespread, and pose a significant threat to online social systems; a single adversary can inject multiple colluding identities in the system to compromise security and privacy. Recent works have leveraged the use of social network-based trust relationships to defend against Sybil attacks. However, existing defenses are based on oversimplified assumptions, which do not hold in real world social graphs. In this work, we propose SybilFrame, a defense-in-depth framework for mitigating the problem of Sybil attacks when the oversimplified assumptions are relaxed. Our framework is able to incorporate prior information about users and edges in the social graph. We validate our framework on synthetic and real world network topologies, including a large-scale Twitter dataset with 20M nodes and 265M edges, and demonstrate that our scheme performs an order of magnitude better than previous structure-based approaches.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Peng Gao, Neil Zhenqiang Gong, Sanjeev Kulkarni, Kurt Thomas, Prateek Mittal,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02971", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02971", "title": "\nFirst-Order Logic Theorem Proving via Counterexample-Guided Abstraction  Refinement", "abstract": "Counterexample-guided abstraction refinement is a well-established technique in verification. In this paper we instantiate the idea for first-order logic theorem proving. Given a clause set we propose its abstraction into a clause set belonging to a decidable first-order fragment. The abstraction preserves satisfiability: if is satisfiable, so is . A refutation in can then either be lifted to a refutation in , or it guides a refinement of and its abstraction excluding the previously found refutation that is not liftable.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Andreas Teucke, Christoph Weidenbach,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02970", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02970", "title": "\nHam-Sandwich Cuts for Abstract Order Types", "abstract": "The linear-time ham-sandwich cut algorithm of Lo, Matou vek, and Steiger for bi-chromatic finite point sets in the plane works by appropriately selecting crossings of the lines in the dual line arrangement with a set of well-chosen vertical lines. We consider the setting where we are not given the coordinates of the point set, but only the orientation of each point triple (the order type) and give a deterministic linear-time algorithm for the mentioned sub-algorithm. This yields a linear-time ham-sandwich cut algorithm even in our restricted setting. We also show that our methods are applicable to abstract order types.", "subjects": "Computational Geometry (cs.CG)", "authors": "Stefan Felsner, Alexander Pilz,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02951", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02951", "title": "\nEnergy Coupon: A Mean Field Game Perspective on Demand Response in Smart  Grids", "abstract": "We consider the problem of a Load Serving Entity (LSE) trying to reduce its exposure to electricity market volatility by incentivizing demand response in a Smart Grid setting. We focus on the day-ahead electricity market, wherein the LSE has a good estimate of the statistics of the wholesale price of electricity at different hours in the next day, and wishes its customers to move a part of their power consumption to times of low mean and variance in price. Based on the time of usage, the LSE awards a differential number of \"Energy Coupons\" to each customer in proportion to the customer's electricity usage at that time. A lottery is held periodically in which the coupons held by all the customers are used as lottery tickets. Our study takes the form of a Mean Field Game, wherein each customer models the number of coupons that each of its opponents possesses via a distribution, and plays a best response pattern of electricity usage by trading off the utility of winning at the lottery versus the discomfort suffered by changing its usage pattern. The system is at a Mean Field Equilibrium (MFE) if the number of coupons that the customer receives is itself a sample drawn from the assumed distribution. We show the existence of an MFE, and characterize the mean field customer policy as having a multiple-threshold structure in which customers who have won too frequently or infrequently have low incentives to participate. We then numerically study the system with a candidate application of air conditioning during the summer months in the state of Texas. Besides verifying our analytical results, we show that the LSE can potentially attain quite substantial savings using our scheme. Our techniques can also be applied to resource sharing problems in other emph networks such as transportation or communication.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Jian Li, Bainan Xia, Xinbo Geng, Hao Ming, Srinivas Shakkottai, Vijay Subramanian, Le Xie,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02948", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02948", "title": "\nLinear Integer Arithmetic Revisited", "abstract": "We consider feasibility of linear integer programs in the context of verification systems such as SMT solvers or theorem provers. Although satisfiability of linear integer programs is decidable, many state-of-the-art solvers neglect termination in favor of efficiency. It is challenging to design a solver that is both terminating and practically efficient. Recent work by Jovanovic and de Moura constitutes an important step into this direction. Their algorithm CUTSAT is sound, but does not terminate, in general. In this paper we extend their CUTSAT algorithm by refined inference rules, a new type of conflicting core, and a dedicated rule application strategy. This leads to our algorithm CUTSAT++, which guarantees termination.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Martin Bromberger, Thomas Sturm, Christoph Weidenbach,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02945", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02945", "title": "\nFast Multi-class Dictionaries Learning with Geometrical Directions in  MRI Reconstruction", "abstract": "Compressed sensing magnetic resonance imaging has shown great capability to accelerate data acquisition by exploiting sparsity of images under a certain transform or dictionary. Sparser representations usually lead to lower reconstruction errors, thus enduring efforts have been made to find dictionaries that provide sparser representation of magnetic resonance images. Previously, adaptive sparse representations are typically trained with K-SVD and the state-of-the-art image quality is achieved in image reconstruction. However, this reconstruction is time consuming because of the relatively slow training process. In this paper, we introduce a fast dictionary learning method, which is essentially an adaptive tight frame construction, into magnetic resonance image reconstruction. To enhance the sparsity, images are divided into classified patches according to the same geometrical directions and dictionary is trained within each class. We set up a sparse reconstruction model with the multi-class dictionaries and solve the problem with a fast alternative direction multiplier method. Experiments on real magnetic resonance imaging data demonstrate that the proposed approach achieves the lowest reconstruction error compared with several state-of-the-art methods and the computation is much faster than previous dictionary learning methods.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Zhifang Zhan, Jian-Feng Cai, Di Guo, Yunsong Liu, Zhong Chen, Xiaobo Qu,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02940", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02940", "title": "\nEfficient Query Processing for SPARQL Federations with Replicated  Fragments", "abstract": "Low reliability and availability of public SPARQL endpoints prevent real-world applications from exploiting all the potential of these querying infras-tructures. Fragmenting data on servers can improve data availability but degrades performance. Replicating fragments can offer new tradeoff between performance and availability. We propose FEDRA, a framework for querying Linked Data that takes advantage of client-side data replication, and performs a source selection algorithm that aims to reduce the number of selected public SPARQL endpoints, execution time, and intermediate results. FEDRA has been implemented on the state-of-the-art query engines ANAPSID and FedX, and empirically evaluated on a variety of real-world datasets.", "subjects": "Databases (cs.DB)", "authors": "Gabriela Montoya, Hala Skaf-Molli, Pascal Molli, Maria-Esther Vidal,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02935", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02935", "title": "\nRobust PI Passivity-based Control of Nonlinear Systems: Application to  Port-Hamiltonian Systems and Temperature Regulation", "abstract": "This paper deals with the problem of control of partially known nonlinear systems, which have an open-loop stable equilibrium, but we would like to add a PI controller to regulate its behavior around another operating point. Our main contribution is the identification of a class of systems for which a globally stable PI can be designed knowing only the systems input matrix and measuring only the actuated coordinates. The construction of the PI is done invoking passivity theory. The difficulties encountered in the design of adaptive PI controllers with the existing theoretical tools are also discussed. As an illustration of the theory, we consider port--Hamiltonian systems and a class of thermal processes.", "subjects": "Systems and Control (cs.SY)", "authors": "Stanislav Aranovskiy, Romeo Ortega, Rafael Cisneros,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02927", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02927", "title": "\nBroadcasting Correlated Vector Gaussians", "abstract": "The problem of sending two correlated vector Gaussian sources over a bandwidth-matched two-user scalar Gaussian broadcast channel is studied in this work, where each receiver wishes to reconstruct its target source under a covariance distortion constraint. We derive a lower bound on the optimal tradeoff between the transmit power and the achievable reconstruction distortion pair. Our derivation is based on a new bounding technique which involves the introduction of appropriate remote sources. Furthermore, it is shown that this lower bound is achievable by a class of hybrid schemes for the special case where the weak receiver wishes to reconstruct a scalar source under the mean squared error distortion constraint.", "subjects": "Information Theory (cs.IT)", "authors": "Lin Song, Jun Chen, Chao Tian,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02920", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02920", "title": "\nDealing With 4-Variables by Resolution: An Improved MaxSAT Algorithm", "abstract": "We study techniques for solving the Maximum Satisfiability problem (MaxSAT). Our focus is on variables of degree 4. We identify cases for degree-4 variables and show how the resolution principle and the kernelization techniques can be nicely integrated to achieve more efficient algorithms for the MaxSAT problem. As a result, we present an algorithm of time for the MaxSAT problem, improving the previous best upper bound by Ivan Bliznets and Alexander.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Jianer Chen, Chao Xu,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02917", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02917", "title": "\nA Case Based Reasoning Approach for Answer Reranking in Question  Answering", "abstract": "In this document I present an approach to answer validation and reranking for question answering (QA) systems. A cased-based reasoning (CBR) system judges answer candidates for questions from annotated answer candidates for earlier questions. The promise of this approach is that user feedback will result in improved answers of the QA system, due to the growing case base. In the paper, I present the adequate structuring of the case base and the appropriate selection of relevant similarity measures, in order to solve the answer validation problem. The structural case base is built from annotated MultiNet graphs, which provide representations for natural language expressions, and corresponding graph similarity measures. I cover a priori relations to experienced answer candidates for former questions. I compare the CBR System results to current approaches in an experiment integrating CBR into an existing framework for answer validation and reranking. This integration is achieved by adding CBR-related features to the input of a learned ranking model that determines the final answer ranking. In the experiments based on QA@CLEF questions, the best learned models make heavy use of CBR features. Observing the results with a continually growing case base, I present a positive effect of the size of the case base on the accuracy of the CBR subsystem.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Karl-Heinz Weis,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02911", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02911", "title": "\nRDF-Hunter: Automatically Crowdsourcing the Execution of Queries Against  RDF Data Sets", "abstract": "In the last years, a large number of RDF data sets has become available on the Web. However, due to the semi-structured nature of RDF data, missing values affect answer completeness of queries that are posed against this data. To overcome this limitation, we propose RDF-Hunter, a novel hybrid query processing approach that brings together machine and human computation to execute queries against RDF data. We develop a novel quality model and query engine in order to enable RDF-Hunter to on the fly decide which parts of a query should be executed through conventional technology or crowd computing. To evaluate RDF-Hunter, we created a collection of 50 SPARQL queries against the DBpedia data set, executed them using our hybrid query engine, and analyzed the accuracy of the outcomes obtained from the crowd. The experiments clearly show that the overall approach is feasible and produces query results that reliably and significantly enhance completeness of automatic query processing responses.", "subjects": "Databases (cs.DB)", "authors": "Maribel Acosta, Elena Simperl, Fabian Fl\u00f6ck, Maria-Esther Vidal, Rudi Studer,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02893", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02893", "title": "\nRobust recovery of complex exponential signals from random Gaussian  projections via low rank Hankel matrix reconstruction", "abstract": "This paper explores robust recovery of a superposition of distinct complex exponential functions from a few random Gaussian projections. We assume that the signal of interest is of dimensional and . This framework covers a large class of signals arising from real applications in biology, automation, imaging science, etc. To reconstruct such a signal, our algorithm is to seek a low-rank Hankel matrix of the signal by minimizing its nuclear norm subject to the consistency on the sampled data. Our theoretical results show that a robust recovery is possible as long as the number of projections exceeds . No incoherence or separation condition is required in our proof. Our method can be applied to spectral compressed sensing where the signal of interest is a superposition of complex sinusoids. Compared to existing results, our result here does not need any separation condition on the frequencies, while achieving better or comparable bounds on the number of measurements. Furthermore, our method provides theoretical guidance on how many samples are required in the state-of-the-art non-uniform sampling in NMR spectroscopy. The performance of our algorithm is further demonstrated by numerical experiments.", "subjects": "Information Theory (cs.IT)", "authors": "Jian-Feng Cai, Xiaobo Qu, Weiyu Xu, Gui-Bo Ye,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02880", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02880", "title": "\nOn the Approximability of Independent Set Problem on Power Law Graphs", "abstract": "We give the first nonconstant lower bounds for the approximability of the Independent Set Problem on the Power Law Graphs. These bounds are of the form in the case when the power law exponent satisfies . In the case when , the lower bound is of the form . The embedding technique used in the proof could also be of independent interest.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Mathias Hauptmann, Marek Karpinski,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02878", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02878", "title": "\nMobile Node Localization via Pareto Optimization: Algorithm and  Fundamental Performance Limitations", "abstract": "Accurate estimation of the position of network nodes is essential, e.g., in localization, geographic routing, and vehicular networks. Unfortunately, typical positioning techniques based on ranging or on velocity and angular measurements are inherently limited. To overcome the limitations of specific positioning techniques, the fusion of multiple and heterogeneous sensor information is an appealing strategy. In this paper, we investigate the fundamental performance of linear fusion of multiple measurements of the position of mobile nodes, and propose a new distributed recursive position estimator. The Cram 'er-Rao lower bounds for the parametric and a-posteriori cases are investigated. The proposed estimator combines information coming from ranging, speed, and angular measurements, which is jointly fused by a Pareto optimization problem where the mean and the variance of the localization error are simultaneously minimized. A distinguished feature of the method is that it assumes a very simple dynamical model of the mobility and therefore it is applicable to a large number of scenarios providing good performance. The main challenge is the characterization of the statistical information needed to model the Fisher information matrix and the Pareto optimization problem. The proposed analysis is validated by Monte Carlo simulations, and the performance is compared to several Kalman-based filters, commonly employed for localization and sensor fusion. Simulation results show that the proposed estimator outperforms the traditional approaches that are based on the extended Kalman filter when no assumption on the model of motion is used. In such a scenario, better performance is achieved by the proposed method, but at the price of an increased computational complexity.", "subjects": "Information Theory (cs.IT)", "authors": "Alessio De Angelis, Carlo Fischione,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02877", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02877", "title": "\nWideband Self-Adaptive RF Cancellation Circuit for Full-Duplex Radio:  Operating Principle and Measurements", "abstract": "This paper presents a novel RF circuit architecture for self-interference cancellation in inband full-duplex radio transceivers. The developed canceller is able to provide wideband cancellation with waveform bandwidths in the order of 100 MHz or beyond and contains also self-adaptive or self-healing features enabling automatic tracking of time-varying self-interference channel characteristics. In addition to architecture and operating principle descriptions, we also provide actual RF measurements at 2.4 GHz ISM band demonstrating the achievable cancellation levels with different bandwidths and when operating in different antenna configurations and under low-cost highly nonlinear power amplifier. In a very challenging example with a 100 MHz waveform bandwidth, around 41 dB total cancellation is obtained while the corresponding cancellation figure is close to 60 dB with the more conventional 20 MHz carrier bandwidth. Also, efficient tracking in time-varying reflection scenarios is demonstrated.", "subjects": "Information Theory (cs.IT)", "authors": "Timo Huusari, Yang-Seok Choi, Petteri Liikkanen, Dani Korpi, Shilpa Talwar, Mikko Valkama,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02852", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02852", "title": "\nSingle stream parallelization of generalized LSTM-like RNNs on a GPU", "abstract": "Recurrent neural networks (RNNs) have shown outstanding performance on processing sequence data. However, they suffer from long training time, which demands parallel implementations of the training procedure. Parallelization of the training algorithms for RNNs are very challenging because internal recurrent paths form dependencies between two different time frames. In this paper, we first propose a generalized graph-based RNN structure that covers the most popular long short-term memory (LSTM) network. Then, we present a parallelization approach that automatically explores parallelisms of arbitrary RNNs by analyzing the graph structure. The experimental results show that the proposed approach shows great speed-up even with a single training stream, and further accelerates the training when combined with multiple parallel training streams.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "Kyuyeon Hwang, Wonyong Sung,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02843", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02843", "title": "\nAn Energy Efficient Ethernet Strategy Based on Traffic Prediction and  Shaping", "abstract": "Recently, different communities in computer science, telecommunication and control systems have devoted a huge effort towards the design of energy efficient solutions for data transmission and network management. This paper collocates along this research line and presents a novel energy efficient strategy conceived for Ethernet networks. The proposed strategy combines the statistical properties of the network traffic with the opportunities offered by the IEEE 802.3az amendment to the Ethernet standard, called Energy Efficient Ethernet (EEE). This strategy exploits the possibility of predicting the incoming traffic from the analysis of the current data flow, which typically presents a self-similar behavior. Based on the prediction, Ethernet links can then be put in a low power consumption state for the intervals of time in which traffic is expected to be of low intensity. Theoretical bounds are derived that detail how the performance figures depend on the parameters of the designed strategy and scale with respect to the traffic load. Furthermore, simulations results, based on both real and synthetic traffic traces, are presented to prove the effectiveness of the strategy, which leads to considerable energy savings at the cost of only a limited bounded delay in data delivery.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Angelo Cenedese, Marco Michielan, Federico Tramarin, Stefano Vitturi,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02835", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02835", "title": "\nPolynomial-time approximability of the k-Sink Location problem", "abstract": "A dynamic network where is a graph, integers and represent, for each edge , the time required to traverse edge and its nonnegative capacity, and the set is a set of sources. In the - problem, one is given as input a dynamic network where every source is given a nonnegative supply value . The task is then to find a set of sinks in that minimizes the routing time of all supply to . Note that, in the case where is an undirected graph, the optimal position of the sinks in needs not be at vertices, and can be located along edges. Hoppe and Tardos showed that, given an instance of - and a set of vertices , one can find an optimal routing scheme of all the supply in to in polynomial time, in the case where graph is directed. Note that when is directed, this suffices to obtain polynomial-time solvability of the - problem, since any optimal position will be located at vertices of . However, the computational complexity of the - problem on general undirected graphs is still open. In this paper, we show that the - problem admits a fully polynomial-time approximation scheme (FPTAS) for every fixed , and that the problem is -hard when parameterized by .", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "R\u00e9my Belmonte, Yuya Higashikawa, Naoki Katoh, Yoshio Okamoto,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02831", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02831", "title": "\nFree Space Optical Communication with Spatial Modulation and Coherent  Detection over Atmospheric Turbulence Channels", "abstract": "In this paper, the use of optical spatial modulation (OSM) which has recently emerged as a power and bandwidth efficient pulsed modulation technique for indoor optical wireless communication is proposed as a simple, low complexity means of achieving spatial diversity in coherent free space optical communication systems. In doing so, this paper makes several novel contributions as follows. Firstly, it presents a very generic mathematical framework for obtaining the Average Bit Error Probability (ABEP) of uncoded OSM in the presence of turbulence induced fading. Although the proposed framework is general enough to accommodate any type of models based on turbulence scattering, here we focus on the H-K distribution, as the adopted atmospheric turbulence channel model. This framework is exact for MIMO systems with two transmit- and an arbitrary number of receive apertures. For OSM systems with an arbitrary number of transmit apertures, tight bounds for the ABEP are also proposed. Secondly, for convolutional coded OSM systems, tight upper bounds for the ABEP are derived. Various numerical performance evaluation results are also presented and compared with equivalent results obtained by Monte Carlo simulations which verify the accuracy of the analytical expressions.", "subjects": "Information Theory (cs.IT)", "authors": "Kostas P. Peppas, P. Takis Mathiopoulos,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02825", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02825", "title": "\nThe Digital Life of Walkable Streets", "abstract": "Walkability has many health, environmental, and economic benefits. That is why web and mobile services have been offering ways of computing walkability scores of individual street segments. Those scores are generally computed from survey data and manual counting (of even trees). However, that is costly, owing to the high time, effort, and financial costs. To partly automate the computation of those scores, we explore the possibility of using the social media data of Flickr and Foursquare to automatically identify safe and walkable streets. We find that unsafe streets tend to be photographed during the day, while walkable streets are tagged with walkability-related keywords. These results open up practical opportunities (for, e.g., room booking services, urban route recommenders, and real-estate sites) and have theoretical implications for researchers who might resort to the use social media data to tackle previously unanswered questions in the area of walkability.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Daniele Quercia, Luca Maria Aiello, Rossano Schifanella, Adam Davies,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02815", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02815", "title": "\nOn the Performance of Multi-Antenna Wireless-Powered Communications with  Energy Beamforming", "abstract": "In this paper, we study the average throughput performance of energy beamforming in a multi-antenna wireless-powered communication network (WPCN). The considered network consists of one hybrid access-point (AP) with multiple antennas and a single antenna user. The user does not have constant power supply and thus needs to harvest energy from the signals broadcast by the AP in the downlink (DL), before sending its data back to the AP with the harvested energy in the uplink (UL). We derive closed-form expressions of the average throughput and their asymptotic expressions at high SNR for both delay-limited and delay-tolerant transmission modes. The optimal DL energy harvesting time, which maximizes the system throughput, is then obtained for high SNR. All analytical expressions are validated by numerical simulations. The impact of various parameters, such as the AP transmit power, the energy harvesting time, and the number of antennas, on the system throughput is also investigated.", "subjects": "Information Theory (cs.IT)", "authors": "Wenzhu Huang, He Chen, Yonghui Li, Branka Vucetic,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02809", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02809", "title": "\nA Universal Channel Model for Molecular Communication Systems with  Metal-Oxide Detectors", "abstract": "In this paper, we propose an end-to-end channel model for molecular communication systems with metal-oxide sensors. In particular, we focus on the recently developed table top molecular communication platform. The system is separated into two parts: the propagation and the sensor detection. There is derived, based on this, a more realistic end-to-end channel model. However, since some of the coefficients in the derived models are unknown, we collect a great deal of experimental data to estimate these coefficients and evaluate how they change with respect to the different system parameters. Finally, a noise model is derived for the system to complete an end-to-end system model for the tabletop platform.", "subjects": "Emerging Technologies (cs.ET)", "authors": "Na-Rae Kim, Nariman Farsad, Chan-Byoung Chae, Andrew W. Eckford,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02801", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02801", "title": "\nShort Text Hashing Improved by Integrating Multi-Granularity Topics and  Tags", "abstract": "Due to computational and storage efficiencies of compact binary codes, hashing has been widely used for large-scale similarity search. Unfortunately, many existing hashing methods based on observed keyword features are not effective for short texts due to the sparseness and shortness. Recently, some researchers try to utilize latent topics of certain granularity to preserve semantic similarity in hash codes beyond keyword matching. However, topics of certain granularity are not adequate to represent the intrinsic semantic information. In this paper, we present a novel unified approach for short text Hashing using Multi-granularity Topics and Tags, dubbed HMTT. In particular, we propose a selection method to choose the optimal multi-granularity topics depending on the type of dataset, and design two distinct hashing strategies to incorporate multi-granularity topics. We also propose a simple and effective method to exploit tags to enhance the similarity of related texts. We carry out extensive experiments on one short text dataset as well as on one normal text dataset. The results demonstrate that our approach is effective and significantly outperforms baselines on several evaluation metrics.", "subjects": "Information Retrieval (cs.IR)", "authors": "Jiaming Xu, Bo Xu, Guanhua Tian, Jun Zhao, Fangyuan Wang, Hongwei Hao,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02784", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02784", "title": "\nPromoting Truthful Behaviour in Participatory-Sensing Mechanisms", "abstract": "In this paper, the interplay between a class of nonlinear estimators and strategic sensors is studied in several participatory-sensing scenarios. It is shown that for the class of estimators, if the strategic sensors have access to noiseless measurements of the to-be-estimated-variable, truth-telling is an equilibrium of the game that models the interplay between the sensors and the estimator. Furthermore, performance of the proposed estimators is examined in the case that the strategic sensors form coalitions and in the presence of noise.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Farhad Farokhi, Iman Shames, Michael Cantoni,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02782", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02782", "title": "\nReduced Complexity Calculation of LMMSE Filter Coefficients for GFDM", "abstract": "A low-complexity algorithm for calculation of the LMMSE filter coefficients for GFDM in a block-fading multipath environment is derived in this letter. The simplification is based on the block circularity of the involved matrices. The proposal reduces complexity from cubic to squared order.", "subjects": "Information Theory (cs.IT)", "authors": "Maximilian Matth\u00e9, Ivan Gaspar, Dan Zhang, Gerhard Fettweis,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02781", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02781", "title": "\nUnravelling Graph-Exchange File Formats", "abstract": "A graph is used to represent data in which the relationships between the objects in the data are at least as important as the objects themselves. Over the last two decades nearly a hundred file formats have been proposed or used to provide portable access to such data. This paper seeks to review these formats, and provide some insight to both reduce the ongoing creation of unnecessary formats, and guide the development of new formats where needed.", "subjects": "Databases (cs.DB)", "authors": "Matthew Roughan, Jonathan Tuke,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02774", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02774", "title": "\nImproved Connectivity Condition for Byzantine Fault Tolerance", "abstract": "Given a network in which some pairs of nodes can communicate freely, and some subsets of the nodes could be faulty and colluding to disrupt communication, when can messages reliably be sent from one given node to another? We give a new characterization of when the agreement problem can be solved and provide an agreement algorithm which can reach agreement when the number of Byzantine nodes along each minimal vertex cut is bounded. Our new bound holds for a strict superset of cases than the previously known bound. We show that the new bound is tight. Furthermore, we show that this algorithm does not require the processes to know the graph structure, as the previously known algorithm did. Finally, we explore some of the situations in which we can reach agreement if we assume that individual nodes or entire subgraphs are trustworthy.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Adam Hesterberg, Andrea Lincoln, Jayson Lynch,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02773", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02773", "title": "\nSimpler, Linear-Time Transitive Orientation via Lexicographic  Breadth-First Search", "abstract": "Comparability graphs are the undirected graphs whose edges can be directed so that the resulting directed graph is transitive. They are related to posets and have applications in scheduling theory. This paper considers the problem of finding a transitive orientation of a comparability graph, a requirement for many of its applications. A linear-time algorithm is presented based on an elegant partition refinement scheme developed elsewhere for the problem. The algorithm is intended as a simpler and more practical alternative to the existing lineartime solution, which is commonly understood to be difficult and mainly of theoretical value. It accomplishes this by using Lexicographic Breadth-First Search to achieve the same effect as produced by modular decomposition in the earlier linear-time algorithm.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Marc Tedder,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02766", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02766", "title": "\nGenerating Single Peaked Votes", "abstract": "We discuss how to generate singled peaked votes uniformly from the Impartial Culture model.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Toby Walsh,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02754", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02754", "title": "\nModeling and Predicting Popularity Dynamics of Microblogs using  Self-Excited Hawkes Processes", "abstract": "The ability to model and predict the popularity dynamics of individual user generated items on online media has important implications in a wide range of areas. In this paper, we propose a probabilistic model using a Self-Excited Hawkes Process(SEHP) to characterize the process through which individual microblogs gain their popularity. This model explicitly captures the triggering effect of each forwarding, distinguishing itself from the reinforced Poisson process based model where all previous forwardings are simply aggregated as a single triggering effect. We validate the proposed model by applying it on Sina Weibo, the most popular microblogging network in China. Experimental results demonstrate that the SEHP model consistently outperforms the model based on reinforced Poisson process.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Peng Bao, Hua-Wei Shen, Xiaolong Jin, Xue-Qi Cheng,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02747", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02747", "title": "\nRate Selection for Cooperative HARQ-CC Systems over Time-Correlated  Nakagami-m Fading Channels", "abstract": "This paper addresses the problem of rate selection for the cooperative hybrid automatic repeat request with chase combination (HARQ-CC) system, where time correlated Nakagami-m fading channels are considered. To deal with this problem, the closed-form cumulative distribution function (CDF) for the combine SNRs through maximal ratio combining (MRC) is first derived as a generalized Fox's function. By using this result, outage probability and delay-limited throughput (DLT) are derived in closed forms, which then enables the rate selection for maximum DLT. These analytical results are validated via Monte Carlo simulations. The impacts of time correlation and channel fading-order parameter upon outage probability, DLT and the optimal rate are investigated thoroughly. It is found that the system can achieve more diversity gain from less correlated channels, and the outage probability of cooperative HARQ-CC system decreases with the increase of , and etc. Furthermore, the optimal rate increases with the number of retransmissions, while it decreases with the increase of the channel time correlation.", "subjects": "Information Theory (cs.IT)", "authors": "Zheng Shi, Shaodan Ma, Kam-Weng Tam,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02737", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02737", "title": "\nScrambled geometric net integration over general product spaces", "abstract": "Quasi-Monte Carlo (QMC) sampling has been developed for integration over where it has superior accuracy to Monte Carlo (MC) for integrands of bounded variation. Scrambled net quadrature gives allows replication based error estimation for QMC with at least the same accuracy and for smooth enough integrands even better accuracy than plain QMC. Integration over triangles, spheres, disks and Cartesian products of such spaces is more difficult for QMC because the induced integrand on a unit cube may fail to have the desired regularity. In this paper, we present a construction of point sets for numerical integration over Cartesian products of spaces of dimension , with triangles () being of special interest. The point sets are transformations of randomized -nets using recursive geometric partitions. The resulting integral estimates are unbiased and their variance is for any integrand in of the product space. Under smoothness assumptions on the integrand, our randomized QMC algorithm has variance , for integration over -fold Cartesian products of -dimensional domains, compared to for ordinary Monte Carlo.", "subjects": "Numerical Analysis (cs.NA)", "authors": "K. Basu, A. B. Owen,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02735", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02735", "title": "\nDynamic Service Placement for Mobile Micro-Clouds with Predicted Future  Costs", "abstract": "Seamless computing and data access is enabled by the emerging technology of mobile micro-clouds (MMCs). Different from traditional centralized clouds, an MMC is typically connected directly to a wireless base-station and provides services to a small group of users, which allows users to have instantaneous access to cloud services. Due to the limited coverage area of base-stations and the dynamic nature of mobile users, network background traffic, etc., the question of where to place the services to cope with these dynamics arises. In this paper, we focus on dynamic service placement for MMCs. We consider the case where there is an underlying mechanism to predict the future costs of service hosting and migration, and the prediction error is assumed to be bounded. Our goal is to find the optimal service placement sequence which minimizes the average cost over a given time. To solve this problem, we first propose a method which solves for the optimal placement sequence for a specific look-ahead time-window, based on the predicted costs in this time-window. We show that this problem is equivalent to a shortest-path problem and propose an algorithm with polynomial time-complexity to find its solution. Then, we propose a method to find the optimal look-ahead window size, which minimizes an upper bound of the average cost. Finally, we evaluate the effectiveness of the proposed approach by simulations with real-world user-mobility traces.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Shiqiang Wang, Rahul Urgaonkar, Kevin Chan, Ting He, Murtaza Zafer, Kin K. Leung,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02732", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02732", "title": "\nDetecting Incompleteness, Conflicting and Unreachability XACML Policies  using Answer Set Programming", "abstract": "Recently, XACML is a popular access control policy language that is used widely in many applications. Policies in XACML are built based on many components over distributed resources. Due to the expressiveness of XACML, it is not trivial for policy administrators to understand the overall effect and consequences of XACML policies they have written. In this paper we show a mechanism and a tool how to analyses big access control policies sets such as (i) incompleteness policies, (ii) conflicting policies, and (iii) unreachable policies. To detect these problems we present a method using Answer Set Programming (ASP) in the context of XACML 3.0.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Carroline Dewi Puspa Kencana Ramli,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02729", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02729", "title": "\nDonor Retention in Online Crowdfunding Communities: A Case Study of  DonorsChoose.org", "abstract": "Online crowdfunding platforms like DonorsChoose.org and Kickstarter allow specific projects to get funded by targeted contributions from a large number of people. Critical for the success of crowdfunding communities is recruitment and continued engagement of donors. With donor attrition rates above 70%, a significant challenge for online crowdfunding platforms as well as traditional offline non-profit organizations is the problem of donor retention. We present a large-scale study of millions of donors and donations on DonorsChoose.org, a crowdfunding platform for education projects. Studying an online crowdfunding platform allows for an unprecedented detailed view of how people direct their donations. We explore various factors impacting donor retention which allows us to identify different groups of donors and quantify their propensity to return for subsequent donations. We find that donors are more likely to return if they had a positive interaction with the receiver of the donation. We also show that this includes appropriate and timely recognition of their support as well as detailed communication of their impact. Finally, we discuss how our findings could inform steps to improve donor retention in crowdfunding communities and non-profit organizations.", "subjects": "Computers and Society (cs.CY)", "authors": "Tim Althoff, Jure Leskovec,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02727", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02727", "title": "\nVideo Compressive Sensing for Spatial Multiplexing Cameras using  Motion-Flow Models", "abstract": "Spatial multiplexing cameras (SMCs) acquire a (typically static) scene through a series of coded projections using a spatial light modulator (e.g., a digital micro-mirror device) and a few optical sensors. This approach finds use in imaging applications where full-frame sensors are either too expensive (e.g., for short-wave infrared wavelengths) or unavailable. Existing SMC systems reconstruct static scenes using techniques from compressive sensing (CS). For videos, however, existing acquisition and recovery methods deliver poor quality. In this paper, we propose the CS multi-scale video (CS-MUVI) sensing and recovery framework for high-quality video acquisition and recovery using SMCs. Our framework features novel sensing matrices that enable the efficient computation of a low-resolution video preview, while enabling high-resolution video recovery using convex optimization. To further improve the quality of the reconstructed videos, we extract optical-flow estimates from the low-resolution previews and impose them as constraints in the recovery procedure. We demonstrate the efficacy of our CS-MUVI framework for a host of synthetic and real measured SMC video data, and we show that high-quality videos can be recovered at roughly compression.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Aswin C. Sankaranarayanan, Lina Xu, Christoph Studer, Yun Li, Kevin Kelly, Richard G. Baraniuk,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02725", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02725", "title": "\nDeep Hierarchical Parsing for Semantic Segmentation", "abstract": "This paper proposes a learning-based approach to scene parsing inspired by the deep Recursive Context Propagation Network (RCPN). RCPN is a deep feed-forward neural network that utilizes the contextual information from the entire image, through bottom-up followed by top-down context propagation via random binary parse trees. This improves the feature representation of every super-pixel in the image for better classification into semantic categories. We analyze RCPN and propose two novel contributions to further improve the model. We first analyze the learning of RCPN parameters and discover the presence of bypass error paths in the computation graph of RCPN that can hinder contextual propagation. We propose to tackle this problem by including the classification loss of the internal nodes of the random parse trees in the original RCPN loss function. Secondly, we use an MRF on the parse tree nodes to model the hierarchical dependency present in the output. Both modifications provide performance boosts over the original RCPN and the new system achieves state-of-the-art performance on Stanford Background, SIFT-Flow and Daimler urban datasets.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Abhishek Sharma, Oncel Tuzel, David W. Jacobs,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02678", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02678", "title": "\nWhen In-Memory Computing is Slower than Heavy Disk Usage", "abstract": "Disk access latency and transfer times are often considered to have a major and detrimental impact on the running time of software. Developers are often advised to favour in-memory operations and minimise disk access. Furthermore, diskless computer architectures are being studied and designed to remove this bottleneck all together, to improve application performance in areas such as High Performance Computing, Big Data, and Business Intelligence. In this paper we use code inspired by real, production software, to show that in-memory operations are not always a guarantee for high performance, and may actually cause a considerable slow-down. We also show how small code changes can have dramatic effects on running times. We argue that a combination of system-level improvements and better developer awareness and coding practices are necessary to ensure in-memory computing can achieve its full potential.", "subjects": "Other Computer Science (cs.OH)", "authors": "Kamran Karimi, Diwakar Krishnamurthy, Parissa Mirjafari,", "date": "2015-3-10"}, 
{"urllink": "http://arxiv.org/abs/1503.02675", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02675", "title": "\nGlobal 6DOF Pose Estimation from Untextured 2D City Models", "abstract": "We propose a method for estimating the 3D pose for the camera of a mobile device in outdoor conditions, using only an untextured 2D model. Previous methods compute only a relative pose using a SLAM algorithm, or require many registered images, which are cumbersome to acquire. By contrast, our method returns an accurate, absolute camera pose in an absolute referential using simple 2D+height maps, which are broadly available, to refine a first estimate of the pose provided by the device's sensors. We show how to first estimate the camera absolute orientation from straight line segments, and then how to estimate the translation by aligning the 2D map with a semantic segmentation of the input image. We demonstrate the robustness and accuracy of our approach on a challenging dataset.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Clemens Arth, Christian Pirchheim, Jonathan Ventura, Vincent Lepetit,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02656", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02656", "title": "\nModeling and Improving the Energy Performance of GPS Receivers for  Mobile Applications", "abstract": "Integrated GPS receivers have become a basic module in today's mobile devices. While serving as the cornerstone for location based services, GPS modules have a serious battery drain problem due to high computation load. This paper aims to reveal the impact of key software parameters on hardware energy consumption, by establishing an energy model for a standard GPS receiver architecture as found in both academic and industrial designs. In particular, our measurements show that the receiver's energy consumption is in large part linear with the number of tracked satellites. This leads to a design of selective tracking algorithm that provides similar positioning accuracy (around 12m) with a subset of selected satellites, which translates to an energy saving of 20.9-23.1 % on the Namuru board.", "subjects": "Other Computer Science (cs.OH)", "authors": "Kongyang Chen, Guang Tan,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02654", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02654", "title": "\nAlgorithms for Replica Placement in High-Availability Storage", "abstract": "A new model of causal failure is presented, and used to solve a novel replica placement problem in data centers. The model describes dependencies among system components as a directed graph. A replica placement is defined as a subset of vertices in such a graph. A criterion for optimizing replica placements is formalized and explained. In this work, the optimization goal is to avoid choosing placements in which a single event is likely to wipe out multiple replicas. Using this criterion, a fast algorithm is given for the scenario in which the dependency model is a tree. The main contribution of the paper is an dynamic programming algorithm for placing replicas on a tree with vertices. This algorithm exhibits the interesting property that only two subproblems need to be recursively considered at each stage. An greedy algorithm is also briefly reported.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "K. Alex Mills, R. Chandrasekaran, Neeraj Mittal,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02642", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02642", "title": "\nSecurity of Power Packet Dispatching Using Differential Chaos Shift  Keying", "abstract": "This paper investigates and confirms one advantageous function of a power packet dispatching system, which has been proposed by authors' group with being apart from the conventional power distribution system. Here is focused on the function to establish the security of power packet dispatching for prohibiting not only information but also power of power packet from being stolen by attackers. For the purpose of protecting power packets, we introduce a simple encryption of power packets before sending them. Encryption scheme based on chaotic signal is one possibility for this purpose. This paper adopts the Differential Chaos Shift Keying (DCSK) scheme for the encryption, those are partial power packet encryption and whole power packet encryption.", "subjects": "Information Theory (cs.IT)", "authors": "Yanzi Zhou, Ryo Takahashi, Takashi Hikihara,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1503.02626", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02626", "title": "\nOn the Intrinsic Limits to Representationally-Adaptive Machine-Learning", "abstract": "Online learning is a familiar problem setting within Machine-Learning in which data is presented serially in time to a learning agent, requiring it to progressively adapt within the constraints of the learning algorithm. More sophisticated variants may involve concepts such as transfer-learning which increase this adaptive capability, enhancing the learner's cognitive capacities in a manner that can begin to imitate the open-ended learning capabilities of human beings. We shall argue in this paper, however, that a full realization of this notion requires that, in addition to the capacity to adapt to novel data, autonomous online learning must ultimately incorporate the capacity to update its own representational capabilities in relation to the data. We therefore enquire about the philosophical limits of this process, and argue that only fully embodied learners exhibiting an a priori perception-action link in order to ground representational adaptations are capable of exhibiting the full range of human cognitive capability.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "David Windridge,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02619", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02619", "title": "\nMODS: Fast and Robust Method for Two-View Matching", "abstract": "A novel algorithm for wide-baseline matching called MODS - Matching On Demand with view Synthesis algorithm (MODS) - is presented. The MODS algorithm is experimentally shown to solve a broader range of wide-baseline problems than the state of the art while being nearly as fast as standard matchers on simple problems. The apparent robustness vs. speed trade-off is finessed by the use of progressively more time-consuming feature detectors and by on-demand generation of synthesized images that is performed until a reliable estimate of geometry is obtained. We also introduce an improved method for tentative correspondence selection, applicable both with and without view synthesis. A modification of the standard first to second nearest distance rule increases the number of correct matches by 5-20% at no additional computational cost. Performance of the MODS algorithm is evaluated on standard publicly available datasets and on a new set of geometrically challenging wide baseline problems that is made public together with the ground truth. Experiments show that the MODS outperforms the state-of-the-art in robustness and speed. Moreover, MODS performs well on other classes of difficult two-view problems like matching of images from different modalities, with wide temporal baseline or with significant lighting changes.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Dmytro Mishkin, Jiri Matas, Michal Perdoch,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02603", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02603", "title": "\nAn asymptotically optimal policy and state-space collapse for the  multi-class shared queue", "abstract": "We consider a multi-class G/G/1 queue with a finite shared buffer. There is task admission and server scheduling control which aims to minimize the cost which consists of holding and rejection components. We construct a policy that is asymptotically optimal in the heavy traffic limit. The policy stems from solution to Harrison-Taksar (HT) free boundary problem and is expressed by a single free boundary point. We show that the HT problem solution translated into the queuelength processes follows a specific form. This form implies the queuelength control policy which is different from the known priority rule and has a novel structure. We exemplify that the probabilistic methods we exploit can be successfully applied to solving scheduling and admission problems in cloud computing.", "subjects": "Performance (cs.PF)", "authors": "Mark Shifrin,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02592", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02592", "title": "\nTwo Compact Incremental Prime Sieves", "abstract": "A prime sieve is an algorithm that finds the primes up to a bound . We say that a prime sieve is incremental, if it can quickly determine if is prime after having found all primes up to . We say a sieve is compact if it uses roughly space or less. In this paper we present two new results: (1) We describe the rolling sieve, a practical, incremental prime sieve that takes time and bits of space, and (2) We show how to modify the sieve of Atkin and Bernstein (2004) to obtain a sieve that is simultaneously sublinear, compact, and incremental. The second result solves an open problem given by Paul Pritchard in 1994.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Jonathan P. Sorenson,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02578", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02578", "title": "\nModeling State-Conditional Observation Distribution using Weighted  Stereo Samples for Factorial Speech Processing Models", "abstract": "This paper investigates the role of factorial speech processing models in noise-robust automatic speech recognition tasks. Factorial models can embed non-stationary noise models using Markov chains as one of its source chain. The paper proposes a modeling scheme for modeling state-conditional observation distribution of factorial models based on weighted stereo samples. This scheme is an extension to previous single pass retraining for ideal model compensation and here we used it to construct ideal state-conditional observation distributions. Experiments of this paper over the set A of the Aurora 2 dataset shows that by considering noise models with multiple states, system performance can be improved especially in low SNR conditions up to 4% absolute word recognition performance. In addition to its power in accurate representation of state-conditional observation distribution, it has an important advantage over previous methods by providing the opportunity to independently select feature spaces for both source and corrupted features. This opens a new window for seeking better feature spaces appropriate for noise-robust tasks independent from clean speech feature space.", "subjects": "Learning (cs.LG)", "authors": "Mahdi Khademian, Mohammad Mehdi Homayounpour,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02577", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02577", "title": "\nNew Algorithms for Computing a Single Component of the Discrete Fourier  Transform", "abstract": "This paper introduces the theory and hardware implementation of two new algorithms for computing a single component of the discrete Fourier transform. In terms of multiplicative complexity, both algorithms are more efficient, in general, than the well known Goertzel Algorithm.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "G. Jer\u00f4nimo da Silva Jr., R.M. Campello de Souza, H.M. de Oliveira,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02563", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02563", "title": "\nCo-Utility: Self-Enforcing Protocols without Coordination Mechanisms", "abstract": "Performing some task among a set of agents requires the use of some protocol that regulates the interactions between them. If those agents are rational, they may try to subvert the protocol for their own benefit, in an attempt to reach an outcome that provides greater utility. We revisit the traditional notion of self-enforcing protocols implemented using existing game-theoretic solution concepts, we describe its shortcomings in real-world applications, and we propose a new notion of self-enforcing protocols, namely co-utile protocols. The latter represent a solution concept that can be implemented without a coordination mechanism in situations when traditional self-enforcing protocols need a coordination mechanism. Co-utile protocols are preferable in decentralized systems of rational agents because of their efficiency and fairness. We illustrate the application of co-utile protocols to information technology, specifically to preserving the privacy of query profiles of database/search engine users.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Josep Domingo-Ferrer, Jordi Soria-Comas, Oana Ciobotaru,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02550", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02550", "title": "\nThe coloring problem for $\\{P_5,\\bar{P_5}\\}$-free graphs and  $\\{P_5,K_p-e\\}$-free graphs is polynomial", "abstract": "We show that determining the chromatic number of a -free graph or a -free graph can be done in polynomial time", "subjects": "Discrete Mathematics (cs.DM)", "authors": "D.S. Malyshev, O.O.Lobanova,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02521", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02521", "title": "\nA Single-Pass Classifier for Categorical Data", "abstract": "This paper describes a new method for classifying a dataset that partitions elements into different categories. It has relations with neural networks but works in a different way, requiring only a single pass through the classifier to generate the weight sets. A grid structure is required and a novel idea of converting a row of real values into a 2-D or grid-like structure of value bands. Each cell in the band can then store a cell weight value and also a set of weights that represent its own importance to each of the output categories. For any input that needs to be categorised, all of the output weight lists for each relevant input cell can be retrieved and summed to produce a probability for what the correct output category is. So the relative importance of each input point to the output is distributed to each cell. The construction process itself can simply be the reinforcement of the weight values, without requiring an iterative adjustment process, making it potentially much faster.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Kieran Greer,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02517", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02517", "title": "\nModified Dijkstra Algorithm with Invention Hierarchies Applied to a  Conic Graph", "abstract": "A modified version of the Dijkstra algorithm using an inventive contraction hierarchy is proposed. The algorithm considers a directed acyclic graph with a conical or semi-circular structure for which a pair of edges is chosen iteratively from multi-sources. The algorithm obtains minimum paths by using a comparison process. The comparison process follows a mathematical construction routine that considers a forward and backward check such that only paths with minimum lengths are selected. In addition, the algorithm automatically invents a new path by computing the absolute edge difference for the minimum edge pair and its succeeding neighbour in O (n) time. The invented path is approximated to the hidden path using a fitness criterion. The proposed algorithm extends the multi-source multi-destination problem to include those paths for which a path mining redirection from multi-sources to multi-destinations is a minimum. The algorithm has been applied to a hospital locator path finding system and the results were quite satisfactory.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Ugochi A. Okengwu, Enoch O. Nwachukwu, Emmanuel N. Osegi,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02516", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02516", "title": "\nOptimal Pricing is Hard", "abstract": "We show that computing the revenue-optimal deterministic auction in unit-demand single-buyer Bayesian settings, i.e. the optimal item-pricing, is computationally hard even in single-item settings where the buyer's value distribution is a sum of independently distributed attributes, or multi-item settings where the buyer's values for the items are independent. We also show that it is intractable to optimally price the grand bundle of multiple items for an additive bidder whose values for the items are independent. These difficulties stem from implicit definitions of a value distribution. We provide three instances of how different properties of implicit distributions can lead to intractability: the first is a #P-hardness proof, while the remaining two are reductions from the SQRT-SUM problem of Garey, Graham, and Johnson. While simple pricing schemes can oftentimes approximate the best scheme in revenue, they can have drastically different underlying structure. We argue therefore that either the specification of the input distribution must be highly restricted in format, or it is necessary for the goal to be mere approximation to the optimal scheme's revenue instead of computing properties of the scheme itself.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Constantinos Daskalakis, Alan Deckelbaum, Christos Tzamos,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02510", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02510", "title": "\nCompositional Distributional Semantics with Long Short Term Memory", "abstract": "We are proposing an extension of the recursive neural network that makes use of a variant of the long short-term memory architecture. The extension allows information low in parse trees to be stored in a memory register (the `memory cell') and used much later higher up in the parse tree. This provides a solution to the vanishing gradient problem and allows the network to capture long range dependencies. Experimental results show that our composition outperformed the traditional neural-network composition on the Stanford Sentiment Treebank.", "subjects": "Computation and Language (cs.CL)", "authors": "Phong Le, Willem Zuidema,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02504", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02504", "title": "\nThe Quicksort algorithm and related topics", "abstract": "Sorting algorithms have attracted a great deal of attention and study, as they have numerous applications to Mathematics, Computer Science and related fields. In this thesis, we first deal with the mathematical analysis of the Quicksort algorithm and its variants. Specifically, we study the time complexity of the algorithm and we provide a complete demonstration of the variance of the number of comparisons required, a known result but one whose detailed proof is not easy to read out of the literature. We also examine variants of Quicksort, where multiple pivots are chosen for the partitioning of the array. The rest of this work is dedicated to the analysis of finding the true order by further pairwise comparisons when a partial order compatible with the true order is given in advance. We discuss a number of cases where the partially ordered sets arise at random. To this end, we employ results from Graph and Information Theory. Finally, we obtain an alternative bound on the number of linear extensions when the partially ordered set arises from a random graph, and discuss the possible application of Shellsort in merging chains.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Vasileios Iliopoulos,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02479", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02479", "title": "\nCournot Games with Uncertainty: Coalitions, Competition, and Efficiency", "abstract": "We investigate the impact of group formations on the efficiency of Cournot games where producers face uncertainties. In particular, we study a market model where producers must determine their output before an uncertainty production capacity is realized. In contrast to standard Cournot models, we show that the game is not efficient when there are many small producers. Instead, producers tend to act conservatively to hedge against their risks. We show that in the presence of uncertainty, the game becomes efficient when producers are allowed to take advantage of diversity to form groups of certain sizes. We characterize the trade-off between market power and uncertainty reduction as a function of group size. Namely, we show that when there are N producers present, competition between groups of size square root of N results in equilibria that are socially optimal.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Baosen Zhang, Ramesh Johari, Ram Rajagopal,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02466", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02466", "title": "\nBrain Tumor Segmentation: A Comparative Analysis", "abstract": "Five different threshold segmentation based approaches have been reviewed and compared over here to extract the tumor from set of brain images. This research focuses on the analysis of image segmentation methods, a comparison of five semi-automated methods have been undertaken for evaluating their relative performance in the segmentation of tumor. Consequently, results are compared on the basis of quantitative and qualitative analysis of respective methods. The purpose of this study was to analytically identify the methods, most suitable for application for a particular genre of problems. The results show that of the region growing segmentation performed better than rest in most cases.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Muhammad Ali Qadar, Yan Zhaowen,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02464", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02464", "title": "\nOptimising PICCANTE -- an open source particle-in-cell code for advanced  simulations on Tier-0 systems", "abstract": "We discuss a detailed strong and weak scaling analysis of PICCANTE, an open source, massively parallel, fully-relativistic Particle-In-Cell (PIC) code. PIC codes are widely used in plasma physics and astrophysics to study the cases where kinetic effects are relevant. PICCANTE is primarily developed to study laser-plasma interaction. Within a PRACE Preparatory Access Project, various revisions of different routines of the code have been analysed on the HPC systems JUQUEEN at J \"ulich Supercomputing Centre (JSC), Germany, and FERMI at CINECA, Italy, to improve the parallel scalability and the I/O performance of the application. The diagnostic tool Scalasca is used to filter out suboptimal routines. Different output strategies are discussed. The detailed strong and weak scaling behaviour of the improved code is presented in comparison with the original version of the code.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Andrea Sgattoni, Luca Fedeli, Stefano Sinigardi, Alberto Marocchino, Andrea Macchi, Volker Weinberg, Anupam Karmakar,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02447", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02447", "title": "\nPresenting Distributive Laws", "abstract": "Distributive laws of a monad T over a functor F are categorical tools for specifying algebra-coalgebra interaction. They proved to be important for solving systems of corecursive equations, for the specification of well-behaved structural operational semantics and, more recently, also for enhancements of the bisimulation proof method. If T is a free monad, then such distributive laws correspond to simple natural transformations. However, when T is not free it can be rather difficult to prove the defining axioms of a distributive law. In this paper we describe how to obtain a distributive law for a monad with an equational presentation from a distributive law for the underlying free monad. We apply this result to show the equivalence between two different representations of context-free languages.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Marcello M. Bonsangue, Helle H. Hansen, Alexander Kurz, Jurriaan Rot,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02445", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02445", "title": "\nRepresentation Learning with Deep Extreme Learning Machines for  Efficient Image Set Classification", "abstract": "Efficient and accurate joint representation of a collection of images, that belong to the same class, is a major research challenge for practical image set classification. Existing methods either make prior assumptions about the data structure, or perform heavy computations to learn structure from the data itself. We propose a Deep Extreme Learning Machine (DELM) for efficient learning of the nonlinear structure of image sets without making any assumption about the underlying data. The DELM generalizes very well based on a limited number of training samples. We learn a domain specific DELM model in an unsupervised fashion and then adapt it to learn class specific representations. Extensive experiments on a broad range of public datasets for image set classification (Honda/UCSD, CMU Mobo, YouTube Celebrities, Celebrity-1000, ETH-80) show that the proposed DELM consistently outperforms state-ofthe- art image set classification methods both in terms of speed and accuracy.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Muhammad Uzair, Faisal Shafait, Bernard Ghanem, Ajmal Mian,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02442", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02442", "title": "\nSpecification of Complex Structures in Distributed Service Function  Chaining Using a YANG Data Model", "abstract": "While services benefit from distributed cloud centers running in isolation, allowing multiple centers to cooperate on implementing services unlocks the full power of distributed cloud computing. Distributed cloud services are typically set up by chaining together a number of functions that are specified with an implicit order. They can incorporate complex structures, e.g., include functions that classify and forward flows over distinct branches and functions that are traversed by certain types of flows but skipped by others. These requirements need specification techniques more powerful than existing graph-based ones. We present a context-free grammar for abstract description of service function chaining structures and a concrete syntax based on the YANG data modeling language that can easily be translated into an explicit configuration of service functions. Finally, we present examples of using our models for complex services within common use cases of service function chaining.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Sevil Mehraghdam, Holger Karl,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02434", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02434", "title": "\nDistributed execution of bigraphical reactive systems", "abstract": "The bigraph embedding problem is crucial for many results and tools about bigraphs and bigraphical reactive systems (BRS). Current algorithms for computing bigraphical embeddings are centralized, i.e. designed to run locally with a complete view of the guest and host bigraphs. In order to deal with large bigraphs, and to parallelize reactions, we present a decentralized algorithm, which distributes both state and computation over several concurrent processes. This allows for distributed, parallel simulations where non-interfering reactions can be carried out concurrently; nevertheless, even in the worst case the complexity of this distributed algorithm is no worse than that of a centralized algorithm.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Alessio Mansutti, Marino Miculan, Marco Peressotti,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02427", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02427", "title": "\nSyntax-based Deep Matching of Short Texts", "abstract": "Many tasks in natural language processing, ranging from machine translation to question answering, can be reduced to the problem of matching two sentences or more generally two short texts. We propose a new approach to the problem, called Deep Match Tree (DeepMatch), under a general setting. The approach consists of two components, 1) a mining algorithm to discover patterns for matching two short-texts, defined in the product space of dependency trees, and 2) a deep neural network for matching short texts using the mined patterns, as well as a learning algorithm to build the network having a sparse structure. We test our algorithm on the problem of matching a tweet and a response in social media, a hard matching problem proposed in [Wang et al., 2013], and show that DeepMatch can outperform a number of competitor models including one without using dependency trees and one based on word-embedding, all with large margins", "subjects": "Computation and Language (cs.CL)", "authors": "Mingxuan Wang, Zhengdong Lu, Hang Li, Qun Liu,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02422", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02422", "title": "\nTimed pushdown automata revisited", "abstract": "This paper contains two results on timed extensions of pushdown automata (PDA). As our first result we prove that the model of dense-timed PDA of Abdulla et al. collapses: it is expressively equivalent to dense-timed PDA with timeless stack. Motivated by this result, we advocate the framework of first-order definable PDA, a specialization of PDA in sets with atoms, as the right setting to define and investigate timed extensions of PDA. The general model obtained in this way is Turing complete. As our second result we prove NEXPTIME upper complexity bound for the non-emptiness problem for an expressive subclass. As a byproduct, we obtain a tight EXPTIME complexity bound for a more restrictive subclass of PDA with timeless stack, thus subsuming the complexity bound known for dense-timed PDA.", "subjects": "Formal Languages and Automata Theory (cs.FL)", "authors": "Lorenzo Clemente, S\u0142awomir Lasota,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02417", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02417", "title": "\nStructured Prediction of Sequences and Trees using Infinite Contexts", "abstract": "Linguistic structures exhibit a rich array of global phenomena, however commonly used Markov models are unable to adequately describe these phenomena due to their strong locality assumptions. We propose a novel hierarchical model for structured prediction over sequences and trees which exploits global context by conditioning each generation decision on an unbounded context of prior decisions. This builds on the success of Markov models but without imposing a fixed bound in order to better represent global phenomena. To facilitate learning of this large and unbounded model, we use a hierarchical Pitman-Yor process prior which provides a recursive form of smoothing. We propose prediction algorithms based on A* and Markov Chain Monte Carlo sampling. Empirical results demonstrate the potential of our model compared to baseline finite-context Markov models on part-of-speech tagging and syntactic parsing.", "subjects": "Learning (cs.LG)", "authors": "Ehsan Shareghi, Gholamreza Haffari, Trevor Cohn, Ann Nicholson,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02416", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02416", "title": "\nApproximating LZ77 in Small Space", "abstract": "Given a positive ( epsilon leq 1 ) and read-only access to a string (S [1..n] ) whose LZ77 parse consists of phrases, with high probability we can build an LZ77-like parse of that consists of phrases using time, I/Os (where is the size of a disk block) and space.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Travis Gagie,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02413", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02413", "title": "\nStochastic Service Placement", "abstract": "Resource allocation for cloud services is a complex task due to the diversity of the services and the dynamic workloads. One way to address this is by overprovisioning which results in high cost due to the unutilized resources. A much more economical approach, relying on the stochastic nature of the demand, is to allocate just the right amount of resources and use additional more expensive mechanisms in case of overflow situations where demand exceeds the capacity. In this paper we study this approach and show both by comprehensive analysis for independent normal distributed demands and simulation on synthetic data that it is significantly better than currently deployed methods.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Galia Shabtai, Danny Raz, Yuval Shavitt,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02408", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02408", "title": "\nPredictors for the Adoption of Virtual Learning Environments - a Case  Study from Bhutan", "abstract": "This study investigates the significance of Rogers Diffusion of Innovations (DOI) theory with regard to the use of a Virtual Learning Environment (VLE) at the Royal University of Bhutan (RUB). The focus is on different adoption types and characteristics of users. Rogers DOI theory is applied to investigate the influence of five predictors (relative advantage, complexity, compatibility, trialability and observability) and their significance in the perception of academic staff at the RUB in relation to the probability of VLE adoption. These predictors are attributes of the VLE that determine the rate of adoption by various adopter group memberships (Innovators, Early Adopters, Early Majority, Late Majority, Laggards). Descriptive statistics and regression analysis were deployed to analyse adopter group memberships and predictor significance in VLE adoption and use. The results reveal varying attitudes towards VLE adoption by academic staff at RUB. Few predictors are consistent with previous research on VLE adoption. There are also significant differences from previous research on predictors such as the deviation in adopter frequency from that predicted by Rogers DOI theory. Therefore, it can be concluded that it is misleading to rely on the DOI theory in the way it is currently operationalised for predicting VLE use.", "subjects": "Computers and Society (cs.CY)", "authors": "Sonam Penjor, Par-Ola Zander,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02406", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02406", "title": "\nDeep Learning and the Information Bottleneck Principle", "abstract": "Deep Neural Networks (DNNs) are analyzed via the theoretical framework of the information bottleneck (IB) principle. We first show that any DNN can be quantified by the mutual information between the layers and the input and output variables. Using this representation we can calculate the optimal information theoretic limits of the DNN and obtain finite sample generalization bounds. The advantage of getting closer to the theoretical limit is quantifiable both by the generalization bound and by the network's simplicity. We argue that both the optimal architecture, number of layers and features/connections at each layer, are related to the bifurcation points of the information bottleneck tradeoff, namely, relevant compression of the input layer with respect to the output layer. The hierarchical representations at the layered network naturally correspond to the structural phase transitions along the information curve. We believe that this new insight can lead to new optimality bounds and deep learning algorithms.", "subjects": "Learning (cs.LG)", "authors": "Naftali Tishby, Noga Zaslavsky,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02401", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02401", "title": "\n#FailedRevolutions: Using Twitter to Study the Antecedents of ISIS  Support", "abstract": "Within a fairly short amount of time, the Islamic State of Iraq and Syria (ISIS) has managed to put large swaths of land in Syria and Iraq under their control. To many observers, the sheer speed at which this \"state\" was established was dumbfounding. To better understand the roots of this organization and its supporters we present a study using data from Twitter. We start by collecting large amounts of Arabic tweets referring to ISIS and classify them into pro-ISIS and anti-ISIS. This classification turns out to be easily done simply using the name variants used to refer to the organization: the full name and the description as \"state\" is associated with support, whereas abbreviations usually indicate opposition. We then \"go back in time\" by analyzing the historic timelines of both users supporting and opposing and look at their pre-ISIS period to gain insights into the antecedents of support. To achieve this, we build a classifier using pre-ISIS data to \"predict\", in retrospect, who will support or oppose the group. The key story that emerges is one of frustration with failed Arab Spring revolutions. ISIS supporters largely differ from ISIS opposition in that they refer a lot more to Arab Spring uprisings that failed. We also find temporal patterns in the support and opposition which seems to be linked to major news, such as reported territorial gains, reports on gruesome acts of violence, and reports on airstrikes and foreign intervention.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Walid Magdy, Kareem Darwish, Ingmar Weber,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02398", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02398", "title": "\nLearning Co-Sparse Analysis Operators with Separable Structures", "abstract": "In the co-sparse analysis model a set of filters is applied to a signal out of the signal class of interest yielding sparse signal responses. As such, it may serve as a prior in inverse problems, or for structural analysis of signals that are known to belong to the signal class. The more the model is adapted to the class, the more reliable it is for these purposes. The task of learning such operators for a given class is therefore a crucial problem. In many applications, it is also required that the filter responses are obtained in a timely manner, which can be achieved by filters with a separable structure. Not only can operators of this sort be efficiently used for computing the filter responses, but they also have the advantage that less training samples are required to obtain a reliable estimate of the operator. The first contribution of this work is to give theoretical evidence for this claim by providing an upper bound for the sample complexity of the learning process. The second is a stochastic gradient descent (SGD) method designed to efficiently learn an analysis operators with separable structures, which incorporates an efficient step size selection. Numerical experiments are provided that link the sample complexity to the convergence speed of the SGD algorithm.", "subjects": "Learning (cs.LG)", "authors": "Matthias Seibert, Julian W\u00f6rmann, R\u00e9mi Gribonval, Martin Kleinsteuber,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02391", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02391", "title": "\nDeep Human Parsing with Active Template Regression", "abstract": "In this work, the human parsing task, namely decomposing a human image into semantic fashion/body regions, is formulated as an Active Template Regression (ATR) problem, where the normalized mask of each fashion/body item is expressed as the linear combination of the learned mask templates, and then morphed to a more precise mask with the active shape parameters, including position, scale and visibility of each semantic region. The mask template coefficients and the active shape parameters together can generate the human parsing results, and are thus called the structure outputs for human parsing. The deep Convolutional Neural Network (CNN) is utilized to build the end-to-end relation between the input human image and the structure outputs for human parsing. More specifically, the structure outputs are predicted by two separate networks. The first CNN network is with max-pooling, and designed to predict the template coefficients for each label mask, while the second CNN network is without max-pooling to preserve sensitivity to label mask position and accurately predict the active shape parameters. For a new image, the structure outputs of the two networks are fused to generate the probability of each label for each pixel, and super-pixel smoothing is finally used to refine the human parsing result. Comprehensive evaluations on a large dataset well demonstrate the significant superiority of the ATR framework over other state-of-the-arts for human parsing. In particular, the F1-score reaches by our ATR framework, significantly higher than based on the state-of-the-art algorithm.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Xiaodan Liang, Si Liu, Xiaohui Shen, Jianchao Yang, Luoqi Liu, Jian Dong, Liang Lin, Shuicheng Yan,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02389", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02389", "title": "\nExact Random Coding Error Exponents for the Two-User Interference  Channel", "abstract": "This paper is about exact error exponents for the two-user interference channel under the random coding regime. Specifically, we first analyze the standard random coding ensemble, where the codebooks are comprised of independently and identically distributed (i.i.d.) codewords. For this ensemble, we focus on optimum decoding, which is in contrast to other, heuristic decoding rules that have been used in the literature (e.g., joint typicality decoding, treating interference as noise, etc.). The fact that the interfering signal is a codeword, and not an i.i.d. noise process, complicates the application of conventional techniques of performance analysis of the optimum decoder. Also, unfortunately, these conventional techniques result in loose bounds. Using analytical tools rooted in statistical physics, as well as advanced union bounds, we derive exact single-letter formulas for the random coding error exponents. We compare our results with the best known lower bound on the error exponent, and show that our exponents can be strictly better. It turns out that the methods employed in this paper, can also be used to analyze more complicated coding ensembles. Accordingly, as an example, using the same techniques, we find exact formulas for the error exponent associated with the Han-Kobayashi (HK) random coding ensemble, which is based on superposition coding.", "subjects": "Information Theory (cs.IT)", "authors": "Wasim Huleihel, Neri Merhav,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02388", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02388", "title": "\nTowards \"Reproducibility-as-a-Service\"", "abstract": "The reproduction and replication of novel results has become a major issue for a number of scientific disciplines. In computer science and related computational disciplines such as systems biology, the issues closely revolve around the ability to implement novel algorithms and models. Taking an approach from the literature and applying it to a new codebase frequently requires local knowledge missing from the published manuscripts and project websites. Alongside this issue, benchmarking, and the development of fair -- and publicly available -- benchmark sets present another barrier. In this paper, we outline several suggestions to address these issues, driven by specific examples from a range of scientific domains. Finally, based on these suggestions, we propose a new open automated platform for scientific software development which effectively abstracts specific dependencies from the individual researcher and their workstation, allowing easy sharing and reproduction of results. This new cyberinfrastructure for computational science offers the potential to incentivise a culture change and drive the adoption of new techniques to improve the efficiency of scientific exploration.", "subjects": "Software Engineering (cs.SE)", "authors": "Tom Crick, Samin Ishtiaq, Benjamin A. Hall,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02386", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02386", "title": "\nRiemann-Roch Spaces and Linear Network Codes", "abstract": "We construct linear network codes utilizing algebraic curves over finite fields and certain associated Riemann-Roch spaces and present methods to obtain their parameters. In particular we treat the Hermitian curve and the curves associated with the Suzuki and Ree groups all having the maximal number of points for curves of their respective genera. Linear network coding transmits information in terms of a basis of a vector space and the information is received as a basis of a possibly altered vector space. Ralf Koetter and Frank R. Kschischang % cite introduced a metric on the set of vector spaces and showed that a minimal distance decoder for this metric achieves correct decoding if the dimension of the intersection of the transmitted and received vector space is sufficiently large. The vector spaces in our construction have minimal distance bounded from below in the above metric making them suitable for linear network coding.", "subjects": "Information Theory (cs.IT)", "authors": "Johan P. Hansen,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02379", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02379", "title": "\nDigital Cancelation of Self-Interference for Signle-Frequency  Full-Duplex Relay Stations via Sampled-Data Control", "abstract": "In this article, we propose sampled-data design of digital filters that cancel the continuous-time effect of coupling waves in a single-frequency full-duplex relay station. In this study, we model a relay station as a continuoustime system while conventional researches treat it as a discrete-time system. For a continuous-time model, we propose digital feedback canceler based on the sampled-data H-infinity control theory to cancel coupling waves taking intersample behavior into account. We also propose robust control against unknown multipath interference. Simulation results are shown to illustrate the effectiveness of the proposed method.", "subjects": "Systems and Control (cs.SY)", "authors": "Hampei Sasahara, Masaaki Nagahara, Kazunori Hayashi, Yutaka Yamamoto,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02377", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02377", "title": "\nOf Two Minds, Multiple Addresses, and One History: Characterizing  Opinions, Knowledge, and Perceptions of Bitcoin Across Groups", "abstract": "Digital currencies represent a new method for exchange and investment that differs strongly from any other fiat money seen throughout history. A digital currency makes it possible to perform all financial transactions without the intervention of a third party to act as an arbiter of verification; payments can be made between two people with degrees of anonymity, across continents, at any denomination, and without any transaction fees going to a central authority. The most successful example of this is Bitcoin, introduced in 2008, which has experienced a recent boom of popularity, media attention, and investment. With this surge of attention, we became interested in finding out how people both inside and outside the Bitcoin community perceive Bitcoin -- what do they think of it, how do they feel, and how knowledgeable they are. Towards this end, we conducted the first interview study (N = 20) with participants to discuss Bitcoin and other related financial topics. Some of our major findings include: not understanding how Bitcoin works is not a barrier for entry, although non-user participants claim it would be for them and that user participants are in a state of cognitive dissonance concerning the role of governments in the system. Our findings, overall, contribute to knowledge concerning Bitcoin and attitudes towards digital currencies in general.", "subjects": "Computers and Society (cs.CY)", "authors": "Xianyi Gao, Gradeigh D. Clark, Janne Lindqvist,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02373", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02373", "title": "\nNetwork Maps of Technology Fields: How Measures of Relatedness Influence  Network Structures", "abstract": "The structure of the total technology space, together with the specialized knowledge positions of the inventors, companies and countries, conditions the prospect of their next innovations. Prior studies have proposed representing the technology space as a network of patent technology classes connected by links weighted according to their relatedness. Although the choice of relatedness measures affects the structure of the resulting networks, such measures have not been assessed in terms of their influences on network structures. In this paper, we first present six measures based on the similarity of knowledge bases of different technology fields and, alternatively, on the likelihood for inventors, organizations or countries to diversify across technology fields. Then, we compare the resulting networks in terms of network structures, vertex and edge properties and their predictability on the importance of the represented technology fields. Based on USPTO patent data from 1976 to 2010 and International Patent Classification, our results suggest that the technology space is almost fully but heterogeneously connected, with extremely weak relatedness between most pairs of technology classes, that is consistent in different types of networks. Our results also suggest that networks using co-reference and inventor diversification likelihood to relate technology fields are strongly correlated with each other, are relatively more correlated with other types of networks, and provide the strongest correlations between network centrality measures of the vertices and the importance of the represented technology fields. These two types of technology networks may be most useful for general network analysis on how the structure of the technology space conditions the search for inventions of different agents.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Bowen Yan, Jianxi Luo,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02368", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02368", "title": "\nEmptyHeaded: Boolean Algebra Based Graph Processing", "abstract": "We present a graph pattern engine, EmptyHeaded, that uses recent algorithmic advances in join processing to compile patterns into Boolean algebra operations that exploit SIMD parallelism. The EmptyHeaded engine demonstrates that treating graph patterns as a general join processing problem can compete with and often outperform both specialized approaches and existing OLAP systems on graph queries. The core Boolean algebra operation performed in EmptyHeaded is set intersection. Extracting SIMD parallelism during set intersections on graph data is challenging because graph data can be skewed in several different ways. Our contributions are a demonstration of this new type of engine with Boolean algebra at its core, an exploration of set intersection representations and algorithms for set intersections that are optimized for skew. We demonstrate that EmptyHeaded outperforms specialized graph engines by over an order of magnitude and relational systems by over two orders of magnitude. Our results suggest that this new style of engine is a promising new direction for future graph engines and accelerators.", "subjects": "Databases (cs.DB)", "authors": "Christopher R. Aberger, Andres N\u00f6tzli, Kunle Olukotun, Christopher R\u00e9,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02367", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02367", "title": "\nDesign of a visible-light-communication enhanced WiFi system", "abstract": "Visible light communication (VLC) has wide unlicensed bandwidth, enables communication in radio frequency (RF) sensitive environments, realizes energy-efficient data transmission, and has the potential to boost the capacity of wireless access networks through spatial reuse. On the other hand, WiFi provides more coverage than VLC and does not suffer from the likelihood of blockage due to the light of sight (LOS) requirement of VLC. In order to take the advantages of both WiFi and VLC, we propose and implement two heterogeneous systems with Internet access. One is the hybrid WiFi-VLC system, utilizing unidirectional VLC channel as downlink and reserving the WiFi back-channel as uplink. The asymmetric solution resolves the optical uplink challenges and benefits from the full-duplex communication based on VLC. To further enhance the robustness and increase throughput, the other system is presented, in which we aggregate WiFi and VLC in parallel by leveraging the bonding technique in Linux operating system. Online experiment results reveal that the hybrid system outperforms the conventional WiFi for the crowded environments in terms of throughput and web page loading time; and also demonstrate the further improved performance of the aggregated system when considering the blocking duration and the distance between access point and user device.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Sihua Shao, Abdallah Khreishah, Moussa Ayyash, Michael B. Rahaim, Hany Elgala, Volker Jungnickel, Dominic Schulz, Thomas D.C. Little,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02364", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02364", "title": "\nNeural Responding Machine for Short-Text Conversation", "abstract": "We propose Neural Responding Machine (NRM), a neural network-based response generator for Short-Text Conversation. NRM takes the general encoder-decoder framework: it formalizes the generation of response as a decoding process based on the latent representation of the input text, while both encoding and decoding are realized with recurrent neural networks (RNN). The NRM is trained with a large amount of one-round conversation data collected from a microblogging service. Empirical study shows that NRM can generate grammatically correct and content-wise appropriate responses to over 75% of the input text, outperforming state-of-the-arts in the same setting, including retrieval-based and SMT-based models.", "subjects": "Computation and Language (cs.CL)", "authors": "Lifeng Shang, Zhengdong Lu, Hang Li,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02357", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02357", "title": "\nContext-Dependent Translation Selection Using Convolutional Neural  Network", "abstract": "We propose a novel method for translation selection in statistical machine translation, in which a convolutional neural network is employed to judge the similarity between a phrase pair in two languages. The specifically designed convolutional architecture encodes not only the semantic similarity of the translation pair, but also the context containing the phrase in the source language. Therefore, our approach is able to capture context-dependent semantic similarities of translation pairs. We adopt a curriculum learning strategy to train the model: we classify the training examples into easy, medium, and difficult categories, and gradually build the ability of representing phrase and sentence level context by using training examples from easy to difficult. Experimental results show that our approach significantly outperforms the baseline system by up to 1.4 BLEU points.", "subjects": "Computation and Language (cs.CL)", "authors": "Zhaopeng Tu, Baotian Hu, Zhengdong Lu, Hang Li,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02354", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02354", "title": "\nA General Scheme for Noise-Tolerant Logic Design Based on Probabilistic  and DCVS Approaches", "abstract": "In this paper, a general circuit scheme for noise-tolerant logic design based on Markov Random Field theory and differential Cascade Voltage Switch technique has been proposed, which is an extension of the work in [1-3], [4]. A block with only four transistors has been successfully inserted to the original circuit scheme from [3] and extensive simulation results show that our proposed design can operate correctly with the input signal of 1 dB signal-noise-ratio. When using the evaluation parameter from [5], the output value of our design decreases by 76.5% on average than [3] which means that superior noise-immunity could be obtained through our work.", "subjects": "Hardware Architecture (cs.AR)", "authors": "Xinghua Yang, Fei Qiao, Qi Wei, Huazhong Yang,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02353", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02353", "title": "\nAlmost Optimal Distributed Algorithms for Large-Scale Graph Problems", "abstract": "We present (almost) optimal distributed algorithms for fundamental graph problems in the -machine (a.k.a. Big Data) model of distributed computation introduced in [Klauck et al., SODA 2015]. Our main result is an optimal algorithm for graph connectivity which solves an important open problem posed in that paper. Our algorithm runs in rounds ( notation hides a factor and an additive term), where is the number of nodes of the input graph and is the number of available machines. This improves over the previous best bound of , and is optimal (up to a polylogarithmic factor) in view of the existing lower bound of . Our improved algorithm uses a bunch of different techniques that prove useful in the design of efficient distributed graph algorithms. These are emph (to load-balance communication among machines), emph (to produce low-diameter trees), and emph (to sample inter-component edges fast). In particular, to the best of our knowledge, we make the first application of the linear graph sketching technique in distributed computing. We then present fast algorithms for computing minimum spanning trees, (approximate) min-cuts, and for many graph verification problems; these rely on the above techniques and on the fast connectivity algorithm. All these algorithms take rounds and are (almost) optimal.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Gopal Pandurangan, Peter Robinson, Michele Scquizzato,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02351", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02351", "title": "\nFully Connected Deep Structured Networks", "abstract": "Convolutional neural networks with many layers have recently been shown to achieve excellent results on many high-level tasks such as image classification, object detection and more recently also semantic segmentation. Particularly for semantic segmentation, a two-stage procedure is often employed. Hereby, convolutional networks are trained to provide good local pixel-wise features for the second step being traditionally a more global graphical model. In this work we unify this two-stage process into a single joint training algorithm. We demonstrate our method on the semantic image segmentation task and show encouraging results on the challenging PASCAL VOC 2012 dataset.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Alexander G. Schwing, Raquel Urtasun,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02348", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02348", "title": "\nBuffer Aided Relaying Improves Both Throughput and End-to-End Delay", "abstract": "Buffer aided relaying has recently attracted a lot of attention due to the improvement in the system throughput. However, a side effect usually deemed is that buffering at relay nodes results in the increase in packet delays. In this paper, we study the effect of buffering relays on the end-to-end delay of users' data, from the time they arrive at source until delivery to the destination. We use simple discussions to provide an insight on the overall waiting time of the packets in the system. By studying the Bernoulli distributed channel conditions, and using intuitive generalizations, we conclude that the use of buffers at relays improves not only throughput, but ironically the end-to-end delay as well. Computer simulations in the settings of practical systems confirm the above results.", "subjects": "Information Theory (cs.IT)", "authors": "Javad Hajipour, Amr Mohamed, Victor C. M. Leung,", "date": "2015-3-9"}, 
{"urllink": "http://arxiv.org/abs/1503.02337", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02337", "title": "\nBotnet Detection using Social Graph Analysis", "abstract": "Signature-based botnet detection methods identify botnets by recognizing Command and Control (C &amp;C) traffic and can be ineffective for botnets that use new and sophisticate mechanisms for such communications. To address these limitations, we propose a novel botnet detection method that analyzes the social relationships among nodes. The method consists of two stages: (i) anomaly detection in an \"interaction\" graph among nodes using large deviations results on the degree distribution, and (ii) community detection in a social \"correlation\" graph whose edges connect nodes with highly correlated communications. The latter stage uses a refined modularity measure and formulates the problem as a non-convex optimization problem for which appropriate relaxation strategies are developed. We apply our method to real-world botnet traffic and compare its performance with other community detection methods. The results show that our approach works effectively and the refined modularity measure improves the detection accuracy.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Jing Wang, Ioannis Ch. Paschalidis,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.02335", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02335", "title": "\nAn Unsupervised Method for Uncovering Morphological Chains", "abstract": "Most state-of-the-art systems today produce morphological analysis based only on orthographic patterns. In contrast, we propose a model for unsupervised morphological analysis that integrates orthographic and semantic views of words. We model word formation in terms of morphological chains, from base words to the observed words, breaking the chains into parent-child relations. We use log-linear models with morpheme and word-level features to predict possible parents, including their modifications, for each word. The limited set of candidate parents for each word render contrastive estimation feasible. Our model consistently matches or outperforms five state-of-the-art systems on Arabic, English and Turkish.", "subjects": "Computation and Language (cs.CL)", "authors": "Karthik Narasimhan, Regina Barzilay, Tommi Jaakkola,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.02332", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02332", "title": "\nRobust Anomaly Detection in Dynamic Networks", "abstract": "We propose two robust methods for anomaly detection in dynamic networks in which the properties of normal traffic are time-varying. We formulate the robust anomaly detection problem as a binary composite hypothesis testing problem and propose two methods: a model-free and a model-based one, leveraging techniques from the theory of large deviations. Both methods require a family of Probability Laws (PLs) that represent normal properties of traffic. We devise a two-step procedure to estimate this family of PLs. We compare the performance of our robust methods and their vanilla counterparts, which assume that normal traffic is stationary, on a network with a diurnal normal pattern and a common anomaly related to data exfiltration. Simulation results show that our robust methods perform better than their vanilla counterparts in dynamic networks.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Jing Wang, Ioannis Ch. Paschalidis,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.02330", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02330", "title": "\nFitting 3D Morphable Models using Local Features", "abstract": "In this paper, we propose a novel fitting method that uses local image features to fit a 3D Morphable Model to 2D images. To overcome the obstacle of optimising a cost function that contains a non-differentiable feature extraction operator, we use a learning-based cascaded regression method that learns the gradient direction from data. The method allows to simultaneously solve for shape and pose parameters. Our method is thoroughly evaluated on Morphable Model generated data and first results on real data are presented. Compared to traditional fitting methods, which use simple raw features like pixel colour or edge maps, local features have been shown to be much more robust against variations in imaging conditions. Our approach is unique in that we are the first to use local features to fit a Morphable Model. Because of the speed of our method, it is applicable for realtime applications. Our cascaded regression framework is available as an open source library (this https URL).", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Patrik Huber, Zhen-Hua Feng, William Christmas, Josef Kittler, Matthias R\u00e4tsch,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.02328", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02328", "title": "\nFinancial Market Prediction", "abstract": "Given financial data from popular sites like Yahoo and the London Exchange, the presented paper attempts to model and predict stocks that can be considered \"good investments\". Stocks are characterized by 125 features ranging from gross domestic product to EDIBTA, and are labeled by discrepancies between stock and market price returns. An artificial neural network (Self-Organizing Map) is fitted to train on more than a million data points to predict \"good investments\" given testing stocks from 2013 and after.", "subjects": "Computational Engineering, Finance, and Science (cs.CE)", "authors": "Mike Wu,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.02319", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02319", "title": "\nUniform Interpolation for Coalgebraic Fixpoint Logic", "abstract": "We use the connection between automata and logic to prove that a wide class of coalgebraic fixpoint logics enjoys uniform interpolation. To this aim, first we generalize one of the central results in coalgebraic automata theory, namely closure under projection, which is known to hold for weak-pullback preserving functors, to a more general class of functors, i.e.; functors with quasi-functorial lax extensions. Then we will show that closure under projection implies definability of the bisimulation quantifier in the language of coalgebraic fixpoint logic, and finally we prove the uniform interpolation theorem.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Johannes Marti, Fatemeh Seifan, Yde Venema,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.02318", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02318", "title": "\nUnderstanding Image Virality", "abstract": "Virality of online content on social networking websites is an important but esoteric phenomenon often studied in fields like marketing, psychology and data mining. In this paper we study viral images from a computer vision perspective. We introduce three new image datasets from Reddit and define a virality score using Reddit metadata. We train classifiers with state-of-the-art image features to predict virality of individual images, relative virality in pairs of images, and the dominant topic of a viral image. We also compare machine performance to human performance on these tasks. We find that computers perform poorly with low level features, and high level information is critical for predicting virality. We encode semantic information through relative attributes. We identify the 5 key visual attributes that correlate with virality. We create an attribute-based characterization of images that can predict relative virality with 70.23% accuracy (SVM+Deep Relative Attributes). Finally, we study how human prediction of image virality varies with different 'contexts' in which the images are viewed, such as the influence of neighbouring images, images recently viewed, as well as the image title or caption. This work is a first step in understanding the complex but important phenomenon of relative image virality. Our datasets and annotations will be made publicly available.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Arturo Deza, Devi Parikh,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.02314", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02314", "title": "\nTowards Making Random Passwords Memorable: Leveraging Users' Cognitive  Ability Through Multiple Cues", "abstract": "Given the choice, users produce passwords reflecting common strategies and patterns that ease recall but offer uncertain and often weak security. System-assigned passwords provide measurable security but suffer from poor memorability. To address this usability-security tension, we argue that systems should assign random passwords but also help with memorization and recall. We investigate the feasibility of this approach with CuedR, a novel cued-recognition authentication scheme that provides users with multiple cues (visual, verbal, and spatial) and lets them choose the cues that best fit their learning process for later recognition of system-assigned keywords. In our lab study, all 37 of our participants could log in within three attempts one week after registration (mean login time: 38.0 seconds). A pilot study on using multiple CuedR passwords also showed 100% recall within three attempts. Based on our results, we suggest appropriate applications for CuedR, such as financial and e-commerce accounts.", "subjects": "Human-Computer Interaction (cs.HC)", "authors": "Mahdi Nasrullah Al-Ameen, Matthew Wright, Shannon Scielzo,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.02313", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02313", "title": "\nAchieving Secrecy Capacity of the Gaussian Wiretap Channel with Polar  Lattices", "abstract": "In this work, an explicit wiretap coding scheme based on polar lattices is proposed to achieve the secrecy capacity of the additive white Gaussian noise (AWGN) wiretap channel. Firstly, polar lattices are used to construct secrecy-good lattices for the mod- Gaussian wiretap channel. Then we propose an explicit shaping scheme to remove this mod- front end and extend polar lattices to the genuine Gaussian wiretap channel. The shaping technique is based on the lattice Gaussian distribution, which leads to a binary asymmetric channel at each level for the multilevel lattice codes. By employing the asymmetric polar coding technique, we construct an AWGN-good lattice and a secrecy-good lattice with optimal shaping simultaneously. As a result, the encoding complexity for the sender and the decoding complexity for the legitimate receiver are both O(N logN log(logN)). The proposed scheme is proven to be semantically secure.", "subjects": "Information Theory (cs.IT)", "authors": "Ling Liu, Yanfei Yan, Cong Ling,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.02304", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02304", "title": "\nEfficient Hardware Design and Implementation of Encrypted MIPS Processor", "abstract": "The paper describes the design and hardware implementation of 32-bit encrypted MIPS processor based on MIPS pipeline architecture. The organization of pipeline stages in such a way that pipeline can be clocked at high frequency. Encryption and Decryption blocks of data encryption standard (DES) cryptosystem and dependency among themselves are explained in detail with the help of block diagram. In order to increase the processor functionality and performance, especially for security applications we include three new instructions 32-bit LKLW, LKUW and CRYPT. The design has been synthesized at 40nm process technology targeting using Xilinx Virtex-6 device. The encrypted MIPS pipeline processor can work at 218MHz at synthesis level and 744MHz at simulation level.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Kirat Pal Singh, Dilip Kumar,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.02300", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02300", "title": "\nModel Predictive Control under Timing Constraints induced by Controller  Area Networks", "abstract": "When multiple model predictive controllers are implemented on a shared control area network (CAN), their performance may degrade due to the inhomogeneous timing and delays among messages. The priority based real-time scheduling of messages on the CAN introduces complex timing of events, especially when the types and number of messages change at runtime. This paper introduces a novel hybrid timing model to make runtime predictions on the timing of the messages for a finite time window. Controllers can be designed using the optimization algorithms for model predictive control by considering the timing as optimization constraints. This timing model allows multiple controllers to share a CAN without significant degradation in the controller performance. The timing model also provides a convenient way to check the schedulability of messages on the CAN at runtime. Simulation results demonstrate that the timing model is accurate and computationally efficient to meet the needs of real-time implementation. Simulation results also demonstrate that model predictive controllers designed when considering the timing constraints have superior performance than the controllers designed without considering the timing constraints.", "subjects": "Systems and Control (cs.SY)", "authors": "Zhenwu Shi, Fumin Zhang,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.02295", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02295", "title": "\nGOptimaEmbed: A SmartSMS-SQLDatabaseManagementSystem for Low-Cost  Microcontrollers", "abstract": "The era of the Internet of things, machine-to-machine and human to machine computing has heralded the development of a modern-day smart industry in which humanoids can co-operate,co-exist and interact seamlessly.Currently, there are many projects in this area of smart communication and thus giving rise to an industry electrified by smart things.In this paper we present a novel smart database management system (dbms),GOptimaEmbed, for intelligent querying of databases in device constrained embedded systems. The system uses genetic algorithms as main search engine and simplifies the query process using stored in-memory model based on an invented device dependent Short-messaging-Structured Query Language SMS SQL schema translator. In addition, querying is done over the air using integrated GSM module in the smart space. The system has been applied to querying a plant database and results were quite satisfactory. Keywords. GOptimaEmbed,smart dbms, genetic algorithms, SMS SQL", "subjects": "Databases (cs.DB)", "authors": "N.E. Osegi, P. Enyindah,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.02292", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02292", "title": "\nExploiting Device-to-Device Communications in Joint Scheduling of Access  and Backhaul for mmWave Small Cells", "abstract": "With the explosive growth of mobile data demand, there has been an increasing interest in deploying small cells of higher frequency bands underlying the conventional homogeneous macrocell network, which is usually referred to as heterogeneous cellular networks, to significantly boost the overall network capacity. With vast amounts of spectrum available in the millimeter wave (mmWave) band, small cells at mmWave frequencies are able to provide multi-gigabit access data rates, while the wireless backhaul in the mmWave band is emerging as a cost-effective solution to provide high backhaul capacity to connect access points (APs) of the small cells. In order to operate the mobile network optimally, it is necessary to jointly design the radio access and backhaul networks. Meanwhile, direct transmissions between devices should also be considered to improve system performance and enhance the user experience. In this paper, we propose a joint transmission scheduling scheme for the radio access and backhaul of small cells in the mmWave band, termed D2DMAC, where a path selection criterion is designed to enable device-to-device transmissions for performance improvement. In D2DMAC, a concurrent transmission scheduling algorithm is proposed to fully exploit spatial reuse in mmWave networks. Through extensive simulations under various traffic patterns and user deployments, we demonstrate D2DMAC achieves near-optimal performance in some cases, and outperforms other protocols significantly in terms of delay and throughput. Furthermore, we also analyze the impact of path selection on the performance improvement of D2DMAC under different selected parameters.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Yong Niu, Chuhan Gao, Yong Li, Li Su, Depeng Jin, Athanasios V. Vasilakos,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.02291", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02291", "title": "\nA Tolerant Edit Distance for Evaluation and Training of Electron  Microscopy Reconstruction Algorithms", "abstract": "We present a measure to compare the labeling of automatic neuron reconstruction methods against ground truth. This measure, which we call tolerant edit distance (TED), is motivated by two observations: (1) Some errors, like small boundary shifts, are tolerable in practice. Which errors are tolerable is application dependent and should be a parameter of the measure. (2) Non-tolerable errors have to be corrected manually. The time needed to do so should be reflected by the error measure and minimized during training. The TED finds the minimal weighted sum of split and merge errors exceeding a given tolerance criterion, and thus provides a time-to-fix estimate. Our measure works on both isotropic and anisotropic EM datasets, the results are intuitive, and errors can be localized in the volume. We also present a structured learning framework for assignment models for anisotropic neuron reconstruction and show how this framework can be used to minimize the TED on annotated training samples. Evaluated on two publicly available EM-datasets, our method shows consistently higher reconstruction accuracy, even on pre-existing measures, than other current learning methods. Furthermore, we show how an appropriately defined tolerance criterion allows us to train on skeleton (i.e., non-volumetric) annotations, which are much faster to obtain in practice.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Jan Funke, Jonas Klein, Albert Cardona, Matthew Cook,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.02286", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02286", "title": "\nThree-Source Extractors for Polylogarithmic Min-Entropy", "abstract": "We continue the study of constructing explicit extractors for independent general weak random sources. The ultimate goal is to give a construction that matches what is given by the probabilistic method --- an extractor for two independent -bit weak random sources with min-entropy as small as . Previously, the best known result in the two-source case is an extractor by Bourgain cite, which works for min-entropy ; and the best known result in the general case is an earlier work of the author cite, which gives an extractor for a constant number of independent sources with min-entropy . However, the constant in the construction of cite depends on the hidden constant in the best known seeded extractor, and can be large; moreover the error in that construction is only . In this paper, we make two important improvements over the result in cite. First, we construct an explicit extractor for emph independent sources on bits with min-entropy . In fact, our extractor works for one independent source with poly-logarithmic min-entropy and another independent block source with two blocks each having poly-logarithmic min-entropy. Thus, our result is nearly optimal, and the next step would be to break the barrier in two-source extractors. Second, we improve the error of the extractor from to , which is almost optimal and crucial for cryptographic applications. Some of the techniques developed here may be of independent interests.", "subjects": "Computational Complexity (cs.CC)", "authors": "Xin Li,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.02276", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02276", "title": "\nTradeoff for Heterogeneous Distributed Storage Systems between Storage  and Repair Cost", "abstract": "In this paper, we consider heterogeneous distributed storage systems (DSSs) having flexible reconstruction degree, where each node in the system has dynamic repair bandwidth and dynamic storage capacity. In particular, a data collector can reconstruct the file at time using some arbitrary nodes in the system and for a node failure the system can be repaired by some set of arbitrary nodes. Using - bound, we investigate the fundamental tradeoff between storage and repair cost for our model of heterogeneous DSS. In particular, the problem is formulated as bi-objective optimization linear programing problem. For an arbitrary DSS, it is shown that the calculated - bound is tight.", "subjects": "Information Theory (cs.IT)", "authors": "Krishna Gopal Benerjee, Manish K. Gupta,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.02266", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02266", "title": "\nNetwork Coding for Cooperative Mobile Devices with Multiple Interfaces", "abstract": "Cooperation among mobile devices and utilizing multiple interfaces such as cellular and local area links are promising to meet the increasing throughput demand over cellular links. In particular, when mobile devices are in the close proximity of each other and are interested in the same content, device-to-device connections such as WiFi-Direct, in addition to cellular links, can be opportunistically used to construct a cooperative system. However, it is crucial to understand the potential of network coding for cooperating mobile devices with multiple interfaces. In this paper, we consider this problem, and (i) develop a network coding scheme for cooperative mobile devices with multiple interfaces, and (ii) characterize the performance of network coding by using the number of transmissions to recover all packets as a performance metric.", "subjects": "Information Theory (cs.IT)", "authors": "Yasaman Keshtkarjahromi, Hulya Seferoglu, Rashid Ansari, Ashfaq Khokhar,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.02261", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02261", "title": "\nAttack Trees with Sequential Conjunction", "abstract": "We provide the first formal foundation of SAND attack trees which are a popular extension of the well-known attack trees. The SAND attack tree formalism increases the expressivity of attack trees by introducing the sequential conjunctive operator SAND. This operator enables the modeling of ordered events. We give a semantics to SAND attack trees by interpreting them as sets of series-parallel graphs and propose a complete axiomatization of this semantics. We define normal forms for SAND attack trees and a term rewriting system which allows identification of semantically equivalent trees. Finally, we formalize how to quantitatively analyze SAND attack trees using attributes.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Ravi Jhawar, Barbara Kordy, Sjouke Mauw, Sasa Radomirovic, Rolando Trujillo-Rasua,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.02241", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02241", "title": "\nAn Analysis of a Virtually Synchronous Protocol", "abstract": "Enterprise-scale systems such as those used for cloud computing require a scalable and highly available infrastructure. One crucial ingredient of such an infrastructure is the ability to replicate data coherently among a group of cooperating processes in the presence of process failures and group membership changes. The last few decades have seen prolific research into efficient protocols for such data replication. One family of such protocols are the virtually synchronous protocols. Virtually synchronous protocols achieve their efficiency by limiting their synchronicity guarantee to messages that bear a causal relationship to each other. Such protocols have found wide-ranging commercial uses over the years. One protocol in particular, the CBCAST protocol developed by Birman, Schiper and Stephenson in 1991 and used in their ISIS platform was particularly promising due to its unique no-wait properties, but has suffered from seemingly intractable race conditions. In this paper we describe a corrected version of this protocol and prove its formal properties.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Dan Arnon, Navindra Sharma,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.02240", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02240", "title": "\nA General Mechanism Design Methodology for Social Utility Maximization  with Linear Constraints", "abstract": "Social utility maximization refers to the process of allocating resources in such a way that the sum of agents' utilities is maximized under the system constraints. Such allocation arises in several problems in the general area of communications, including unicast (and multicast multi-rate) service on the Internet, as well as in applications with (local) public goods, such as power allocation in wireless networks, spectrum allocation, etc. Mechanisms that implement such allocations in Nash equilibrium have also been studied but either they do not possess full implementation property, or are given in a case-by-case fashion, thus obscuring fundamental understanding of these problems. In this paper we propose a unified methodology for creating mechanisms that fully implement, in Nash equilibria, social utility maximizing functions arising in various contexts where the constraints are convex. The construction of the mechanism is done in a systematic way by considering the dual optimization problem. In addition to the required properties of efficiency and individual rationality that such mechanisms ought to satisfy, three additional design goals are the focus of this paper: a) the size of the message space scaling linearly with the number of agents (even if agents' types are entire valuation functions), b) allocation being feasible on and off equilibrium, and c) strong budget balance at equilibrium and also off equilibrium whenever demand is feasible.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Abhinav Sinha, Achilleas Anastasopoulos,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.02239", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02239", "title": "\nOn the Computation of the Galois Group of Linear Difference Equations", "abstract": "We present an algorithm that determines the Galois group of linear difference equations with rational function coefficients.", "subjects": "Symbolic Computation (cs.SC)", "authors": "Ruyong Feng,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.02230", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02230", "title": "\nPlayer Behavior and Optimal Team Composition for Online Multiplayer  Games", "abstract": "We consider clustering player behavior and learning the optimal team composition for multiplayer online games. The goal is to determine a set of descriptive play style groupings and learn a predictor for win/loss outcomes. The predictor takes in as input the play styles of the participants in each team; i.e., the various team compositions in a game. Our framework uses unsupervised learning to find behavior clusters, which are, in turn, used with classification algorithms to learn the outcome predictor. For our numerical experiments, we consider League of Legends, a popular team-based role-playing game developed by Riot Games. We observe the learned clusters to not only corroborate well with game knowledge, but also provide insights surprising to expert players. We also demonstrate that game outcomes can be predicted with fairly high accuracy given team composition-based features.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Hao Yi Ong, Sunil Deolalikar, Mark Peng,", "date": "2015-3-8"}, 
{"urllink": "http://arxiv.org/abs/1503.02217", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02217", "title": "\nBounding the Bethe and the Degree-$M$ Bethe Permanents", "abstract": "It was recently conjectured that the permanent of a -lifting of a matrix of degree is less than or equal to the th power of the permanent perm, i.e., perm and, consequently, that the degree- Bethe permanent of a matrix is less than or equal to the permanent perm of , i.e., perm. In this paper, we prove these related conjectures and show in addition a few properties of the permanent of block matrices that are lifts of a matrix. As a corollary, we obtain an alternative proof of the inequality perm on the Bethe permanent of the base matrix that uses only the combinatorial definition of the Bethe permanent.", "subjects": "Information Theory (cs.IT)", "authors": "Roxana Smarandache, Martin Haenggi,", "date": "2015-3-7"}, 
{"urllink": "http://arxiv.org/abs/1503.02210", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02210", "title": "\nContainment for Conditional Tree Patterns", "abstract": "A Conditional Tree Pattern (CTP) expands an XML tree pattern with labels attached to the descendant edges. These labels can be XML element names or Boolean CTPs. The meaning of a descendant edge labelled by A and ending in a node labelled by B is a path of child steps ending in a B node such that all intermediate nodes are A nodes. In effect this expresses the until B, A holds construction from temporal logic.This paper studies the containment problem for CTP. For tree patterns (TP), this problem is known to be coNP-complete. We show that it is PSPACE-complete for CTP. This increase in complexity is due to the fact that CTP is expressive enough to encode an unrestricted form of label negation: , meaning \"any node except an a-node\". Containment of TP expanded with this type of negation is already PSPACE-hard. CTP is a positive, forward, first order fragment of Regular XPath. Unlike TP, CTP expanded with disjunction is not equivalent to unions of CTP's. Like TP, CTP is a natural fragment to consider: CTP is closed under intersections and CTP with disjunction is equally expressive as positive existential first order logic expanded with the until operator.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Alessandro Facchini, Yoichi Hirai, Maarten Marx, Evgeny Sherkhonov,", "date": "2015-3-7"}, 
{"urllink": "http://arxiv.org/abs/1503.02208", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02208", "title": "\nQuotient Complexities of Atoms in Regular Ideal Languages", "abstract": "A (left) quotient of a language by a word is the language . The quotient complexity of a regular language is the number of quotients of ; it is equal to the state complexity of , which is the number of states in a minimal deterministic finite automaton accepting . An atom of is an equivalence class of the relation in which two words are equivalent if for each quotient, they either are both in the quotient or both not in it; hence it is a non-empty intersection of complemented and uncomplemented quotients of . A right (respectively, left and two-sided) ideal is a language over an alphabet that satisfies (respectively, and ). We compute the maximal number of atoms and the maximal quotient complexities of atoms of right, left and two-sided regular ideals.", "subjects": "Formal Languages and Automata Theory (cs.FL)", "authors": "Janusz Brzozowski, Sylvie Davies,", "date": "2015-3-7"}, 
{"urllink": "http://arxiv.org/abs/1503.02200", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02200", "title": "\nSequential Posted Price Mechanisms with Correlated Valuations", "abstract": "We study the revenue performance of sequential posted price (SPP) mechanisms and some natural extensions, for a general setting where the valuations of the buyers are drawn from a correlated distribution. SPP mechanisms are conceptually simple mechanisms that work by proposing a \"take-it-or-leave-it\" offer to each buyer. We apply SPP mechanisms to settings in which each buyer has unit demand and the mechanism can assign the service to at most of the buyers. For standard SPP mechanisms, we prove that with the valuation distribution having finite support, no SPP mechanism can extract a constant fraction of the optimal expected revenue, even with unlimited supply. We extend this result to the the case of a continuous valuation distribution when various standard assumptions hold simultaneously (i.e., everywhere-supported, continuous, symmetric, and normalized (conditional) distributions that satisfy regularity, the MHR condition, and affiliation). In fact, it turns out that the best fraction of the optimal revenue that is extractable by a SPP mechanism is proportional to ratio of the highest and lowest possible valuation. We prove that for two simple generalizations of these mechansims, a better revenue performance can be achieved: if the SPP mechanism has for each buyer the option of either proposing an offer or asking the buyer for its valuation, then a fraction of the optimal revenue can be extracted, where denotes the degree of dependence of the valuations, ranging from complete independence () to arbitrary dependence (). Moreover, when we generalize the SPP mechanisms further, such that the mechanism has the ability to make a take-it-or-leave-it offer to the -th buyer that depends on the valuations of all buyers except 's, we prove that a constant fraction of the optimal revenue can be always be extracted.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Marek Adamczyk, Allan Borodin, Diodato Ferraioli, Bart de Keijzer, Stefano Leonardi,", "date": "2015-3-7"}, 
{"urllink": "http://arxiv.org/abs/1503.02196", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02196", "title": "\nHigher Weights of Affine Grassmann Codes and Their Duals", "abstract": "We consider the question of determining the higher weights or the generalized Hamming weights of affine Grassmann codes and their duals. Several initial as well as terminal higher weights of affine Grassmann codes of an arbitrary level are determined explicitly. In the case of duals of these codes, we give a formula for many initial as well as terminal higher weights. As a special case, we obtain an alternative simpler proof of the formula of Beelen et al for the minimum distance of the dual of an affine Grasmann code.", "subjects": "Information Theory (cs.IT)", "authors": "Mrinmoy Datta, Sudhir R. Ghorpade,", "date": "2015-3-7"}, 
{"urllink": "http://arxiv.org/abs/1503.02193", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02193", "title": "\nLabel optimal regret bounds for online local learning", "abstract": "We resolve an open question from (Christiano, 2014b) posed in COLT'14 regarding the optimal dependency of the regret achievable for online local learning on the size of the label set. In this framework the algorithm is shown a pair of items at each step, chosen from a set of items. The learner then predicts a label for each item, from a label set of size and receives a real valued payoff. This is a natural framework which captures many interesting scenarios such as collaborative filtering, online gambling, and online max cut among others. (Christiano, 2014a) designed an efficient online learning algorithm for this problem achieving a regret of , where is the number of rounds. Information theoretically, one can achieve a regret of . One of the main open questions left in this framework concerns closing the above gap. In this work, we provide a complete answer to the question above via two main results. We show, via a tighter analysis, that the semi-definite programming based algorithm of (Christiano, 2014a), in fact achieves a regret of . Second, we show a matching computational lower bound. Namely, we show that a polynomial time algorithm for online local learning with lower regret would imply a polynomial time algorithm for the planted clique problem which is widely believed to be hard. We prove a similar hardness result under a related conjecture concerning planted dense subgraphs that we put forth. Unlike planted clique, the planted dense subgraph problem does not have any known quasi-polynomial time algorithms. Computational lower bounds for online learning are relatively rare, and we hope that the ideas developed in this work will lead to lower bounds for other online learning scenarios as well.", "subjects": "Learning (cs.LG)", "authors": "Pranjal Awasthi, Moses Charikar, Kevin A. Lai, Andrej Risteski,", "date": "2015-3-7"}, 
{"urllink": "http://arxiv.org/abs/1503.02192", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02192", "title": "\nUplink Performance Evaluation of Massive MU-MIMO Systems", "abstract": "The present paper deals with an OFDM-based uplink within a multi-user MIMO (MU-MIMO) system where a massive MIMO approach is employed. In this context, the linear detectors Minimum Mean-Squared Error (MMSE), Zero Forcing (ZF) and Maximum Ratio Combining (MRC) are considered and assessed. This papers includes Bit Error Rate (BER) results for uncoded QPSK/OFDM transmissions through a flat Rayleigh fading channel under the assumption of perfect power control and channel estimation. BER results are obtained through Monte Carlo simulations. Performance results are discussed in detail and we confirm the achievable \"massive MIMO\" effects, even for a reduced complexity detection technique, when the number of receive antennas at BS is much larger than the number of transmit antennas.", "subjects": "Information Theory (cs.IT)", "authors": "Felipe A. P. de Figueiredo, Joao Paulo Miranda, Fabricio L. Figueiredo, Fabbryccio A. C. M. Cardoso,", "date": "2015-3-7"}, 
{"urllink": "http://arxiv.org/abs/1503.02164", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02164", "title": "\nA Nonconvex Approach for Structured Sparse Learning", "abstract": "Sparse learning is an important topic in many areas such as machine learning, statistical estimation, signal processing, etc. Recently, there emerges a growing interest on structured sparse learning. In this paper we focus on the -analysis optimization problem for structured sparse learning (). Compared to previous work, we establish weaker conditions for exact recovery in noiseless case and a tighter non-asymptotic upper bound of estimate error in noisy case. We further prove that the nonconvex -analysis optimization can do recovery with a lower sample complexity and in a wider range of cosparsity than its convex counterpart. In addition, we develop an iteratively reweighted method to solve the optimization problem under the variational framework. Theoretical analysis shows that our method is capable of pursuing a local minima close to the global minima. Also, empirical results of preliminary computational experiments illustrate that our nonconvex method outperforms both its convex counterpart and other state-of-the-art methods.", "subjects": "Information Theory (cs.IT)", "authors": "Shubao Zhang, Hui Qian, Zhihua Zhang,", "date": "2015-3-7"}, 
{"urllink": "http://arxiv.org/abs/1503.02155", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02155", "title": "\nAdaptive Power Allocation and Control in Time-Varying Multi-Carrier MIMO  Networks", "abstract": "In this paper, we examine the fundamental trade-off between radiated power and achieved throughput in wireless multi-carrier, multiple-input and multiple-output (MIMO) systems that vary with time in an unpredictable fashion (e.g. due to changes in the wireless medium or the users' QoS requirements). Contrary to the static/stationary channel regime, there is no optimal power allocation profile to target (either static or in the mean), so the system's users must adapt to changes in the environment \"on the fly\", without being able to predict the system's evolution ahead of time. In this dynamic context, we formulate the users' power/throughput trade-off as an online optimization problem and we provide a matrix exponential learning algorithm that leads to no regret - i.e. the proposed transmit policy is asymptotically optimal in hindsight, irrespective of how the system evolves over time. Furthermore, we also examine the robustness of the proposed algorithm under imperfect channel state information (CSI) and we show that it retains its regret minimization properties under very mild conditions on the measurement noise statistics. As a result, users are able to track the evolution of their individually optimum transmit profiles remarkably well, even under rapidly changing network conditions and high uncertainty. Our theoretical analysis is validated by extensive numerical simulations corresponding to a realistic network deployment and providing further insights in the practical implementation aspects of the proposed algorithm.", "subjects": "Information Theory (cs.IT)", "authors": "Ioannis Stiakogiannakis, Panayotis Mertikopoulos, Corinne Touati,", "date": "2015-3-7"}, 
{"urllink": "http://arxiv.org/abs/1503.02144", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02144", "title": "\nSparse Bayesian Dictionary Learning with a Gaussian Hierarchical Model", "abstract": "We consider a dictionary learning problem whose objective is to design a dictionary such that the signals admits a sparse or an approximate sparse representation over the learned dictionary. Such a problem finds a variety of applications such as image denoising, feature extraction, etc. In this paper, we propose a new hierarchical Bayesian model for dictionary learning, in which a Gaussian-inverse Gamma hierarchical prior is used to promote the sparsity of the representation. Suitable priors are also placed on the dictionary and the noise variance such that they can be reasonably inferred from the data. Based on the hierarchical model, a variational Bayesian method and a Gibbs sampling method are developed for Bayesian inference. The proposed methods have the advantage that they do not require the knowledge of the noise variance emph. Numerical results show that the proposed methods are able to learn the dictionary with an accuracy better than existing methods, particularly for the case where there is a limited number of training signals.", "subjects": "Learning (cs.LG)", "authors": "Linxiao Yang, Jun Fang, Hong Cheng, Hongbin Li,", "date": "2015-3-7"}, 
{"urllink": "http://arxiv.org/abs/1503.02143", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02143", "title": "\nModel selection of polynomial kernel regression", "abstract": "Polynomial kernel regression is one of the standard and state-of-the-art learning strategies. However, as is well known, the choices of the degree of polynomial kernel and the regularization parameter are still open in the realm of model selection. The first aim of this paper is to develop a strategy to select these parameters. On one hand, based on the worst-case learning rate analysis, we show that the regularization term in polynomial kernel regression is not necessary. In other words, the regularization parameter can decrease arbitrarily fast when the degree of the polynomial kernel is suitable tuned. On the other hand,taking account of the implementation of the algorithm, the regularization term is required. Summarily, the effect of the regularization term in polynomial kernel regression is only to circumvent the \" ill-condition\" of the kernel matrix. Based on this, the second purpose of this paper is to propose a new model selection strategy, and then design an efficient learning algorithm. Both theoretical and experimental analysis show that the new strategy outperforms the previous one. Theoretically, we prove that the new learning strategy is almost optimal if the regression function is smooth. Experimentally, it is shown that the new strategy can significantly reduce the computational burden without loss of generalization capability.", "subjects": "Learning (cs.LG)", "authors": "Shaobo Lin, Xingping Sun, Zongben Xu, Jinshan Zeng,", "date": "2015-3-7"}, 
{"urllink": "http://arxiv.org/abs/1503.02136", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02136", "title": "\nAn Improved Image Mosaicing Algorithm for Damaged Documents", "abstract": "It is a common phenomenon in day to day life; where in some of the document gets damaged. Out of several reasons, the main reason for documents getting damaged is shredding by hands. Recovery of such documents is essential. Manual recovery of such damaged document is tedious and time consuming task. In this paper, we are describing an algorithm which recovers the original document from such shredded pieces of the same. In order to implement this, we are using a simple technique called Image Mosaicing. In this technique a complete new image is developed using two or more torn fragments. For simplicity of implementation, we are considering only two torn pieces of a document that will be mosaiced together. The successful implementation of this algorithm would lead to recovery of important information which in turn would be beneficial in various fields such as forensic sciences, archival study, etc", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Waheeda Dhokley, Khan Munifa, Shaikh Nazia, Shaikh Saiqua,", "date": "2015-3-7"}, 
{"urllink": "http://arxiv.org/abs/1503.02129", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02129", "title": "\nLearning Scale Free Network by Node Specific Degree Prior", "abstract": "Learning the network structure underlying data is an important problem in machine learning. This paper introduces a novel prior to study the inference of scale-free networks, which are widely used to model social and biological networks. The prior not only favors a desirable global node degree distribution, but also takes into consideration the relative strength of all the possible edges adjacent to the same node and the estimated degree of each individual node. To fulfill this, ranking is incorporated into the prior, which makes the problem challenging to solve. We employ an ADMM (alternating direction method of multipliers) framework to solve the Gaussian Graphical model regularized by this prior. Our experiments on both synthetic and real data show that our prior not only yields a scale-free network, but also produces many more correctly predicted edges than the others such as the scale-free inducing prior, the hub-inducing prior and the norm.", "subjects": "Learning (cs.LG)", "authors": "Qingming Tang, Siqi Sun, Chao Yang, Jinbo Xu,", "date": "2015-3-7"}, 
{"urllink": "http://arxiv.org/abs/1503.02128", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02128", "title": "\nExact Hybrid Covariance Thresholding for Joint Graphical Lasso", "abstract": "This paper considers the problem of estimating multiple related Gaussian graphical models from a -dimensional dataset consisting of different classes. Our work is based upon the formulation of this problem as group graphical lasso. This paper proposes a novel hybrid covariance thresholding algorithm that can effectively identify zero entries in the precision matrices and split a large joint graphical lasso problem into small subproblems. Our hybrid covariance thresholding method is superior to existing uniform thresholding methods in that our method can split the precision matrix of each individual class using different partition schemes and thus split group graphical lasso into much smaller subproblems, each of which can be solved very fast. In addition, this paper establishes necessary and sufficient conditions for our hybrid covariance thresholding algorithm. The superior performance of our thresholding method is thoroughly analyzed and illustrated by a few experiments on simulated data and real gene expression data.", "subjects": "Learning (cs.LG)", "authors": "Qingming Tang, Chao Yang, Jian Peng, Jinbo Xu,", "date": "2015-3-7"}, 
{"urllink": "http://arxiv.org/abs/1503.02123", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02123", "title": "\nTo NACK or not to NACK? Negative Acknowledgments in Information-Centric  Networking", "abstract": "Information-Centric Networking (ICN) is an internetworking paradigm that offers an alternative to the current IP nobreakdash-based Internet architecture. ICN's most distinguishing feature is its emphasis on information (content) instead of communication endpoints. One important open issue in ICN is whether negative acknowledgments (NACKs) at the network layer are useful for notifying downstream nodes about forwarding failures, or requests for incorrect or non-existent information. In benign settings, NACKs are beneficial for ICN architectures, such as CCNx and NDN, since they flush state in routers and notify consumers. In terms of security, NACKs seem useful as they can help mitigating so-called Interest Flooding attacks. However, as we show in this paper, network-layer NACKs also have some unpleasant security implications. We consider several types of NACKs and discuss their security design requirements and implications. We also demonstrate that providing secure NACKs triggers the threat of producer-bound flooding attacks. Although we discuss some potential countermeasures to these attacks, the main conclusion of this paper is that network-layer NACKs are best avoided, at least for security reasons.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Alberto Compagno, Mauro Conti, Cesar Ghali, Gene Tsudik,", "date": "2015-3-7"}, 
{"urllink": "http://arxiv.org/abs/1503.02120", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02120", "title": "\nIdentifying missing dictionary entries with frequency-conserving context  models", "abstract": "In an effort to better understand meaning from natural language texts, we explore methods aimed at organizing lexical objects into contexts. A number of these methods for organization fall into a family defined by word ordering. Unlike demographic or spatial partitions of data, these collocation models are of special importance for their universal applicability in the presence of ordered symbolic data (e.g., text, speech, genes, etc...). Our approach focuses on the phrase (whether word or larger) as the primary meaning-bearing lexical unit and object of study. To do so, we employ our previously developed framework for generating word-conserving phrase-frequency data. Upon training our model with the Wiktionary---an extensive, online, collaborative, and open-source dictionary that contains over 100,000 phrasal-definitions---we develop highly effective filters for the identification of meaningful, missing phrase-entries. With our predictions we then engage the editorial community of the Wiktionary and propose short lists of potential missing entries for definition, developing a breakthrough, lexical extraction technique, and expanding our knowledge of the defined English lexicon of phrases.", "subjects": "Computation and Language (cs.CL)", "authors": "Jake Ryland Williams, Eric M. Clark, James P. Bagrow, Christopher M. Danforth, Peter Sheridan Dodds,", "date": "2015-3-7"}, 
{"urllink": "http://arxiv.org/abs/1503.02108", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02108", "title": "\nMaximum a Posteriori Adaptation of Network Parameters in Deep Models", "abstract": "We present a Bayesian approach to adapting parameters of a well-trained context-dependent deep-neural-network hid-den Markov models (CD-DNN-HMMs) to improve automatic speech recognition performance. Due to an abundance of DNN parameters but with only a limited amount of adaptation data, the posterior probabilities of unseen CD states (senones) are often pushed towards zero during adaptation, and consequently the ability to model these senones can be degraded. We formulate maximum a posteriori (MAP) adaptation of parameters of a specially designed CD-DNN-HMM with an augmented linear hidden networks connected to the output senones and compare it to the feature space maximum a posteriori linear regression previously proposed. Experimental evidences on the 20,000-word open vocabulary Wall Street Journal task demonstrate the feasibility of the proposed framework. In supervised adaptation, the proposed MAP adaptation provides more than 10% relative error reduction and consistently outperforms the conventional transformation based methods. Furthermore, we present an initial attempt to generate hierarchical priors to improve adaptation efficiency and effectiveness with limited adaptation data by exploiting similarities among senones.", "subjects": "Learning (cs.LG)", "authors": "Zhen Huang, Sabato Marco Siniscalchi, I-Fan Chen, Jiadong Wu, Chin-Hui Lee,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.02101", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02101", "title": "\nEscaping From Saddle Points --- Online Stochastic Gradient for Tensor  Decomposition", "abstract": "We analyze stochastic gradient descent for optimizing non-convex functions. In many cases for non-convex functions the goal is to find a reasonable local minimum, and the main concern is that gradient updates are trapped in saddle points. In this paper we identify strict saddle property for non-convex problem that allows for efficient optimization. Using this property we show that stochastic gradient descent converges to a local minimum in a polynomial number of iterations. To the best of our knowledge this is the first work that gives global convergence guarantees for stochastic gradient descent on non-convex functions with exponentially many local minima and saddle points. Our analysis can be applied to orthogonal tensor decomposition, which is widely used in learning a rich class of latent variable models. We propose a new optimization formulation for the tensor decomposition problem that has strict saddle property. As a result we get the first online algorithm for orthogonal tensor decomposition with global convergence guarantee.", "subjects": "Learning (cs.LG)", "authors": "Rong Ge, Furong Huang, Chi Jin, Yang Yuan,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.02090", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02090", "title": "\nBand selection in RKHS for fast nonlinear unmixing of hyperspectral  images", "abstract": "The profusion of spectral bands generated by the acquisition process of hyperspectral images generally leads to high computational costs. Such difficulties arise in particular with nonlinear unmixing methods, which are naturally more complex than linear ones. This complexity, associated with the high redundancy of information within the complete set of bands, make the search of band selection algorithms relevant. With this work, we propose a band selection strategy in reproducing kernel Hilbert spaces that allows to drastically reduce the processing time required by nonlinear unmixing techniques. Simulation results show a complexity reduction of two orders of magnitude without compromising unmixing performance.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "T. Imbiriba, J. C. M. Bermudez, C. Richard, J.-Y. Tourneret,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.02086", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02086", "title": "\nGender-Based Violence in 140 Characters or Fewer: A #BigData Case Study  of Twitter", "abstract": "Humanitarian and public institutions are increasingly relying on data from social media sites to measure public attitude, and provide timely public engagement. Such engagement supports the exploration of public views on important social issues such as gender-based violence (GBV). In this study, we examine Big (Social) Data consisting of nearly fourteen million tweets collected from the Twitter platform over a period of ten months to analyze public opinion regarding GBV, highlighting the nature of tweeting practices by geographical location and gender. The exploitation of Big Data requires the techniques of Computational Social Science to mine insight from the corpus while accounting for the influence of both transient events and sociocultural factors. We reveal public awareness regarding GBV tolerance and suggest opportunities for intervention and the measurement of intervention effectiveness assisting both governmental and non-governmental organizations in policy development.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Hemant Purohit, Tanvi Banerjee, Andrew Hampton, Valerie L. Shalin, Nayanesh Bhandutia, Amit P. Sheth,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.02064", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02064", "title": "\nA Unified Platform Enabling Power System Circuit Model Data Transfer  Among Different Software", "abstract": "Diversity of software packages to simulate the power system circuits is considerable. It is challenging to transfer power system circuit model data (PSCMD) among different software tools and rebuild the same circuit in the second software environment. This paper proposes a unified platform (UP) where PSCMD are stored in a spreadsheet file with a defined format. Script-based PSCMD transfer applications, written in MATLAB, have been developed for a set of software to read the circuit model data from the UP spreadsheet and reconstruct the circuit in the destination software. This significantly eases the process of transferring circuit model data between each pair of software tools. In this paper ETAP, OpenDSS, Grid LabD, and DEW are considered. In order to test the developed PSCMD transfer applications, circuit model data of a test circuit and an actual sample circuit from a Californian utility company, both built in CYME, were exported into the spreadsheet file according to the UP format. Thereafter, circuit model data were imported successfully from the spreadsheet files into all above mentioned software using the PSCMD transfer applications developed for each software individually. Finally, load flow analysis is performed in all software and the obtained results match with each other.", "subjects": "Systems and Control (cs.SY)", "authors": "Arash Khoshkbar Sadigh, Mojtaba Hydari, Marco Tedde, Reza Arghandeh, Keyue Smedley, Alexandra von Meier,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.02045", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02045", "title": "\nEstimation after Parameter Selection: Performance Analysis and  Estimation Methods", "abstract": "In many practical parameter estimation problems, prescreening and parameter selection are performed prior to estimation. In this paper, we consider the problem of estimating a preselected unknown deterministic parameter chosen from a parameter set based on observations according to a predetermined selection rule, . The data-based parameter selection process may impact the subsequent estimation by introducing a selection bias and creating coupling between decoupled parameters. This paper introduces a post-selection mean squared error (PSMSE) criterion as a performance measure. A corresponding Cram 'er-Rao-type bound on the PSMSE of any -unbiased estimator is derived, where the -unbiasedness is in the Lehmann-unbiasedness sense. The post-selection maximum-likelihood (PSML) estimator is presented .It is proved that if there exists an -unbiased estimator that achieves the -Cram 'er-Rao bound (CRB), i.e. an -efficient estimator, then it is produced by the PSML estimator. In addition, iterative methods are developed for the practical implementation of the PSML estimator. Finally, the proposed -CRB and PSML estimator are examined in estimation after parameter selection with different distributions.", "subjects": "Information Theory (cs.IT)", "authors": "Tirza Routtenberg, Lang Tong,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.02041", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02041", "title": "\nOn the Invariance of Dictionary Learning and Sparse Representation to  Projecting Data to a Discriminative Space", "abstract": "In this paper, it is proved that dictionary learning and sparse representation is invariant to a linear transformation. It subsumes the special case of transforming/projecting the data into a discriminative space. This is important because recently, supervised dictionary learning algorithms have been proposed, which suggest to include the category information into the learning of dictionary to improve its discriminative power. Among them, there are some approaches that propose to learn the dictionary in a discriminative projected space. To this end, two approaches have been proposed: first, assigning the discriminative basis as the dictionary and second, perform dictionary learning in the projected space. Based on the invariance of dictionary learning to any transformation in general, and to a discriminative space in particular, we advocate the first approach.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Mehrdad J. Gangeh, Ali Ghodsi,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.02031", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02031", "title": "\nTo Drop or Not to Drop: Robustness, Consistency and Differential Privacy  Properties of Dropout", "abstract": "Training deep belief networks (DBNs) requires optimizing a non-convex function with an extremely large number of parameters. Naturally, existing gradient descent (GD) based methods are prone to arbitrarily poor local minima. In this paper, we rigorously show that such local minima can be avoided (upto an approximation error) by using the dropout technique, a widely used heuristic in this domain. In particular, we show that by randomly dropping a few nodes of a one-hidden layer neural network, the training objective function, up to a certain approximation error, decreases by a multiplicative factor. On the flip side, we show that for training convex empirical risk minimizers (ERM), dropout in fact acts as a \"stabilizer\" or regularizer. That is, a simple dropout based GD method for convex ERMs is stable in the face of arbitrary changes to any one of the training points. Using the above assertion, we show that dropout provides fast rates for generalization error in learning (convex) generalized linear models (GLM). Moreover, using the above mentioned stability properties of dropout, we design dropout based differentially private algorithms for solving ERMs. The learned GLM thus, preserves privacy of each of the individual training points while providing accurate predictions for new test points. Finally, we empirically validate our stability assertions for dropout in the context of convex ERMs and show that surprisingly, dropout significantly outperforms (in terms of prediction accuracy) the L2 regularization based methods for several benchmark datasets.", "subjects": "Learning (cs.LG)", "authors": "Prateek Jain, Vivek Kulkarni, Abhradeep Thakurta, Oliver Williams,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.02009", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02009", "title": "\nTowards an intelligent VNS heuristic for the k-labelled spanning forest  problem", "abstract": "In a currently ongoing project, we investigate a new possibility for solving the k-labelled spanning forest (kLSF) problem by an intelligent Variable Neighbourhood Search (Int-VNS) metaheuristic. In the kLSF problem we are given an undirected input graph G and an integer positive value k, and the aim is to find a spanning forest of G having the minimum number of connected components and the upper bound k on the number of labels to use. The problem is related to the minimum labelling spanning tree (MLST) problem, whose goal is to get the spanning tree of the input graph with the minimum number of labels, and has several applications in the real world, where one aims to ensure connectivity by means of homogeneous connections. The Int-VNS metaheuristic that we propose for the kLSF problem is derived from the promising intelligent VNS strategy recently proposed for the MLST problem, and integrates the basic VNS for the kLSF problem with other complementary approaches from machine learning, statistics and experimental algorithmics, in order to produce high-quality performance and to completely automate the resulting strategy.", "subjects": "Other Computer Science (cs.OH)", "authors": "Sergio Consoli, Jos\u00e8 Andr\u00e8s Moreno P\u00e8rez, Nenad Mladenovic,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.02007", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.02007", "title": "\nQualitative Analysis of Integration Adapter Modeling", "abstract": "Integration Adapters are a fundamental part of an integration system, since they provide (business) applications access to its messaging channel. However, their modeling and configuration remain under-represented. In previous work, the integration control and data flow syntax and semantics have been expressed in the Business Process Model and Notation (BPMN) as a semantic model for message-based integration, while adapter and the related quality of service modeling were left for further studies. In this work we specify common adapter capabilities and derive general modeling patterns, for which we define a compliant representation in BPMN. The patterns extend previous work by the adapter flow, evaluated syntactically and semantically for common adapter characteristics.", "subjects": "Software Engineering (cs.SE)", "authors": "Daniel Ritter, Manuel Holzleitner,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01993", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01993", "title": "\nTomographic Image Reconstruction using Dictionary Priors", "abstract": "We describe and examine a framework for tomographic image reconstruction where prior knowledge about the solution is available in the form of training images. We first construct a dictionary that contains prototype elements from these images. Then by using the dictionary as a prior to regularize the inverse problem, and looking for a solution with a sparse representation in the dictionary, we formulate the reconstruction problem in a convex optimization framework. Our computational experiments clarify the choice and interplay of the model parameters and the regularization parameters, and they show that in few-projection settings we are able to produce better images with more structural features than the total variation approach.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Sara Soltani, Martin S. Andersen, Per Christian Hansen,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01986", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01986", "title": "\nConvex Color Image Segmentation with Optimal Transport Distances", "abstract": "This work is about the use of regularized optimal-transport distances for convex, histogram-based image segmentation. In the considered framework, fixed exemplar histograms define a prior on the statistical features of the two regions in competition. In this paper, we investigate the use of various transport-based cost functions as discrepancy measures and rely on a primal-dual algorithm to solve the obtained convex optimization problem.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Julien Rabin, Nicolas Papadakis,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01981", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01981", "title": "\nA Uniform Substitution Calculus for Differential Dynamic Logic", "abstract": "This paper introduces a new proof calculus for differential dynamic logic (dL) that is entirely based on uniform substitution, a proof rule that substitutes a formula for a predicate symbol everywhere. Uniform substitutions make it possible to rely on axioms rather than axiom schemata, substantially simplifying implementations. Instead of nontrivial schema variables and soundness-critical side conditions on the occurrence patterns of variables, the resulting calculus adopts only a finite number of ordinary dL formulas as axioms. The static semantics of differential dynamic logic is captured exclusively in uniform substitutions and bound variable renamings as opposed to being spread in delicate ways across the prover implementation. In addition to sound uniform substitutions, this paper introduces a differential form of differential dynamic logic that makes it possible to internalize differential invariants, differential substitutions, and derivations as first-class citizens in the logic.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Andr\u00e9 Platzer,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01967", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01967", "title": "\nInformation entropy as an anthropomorphic concept", "abstract": "According to E.T. Jaynes and E.P. Wigner, entropy is an anthropomorphic concept in the sense that in a physical system correspond many thermodynamic systems. The physical system can be examined from many points of view each time examining different variables and calculating entropy differently. In this paper we discuss how this concept may be applied in information entropy; how Shannon's definition of entropy can fit in Jayne's and Wigner's statement. This is achieved by generalizing Shannon's notion of information entropy and this is the main contribution of the paper. Then we discuss how entropy under these considerations may be used for the comparison of password complexity and as a measure of diversity useful in the analysis of the behavior of genetic algorithms.", "subjects": "Information Theory (cs.IT)", "authors": "Panteleimon Rodis,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01960", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01960", "title": "\nConferences vs. Journals: Throwing the baby out with the bath water?", "abstract": "Criticism of the conference model should be put in context. Evidences suggest that the essential features of this model have emerged as responses to challenges posed by current trends of scientific research and the impact of the new techno-economic paradigm, the age of Information and Communication Technology. This context seems indispensable when discussing today's problems of scientific evaluation, in particular the Conference vs. Journal (CvJ) debate. This debate, also, would benefit from systematic historical and sociological studies of these practices. In this note we briefly develop these arguments.", "subjects": "Digital Libraries (cs.DL)", "authors": "Claudio Gutierrez,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01958", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01958", "title": "\nMechanism Design via Optimal Transport", "abstract": "Optimal mechanisms have been provided in quite general multi-item settings, as long as each bidder's type distribution is given explicitly by listing every type in the support along with its associated probability. In the implicit setting, e.g. when the bidders have additive valuations with independent and/or continuous values for the items, these results do not apply, and it was recently shown that exact revenue optimization is intractable, even when there is only one bidder. Even for item distributions with special structure, optimal mechanisms have been surprisingly rare and the problem is challenging even in the two-item case. In this paper, we provide a framework for designing optimal mechanisms using optimal transport theory and duality theory. We instantiate our framework to obtain conditions under which only pricing the grand bundle is optimal in multi-item settings (complementing the work of [Manelli and Vincent 2006], as well as to characterize optimal two-item mechanisms. We use our results to derive closed-form descriptions of the optimal mechanism in several two-item settings, exhibiting also a setting where a continuum of lotteries is necessary for revenue optimization but a closed-form representation of the mechanism can still be found efficiently using our framework.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Constantinos Daskalakis, Alan Deckelbaum, Christos Tzamos,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01955", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01955", "title": "\nLinear-time list recovery of high-rate expander codes", "abstract": "We show that expander codes, when properly instantiated, are high-rate list recoverable codes with linear-time list recovery algorithms. List recoverable codes have been useful recently in constructing efficiently list-decodable codes, as well as explicit constructions of matrices for compressive sensing and group testing. Previous list recoverable codes with linear-time decoding algorithms have all had rate at most 1/2; in contrast, our codes can have rate for any . We can plug our high-rate codes into a construction of Meir (2014) to obtain linear-time list recoverable codes of arbitrary rates, which approach the optimal trade-off between the number of non-trivial lists provided and the rate of the code. While list-recovery is interesting on its own, our primary motivation is applications to list-decoding. A slight strengthening of our result would implies linear-time and optimally list-decodable codes for all rates, and our work is a step in the direction of solving this important problem.", "subjects": "Information Theory (cs.IT)", "authors": "Brett Hemenway, Mary Wootters,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01954", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01954", "title": "\nDenoising Autoencoders for fast Combinatorial Black Box Optimization", "abstract": "Estimation of Distribution Algorithms (EDAs) require flexible probability models that can be efficiently learned and sampled. Autoencoders (AE) are generative stochastic networks with these desired properties. We integrate a special type of AE, the Denoising Autoencoder (DAE), into an EDA and evaluate the performance of DAE-EDA on several combinatorial optimization problems with a single objective. We asses the number of fitness evaluations as well as the required CPU times. We compare the results to the performance to the Bayesian Optimization Algorithm (BOA) and RBM-EDA, another EDA which is based on a generative neural network which has proven competitive with BOA. For the considered problem instances, DAE-EDA is considerably faster than BOA and RBM-EDA, sometimes by orders of magnitude. The number of fitness evaluations is higher than for BOA, but competitive with RBM-EDA. These results show that DAEs can be useful tools for problems with low but non-negligible fitness evaluation costs.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "Malte Probst,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01934", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01934", "title": "\nReliable SVD based Semi-blind and Invisible Watermarking Schemes", "abstract": "A semi-blind watermarking scheme is presented based on Singular Value Decomposition (SVD), which makes essential use of the fact that, the SVD subspace preserves significant amount of information of an image and is a one way decomposition. The principal components are used, along with the corresponding singular vectors of the watermark image to watermark the target image. For further security, the semi-blind scheme is extended to an invisible hash based watermarking scheme. The hash based scheme commits a watermark with a key such that, it is incoherent with the actual watermark, and can only be extracted using the key. Its security is analyzed in the random oracle model and shown to be unforgeable, invisible and satisfying the property of non-repudiation.", "subjects": "Multimedia (cs.MM)", "authors": "Subhayan Roy Moulick, Siddharth Arora, Chirag Jain, Prasanta K. Panigrahi,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01918", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01918", "title": "\nFast image-based obstacle detection from unmanned surface vehicles", "abstract": "Obstacle detection plays an important role in unmanned surface vehicles (USV). The USVs operate in highly diverse environments in which an obstacle may be a floating piece of wood, a scuba diver, a pier, or a part of a shoreline, which presents a significant challenge to continuous detection from images taken onboard. This paper addresses the problem of online detection by constrained unsupervised segmentation. To this end, a new graphical model is proposed that affords a fast and continuous obstacle image-map estimation from a single video stream captured onboard a USV. The model accounts for the semantic structure of marine environment as observed from USV by imposing weak structural constraints. A Markov random field framework is adopted and a highly efficient algorithm for simultaneous optimization of model parameters and segmentation mask estimation is derived. Our approach does not require computationally intensive extraction of texture features and comfortably runs in real-time. The algorithm is tested on a new, challenging, dataset for segmentation and obstacle detection in marine environments, which is the largest annotated dataset of its kind. Results on this dataset show that our model outperforms the related approaches, while requiring a fraction of computational effort.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Matej Kristan, Vildana Sulic, Stanislav Kovacic, Janez Pers,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01913", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01913", "title": "\nTerminating Distributed Construction of Shapes and Patterns in a Fair  Solution of Automata", "abstract": "We consider a solution of automata similar to Population Protocols and Network Constructors. The automata (or nodes) move passively in a well-mixed solution and can cooperate by interacting in pairs. Every such interaction may result in an update of the local states of the nodes. Additionally, the nodes may also choose to connect to each other in order to start forming some required structure. We may think of such nodes as the smallest possible programmable pieces of matter. The model that we introduce here is a more applied version of Network Constructors, imposing physical (or geometrical) constraints on the connections. Each node can connect to other nodes only via a very limited number of local ports, therefore at any given time it has only a bounded number of neighbors. Connections are always made at unit distance and are perpendicular to connections of neighboring ports. We show that this restricted model is still capable of forming very practical 2D or 3D shapes. We provide direct constructors for some basic shape construction problems. We then develop new techniques for determining the constructive capabilities of our model. One of the main novelties of our approach, concerns our attempt to overcome the inability of such systems to detect termination. In particular, we exploit the assumptions that the system is well-mixed and has a unique leader, in order to give terminating protocols that are correct with high probability (w.h.p.). This allows us to develop terminating subroutines that can be sequentially composed to form larger modular protocols. One of our main results is a terminating protocol counting the size of the system w.h.p.. We then use this protocol as a subroutine in order to develop our universal constructors, establishing that the nodes can self-organize w.h.p. into arbitrarily complex shapes while still detecting termination of the construction.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Othon Michail,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01910", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01910", "title": "\nSequential Relevance Maximization with Binary Feedback", "abstract": "Motivated by online settings where users can provide explicit feedback about the relevance of products that are sequentially presented to them, we look at the recommendation process as a problem of dynamically optimizing this relevance feedback. Such an algorithm optimizes the fine tradeoff between presenting the products that are most likely to be relevant, and learning the preferences of the user so that more relevant recommendations can be made in the future. We assume a standard predictive model inspired by collaborative filtering, in which a user is sampled from a distribution over a set of possible types. For every product category, each type has an associated relevance feedback that is assumed to be binary: the category is either relevant or irrelevant. Assuming that the user stays for each additional recommendation opportunity with probability independent of the past, the problem is to find a policy that maximizes the expected number of recommendations that are deemed relevant in a session. We analyze this problem and prove key structural properties of the optimal policy. Based on these properties, we first present an algorithm that strikes a balance between recursion and dynamic programming to compute this policy. We further propose and analyze two heuristic policies: a `farsighted' greedy policy that attains at least factor of the optimal payoff, and a naive greedy policy that attains at least factor of the optimal payoff in the worst case. Extensive simulations show that these heuristics are very close to optimal in practice.", "subjects": "Learning (cs.LG)", "authors": "Vijay Kamble, Nadia Fawaz, Fernando Silveira,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01903", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01903", "title": "\nPartial light field tomographic reconstruction from a fixed-camera focal  stack", "abstract": "This paper describes a novel approach to partially reconstruct high-resolution 4D light fields from a stack of differently focused photographs taken with a fixed camera. First, a focus map is calculated from this stack using a simple approach combining gradient detection and region expansion with graph-cut. Then, this focus map is converted into a depth map thanks to the calibration of the camera. We proceed after this with the tomographic reconstruction of the epipolar images by back-projecting the focused regions of the scene only. We call it masked back-projection. The angles of back-projection are calculated from the depth map. Thanks to the high angular resolution we achieve by suitably exploiting the image content captured over a large interval of focus distances, we are able to render puzzling perspective shifts although the original photographs were taken from a single fixed camera at a fixed position.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "A. Mousnier, E. Vural, C. Guillemot,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01895", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01895", "title": "\nNatural Notation for the Domestic Internet of Things", "abstract": "This study explores the use of natural language to give instructions that might be interpreted by Internet of Things (IoT) devices in a domestic `smart home' environment. We start from the proposition that reminders can be considered as a type of end-user programming, in which the executed actions might be performed either by an automated agent or by the author of the reminder. We conducted an experiment in which people wrote sticky notes specifying future actions in their home. In different conditions, these notes were addressed to themselves, to others, or to a computer agent.We analyse the linguistic features and strategies that are used to achieve these tasks, including the use of graphical resources as an informal visual language. The findings provide a basis for design guidance related to end-user development for the Internet of Things.", "subjects": "Human-Computer Interaction (cs.HC)", "authors": "Charith Perera, Saeed Aghaee, Alan Blackwell,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01883", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01883", "title": "\nRanking and significance of variable-length similarity-based time series  motifs", "abstract": "The detection of very similar patterns in a time series, commonly called motifs, has received continuous and increasing attention from diverse scientific communities. In particular, recent approaches for discovering similar motifs of different lengths have been proposed. In this work, we show that such variable-length similarity-based motifs cannot be directly compared, and hence ranked, by their normalized dissimilarities. Specifically, we find that length-normalized motif dissimilarities still have intrinsic dependencies on the motif length, and that lowest dissimilarities are particularly affected by this dependency. Moreover, we find that such dependencies are generally non-linear and change with the considered data set and dissimilarity measure. Based on these findings, we propose a solution to rank those motifs and measure their significance. This solution relies on a compact but accurate model of the dissimilarity space, using a beta distribution with three parameters that depend on the motif length in a non-linear way. We believe the incomparability of variable-length dissimilarities could go beyond the field of time series, and that similar modeling strategies as the one used here could be of help in a more broad context.", "subjects": "Learning (cs.LG)", "authors": "Joan Serr\u00e0, Isabel Serra, \u00c1lvaro Corral, Josep Lluis Arcos,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01874", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01874", "title": "\nExploring Ways To Mitigate Sensor-Based Smartphone Fingerprinting", "abstract": "Modern smartphones contain motion sensors, such as accelerometers and gyroscopes. These sensors have many useful applications; however, they can also be used to uniquely identify a phone by measuring anomalies in the signals, which are a result from manufacturing imperfections. Such measurements can be conducted surreptitiously in the browser and can be used to track users across applications, websites, and visits. We analyze techniques to mitigate such device fingerprinting either by calibrating the sensors to eliminate the signal anomalies, or by adding noise that obfuscates the anomalies. To do this, we first develop a highly accurate fingerprinting mechanism that combines multiple motion sensors and makes use of (inaudible) audio stimulation to improve detection. We then collect measurements from a large collection of smartphones and evaluate the impact of calibration and obfuscation techniques on the classifier accuracy.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Anupam Das, Nikita Borisov, Matthew Caesar,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01868", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01868", "title": "\nA Novel Tensor Robust PCA Approach for Background Subtraction from  Compressive Measurements", "abstract": "Background subtraction so far has been a fundamental and widely studied task in the field of video analysis, with a wide range of applications to video surveillance, teleconferencing and 3D modeling. Recently, due to the emergence of massive video data, background subtraction from compressive measurements (BSCM) provides a promising way for reducing the burden of storing and transmitting large video data. In this paper, we propose a novel tensor robust PCA approach for the task of BSCM. We utilize tensor low-rank approximation to eliminate the spatial-temporal redundancy in the video backgrounds, and design a multi-scale 3D total variation regularizer to enforce the smoothness of video foreground. Furthermore, we introduce the non-local self-similarity of video cuboid into our model to further reduce the video redundancy. The alternating direction method of multipliers (ADMM) is employed to solve the proposed optimization models. Extensive experiments on simulated and real-world videos demonstrate the superiority of the proposed models over the state-of-the-art approaches.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Wenfei Cao, Yao Wang, Jian Sun, Deyu Meng, Can Yang, Andrzej Cichocki, Zongben Xu,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01850", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01850", "title": "\nWhat is User Experience Really: towards a UX Conceptual Framework", "abstract": "For more then a decade the term User Experience (UX) has been highly debated and defined in many ways. However, often UX remains as a vague concept and it may be hard to understand the very nature of it. In this paper we aimed at providing a better understanding of this concept. We explored the multi-faceted UX literature, reviewing the current state-of- the-art knowledge and emphasizing the multi-dimensional nature of the concept. Based on the literature review we built a conceptual framework of UX using the elements that are linked to it and reported in different studies. To show the potential use of the framework, we examined the UX delivered by different phone applications on different mobile devices using the elements in the framework. Several interesting insights have been obtained in terms of how the phone applications deliver different UX. Our study opens up a promising line of investigating the contemporary meaning of UX.", "subjects": "Human-Computer Interaction (cs.HC)", "authors": "Stefan Hellweger, Xiaofeng Wang,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01847", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01847", "title": "\nEstimation of the parameters of an infectious disease model using neural  networks", "abstract": "In this paper, we propose a realistic mathematical model taking into account the mutual interference among the interacting populations. This model attempts to describe the control (vaccination) function as a function of the number of infective individuals, which is an improvement over the existing susceptible ?infective epidemic models. Regarding the growth of the epidemic as a nonlinear phenomenon we have developed a neural network architecture to estimate the vital parameters associated with this model. This architecture is based on a recently developed new class of neural networks known as co-operative and supportive neural networks. The application of this architecture to the present study involves preprocessing of the input data, and this renders an efficient estimation of the rate of spread of the epidemic. It is observed that the proposed new neural network outperforms a simple feed-forward neural network and polynomial regression.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "V. Sree Hari Rao, M. Naresh Kumar,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01838", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01838", "title": "\nEncoding Source Language with Convolutional Neural Network for Machine  Translation", "abstract": "The recently proposed neural network joint model (NNJM) (Devlin et al., 2014) augments the n-gram target language model with a heuristically chosen source context window, achieving state-of-the-art performance in SMT. In this paper, we give a more systematic treatment by summarizing the relevant source information through a convolutional architecture guided by the target information. With different guiding signals during decoding, our specifically designed convolution+gating architectures can pinpoint the parts of a source sentence that are relevant to predicting a target word, and fuse them with the context of entire source sentence to form a unified representation. This representation, together with target language words, are fed to a deep neural network (DNN) to form a stronger NNJM. Experiments on two NIST Chinese-English translation tasks show that the proposed model can achieve significant improvements over the previous NNJM by up to +1.01 BLEU points on average", "subjects": "Computation and Language (cs.CL)", "authors": "Fandong Meng, Zhengdong Lu, Mingxuan Wang, Hang Li, Wenbin Jiang, Qun Liu,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01837", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01837", "title": "\nCombinatorial rigidity and independence of generalized pinned  subspace-incidence constraint systems", "abstract": "Given a hypergraph with hyperedges and a set of emph, i.e. globally fixed subspaces in Euclidean space , a emph is the pair , with the constraint that each pin in lies on the subspace spanned by the point realizations in of vertices of the corresponding hyperedge of . We are interested in combinatorial characterization of pinned subspace-incidence systems that are emph, i.e. those systems that are guaranteed to generically yield a locally unique realization. As is customary, this is accompanied by a characterization of generic independence as well as rigidity. In a previous paper cite, we used pinned subspace-incidence systems towards solving the emph problem, i.e. dictionary learning with specified underlying hypergraph, and gave a combinatorial characterization of minimal rigidity for a more restricted version of pinned subspace-incidence system, with being a uniform hypergraph and pins in being 1-dimension subspaces. Moreover in a recent paper cite, the special case of pinned line incidence systems was used to model biomaterials such as cellulose and collagen fibrils in cell walls. In this paper, we extend the combinatorial characterization to general pinned subspace-incidence systems, with being a non-uniform hypergraph and pins in being subspaces with arbitrary dimension. As there are generally many data points per subspace in a dictionary learning problem, which can only be modeled with pins of dimension larger than , such an extension enables application to a much larger class of fitted dictionary learning problems.", "subjects": "Computational Geometry (cs.CG)", "authors": "Menghan Wang, Meera Sitharam,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01832", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01832", "title": "\nLinear Global Translation Estimation from Feature Tracks", "abstract": "This paper derives a novel linear position constraint for cameras seeing a common scene point, which leads to a direct linear method for global camera translation estimation. Unlike previous solutions, this method does not require connected camera-triplet graph, and works on images with weaker association. The final linear formulation does not involve the coordinates of scene points, which makes it efficient even for large scale data. We solve the linear equation based on robust norm, which makes our system more robust to outliers in essential matrices and feature correspondences. We experiment this method on both sequentially captured data and unordered Internet images. The experiments demonstrate its strength in robustness, accuracy, and efficiency.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Zhaopeng Cui, Nianjuan Jiang, Ping Tan,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01824", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01824", "title": "\nDeep Clustered Convolutional Kernels", "abstract": "Deep neural networks have recently achieved state of the art performance thanks to new training algorithms for rapid parameter estimation and new regularization methods to reduce overfitting. However, in practice the network architecture has to be manually set by domain experts, generally by a costly trial and error procedure, which often accounts for a large portion of the final system performance. We view this as a limitation and propose a novel training algorithm that automatically optimizes network architecture, by progressively increasing model complexity and then eliminating model redundancy by selectively removing parameters at training time. For convolutional neural networks, our method relies on iterative split/merge clustering of convolutional kernels interleaved by stochastic gradient descent. We present a training algorithm and experimental results on three different vision tasks, showing improved performance compared to similarly sized hand-crafted architectures.", "subjects": "Learning (cs.LG)", "authors": "Minyoung Kim, Luca Rigazio,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01820", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01820", "title": "\nLatent Hierarchical Model for Activity Recognition", "abstract": "We present a novel hierarchical model for human activity recognition. In contrast to approaches that successively recognize actions and activities, our approach jointly models actions and activities in a unified framework, and their labels are simultaneously predicted. The model is embedded with a latent layer that is able to capture a richer class of contextual information in both state-state and observation-state pairs. Although loops are present in the model, the model has an overall linear-chain structure, where the exact inference is tractable. Therefore, the model is very efficient in both inference and learning. The parameters of the graphical model are learned with a Structured Support Vector Machine (Structured-SVM). A data-driven approach is used to initialize the latent variables; therefore, no manual labeling for the latent states is required. The experimental results from using two benchmark datasets show that our model outperforms the state-of-the-art approach, and our model is computationally more efficient.", "subjects": "Robotics (cs.RO)", "authors": "Ninghang Hu, Gwenn Englebienne, Zhongyu Lou, Ben Kr\u00f6se,", "date": "2015-3-6"}, 
{"urllink": "http://arxiv.org/abs/1503.01817", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01817", "title": "\nThe New Data and New Challenges in Multimedia Research", "abstract": "We present the Yahoo Flickr Creative Commons 100 Million Dataset (YFCC100M), the largest public multimedia collection that has ever been released. The dataset contains a total of 100 million media objects, of which approximately 99.2 million are photos and 0.8 million are videos, all of which carry a Creative Commons license. Each media object in the dataset is represented by several pieces of metadata, e.g. Flickr identifier, owner name, camera, title, tags, geo, media source. The collection provides a comprehensive snapshot of how photos and videos were taken, described, and shared over the years, from the inception of Flickr in 2004 until early 2014. In this article we explain the rationale behind its creation, as well as the implications the dataset has for science, research, engineering, and development. We further present several new challenges in multimedia research that can now be expanded upon with our dataset.", "subjects": "Multimedia (cs.MM)", "authors": "Bart Thomee, David A. Shamma, Gerald Friedland, Benjamin Elizalde, Karl Ni, Douglas Poland, Damian Borth, Li-Jia Li,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01812", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01812", "title": "\nOntology-Based Quality Evaluation of Value Generalization Hierarchies  for Data Anonymization", "abstract": "In privacy-preserving data publishing, approaches using Value Generalization Hierarchies (VGHs) form an important class of anonymization algorithms. VGHs play a key role in the utility of published datasets as they dictate how the anonymization of the data occurs. For categorical attributes, it is imperative to preserve the semantics of the original data in order to achieve a higher utility. Despite this, semantics have not being formally considered in the specification of VGHs. Moreover, there are no methods that allow the users to assess the quality of their VGH. In this paper, we propose a measurement scheme, based on ontologies, to quantitatively evaluate the quality of VGHs, in terms of semantic consistency and taxonomic organization, with the aim of producing higher-quality anonymizations. We demonstrate, through a case study, how our evaluation scheme can be used to compare the quality of multiple VGHs and can help to identify faulty VGHs.", "subjects": "Databases (cs.DB)", "authors": "Vanessa Ayala-Rivera, Patrick McDonagh, Thomas Cerqueus, Liam Murphy,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01811", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01811", "title": "\nOptimally Combining Classifiers Using Unlabeled Data", "abstract": "We develop a worst-case analysis of aggregation of classifier ensembles for binary classification. The task of predicting to minimize error is formulated as a game played over a given set of unlabeled data (a transductive setting), where prior label information is encoded as constraints on the game. The minimax solution of this game identifies cases where a weighted combination of the classifiers can perform significantly better than any single classifier.", "subjects": "Learning (cs.LG)", "authors": "Akshay Balsubramani, Yoav Freund,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01804", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01804", "title": "\nFrequency Domain TOF: Encoding Object Depth in Modulation Frequency", "abstract": "Time of flight cameras may emerge as the 3-D sensor of choice. Today, time of flight sensors use phase-based sampling, where the phase delay between emitted and received, high-frequency signals encodes distance. In this paper, we present a new time of flight architecture that relies only on frequency---we refer to this technique as frequency-domain time of flight (FD-TOF). Inspired by optical coherence tomography (OCT), FD-TOF excels when frequency bandwidth is high. With the increasing frequency of TOF sensors, new challenges to time of flight sensing continue to emerge. At high frequencies, FD-TOF offers several potential benefits over phase-based time of flight methods.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Achuta Kadambi, Vage Taamazyan, Suren Jayasuriya, Ramesh Raskar,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01800", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01800", "title": "\nEmoNets: Multimodal deep learning approaches for emotion recognition in  video", "abstract": "The task of the emotion recognition in the wild (EmotiW) Challenge is to assign one of seven emotions to short video clips extracted from Hollywood style movies. The videos depict acted-out emotions under realistic conditions with a large degree of variation in attributes such as pose and illumination, making it worthwhile to explore approaches which consider combinations of features from multiple modalities for label assignment. In this paper we present our approach to learning several specialist models using deep learning techniques, each focusing on one modality. Among these are a convolutional neural network, focusing on capturing visual information in detected faces, a deep belief net focusing on the representation of the audio stream, a K-Means based \"bag-of-mouths\" model, which extracts visual features around the mouth region and a relational autoencoder, which addresses spatio-temporal aspects of videos. We explore multiple methods for the combination of cues from these modalities into one common classifier. This achieves a considerably greater accuracy than predictions from our strongest single-modality classifier. Our method was the winning submission in the 2013 EmotiW challenge and achieved a test set accuracy of 47.67% on the 2014 dataset.", "subjects": "Learning (cs.LG)", "authors": "Samira Ebrahimi Kahou, Xavier Bouthillier, Pascal Lamblin, Caglar Gulcehre, Vincent Michalski, Kishore Konda, S\u00e9bastien Jean, Pierre Froumenty, Aaron Courville, Pascal Vincent, Roland Memisevic, Christopher Pal, Yoshua Bengio,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01793", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01793", "title": "\nCorrect-by-synthesis reinforcement learning with temporal logic  constraints", "abstract": "We consider a problem on the synthesis of reactive controllers that optimize some a priori unknown performance criterion while interacting with an uncontrolled environment such that the system satisfies a given temporal logic specification. We decouple the problem into two subproblems. First, we extract a (maximally) permissive strategy for the system, which encodes multiple (possibly all) ways in which the system can react to the adversarial environment and satisfy the specifications. Then, we quantify the a priori unknown performance criterion as a (still unknown) reward function and compute an optimal strategy for the system within the operating envelope allowed by the permissive strategy by using the so-called maximin-Q learning algorithm. We establish both correctness (with respect to the temporal logic specifications) and optimality (with respect to the a priori unknown performance criterion) of this two-step technique for a fragment of temporal logic specifications. For specifications beyond this fragment, correctness can still be preserved, but the learned strategy may be sub-optimal. We present an algorithm to the overall problem, and demonstrate its use and computational requirements on a set of robot motion planning examples.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Min Wen, Ruediger Ehlers, Ufuk Topcu,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01752", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01752", "title": "\nEfficient Inverse Maintenance and Faster Algorithms for Linear  Programming", "abstract": "In this paper, we consider the following inverse maintenance problem: given and a number of rounds , we receive a diagonal matrix at round and we wish to maintain an efficient linear system solver for under the assumption does not change too rapidly. This inverse maintenance problem is the computational bottleneck in solving multiple optimization problems. We show how to solve this problem in amortized time per round, improving upon previous running times for solving this problem. Consequently, we obtain the fastest known running times for solving multiple problems including, linear programming, computing a rounding of a polytope, and sampling a point in a polytope. In particular given a feasible point in a linear program with variables, constraints, and constraint matrix , we show how to solve the linear program in time . We achieve our results through a novel combination of classic numerical techniques of low rank update, preconditioning, and fast matrix multiplication as well as recent work on subspace embeddings and spectral sparsification that we hope will be of independent interest.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Yin Tat Lee, Aaron Sidford,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01732", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01732", "title": "\nThe Contemporary Understanding of User Experience in Practice", "abstract": "User Experience (UX) has been a buzzword in agile literature in recent years. However, often UX remains as a vague concept and it may be hard to understand the very nature of it in the context of agile software development. This paper explores the multifaceted UX literature, emphasizes the multi-dimensional nature of the concept and organizes the current state-of-the-art knowledge. As a starting point to better understand the contemporary meaning of UX assigned by practitioners, we selected four UX blogs and performed an analysis using a framework derived from the literature review. The preliminary results show that the practitioners more often focus on interaction between product and user and view UX from design perspective predominantly. While the economical perspective receives little attention in literature, it is evident in practitioners writings. Our study opens up a promising line of request of the contemporary meaning of UX in practice.", "subjects": "Human-Computer Interaction (cs.HC)", "authors": "Stefan Hellweger, Xiaofeng Wang, Pekka Abrahamsson,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01723", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01723", "title": "\nModelling the Semantic Web using a Type System", "abstract": "We present an approach for modeling the Semantic Web as a type system. By using a type system, we can use symbolic representation for representing linked data. Objects with only data properties and references to external resources are represented as terms in the type system. Triples are represented symbolically using type constructors as the predicates. In our type system, we allow users to add analytics that utilize machine learning or knowledge discovery to perform inductive reasoning over data. These analytics can be used by the inference engine when performing reasoning to answer a query. Furthermore, our type system defines a means to resolve semantic heterogeneity on-the-fly.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Rod Moten,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01720", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01720", "title": "\nHow friends and non-determinism affect opinion dynamics", "abstract": "The Hegselmann-Krause system (HK system for short) is one of the most popular models for the dynamics of opinion formation in multiagent systems. Agents are modeled as points in opinion space, and at every time step, each agent moves to the mass center of all the agents within unit distance. The rate of convergence of HK systems has been the subject of several recent works. In this work, we investigate two natural variations of the HK system and their effect on the dynamics. In the first variation, we only allow pairs of agents who are friends in an underlying social network to communicate with each other. In the second variation, agents may not move exactly to the mass center but somewhere close to it. The dynamics of both variants are qualitatively very different from that of the classical HK system. Nevertheless, we prove that both these systems converge in polynomial number of non-trivial steps, regardless of the social network in the first variant and noise patterns in the second variant.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Arnab Bhattacharyya, Kirankumar Shiragur,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01713", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01713", "title": "\nNavigo: Interest Forwarding by Geolocations in Vehicular Named Data  Networking", "abstract": "This paper proposes Navigo, a location based packet forwarding mechanism for vehicular Named Data Networking (NDN). Navigo takes a radically new approach to address the challenges of frequent connectivity disruptions and sudden network changes in a vehicle network. Instead of forwarding packets to a specific moving car, Navigo aims to fetch specific pieces of data from multiple potential carriers of the data. The design provides (1) a mechanism to bind NDN data names to the producers' geographic area(s); (2) an algorithm to guide Interests towards data producers using a specialized shortest path over the road topology; and (3) an adaptive discovery and selection mechanism that can identify the best data source across multiple geographic areas, as well as quickly react to changes in the V2X network.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Giulio Grassi, Davide Pesavento, Giovanni Pau, Lixia Zhang, Serge Fdida,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01707", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01707", "title": "\nMapping-equivalence and oid-equivalence of single-function  object-creating conjunctive queries", "abstract": "Conjunctive database queries have been extended with a mechanism for object creation to capture important applications such as data exchange, data integration, and ontology-based data access. Object creation generates new object identifiers in the result, that do not belong to the set of constants in the source database. The new object identifiers can be also seen as Skolem terms. Hence, object-creating conjunctive queries can also be regarded as restricted second-order tuple-generating dependencies (SO tgds), considered in the data exchange literature. In this paper, we focus on the class of single-function object-creating conjunctive queries, or sifo CQs for short. We give a new characterization for oid-equivalence of sifo CQs that is simpler than the one given by Hull and Yoshikawa and places the problem in the complexity class NP. Our characterization is based on Cohen's equivalence notions for conjunctive queries with multiplicities. We also solve the logical entailment problem for sifo CQs, showing that also this problem belongs to NP. Results by Pichler et al. have shown that logical equivalence for more general classes of SO tgds is either undecidable or decidable with as yet unknown complexity upper bounds.", "subjects": "Databases (cs.DB)", "authors": "Angela Bonifati, Werner Nutt, Riccardo Torlone, Jan Van den Bussche,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01706", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01706", "title": "\nEfficient Farthest-Point Queries in Two-Terminal Series-Parallel  Networks", "abstract": "Consider the continuum of points along the edges of a network, i.e., a connected, undirected graph with positive edge weights. We measure the distance between these points in terms of the weighted shortest path distance, called the network distance. Within this metric space, we study farthest points and farthest distances. We introduce a data structure supporting queries for the farthest distance and the farthest points on two-terminal series-parallel networks. This data structure supports farthest-point queries in O(k + log n) time after O(n log p) construction time, where k is the number of farthest points, n is the size of the network, and p parallel operations are required to generate the network.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Carsten Grimm,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01676", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01676", "title": "\nWireless Sensor Network Virtualization: A Survey", "abstract": "Wireless Sensor Networks (WSNs) are the key components of the emerging Internet-of-Things (IoT) paradigm. They are now ubiquitous and used in a plurality of application domains. WSNs are still domain specific and usually deployed to support a specific application. However, as WSN nodes are becoming more and more powerful, it is getting more and more pertinent to research how multiple applications could share a very same WSN infrastructure. Virtualization is a technology that can potentially enable this sharing. This paper is a survey on WSN virtualization. It provides a comprehensive review of the state-of-the-art and an in-depth discussion of the research issues. We introduce the basics of WSN virtualization and motivate its pertinence with carefully selected scenarios. Existing works are presented in detail and critically evaluated using a set of requirements derived from the scenarios. The pertinent research projects are also reviewed. Several research issues are also discussed with hints on how they could be tackled.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Imran Khan, Fatna Belqasmi, Roch Glitho, Noel Crespi, Monique Morrow, Paul Polako,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01663", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01663", "title": "\nDimensionality Reduction of Massive Sparse Datasets Using Coresets", "abstract": "In this paper we present a practical solution with performance guarantees to the problem of dimensionality reduction for very large scale sparse matrices. We show applications of our approach to computing the low rank approximation (reduced SVD) of such matrices. Our solution uses coresets, which is a subset of scaled rows from the input matrix, that approximates the sub of squared distances from its rows to every -dimensional subspace in , up to a factor of . An open theoretical problem has been whether we can compute such a coreset that is independent of the input matrix and also a weighted subset of its rows. %An open practical problem has been whether we can compute a non-trivial approximation to the reduced SVD of very large databases such as the Wikipedia document-term matrix in a reasonable time. We answer this question affirmatively. % and demonstrate an algorithm that efficiently computes a low rank approximation of the entire English Wikipedia. Our main technical result is a novel technique for deterministic coreset construction that is based on a reduction to the problem of approximation for item frequencies.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Dan Feldman, Mikhail Volkov, Daniela Rus,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01657", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01657", "title": "\nColor Image Classification via Quaternion Principal Component Analysis  Network", "abstract": "The Principal Component Analysis Network (PCANet), which is one of the recently proposed deep learning architectures, achieves the state-of-the-art classification accuracy in various databases. However, the performance of PCANet may be degraded when dealing with color images. In this paper, a Quaternion Principal Component Analysis Network (QPCANet), which is an extension of PCANet, is proposed for color images classification. Compared to PCANet, the proposed QPCANet takes into account the spatial distribution information of color images and ensures larger amount of intra-class invariance of color images. Experiments conducted on different color image datasets such as Caltech-101, UC Merced Land Use, Georgia Tech face and CURet have revealed that the proposed QPCANet achieves higher classification accuracy than PCANet.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Rui Zeng, Jiasong Wu, Zhuhong Shao, Yang Chen, Lotfi Senhadji, Huazhong Shu,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01655", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01655", "title": "\nStudying the Wikipedia Hyperlink Graph for Relatedness and  Disambiguation", "abstract": "Hyperlinks and other relations in Wikipedia are a extraordinary resource which is still not fully understood. In this paper we study the different types of links in Wikipedia, and contrast the use of the full graph with respect to just direct links. We apply a well-known random walk algorithm on two tasks, word relatedness and named-entity disambiguation. We show that using the full graph is more effective than just direct links by a large margin, that non-reciprocal links harm performance, and that there is no benefit from categories and infoboxes, with coherent results on both tasks. We set new state-of-the-art figures for systems based on Wikipedia links, comparable to systems exploiting several information sources and/or supervised machine learning. Our approach is open source, with instruction to reproduce results, and amenable to be integrated with complementary text-based methods.", "subjects": "Computation and Language (cs.CL)", "authors": "Eneko Agirre, Ander Barrena, Aitor Soroa,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01647", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01647", "title": "\nDecentralized Recommender Systems", "abstract": "This paper proposes a decentralized recommender system by formulating the popular collaborative filleting (CF) model into a decentralized matrix completion form over a set of users. In such a way, data storages and computations are fully distributed. Each user could exchange limited information with its local neighborhood, and thus it avoids the centralized fusion. Advantages of the proposed system include a protection on user privacy, as well as better scalability and robustness. We compare our proposed algorithm with several state-of-the-art algorithms on the FlickerUserFavor dataset, and demonstrate that the decentralized algorithm can gain a competitive performance to others.", "subjects": "Information Retrieval (cs.IR)", "authors": "Zhangyang Wang, Xianming Liu, Shiyu Chang, Jiayu Zhou, Guo-Jun Qi, Thomas S. Huang,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01646", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01646", "title": "\nVideo-Based Facial Expression Recognition Using Local Directional Binary  Pattern", "abstract": "Automatic facial expression analysis is a challenging issue and influenced so many areas such as human computer interaction. Due to the uncertainties of the light intensity and light direction, the face gray shades are uneven and the expression recognition rate under simple Local Binary Pattern is not ideal and promising. In this paper we propose two state-of-the-art descriptors for person-independent facial expression recognition. First the face regions of the whole images in a video sequence are modeled with Volume Local Directional Binary pattern (VLDBP), which is an extended version of the LDBP operator, incorporating movement and appearance together. To make the survey computationally simple and easy to expand, only the co-occurrences of the Local Directional Binary Pattern on three orthogonal planes (LDBP-TOP) are debated. After extracting the feature vectors the K-Nearest Neighbor classifier was used to recognize the expressions. The proposed methods are applied to the videos of the Extended Cohn-Kanade database (CK+) and the experimental outcomes demonstrate that the offered techniques achieve more accuracy in comparison with the classic and traditional algorithms.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Sahar Hooshmand, Ali Jamali Avilaq, Amir Hossein Rezaie,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01640", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01640", "title": "\nBoxSup: Exploiting Bounding Boxes to Supervise Convolutional Networks  for Semantic Segmentation", "abstract": "Recent advanced approaches to semantic segmentation in general rely on deep convolutional networks trained with annotated segmentation masks. Such pixel-level supervision demands expensive labor, and thus limits the performance of deep networks that desire plenty of training data. In this paper, we make use of bounding box annotations to supervise convolutional networks for semantic segmentation. From these boxes, we estimate segmentation masks with the help of region proposals. These masks are used to update the convolutional network, which is in turn fed back to mask estimation. This procedure is iterated. This method, called \"BoxSup\", is thoroughly evaluated on the PASCAL VOC 2012 semantic segmentation benchmark. Our method with only bounding boxes as supervision shows results competitive with previous methods supervised by masks. Our method supervised by a few masks and a large amount of bounding boxes yields a new state-of-the-art result (71.0% mean IoU) on this challenging dataset.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Jifeng Dai, Kaiming He, Jian Sun,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01624", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01624", "title": "\nGDC 2: Compression of large collections of genomes", "abstract": "The fall of prices of the high-throughput genome sequencing changes the landscape of modern genomics. A number of large scale projects aimed at sequencing many human genomes are in progress. Genome sequencing also becomes an important aid in the personalized medicine. One of the significant side effects of this change is a necessity of storage and transfer of huge amounts of genomic data. In this paper we deal with the problem of compression of large collections of complete genomic sequences. We propose an algorithm that is able to compress the collection of 1092 human diploid genomes about 9,500 times. This result is about 4 times better than what is offered by the other existing compressors. Moreover, our algorithm is very fast as it processes the data with speed 200MB/s on a modern workstation. In a consequence the proposed algorithm allows storing the complete genomic collections at low cost, e.g., the examined collection of 1092 human genomes needs only about 700MB when compressed, what can be compared to about 6.7 TB of uncompressed FASTA files. The source code is available at this http URL&amp;project=gdc&amp;subpage=about.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Sebastian Deorowicz, Agnieszka Danek, Marcin Niemiec,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01620", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01620", "title": "\nGaussian Mixture Model Based Contrast Enhancement", "abstract": "In this paper, a method for enhancing low contrast images is proposed. This method, called Gaussian Mixture Model based Contrast Enhancement (GMMCE), brings into play the Gaussian mixture modeling of histograms to model the content of the images. Based on the fact that each homogeneous area in natural images has a Gaussian-shaped histogram, it decomposes the narrow histogram of low contrast images into a set of scaled and shifted Gaussians. The individual histograms are then stretched by increasing their variance parameters, and are diffused on the entire histogram by scattering their mean parameters, to build a broad version of the histogram. The number of Gaussians as well as their parameters are optimized to set up a GMM with lowest approximation error and highest similarity to the original histogram. Compared to the existing histogram-based methods, the experimental results show that the quality of GMMCE enhanced pictures are mostly consistent and outperform other benchmark methods. Additionally, the computational complexity analysis show that GMMCE is a low complexity method.", "subjects": "Multimedia (cs.MM)", "authors": "Mohsen Abdoli, Hossein Sarikhani, Mohammad Ghanbari, Patrice Brault,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01613", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01613", "title": "\nResolution space for random 3-SAT", "abstract": "Resolution is a rule of inference for boolean formulas in conjunctive normal form. Specifically, if the formula contains the clauses and then any satisfying assignment must also satisfy the clause . Any unsatisfiable formula can be used to derive the empty clause using repeated applications of the resolution rule. Such a derivation is called a resolution refutation for the formula. The total resolution space of an unsatisfiable formula is the least amount of memory required to verify any resolution refutation for the formula. We show that with high probability the resolution space of random instances of 3-SAT (chosen from a distribution where we know the formula is unsatifiable w.h.p.), the total resolution space is quadratic, which is worst possible up to a constant. Bonacina, Galesi, and Thapen proved the same result for -SAT when .", "subjects": "Computational Complexity (cs.CC)", "authors": "Patrick Bennett, Mike Molloy,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01604", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01604", "title": "\nMSOL-Definability Equals Recognizability for Halin Graphs and Bounded  Degree $k$-Outerplanar Graphs", "abstract": "One of the most famous algorithmic meta-theorems states that every graph property that can be defined by a sentence in counting monadic second order logic (CMSOL) can be checked in linear time for graphs of bounded treewidth, which is known as Courcelle's Theorem. These algorithms are constructed as finite state tree automata, and hence every CMSOL-definable graph property is recognizable. Courcelle also conjectured that the converse holds, i.e. every recognizable graph property is definable in CMSOL for graphs of bounded treewidth. We prove this conjecture for a number of special cases in a stronger form. That is, we show that each recognizable property is definable in MSOL, i.e. the counting operation is not needed in our expressions. We give proofs for Halin graphs, bounded degree -outerplanar graphs and some related graph classes. We furthermore show that the conjecture holds for any graph class that admits tree decompositions that can be defined in MSOL, thus providing a useful tool for future proofs.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Lars Jaffke, Hans L. Bodlaender,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01596", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01596", "title": "\nLarge-Scale Distributed Bayesian Matrix Factorization using Stochastic  Gradient MCMC", "abstract": "Despite having various attractive qualities such as high prediction accuracy and the ability to quantify uncertainty and avoid over-fitting, Bayesian Matrix Factorization has not been widely adopted because of the prohibitive cost of inference. In this paper, we propose a scalable distributed Bayesian matrix factorization algorithm using stochastic gradient MCMC. Our algorithm, based on Distributed Stochastic Gradient Langevin Dynamics, can not only match the prediction accuracy of standard MCMC methods like Gibbs sampling, but at the same time is as fast and simple as stochastic gradient descent. In our experiments, we show that our algorithm can achieve the same level of prediction accuracy as Gibbs sampling an order of magnitude faster. We also show that our method reduces the prediction error as fast as distributed stochastic gradient descent, achieving a 4.1% improvement in RMSE for the Netflix dataset and an 1.8% for the Yahoo music dataset.", "subjects": "Learning (cs.LG)", "authors": "Sungjin Ahn, Anoop Korattikara, Nathan Liu, Suju Rajan, Max Welling,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01588", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01588", "title": "\nAdaptively Secure Coin-Flipping, Revisited", "abstract": "The full-information model was introduced by Ben-Or and Linial in 1985 to study collective coin-flipping: the problem of generating a common bounded-bias bit in a network of players with faults. They showed that the majority protocol can tolerate adaptive corruptions, and conjectured that this is optimal in the adaptive setting. Lichtenstein, Linial, and Saks proved that the conjecture holds for protocols in which each player sends a single bit. Their result has been the main progress on the conjecture in the last 30 years. In this work we revisit this question and ask: what about protocols involving longer messages? Can increased communication allow for a larger fraction of faulty players? We introduce a model of strong adaptive corruptions, where in each round, the adversary sees all messages sent by honest parties and, based on the message content, decides whether to corrupt a party (and intercept his message) or not. We prove that any one-round coin-flipping protocol, regardless of message length, is secure against at most strong adaptive corruptions. Thus, increased message length does not help in this setting. We then shed light on the connection between adaptive and strongly adaptive adversaries, by proving that for any symmetric one-round coin-flipping protocol secure against adaptive corruptions, there is a symmetric one-round coin-flipping protocol secure against strongly adaptive corruptions. Returning to the standard adaptive model, we can now prove that any symmetric one-round protocol with arbitrarily long messages can tolerate at most adaptive corruptions. At the heart of our results there is a new technique for converting any one-round secure protocol with arbitrarily long messages into one with messages of bits. This technique may be of independent interest.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Shafi Goldwasser, Yael Tauman Kalai, Sunoo Park,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01578", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01578", "title": "\nScalable Iterative Algorithm for Robust Subspace Clustering", "abstract": "Subspace clustering (SC) is a popular method for dimensionality reduction of high-dimensional data, where it generalizes Principal Component Analysis (PCA). Recently, several methods have been proposed to enhance the robustness of PCA and SC, while most of them are computationally very expensive, in particular, for high dimensional large-scale data. In this paper, we develop much faster iterative algorithms for SC, incorporating robustness using a -norm objective. The known implementations for optimizing the objective would be costly due to the alternative optimization of two separate objectives: optimal cluster-membership assignment and robust subspace selection, while the substitution of one process to a faster surrogate can cause failure in convergence. To address the issue, we use a simplified procedure requiring efficient matrix-vector multiplications for subspace update instead of solving an expensive eigenvector problem at each iteration, in addition to release nested robust PCA loops. We prove that the proposed algorithm monotonically converges to a local minimum with approximation guarantees, e.g., it achieves 2-approximation for the robust PCA objective. In our experiments, the proposed algorithm is shown to converge at an order of magnitude faster than known algorithms optimizing the same objective, and have outperforms prior subspace clustering methods in accuracy and running time for MNIST dataset.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Sanghyuk Chun, Yung-Kyun Noh, Jinwoo Shin,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01566", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01566", "title": "\nCoordinated Two-Tier Heterogeneous Cellular Networks with Leakage Based  Beamforming", "abstract": "In this paper we demonstrate the rate gains achieved by two-tier heterogeneous cellular networks (HetNets) with varying degrees of coordination between macrocell and microcell base stations (BSs). We show that without the presence of coordination, network densification does not provide any gain in the sum rate and rapidly decreases the mean per-user signal-to-interference-plus-noise-ratio (SINR). Our results show that coordination reduces the rate of SINR decay with increasing numbers of microcell BSs in the system. Validity of the analytically approximated mean per-user SINR over a wide range of signal-to-noise-ratio (SNR) is demonstrated via comparison with the simulated results.", "subjects": "Information Theory (cs.IT)", "authors": "Harsh Tataria, Mansoor Shafi, Peter J. Smith, Pawel A. Dmochowski,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01563", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01563", "title": "\nConvex Optimization for Parallel Energy Minimization", "abstract": "Energy minimization has been an intensely studied core problem in computer vision. With growing image sizes (2D and 3D), it is now highly desirable to run energy minimization algorithms in parallel. But many existing algorithms, in particular, some efficient combinatorial algorithms, are difficult to par-allelize. By exploiting results from convex and submodular theory, we reformulate the quadratic energy minimization problem as a total variation denoising problem, which, when viewed geometrically, enables the use of projection and reflection based convex methods. The resulting min-cut algorithm (and code) is conceptually very simple, and solves a sequence of TV denoising problems. We perform an extensive empirical evaluation comparing state-of-the-art combinatorial algorithms and convex optimization techniques. On small problems the iterative convex methods match the combinatorial max-flow algorithms, while on larger problems they offer other flexibility and important gains: (a) their memory footprint is small; (b) their straightforward parallelizability fits multi-core platforms; (c) they can easily be warm-started; and (d) they quickly reach approximately good solutions, thereby enabling faster \"inexact\" solutions. A key consequence of our approach based on submodularity and convexity is that it is allows to combine any arbitrary combinatorial or convex methods as subroutines, which allows one to obtain hybrid combinatorial and convex optimization algorithms that benefit from the strengths of both.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "K. S. Sesh Kumar, Alvaro Barbero, Stefanie Jegelka, Suvrit Sra, Francis Bach,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01558", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01558", "title": "\nWhat's Cookin'? Interpreting Cooking Videos using Text, Speech and  Vision", "abstract": "We present a novel method for aligning a sequence of instructions to a video of someone carrying out a task. In particular, we focus on the cooking domain, where the instructions correspond to the recipe. Our technique relies on an HMM to align the recipe steps to the (automatically generated) speech transcript. We then refine this alignment using a state-of-the-art visual food detector, based on a deep convolutional neural network. We show that our technique outperforms simpler techniques based on keyword spotting. It also enables interesting applications, such as automatically illustrating recipes with keyframes, and searching within a video for events of interest.", "subjects": "Computation and Language (cs.CL)", "authors": "Jonathan Malmaud, Jonathan Huang, Vivek Rathod, Nick Johnston, Andrew Rabinovich, Kevin Murphy,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01557", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01557", "title": "\nSupervised Discrete Hashing", "abstract": "Recently, learning based hashing techniques have attracted broad research interests due to the resulting efficient storage and retrieval of images, videos, documents, etc. However, a major difficulty of learning to hash lies in handling the discrete constraints imposed on the needed hash codes, which typically makes hash optimizations very challenging (NP-hard in general). In this work, we propose a new supervised hashing framework, where the learning objective for hashing is to make the optimal binary hash codes for classification. By introducing an auxiliary variable, we reformulate the objective such that it can be solved substantially efficiently by using a regularization algorithm. One of the key steps in the algorithm is to solve the regularization sub-problem associated with the NP-hard binary optimization. We show that with cyclic coordinate descent, the sub-problem admits an analytical solution. As such, a high-quality discrete solution can eventually be obtained in an efficient computing manner, which enables to tackle massive datasets. We evaluate the proposed approach, dubbed Supervised Discrete Hashing (SDH), on four large image datasets, and demonstrate that SDH outperforms the state-of-the-art hashing methods in large-scale image retrieval.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Fumin Shen, Chunhua Shen, Wei Liu, Heng Tao Shen,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01549", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01549", "title": "\nVisualization of Clandestine Labs from Seizure Reports: Thematic Mapping  and Data Mining Research Directions", "abstract": "The problem of spatiotemporal event visualization based on reports entails subtasks ranging from named entity recognition to relationship extraction and mapping of events. We present an approach to event extraction that is driven by data mining and visualization goals, particularly thematic mapping and trend analysis. This paper focuses on bridging the information extraction and visualization tasks and investigates topic modeling approaches. We develop a static, finite topic model and examine the potential benefits and feasibility of extending this to dynamic topic modeling with a large number of topics and continuous time. We describe an experimental test bed for event mapping that uses this end-to-end information retrieval system, and report preliminary results on a geoinformatics problem: tracking of methamphetamine lab seizure events across time and space.", "subjects": "Information Retrieval (cs.IR)", "authors": "William Hsu, Mohammed Abduljabbar, Ryuichi Osuga, Max Lu, Wesam Elshamy,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01547", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01547", "title": "\nBinary-Decision-Diagrams for Set Abstraction", "abstract": "Whether explicit or implicit, sets are a critical part of many pieces of software. As a result, it is necessary to develop abstractions of sets for the purposes of abstract interpretation, model checking, and deductive verification. However, the construction of effective abstractions for sets is challenging because they are a higher-order construct. It is necessary to reason about contents of sets as well as relationships between sets. This paper presents a new abstraction for sets that is based on binary decision diagrams. It is optimized for precisely and efficiently representing relations between sets while still providing limited support for content reasoning.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Arlen Cox,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01546", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01546", "title": "\n#FoodPorn: Obesity Patterns in Culinary Interactions", "abstract": "We present a large-scale analysis of Instagram pictures taken at 164,753 restaurants by millions of users. Motivated by the obesity epidemic in the United States, our aim is three-fold: (i) to assess the relationship between fast food and chain restaurants and obesity, (ii) to better understand people's thoughts on and perceptions of their daily dining experiences, and (iii) to reveal the nature of social reinforcement and approval in the context of dietary health on social media. When we correlate the prominence of fast food restaurants in US counties with obesity, we find the Foursquare data to show a greater correlation at 0.424 than official survey data from the County Health Rankings would show. Our analysis further reveals a relationship between small businesses and local foods with better dietary health, with such restaurants getting more attention in areas of lower obesity. However, even in such areas, social approval favors the unhealthy foods high in sugar, with donut shops producing the most liked photos. Thus, the dietary landscape our study reveals is a complex ecosystem, with fast food playing a role alongside social interactions and personal perceptions, which often may be at odds.", "subjects": "Computers and Society (cs.CY)", "authors": "Yelena Mejova, Hamed Haddadi, Anastasios Noulas, Ingmar Weber,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01543", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01543", "title": "\nLearning to rank in person re-identification with metric ensembles", "abstract": "We propose an effective structured learning based approach to the problem of person re-identification which outperforms the current state-of-the-art on most benchmark data sets evaluated. Our framework is built on the basis of multiple low-level hand-crafted and high-level visual features. We then formulate two optimization algorithms, which directly optimize evaluation measures commonly used in person re-identification, also known as the Cumulative Matching Characteristic (CMC) curve. Our new approach is practical to many real-world surveillance applications as the re-identification performance can be concentrated in the range of most practical importance. The combination of these factors leads to a person re-identification system which outperforms most existing algorithms. More importantly, we advance state-of-the-art results on person re-identification by improving the rank- recognition rates from to on the iLIDS benchmark, to on the PRID2011 benchmark, to on the VIPeR benchmark, to on the CUHK01 benchmark and to on the CUHK03 benchmark.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Sakrapee Paisitkriangkrai, Chunhua Shen, Anton van den Hengel,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01539", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01539", "title": "\nA Game-Theoretic Analysis of User Behaviors in Crowdsourced Wireless  Community Networks", "abstract": "A crowdsourced wireless community network can effectively alleviate the limited coverage issue of Wi-Fi access points (APs), by encouraging individuals (users) to share their private residential Wi-Fi APs with each other. This paper presents the first study on the users' joint membership selection and network access problem in such a network. Specifically, we formulate the problem as a two-stage dynamic game: Stage I corresponds to a membership selection game, in which each user chooses his membership type; Stage II corresponds to a set of network access games, in each of which each user decides his WiFi connection time on the AP at his current location. We analyze the Subgame Perfect Equilibrium (SPE) systematically, and study whether and how best response dynamics can reach the equilibrium. Through numerical studies, we further explore how the equilibrium changes with the users' mobility patterns and network access evaluations. We show that a user with a more popular home location, a smaller travel time, or a smaller network access evaluation is more likely to choose a specific type of membership called Bill. We further demonstrate how the network operator can optimize its pricing and incentive mechanism based on the game equilibrium analysis in this work.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Qian Ma, Lin Gao, Ya-Feng Liu, Jianwei Huang,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01535", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01535", "title": "\nManaging Relocation and Delay in Container Terminals with Flexible  Service Policies", "abstract": "We introduce a new model and mathematical formulation for planning crane moves in the storage yard of container terminals. Our objective is to develop a tool that captures customer centric elements, especially service time, and helps operators to manage costly relocation moves. Our model incorporates several practical details and provides port operators with expanded capabilities including planning repositioning moves in off-peak hours, controlling wait times of each customer as well as total service time, optimizing the number of relocations and wait time jointly, and optimizing simultaneously the container stacking and retrieval process. We also study a class of flexible service policies which allow for out-of-order retrieval. We show that under such flexible policies, we can decrease the number of relocations and retrieval delays without creating inequities.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Setareh Borjian, Vahideh H. Manshadi, Cynthia Barnhart, Patrick Jaillet,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01532", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01532", "title": "\nDeep Temporal Appearance-Geometry Network for Facial Expression  Recognition", "abstract": "Temporal information can provide useful features for recognizing facial expressions. However, to manually design useful features requires a lot of effort. In this paper, to reduce this effort, a deep learning technique which is regarded as a tool to automatically extract useful features from raw data, is adopted. Our deep network is based on two different models. The first deep network extracts temporal geometry features from temporal facial landmark points, while the other deep network extracts temporal appearance features from image sequences . These two models are combined in order to boost the performance of the facial expression recognition. Through several experiments, we showed that the two models cooperate with each other. As a result, we achieved superior performance to other state-of-the-art methods in CK+ and Oulu-CASIA databases. Furthermore, one of the main contributions of this paper is that our deep network catches the facial action points automatically.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Heechul Jung, Sihaeng Lee, Sunjeong Park, Injae Lee, Chunghyun Ahn, Junmo Kim,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01531", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01531", "title": "\nSpectral Clustering by Ellipsoid and Its Connection to Separable  Nonnegative Matrix Factorization", "abstract": "This paper proposes a variant of the normalized cut algorithm for spectral clustering. Although the normalized cut algorithm applies the K-means algorithm to the eigenvectors of a normalized graph Laplacian for finding clusters, our algorithm instead uses a minimum volume enclosing ellipsoid for them. We show that the algorithm shares similarity with the ellipsoidal rounding algorithm for separable nonnegative matrix factorization. Our theoretical insight implies that the algorithm can serve as a bridge between spectral clustering and separable NMF. The K-means algorithm has the issues in that the choice of initial points affects the construction of clusters and certain choices result in poor clustering performance. The normalized cut algorithm inherits these issues since K-means is incorporated in it, whereas the algorithm proposed here does not. An empirical study is presented to examine the performance of the algorithm.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Tomohiko Mizutani,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01524", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01524", "title": "\nGenetic optimization of the Hyperloop route through the Grapevine", "abstract": "We demonstrate a genetic algorithm that employs a versatile fitness function to optimize route selection for the Hyperloop, a proposed high speed passenger transportation system.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "Casey J. Handmer,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01514", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01514", "title": "\nThe Role of Data Cap in Optimal Two-part Network Pricing", "abstract": "Internet services are traditionally priced at flat rates; however, many Internet service providers (ISPs) have recently shifted towards two-part tariffs where a data cap is imposed to restrain data demand from heavy users and usage over the data cap is charged based on a per-unit fee. Although two-part tariff could generally increase the revenue for ISPs and has been supported by the FCC chairman, the role of data cap and its revenue-optimal and welfare-optimal pricing structures are not well understood. In this paper, we study the impact of data cap on the optimal two-part pricing schemes for congestion-prone service markets, e.g., broadband or cloud services. We model users' demand and preferences over pricing and congestion alternatives and derive the market share and congestion of service providers under a market equilibrium. Based on the equilibrium model, we characterize the two-part structure of the revenue-optimal and welfare-optimal pricing schemes. Our results reveal that 1) the data cap provides a mechanism for ISPs to transition from flat-rate to pay-as-you-go type of schemes, 2) with the growing data demand and network capacity, revenue-optimal pricing moves towards usage-based schemes with diminishing data caps, and 3) the structure of the welfare-optimal tariff comprises lower fees and data cap than those of the revenue-optimal counterpart, suggesting that regulators might want to promote usage-based pricing but regulate the per-unit fees. Our results could help providers design revenue-optimal pricing schemes and guide regulatory authorities to legislate desirable regulations.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Xin Wang, Richard T.B. Ma, Yinlong Xu,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01508", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01508", "title": "\nDo We Need More Training Data?", "abstract": "Datasets for training object recognition systems are steadily increasing in size. This paper investigates the question of whether existing detectors will continue to improve as data grows, or saturate in performance due to limited model complexity and the Bayes risk associated with the feature spaces in which they operate. We focus on the popular paradigm of discriminatively trained templates defined on oriented gradient features. We investigate the performance of mixtures of templates as the number of mixture components and the amount of training data grows. Surprisingly, even with proper treatment of regularization and \"outliers\", the performance of classic mixture models appears to saturate quickly (10 templates and 100 positive training examples per template). This is not a limitation of the feature space as compositional mixtures that share template parameters via parts and that can synthesize new templates not encountered during training yield significantly better performance. Based on our analysis, we conjecture that the greatest gains in detection performance will continue to derive from improved representations and learning algorithms that can make efficient use of large datasets.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Xiangxin Zhu, Carl Vondrick, Charless Fowlkes, Deva Ramanan,", "date": "2015-3-5"}, 
{"urllink": "http://arxiv.org/abs/1503.01489", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01489", "title": "\nOn Flattenability of Graphs", "abstract": "We first show, for general -norms, the equivalence between -flattenability of and the convexity of -dimensional, inherent Cayley configuration spaces for all subgraphs of (for the norm, one direction was proven before). As a corollary, it follows that both properties are minor-closed for general norms. Using the natural notions of genericity and rigidity matrices introduced by Kitson for frameworks in , we show that: -flattenability is not a generic property of frameworks (in arbitrary dimension), and neither is the convexity of Cayley configuration spaces over specified non-edges of the -dimensional framework; is -flattenable if all its generic frameworks are; existence of one, however is equivalent to independence of the rows of its rigidity matrix -- a generic property of frameworks -- in -dimensions; and rank of in the -dimensional rigidity matroid is equal to the dimension of the projection of the -dimensional stratum of the cone on the edges of . Finally, we give stronger results for specific norms for : we show that 2-flattenable graphs for the -norm (and -norm) are a larger class than 2-flattenable graphs for Euclidean -norm case; and prove further results towards characterizing 2-flattenability in the -norm.", "subjects": "Computational Geometry (cs.CG)", "authors": "Meera Sitharam, Joel Willoughby,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01488", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01488", "title": "\nRandom Serial Dictatorship versus Probabilistic Serial Rule: A Tale of  Two Random Mechanisms", "abstract": "For assignment problems where agents, specifying ordinal preferences, are allocated indivisible objects, two widely studied randomized mechanisms are the Random Serial Dictatorship (RSD) and Probabilistic Serial Rule (PS). These two mechanisms both have desirable economic and computational properties, but the outcomes they induce can be incomparable in many instances, thus creating challenges in deciding which mechanism to adopt in practice. In this paper we first look at the space of lexicographic preferences and show that, as opposed to the general preference domain, RSD satisfies envyfreeness. Moreover, we show that although under lexicographic preferences PS is strategyproof when the number of objects is less than or equal agents, it is strictly manipulable when there are more objects than agents. In the space of general preferences, we provide empirical results on the (in)comparability of RSD and PS, analyze economic properties, and provide further insights on the applicability of each mechanism in different application domains.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Hadi Hosseini, Kate Larson, Robin Cohen,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01484", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01484", "title": "\np-norm-like Constraint Leaky LMS Algorithm for Sparse System  Identification", "abstract": "In this paper, we propose a novel leaky least mean square (leaky LMS, LLMS) algorithm which employs a p-norm-like constraint to force the solution to be sparse in the application of system identification. As an extension of the LMS algorithm which is the most widely-used adaptive filtering technique, the LLMS algorithm has been proposed for decades, due to the deteriorated performance of the standard LMS algorithm with highly correlated input. However, both ofthem do not consider the sparsity information to have better behaviors. As a sparse-aware modification of the LLMS, our proposed Lplike-LLMS algorithm, incorporates a p-norm-like penalty into the cost function of the LLMS to obtain a shrinkage in the weight update, which then enhances the performance in sparse system identification settings. The simulation results show that the proposed algorithm improves the performance of the filter in sparse system settings in the presence of noisy input signals.", "subjects": "Systems and Control (cs.SY)", "authors": "Yong Feng, Rui Zeng, Jiasong Wu,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01446", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01446", "title": "\nPredicting opponent team activity in a RoboCup environment", "abstract": "The goal of this project is to predict the opponent's configuration in a RoboCup SSL environment. For simplicity, a Markov model assumption is made such that the predicted formation of the opponent team only depends on its current formation. The field is divided into a grid and a robot state per player is created with information about its position and its velocity. To gather a more general sense of what the opposing team is doing, the state also incorporates the team's average position (centroid). All possible state transitions are stored in a hash table that requires minimum storage space. The table is populated with transition probabilities that are learned by reading vision packages and counting the state transitions regardless of the specific robot player. Therefore, the computation during the game is reduced to interpreting a given vision package to assign each player to a state, and looking for the most likely state it will transition to. The confidence of the predicted team's formation is the product of each individual player's probability. The project is noteworthy in that it minimizes the time and space complexity requirements for opponent's moves prediction.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Selene Baez,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01444", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01444", "title": "\nPartial Sum Minimization of Singular Values in Robust PCA: Algorithm and  Applications", "abstract": "Robust Principal Component Analysis (RPCA) via rank minimization is a powerful tool for recovering underlying low-rank structure of clean data corrupted with sparse noise/outliers. In many low-level vision problems, not only it is known that the underlying structure of clean data is low-rank, but the exact rank of clean data is also known. Yet, when applying conventional rank minimization for those problems, the objective function is formulated in a way that does not fully utilize a priori target rank information about the problems. This observation motivates us to investigate whether there is a better alternative solution when using rank minimization. In this paper, instead of minimizing the nuclear norm, we propose to minimize the partial sum of singular values, which implicitly encourages the target rank constraint in rank minimization. Our experimental analyses show that, when the number of samples is deficient, our approach leads to a higher success rate than conventional rank minimization, while the solutions obtained by the two approaches are almost identical when the number of samples is more than sufficient. We apply our approach to various low-level vision problems, e.g. high dynamic range imaging, motion edge detection, photometric stereo, image alignment and recovery, and show that our results outperform those obtained by the conventional nuclear norm rank minimization method.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Tae-Hyun Oh, Yu-Wing Tai, Jean-Charles Bazin, Hyeongwoo Kim, In So Kweon,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01440", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01440", "title": "\nA Blind Zone Alert System based on Intra-vehicular Wireless Sensor  Networks", "abstract": "Due to the increasing number of sensors deployed in modern vehicles, Intra-Vehicular Wireless Sensor Networks (IVWSNs) have recently received a lot of attention in the automotive industry as they can reduce the amount of wiring harness inside a vehicle. By removing the wires, car manufacturers can reduce the weight of a vehicle and improve engine performance, fuel economy, and reliability. In addition to these direct benefits, an IVWSN is a versatile platform that can support other vehicular applications as well. An example application, known as a Side Blind Zone Alert (SBZA) system, which monitors the blind zone of the vehicle and alerts the driver in a timely manner to prevent collisions, is discussed in this paper. The performance of the IVWSN-based SBZA system is evaluated via real experiments conducted on two test vehicles. Our results show that the proposed system can achieve approximately 95% to 99% detection rate with less than 15% false alarm rate. Compared to commercial systems using radars or cameras, the main benefit of the IVWSN-based SBZA is substantially lower cost.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Jiun-Ren Lin, Timothy Talty, Ozan K. Tonguz,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01438", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01438", "title": "\nScalable Methods for Adaptively Seeding a Social Network", "abstract": "In recent years, social networking platforms have developed into extraordinary channels for spreading and consuming information. Along with the rise of such infrastructure, there is continuous progress on techniques for spreading information effectively through influential users. In many applications, one is restricted to select influencers from a set of users who engaged with the topic being promoted, and due to the structure of social networks, these users often rank low in terms of their influence potential. An alternative approach one can consider is an adaptive method which selects users in a manner which targets their influential neighbors. The advantage of such an approach is that it leverages the friendship paradox in social networks: while users are often not influential, they often know someone who is. Despite the various complexities in such optimization problems, we show that scalable adaptive seeding is achievable. In particular, we develop algorithms for linear influence models with provable approximation guarantees that can be gracefully parallelized. To show the effectiveness of our methods we collected data from various verticals social network users follow. For each vertical, we collected data on the users who responded to a certain post as well as their neighbors, and applied our methods on this data. Our experiments show that adaptive seeding is scalable, and importantly, that it obtains dramatic improvements over standard approaches of information dissemination.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Thibaut Horel, Yaron Singer,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01436", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01436", "title": "\nA Differential Geometric Approach to Classification", "abstract": "We use differential geometry techniques to study the classification problem to estimate the conditional label probability for learning a plug-in classifier. In particular, we propose a geometric regularization technique to find the optimal hypersurface corresponding to the estimator of . The regularization term measures the total Riemannian curvature of the hypersurface corresponding to the estimator of , based on the intuition that overfitting corresponds to fast oscillations and hence large curvature of the estimator. We use gradient flow type methods to move from an initial estimator towards a minimizer of a penalty function that penalizes both the deviation of the hypersurface from the training data and the total curvature of the hypersurface. We establish Bayes consistency for our algorithm under mild initialization assumptions and implement a discrete version of this algorithm. In experiments for binary classification, our implementation compares favorably to several widely used classification methods.", "subjects": "Learning (cs.LG)", "authors": "Qinxun Bai, Steven Rosenberg, Stan Sclaroff,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01428", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01428", "title": "\nProbabilistic Label Relation Graphs with Ising Models", "abstract": "We consider classification problems in which the label space has structure. A common example is hierarchical label spaces, corresponding to the case where one label subsumes another (e.g., animal subsumes dog). But labels can also be mutually exclusive (e.g., dog vs cat) or unrelated (e.g., furry, carnivore). In our prior work, we introduced the notion of a HEX graph, which is a way of encoding hierarchy and exclusion relations between labels into a conditional random field (CRF). We combined the CRF with a deep neural network (DNN), resulting in state of the art results when applied to visual object classification problems where the training labels were drawn from different levels of the ImageNet hierarchy (e.g., an image might be labeled with the basic level category ``dog'', rather than the more specific label ``husky''). In this paper, we extend the HEX model to allow for soft or probabilistic relations between labels, which is useful when there is uncertainty about the relationship between two labels (e.g., a penguin is ``sort of'' a subclass of birds, but not to the same degree as a robin or sparrow). We call our new model pHEX, for probabilistic HEX. We show that the pHEX graph can be converted to an Ising model, which allows us to use existing off-the-shelf inference methods (in contrast to the HEX method, which needed specialized inference algorithms). Experimental results show significant improvements in a number of large-scale object classification tasks.", "subjects": "Learning (cs.LG)", "authors": "Nan Ding, Jia Deng, Kevin Murphy, Hartmut Neven,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01427", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01427", "title": "\nThe business model bank: conceptualizing a database structure for  large-sample study of an emerging management concept", "abstract": "The business model represents an increasingly important management concept. However, progress in research related to the concept is currently inhibited from inconsistencies in terms of formalizing and therewith also empirically measuring the business model concept. Taking this as a starting point, this paper offers a conceptualization for building a scalable database to rigorously capture large samples of business models. The following contributions are made: First, we suggest a concept for dimensions to be modeled in the database. Second, we discuss issues critical to the scalability of such an endeavor. Third, we point to empirical and simulation-based studies enabled by the population of such a database. Considerations for theory and practice are offered.", "subjects": "Computers and Society (cs.CY)", "authors": "Fredrik Hacklin, Nobuaki Minato, Toma Kobayashi,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.01425", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01425", "title": "\nCombinatorial Auction-Based Pricing for Multi-tenant Autonomous Vehicle  Public Transportation System", "abstract": "A smart city provides its people with high standard of living through advanced technologies and transport is one of the major foci. With the advent of autonomous vehicles (AVs), an AV-based public transportation system has been proposed recently, which is capable of providing new forms of transportation services with high efficiency, high flexibility, and low cost. For the benefit of passengers, multitenancy can increase market competition leading to lower service charge and higher quality of service. In this paper, we study the pricing issue of the multi-tenant AV public transportation system and three types of services are defined. The pricing process for each service type is modeled as a combinatorial auction, in which the service providers, as bidders, compete for offering transportation services. The winners of the auction are determined through an integer linear program. To prevent the bidders from raising their bids for higher returns, we propose a strategy-proof Vickrey-Clarke-Groves-based charging mechanism, which can maximize the social welfare, to settle the final charges for the customers. We perform extensive simulations to verify the analytical results and evaluate the performance of the charging mechanism.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Albert Y.S. Lam,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01416", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01416", "title": "\nDisaggregated and optically interconnected memory: when will it be cost  effective?", "abstract": "The \"Disaggregated Server\" concept has been proposed for datacenters where the same type server resources are aggregated in their respective pools, for example a compute pool, memory pool, network pool, and a storage pool. Each server is constructed dynamically by allocating the right amount of resources from these pools according to the workload's requirements. Modularity, higher packaging and cooling efficiencies, and higher resource utilization are among the suggested benefits. With the emergence of very large datacenters, \"clouds\" containing tens of thousands of servers, datacenter efficiency has become an important topic. Few computer chip and systems vendors are working on and making frequent announcements on silicon photonics and disaggregated memory systems. In this paper we study the trade-off between cost and performance of building a disaggregated memory system where DRAM modules in the datacenter are pooled, for example in memory-only chassis and racks. The compute pool and the memory pool are interconnected by an optical interconnect to overcome the distance and bandwidth issues of electrical fabrics. We construct a simple cost model that includes the cost of latency, cost of bandwidth and the savings expected from a disaggregated memory system. We then identify the level at which a disaggregated memory system becomes cost competitive with a traditional direct attached memory system. Our analysis shows that a rack-scale disaggregated memory system will have a non-trivial performance penalty, and at the datacenter scale the penalty is impractically high, and the optical interconnect costs are at least a factor of 10 more expensive than where they should be when compared to the traditional direct attached memory systems.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Bulent Abali, Richard J. Eickemeyer, Hubertus Franke, Chung-Sheng Li, Marc A. Taubenblatt,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01415", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01415", "title": "\nUnified Analysis of Cooperative Spectrum Sensing over Composite and  Generalized Fading Channels", "abstract": "In this paper, we investigate the performance of cooperative spectrum sensing (CSS) with multiple antenna nodes over composite and generalized fading channels. We model the probability density function (PDF) of the signal-to-noise ratio (SNR) using the mixture gamma (MG) distribution. We then derive a generalized closed-form expression for the probability of energy detection, which can be used efficiently for generalized multipath as well as composite (multipath and shadowing) fading channels. The composite effect of fading and shadowing scenarios in CSS is mitigated by applying an optimal fusion rule that minimizes the total error rate (TER), where the optimal number of nodes is derived under the Bayesian criterion, assuming erroneous feedback channels. For imperfect feedback channels, we demonstrate the existence of a TER floor as the number of antennas of the CR nodes increases. Accordingly, we derive the optimal rule for the number of antennas that minimizes the TER. Numerical and Monte-Carlo simulations are presented to corroborate the analytical results and to provide illustrative performance comparisons between different composite fading channels.", "subjects": "Information Theory (cs.IT)", "authors": "Ahmed Al Hammadi, Omar Alhussein, Sami Muhaidat, Mahmoud Al-Qutayri, Saleh Al-Araji, George K. Karagiannidis,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01408", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01408", "title": "\nHardware Fingerprinting Using HTML5", "abstract": "Device fingerprinting over the web has received much attention both by the research community and the commercial market a like. Almost all the fingerprinting features proposed to date depend on software run on the device. All of these features can be changed by the user, thereby thwarting the device's fingerprint. In this position paper we argue that the recent emergence of the HTML5 standard gives rise to a new class of fingerprinting features that are based on the emph of the device. Such features are much harder to mask or change thus provide a higher degree of confidence in the fingerprint. We propose several possible fingerprint methods that allow a HTML5 web application to identify a device's hardware. We also present an initial experiment to fingerprint a device's GPU.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Gabi Nakibly, Gilad Shelef, Shiran Yudilevich,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01407", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01407", "title": "\nInvariant EKF Design for Scan Matching-aided Localization", "abstract": "Localization in indoor environments is a technique which estimates the robot's pose by fusing data from onboard motion sensors with readings of the environment, in our case obtained by scan matching point clouds captured by a low-cost Kinect depth camera. We develop both an Invariant Extended Kalman Filter (IEKF)-based and a Multiplicative Extended Kalman Filter (MEKF)-based solution to this problem. The two designs are successfully validated in experiments and demonstrate the advantage of the IEKF design.", "subjects": "Systems and Control (cs.SY)", "authors": "Martin Barczyk, Silv\u00e8re Bonnabel, Jean-Emmanuel Deschaud, Fran\u00e7ois Goulette,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01402", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01402", "title": "\nDeterministic construction of sparse binary and ternary matrices from  existing binary sensing matrices", "abstract": "In the present work, we discuss a procedure for constructing sparse binary and ternary matrices from existing two binary sensing matrices. The matrices that we construct have several attractive properties such as smaller density, which supports algorithms with low computational complexity. As an application of our method, we show that a CS matrix of general row size different from (for different primes ) can be constructed.", "subjects": "Information Theory (cs.IT)", "authors": "Pradip Sasmal, R. Ramu Naidu, C. S. Sastry, P. V. Jampana,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01398", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01398", "title": "\nNode.DPWS: High performance and scalable Web Services for the IoT", "abstract": "Interconnected computing systems, in various forms, are expected to permeate our lives, realizing the vision of the Internet of Things (IoT) and allowing us to enjoy novel, enhanced services that promise to improve our everyday lives. Nevertheless, this new reality also introduces significant challenges in terms of performance, scaling, usability and interoperability. Leveraging the benefits of Service Oriented Architectures (SOAs) can help alleviate many of the issues that developers, implementers and end-users have to face in the context of the IoT. This work presents Node.DPWS, a novel implementation of the Devices Profile for Web Services (DPWS) based on the Node.js platform. Node.DPWS can be used to deploy lightweight, efficient and scalable Web Services over heterogeneous nodes, including devices with limited resources. The performance of the presented work is evaluated on typical embedded devices, including comparisons with implementations created using alternative DPWS toolkits.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Konstantinos Fysarakis, Damianos Mylonakis, Charalampos Manifavas, Ioannis Papaefstathiou,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01393", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01393", "title": "\nA Hierarchical Approach for Joint Multi-view Object Pose Estimation and  Categorization", "abstract": "We propose a joint object pose estimation and categorization approach which extracts information about object poses and categories from the object parts and compositions constructed at different layers of a hierarchical object representation algorithm, namely Learned Hierarchy of Parts (LHOP). In the proposed approach, we first employ the LHOP to learn hierarchical part libraries which represent entity parts and compositions across different object categories and views. Then, we extract statistical and geometric features from the part realizations of the objects in the images in order to represent the information about object pose and category at each different layer of the hierarchy. Unlike the traditional approaches which consider specific layers of the hierarchies in order to extract information to perform specific tasks, we combine the information extracted at different layers to solve a joint object pose estimation and categorization problem using distributed optimization algorithms. We examine the proposed generative-discriminative learning approach and the algorithms on two benchmark 2-D multi-view image datasets. The proposed approach and the algorithms outperform state-of-the-art classification, regression and feature extraction algorithms. In addition, the experimental results shed light on the relationship between object categorization, pose estimation and the part realizations observed at different layers of the hierarchy.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Mete Ozay, Krzysztof Walas, Ales Leonardis,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01386", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01386", "title": "\nSaturated simple and 2-simple topological graphs with few edges", "abstract": "A simple topological graph is a topological graph in which any two edges have at most one common point, which is either their common endpoint or a proper crossing. More generally, in a k-simple topological graph, every pair of edges has at most k common points of this kind. We construct saturated simple and 2-simple graphs with few edges. These are k-simple graphs in which no further edge can be added. We improve the previous upper bounds of Kyn vl, Pach, Radoi vi 'c, and T 'oth and show that there are saturated simple graphs on n vertices with only 7n edges and saturated 2-simple graphs on n vertices with 14.5n edges. As a consequence, 14.5n edges is also a new upper bound for k-simple graphs (considering all values of k). We also construct saturated simple and 2-simple graphs that have some vertices with low degree.", "subjects": "Computational Geometry (cs.CG)", "authors": "P\u00e9ter Hajnal, Alexander Igamberdiev, G\u00fcnter Rote, Andr\u00e9 Schulz,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01382", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01382", "title": "\nOptimal Constructions for Chain-based Cryptographic Enforcement of  Information Flow Policies", "abstract": "The simple security property in an information flow policy can be enforced by encrypting data objects and distributing an appropriate secret to each user. A user derives a suitable decryption key from the secret and publicly available information. A chain-based enforcement scheme provides an alternative method of cryptographic enforcement that does not require any public information, the trade-off being that a user may require more than one secret. For a given information flow policy, there will be many different possible chain-based enforcement schemes. In this paper, we provide a polynomial-time algorithm for selecting a chain-based scheme which uses the minimum possible number of keys. We also compute the number of secrets that will be required and establish an upper bound on the number of secrets required by any user.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Jason Crampton, Naomi Farley, Gregory Gutin, Mark Jones,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01380", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01380", "title": "\nJournal rank in the Science and Technology domain: A lightweight  quantitative approach for evaluation", "abstract": "The evaluation of journals based on their influence is of interest for numerous reasons. Various methods of computing a score have been proposed for measuring the scientific influence of scholarly journals. Typically the computation of any of these scores involves compiling the citation information pertaining to the journal under consideration. This involves significant overhead since the article citation information of not only the journal under consideration but also that of other journals for the recent few years need to be stored. Our work is motivated by the idea of developing a computationally lightweight approach that does not require any data storage, yet yields a score which is useful for measuring the importance of journals. In this paper, a regression analysis based method is proposed to calculate Journal Influence Score. Proposed model is validated using historical data from the SCImago portal. The results show that the error is small between rankings obtained using the proposed method and the SCImago Journal Rank, thus proving that the proposed approach is a feasible and effective method of calculating scientific impact of journals.", "subjects": "Digital Libraries (cs.DL)", "authors": "Snehanshu Saha, Neelam Jangid, Anand MN, Sidhant Gupta,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01376", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01376", "title": "\nBVNS para el problema del bosque generador k-etiquetado", "abstract": "In this paper we propose an efficient solution for the problem of generating k-labeling forest VNS. This problem is an extension of the Minimum Spanning Tree Problem Labelling problem with important applications in telecommunications networks and multimodal transport. It is, given an undirected graph whose links are labeled, and an integer positive number k, find the spanning forest with the lowest number of connected components using at most k different labels. To address the problem a Basic Variable Neighbourhood Search is proposed where the maximum amplitude of the neighbourhood space, n, is a key parameter. Different strategies are studied to establish the value of n. BVNS with the best selected strategy is experimentally compared with other metaheuristics that have appeared in the literature applied to this type of problem.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Sergio Consoli, Nenad Mladenov\u00ecc, Jos\u00e8 A. Moreno-P\u00e8rez,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01363", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01363", "title": "\nConstant-Time Testing and Learning of Image Properties", "abstract": "We initiate a systematic study of sublinear-time algorithms for image analysis that have access only to labeled random samples from the input. Most previous sublinear-time algorithms for image analysis were query-based, that is, they could query pixels of their choice. We consider algorithms with two types of input access: sample-based algorithms that draw independent uniformly random pixels, and block-sample-based algorithms that draw pixels from independently random square blocks of the image. We investigate three basic properties: being a half-plane, convexity, and connectedness. For the first two, our algorithms are sample-based; for connectedness, they are block-sample-based. All our algorithms have low sample complexity that depends polynomially on the inverse of the error parameter and is independent of the input size. We design algorithms that approximate the distance to the three properties within a small additive error or, equivalently, tolerant testers for being a half-plane, convexity and connectedness. Tolerant testers for these properties, even with query access to the image, were not investigated previously. Tolerance is important in image processing applications because it allows algorithms to be robust to noise in the image. We also give (non-tolerant) testers for convexity and connectedness with better complexity than our distance approximation algorithms and previously known query-based testers. To obtain our algorithms for convexity, we design two fast proper PAC learners of convex sets in two dimensions that work under the uniform distribution: non-agnostic and agnostic.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Piotr Berman, Meiram Murzabulatov, Sofya Raskhodnikova,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01348", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01348", "title": "\nTensors, !-graphs, and non-commutative quantum structures (extended  version)", "abstract": "!-graphs provide a means of reasoning about infinite families of string diagrams and have proven useful in manipulation of (co)algebraic structures like Hopf algebras, Frobenius algebras, and compositions thereof. However, they have previously been limited by an inability to express families of diagrams involving non-commutative structures which play a central role in algebraic quantum information and the theory of quantum groups. In this paper, we fix this shortcoming by offering a new semantics for non-commutative !-graphs using an enriched version of Penrose's abstract tensor notation.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Aleks Kissinger, David Quick,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01337", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01337", "title": "\np Norm Constraint Leaky LMS Algorithm for Sparse System Identification", "abstract": "This paper proposes a new leaky least mean square (leaky LMS, LLMS) algorithm in which a norm penalty is introduced to force the solution to be sparse in the application of system identification. The leaky LMS algorithm is derived because the performance ofthe standard LMS algorithm deteriorates when the input is highly correlated. However, both ofthem do not take the sparsity information into account to yield better behaviors. As a modification ofthe LLMS algorithm, the proposed algorithm, named Lp-LLMS, incorporates a p norm penalty into the cost function ofthe LLMS to obtain a shrinkage in the weight update equation, which then enhances the performance of the filter in system identification settings, especially when the impulse response is sparse. The simulation results verify that the proposed algorithm improves the performance ofthe filter in sparse system settings in the presence ofnoisy input signals.", "subjects": "Systems and Control (cs.SY)", "authors": "Yong Feng, Rui Zeng, Jiasong Wu,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01331", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01331", "title": "\nPageRank Approach to Ranking National Football Teams", "abstract": "The Football World Cup as world's favorite sporting event is a source of both entertainment and overwhelming amount of data about the games played. In this paper we analyse the available data on football world championships since 1930 until today. Our goal is to rank the national teams based on all matches during the championships. For this purpose, we apply the PageRank with restarts algorithm to a graph built from the games played during the tournaments. Several statistics such as matches won and goals scored are combined in different metrics that assign weights to the links in the graph. Finally, our results indicate that the Random walk approach with the use of right metrics can indeed produce relevant rankings comparable to the FIFA official all-time ranking board.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Verica Lazova, Lasko Basnarkov,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01327", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01327", "title": "\nEstimating the Probability of Meeting a Deadline in Hierarchical Plans", "abstract": "Given a hierarchical plan (or schedule) with uncertain task times, we may need to determine the probability that a given plan will satisfy a given deadline. This problem is shown to be NP-hard for series-parallel hierarchies. We provide a polynomial-time approximation algorithm for it. Computing the expected makespan of an hierarchical plan is also shown to be NP-hard. We examine the approximation bounds empirically and demonstrate where our scheme is superior to sampling and to exact computation.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Liat Cohen, Solomon Eyal Shimony, Gera Weiss,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01314", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01314", "title": "\nAn Incentivized Approach for Fair Participation in Wireless Ad hoc  Networks", "abstract": "In Wireless Ad hoc networks (WANETs), nodes separated by considerable distance communicate with each other by relaying their messages through other nodes. However, it might not be in the best interests of a node to forward the message of another node due to power constraints. In addition, all nodes being rational, some nodes may be selfish, i.e. they might not relay data from other nodes so as to increase their lifetime. In this paper, we present a fair and incentivized approach for participation in Ad hoc networks. Given the power required for each transmission, we are able to determine the power saving contributed by each intermediate hop. We propose the FAir Share incenTivizEd Ad hoc paRticipation protocol (FASTER), which takes a selected route from a routing protocol as input, to calculate the worth of each node using the cooperative game theory concept of 'Shapley Value' applied on the power saved by each node. This value can be used for allocation of Virtual Currency to the nodes, which can be spent on subsequent message transmissions.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Arka Rai Choudhuri, Kalyanasundaram S, Shriyak Sridhar, Annappa B,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01313", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01313", "title": "\nA Novel Performance Evaluation Methodology for Single-Target Trackers", "abstract": "This paper addresses the problem of single-target tracker performance evaluation. We consider the performance measures, the dataset and the evaluation system to be the most important components of tracker evaluation and propose requirements for each of them. The requirements are the basis of a new evaluation methodology that aims at a simple and easily interpretable tracker comparison. The ranking-based methodology addresses tracker equivalence in terms of statistical significance and practical differences. A fully-annotated dataset with per-frame annotations with several visual attributes is introduced. The diversity of its visual properties is maximized in a novel way by clustering a large number of videos according to their visual attributes. This makes it the most sophistically constructed and annotated dataset to date. A multi-platform evaluation system allowing easy integration of third-party trackers is presented as well. The proposed evaluation methodology was tested on the VOT2014 challenge on the new dataset and 38 trackers, making it the largest benchmark to date. Most of the tested trackers are indeed state-of-the-art since they outperform the standard baselines, resulting in a highly-challenging benchmark. An exhaustive analysis of the dataset from the perspective of tracking difficulty is carried out. To facilitate tracker comparison a new performance visualization technique is proposed.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Matej Kristan, Jiri Matas, Ales Leonardis, Tomas Vojir, Roman Pflugfelder, Gustavo Fernandez, Georg Nebehay, Fatih Porikli, Luka Cehovin,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01299", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01299", "title": "\nTelling cause from effect in deterministic linear dynamical systems", "abstract": "Inferring a cause from its effect using observed time series data is a major challenge in natural and social sciences. Assuming the effect is generated by the cause trough a linear system, we propose a new approach based on the hypothesis that nature chooses the \"cause\" and the \"mechanism that generates the effect from the cause\" independent of each other. We therefore postulate that the power spectrum of the time series being the cause is uncorrelated with the square of the transfer function of the linear filter generating the effect. While most causal discovery methods for time series mainly rely on the noise, our method relies on asymmetries of the power spectral density properties that can be exploited even in the context of deterministic systems. We describe mathematical assumptions in a deterministic model under which the causal direction is identifiable with this approach. We also discuss the method's performance under the additive noise model and its relationship to Granger causality. Experiments show encouraging results on synthetic as well as real-world data. Overall, this suggests that the postulate of Independence of Cause and Mechanism is a promising principle for causal inference on empirical time series.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Naji Shajarisales, Dominik Janzing, Bernhard Shoelkopf, Michel Besserve,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01298", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01298", "title": "\nResearch Data Explored II: the Anatomy and Reception of figshare", "abstract": "This is the second paper in a series of bibliometric studies of research data. In this paper, we present an analysis of figshare, one of the largest multidisciplinary repositories for research materials to date. We analysed the structure of items archived in figshare, their usage, and their reception in two altmetrics sources (PlumX and ImpactStory). We found that figshare acts as a platform for newly published research materials, and as an archive for PLOS. Depending on the function, we found different bibliometric characteristics. Items archived from PLOS tend to be coming from the natural sciences and are often unviewed and non-downloaded. Self-archived items, however, come from a variety of disciplines and exhibit some patterns of higher usage. In the altmetrics analysis, we found that Twitter was the social media service where research data gained most attention; generally, research data published in 2014 were most popular across social media services. PlumX detects considerably more items in social media and also finds higher altmetric scores than ImpactStory.", "subjects": "Digital Libraries (cs.DL)", "authors": "Peter Kraker, Elisabeth Lex, Juan Gorraiz, Christian Gumpenberger, Isabella Peters,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01288", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01288", "title": "\nGame-theoretic Approach for Non-Cooperative Planning", "abstract": "When two or more self-interested agents put their plans to execution in the same environment, conflicts may arise as a consequence, for instance, of a common utilization of resources. In this case, an agent can postpone the execution of a particular action, if this punctually solves the conflict, or it can resort to execute a different plan if the agent's payoff significantly diminishes due to the action deferral. In this paper, we present a game-theoretic approach to non-cooperative planning that helps predict before execution what plan schedules agents will adopt so that the set of strategies of all agents constitute a Nash equilibrium. We perform some experiments and discuss the solutions obtained with our game-theoretical approach, analyzing how the conflicts between the plans determine the strategic behavior of the agents.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Jaume Jord\u00e1n, Eva Onaindia,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01269", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01269", "title": "\nAccelerating Consensus by Spectral Clustering and Polynomial Filters", "abstract": "It is known that polynomial filtering can accelerate the convergence towards average consensus on an undirected network. In this paper the gain of a second-order filtering is investigated. A set of graphs is determined for which consensus can be attained in finite time, and a preconditioner is proposed to adapt the undirected weights of any given graph to achieve fastest convergence with the polynomial filter. The corresponding cost function differs from the traditional spectral gap, as it favors grouping the eigenvalues in two clusters. A possible loss of robustness of the polynomial filter is also highlighted.", "subjects": "Systems and Control (cs.SY)", "authors": "Simon Apers, Alain Sarlette,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01267", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01267", "title": "\nElectric Vehicles Charging Control based on Future Internet Generic  Enablers", "abstract": "In this paper a rationale for the deployment of Future Internet based applications in the field of Electric Vehicles (EVs) smart charging is presented. The focus is on the Connected Device Interface (CDI) Generic Enabler (GE) and the Network Information and Controller (NetIC) GE, which are recognized to have a potential impact on the charging control problem and the configuration of communications networks within reconfigurable clusters of charging points. The CDI GE can be used for capturing the driver feedback in terms of Quality of Experience (QoE) in those situations where the charging power is abruptly limited as a consequence of short term grid needs, like the shedding action asked by the Transmission System Operator to the Distribution System Operator aimed at clearing networks contingencies due to the loss of a transmission line or large wind power fluctuations. The NetIC GE can be used when a master Electric Vehicle Supply Equipment (EVSE) hosts the Load Area Controller, responsible for managing simultaneous charging sessions within a given Load Area (LA); the reconfiguration of distribution grid topology results in shift of EVSEs among LAs, then reallocation of slave EVSEs is needed. Involved actors, equipment, communications and processes are identified through the standardized framework provided by the Smart Grid Architecture Model (SGAM).", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Andrea Lanna, Francesco Liberati, Letterio Zuccaro, Alessandro Di Giorgio,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01258", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01258", "title": "\nThe concept \"altruism\" for sociological research: from conceptualization  to operationalization", "abstract": "This article addresses the question of the relevant conceptualization of altruism in Russian from the perspective sociological research operationalization. It investigates the spheres of social application of the word altruism, include Russian equivalent vzaimopomoshh` (mutual help). The data for the study comes from Russian National Corpus (Russian). The theoretical framework consists of Paul F. Lazarsfeld`s Theory of Sociological Research Methodology and the Natural Semantic Metalanguage (NSM). Quantitative analysis shows features in the representation of altruism in Russian that sociologists need to know in the preparation of questionnaires, interview guides and analysis of transcripts.", "subjects": "Computers and Society (cs.CY)", "authors": "Oleg V. Pavenkov, Vladimir G. Pavenkov, Mariia V. Rubtcova,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01250", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01250", "title": "\nA new method on deterministic construction of the measurement matrix in  compressed sensing", "abstract": "Construction on the measurement matrix is a central problem in compressed sensing. Although using random matrices is proven optimal and successful in both theory and applications. A deterministic construction on the measurement matrix is still very important and interesting. In fact, it is still an open problem proposed by T. Tao. In this paper, we shall provide a new deterministic construction method and prove it is optimal with regard to the mutual incoherence.", "subjects": "Information Theory (cs.IT)", "authors": "Qun Mo,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01244", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01244", "title": "\nReplication of arbitrary hole-free shapes via self-assembly with  signal-passing tiles (extended abstract)", "abstract": "In this paper, we investigate the abilities of systems of self-assembling tiles which can each pass a constant number of signals to their immediate neighbors to create replicas of input shapes. Namely, we work within the Signal-passing Tile Assembly Model (STAM), and we provide a universal STAM tile set which is capable of creating unbounded numbers of assemblies of shapes identical to those of input assemblies. The shapes of the input assemblies can be arbitrary 2-dimensional hole-free shapes at scale factor 2. This greatly improves previous shape replication results in self-assembly that required models in which multiple assembly stages and/or bins were required, and the shapes which could be replicated were quite constrained.", "subjects": "Emerging Technologies (cs.ET)", "authors": "Jacob Hendricks, Matthew J. Patitz, Trent A. Rogers,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01239", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01239", "title": "\nActive Sample Learning and Feature Selection: A Unified Approach", "abstract": "This paper focuses on the problem of simultaneous sample and feature selection for machine learning in a fully unsupervised setting. Though most existing works tackle these two problems separately that derives two well-studied sub-areas namely active learning and feature selection, a unified approach is inspirational since they are often interleaved with each other. Noisy and high-dimensional features will bring adverse effect on sample selection, while `good' samples will be beneficial to feature selection. We present a unified framework to conduct active learning and feature selection simultaneously. From the data reconstruction perspective, both the selected samples and features can best approximate the original dataset respectively, such that the selected samples characterized by the selected features are very representative. Additionally our method is one-shot without iteratively selecting samples for progressive labeling. Thus our model is especially suitable when the initial labeled samples are scarce or totally absent, which existing works hardly address particularly for simultaneous feature selection. To alleviate the NP-hardness of the raw problem, the proposed formulation involves a convex but non-smooth optimization problem. We solve it efficiently by an iterative algorithm, and prove its global convergence. Experiments on publicly available datasets validate that our method is promising compared with the state-of-the-arts.", "subjects": "Learning (cs.LG)", "authors": "Changsheng Li, Xiangfeng Wang, Weishan Dong, Junchi Yan, Qingshan Liu, Hongyuan Zha,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01228", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01228", "title": "\nBethe Learning of Conditional Random Fields via MAP Decoding", "abstract": "Many machine learning tasks can be formulated in terms of predicting structured outputs. In frameworks such as the structured support vector machine (SVM-Struct) and the structured perceptron, discriminative functions are learned by iteratively applying efficient maximum a posteriori (MAP) decoding. However, maximum likelihood estimation (MLE) of probabilistic models over these same structured spaces requires computing partition functions, which is generally intractable. This paper presents a method for learning discrete exponential family models using the Bethe approximation to the MLE. Remarkably, this problem also reduces to iterative (MAP) decoding. This connection emerges by combining the Bethe approximation with a Frank-Wolfe (FW) algorithm on a convex dual objective which circumvents the intractable partition function. The result is a new single loop algorithm MLE-Struct, which is substantially more efficient than previous double-loop methods for approximate maximum likelihood estimation. Our algorithm outperforms existing methods in experiments involving image segmentation, matching problems from vision, and a new dataset of university roommate assignments.", "subjects": "Learning (cs.LG)", "authors": "Kui Tang, Nicholas Ruozzi, David Belanger, Tony Jebara,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01224", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01224", "title": "\nTemporal Pyramid Pooling Based Convolutional Neural Networks for Action  Recognition", "abstract": "Encouraged by the success of Convolutional Neural Networks (CNNs) in image classification, recently much effort is spent on applying CNNs to video based action recognition problems. One challenge is that video contains a varying number of frames which is incompatible to the standard input format of CNNs. Existing methods handle this issue either by directly sampling a fixed number of frames or bypassing this issue by introducing a 3D convolutional layer which conducts convolution in spatial-temporal domain. To solve this issue, here we propose a novel network structure which allows an arbitrary number of frames as the network input. The key of our solution is to introduce a module consisting of an encoding layer and a temporal pyramid pooling layer. The encoding layer maps the activation from previous layers to a feature vector suitable for pooling while the temporal pyramid pooling layer converts multiple frame-level activations into a fixed-length video-level representation. In addition, we adopt a feature concatenation layer which combines appearance information and motion information. Compared with the frame sampling strategy, our method avoids the risk of missing any important frames. Compared with the 3D convolutional method which requires a huge video dataset for network training, our model can be learned on a small target dataset because we can leverage the off-the-shelf image-level CNN for model parameter initialization. Experiments on two challenging datasets, Hollywood2 and HMDB51, demonstrate that our method achieves superior performance over state-of-the-art methods while requiring much fewer training data.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Peng Wang, Yuanzhouhan Cao, Chunhua Shen, Lingqiao Liu, Heng Tao Shen,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01220", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01220", "title": "\nCompetitive Diffusion in Social Networks: Quality or Seeding?", "abstract": "In this paper, we study a strategic model of marketing and product consumption in social networks. We consider two firms in a market competing to maximize the consumption of their products. Firms have a limited budget which can be either invested on the quality of the product or spent on initial seeding in the network in order to better facilitate spread of the product. After the decision of firms, agents choose their consumptions following a myopic best response dynamics which results in a local, linear update for their consumption decision. We characterize the unique Nash equilibrium of the game between firms and study the effect of the budgets as well as the network structure on the optimal allocation. We show that at the equilibrium, firms invest more budget on quality when their budgets are close to each other. However, as the gap between budgets widens, competition in qualities becomes less effective and firms spend more of their budget on seeding. We also show that given equal budget of firms, if seeding budget is nonzero for a balanced graph, it will also be nonzero for any other graph, and if seeding budget is zero for a star graph it will be zero for any other graph as well. As a practical extension, we then consider a case where products have some preset qualities that can be only improved marginally. At some point in time, firms learn about the network structure and decide to utilize a limited budget to mount their market share by either improving the quality or new seeding some agents to incline consumers towards their products. We show that the optimal budget allocation in this case simplifies to a threshold strategy. Interestingly, we derive similar results to that of the original problem, in which preset qualities simulate the role that budgets had in the original setup.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Arastoo Fazeli, Amir Ajorlou, Ali Jadbabaie,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01218", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01218", "title": "\nMaximizing Submodular Functions with the Diminishing Return Property  over the Integer Lattice", "abstract": "The problem of maximizing non-negative monotone submodular functions under a certain constraint has been intensively studied in the last decade. In this paper, we address the problem for functions defined over the integer lattice. Suppose that a non-negative monotone submodular function is given via an evaluation oracle. Furthermore, we assume that satisfies the diminishing return property, which is not an immediate consequence of the submodularity when the domain is the integer lattice. Then, we show (i) a -approximation algorithm for a cardinality constraint with queries, where is the maximum cardinality of feasible solutions, (ii) a -approximation algorithm for a polymatroid constraint with queries, where is the rank of the polymatroid, and (iii) a -approximation algorithm for a knapsack constraint with queries, where is the minumum weight of elements. Our algorithms for polymatroid constraints and knapsack constraints first extend the domain of the objective function to the Euclidean space and then run the continuous greedy algorithm. We give two different kinds of continuous extensions, one is for knapsack constraints and the other is for polymatroid constraints, which might be of independent interest.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Tasuku Soma, Yuichi Yoshida,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01214", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01214", "title": "\nBuilding a RAPPOR with the Unknown: Privacy-Preserving Learning of  Associations and Data Dictionaries", "abstract": "Techniques based on randomized response enable the collection of potentially sensitive data from clients in a privacy-preserving manner with strong local differential privacy guarantees. One of the latest such technologies, RAPPOR, allows the marginal frequencies of an arbitrary set of strings to be estimated via privacy-preserving crowdsourcing. However, this original estimation process requires a known set of possible strings; in practice, this dictionary can often be extremely large and sometimes completely unknown. In this paper, we propose a novel decoding algorithm for the RAPPOR mechanism that enables the estimation of \"unknown unknowns,\" i.e., strings we do not even know we should be estimating. To enable learning without explicit knowledge of the dictionary, we develop methodology for estimating the joint distribution of two or more variables collected with RAPPOR. This is a critical step towards understanding relationships between multiple variables collected in a privacy-preserving manner.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Giulia Fanti, Vasyl Pihur, \u00dalfar Erlingsson,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01212", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01212", "title": "\nHierarchies of Relaxations for Online Prediction Problems with Evolving  Constraints", "abstract": "We study online prediction where regret of the algorithm is measured against a benchmark defined via evolving constraints. This framework captures online prediction on graphs, as well as other prediction problems with combinatorial structure. A key aspect here is that finding the optimal benchmark predictor (even in hindsight, given all the data) might be computationally hard due to the combinatorial nature of the constraints. Despite this, we provide polynomial-time emph algorithms that achieve low regret against combinatorial benchmark sets. We do so by building improper learning algorithms based on two ideas that work together. The first is to alleviate part of the computational burden through random playout, and the second is to employ Lasserre semidefinite hierarchies to approximate the resulting integer program. Interestingly, for our prediction algorithms, we only need to compute the values of the semidefinite programs and not the rounded solutions. However, the integrality gap for Lasserre hierarchy emph enter the generic regret bound in terms of Rademacher complexity of the benchmark set. This establishes a trade-off between the computation time and the regret bound of the algorithm.", "subjects": "Learning (cs.LG)", "authors": "Alexander Rakhlin, Karthik Sridharan,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01210", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01210", "title": "\nLow-dimensional Models in Spatio-Temporal Wind Speed Forecasting", "abstract": "Integrating wind power into the grid is challenging because of its random nature. Integration is facilitated with accurate short-term forecasts of wind power. The paper presents a spatio-temporal wind speed forecasting algorithm that incorporates the time series data of a target station and data of surrounding stations. Inspired by Compressive Sensing (CS) and structured-sparse recovery algorithms, we claim that there usually exists an intrinsic low-dimensional structure governing a large collection of stations that should be exploited. We cast the forecasting problem as recovery of a block-sparse signal from a set of linear equations for which we propose novel structure-sparse recovery algorithms. Results of a case study in the east coast show that the proposed Compressive Spatio-Temporal Wind Speed Forecasting (CST-WSF) algorithm significantly improves the short-term forecasts compared to a set of widely-used benchmark models.", "subjects": "Systems and Control (cs.SY)", "authors": "Borhan M. Sanandaji, Akin Tascikaraoglu, Kameshwar Poolla, Pravin Varaiya,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01205", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01205", "title": "\nOptimal Demodulation of Reaction Shift Keying Signals in Diffusion-based  Molecular Communication Networks", "abstract": "In a diffusion-based molecular communication network, transmitters and receivers communicate by using signalling molecules (or ligands) in a fluid medium. This paper proposes a novel modulation mechanism for molecular communication called Reaction Shift Keying (RSK). In RSK, the transmitter uses different chemical reactions to generate different time-varying functions of concentration of signalling molecules to represent different transmission symbols. We consider the problem of demodulating the RSK symbols assuming that the transmitter and receiver are synchronised. We assume the receiver consists of receptors and signalling molecules may react with these receptors to form ligand-receptor complexes. We derive an optimal RSK demodulator using the continuous history of the number of complexes at the receiver as the input to the demodulator. We do that by first deriving a communication model which includes the chemical reactions in the transmitter, diffusion in the transmission medium and the ligand-receptor process in the receiver. This model, which takes the form of a continuous-time Markov process, captures the noise in the receiver signal due to the stochastic nature of chemical reactions and diffusion. We then adopt a maximum posterior framework and use Bayesian filtering to derive the optimal demodulator for RSK signals. We use numerical examples to illustrate the properties of the RSK demodulator.", "subjects": "Information Theory (cs.IT)", "authors": "Chun Tung Chou,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01203", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01203", "title": "\nOn the Number of Minimal Separators in Graphs", "abstract": "We consider the largest number of minimal separators a graph on n vertices can have at most. We give a new proof that this number is in . We prove that this number is in , improving on the previous best lower bound of . This gives also an improved lower bound on the number of potential maximal cliques in a graph. We would like to emphasize that our proofs are short, simple, and elementary.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Serge Gaspers, Simon Mackenzie,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01192", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01192", "title": "\nCounting Inversions Adaptively", "abstract": "We give a simple and efficient algorithm for adaptively counting inversions in a sequence of integers. Our algorithm runs in time in the word-RAM model of computation, where is the number of inversions.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Amr Elmasry,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01191", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01191", "title": "\nContract-Based Interference Coordination in Heterogeneous Cloud Radio  Access Networks", "abstract": "Heterogeneous cloud radio access networks (HCRANs) are potential solutions to improve both spectral and energy efficiencies by embedding cloud computing into heterogeneous networks (HetNets). The interference among remote radio heads (RRHs) can be suppressed with centralized cooperative processing in the base band unit (BBU) pool, while the intertier interference between RRHs and macro base stations (MBSs) is still challenging in H-CRANs. In this paper, to mitigate this inter-tier interference, a contract-based interference coordination framework is proposed, where three scheduling schemes are involved, and the downlink transmission interval is divided into three phases accordingly. The core idea of the proposed framework is that the BBU pool covering all RRHs is selected as the principal that would offer a contract to the MBS, and the MBS as the agent decides whether to accept the contract or not according to an individual rational constraint. An optimal contract design that maximizes the rate-based utility is derived when perfect channel state information (CSI) is acquired at both principal and agent. Furthermore, contract optimization under the situation where only the partial CSI can be obtained from practical channel estimation is addressed as well. Monte Carlo simulations are provided to confirm the analysis, and simulation results show that the proposed framework can significantly increase the transmission data rates over baselines, thus demonstrating the effectiveness of the proposed contract-based solution.", "subjects": "Information Theory (cs.IT)", "authors": "Mugen Peng, Xinqian Xie, Qiang Hu, Jie Zhang, H. Vincent Poor,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01190", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01190", "title": "\nStatistical modality tagging from rule-based annotations and  crowdsourcing", "abstract": "We explore training an automatic modality tagger. Modality is the attitude that a speaker might have toward an event or state. One of the main hurdles for training a linguistic tagger is gathering training data. This is particularly problematic for training a tagger for modality because modality triggers are sparse for the overwhelming majority of sentences. We investigate an approach to automatically training a modality tagger where we first gathered sentences based on a high-recall simple rule-based modality tagger and then provided these sentences to Mechanical Turk annotators for further annotation. We used the resulting set of training data to train a precise modality tagger using a multi-class SVM that delivers good performance.", "subjects": "Computation and Language (cs.CL)", "authors": "Vinodkumar Prabhakaran, Michael Bloodgood, Mona Diab, Bonnie Dorr, Lori Levin, Christine D. Piatko, Owen Rambow, Benjamin Van Durme,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01189", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01189", "title": "\nPhysical Interpretations of Negative Imaginary Systems Theory", "abstract": "This paper presents some physical interpretations of recent stability results on the feedback interconnection of negative imaginary systems. These interpretations involve spring mass damper systems coupled together by springs or RLC electrical networks coupled together via inductors or capacitors.", "subjects": "Systems and Control (cs.SY)", "authors": "Ian R. Petersen,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01187", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01187", "title": "\nFronthaul-Constrained Cloud Radio Access Networks: Insights and  Challenges", "abstract": "As a promising paradigm for fifth generation (5G) wireless communication systems, cloud radio access networks (C-RANs) have been shown to reduce both capital and operating expenditures, as well as to provide high spectral efficiency (SE) and energy efficiency (EE). The fronthaul in such networks, defined as the transmission link between a baseband unit (BBU) and a remote radio head (RRH), requires high capacity, but is often constrained. This article comprehensively surveys recent advances in fronthaul-constrained C-RANs, including system architectures and key techniques. In particular, key techniques for alleviating the impact of constrained fronthaul on SE/EE and quality of service for users, including compression and quantization, large-scale coordinated processing and clustering, and resource allocation optimization, are discussed. Open issues in terms of software-defined networking, network function virtualization, and partial centralization are also identified.", "subjects": "Information Theory (cs.IT)", "authors": "M. Peng, C. Wang, V. Lau, H. V. Poor,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01186", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01186", "title": "\nAutomated detection and classification of cryptographic algorithms in  binary programs through machine learning", "abstract": "Threats from the internet, particularly malicious software (i.e., malware) often use cryptographic algorithms to disguise their actions and even to take control of a victim's system (as in the case of ransomware). Malware and other threats proliferate too quickly for the time-consuming traditional methods of binary analysis to be effective. By automating detection and classification of cryptographic algorithms, we can speed program analysis and more efficiently combat malware. This thesis will present several methods of leveraging machine learning to automatically discover and classify cryptographic algorithms in compiled binary programs. While further work is necessary to fully evaluate these methods on real-world binary programs, the results in this paper suggest that machine learning can be used successfully to detect and identify cryptographic primitives in compiled code. Currently, these techniques successfully detect and classify cryptographic algorithms in small single-purpose programs, and further work is proposed to apply them to real-world examples.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Diane Duros Hosfelt,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01185", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01185", "title": "\nGradient Compared Lp-LMS Algorithms for Sparse System Identification", "abstract": "In this paper, we propose two novel p-norm penalty least mean square (Lp-LMS) algorithms as supplements of the conventional Lp-LMS algorithm established for sparse adaptive filtering recently. A gradient comparator is employed to selectively apply the zero attractor of p-norm constraint for only those taps that have the same polarity as that of the gradient of the squared instantaneous error, which leads to the new proposed gradient compared p-norm constraint LMS algorithm (LpGC-LMS). We explain that the LpGC-LMS can achieve lower mean square error than the standard Lp-LMS algorithm theoretically and experimentally. To further improve the performance of the filter, the LpNGC-LMS algorithm is derived using a new gradient comparator which takes the sign-smoothed version of the previous one. The performance of the LpNGC-LMS is superior to that of the LpGC-LMS in theory and in simulations. Moreover, these two comparators can be easily applied to other norm constraint LMS algorithms to derive some new approaches for sparse adaptive filtering. The numerical simulation results show that the two proposed algorithms achieve better performance than the standard LMS algorithm and Lp-LMS algorithm in terms of convergence rate and steady-state behavior in sparse system identification settings.", "subjects": "Systems and Control (cs.SY)", "authors": "Yong Feng, Jiasong Wu, Rui Zeng, Limin Luo, Huazhong Shu,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01180", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01180", "title": "\nAll Who Wander: On the Prevalence and Characteristics of Multi-community  Engagement", "abstract": "Although analyzing user behavior within individual communities is an active and rich research domain, people usually interact with multiple communities both on- and off-line. How do users act in such multi-community environments? Although there are a host of intriguing aspects to this question, it has received much less attention in the research community in comparison to the intra-community case. In this paper, we examine three aspects of multi-community engagement: the sequence of communities that users post to, the language that users employ in those communities, and the feedback that users receive, using longitudinal posting behavior on Reddit as our main data source, and DBLP for auxiliary experiments. We also demonstrate the effectiveness of features drawn from these aspects in predicting users' future level of activity. One might expect that a user's trajectory mimics the \"settling-down\" process in real life: an initial exploration of sub-communities before settling down into a few niches. However, we find that the users in our data continually post in new communities; moreover, as time goes on, they post increasingly evenly among a more diverse set of smaller communities. Interestingly, it seems that users that eventually leave the community are \"destined\" to do so from the very beginning, in the sense of showing significantly different \"wandering\" patterns very early on in their trajectories; this finding has potentially important design implications for community maintainers. Our multi-community perspective also allows us to investigate the \"situation vs. personality\" debate from language usage across different communities.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Chenhao Tan, Lillian Lee,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01173", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01173", "title": "\nAutonomous surveillance for biosecurity", "abstract": "The global movement of people and goods has increased the risk of biosecurity threats and their potential to incur large economic, social, and environmental costs. Conventional manual biosecurity surveillance methods are limited by their scalability in space and time. This article focuses on autonomous surveillance systems, comprising sensor networks, robots, and intelligent algorithms, and their applicability to biosecurity threats. We discuss the spatial and temporal attributes of autonomous surveillance technologies and map them to three broad categories of biosecurity threat: (i) vector-borne diseases; (ii) plant pests; and (iii) aquatic pests. Our discussion reveals a broad range of opportunities to serve biosecurity needs through autonomous surveillance.", "subjects": "Robotics (cs.RO)", "authors": "Raja Jurdak, Alberto Elfes, Branislav Kusy, Ashley Tews, Wen Hu, Emili Hernandez, Navinda Kottege, Pavan Sikka,", "date": "2015-3-4"}, 
{"urllink": "http://arxiv.org/abs/1503.01158", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01158", "title": "\nSystematic Construction of Anomaly Detection Benchmarks from Real Data", "abstract": "Research in anomaly detection suffers from a lack of realistic and publicly-available data sets. Because of this, most published experiments in anomaly detection validate their algorithms with application-specific case studies or benchmark datasets of the researchers' construction. This makes it difficult to compare different methods or to measure progress in the field. It also limits our ability to understand the factors that determine the performance of anomaly detection algorithms. This article proposes a new methodology for empirical analysis and evaluation of anomaly detection algorithms. It is based on generating thousands of benchmark datasets by transforming existing supervised learning benchmark datasets and manipulating properties relevant to anomaly detection. The paper identifies and validates four important dimensions: (a) point difficulty, (b) relative frequency of anomalies, (c) clusteredness of anomalies, and (d) relevance of features. We apply our generated datasets to analyze several leading anomaly detection algorithms. The evaluation verifies the importance of these dimensions and shows that, while some algorithms are clearly superior to others, anomaly detection accuracy is determined more by variation in the four dimensions than by the choice of algorithm.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Andrew Emmott, Shubhomoy Das, Thomas Dietterich, Alan Fern, Weng-Keen Wong,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01156", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01156", "title": "\nA randomized online quantile summary in $O(\\frac{1}{\\varepsilon} \\log  \\frac{1}{\\varepsilon})$ words", "abstract": "A quantile summary is a data structure that approximates to -relative error the order statistics of a much larger underlying dataset. In this paper we develop a randomized online quantile summary for the cash register data input model and comparison data domain model that uses words of memory. This improves upon the previous best upper bound of by Agarwal et. al. (PODS 2012). Further, by a lower bound of Hung and Ting (FAW 2010) no deterministic summary for the comparison model can outperform our randomized summary in terms of space complexity. Lastly, our summary has the nice property that words suffice to ensure that the success probability is .", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "David Felber, Rafail Ostrovsky,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01147", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01147", "title": "\nRandom Pulse Train Spectrum Calculation Unleashed", "abstract": "For the first time the problem of the full solution for the calculation of the power spectrum density of the random pulse train is solved. This well known problem led to a mistaken publication in the past and even its partial solution was considered worthy of publication in a textbook. The little known solution for only the continues random pulse train spectrum is explained by examples and is extended to cover each signal having a discrete spectrum, too. A developed approach is used to derive the general equation for two important representative pulse trains with unbalanced symbol duration: a signal with stretched pulse with a transition from one to zero, and shortened blank symbols. The developed theoretical results are validated by simulation. It is shown that the pulse trains under consideration pose spectrum peaks. The characteristics of these peaks are investigated.", "subjects": "Information Theory (cs.IT)", "authors": "Sander Stepanov, Anastasios Venetsanopoulos,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01145", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01145", "title": "\nDesign for Online Deliberative Processes and Technologies: Towards a  Multidisciplinary Research Agenda", "abstract": "There has been rapidly growing interest in studying and designing online deliberative processes and technologies. This SIG aims at providing a venue for continuous and constructive dialogue between social, political and cognitive sciences as well as computer science, HCI, and CSCW. Through an online community and a modified version of world cafe discussions, we contribute to the definition of the theoretical building blocks, the identification of a research agenda for the CHI community, and the network of individuals from academia, industry, and the public sector who share interests in different aspects of online deliberation.", "subjects": "Human-Computer Interaction (cs.HC)", "authors": "Lu Xiao, Weiyu Zhang, Anna Przybylska, Anna De Liddo, Gregorio Convertino, Todd Davies, Mark Klein,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01144", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01144", "title": "\nTractability Frontier of Data Complexity in Team Semantics", "abstract": "We study the data complexity of model-checking for logics with team semantics. For dependence and independence logic, we completely characterize the tractability/intractability frontier of data complexity of both quantifier-free and quantified formulas. For inclusion logic formulas, we reduce the model-checking problem to the satisfiability problem of so-called Dual-Horn propositional formulas. While interesting in its own right, this also provides an alternative proof for the recent result of P. Galliani and L. Hella in 2013 showing that the data complexity of inclusion logic is in PTIME. In the last section we consider the data complexity of inclusion logic under so-called strict semantics.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Arnaud Durand, Juha Kontinen, Nicolas de Rugy-Altherre, Jouko V\u00e4\u00e4n\u00e4nen,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01143", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01143", "title": "\nS-Store: Streaming Meets Transaction Processing", "abstract": "Stream processing addresses the needs of real-time applications. Transaction processing addresses the coordination and safety of short atomic computations. Heretofore, these two modes of operation existed in separate, stove-piped systems. In this work, we attempt to fuse the two computational paradigms in a single system called S-Store. In this way, S-Store can simultaneously accommodate OLTP and streaming applications. We present a simple transaction model for streams that integrates seamlessly with a traditional OLTP system. We chose to build S-Store as an extension of H-Store, an open-source, in-memory, distributed OLTP database system. By implementing S-Store in this way, we can make use of the transaction processing facilities that H-Store already supports, and we can concentrate on the additional implementation features that are needed to support streaming. Similar implementations could be done using other main-memory OLTP platforms. We show that we can actually achieve higher throughput for streaming workloads in S-Store than an equivalent deployment in H-Store alone. We also show how this can be achieved within H-Store with the addition of a modest amount of new functionality. Furthermore, we compare S-Store to two state-of-the-art streaming systems, Spark Streaming and Storm, and show how S-Store matches and sometimes exceeds their performance while providing stronger transactional guarantees.", "subjects": "Databases (cs.DB)", "authors": "John Meehan, Nesime Tatbul, Stan Zdonik, Cansu Aslantas, Ugur Cetintemel, Jiang Du, Tim Kraska, Samuel Madden, David Maier, Andrew Pavlo, Michael Stonebraker, Kristin Tufte, Hao Wang,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01138", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01138", "title": "\nLearning Super-Resolution Jointly from External and Internal Examples", "abstract": "Single image super-resolution (SR) aims to estimate a high-resolution (HR) image from a lowresolution (LR) input. Image priors are commonly learned to regularize the otherwise seriously ill-posed SR problem, either using external LR-HR pairs or internal similar patterns. We propose joint SR to adaptively combine the advantages of both external and internal SR methods. We define two loss functions using sparse coding based external examples, and epitomic matching based on internal examples, as well as a corresponding adaptive weight to automatically balance their contributions according to their reconstruction errors. Extensive SR results demonstrate the effectiveness of the proposed method over the existing state-of-the-art methods, and is also verified by our subjective evaluation study.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Zhangyang Wang, Yingzhen Yang, Zhaowen Wang, Shiyu Chang, Jianchao Yang, Thomas S. Huang,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01129", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01129", "title": "\nComplexity and universality in the long-range order of words", "abstract": "As is the case of many signals produced by complex systems, language presents a statistical structure that is balanced between order and disorder. Here we review and extend recent results from quantitative characterisations of the degree of order in linguistic sequences that give insights into two relevant aspects of language: the presence of statistical universals in word ordering, and the link between semantic information and the statistical linguistic structure. We first analyse a measure of relative entropy that assesses how much the ordering of words contributes to the overall statistical structure of language. This measure presents an almost constant value close to 3.5 bits/word across several linguistic families. Then, we show that a direct application of information theory leads to an entropy measure that can quantify and extract semantic structures from linguistic samples, even without prior knowledge of the underlying language.", "subjects": "Computation and Language (cs.CL)", "authors": "Marcelo A Montemurro, Dami\u00e1n H Zanette,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01105", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01105", "title": "\nROSA: Robust sparse adaptive channel estimation in the presence of  impulsive noises", "abstract": "Based on the assumption of Gaussian noise model, conventional adaptive filtering algorithms for reconstruction sparse channels were proposed to take advantage of channel sparsity due to the fact that broadband wireless channels usually have the sparse nature. However, state-of-the-art algorithms are vulnerable to deteriorate under the assumption of non-Gaussian noise models (e.g., impulsive noise) which often exist in many advanced communications systems. In this paper, we study the problem of RObust Sparse Adaptive channel estimation (ROSA) in the environment of impulsive noises using variable step-size affine projection sign algorithm (VSS-APSA). Specifically, standard VSS-APSA algorithm is briefly reviewed and three sparse VSS-APSA algorithms are proposed to take advantage of channel sparsity with different sparse constraints. To fairly evaluate the performance of these proposed algorithms, alpha-stable noise is considered to approximately model the realistic impulsive noise environments. Simulation results show that the proposed algorithms can achieve better performance than standard VSS-APSA algorithm in different impulsive environments.", "subjects": "Information Theory (cs.IT)", "authors": "Guan Gui, Li Xu, Nobuhiro Shimoi,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01102", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01102", "title": "\nCooperative Base Station Coloring for Pair-wise Multi-Cell Coordination", "abstract": "A semi-static base station (BS) coordination strategy exploits predefined multiple BS cluster patterns for cooperative transmissions to improve the cell-edge user throughput. This paper proposes an efficient BS cluster pattern for pair-wise semi-static BS coordination, where edge users are guaranteed to be protected from dominant out-of-cluster interference in an irregular cellular network. The key idea is that each BS cluster is formed by using the 2nd-order Voronoi region of BSs locations and formed BS clusters are assigned to multiple cluster patterns by using the edge-coloring. The main advantage of the proposed BS cluster pattern is that every user is guaranteed to be served by the two closest BSs irrespective of a BS deployment scenario. With the proposed coordination strategy, analytical expressions for the rate distribution and the ergodic spectral efficiency are derived as a function of relevant system parameters in a non-random network model with irregular BS locations. A lower bound on the ergodic spectral efficiency is characterized for a random network where locations of BSs and users are modeled by using a homogeneous Poisson point process. Through simulations, the analytical expressions are verified, and the performance is compared with that of conventional methods. Our major finding is that the proposed BS cluster pattern provides considerable performance gains in both the rate coverage probability and the ergodic spectral efficiency for cell-edge users compared to conventional strategies.", "subjects": "Information Theory (cs.IT)", "authors": "Jeonghun Park, Namyoon Lee, Robert W. Heath Jr,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01098", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01098", "title": "\nRecognizing k-equistable graphs in FPT time", "abstract": "A graph is called equistable if there exist a positive integer and a weight function such that is a maximal stable set of if and only if . Such a function is called an equistable function of . For a positive integer , a graph is said to be -equistable if it admits an equistable function which is bounded by . We prove that the problem of recognizing -equistable graphs is fixed parameter tractable when parameterized by , affirmatively answering a question of Levit et al. In fact, the problem admits an -vertex kernel that can be computed in linear time.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Eun Jung Kim, Martin Milanic, Oliver Schaudt,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01093", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01093", "title": "\nA note on the longest common Abelian factor problem", "abstract": "Abelian string matching problems are becoming an object of considerable interest in last years. Very recently, Alatabbi et al. cite presented the first solution for the longest common Abelian factor problem for a pair of strings, reaching time with bits of space, where is the length of the strings and is the alphabet size. In this note we show how the time complexity can be preserved while the space is reduced by a factor of , and then how the time complexity can be improved, if the alphabet is not too small, when superlinear space is allowed.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Szymon Grabowski,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01082", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01082", "title": "\nAssessing a human mediated current awareness service", "abstract": "In this paper, we present an approach for analyzing the behavior of editors in the large current awareness service \"NEP: New Economics Papers\". We processed data from more than 38,000 issues derived from 90 different NEP reports over the past ten years. The aim of our analysis was to gain an inside to the editor behaviour when creating an issue and to look for factors that influence the success of a report. In our study we looked at the following features: average editing time, the average number of papers in an issue and the editor effort measured on presorted issues as relative search length (RSL). We found an average issue size of 12.4 documents per issue. The average editing time is rather low with 14.5 minute. We get to the point that the success of a report is mainly driven by its topic and the number of subscribers, as well as proactive action by the editor to promote the report in her community.", "subjects": "Digital Libraries (cs.DL)", "authors": "Zeljko Carevic, Thomas Krichel, Philipp Mayr,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01073", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01073", "title": "\nT3PS: Tool for Parallel Processing in Parameter Scans", "abstract": "T3PS is a program that can be used to quickly design and perform parameter scans while easily taking advantage of the multi-core architecture of current processors. It takes an easy to read and write parameter scan definition file format as input. Based on the parameter ranges and other options contained therein, it distributes the calculation of the parameter space over multiple processes and possibly computers. The derived data is saved in a plain text file format readable by most plotting software. The supported scanning strategies include: grid scan, random scan, Markov Chain Monte Carlo, numerical optimization. Several example parameter scans are shown and compared with results in the literature.", "subjects": "Mathematical Software (cs.MS)", "authors": "Vinzenz Maurer,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1503.01070", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01070", "title": "\nUsing Descriptive Video Services to Create a Large Data Source for Video  Annotation Research", "abstract": "In this work, we introduce a dataset of video annotated with high quality natural language phrases describing the visual content in a given segment of time. Our dataset is based on the Descriptive Video Service (DVS) that is now encoded on many digital media products such as DVDs. DVS is an audio narration describing the visual elements and actions in a movie for the visually impaired. It is temporally aligned with the movie and mixed with the original movie soundtrack. We describe an automatic DVS segmentation and alignment method for movies, that enables us to scale up the collection of a DVS-derived dataset with minimal human intervention. Using this method, we have collected the largest DVS-derived dataset for video description of which we are aware. Our dataset currently includes over 84.6 hours of paired video/sentences from 92 DVDs and is growing.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Atousa Torabi, Christopher Pal, Hugo Larochelle, Aaron Courville,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01068", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01068", "title": "\nAn approach to computing downward closures", "abstract": "The downward closure of a word language is the set of all (not necessarily contiguous) subwords of its members. It is well-known that the downward closure of any language is regular. While the downward closure appears to be a powerful abstraction, algorithms for computing downward closures have been established only for few language classes. This work presents a simple general method for computing downward closures. For language classes that are closed under rational transductions, it is shown that the computation of downward closures can be reduced to checking a certain unboundedness property. This result is used to show that downward closures are computable for (i) every language class with effectively semilinear Parikh images that are closed under rational transductions, (ii) matrix languages, and (iii) indexed languages (equivalently, languages accepted by higher-order pushdown automata of order~2).", "subjects": "Formal Languages and Automata Theory (cs.FL)", "authors": "Georg Zetzsche,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01067", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01067", "title": "\nExploring Cultures through Pattern Mining - Practices from Generative  Beauty Workshops", "abstract": "This paper presents a method for understanding personal ways of thinking and doing in daily lives among different countries by mining their ways as patterns in a sense of pattern language. Pattern language is a methodology of describing tacit practical knowledge, where each pattern consists of context, problem, and solution. In this paper, patterns mined from the workshops we held in the following three countries: Japan, Korea, and the United States, are analysed. The results demonstrate similarities and reflect characteristics of the patterns of each country. We anticipate that this workshop can be used as a method for better understanding of cultural similarities and features in the light of practical knowledge in daily lives.", "subjects": "Computers and Society (cs.CY)", "authors": "Jei-Hee Hong, Yuma Akado, Sakurako Kogure, Alice Sasabe, Keishi Saruwatari, Takashi Iba,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.01066", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01066", "title": "\nCollective achievement of making in cosplay culture", "abstract": "This paper analyzes peer-based learning and the concept of Scaffolding represented in ethnographic case studies of ten female informants aged 20-25 participating in the cosplay community. Cosplay is a female-dominated niche subculture of extreme fans and mavens, who are devoted to dressing up as characters from manga, games, and anime. Cosplayers are highly conscious of quality standards for costumes, makeup, and accessories. Cosplay events and dedicated SNSs for cosplayers are a valuable venue for exchanging information about costume making. First we frame this work as an effort to think about their learning environment using the concept of connected learning by Ito et al(2013). Then we share an overview of cosplay culture in Japan and our methodologies based on interviews and fieldwork. The interview transcripts were analyzed according to the Steps for coding and Theorization method, a qualitative data analysis technique by Otani (2008). In this study, We focus on their reciprocal learning and expanding the concept of Scaffolding.", "subjects": "Computers and Society (cs.CY)", "authors": "Rie Matsuura, Daisuke Okabe,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.01065", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01065", "title": "\nCollaboration Tools and Patterns for Creative Thinking", "abstract": "Many creativity methods follow similar structures and principles. Design Patterns capture such invariants of proven good practices and discuss why, when and how creative thinking methods match various situations of collaboration. Moreover patterns connect different forms with each other. Once we understand the underlying structures of creative thinking processes we can facilitate digital tools to support them. While such tools can foster the effective application of established methods and even change their properties, tools can also enable new patterns of collaboration.", "subjects": "Computers and Society (cs.CY)", "authors": "Christian Kohls,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.01063", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01063", "title": "\nOn the Capacity of Wireless Networks with Random Transmission Delay", "abstract": "In this paper, we introduce novel coding schemes for wireless networks with random transmission delays. These coding schemes obviate the need for synchronicity, reduce the number of transmissions and achieve the optimal rate region in the corresponding wired model for both multiple unicast and multicast cases with up to three users under the equal rate constraint. The coding schemes are presented in two phases; first, coding schemes for line, star and line-star topologies with random transmission delays are provided. Second, any general topology with multiple bidirectional unicast and multicast sessions is shown to be decomposable into these canonical topologies to reduce the number of transmissions without rate redundancy. As a result, the coding schemes developed for the line, star and line-star topologies serve as building blocks for the construction of more general coding schemes for all networks. The proposed schemes are proved to be Real Time (RT) for wireless networks in the sense that they achieve the minimal decoding delay. With a negligible size header, these coding schemes are shown to be applicable to unsynchronized networks, i.e., networks with random transmission delays. Finally, we demonstrate the applicability of these schemes by extensive simulations. The implementation of such coding schemes on a wireless network with random transmission delay can improve performance and power efficiency.", "subjects": "Information Theory (cs.IT)", "authors": "Niv Voskoboynik, Haim H. Permuter, Asaf Cohen,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01061", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01061", "title": "\nDistributed Hierarchical Control versus an Economic Model for Cloud  Resource Management", "abstract": "We investigate a hierarchically organized cloud infrastructure and compare distributed hierarchical control based on resource monitoring with market mechanisms for resource management. The latter do not require a model of the system, incur a low overhead, are robust, and satisfy several other desiderates of autonomic computing. We introduce several performance measures and report on simulation studies which show that a straightforward bidding scheme supports an effective admission control mechanism, while reducing the communication complexity by several orders of magnitude and also increasing the acceptance rate compared to hierarchical control and monitoring mechanisms. Resource management based on market-based mechanisms can be seen as an intermediate step towards cloud self-organization, an ideal alternative to current mechanisms for cloud resource management.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Dan C. Marinescu, Ashkan Paya, John P. Morrison, Philip Healy,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01058", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01058", "title": "\nAn algorithm for multiplication of split-octonions", "abstract": "In this paper we introduce efficient algorithm for the multiplication of split-octonions. The direct multiplication of two split-octonions requires 64 real multiplications and 56 real additions. More effective solutions still do not exist. We show how to compute a product of the split-octonions with 28 real multiplications and 92 real additions. During synthesis of the discussed algorithm we use the fact that product of two split-octonions may be represented as vector-matrix product. The matrix that participates in the product calculating has unique structural properties that allow performing its advantageous decomposition. Namely this decomposition leads to significant reducing of the multiplicative complexity of split-octonions multiplication.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Aleksandr Cariow, Galina Cariowa, Bartosz Kubsik,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01057", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01057", "title": "\nKernel Interpolation for Scalable Structured Gaussian Processes  (KISS-GP)", "abstract": "We introduce a new structured kernel interpolation (SKI) framework, which generalises and unifies inducing point methods for scalable Gaussian processes (GPs). SKI methods produce kernel approximations for fast computations through kernel interpolation. The SKI framework clarifies how the quality of an inducing point approach depends on the number of inducing (aka interpolation) points, interpolation strategy, and GP covariance kernel. SKI also provides a mechanism to create new scalable kernel methods, through choosing different kernel interpolation strategies. Using SKI, with local cubic kernel interpolation, we introduce KISS-GP, which is 1) more scalable than inducing point alternatives, 2) naturally enables Kronecker and Toeplitz algebra for substantial additional gains in scalability, without requiring any grid data, and 3) can be used for fast and expressive kernel learning. KISS-GP costs O(n) time and storage for GP inference. We evaluate KISS-GP for kernel matrix approximation, kernel learning, and natural sound modelling.", "subjects": "Learning (cs.LG)", "authors": "Andrew Gordon Wilson, Hannes Nickisch,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01056", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01056", "title": "\nSecrecy Transmit Beamforming for Heterogeneous Networks", "abstract": "In this paper, we pioneer the study of physical-layer security in heterogeneous networks (HetNets). We investigate secure communications in a two-tier downlink HetNet, which comprises one macrocell and several femtocells. Each cell has multiple users and an eavesdropper attempts to wiretap the intended macrocell user. Firstly, we consider an orthogonal spectrum allocation strategy to eliminate co-channel interference, and propose the secrecy transmit beamforming only operating in the macrocell (STB-OM) as a partial solution for secure communication in HetNet. Next, we consider a secrecy-oriented non-orthogonal spectrum allocation strategy and propose two cooperative STBs which rely on the collaboration amongst the macrocell base station (MBS) and the adjacent femtocell base stations (FBSs). Our first cooperative STB is the STB sequentially operating in the macrocell and femtocells (STB-SMF), where the cooperative FBSs individually design their STB matrices and then feed their performance metrics to the MBS for guiding the STB in the macrocell. Aiming to improve the performance of STB-SMF, we further propose the STB jointly designed in the macrocell and femtocells (STB-JMF), where all cooperative FBSs feed channel state information to the MBS for designing the joint STB. Unlike conventional STBs conceived for broadcasting or interference channels, the three proposed STB schemes all entail relatively sophisticated optimizations due to QoS constraints of the legitimate users. In order to efficiently use these STB schemes, the original optimization problems are reformulated and convex optimization techniques, such as second-order cone programming and semidefinite programming, are invoked to obtain the optimal solutions. Numerical results demonstrate that the proposed STB schemes are highly effective in improving the secrecy rate performance of HetNet.", "subjects": "Information Theory (cs.IT)", "authors": "Tiejun Lv, Hui Gao, Shaoshi Yang,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01052", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01052", "title": "\nEstimating the Benefits of Electric Vehicle Smart Charging at  Non-Residential Locations: A Data-Driven Approach", "abstract": "In this paper, we use data collected from over 2000 non-residential electric vehicle supply equipments (EVSEs) located in Northern California for the year of 2013 to estimate the potential benefits of smart electric vehicle (EV) charging. We develop a smart charging framework to identify the benefits of non-residential EV charging to the load aggregators and the distribution grid. Using this extensive dataset, we aim to improve upon past studies focusing on the benefits of smart EV charging by relaxing the assumptions made in these studies regarding: (i) driving patterns, driver behavior and driver types; (ii) the scalability of a limited number of simulated vehicles to represent different load aggregation points in the power system with different customer characteristics; and (iii) the charging profile of EVs. First, we study the benefits of EV aggregations behind-the-meter, where a time-of-use pricing schema is used to understand the benefits to the owner when EV aggregations shift load from high cost periods to lower cost periods. For the year of 2013, we show a reduction of up to 24.8% in the monthly bill is possible. Then, following a similar aggregation strategy, we show that EV aggregations decrease their contribution to the system peak load by approximately 40% when charging is controlled within arrival and departure times. Our results also show that it could be expected to shift approximately 0.25kWh (~2.8%) of energy per non-residential EV charging session from peak periods (12PM-6PM) to off-peak periods (after 6PM) in Northern California for the year of 2013.", "subjects": "Systems and Control (cs.SY)", "authors": "Emre Can Kara, Jason S. Macdonald, Douglas Black, Mario Berges, Gabriela Hug, Sila Kiliccote,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01051", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01051", "title": "\nCombining Probabilistic, Causal, and Normative Reasoning in CP-logic", "abstract": "In recent years the search for a proper formal definition of actual causation -- i.e., the relation of cause-effect as it is instantiated in specific observations, rather than general causal relations -- has taken on impressive proportions. In part this is due to the insight that this concept plays a fundamental role in many different fields, such as legal theory, engineering, medicine, ethics, etc. Because of this diversity in applications, some researchers have shifted focus from a single idealized definition towards a more pragmatic, context-based account. For instance, recent work by Halpern and Hitchcock draws on empirical research regarding people's causal judgments, to suggest a graded and context-sensitive notion of causation. Although we sympathize with many of their observations, their restriction to a merely qualitative ordering runs into trouble for more complex examples. Therefore we aim to improve on their approach, by using the formal language of CP-logic (Causal Probabilistic logic), and the framework for defining actual causation that was developed by the current authors using it. First we rephrase their ideas into our quantitative, probabilistic setting, after which we modify it to accommodate a greater class of examples. Further, we introduce a formal distinction between statistical and normative considerations.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Sander Beckers, Joost Vennekens,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01034", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01034", "title": "\nQuantomatic: A proof assistant for diagrammatic reasoning", "abstract": "Monoidal algebraic structures consist of operations that can have multiple outputs as well as multiple inputs, which have applications in many areas including categorical algebra, programming language semantics, representation theory, algebraic quantum information, and quantum groups. String diagrams provide a convenient graphical syntax for reasoning formally about such structures, while avoiding many of the technical challenges of a term-based approach. Quantomatic is a tool that supports the (semi-)automatic construction of equational proofs using string diagrams. We briefly outline the theoretical basis of Quantomatic's rewriting engine, then give an overview of the core features and architecture and give a simple example project that computes normal forms for commutative bialgebras.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Aleks Kissinger, Vladimir Zamdzhiev,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01008", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01008", "title": "\nTropical Dominating Sets in Vertex-Coloured Graphs", "abstract": "Given a vertex-coloured graph, a dominating set is said to be tropical if every colour of the graph appears at least once in the set. Here, we study minimum tropical dominating sets from structural and algorithmic points of view. First, we prove that the tropical dominating set problem is NP-complete even when restricted to a simple path. Then, we establish upper bounds related to various parameters of the graph such as minimum degree and number of edges. We also give upper bounds for random graphs. Last, we give approximability and inapproximability results for general and restricted classes of graphs, and establish a FPT algorithm for interval graphs.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "J.-A. Angles d'Auriac, Cs. Bujtas, H. El Maftouhi, M. Karpinski, Y. Manoussakis, L. Montero, N. Narayanan, L. Rosaz, J. Thapper, Zs. Tuza,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01007", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01007", "title": "\nInferring Algorithmic Patterns with Stack-Augmented Recurrent Nets", "abstract": "While machine learning is currently very successful in several application domains, we are still very far from achieving a real artificial intelligence. In this paper, we study basic sequence prediction problems that are beyond the scope of what is learnable with popular methods such as recurrent networks. We show that simple algorithms can be learned from sequential data with a recurrent network associated with trainable stacks. We focus our study on algorithmically generated sequences such as , that can only be learned by models which have the capacity to count. Once trained, we show that our method is able generalize to sequences up to an arbitrary size. We discuss the limitations of standard machine learning approaches to learn algorithmic regularities of this type. We propose directions to overcome these shortcomings, such as using search based optimization.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "Armand Joulin, Tomas Mikolov,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.01002", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.01002", "title": "\nProjection onto the capped simplex", "abstract": "We provide a simple and efficient algorithm for computing the Euclidean projection of a point onto the capped simplex---a simplex with an additional uniform bound on each coordinate---together with an elementary proof. Both the MATLAB and C++ implementations of the proposed algorithm can be downloaded at this https URL", "subjects": "Learning (cs.LG)", "authors": "Weiran Wang, Canyi Lu,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00992", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00992", "title": "\nAnisotropic Diffusion in ITK", "abstract": "Anisotropic Non-Linear Diffusion is a powerful image processing technique, which allows to simultaneously remove the noise and enhance sharp features in two or three dimensional images. Anisotropic Diffusion is understood here in the sense of Weickert, meaning that diffusion tensors are anisotropic and reflect the local orientation of image features. This is in contrast with the non-linear diffusion filter of Perona and Malik, which only involves scalar diffusion coefficients, in other words isotropic diffusion tensors. In this paper, we present an anisotropic non-linear diffusion technique we implemented in ITK. This technique is based on a recent adaptive scheme making the diffusion stable and requiring limited numerical resources. (See supplementary data.)", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Jean-Marie Mirebeau, J\u00e9r\u00f4me Fehrenbach, Laurent Risser, Shaza Tobji,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00981", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00981", "title": "\nMorphological Detector for Multilevel Signals in epsilon-Noise", "abstract": "The novel approach was developed for multilevel signal detection in channels with impulsive non-Gaussian noise. This approach consists of using morphological nonlinear image filtration principles for two dimensional signals. It is a new method of signal demodulation, using three - dimensional image processing algorithms. Successful results of this morphological detector encourage more investigation towards using image processing theory and algorithms for two dimensional signal processing. As can be seen in the example in section IV, this new approach of reusing well developed and extensively developing image processing has significantly improved performance.", "subjects": "Information Theory (cs.IT)", "authors": "Sander Stepanov, Anastasios Venetsanopoulos,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00980", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00980", "title": "\nOn memetic search for the max-mean dispersion problem", "abstract": "Given a set of elements and a distance matrix among elements, the max-mean dispersion problem (MaxMeanDP) consists in selecting a subset from such that the mean dispersion (or distance) among the selected elements is maximized. Being a useful model to formulate several relevant applications, MaxMeanDP is known to be NP-hard and thus computationally difficult. In this paper, we present a highly effective memetic algorithm for MaxMeanDP which relies on solution recombination and local optimization to find high quality solutions. Computational experiments on the set of 160 benchmark instances with up to 1000 elements commonly used in the literature show that the proposed algorithm improves or matches the published best known results for all instances in a short computing time, with only one exception, while achieving a high success rate of 100 %. In particular, we improve 59 previous best results out of the 60 most challenging instances. Results on a set of 40 new large instances with 3000 and 5000 elements are also presented. The key ingredients of the proposed algorithm are investigated to shed light on how they affect the performance of the algorithm.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Xiangjing Lai, Jin-Kao Hao,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00949", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00949", "title": "\nWeakly Supervised Object Localization with Multi-fold Multiple Instance  Learning", "abstract": "Object category localization is a challenging problem in computer vision. Standard supervised training requires bounding box annotations of object instances. This time-consuming annotation process is sidestepped in weakly supervised learning. In this case, the supervised information is restricted to binary labels that indicate the absence/presence of object instances in the image, without their locations. We follow a multiple-instance learning approach that iteratively trains the detector and infers the object locations in the positive training images. Our main contribution is a multi-fold multiple instance learning procedure, which prevents training from prematurely locking onto erroneous object locations. This procedure is particularly important when using high-dimensional representations, such as Fisher vectors and convolutional neural network features. We also propose a window refinement method, which improves the localization accuracy by incorporating an objectness prior. We present a detailed experimental evaluation using the PASCAL VOC 2007 dataset, which verifies the effectiveness of our approach.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Ramazan Gokberk Cinbis, Jakob Verbeek, Cordelia Schmid,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00948", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00948", "title": "\nHilbert-Post completeness for the state and the exception effects", "abstract": "In this paper, we present a novel framework for studying the syntactic completeness of computational effects and we apply it to the exception effect. When applied to the states effect, our framework can be seen as a generalization of Pretnar's work on this subject. We first introduce a relative notion of Hilbert-Post completeness, well-suited to the composition of effects. Then we prove that the exception effect is relatively Hilbert-Post complete, as well as the \" core \" language which may be used for implementing it; these proofs have been formalized and checked with the proof assistant Coq.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Jean-Guillaume Dumas, Dominique Duval, Burak Ekici, Damien Pous, Jean-Claude Reynaud,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00943", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00943", "title": "\nTransform Domain Analysis of Sequences", "abstract": "In cryptanalysis, security of ciphers vis-a-vis attacks is gauged against three criteria of complexities, i.e., computations, memory and time. Some features may not be so apparent in a particular domain, and their analysis in a transformed domain often reveals interesting patterns. Moreover, the complexity criteria in different domains are different and performance improvements are often achieved by transforming the problem in an alternate domain. Owing to the results of coding theory and signal processing, Discrete Fourier Transform (DFT) based attacks have proven to be efficient than algebraic attacks in terms of their computational complexity. Motivated by DFT based attacks, we present a transform domain analysis of Linear Feedback Shift Register(LFSR) based sequence generators. The time and frequency domain behavior of non-linear filter and combiner generators is discussed along with some novel observations based on the Chinese Remainder Theorem (CRT). CRT is exploited to establish patterns in LFSR sequences and underlying cyclic structures of finite fields. Application of DFT spectra attacks on combiner generators is also demonstrated. Our proposed method saves on the last stage computations of selective DFT attacks for combiner generators. The proposed approach is demonstrated on some examples of combiner generators and is scalable to general configuration of combiner generators.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Muhammad Asad Khan, Amir A Khan, Fauzan Mirza,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00941", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00941", "title": "\nApproximation Algorithms for Computing Maximin Share Allocations", "abstract": "We study the problem of computing maximin share guarantees, a recently introduced fairness notion. Given a set of agents and a set of goods, the maximin share of a single agent is the best that she can guarantee to herself, if she would be allowed to partition the goods in any way she prefers, into bundles, and then receive her least desirable bundle. The objective then in our problem is to find a partition, so that each agent is guaranteed her maximin share. In settings with indivisible goods, such allocations are not guaranteed to exist, so we resort to approximation algorithms. Our main result is a -approximation, that runs in polynomial time for any number of agents. This improves upon the algorithm of Procaccia and Wang, which also produces a -approximation but runs in polynomial time only for a constant number of agents. To achieve this, we redesign certain parts of their algorithm. Furthermore, motivated by the apparent difficulty, both theoretically and experimentally, in finding lower bounds on the existence of approximate solutions, we undertake a probabilistic analysis. We prove that in randomly generated instances, with high probability there exists a maximin share allocation. This can be seen as a justification of the experimental evidence reported in relevant works. Finally, we provide further positive results for two special cases that arise from previous works. The first one is the intriguing case of agents, for which it is already known that exact maximin share allocations do not always exist (contrary to the case of agents). We provide a -approximation algorithm, improving the previously known result of . The second case is when all item values belong to , extending the setting studied in Bouveret and Lema ^itre. We obtain an exact algorithm for any number of agents in this case.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Georgios Amanatidis, Evangelos Markakis, Afshin Nikzad, Amin Saberi,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00923", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00923", "title": "\nAn Interoperable Realization of Smart Cities with Plug and Play based  Device Management", "abstract": "The primal problem with Internet of Things (IoT) solutions for smart cities is the lack of interoperability at various levels, and more predominately at the device level. While there exist multitude of platforms from multiple manufacturers, the existing ecosystem still remains highly closed. In this paper, we propose SNaaS or Sensor/Network as a Service: a service layer that enables the creation of the plug-n-play infrastructure, across platforms from multiple vendors, necessary for interoperability and successful deployment of large-scale city wide systems. In order to correctly position the new service layer, we present a high level reference IoT architecture for smart city implementations, and follow it up with the workflow details of SNaaS along with preliminary microbenchmarks.", "subjects": "Systems and Control (cs.SY)", "authors": "Prasant Misra, Vasanth Rajaraman, Kumaresh Dhotrad, Jay Warrior, Yogesh Simmhan,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00916", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00916", "title": "\nDoF Analysis of the K-user MISO Broadcast Channel with Hybrid CSIT", "abstract": "We consider a -user multiple-input single-output (MISO) broadcast channel (BC) where the channel state information (CSI) of user may be either instantaneously perfect (P), delayed (D) or not known (N) at the transmitter with probabilities , and , respectively. In this setting, according to the three possible CSIT for each user, knowledge of the joint CSIT of the users could have at most states. Although the results by Tandon et al. show that for the symmetric two user MISO BC (i.e., ), the Degrees of Freedom (DoF) region depends only on the marginal probabilities, we show that this interesting result does not hold in general when . In other words, the DoF region is a function of all the joint probabilities. In this paper, given the marginal probabilities of CSIT, we derive an outer bound for the DoF region of the -user MISO BC. Subsequently, we investigate the achievability of the outer bound in some scenarios. Finally, we show the dependence of the DoF region on the joint probabilities.", "subjects": "Information Theory (cs.IT)", "authors": "Borzoo Rassouli, Chenxi Hao, Bruno Clerckx,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00900", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00900", "title": "\nNormalization based K means Clustering Algorithm", "abstract": "K-means is an effective clustering technique used to separate similar data into groups based on initial centroids of clusters. In this paper, Normalization based K-means clustering algorithm(N-K means) is proposed. Proposed N-K means clustering algorithm applies normalization prior to clustering on the available data as well as the proposed approach calculates initial centroids based on weights. Experimental results prove the betterment of proposed N-K means clustering algorithm over existing K-means clustering algorithm in terms of complexity and overall performance.", "subjects": "Learning (cs.LG)", "authors": "Deepali Virmani, Shweta Taneja, Geetika Malhotra,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00899", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00899", "title": "\nAn Ant Colony Optimization Algorithm for Partitioning Graphs with Supply  and Demand", "abstract": "In this paper we focus on finding high quality solutions for the problem of maximum partitioning of graphs with supply and demand (MPGSD). There is a growing interest for the MPGSD due to its close connection to problems appearing in the field of electrical distribution systems, especially for the optimization of self-adequacy of interconnected microgrids. We propose an ant colony optimization algorithm for the problem. With the goal of further improving the algorithm we combine it with a previously developed correction procedure. In our computational experiments we evaluate the performance of the proposed algorithm on both trees and general graphs. The tests show that the method manages to find optimal solutions in more than 50% of the problem instances, and has an average relative error of less than 0.5% when compared to known optimal solutions.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Raka Jovanovic, Milan Tuba, Stefan Voss,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00886", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00886", "title": "\nOn Geometry of Interaction for Polarized Linear Logic", "abstract": "We present Geometry of Interaction (GoI) models for Multiplicative Polarized Linear Logic, MLLP, the multiplicative fragment (without structural rules) of Olivier Laurent's Polarized Linear Logic. This is done by uniformly adding multipoints to various categorical models of GoI. Multipoints are shown to play an essential role in semantically characterizing the dynamics of proof networks in polarized proof theory. They permit us to characterize the key feature of polarization, focusing, as well as playing a fundamental role in helping us construct concrete polarized GoI models. Our approach to polarized GoI involves two independent studies based on different categorical approaches to GoI. (i) Inspired by work of Abramsky, Haghverdi, and Scott, a polarized GoI situation is defined which adds multipoints to a traced monoidal category with an appropriate reflexive object U. Categorical versions of Girard's Execution formula (taking into account the multipoints) are defined, as well as the GoI interpretation of MLLP proofs. The Execution formula is shown to characterize the focusing property (thus polarities) as well as the dynamics of cut-elimination. (ii) The Int construction of Joyal-Street-Verity is another fundamental categorical structure associated to GoI. Here, we investigate it in a multipointed setting compatible with the existence of certain weak pullbacks. This yields a method for constructing denotational models of MLLP, in particular a compact version of Hamano-Scott's polarized categories. These are built from a contravariant duality between so-called positive and negative monoidal categories, along with an appropriate module structure (representing \"non-focused proofs\") between them. As a special case of (ii) above, a compact model of MLLP is also presented based on Rel_+ with multi-points.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Masahiro Hamano, Philip Scott,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00883", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00883", "title": "\nEfficiently intertwining widening and narrowing", "abstract": "Non-trivial analysis problems require posets with infinite ascending and descending chains. In order to compute reasonably precise post-fixpoints of the resulting systems of equations, Cousot and Cousot have suggested accelerated fixpoint iteration by means of widening and narrowing. The strict separation into phases, however, may unnecessarily give up precision that cannot be recovered later, as over-approximated interim results have to be fully propagated through the equation the system. Additionally, classical two-phased approach is not suitable for equation systems with infinitely many unknowns---where demand driven solving must be used. Construction of an intertwined approach must be able to answer when it is safe to apply narrowing---or when widening must be applied. In general, this is a difficult problem. In case the right-hand sides of equations are monotonic, however, we can always apply narrowing whenever we have reached a post-fixpoint for an equation. The assumption of monotonicity, though, is not met in presence of widening. It is also not met by equation systems corresponding to context-sensitive inter-procedural analysis, possibly combining context-sensitive analysis of local information with flow-insensitive analysis of globals. As a remedy, we present a novel operator that combines a given widening operator with a given narrowing operator. We present adapted versions of round-robin as well as of worklist iteration, local and side-effecting solving algorithms for the combined operator and prove that the resulting solvers always return sound results and are guaranteed to terminate for monotonic systems whenever only finitely many unknowns (constraint variables) are encountered. Practical remedies are proposed for termination in the non-monotonic case.", "subjects": "Programming Languages (cs.PL)", "authors": "Gianluca Amato, Francesca Scozzari, Helmut Seidl, Kalmer Apinis, Vesal Vojdani,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00879", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00879", "title": "\nStabilizer quantum codes from $J$-affine variety codes and a new  Steane-like enlargement", "abstract": "New stabilizer codes with parameters better than the ones available in the literature are provided in this work, in particular quantum codes with parameters and that are records. These codes are constructed with a new generalization of the Steane's enlargement procedure and by considering orthogonal subfield-subcodes --with respect to the Euclidean and Hermitian inner product-- of a new family of linear codes, the -affine variety codes.", "subjects": "Information Theory (cs.IT)", "authors": "Carlos Galindo, Fernando Hernando, Diego Ruano,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00877", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00877", "title": "\nModeling and Analysis of Wireless Channels via the Mixture of Gaussian  Distribution", "abstract": "Considerable efforts have been devoted to statistical modeling and the characterization of channels in a range of statistical models for fading channels. In this paper, we consider a unified approach to model wireless channels by the mixture of Gaussian (MoG) distribution. Simulations provided have shown the new probability density function to accurately characterize multipath fading as well as composite fading channels. We utilize the well known expectation-maximization algorithm to estimate the parameters of the MoG model and further utilize the Kullback-Leibler divergence and the mean square error criteria to demonstrate that our model provides both high accuracy and low computational complexity, in comparison with existing results. Additionally, we provide closed form expressions for several performance metrics used in wireless communication systems, including the moment generating function, the raw moments, the amount of fading, the outage probability, the average channel capacity, and the probability of energy detection for cognitive radio. Numerical Analysis and Monte-Carlo simulations are presented to corroborate the analytical results and to provide detailed performance comparisons with the other models in the literature.", "subjects": "Information Theory (cs.IT)", "authors": "Bassant Selim, Omar Alhussein, Sami Muhaidat, George K. Karagiannidis, Jie Liang,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00851", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00851", "title": "\nConnectionist-Symbolic Machine Intelligence using Cellular Automata  based Reservoir-Hyperdimensional Computing", "abstract": "We introduce a novel framework of reservoir computing, that is capable of both connectionist machine intelligence and symbolic computation. Cellular automaton is used as the reservoir of dynamical systems. Input is randomly projected onto the initial conditions of automaton cells and nonlinear computation is performed on the input via application of a rule in the automaton for a period of time. The evolution of the automaton creates a space-time volume of the automaton state space, and it is used as the reservoir. The proposed framework is capable of long short-term memory and it requires orders of magnitude less computation compared to Echo State Networks. We prove that cellular automaton reservoir holds a distributed representation of attribute statistics, which provides a more effective computation than local representation. It is possible to estimate the kernel for linear cellular automata via metric learning, that enables a much more efficient distance computation in support vector machine framework. Also, binary reservoir feature vectors can be combined using Boolean operations as in hyperdimensional computing, paving a direct way for concept building and symbolic processing.", "subjects": "Emerging Technologies (cs.ET)", "authors": "Ozgur Yilmaz,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00849", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00849", "title": "\nA Selectivity based approach to Continuous Pattern Detection in  Streaming Graphs", "abstract": "Cyber security is one of the most significant technical challenges in current times. Detecting adversarial activities, prevention of theft of intellectual properties and customer data is a high priority for corporations and government agencies around the world. Cyber defenders need to analyze massive-scale, high-resolution network flows to identify, categorize, and mitigate attacks involving networks spanning institutional and national boundaries. Many of the cyber attacks can be described as subgraph patterns, with prominent examples being insider infiltrations (path queries), denial of service (parallel paths) and malicious spreads (tree queries). This motivates us to explore subgraph matching on streaming graphs in a continuous setting. The novelty of our work lies in using the subgraph distributional statistics collected from the streaming graph to determine the query processing strategy. We introduce a \"Lazy Search\" algorithm where the search strategy is decided on a vertex-to-vertex basis depending on the likelihood of a match in the vertex neighborhood. We also propose a metric named \"Relative Selectivity\" that is used to select between different query processing strategies. Our experiments performed on real online news, network traffic stream and a synthetic social network benchmark demonstrate 10-100x speedups over selectivity agnostic approaches.", "subjects": "Databases (cs.DB)", "authors": "Sutanay Choudhury, Lawrence Holder, George Chin, Khushbu Agarwal, John Feo,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00848", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00848", "title": "\nMultiscale Combinatorial Grouping for Image Segmentation and Object  Proposal Generation", "abstract": "We propose a unified approach for bottom-up hierarchical image segmentation and object proposal generation for recognition, called Multiscale Combinatorial Grouping (MCG). For this purpose, we first develop a fast normalized cuts algorithm. We then propose a high-performance hierarchical segmenter that makes effective use of multiscale information. Finally, we propose a grouping strategy that combines our multiscale regions into highly-accurate object proposals by exploring efficiently their combinatorial space. We also present Single-scale Combinatorial Grouping (SCG), a faster version of MCG that produces competitive proposals in under five second per image. We conduct an extensive and comprehensive empirical validation on the BSDS500, SegVOC12, SBD, and COCO datasets, showing that MCG produces state-of-the-art contours, hierarchical regions, and object proposals.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Jordi Pont-Tuset, Pablo Arbelaez, Jonathan T. Barron, Ferran Marques, Jitendra Malik,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00843", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00843", "title": "\nA Survey On Video Forgery Detection", "abstract": "The Digital Forgeries though not visibly identifiable to human perception it may alter or meddle with underlying natural statistics of digital content. Tampering involves fiddling with video content in order to cause damage or make unauthorized alteration/modification. Tampering detection in video is cumbersome compared to image when considering the properties of the video. Tampering impacts need to be studied and the applied technique/method is used to establish the factual information for legal course in judiciary. In this paper we give an overview of the prior literature and challenges involved in video forgery detection where passive approach is found.", "subjects": "Multimedia (cs.MM)", "authors": "Sowmya K.N., H.R. Chennamma,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00841", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00841", "title": "\nRobustly Leveraging Prior Knowledge in Text Classification", "abstract": "Prior knowledge has been shown very useful to address many natural language processing tasks. Many approaches have been proposed to formalise a variety of knowledge, however, whether the proposed approach is robust or sensitive to the knowledge supplied to the model has rarely been discussed. In this paper, we propose three regularization terms on top of generalized expectation criteria, and conduct extensive experiments to justify the robustness of the proposed methods. Experimental results demonstrate that our proposed methods obtain remarkable improvements and are much more robust than baselines.", "subjects": "Computation and Language (cs.CL)", "authors": "Biao Liu, Minlie Huang,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00833", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00833", "title": "\nThe complexity of dominating set reconfiguration", "abstract": "Suppose that we are given two dominating sets and of a graph whose cardinalities are at most a given threshold . Then, we are asked whether there exists a sequence of dominating sets of between and such that each dominating set in the sequence is of cardinality at most and can be obtained from the previous one by either adding or deleting exactly one vertex. This problem is known to be PSPACE-complete in general. In this paper, we study the complexity of this decision problem from the viewpoint of graph classes. We first prove that the problem remains PSPACE-complete even for planar graphs, bounded bandwidth graphs, split graphs, and bipartite graphs. We then give a general scheme to construct linear-time algorithms and show that the problem can be solved in linear time for cographs, trees, and interval graphs. Furthermore, for these tractable cases, we can obtain a desired sequence such that the number of additions and deletions is bounded by , where is the number of vertices in the input graph.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Arash Haddadan, Takehiro Ito, Amer E. Mouawad, Naomi Nishimura, Hirotaka Ono, Akira Suzuki, Youcef Tebbal,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00827", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00827", "title": "\nHow to Round Subspaces: A New Spectral Clustering Algorithm", "abstract": "Consider the problem of approximating a -dimensional linear subspace with another constant subspace in spectral norm. This problem is at the heart of many spectral methods used in data clustering and graph partitioning. Our main contribution is a new spectral clustering algorithm: It can recover a -partition such that the subspace corresponding to the span of its indicator vectors is close to the original subspace in spectral norm, with being the minimum possible. Moreover our algorithm does not impose any restriction on the cluster sizes. Previously, no algorithm was known which could find a -partition closer than . We present two applications for our algorithm. First one finds a disjoint union of -expanders which approximate a given graph in spectral norm. The second one is for approximating the -partition whose clusters have expansion at most on graphs satisfying , where is the eigenvalue of Laplacian matrix. This significantly improves upon the previous algorithms, which required .", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Ali Kemal Sinop,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00826", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00826", "title": "\nTowards Reasoning About Properties of Imperative Programs using Linear  Logic", "abstract": "In this paper we propose an approach to reasoning about properties of imperative programs. We assume in this context that the meanings of program constructs are described using rules in the natural semantics style with the additional observation that these rules may involve the treatment of state. Our approach involves modeling natural semantics style rules within a logic and then reasoning about the behavior of particular programs by reasoning about proofs in that logic. A key aspect of our proposal is to use a fragment of linear logic called Lolli (invented by Hodas and Miller) to model natural semantics style descriptions. Being based on linear logic, Lolli can provide logical expression to resources such as state. Lolli additionally possesses proof-theoretic properties that allow it to encode natural semantics style descriptions in such a way that proofs in Lolli mimic the structure of derivations based on the natural semantics rules. We will discuss these properties of Lolli and demonstrate how they can be exploited in modeling the semantics of imperative programs and in reasoning about such models.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Daniel DaCosta,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00814", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00814", "title": "\nMobile Application for Dengue Fever Monitoring and Tracking via GPS:  Case Study for Fiji", "abstract": "The 2013 outbreak of Dengue in Fiji resulted in an alarming number of deaths and has been is a matter of serious concern. Dengue fever is a disease caused by the four types of the Dengue virus serotypes and transmitted mostly from mosquito bites. In Fiji, dengue diagnosis is only done in hospitals which are slow and time consuming. It is also important to monitor the spread of Dengue. Fiji needs an convenient method of monitoring the spread of Dengue. With increase in affordable smartphones and better Internet coverage, there is scope for a mobile application for Dengue fever monitoring and tracking. This paper proposes a mobile application for Dengue monitoring based on global positioning system (GPS) enabled mobile phone technology. It also provides an information network that shows the spread of dengue which will allow health authorities to quickly identify dengue infected areas in Fiji. A mobile application prototype is developed and tested and the scope for further testing and implementation is also given.", "subjects": "Computers and Society (cs.CY)", "authors": "Emmenual Reddy, Sarnil Kumar, Nicholas Rollings, Rohitash Chandra,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00812", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00812", "title": "\nUndirected Rigid Formations are Problematic", "abstract": "By an undirected rigid formation of mobile autonomous agents is meant a formation based on graph rigidity in which each pair of \"neighboring\" agents is responsible for maintaining a prescribed target distance between them. In a recent paper a systematic method was proposed for devising gradient control laws for asymptotically stabilizing a large class of rigid, undirected formations in two dimensional space assuming all agents are described by kinematic point models. The aim of this paper is to explain what happens to such formations if neighboring agents have slightly different understandings of what the desired distance between them is supposed to be or equivalently if neighboring agents have differing estimates of what the actual distance between them is. In either case, what one would expect would be a gradual distortion of the formation from its target shape as discrepancies in desired or sensed distances increase. While this is observed for the gradient laws in question, something else quite unexpected happens at the same time. It is shown that for any rigidity-based, undirected formation of this type which is comprised of three or more agents, that if some neighboring agents have slightly different understandings of what the desired distances between them are suppose to be, then almost for certain, the trajectory of the resulting distorted but rigid formation will converge exponentially fast to a closed circular orbit in two-dimensional space which is traversed periodically at a constant angular speed.", "subjects": "Systems and Control (cs.SY)", "authors": "Shaoshuai Mou, A. Stephen Morse, Mohamed Ali Belabbas, Zhiyong Sun, Brian D. O. Anderson,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00810", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00810", "title": "\nDevelopment of an Android Application for an Electronic Medical Record  System in an Outpatient Environment for Healthcare in Fiji", "abstract": "The outpatients department in a developing country is typically understaffed and inadequately equipped to handle a large numbers of patients filing through on an average day. The use of electronic medical record (EMR) systems can resolve some of the longstanding medical inefficiencies common in developing countries. This paper presents the design and implementation of a proposed outpatient management system that enables efficient management of a patient's medical details. We present a system to create appointments with medical practitioners by integrating a proposed Android-based mobile application with a selected open source EMR system. The application allows both the patient and the medical practitioners to manage appointments and make use of the electronic messaging facility to send reminders when the appointed time is approaching in real-time. A mobile application prototype is developed and the road map for implementation is also discussed.", "subjects": "Computers and Society (cs.CY)", "authors": "Daryl Abel, Bulou Gavidi, Nicholas Rollings, Rohitash Chandra,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00808", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00808", "title": "\nA Distributed Algorithm for Solving a Linear Algebraic Equation", "abstract": "A distributed algorithm is described for solving a linear algebraic equation of the form assuming the equation has at least one solution. The equation is simultaneously solved by agents assuming each agent knows only a subset of the rows of the partitioned matrix , the current estimates of the equation's solution generated by its neighbors, and nothing more. Each agent recursively updates its estimate by utilizing the current estimates generated by each of its neighbors. Neighbor relations are characterized by a time-dependent directed graph whose vertices correspond to agents and whose arcs depict neighbor relations. It is shown that for any matrix for which the equation has a solution and any sequence of \"repeatedly jointly strongly connected graphs\" , , the algorithm causes all agents' estimates to converge exponentially fast to the same solution to . It is also shown that the neighbor graph sequence must actually be repeatedly jointly strongly connected if exponential convergence is to be assured. A worst case convergence rate bound is derived for the case when has a unique solution. It is demonstrated that with minor modification, the algorithm can track the solution to , even if and are changing with time, provided the rates of change of and are sufficiently small. It is also shown that in the absence of communication delays, exponential convergence to a solution occurs even if the times at which each agent updates its estimates are not synchronized with the update times of its neighbors. A modification of the algorithm is outlined which enables it to obtain a least squares solution to in a distributed manner, even if does not have a solution.", "subjects": "Systems and Control (cs.SY)", "authors": "Shaoshuai Mou, Ji Liu, A. Stephen Morse,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00806", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00806", "title": "\nAn Introduction to Logics of Knowledge and Belief", "abstract": "This chapter provides an introduction to some basic concepts of epistemic logic, basic formal languages, their semantics, and proof systems. It also contains an overview of the handbook, and a brief history of epistemic logic and pointers to the literature.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Hans van Ditmarsch, Joseph Y. Halpern, Wiebe van der Hoek, Barteld Kooi,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00805", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00805", "title": "\nBinary Search in Graphs", "abstract": "We study the following natural generalization of Binary Search to arbitrary connected graphs and finite metric spaces. In a given and known undirected positively weighted graph, one vertex is a target. The algorithm's task is to identify the target by adaptively querying vertices. In response to querying a vertex q, the algorithm learns either that q is the target, or is given an edge out of q that lies on a shortest path from q to the target. Our main positive result is that in undirected graphs, log_2(n) queries are always sufficient to find the target. This result extends to directed graphs that are \"almost undirected\" in the sense that each edge e with weight w(e) is part of a cycle of total weight at most c.w(e): here, c.ln(n) queries are sufficient. On the negative side, for strongly connected directed graphs, deciding whether K queries are sufficient to identify the target in the worst case is PSPACE-complete. This result also applies to undirected graphs with non-uniform query costs. We also show hardness in the polynomial hierarchy for a \"semi-adaptive\" version of the problem: the algorithm gets to query r vertices each in k rounds. This version is Sigma_-hard and in Sigma_ in the polynomial hierarchy.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Ehsan Emamjomeh-Zadeh, David Kempe,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00802", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00802", "title": "\nMaximum correntropy criterion based sparse adaptive filtering algorithms  for robust channel estimation under non-Gaussian environments", "abstract": "Sparse adaptive channel estimation problem is one of the most important topics in broadband wireless communications systems due to its simplicity and robustness. So far many sparsity-aware channel estimation algorithms have been developed based on the well-known minimum mean square error (MMSE) criterion, such as the zero-attracting least mean square (ZALMS), which are robust under Gaussian assumption. In non-Gaussian environments, however, these methods are often no longer robust especially when systems are disturbed by random impulsive noises. To address this problem, we propose in this work a robust sparse adaptive filtering algorithm using correntropy induced metric (CIM) penalized maximum correntropy criterion (MCC) rather than conventional MMSE criterion for robust channel estimation. Specifically, MCC is utilized to mitigate the impulsive noise while CIM is adopted to exploit the channel sparsity efficiently. Both theoretical analysis and computer simulations are provided to corroborate the proposed methods.", "subjects": "Information Theory (cs.IT)", "authors": "Wentao Ma, Hua Qua, Guan Gui, Li Xu, Jihong Zhaoa, Badong Chen,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00800", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00800", "title": "\nIMAC: Impulsive-mitigation adaptive sparse channel estimation based on  Gaussian-mixture model", "abstract": "Broadband frequency-selective fading channels usually have the inherent sparse nature. By exploiting the sparsity, adaptive sparse channel estimation (ASCE) methods, e.g., reweighted L1-norm least mean square (RL1-LMS), could bring a performance gain if additive noise satisfying Gaussian assumption. In real communication environments, however, channel estimation performance is often deteriorated by unexpected non-Gaussian noises which include conventional Gaussian noises and impulsive interferences. To design stable communication systems, hence, it is urgent to develop advanced channel estimation methods to remove the impulsive interference and to exploit channel sparsity simultaneously. In this paper, robust impulsive-mitigation adaptive sparse channel estimation (IMAC) method is proposed for solving aforementioned technical issues. Specifically, first of all, the non-Gaussian noise model is described by Gaussian mixture model (GMM). Secondly, cost function of reweighted L1-norm penalized least absolute error standard (RL1-LAE) algorithm is constructed. Then, RL1-LAE algorithm is derived for realizing IMAC method. Finally, representative simulation results are provided to corroborate the studies.", "subjects": "Information Theory (cs.IT)", "authors": "Tingping Zhang, Jingpei Dan, Guan Gui,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00798", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00798", "title": "\nImproved adaptive sparse channel estimation using mixed square/fourth  error criterion", "abstract": "Sparse channel estimation problem is one of challenge technical issues in stable broadband wireless communications. Based on square error criterion (SEC), adaptive sparse channel estimation (ASCE) methods, e.g., zero-attracting least mean square error (ZA-LMS) algorithm and reweighted ZA-LMS (RZA-LMS) algorithm, have been proposed to mitigate noise interferences as well as to exploit the inherent channel sparsity. However, the conventional SEC-ASCE methods are vulnerable to 1) random scaling of input training signal; and 2) imbalance between convergence speed and steady state mean square error (MSE) performance due to fixed step-size of gradient descend method. In this paper, a mixed square/fourth error criterion (SFEC) based improved ASCE methods are proposed to avoid aforementioned shortcomings. Specifically, the improved SFEC-ASCE methods are realized with zero-attracting least mean square/fourth error (ZA-LMS/F) algorithm and reweighted ZA-LMS/F (RZA-LMS/F) algorithm, respectively. Firstly, regularization parameters of the SFEC-ASCE methods are selected by means of Monte-Carlo simulations. Secondly, lower bounds of the SFEC-ASCE methods are derived and analyzed. Finally, simulation results are given to show that the proposed SFEC-ASCE methods achieve better estimation performance than the conventional SEC-ASCE methods. 1", "subjects": "Information Theory (cs.IT)", "authors": "Guan Gui, Li Xu, Shinya Matsushita,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00796", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00796", "title": "\nOn the Convergence and Performance of MF Precoding in Distributed  Massive MU-MIMO Systems", "abstract": "In this paper, we analyze both the rate of convergence and the performance of a matched-filter (MF) precoder in a massive multi-user (MU) multiple-input-multiple-output (MIMO) system, with the aim of determining the impact of distributing the transmit antennas into multiple clusters. We consider cases of transmit spatial correlation, unequal link gains and imperfect channel state information (CSI). Furthermore, we derive a MF signal-to-interference-plus-noise-ratio (SINR) limit as both the number of transmit antennas and the number of users tend to infinity. In our results, we show that both the rate of convergence and performance is strongly dependent on spatial correlation. In the presence of spatial correlation, distributing the antennas into multiple clusters renders significant gains over a co-located antenna array scenario. In uncorrelated scenarios, a co-located antenna cluster has a marginally better mean per-user SINR performance due to its superior single-user signal-to-noise-ratio (SNR) regime, i.e., when a user is close to the base station (BS), the links between the user and all transmit antennas becomes strong.", "subjects": "Information Theory (cs.IT)", "authors": "Peter J. Smith, Callum T. Neil, Mansoor Shafi, Pawel A. Dmochowski,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00793", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00793", "title": "\nDAG-width of Control Flow Graphs with Applications to Model Checking", "abstract": "The treewidth of control flow graphs arising from structured programs is known to be at most six. However, as a control flow graph is inherently directed, it makes sense to consider a measure of width for digraphs instead. We use the so-called DAG-width and show that the DAG-width of control flow graphs arising from structured (goto-free) programs is at most three. Additionally, we also give a linear time algorithm to compute the DAG decomposition of these control flow graphs. One consequence of this result is that parity games (and hence the -calculus model checking problem), which are known to be tractable on graphs of bounded DAG-width, can be solved efficiently in practice on control flow graphs.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Therese Biedl, Sebastian Fischmeister, Neeraj Kumar,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00792", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00792", "title": "\nSparsity Aware Normalized Least Mean p-power Algorithms with Correntropy  Induced Metric Penalty", "abstract": "For identifying the non-Gaussian impulsive noise systems, normalized LMP (NLMP) has been proposed to combat impulsive-inducing instability. However, the standard algorithm is without considering the inherent sparse structure distribution of unknown system. To exploit sparsity as well as to mitigate the impulsive noise, this paper proposes a sparse NLMP algorithm, i.e., Correntropy Induced Metric (CIM) constraint based NLMP (CIMNLMP). Based on the first proposed algorithm, moreover, we propose an improved CIM constraint variable regularized NLMP(CIMVRNLMP) algorithm by utilizing variable regularized parameter(VRP) selection method which can further adjust convergence speed and steady-state error. Numerical simulations are given to confirm the proposed algorithms.", "subjects": "Information Theory (cs.IT)", "authors": "Wentao Ma, Hua Qu, Jihong Zhao, Badong Chen, Guan Gui,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00791", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00791", "title": "\nDeployment Issues for Massive MIMO Systems", "abstract": "In this paper we examine a number of deployment issues which arise from practical considerations in massive multiple-input-multiple-output (MIMO) systems. We show both spatial correlation and line-of-sight (LOS) introduce an interference component to the system which causes non-orthogonality between user channels. Distributing the antennas into multiple clusters is shown to reduce spatial correlation and improve performance. Furthermore, due to its ability to minimize interference, zero forcing (ZF) precoding performs well in massive MIMO systems compared to matched filter (MF) precoding which suffers large penalties. However, the noise component in the ZF signal-to-noise-ratio (SNR) increases significantly in the case of imperfect transmit channel state information (CSI).", "subjects": "Information Theory (cs.IT)", "authors": "Callum T. Neil, Mansoor Shafi, Peter J. Smith, Pawel A. Dmochowski,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00789", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00789", "title": "\nOn the Impact of Antenna Topologies for Massive MIMO Systems", "abstract": "Approximate expressions for the spatial correlation of cylindrical and uniform rectangular arrays (URA) are derived using measured distributions of angles of departure (AOD) for both the azimuth and zenith domains. We examine massive multiple-input-multiple-output (MIMO) convergence properties of the correlated channels by considering a number of convergence metrics. The per-user matched filter (MF) signal-to-interference-plus-noise ratio (SINR) performance and convergence rate, to respective limiting values, of the two antenna topologies is also explored.", "subjects": "Information Theory (cs.IT)", "authors": "Callum T. Neil, Mansoor Shafi, Peter J. Smith, Pawel A. Dmochowski,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00787", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00787", "title": "\nContext Forest for efficient object detection with large mixture models", "abstract": "We present Context Forest (ConF), a technique for predicting properties of the objects in an image based on its global appearance. Compared to standard nearest-neighbour techniques, ConF is more accurate, fast and memory efficient. We train ConF to predict which aspects of an object class are likely to appear in a given image (e.g. which viewpoint). This enables to speed-up multi-component object detectors, by automatically selecting the most relevant components to run on that image. This is particularly useful for detectors trained from large datasets, which typically need many components to fully absorb the data and reach their peak performance. ConF provides a speed-up of 2x for the DPM detector [1] and of 10x for the EE-SVM detector [2]. To show ConF's generality, we also train it to predict at which locations objects are likely to appear in an image. Incorporating this information in the detector score improves mAP performance by about 2% by removing false positive detections in unlikely locations.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Davide Modolo, Alexander Vezhnevets, Vittorio Ferrari,", "date": "2015-3-3"}, 
{"urllink": "http://arxiv.org/abs/1503.00783", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00783", "title": "\nJoint calibration of Ensemble of Exemplar SVMs", "abstract": "We present a method for calibrating the Ensemble of Exemplar SVMs model. Unlike the standard approach, which calibrates each SVM independently, our method optimizes their joint performance as an ensemble. We formulate joint calibration as a constrained optimization problem and de- vise an efficient optimization algorithm to find its global optimum. It dynamically discards parts of the solution space that cannot contain the optimum early on, making the optimization computationally feasible. Experiments on the ILSVRC 2014 dataset shows that (i) our joint calibration procedure outperforms independent calibration on the task of classifying windows as belonging to an object class or not; and (ii) this better window classifier leads to better performance on the object detection task.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Davide Modolo, Alexander Vezhnevets, Olga Russakovsky, Vittorio Ferrari,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00778", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00778", "title": "\nSimple, Efficient, and Neural Algorithms for Sparse Coding", "abstract": "Sparse coding is a basic task in many fields including signal processing, neuroscience and machine learning where the goal is to learn a basis that enables a sparse representation of a given set of data, if one exists. Its standard formulation is as a non-convex optimization problem which is solved in practice by heuristics based on alternating minimization. Re- cent work has resulted in several algorithms for sparse coding with provable guarantees, but somewhat surprisingly these are outperformed by the simple alternating minimization heuristics. Here we give a general framework for understanding alternating minimization which we leverage to analyze existing heuristics and to design new ones also with provable guarantees. Some of these algorithms seem implementable on simple neural architectures, which was the original motivation of Olshausen and Field (1997a) in introducing sparse coding. We also give the first efficient algorithm for sparse coding that works almost up to the information theoretic limit for sparse recovery on incoherent dictionaries. All previous algorithms that approached or surpassed this limit run in time exponential in some natural parameter. Finally, our algorithms improve upon the sample complexity of existing approaches. We believe that our analysis framework will have applications in other settings where simple iterative algorithms are used.", "subjects": "Learning (cs.LG)", "authors": "Sanjeev Arora, Rong Ge, Tengyu Ma, Ankur Moitra,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00771", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00771", "title": "\nStable Cluster Core Detection in Correlated Hashtag Graph", "abstract": "Hashtags in twitter are used to track events, topics and activities. Correlated hashtag graph represents contextual relationships among these hashtags. Maximum clusters in the correlated hashtag graph can be contextually meaningful hashtag groups. In order to track the changes of the clusters and understand these hashtag groups, the hashtags in a cluster are categorized into two types: stable core and temporary members which are subject to change. Some initial studies are done in this project and 3 algorithms are designed, implemented and experimented to test them.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Qinyun Zhu,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00769", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00769", "title": "\nGrouping and Recognition of Dot Patterns with Straight Offset Polygons", "abstract": "When the boundary of a familiar object is shown by a series of isolated dots, humans can often recognize the object with ease. This ability can be sustained with addition of distracting dots around the object. However, such capability has not been reproduced algorithmically on computers. We introduce a new algorithm that groups a set of dots into multiple non-disjoint subsets. It connects the dots into a spanning tree using the proximity cue. It then applies the straight polygon transformation to an initial polygon derived from the spanning tree. The straight polygon divides the space into polygons recursively and each polygon can be viewed as grouping of a subset of the dots. The number of polygons generated is O(). We also introduce simple shape selection and recognition algorithms that can be applied to the grouping result. We used both natural and synthetic images to show effectiveness of these algorithms.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Toshiro Kubota,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00760", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00760", "title": "\nOn Using Synthetic Social Media Stimuli in an Emergency Preparedness  Functional Exercise", "abstract": "This paper details the creation and use of a massive (over 32,000 messages) artificially constructed 'Twitter' microblog stream for a regional emergency preparedness functional exercise. By combining microblog conversion, manual production, and a control set, we created a web based information stream providing valid, misleading, and irrelevant information to public information officers (PIOs) representing hospitals, fire departments, the local Red Cross, and city and county government officials. PIOs searched, monitored, and (through conventional channels) verified potentially acionable information that could then be redistributed through a personalized screen name. Our case study of a key PIO reveals several capabilities that social media can support, including event detection, the distribution of information between functions within the emergency response community, and the distribution of messages to the public. We suggest that training as well as information filtering tools are necessary to realize the potential of social media in both emergencies and exercises.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Andrew Hampton, Shreyansh Bhatt, Alan Smith, Jeremy Brunn, Hemant Purohit, Valerie L. Shalin, John M. Flach, Amit P. Sheth,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00756", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00756", "title": "\nConstructing elastic distinguishability metrics for location privacy", "abstract": "With the increasing popularity of hand-held devices, location-based applications and services have access to accurate and real-time location information, raising serious privacy concerns for their users. The recently introduced notion of geo-indistinguishability tries to address this problem by adapting the well-known concept of differential privacy to the area of location-based systems. Although geo-indistinguishability presents various appealing aspects, it has the problem of treating space in a uniform way, imposing the addition of the same amount of noise everywhere on the map. In this paper we propose a novel elastic distinguishability metric that warps the geometrical distance, capturing the different degrees of density of each area. As a consequence, the obtained mechanism adapts the level of noise while achieving the same degree of privacy everywhere. We also show how such an elastic metric can easily incorporate the concept of a \"geographic fence\" that is commonly employed to protect the highly recurrent locations of a user, such as his home or work. We perform an extensive evaluation of our technique by building an elastic metric for Paris' wide metropolitan area, using semantic information from the OpenStreetMap database. We compare the resulting mechanism against the Planar Laplace mechanism satisfying standard geo-indistinguishability, using two real-world datasets from the Gowalla and Brightkite location-based social networks. The results show that the elastic mechanism adapts well to the semantics of each area, adjusting the noise as we move outside the city center, hence offering better overall privacy.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Konstantinos Chatzikokolakis, Catuscia Palamidessi, Marco Stronati,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00753", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00753", "title": "\nNo Small Linear Program Approximates Vertex Cover within a Factor $2 -  \u03b5$", "abstract": "The vertex cover problem is one of the most important and intensively studied combinatorial optimization problems. Khot and Regev (2003) proved that the problem is NP-hard to approximate within a factor , assuming the Unique Games Conjecture (UGC). This is tight because the problem has an easy 2-approximation algorithm. Without resorting to the UGC, the best inapproximability result for the problem is due to Dinur and Safra (2002): vertex cover is NP-hard to approximate within a factor 1.3606. We prove the following unconditional result about linear programming (LP) relaxations of the problem: every LP relaxation that approximates vertex cover within a factor of has super-polynomially many inequalities. As a direct consequence of our methods, we also establish that LP relaxations that approximate the independent set problem within any constant factor have super-polynomially many inequalities.", "subjects": "Computational Complexity (cs.CC)", "authors": "Abbas Bazzi, Samuel Fiorini, Sebastian Pokutta, Ola Svensson,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00745", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00745", "title": "\nReachability in Vector Addition Systems Demystified", "abstract": "More than 30 years after their inception, the decidability proofs for reachability in vector addition systems (VAS) still retain much of their mystery. These proofs rely crucially on a decomposition of runs successively refined by Mayr, Kosaraju, and Lambert, which appears rather magical, and for which no complexity upper bound is known. We first offer a justification for this decomposition technique, by showing that it emerges naturally in the study of the ideals of a well quasi ordering of VAS runs. In a second part, we apply recent results on the complexity of termination thanks to well quasi orders and well orders to obtain fast-growing complexity upper bounds for the decomposition algorithms, thus providing the first known upper bounds for general VAS reachability.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "J\u00e9r\u00f4me Leroux, Sylvain Schmitz,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00711", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00711", "title": "\nSmelling out Code Clones: Clone Detection Tool Evaluation and  Corresponding Challenges", "abstract": "Software clones have been an active area of research for the past two decades. However, although numerous clone detection tools are now available, only a small fraction of the literature has focused on tool evaluation, and this is in fact still an open problem. This is mostly due to the fact that standard information retrieval metrics such as recall and precision require a priori knowledge of clones already in the system. Detection tools also typically have a large number of parameters which are difficult to fine-tune for optimal performance on a particular software system, and different outputs produced by different tools add to the complexity of comparing one tool to another. In this review, we further explore the reasons why tool evaluation is still an open challenge, and present the current tools and frameworks targeted at mitigating these problems, focusing on the current standard benchmarks used to evaluate modern clone detection tools, and also presenting a recent method aimed at finding optimal tool configurations.", "subjects": "Software Engineering (cs.SE)", "authors": "Rachel Gauci,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00709", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00709", "title": "\nSome new insights into information decomposition in complex systems  based on common information", "abstract": "We take a closer look at the structure of bivariate dependency induced by a pair of predictor random variables trying to synergistically, redundantly or uniquely encode a target random variable . We evaluate a recently proposed measure of redundancy based on the G 'acs-K \"rner common information (Griffith et al., Entropy 2014) and show that the measure, in spite of its elegance is degenerate for most non-trivial distributions. We show that Wyner's common information also fails to capture the notion of redundancy as it violates an intuitive monotonically non-increasing property. We identify a set of conditions when a conditional version of G 'acs and K \"rner's common information is an ideal measure of unique information. Finally, we show how the notions of approximately sufficient statistics and conditional information bottleneck can be used to quantify unique information.", "subjects": "Information Theory (cs.IT)", "authors": "Pradeep Kr. Banerjee,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00704", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00704", "title": "\nPolynomial kernelization for removing induced claws and diamonds", "abstract": "A graph is called (claw,diamond)-free if it contains neither a claw (a ) nor a diamond (a with an edge removed) as an induced subgraph. Equivalently, (claw,diamond)-free graphs can be characterized as line graphs of triangle-free graphs, or as linear dominoes, i.e., graphs in which every vertex is in at most two maximal cliques and every edge is in exactly one maximal clique. In this paper we consider the parameterized complexity of the (claw,diamond)-free Edge Deletion problem, where given a graph and a parameter , the question is whether one can remove at most edges from to obtain a (claw,diamond)-free graph. Our main result is that this problem admits a polynomial kernel. We complement this finding by proving that, even on instances with maximum degree , the problem is NP-complete and cannot be solved in time unless the Exponential Time Hypothesis fail", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Marek Cygan, Marcin Pilipczuk, Micha\u0142 Pilipczuk, Erik Jan van Leeuwen, Marcin Wrochna,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00697", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00697", "title": "\nMillimeter Wave Cellular Networks: A MAC Layer Perspective", "abstract": "Due to spectrum scarcity in microwave bands used by legacy communication technologies, millimeter wave (mmWave) bands are considered as a promising enabler for 5G cellular networks to provide multi-gigabit wireless access. However, mmWave communications exhibit high attenuations, vulnerability to obstacles, and sparse-scattering environments, which are not taken into account in the existing cellular wireless design approaches. Moreover, the small wavelengths of mmWave signals make it possible to incorporate a large number of antenna elements both at the base stations and at the user equipments, which in turn lead to high directivity gains and fully-directional communications. This level of directionality can result in a network that is noise-limited as opposed to interference-limited. The significant differences between mmWave networks and traditional ones challenge the classical design constraints, objectives, and available degrees of freedom. This demands a reconsideration of almost all design aspects in mmWave systems, where, despite a recent wave of investigations at the physical layer, very little can be found for the MAC layer. This paper aims at filling this important research gap. The purpose of this study is both to survey the state-of-the-art and to discuss the challenges that arise at the MAC layer of mmWave cellular systems and to propose original research directions to address those challenges. Specifically, this paper focuses on the main MAC decisions such as synchronization, random access, handover, channelization, interference management, scheduling, and association. New challenges and new tradeoffs are identified, and solution approaches based on special characteristics of mmWave systems are suggested. It is concluded that fully-directional communication when supported with proper MAC layer design is an essential component of mmWave cellular networks.", "subjects": "Information Theory (cs.IT)", "authors": "Hossein Shokri-Ghadikolaei, Carlo Fischione, Gabor Fodor, Petar Popovski, Michele Zorzi,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00694", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00694", "title": "\nConsistent Probabilistic Social Choice", "abstract": "Three fundamental axioms in social choice theory are consistency with respect to a variable electorate, consistency with respect to a variable agenda, and consistency with respect to composed preference profiles. In the context of traditional non-probabilistic social choice, these axioms are known to be highly incompatible. We show that in the context of probabilistic social choice, the axioms uniquely characterize a function proposed by Fishburn (Rev. Econ. Stud., 51(4), 683--692, 1984). The function returns so-called maximal lotteries, i.e., lotteries that correspond to optimal mixed strategies of the underlying plurality game. Maximal lotteries are guaranteed to exist due to von Neumann's Minimax Theorem and are almost always unique.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Florian Brandl, Felix Brandt, Hans Georg Seedig,", "date": "2015-2-21"}, 
{"urllink": "http://arxiv.org/abs/1503.00693", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00693", "title": "\nBayesian Optimization of Text Representations", "abstract": "When applying machine learning to problems in NLP, there are many choices to make about how to represent input texts. These choices can have a big effect on performance, but they are often uninteresting to researchers or practitioners who simply need a module that performs well. We propose an approach to optimizing over this space of choices, formulating the problem as global optimization. We apply a sequential model-based optimization technique and show that our method makes standard linear models competitive with more sophisticated, expensive state-of-the-art methods based on latent variable models or neural networks on various topic classification and sentiment analysis problems. Our approach is a first step towards black-box NLP systems that work with raw text and do not require manual tuning.", "subjects": "Computation and Language (cs.CL)", "authors": "Dani Yogatama, Noah A. Smith,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00688", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00688", "title": "\nPhotoplethysmography-Based Heart Rate Monitoring in Physical Activities  via Joint Sparse Spectrum Reconstruction", "abstract": "Goal: A new method for heart rate monitoring using photoplethysmography (PPG) during physical activities is proposed. Methods: It jointly estimates spectra of PPG signals and simultaneous acceleration signals, utilizing the multiple measurement vector model in sparse signal recovery. Due to a common sparsity constraint on spectral coefficients, the method can easily identify and remove spectral peaks of motion artifact (MA) in PPG spectra. Thus, it does not need any extra signal processing modular to remove MA as in some other algorithms. Furthermore, seeking spectral peaks associated with heart rate is simplified. Results: Experimental results on 12 PPG datasets sampled at 25 Hz and recorded during subjects' fast running showed that it had high performance. The average absolute estimation error was 1.28 beat per minute and the standard deviation was 2.61 beat per minute. Conclusion and Significance: These results show that the method has great potential to be used for PPG-based heart rate monitoring in wearable devices for fitness tracking and health monitoring.", "subjects": "Other Computer Science (cs.OH)", "authors": "Zhilin Zhang,", "date": "2015-2-21"}, 
{"urllink": "http://arxiv.org/abs/1503.00687", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00687", "title": "\nA review of mean-shift algorithms for clustering", "abstract": "A natural way to characterize the cluster structure of a dataset is by finding regions containing a high density of data. This can be done in a nonparametric way with a kernel density estimate, whose modes and hence clusters can be found using mean-shift algorithms. We describe the theory and practice behind clustering based on kernel density estimates and mean-shift algorithms. We discuss the blurring and non-blurring versions of mean-shift; theoretical results about mean-shift algorithms and Gaussian mixtures; relations with scale-space theory, spectral clustering and other algorithms; extensions to tracking, to manifold and graph data, and to manifold denoising; K-modes and Laplacian K-modes algorithms; acceleration strategies for large datasets; and applications to image segmentation, manifold denoising and multivalued regression.", "subjects": "Learning (cs.LG)", "authors": "Miguel \u00c1. Carreira-Perpi\u00f1\u00e1n,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00674", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00674", "title": "\n5G Cellular: Key Enabling Technologies and Research Challenges", "abstract": "The evolving fifth generation (5G) cellular wireless networks are envisioned to provide higher data rates, enhanced end-user quality-of-experience (QoE), reduced end-to-end latency, and lower energy consumption. This article presents several emerging technologies, which will enable and define the 5G mobile communications standards. The major research problems, which these new technologies breed, as well as the measurement and test challenges for 5G systems are also highlighted.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Ekram Hossain, Monowar Hasan,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1503.00673", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00673", "title": "\nWhat is an emerging technology?", "abstract": "Despite the growing interest around the emergence of novel technologies, especially from the policy-making perspective, there is still no consensus on what classifies a technology as 'emergent'. The present paper aims to fill this gap by developing a definition of 'emerging technologies' and a framework for their detection and analysis. The definition is developed by combining a basic understanding of the term and in particular the concept of 'emergence' with a review of key innovation studies dealing with definitional issues of technological emergence. The resulting definition identifies five attributes that feature in the emergence of novel technologies. These are: (i) radical novelty, (ii) relatively fast growth, (iii) coherence, (iv) prominent impact, and (v) uncertainty and ambiguity. The conceptual effort is then used to develop a framework for the operationalisation of the proposed attributes. To do so, we identify and review major empirical approaches (mainly in, although not limited to, the scientometric domain) for the detection and study of emerging technologies (these include indicators and trend analysis, citation analysis, co-word analysis, overlay mapping, and combinations thereof) and elaborate on how these can be used to operationalise the different attributes of emergence.", "subjects": "Other Computer Science (cs.OH)", "authors": "Daniele Rotolo, Diana Hicks, Ben Martin,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1503.00658", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00658", "title": "\nMore Analysis of Double Hashing for Balanced Allocations", "abstract": "With double hashing, for a key , one generates two hash values and , and then uses combinations for to generate multiple hash values in the range from the initial two. For balanced allocations, keys are hashed into a hash table where each bucket can hold multiple keys, and each key is placed in the least loaded of choices. It has been shown previously that asymptotically the performance of double hashing and fully random hashing is the same in the balanced allocation paradigm using fluid limit methods. Here we extend a coupling argument used by Lueker and Molodowitch to show that double hashing and ideal uniform hashing are asymptotically equivalent in the setting of open address hash tables to the balanced allocation setting, providing further insight into this phenomenon. We also discuss the potential for and bottlenecks limiting the use this approach for other multiple choice hashing schemes.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Michael Mitzenmacher,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00656", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00656", "title": "\nSpace-Constrained Massive MIMO: Hitting the Wall of Favorable  Propagation", "abstract": "The recent development of the massive multiple-input multiple-output (MIMO) paradigm, has been extensively based on the pursuit of favorable propagation: in the asymptotic limit, the channel vectors become nearly orthogonal and inter-user interference tends to zero [1]. In this context, previous studies have considered fixed inter-antenna distance, which implies an increasing array aperture as the number of elements increases. Here, we focus on a practical, space-constrained topology, where an increase in the number of antenna elements in a fixed total space imposes an inversely proportional decrease in the inter-antenna distance. Our analysis shows that, contrary to existing studies, inter-user interference does not vanish in the massive MIMO regime, thereby creating a saturation effect on the achievable rate.", "subjects": "Information Theory (cs.IT)", "authors": "Christos Masouros, Michail Matthaiou,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00650", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00650", "title": "\nConsistent Answers of Conjunctive Queries on Graphs", "abstract": "During the past decade, there has been an extensive investigation of the computational complexity of the consistent answers of Boolean conjunctive queries under primary key constraints. Much of this investigation has focused on self-join-free Boolean conjunctive queries. In this paper, we study the consistent answers of Boolean conjunctive queries involving a single binary relation, i.e., we consider arbitrary Boolean conjunctive queries on directed graphs. In the presence of a single key constraint, we show that for each such Boolean conjunctive query, either the problem of computing its consistent answers is expressible in first-order logic, or it is polynomial-time solvable, but not expressible in first-order logic.", "subjects": "Databases (cs.DB)", "authors": "Foto N. Afrati, Phokion G. Kolaitis, Angelos Vasilakopoulos,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00648", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00648", "title": "\nOffloading on the Edge: Analysis and Optimization of Local Data Storage  and Offloading in HetNets", "abstract": "The rapid increase in data traffic demand has overloaded existing cellular networks. Planned upgrades in the communication architecture (e.g. LTE), while helpful, are not expected to suffice to keep up with demand. As a result, extensive densification through small cells, caching content closer to or even at the device, and device-to-device (D2D) communications are seen as necessary components for future heterogeneous cellular networks to withstand the data crunch. Nevertheless, these options imply new CAPEX and OPEX costs, extensive backhaul support, contract plan incentives for D2D, and a number of interesting tradeoffs arise for the operator. In this paper, we propose an analytical model to explore how much local storage and communication through \"edge\" nodes could help offload traffic in various heterogeneous network (HetNet) setups and levels of user tolerance to delays. We then use this model to optimize the storage allocation and access mode of different contents as a tradeoff between user satisfaction and cost to the operator. Finally, we validate our findings through realistic simulations and show that considerable amounts of traffic can be offloaded even under moderate densification levels.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Pavlos Sermpezis, Luigi Vigneri, Thrasyvoulos Spyropoulos,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00628", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00628", "title": "\nSampling and reconstruction of operators", "abstract": "We study the recovery of operators with bandlimited Kohn-Nirenberg symbol from the action of such operators on a weighted impulse train, a procedure we refer to as operator sampling. Kailath, and later Kozek and the authors have shown that operator sampling is possible if the symbol of the operator is bandlimited to a set with area less than one. In this paper we develop explicit reconstruction formulas for operator sampling that generalize reconstruction formulas for bandlimited functions. We give necessary and sufficient conditions on the sampling rate that depend on size and geometry of the bandlimiting set. Moreover, we show that under mild geometric conditions, classes of operators bandlimited to an unknown set of area less than one-half permit sampling and reconstruction. A similar result considering unknown sets of area less than one was independently achieved by Heckel and Boelcskei. Operators with bandlimited symbols have been used to model doubly dispersive communication channels with slowly-time-varying impulse response. The results in this paper are rooted in work by Bello and Kailath in the 1960s.", "subjects": "Information Theory (cs.IT)", "authors": "G\u00f6tz E. Pfander, David F. Walnut,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00626", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00626", "title": "\nEffective Techniques for Message Reduction and Load Balancing in  Distributed Graph Computation", "abstract": "Massive graphs, such as online social networks and communication networks, have become common today. To efficiently analyze such large graphs, many distributed graph computing systems have been developed. These systems employ the \"think like a vertex\" programming paradigm, where a program proceeds in iterations and at each iteration, vertices exchange messages with each other. However, using Pregel's simple message passing mechanism, some vertices may send/receive significantly more messages than others due to either the high degree of these vertices or the logic of the algorithm used. This forms the communication bottleneck and leads to imbalanced workload among machines in the cluster. In this paper, we propose two effective message reduction techniques: (1)vertex mirroring with message combining, and (2)an additional request-respond API. These techniques not only reduce the total number of messages exchanged through the network, but also bound the number of messages sent/received by any single vertex. We theoretically analyze the effectiveness of our techniques, and implement them on top of our open-source Pregel implementation called Pregel+. Our experiments on various large real graphs demonstrate that our message reduction techniques significantly improve the performance of distributed graph computation.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Da Yan, James Cheng, Yi Lu, Wilfred Ng,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00623", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00623", "title": "\nUnregularized Online Learning Algorithms with General Loss Functions", "abstract": "In this paper, we consider unregularized online learning algorithms in a Reproducing Kernel Hilbert Spaces (RKHS). Firstly, we derive explicit convergence rates of the unregularized online learning algorithms for classification associated with a general gamma-activating loss (see Definition 1 in the paper). Our results extend and refine the results in Ying and Pontil (2008) for the least-square loss and the recent result in Bach and Moulines (2011) for the loss function with a Lipschitz-continuous gradient. Moreover, we establish a very general condition on the step sizes which guarantees the convergence of the last iterate of such algorithms. Secondly, we establish, for the first time, the convergence of the unregularized pairwise learning algorithm with a general loss function and derive explicit rates under the assumption of polynomially decaying step sizes. Concrete examples are used to illustrate our main results. The main techniques are tools from convex analysis, refined inequalities of Rademacher averages, and an interesting induction approach.", "subjects": "Learning (cs.LG)", "authors": "Yiming Ying, Ding-Xuan Zhou,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00622", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00622", "title": "\nConstraint Satisfaction in Coordinating Components Interfaces", "abstract": "A new approach for coordinating components interfaces based on CSP is presented. The Kahn Process Network (KPN) is taken as a formal model of computation and a Message Definition Language is introduced to describe the format of messages communicated between the processes. The MDL defines a term structure with a partial order to support hierarchical match between message produces and consumers. The language supports term and Boolean variables to support in-flow inheritance and nonparametric polymorphism of the process interfaces, both making the match decisions substantially nonlocal. The KPN communication graph thus becomes a graph of interlocked constraints to be satisfied by finding specific instances of the variables. An algorithm is proposed that solves the satisfaction problem by iterative approximation while generating an adjunct Boolean SAT problem on the way; its correctness proof and an implementation as an OCaml program that operates alongside the PicoSAT solver are presented and discussed.", "subjects": "Programming Languages (cs.PL)", "authors": "Pavel Zaichenkov, Olga Tveretina, Alex Shafarenko,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00617", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00617", "title": "\nEfficient Computation of the Characteristic Polynomial of a Threshold  Graph", "abstract": "An efficient algorithm is presented to compute the characteristic polynomial of a threshold graph. Threshold graphs were introduced by Chv 'atal and Hammer, as well as by Henderson and Zalcstein in 1977. A threshold graph is obtained from a one vertex graph by repeatedly adding either an isolated vertex or a dominating vertex, which is a vertex adjacent to all the other vertices. Threshold graphs are special kinds of cographs, which themselves are special kinds of graphs of clique-width 2. We obtain a running time of for computing the characteristic polynomial, while the previously fastest algorithm ran in quadratic time. Keywords: Efficient Algorithms, Threshold Graphs, Characteristic Polynomial.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Martin F\u00fcrer,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00604", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00604", "title": "\nRobust Group Linkage", "abstract": "We study the problem of group linkage: linking records that refer to entities in the same group. Applications for group linkage include finding businesses in the same chain, finding conference attendees from the same affiliation, finding players from the same team, etc. Group linkage faces challenges not present for traditional record linkage. First, although different members in the same group can share some similar global values of an attribute, they represent different entities so can also have distinct local values for the same or different attributes, requiring a high tolerance for value diversity. Second, groups can be huge (with tens of thousands of records), requiring high scalability even after using good blocking strategies. We present a two-stage algorithm: the first stage identifies cores containing records that are very likely to belong to the same group, while being robust to possible erroneous values; the second stage collects strong evidence from the cores and leverages it for merging more records into the same group, while being tolerant to differences in local values of an attribute. Experimental results show the high effectiveness and efficiency of our algorithm on various real-world data sets.", "subjects": "Databases (cs.DB)", "authors": "Pei Li, Xin Luna Dong, Songtao Guo, Andrea Maurino, Divesh Srivastava,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00603", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00603", "title": "\nSwitching control for tracking of a hybrid position-force trajectory", "abstract": "This work proposes a control law for a manipulator with the aim of realizing desired time-varying motion-force profiles in the presence of a stiff environment. In many cases, the interaction with the environment affects only one degree of freedom of the end-effector of the manipulator. Therefore, the focus is on this contact degree of freedom, and a switching position-force controller is proposed to perform the hybrid position-force tracking task. Sufficient conditions are presented to guarantee input-to-state stability of the switching closed-loop system with respect to perturbations related to the time-varying desired motion-force profile. The switching occurs when the manipulator makes or breaks contact with the environment. The analysis shows that to guarantee closed-loop stability while tracking arbitrary time-varying motion-force profiles, the controller should implement a considerable (and often unrealistic) amount of damping, resulting in inferior tracking performance. Therefore, we propose to redesign the manipulator with a compliant wrist. Guidelines are provided for the design of the compliant wrist while employing the designed switching control strategy, such that stable tracking of a motion-force reference trajectory can be achieved and bouncing of the manipulator while making contact with the stiff environment can be avoided. Finally, numerical simulations are presented to illustrate the effectiveness of the approach.", "subjects": "Robotics (cs.RO)", "authors": "D.J.F. Heck, A. Saccon, N. van de Wouw, H. Nijmeijer,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00600", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00600", "title": "\nAn $\\mathcal{O}(n\\log n)$ projection operator for weighted $\\ell_1$-norm  regularization with sum constraint", "abstract": "We provide a simple and efficient algorithm for the projection operator for weighted -norm regularization subject to a sum constraint, together with an elementary proof. The implementation of the proposed algorithm can be downloaded from the author's homepage.", "subjects": "Learning (cs.LG)", "authors": "Weiran Wang,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00593", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00593", "title": "\nLearning a Convolutional Neural Network for Non-uniform Motion Blur  Removal", "abstract": "In this paper, we address the problem of estimating and removing non-uniform motion blur from a single blurry image. We propose a deep learning approach to predicting the probabilistic distribution of motion blur at the patch level using a convolutional neural network (CNN). We further extend the candidate set of motion kernels predicted by the CNN using carefully designed image rotations. A Markov random field model is then used to infer a dense non-uniform motion blur field enforcing the motion smoothness. Finally the motion blur is removed by a non-uniform deblurring model using patch-level image prior. Experimental evaluations show that our approach can effectively estimate and remove complex non-uniform motion blur that cannot be well achieved by the previous approaches.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Jian Sun, Wenfei Cao, Zongben Xu, Jean Ponce,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00591", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00591", "title": "\nDeep Transfer Network: Unsupervised Domain Adaptation", "abstract": "Domain adaptation aims at training a classifier in one dataset and applying it to a related but not identical dataset. One successfully used framework of domain adaptation is to learn a transformation to match both the distribution of the features (marginal distribution), and the distribution of the labels given features (conditional distribution). In this paper, we propose a new domain adaptation framework named Deep Transfer Network (DTN), where the highly flexible deep neural networks are used to implement such a distribution matching process. This is achieved by two types of layers in DTN: the shared feature extraction layers which learn a shared feature subspace in which the marginal distributions of the source and the target samples are drawn close, and the discrimination layers which match conditional distributions by classifier transduction. We also show that DTN has a computation complexity linear to the number of training samples, making it suitable to large-scale problems. By combining the best paradigms in both worlds (deep neural networks in recognition, and matching marginal and conditional distributions in domain adaptation), we demonstrate by extensive experiments that DTN improves significantly over former methods in both execution time and classification accuracy.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Xu Zhang, Felix Xinnan Yu, Shih-Fu Chang, Shengjin Wang,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00587", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00587", "title": "\nPersonalising Mobile Advertising Based on Users Installed Apps", "abstract": "Mobile advertising is a billion pound industry that is rapidly expanding. The success of an advert is measured based on how users interact with it. In this paper we investigate whether the application of unsupervised learning and association rule mining could be used to enable personalised targeting of mobile adverts with the aim of increasing the interaction rate. Over May and June 2014 we recorded advert interactions such as tapping the advert or watching the whole advert video along with the set of apps a user has installed at the time of the interaction. Based on the apps that the users have installed we applied k-means clustering to profile the users into one of ten classes. Due to the large number of apps considered we implemented dimension reduction to reduced the app feature space by mapping the apps to their iTunes category and clustered users based on the percentage of their apps that correspond to each iTunes app category. The clustering was externally validated by investigating differences between the way the ten profiles interact with the various adverts genres (lifestyle, finance and entertainment adverts). In addition association rule mining was performed to find whether the time of the day that the advert is served and the number of apps a user has installed makes certain profiles more likely to interact with the advert genres. The results showed there were clear differences in the way the profiles interact with the different advert genres and the results of this paper suggest that mobile advert targeting would improve the frequency that users interact with an advert.", "subjects": "Computers and Society (cs.CY)", "authors": "Jenna Reps, Uwe Aickelin, Jonathan Garibaldi, Chris Damski,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1503.00586", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00586", "title": "\nEvaluation of spatial audio reproduction schemes for application in  hearing aid research", "abstract": "Loudspeaker-based spatial audio reproduction schemes are increasingly used for evaluating hearing aids in complex acoustic conditions. To further establish the feasibility of this approach, this study investigated the interaction between spatial resolution of different reproduction methods and technical and perceptual hearing aid performance measures using computer simulations. Three spatial audio reproduction methods -- discrete speakers, vector base amplitude panning and higher order ambisonics -- were compared in regular circular loudspeaker arrays with 4 to 72 channels. The influence of reproduction method and array size on performance measures of representative multi-microphone hearing aid algorithm classes with spatially distributed microphones and a representative single channel noise-reduction algorithm was analyzed. Algorithm classes differed in their way of analyzing and exploiting spatial properties of the sound field, requiring different accuracy of sound field reproduction. Performance measures included beam pattern analysis, signal-to-noise ratio analysis, perceptual localization prediction, and quality modeling. The results show performance differences and interaction effects between reproduction method and algorithm class that may be used for guidance when selecting the appropriate method and number of speakers for specific tasks in hearing aid research.", "subjects": "Sound (cs.SD)", "authors": "Giso Grimm, Stephan Ewert, Volker Hohmann,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00582", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00582", "title": "\nTowards Understanding Enjoyment and Flow in Information Visualization", "abstract": "Traditionally, evaluation studies in information visualization have measured effectiveness by assessing performance time and accuracy. More recently, there has been a concerted effort to understand aspects beyond time and errors. In this paper we study enjoyment, which, while arguably not the primary goal of visualization, has been shown to impact performance and memorability. Different models of enjoyment have been proposed in psychology, education and gaming; yet there is no standard approach to evaluate and measure enjoyment in visualization. In this paper we relate the flow model of Csikszentmihalyi to Munzner's nested model of visualization evaluation and previous work in the area. We suggest that, even though previous papers tackled individual elements of flow, in order to understand what specifically makes a visualization enjoyable, it might be necessary to measure all specific elements.", "subjects": "Human-Computer Interaction (cs.HC)", "authors": "Bahador Saket, Carlos Scheidegger, Stephen Kobourov,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00576", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00576", "title": "\nCounting Triangles in Large Graphs on GPU", "abstract": "The clustering coefficient and the transitivity ratio are concepts often used in network analysis, which creates a need for fast practical algorithms for counting triangles in large graphs. Previous research in this area focused on sequential algorithms, MapReduce parallelization, and fast approximations. In this paper we propose a parallel triangle counting algorithm for CUDA GPU. We describe the implementation details necessary to achieve high performance and present the experimental evaluation of our approach. Our algorithm achieves 8 to 15 times speedup over the CPU implementation and is capable of finding 3.8 billion triangles in an 89 million edges graph in less than 10 seconds on the Nvidia Tesla C2050 GPU.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Adam Polak,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00571", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00571", "title": "\nWell-quasi-ordering does not imply bounded clique-width", "abstract": "We present a hereditary class of graphs of unbounded clique-width which is well-quasi-ordered by the induced subgraph relation. This result provides a negative answer to the question asked by Daligault, Rao and Thomass 'e in (\"Well-quasi-order of relabel functions\", Order, 27(3):301--315, 2010).", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Vadim Lozin, Igor Razgon, Viktor Zamaraev,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00561", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00561", "title": "\nCAPTCHaStar! A novel CAPTCHA based on interactive shape discovery", "abstract": "Over the last years, most websites where users can register (e.g., email providers and social networks) adopted CAPTCHAs (Completely Automated Public Turing test to tell Computers and Humans Apart) as a countermeasure for automated attacks. The battle of wits between designers and attackers of CAPTCHAs led to current ones being annoying and hard to resolve for users, while still being vulnerable to automated attacks. In this paper, we propose CAPTCHaStar, a new image-based CAPTCHA that relies on user interaction. This novel CAPTCHA leverages the innate human ability to recognize shapes in a confused environment. We assess the effectiveness of our proposal for the two key aspects for CAPTCHAs, i.e., usability, and resiliency to automated attacks. In particular, we evaluated the usability, carrying out a thorough user study, and we tested the resiliency of our proposal against several types of automated attacks: traditional ones; designed ad-hoc for our proposal; and based on machine learning. Compared to the state of the art, our proposal is more user friendly (e.g., only some 35% of the users prefer current solutions, such as text-based CAPTCHAs) and more resilient to automated attacks.", "subjects": "Human-Computer Interaction (cs.HC)", "authors": "Mauro Conti, Claudio Guarisco, Riccardo Spolaor,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00555", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00555", "title": "\nLearning Immune-Defectives Graph through Group Tests", "abstract": "This paper deals with an abstraction of a unified problem of drug discovery and pathogen identification. Here, the \"lead compounds\" are abstracted as inhibitors, pathogenic proteins as defectives, and the mixture of \"ineffective\" chemical compounds and non-pathogenic proteins as normal items. A defective could be immune to the presence of an inhibitor in a test. So, a test containing a defective is positive iff it does not contain its \"associated\" inhibitor. The goal of this paper is to identify the defectives, inhibitors, and their \"associations\" with high probability, or in other words, learn the Immune Defectives Graph (IDG). We propose a probabilistic non-adaptive pooling design, a probabilistic two-stage adaptive pooling design and decoding algorithms for learning the IDG. For the two-stage adaptive-pooling design, we show that the sample complexity of the number of tests required to guarantee recovery of the inhibitors, defectives and their associations with high probability, i.e., the upper bound, exceeds the proposed lower bound by a logarithmic multiplicative factor in the number of items. For the non-adaptive pooling design, in the large inhibitor regime, we show that the upper bound exceeds the proposed lower bound by a logarithmic multiplicative factor in the number of inhibitors.", "subjects": "Information Theory (cs.IT)", "authors": "Abhinav Ganesan, Sidharth Jaggi, Venkatesh Saligrama,", "date": "2015-1-6"}, 
{"urllink": "http://arxiv.org/abs/1503.00547", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00547", "title": "\nRecovering PCA from Hybrid-$(\\ell_1,\\ell_2)$ Sparse Sampling of Data  Elements", "abstract": "This paper addresses how well we can recover a data matrix when only given a few of its elements. We present a randomized algorithm that element-wise sparsifies the data, retaining only a few its elements. Our new algorithm independently samples the data using sampling probabilities that depend on both the squares ( sampling) and absolute values ( sampling) of the entries. We prove that the hybrid algorithm recovers a near-PCA reconstruction of the data from a sublinear sample-size: hybrid-() inherits the -ability to sample the important elements as well as the regularization properties of sampling, and gives strictly better performance than either or on their own. We also give a one-pass version of our algorithm and show experiments to corroborate the theory.", "subjects": "Information Theory (cs.IT)", "authors": "Abhisek Kundu, Petros Drineas, Malik Magdon-Ismail,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00524", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00524", "title": "\nRouter deployment of Streetside Parking Sensor Networks in Urban Areas", "abstract": "The deployment of urban infrastructure is very important for urban sensor applications. In this paper, we studied and introduced the deployment strategy of wireless on-street parking sensor networks. We defined a multiple-objective problem with four objectives, and solved them with real street parking map. The results show two sets of Pareto Front with the minimum energy consumption, sensing information delay and the amount of deployed routers and gateways. The result can be considered to provide urban service roadside unit or be taken into account while designing a deployment algorithm.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Trista Lin, Herv\u00e9 Rivano, Fr\u00e9d\u00e9ric Le Mou\u00ebl,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00516", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00516", "title": "\nOptimal Feature Extraction and Classification of Tensors via Matrix  Product State Decomposition", "abstract": "Big data consists of large multidimensional datasets that would often be difficult to analyze if working with the original tensor. There is a rising interest in the use of tensor decompositions to approximate large tensors in order to reduce their dimensions by selecting important features for classification. Of particular interest is the Tucker decomposition (TD) that has already been applied in neuroscience, geoscience, signal processing, pattern and image recognition. However the decomposition itself leads to exponential computational time for high-order tensors. To circumvent this obstacle we propose an alternative known as the matrix product state (MPS) decomposition for the data representation of big data tensors. This decomposition has been used extensively in quantum physics within the last decade and its benefit has surprisingly not been seen in other areas of research. We prove that the MPS decomposition for feature extraction and classification in supervised learning can be implemented efficiently with high classification rates in pattern and image recognition.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Johann A. Bengua, Ho N. Phien, Hoang D. Tuan,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00505", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00505", "title": "\nA neuromorphic hardware framework based on population coding", "abstract": "In the biological nervous system, large neuronal populations work collaboratively to encode sensory stimuli. These neuronal populations are characterised by a diverse distribution of tuning curves, ensuring that the entire range of input stimuli is encoded. Based on these principles, we have designed a neuromorphic system called a Trainable Analogue Block (TAB), which encodes given input stimuli using a large population of neurons with a heterogeneous tuning curve profile. Heterogeneity of tuning curves is achieved using random device mismatches in VLSI (Very Large Scale Integration) process and by adding a systematic offset to each hidden neuron. Here, we present measurement results of a single test cell fabricated in a 65nm technology to verify the TAB framework. We have mimicked a large population of neurons by re-using measurement results from the test cell by varying offset. We thus demonstrate the learning capability of the system for various regression tasks. The TAB system may pave the way to improve the design of analogue circuits for commercial applications, by rendering circuits insensitive to random mismatch that arises due to the manufacturing process.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "Chetan Singh Thakur, Tara Julia Hamilton, Runchun Wang, Jonathan Tapson, Andr\u00e9 van Schaik,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00504", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00504", "title": "\nFPGA Implementation of the CAR Model of the Cochlea", "abstract": "The front end of the human auditory system, the cochlea, converts sound signals from the outside world into neural impulses transmitted along the auditory pathway for further processing. The cochlea senses and separates sound in a nonlinear active fashion, exhibiting remarkable sensitivity and frequency discrimination. Although several electronic models of the cochlea have been proposed and implemented, none of these are able to reproduce all the characteristics of the cochlea, including large dynamic range, large gain and sharp tuning at low sound levels, and low gain and broad tuning at intense sound levels. Here, we implement the Cascade of Asymmetric Resonators (CAR) model of the cochlea on an FPGA. CAR represents the basilar membrane filter in the Cascade of Asymmetric Resonators with Fast-Acting Compression (CAR-FAC) cochlear model. CAR-FAC is a neuromorphic model of hearing based on a pole-zero filter cascade model of auditory filtering. It uses simple nonlinear extensions of conventional digital filter stages that are well suited to FPGA implementations, so that we are able to implement up to 1224 cochlear sections on Virtex-6 FPGA to process sound data in real time. The FPGA implementation of the electronic cochlea described here may be used as a front-end sound analyser for various machine-hearing applications.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "Chetan Singh Thakur, Tara Julia Hamilton, Jonathan Tapson, Richard F. Lyon, Andr\u00e9 van Schaik,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00503", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00503", "title": "\nA Next-Generation Data Language Proposal", "abstract": "This paper attempts to explain consequences of the relational calculus not allowing relations to be domains of relations, and to suggest a solution for the issue. On the example of SQL we describe the consequent problem of the multitude of different representations for relations; analyze in detail the disadvantages of the notions \"TABLE\" and \"FOREIGN KEY\"; and propose a complex solution which includes brand new data language, abandonment of tables as a representation for relations, and relatively small yet very significant alteration of the data storage concept, called \"multitable index\".", "subjects": "Databases (cs.DB)", "authors": "Eugene Panferov,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00493", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00493", "title": "\nReal-Time Model Checking Support for AADL", "abstract": "We describe a model-checking toolchain for the behavioral verification of AADL models that takes into account the realtime semantics of the language and that is compatible with the AADL Behavioral Annex. We give a high-level view of the tools and transformations involved in the verification process and focus on the support offered by our framework for checking user-defined properties. We also describe the experimental results obtained on a significant avionic demonstrator, that models a network protocol in charge of data communications between an airplane and ground stations.", "subjects": "Software Engineering (cs.SE)", "authors": "B Berthomieu, J.-P Bodeveix, S Dal Zilio, M Filali, D Le Botlan, G Verdier, F Vernadat,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00491", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00491", "title": "\nUtility-Theoretic Ranking for Semi-Automated Text Classification", "abstract": "emph (SATC) may be defined as the task of ranking a set of automatically labelled textual documents in such a way that, if a human annotator validates (i.e., inspects and corrects where appropriate) the documents in a top-ranked portion of with the goal of increasing the overall labelling accuracy of , the expected increase is maximized. An obvious SATC strategy is to rank so that the documents that the classifier has labelled with the lowest confidence are top-ranked. In this work we show that this strategy is suboptimal. We develop new utility-theoretic ranking methods based on the notion of emph, defined as the improvement in classification effectiveness that would derive by validating a given automatically labelled document. We also propose a new effectiveness measure for SATC-oriented ranking methods, based on the expected reduction in classification error brought about by partially validating a list generated by a given ranking method. We report the results of experiments showing that, with respect to the baseline method above, and according to the proposed measure, our utility-theoretic ranking methods can achieve substantially higher expected reductions in classification error.", "subjects": "Learning (cs.LG)", "authors": "Giacomo Berardi, Andrea Esuli, Fabrizio Sebastiani,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00488", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00488", "title": "\nGraphical Representation for Heterogeneous Face Recognition", "abstract": "Heterogeneous face recognition (HFR) refers to matching non-photograph face images to face photos for identification. HFR plays an important role in both biometrics research and industry. In spite of promising progresses achieved in recent years, HFR is still a challenging problem due to the difficulty to represent two heterogeneous images in a homogeneous manner. Existing HFR methods either represent an image ignoring the spatial information, or rely on a transformation procedure which complicates the recognition task. Considering these problems, we propose a novel graphical representation based HFR method (G-HFR) in this paper. Markov networks are deployed to represent heterogeneous image patches separately, which take the spatial compatibility between neighboring image patches into consideration. A coupled representation similarity metric (CRSM) is designed to measure the similarity between obtained graphical representations. Extensive experiments conducted on two viewed sketch databases and a forensic sketch database show that the proposed method outperforms state-of-the-art methods.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Chunlei Peng, Xinbo Gao, Nannan Wang, Jie Li,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00484", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00484", "title": "\nSimulating Side Information: Better Provable Security for Leakage  Resilient Stream Ciphers", "abstract": "Given a distribution , any correlated information can be represented as a randomized function of . However, this function might be inefficient because of the following two reasons: (a) it involves a lot of computations or (b) a huge amount of auxiliary randomness is required. In this work we study this problem in the computational setting, where emph from becomes possible if we don't require the simulator output to be identical to but only computationally indistinguishable. We prove the following result: for any and any correlated , for every choice of parameters there is a randomized function from to bits of complexity such that and are ( epsilon,s)-indistinguishable given . This bound is better than in the original proof of Pietrzak and Jetchev (TCC'14) and (surprisingly!) much better for some practically interesting settings than in the alternative proof due to Vadhan and Zheng (CRYPTO'13). Our approach is also much simpler and modular (the standard min-max theorem and a -approximation argument). As an application we give a better security analysis for the leakage-resilient stream cipher from EUROCRYPT'09, increasing the maximal leakage length by 33%. As a contribution of independent interests, we provide a clear analysis of provable security for the (best known) simulator-based proof technique of this construction, showing how the adversary's time/success ratio depends on the simulator complexity. In particular we show that, contrarily to what have been suggested, AES is not enough for this construction and one needs a weak PRF with 512-bit keys, like SHA512. Interestingly, we discover serious limitations for the powerful Uniform Min-Max Theorem of Vadhan and Zheng: applied for this setting, it does not provide any meaningful security.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Maciej Skorski,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00481", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00481", "title": "\nA Reputation Economy: Results from an Empirical Survey on Academic Data  Sharing", "abstract": "Academic data sharing is a way for researchers to collaborate and thereby meet the needs of an increasingly complex research landscape. It enables researchers to verify results and to pursuit new research questions with \"old\" data. It is therefore not surprising that data sharing is advocated by funding agencies, journals, and researchers alike. We surveyed 2661 individual academic researchers across all disciplines on their dealings with data, their publication practices, and motives for sharing or withholding research data. The results for 1564 valid responses show that researchers across disciplines recognise the benefit of secondary research data for their own work and for scientific progress as a whole-still they only practice it in moderation. An explanation for this evidence could be an academic system that is not driven by monetary incentives, nor the desire for scientific progress, but by individual reputation-expressed in (high ranked journal) publications. We label this system a Reputation Economy. This special economy explains our findings that show that researchers have a nuanced idea how to provide adequate formal recognition for making data available to others-namely data citations. We conclude that data sharing will only be widely adopted among research professionals if sharing pays in form of reputation. Thus, policy measures that intend to foster research collaboration need to understand academia as a reputation economy. Successful measures must value intermediate products, such as research data, more highly than it is the case now.", "subjects": "Digital Libraries (cs.DL)", "authors": "Benedikt Fecher, Sascha Friesike, Marcel Hebing, Stephanie Linek, Armin Sauermann,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00477", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00477", "title": "\nBehavioral Aspects of Social Network Analysis", "abstract": "Contrary to the structural aspect of conventional social network analysis, a new method in behavioral analysis is proposed. We define behavioral measures including self-loops and multiple links and illustrate the behavioral analysis with the networks of Wikipedia editing. Behavioral social network analysis provides an explanation of human behavior that may be further extended to the explanation of culture through social phenomena.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Sung Joo Park, Jong Woo Kim, Hong Joo Lee, Hyun Jung Park, Peter Gloor,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00458", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00458", "title": "\nComplexity aspects of the triangle path convexity", "abstract": "A path is a (respectively, ) of if no edges exist joining vertices and of such that ; (respectively, ). A set of vertices is in the triangle path convexity (respectively, monophonic convexity) of if the vertices of every triangle path (respectively, monophonic path) joining two vertices of are in . The cardinality of a maximum proper convex set of is the and the cardinality of a minimum set of vertices whose convex hull is is the . Our main results are polynomial time algorithms for determining the convexity number and the hull number of a graph in the triangle path convexity.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Mitre C. Dourado, Rudini M. Sampaio,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00454", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00454", "title": "\nFlexible and Robust Privacy-Preserving Implicit Authentication", "abstract": "Implicit authentication consists of a server authenticating a user based on the user's usage profile, instead of/in addition to relying on something the user explicitly knows (passwords, private keys, etc.). While implicit authentication makes identity theft by third parties more difficult, it requires the server to learn and store the user's usage profile. Recently, the first privacy-preserving implicit authentication system was presented, in which the server does not learn the user's profile. It uses an ad hoc two-party computation protocol to compare the user's fresh sampled features against an encrypted stored user's profile. The protocol requires storing the usage profile and comparing against it using two different cryptosystems, one of them order-preserving; furthermore, features must be numerical. We present here a simpler protocol based on set intersection that has the advantages of: i) requiring only one cryptosystem; ii) not leaking the relative order of fresh feature samples; iii) being able to deal with any type of features (numerical or non-numerical). Keywords: Privacy-preserving implicit authentication, privacy-preserving set intersection, implicit authentication, active authentication, transparent authentication, risk mitigation, data brokers.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Josep Domingo-Ferrer, Qianhong Wu, Alberto Blanco-Justicia,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00448", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00448", "title": "\nThe Routing of Complex Contagion in Kleinberg's Small-World Networks", "abstract": "In Kleinberg's small-world network model, strong ties are modeled as deterministic edges in the underlying base grid and weak ties are modeled as random edges connecting remote nodes. The probability of connecting a node with node through a weak tie is proportional to , where is the grid distance between and and is the parameter of the model. Complex contagion refers to the propagation mechanism in a network where each node is activated only after neighbors of the node are activated. In this paper, we propose the concept of routing of complex contagion (or complex routing), where we can activate one node at one time step with the goal of activating the targeted node in the end. We consider decentralized routing scheme where only the weak ties from the activated nodes are revealed. We study the routing time of complex contagion and compare the result with simple routing and complex diffusion (the diffusion of complex contagion, where all nodes that could be activated are activated immediately in the same step with the goal of activating all nodes in the end). We show that for decentralized complex routing, the routing time is lower bounded by a polynomial in (the number of nodes in the network) for all range of both in expectation and with high probability (in particular, for and for in expectation), while the routing time of simple contagion has polylogarithmic upper bound when . Our results indicate that complex routing is harder than complex diffusion and the routing time of complex contagion differs exponentially compared to simple contagion at sweetspot.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Wei Chen, Qiang Li, Xiaoming Sun, Jialin Zhang,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00439", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00439", "title": "\nA Novel Framework for Intelligent Information Retrieval in Wireless  Sensor Networks", "abstract": "Recent advances in the development of the low-cost, power-efficient embedded devices, coupled with the rising need for support of new information processing paradigms such as smart spaces and military surveillance systems, have led to active research in large-scale, highly distributed sensor networks of small, wireless, low-power, unattended sensors and actuators. While applications keep diversifying, one common property they share is the need for an efficient network architecture tailored towards information retrieval in sensor networks. Previous solutions designed for traditional networks serve as good references; however, due to the vast differences between previous paradigms and needs of sensor networks, a framework is required to gather and impart only the required information .To achieve this goal in this paper we have proposed a framework for intelligent information retrieval and dissemination to desired destination node. The proposed frame work combines three major concern areas in WSNs i.e. data aggregation, information retrieval and data dissemination in a single scenario. In the proposed framework data aggregation is responsible for combining information from all nodes and removing the redundant data. Information retrieval filters the processed data to obtain final information termed as intelligent data to be disseminated to the required destination node.", "subjects": "Information Retrieval (cs.IR)", "authors": "Savneet Kaur, Deepali Virmani, Satbir Jain,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00436", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00436", "title": "\nGridless Quadrature Compressive Sampling with Interpolated Array  Technique", "abstract": "Quadrature compressive sampling (QuadCS) is a sub-Nyquist sampling scheme for acquiring in-phase and quadrature (I/Q) components in radar. In this scheme, the received intermediate frequency (IF) signals are expressed as a linear combination of time-delayed and scaled replicas of the transmitted waveforms. For sparse IF signals on discrete grids of time-delay space, the QuadCS can efficiently reconstruct the I/Q components from sub-Nyquist samples. In practice, the signals are characterized by a set of unknown time-delay parameters in a continuous space. Then conventional sparse signal reconstruction will deteriorate the QuadCS reconstruction performance. This paper focuses on the reconstruction of the I/Q components with continuous delay parameters. A parametric spectrum-matched dictionary is defined, which sparsely describes the IF signals in the frequency domain by delay parameters and gain coefficients, and the QuadCS system is reexamined under the new dictionary. With the inherent structure of the QuadCS system, it is found that the estimation of delay parameters can be decoupled from that of sparse gain coefficients, yielding a beamspace direction-of-arrival (DOA) estimation formulation with a time-varying beamforming matrix. Then an interpolated beamspace DOA method is developed to perform the DOA estimation. An optimal interpolated array is established and sufficient conditions to guarantee the successful estimation of the delay parameters are derived. With the estimated delays, the gain coefficients can be conveniently determined by solving a linear least-squares problem. Extensive simulations demonstrate the superior performance of the proposed algorithm in reconstructing the sparse signals with continuous delay parameters.", "subjects": "Information Theory (cs.IT)", "authors": "Feng Xi, Shengyao Chen, Yimin D. Zhang, Zhong Liu,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00435", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00435", "title": "\nRobotic Wireless Networks in a Narrow Alley: A Game Theoretic Approach", "abstract": "There are many situations where vehicles may compete with each other to maximize their respective utilities.We consider a narrow alley where two groups, eastbound and westbound, of autonomous vehicles are heading toward each of their destination to minimize their travel distance. However, if the two groups approach the road simultaneously, it will be blocked. The main goal of this paper is to investigate how wireless communications among the vehicles can lead the solution near to Pareto optimum. In addition, we implemented such a vehicular test-bed, composed of networked robots that have an infrared sensor, a DC motor, and a wireless communication module: ZigBee (IEEE 802.15.4).", "subjects": "Robotics (cs.RO)", "authors": "Taehyoung Shim, Seong-Lyun Kim,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00434", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00434", "title": "\nSegment-Sliding Reconstruction of Pulsed Radar Echoes with Sub-Nyquist  Sampling", "abstract": "It has been shown that analog-to-information con- version (AIC) is an efficient scheme to perform sub-Nyquist sampling of pulsed radar echoes. However, it is often impractical, if not infeasible, to reconstruct full-range Nyquist samples because of huge storage and computational load requirements. Based on the analyses of AIC measurement system, this paper develops a novel segment-sliding reconstruction (SegSR) scheme to effectively reconstruct the Nyquist samples. The SegSR per- forms segment-by-segment reconstruction in a sliding mode and can be implemented in real-time. An important characteristic that distinguish the proposed SegSR from the existing methods is that the measurement matrix in each segment satisfies the restricted isometry property (RIP) condition. Partial support in the previous segment can be incorporated into the estimation of the Nyquist samples in the current segment. The effect of interference intro- duced from adjacent segments is theoretically analyzed, and it is revealed that the interference consists of two interference levels having different impacts to the signal reconstruction performance. With these observations, a two-step orthogonal matching pursuit (OMP) procedure is proposed for segment reconstruction, which takes into account different interference levels and partially known support of the previous segment. The proposed SegSR achieves nearly optimal reconstruction performance with a signi- ficant reduction of computational loads and storage requirements. Theoretical analyses and simulations verify its effectiveness.", "subjects": "Information Theory (cs.IT)", "authors": "Suling Zhang, Feng Xi, Shengyao Chen, Yimin D. Zhang, Zhong Liu,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00426", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00426", "title": "\nOn the Null Space Constant for $l_p$ Minimization", "abstract": "The literature on sparse recovery often adopts the \"norm\" as the penalty to induce sparsity of the signal satisfying an underdetermined linear system. The performance of the corresponding minimization problem can be characterized by its null space constant. In spite of the NP-hardness of computing the constant, its properties can still help in illustrating the performance of minimization. In this letter, we show the strict increase of the null space constant in the sparsity level and its continuity in the exponent . We also indicate that the constant is strictly increasing in with probability when the sensing matrix is randomly generated. Finally, we show how these properties can help in demonstrating the performance of minimization, mainly in the relationship between the the exponent and the sparsity level .", "subjects": "Information Theory (cs.IT)", "authors": "Laming Chen, Yuantao Gu,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00424", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00424", "title": "\nLearning Mixtures of Gaussians in High Dimensions", "abstract": "Efficiently learning mixture of Gaussians is a fundamental problem in statistics and learning theory. Given samples coming from a random one out of k Gaussian distributions in Rn, the learning problem asks to estimate the means and the covariance matrices of these Gaussians. This learning problem arises in many areas ranging from the natural sciences to the social sciences, and has also found many machine learning applications. Unfortunately, learning mixture of Gaussians is an information theoretically hard problem: in order to learn the parameters up to a reasonable accuracy, the number of samples required is exponential in the number of Gaussian components in the worst case. In this work, we show that provided we are in high enough dimensions, the class of Gaussian mixtures is learnable in its most general form under a smoothed analysis framework, where the parameters are randomly perturbed from an adversarial starting point. In particular, given samples from a mixture of Gaussians with randomly perturbed parameters, when n &gt; (k^2), we give an algorithm that learns the parameters with polynomial running time and using polynomial number of samples. The central algorithmic ideas consist of new ways to decompose the moment tensor of the Gaussian mixture by exploiting its structural properties. The symmetries of this tensor are derived from the combinatorial structure of higher order moments of Gaussian distributions (sometimes referred to as Isserlis' theorem or Wick's theorem). We also develop new tools for bounding smallest singular values of structured random matrices, which could be useful in other smoothed analysis settings.", "subjects": "Learning (cs.LG)", "authors": "Rong Ge, Qingqing Huang, Sham M. Kakade,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00423", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00423", "title": "\nA Simple Spectral Algorithm for Recovering Planted Partitions", "abstract": "In this paper, we consider the planted partition model, in which vertices of a random graph are partitioned into \"clusters,\" each of size . Edges between vertices in the same cluster and different clusters are included with constant probability and , respectively (where ). We give an efficient algorithm that, with high probability, recovers the clustering as long as the cluster sizes are are least . Our algorithm is based on projecting the graph's adjacency matrix onto the space spanned by its largest eigenvalues and using the result to recover one cluster at a time. While certainly not the first to use this approach, our algorithm has the advantage of being simple, and we employ a novel technique to prove its correctness.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Sam Cole, Shmuel Friedland, Lev Reyzin,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00388", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00388", "title": "\nA Novel Image Steganographic Approach for Hiding Text in Color Images  using HSI Color Model", "abstract": "Image Steganography is the process of embedding text in images such that its existence cannot be detected by Human Visual System (HVS) and is known only to sender and receiver. This paper presents a novel approach for image steganography using Hue-Saturation-Intensity (HSI) color space based on Least Significant Bit (LSB). The proposed method transforms the image from RGB color space to Hue-Saturation-Intensity (HSI) color space and then embeds secret data inside the Intensity Plane (I-Plane) and transforms it back to RGB color model after embedding. The said technique is evaluated by both subjective and Objective Analysis. Experimentally it is found that the proposed method have larger Peak Signal-to Noise Ratio (PSNR) values, good imperceptibility and multiple security levels which shows its superiority as compared to several existing methods", "subjects": "Multimedia (cs.MM)", "authors": "Khan Muhammad, Jamil Ahmad, Haleem Farman, Muhammad Zubair,", "date": "2015-3-2"}, 
{"urllink": "http://arxiv.org/abs/1503.00375", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00375", "title": "\nThe lambda mechanism in lambda calculus and in other calculi", "abstract": "A comparison of Landin's form of lambda calculus with Church's shows that, independently of the lambda calculus, there exists a mechanism for converting functions with arguments indexed by variables to the usual kind of function where the arguments are indexed numerically. We call this the \"lambda mechanism\" and show how it can be used in other calculi. In first-order predicate logic it can be used to define new functions and new predicates in terms of existing ones. In a purely imperative programming language it can be used to provide an Algol-like procedure facility.", "subjects": "Programming Languages (cs.PL)", "authors": "M.H. van Emden,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00374", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00374", "title": "\nA Randomized Algorithm for Approximating the Log Determinant of a  Symmetric Positive Definite Matrix", "abstract": "We introduce a novel algorithm for approximating the logarithm of the determinant of a symmetric positive definite matrix. The algorithm is randomized and proceeds in two steps: first, it finds an approximation to the largest eigenvalue of the matrix after running a few iterations of the so-called \"power method\" from the numerical linear algebra literature. Then, using this information, it approximates the traces of a small number of matrix powers of a specially constructed matrix, using the method of Avron and Toledo~ cite. From a theoretical perspective, we present strong worst-case analysis bounds for our algorithm. From an empirical perspective, we demonstrate that a C++ implementation of our algorithm can approximate the logarithm of the determinant of large matrices very accurately in a matter of seconds.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Christos Boutsidis, Petros Drineas, Prabhanjan Kambadur, Anastasios Zouzias,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00369", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00369", "title": "\nHeuristic Algorithm using Internet of Things and Mobility for solving  demographic issues in Financial Inclusion projects", "abstract": "All over the world, the population in rural and semi-urban areas is a major concern for policy makers as they require technology enablement most to get elevated from their living conditions. Financial Inclusion projects are meant to work in this area as well. However the reach of financial institutions in those areas is much lesser than in urban areas in general. New policies and strategies are being made towards making banking services more accessible to the people in rural and semi-urban area. Technology, in particular Internet of Things (IoT) and Mobility can play a major role in this context as an enabler and multiplier. This paper discusses about an IoT and Mobility driven approach, which the Financial Institutions may consider while trying to work on financial inclusion projects.", "subjects": "Computers and Society (cs.CY)", "authors": "Subhamoy Chakraborti, Sugata Sanyal,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00368", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00368", "title": "\nPhylogenetic incongruence through the lens of Monadic Second Order logic", "abstract": "Within the field of phylogenetics there is growing interest in measures for summarising the dissimilarity, or 'incongruence', of two or more phylogenetic trees. Many of these measures are NP-hard to compute and this has stimulated a considerable volume of research into fixed parameter tractable algorithms. In this article we use Monadic Second Order logic (MSOL) to give alternative, compact proofs of fixed parameter tractability for several well-known incongruency measures. In doing so we wish to demonstrate the considerable potential of MSOL - machinery still largely unknown outside the algorithmic graph theory community - within phylogenetics. A crucial component of this work is the observation that many of these measures, when bounded, imply the existence of an 'agreement forest' of bounded size, which in turn implies that an auxiliary graph structure, the display graph, has bounded treewidth. It is this bound on treewidth that makes the machinery of MSOL available for proving fixed parameter tractability. We give a variety of different MSOL formulations. Some are based on explicitly encoding agreement forests, while some only use them implicitly to generate the treewidth bound. Our formulations introduce a number of \"phylogenetics MSOL primitives\" which will hopefully be of use to other researchers.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Steven Kelk, Leo van Iersel, Celine Scornavacca,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00366", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00366", "title": "\nA New Chaos-Based Cryptosystem for Secure Transmitted Images", "abstract": "This paper presents a novel and robust chaos-based cryptosystem for secure transmitted images and four other versions. In the proposed block encryption/decryption algorithm, a 2D chaotic map is used to shuffle the image pixel positions. Then, substitution (confusion) and permutation (diffusion) operations on every block, with multiple rounds, are combined using two perturbed chaotic PWLCM maps. The perturbing orbit technique improves the statistical properties of encrypted images. The obtained error propagation in various standard cipher block modes demonstrates that the proposed cryptosystem is suitable to transmit cipher data over a corrupted digital channel. Finally, to quantify the security level of the proposed cryptosystem, many tests are performed and experimental results show that the suggested cryptosystem has a high security level.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Abir Awad,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00364", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00364", "title": "\nInvestigating the Impact of Global Positioning System Evidence", "abstract": "The continued amalgamation of Global Positioning Systems (GPS) into everyday activities stimulates the idea that these devices will increasingly contribute evidential importance in digital forensics cases. This study investigates the extent to which GPS devices are being used in criminal and civil court cases in the United Kingdom through the inspection of Lexis Nexis, Westlaw, and the British and Irish Legal Information Institute (BAILII) legal databases. The research identified 83 cases which involved GPS evidence from within the United Kingdom and Europe for the time period from 01 June 1993 to 01 June 2013. The initial empirical analysis indicates that GPS evidence in court cases is rising over time and the majority of those court cases are criminal cases.", "subjects": "Computers and Society (cs.CY)", "authors": "Kiyoshi J Berman, William Bradley Glisson, L. Milton Glisson,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00362", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00362", "title": "\nNEXP-completeness and Universal Hardness Results for Justification Logic", "abstract": "We provide a lower complexity bound for the satisfiability problem of a multi-agent justification logic, establishing that the general NEXP upper bound from our previous work is tight. We then use a simple modification of the corresponding reduction to prove that satisfiability for all multi-agent justification logics from there is hard for the Sigma 2 p class of the second level of the polynomial hierarchy - given certain reasonable conditions. Our methods improve on these required conditions for the same lower bound for the single-agent justification logics, proven by Buss and Kuznets in 2009, thus answering one of their open questions.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Antonis Achilleos,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00361", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00361", "title": "\nCoauthorship networks: A directed network approach considering the order  and number of coauthors", "abstract": "In many scientific fields, the order of coauthors on a paper conveys information about each individual's contribution to a piece of joint work. We argue that in prior network analyses of coauthorship networks, the information on ordering has been insufficiently considered because ties between authors are typically symmetrized. This is basically the same as assuming that each co-author has contributed equally to a paper. We introduce a solution to this problem by adopting a coauthorship credit allocation model proposed by Kim and Diesner (2014), which in its core conceptualizes co-authoring as a directed, weighted, and self-looped network. We test and validate our application of the adopted framework based on a sample data of 861 authors who have published in the journal Psychometrika. Results suggest that this novel sociometric approach can complement traditional measures based on undirected networks and expand insights into coauthoring patterns such as the hierarchy of collaboration among scholars. As another form of validation, we also show how our approach accurately detects prominent scholars in the Psychometric Society affiliated with the journal.", "subjects": "Digital Libraries (cs.DL)", "authors": "Jinseok Kim, Jana Diesner,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00340", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00340", "title": "\nEnvy-Free Pricing in Large Markets: Approximating Revenue and Welfare", "abstract": "We study the classic setting of envy-free pricing, in which a single seller chooses prices for its many items, with the goal of maximizing revenue once the items are allocated. Despite the large body of work addressing such settings, most versions of this problem have resisted good approximation factors for maximizing revenue; this is true even for the classic unit-demand case. In this paper we study envy-free pricing with unit-demand buyers, but unlike previous work we focus on large markets: ones in which the demand of each buyer is infinitesimally small compared to the size of the overall market. We assume that the buyer valuations for the items they desire have a nice (although reasonable) structure, i.e., that the aggregate buyer demand has a monotone hazard rate and that the values of every buyer type come from the same support. For such large markets, our main contribution is a 1.88 approximation algorithm for maximizing revenue, showing that good pricing schemes can be computed when the number of buyers is large. We also give a (e,2)-bicriteria algorithm that simultaneously approximates both maximum revenue and welfare, thus showing that it is possible to obtain both good revenue and welfare at the same time. We further generalize our results by relaxing some of our assumptions, and quantify the necessary tradeoffs between revenue and welfare in our setting. Our results are the first known approximations for large markets, and crucially rely on new lower bounds which we prove for the revenue-maximizing prices.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Elliot Anshelevich, Koushik Kar, Shreyas Sekar,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00339", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00339", "title": "\nVariation in the vocabulary of Russian literary texts", "abstract": "In this paper, the data from a large online collection is used to study variation in the vocabulary of Russian literary texts. First, we find that variation in the vocabulary size of different authors is in a good agreement with Heaps' law with parameter , consistent with previous studies. The overall distribution of word frequencies has lighter tails than both the Zipf and lognormal laws predict. Next, we focus on the variation of word frequencies across texts. We confirm statistically that word frequencies vary significantly across texts, and find that the variance of the cross-text frequency distribution is in general higher for more frequent words. The dependence of the variance on the average word frequency follows a power law with exponent The factor models applied to the data suggest that the most of the cross-text variation is concentrated in less than most frequent words and can be explained by about factors. For less-frequent words, the frequency data is more suitable for factor analysis if it is normalized to take into account the size of texts. The matrix of normalized frequencies for less-frequent words exhibit properties characteristic for a large random matrix deformed by a low-rank matrix. As an example of application, the spectral factors for the most frequent words are used to classify texts, and it is found that the k-means classification algorithm based on these factors can classify texts by authors with the accuracy that varied from about to for prose writers, and from to for poets.", "subjects": "Computation and Language (cs.CL)", "authors": "Vladislav Kargin,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00338", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00338", "title": "\nPhase Transitions in Sparse PCA", "abstract": "We study optimal estimation for sparse principal component analysis when the number of non-zero elements is small but on the same order as the dimension of the data. We employ approximate message passing (AMP) algorithm and its state evolution to analyze what is the information theoretically minimal mean-squared error and the one achieved by AMP in the limit of large sizes. For a special case of rank one and large enough density of non-zeros Deshpande and Montanari [1] proved that AMP is asymptotically optimal. We show that both for low density and for large rank the problem undergoes a series of phase transitions suggesting existence of a region of parameters where estimation is information theoretically possible, but AMP (and presumably every other polynomial algorithm) fails. The analysis of the large rank limit is particularly instructive.", "subjects": "Information Theory (cs.IT)", "authors": "Thibault Lesieur, Florent Krzakala, Lenka Zdeborova,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00336", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00336", "title": "\nCLP(H): Constraint Logic Programming for Hedges", "abstract": "CLP(H) is an instantiation of the general constraint logic programming scheme with the constraint domain of hedges. Hedges are finite sequences of unranked terms, built over variadic function symbols and three kinds of variables: for terms, for hedges, and for function symbols. Constraints involve equations between unranked terms and atoms for regular hedge language membership. We study algebraic semantics of CLP(H) programs, define a sound, terminating, and incomplete constraint solver, investigate two fragments of constraints for which the solver returns a complete set of solutions, and describe classes of programs that generate such constraints.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Besik Dundua, M\u00e1rio Florido, Temur Kutsia, Mircea Marin,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00330", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00330", "title": "\nGPU Based Path Integral Control with Learned Dynamics", "abstract": "We present an algorithm which combines recent advances in model based path integral control with machine learning approaches to learning forward dynamics models. We take advantage of the parallel computing power of a GPU to quickly take a massive number of samples from a learned probabilistic dynamics model, which we use to approximate the path integral form of the optimal control. The resulting algorithm runs in a receding-horizon fashion in realtime, and is subject to no restrictive assumptions about costs, constraints, or dynamics. A simple change to the path integral control formulation allows the algorithm to take model uncertainty into account during planning, and we demonstrate its performance on a quadrotor navigation task. In addition to this novel adaptation of path integral control, this is the first time that a receding-horizon implementation of iterative path integral control has been run on a real system.", "subjects": "Robotics (cs.RO)", "authors": "Grady Williams, Eric Rombokas, Tom Daniel,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00327", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00327", "title": "\nComputing in continuous space with self-assembling polygonal tiles", "abstract": "In this paper we investigate the computational power of the polygonal tile assembly model (polygonal TAM) at temperature 1, i.e. in non-cooperative systems. The polygonal TAM is an extension of Winfree's abstract tile assembly model (aTAM) which not only allows for square tiles (as in the aTAM) but also allows for tile shapes that are polygons. Although a number of self-assembly results have shown computational universality at temperature 1, these are the first results to do so by fundamentally relying on tile placements in continuous, rather than discrete, space. With the square tiles of the aTAM, it is conjectured that the class of temperature 1 systems is not computationally universal. Here we show that the class of systems whose tiles are composed of a regular polygon P with n &gt; 6 sides is computationally universal. On the other hand, we show that the class of systems whose tiles consist of a regular polygon P with n &lt;= 6 cannot compute using any known techniques. In addition, we show a number of classes of systems whose tiles consist of a non-regular polygon with n &gt;= 3 sides are computationally universal.", "subjects": "Computational Geometry (cs.CG)", "authors": "Oscar Gilbert, Jacob Hendricks, Matthew J. Patitz, Trent A. Rogers,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00322", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00322", "title": "\nPersonalized PageRank Solution Paths", "abstract": "Personalized PageRank vectors used for many community detection and graph diffusion problems have a subtle dependence on a parameter epsilon that controls their accuracy. This parameter governs the sparsity of the solution and can be interpreted as a regularization parameter. We study algorithms to estimate the solution path as a function of the sparsity and propose two methods for this task. The first computes a full solution path and we prove it remains localized in the graph for fast runtimes. Using this method, we propose a PageRank solution path plot to diagnose new aspects of the behavior of personalized PageRank. The second method is a faster approximation to the solution path on a grid of logarithmically-spaced values that uses an interesting application of bucket sort to make the process efficient. We demonstrate that both of these algorithms are fast and local on large networks.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Kyle Kloster, David F. Gleich,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00321", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00321", "title": "\nA Sampling Technique of Proving Lower Bounds for Noisy Computations", "abstract": "We present a technique of proving lower bounds for noisy computations. This is achieved by a theorem connecting computations on a kind of randomized decision trees and sampling based algorithms. This approach is surprisingly powerful, and applicable to several models of computation previously studied. As a first illustration we show how all the results of Evans and Pippenger (SIAM J. Computing, 1999) for noisy decision trees, some of which were derived using Fourier analysis, follow immediately if we consider the sampling-based algorithms that naturally arise from these decision trees. Next, we show a tight lower bound of on the number of transmissions required to compute several functions (including the parity function and the majority function) in a network of randomly placed sensors, communicating using local transmissions, and operating with power near the connectivity threshold. This result considerably simplifies and strengthens an earlier result of Dutta, Kanoria Manjunath and Radhakrishnan (SODA 08) that such networks cannot compute the parity function reliably with significantly fewer than transmissions. The lower bound for parity shown earlier made use of special properties of the parity function and is inapplicable, e.g., to the majority function. In this paper, we use our approach to develop an interesting connection between computation of boolean functions on noisy networks that make few transmissionss, and algorithms that work by sampling only a part of the input. It is straightforward to verify that such sampling-based algorithms cannot compute the majority function.", "subjects": "Computational Complexity (cs.CC)", "authors": "Chinmoy Dutta, Jaikumar Radhakrishnan,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00311", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00311", "title": "\nReducing ADC Sampling Rate with Compressive Sensing", "abstract": "Many communication systems involve high bandwidth, while sparse, radio frequency (RF) signals. Working with high frequency signals requires appropriate system-level components such as high-speed analog-to-digital converters (ADC). In particular, an analog signal should be sampled at rates that meet the Nyquist requirements to avoid aliasing. However, implementing high-speed ADC devices can be a limiting factor as well as expensive. To mitigate the caveats with high-speed ADC, the solution space can be explored in several dimensions such as utilizing the compressive sensing (CS) framework in order to reduce the sampling rate to the order of information rate of the signal rather than a rate dictated by the Nyquist. In this note, we review the compressive sensing structure and its extensions for continuous-time signals, which is ultimately used to reduce the sampling rate of high-speed ADC devices. Moreover, we consider the application of the compressive sensing framework in wireless sensor networks to save power by reducing the transmission rate of sensor nodes. We propose an alternative solution for the CS minimization problem that can be solved using gradient descent methods. The modified minimization problem is potentially faster and simpler to implement at the hardware level.", "subjects": "Information Theory (cs.IT)", "authors": "Morteza Hashemi,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00310", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00310", "title": "\nData Fusion: Resolving Conflicts from Multiple Sources", "abstract": "Many data management applications, such as setting up Web portals, managing enterprise data, managing community data, and sharing scientific data, require integrating data from multiple sources. Each of these sources provides a set of values and different sources can often provide conflicting values. To present quality data to users, it is critical to resolve conflicts and discover values that reflect the real world; this task is called . This paper describes a novel approach that finds true values from conflicting information when there are a large number of sources, among which some may copy from others. We present a case study on real-world data showing that the described algorithm can significantly improve accuracy of truth discovery and is scalable when there are a large number of data sources.", "subjects": "Databases (cs.DB)", "authors": "Xin Luna Dong, Laure Berti-Equille, Divesh Srivastava,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00309", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00309", "title": "\nScaling up Copy Detection", "abstract": "Recent research shows that copying is prevalent for Deep-Web data and considering copying can significantly improve truth finding from conflicting values. However, existing copy detection techniques do not scale for large sizes and numbers of data sources, so truth finding can be slowed down by one to two orders of magnitude compared with the corresponding techniques that do not consider copying. In this paper, we study . Our algorithm builds an inverted index for each emph value and processes the index entries in decreasing order of how much the shared value can contribute to the conclusion of copying. We show how we use the index to prune the data items we consider for each pair of sources, and to incrementally refine our results in iterative copy detection. We also apply a sampling strategy with which we are able to further reduce copy-detection time while still obtaining very similar results as on the whole data set. Experiments on various real data sets show that our algorithm can reduce the time for copy detection by two to three orders of magnitude; in other words, truth finding can benefit from copy detection with very little overhead.", "subjects": "Databases (cs.DB)", "authors": "Xian Li, Xin Luna Dong, Kenneth B. Lyons, Weiyi Meng, Divesh Srivastava,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00306", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00306", "title": "\nFusing Data with Correlations", "abstract": "Many applications rely on Web data and extraction systems to accomplish knowledge-driven tasks. Web information is not curated, so many sources provide inaccurate, or conflicting information. Moreover, extraction systems introduce additional noise to the data. We wish to automatically distinguish correct data and erroneous data for creating a cleaner set of integrated data. Previous work has shown that a na \"ive voting strategy that trusts data provided by the majority or at least a certain number of sources may not work well in the presence of copying between the sources. However, correlation between sources can be much broader than copying: sources may provide data from complementary domains ( emph), extractors may focus on different types of information ( emph), and extractors may apply common rules in extraction ( emph). In this paper we present novel techniques modeling correlations between sources and applying it in truth finding.", "subjects": "Databases (cs.DB)", "authors": "Ravali Pochampally, Anish Das Sarma, Xin Luna Dong, Alexandra Meliou, Divesh Srivastava,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00303", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00303", "title": "\nTruth Finding on the Deep Web: Is the Problem Solved?", "abstract": "The amount of useful information available on the Web has been growing at a dramatic pace in recent years and people rely more and more on the Web to fulfill their information needs. In this paper, we study truthfulness of Deep Web data in two domains where we believed data are fairly clean and data quality is important to people's lives: and . To our surprise, we observed a large amount of inconsistency on data from different sources and also some sources with quite low accuracy. We further applied on these two data sets state-of-the-art methods that aim at resolving conflicts and finding the truth, analyzed their strengths and limitations, and suggested promising research directions. We wish our study can increase awareness of the seriousness of conflicting data on the Web and in turn inspire more research in our community to tackle this problem.", "subjects": "Databases (cs.DB)", "authors": "Xian Li, Xin Luna Dong, Kenneth Lyons, Weiyi Meng, Divesh Srivastava,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00302", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00302", "title": "\nFrom Data Fusion to Knowledge Fusion", "abstract": "The task of is to identify the true values of data items (eg, the true date of birth for ) among multiple observed values drawn from different sources (eg, Web sites) of varying (and unknown) reliability. A recent survey cite has provided a detailed comparison of various fusion methods on Deep Web data. In this paper, we study the applicability and limitations of different fusion techniques on a more challenging problem: . Knowledge fusion identifies true subject-predicate-object triples extracted by multiple information extractors from multiple information sources. These extractors perform the tasks of entity linkage and schema alignment, thus introducing an additional source of noise that is quite different from that traditionally considered in the data fusion literature, which only focuses on factual errors in the original sources. We adapt state-of-the-art data fusion techniques and apply them to a knowledge base with 1.6B unique knowledge triples extracted by 12 extractors from over 1B Web pages, which is three orders of magnitude larger than the data sets used in previous data fusion papers. We show great promise of the data fusion approaches in solving the knowledge fusion problem, and suggest interesting research directions through a detailed error analysis of the methods.", "subjects": "Databases (cs.DB)", "authors": "Xin Luna Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko Horn, Kevin Murphy, Shaohua Sun, Wei Zhang,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00301", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00301", "title": "\nOn Defining SPARQL with Boolean Tensor Algebra", "abstract": "The Resource Description Framework (RDF) represents information as subject-predicate-object triples. These triples are commonly interpreted as a directed labelled graph. We propose an alternative approach, interpreting the data as a 3-way Boolean tensor. We show how SPARQL queries - the standard queries for RDF - can be expressed as elementary operations in Boolean algebra, giving us a complete re-interpretation of RDF and SPARQL. We show how the Boolean tensor interpretation allows for new optimizations and analyses of the complexity of SPARQL queries. For example, estimating the size of the results for different join queries becomes much simpler.", "subjects": "Databases (cs.DB)", "authors": "Saskia Metzler, Pauli Miettinen,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00295", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00295", "title": "\nRegular realizability problems and context-free languages", "abstract": "We investigate regular realizability (RR) problems, which are the problems of verifying whether intersection of a regular language -- the input of the problem -- and fixed language called filter is non-empty. In this paper we focus on the case of context-free filters. Algorithmic complexity of the RR problem is a very coarse measure of context-free languages complexity. This characteristic is compatible with rational dominance. We present examples of P-complete RR problems as well as examples of RR problems in the class NL. Also we discuss RR problems with context-free filters that might have intermediate complexity. Possible candidates are the languages with polynomially bounded rational indices.", "subjects": "Formal Languages and Automata Theory (cs.FL)", "authors": "Alexander A. Rubtsov, Mikhail N. Vyalyi,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00288", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00288", "title": "\nSuccess factors for Crowdfunding founders and funders", "abstract": "Crowdfunding has been used as one of the effective ways for entrepreneurs to raise funding especially in creative industries. Individuals as well as organizations are paying more attentions to the emergence of new crowdfunding platforms. In the Netherlands, the government is also trying to help artists access financial resources through crowdfunding platforms. This research aims at discovering the success factors for crowdfunding projects through crowdfunding platforms from both founders and funders perspective. We designed our own website for founders and funders to observe crowdfunding behaviors. Our research will contribute to crowdfunding success factors related to issues of trust and decision making and provide practical recommendations for practitioners and researchers.", "subjects": "Computers and Society (cs.CY)", "authors": "Yang Song, Robert van Boeschoten,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00279", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00279", "title": "\nPartial Derivative Automaton for Regular Expressions with Shuffle", "abstract": "We generalize the partial derivative automaton to regular expressions with shuffle and study its size in the worst and in the average case. The number of states of the partial derivative automata is in the worst case at most 2^m, where m is the number of letters in the expression, while asymptotically and on average it is no more than (4/3)^m.", "subjects": "Formal Languages and Automata Theory (cs.FL)", "authors": "Sabine Broda, Ant\u00f3nio Machiavelo, Nelma Moreira, Rog\u00e9rio Reis,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00278", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00278", "title": "\nAn Introduction to Temporal Graphs: An Algorithmic Perspective", "abstract": "A emph is, informally speaking, a graph that changes with time. When time is discrete and only the relationships between the participating entities may change and not the entities themselves, a temporal graph may be viewed as a sequence of static graphs over the same (static) set of nodes . Though static graphs have been extensively studied, for their temporal generalization we are still far from having a concrete set of structural and algorithmic principles. Recent research shows that many graph properties and problems become radically different and usually substantially more difficult when an extra time dimension in added to them. Moreover, there is already a rich and rapidly growing set of modern systems and applications that can be naturally modeled and studied via temporal graphs. This, further motivates the need for the development of a temporal extension of graph theory. We survey here recent results on temporal graphs and temporal graph problems that have appeared in the Computer Science community.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Othon Michail,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00275", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00275", "title": "\nComparator Circuits over Finite Bounded Posets", "abstract": "Comparator circuit model was originally introduced by Mayr and Subramanian (1992) (and further studied by Cook, Filmus and Le (2012)) to capture problems which are not known to be P-complete but still not known to admit efficient parallel algorithms. The class CC is the complexity class of problems many-one logspace reducible to the Comparator Circuit Value Problem and we know that NL is contained in CC which is inturn contained in P. Cook, Filmus and Le (2012) showed that CC is also the class of languages decided by polynomial size comparator circuits. We study generalizations of the comparator circuit model that work over fixed finite bounded posets. We observe that there are universal comparator circuits even over arbitrary fixed finite bounded posets. Building on this, we show that general (resp. skew) comparator circuits of polynomial size over fixed finite distributive lattices characterizes CC (resp. L). Complementing this, we show that general comparator circuits of polynomial size over arbitrary fixed finite lattices exactly characterizes P and that when the comparator circuit is skew they characterize NL. In addition, we show a characterization of the class NP by a family of polynomial sized comparator circuits over fixed . These results generalize the results by Cook, Filmus and Le (2012) regarding the power of comparator circuits. As an aside, we consider generalizations of Boolean formulae over arbitrary lattices. We show that Spira's theorem (1971) can be extended to this setting as well and show that polynomial sized Boolean formulae over finite fixed lattices capture exactly NC^1. Our results indicate potential new approaches towards the problems P vs CC and NL vs L using lattice theoretic methods.", "subjects": "Computational Complexity (cs.CC)", "authors": "Balagopal Komarath, Jayalal Sarma, K.S. Sunil,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00267", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00267", "title": "\nDistributed Cloud Association in Downlink Multicloud Radio Access  Networks", "abstract": "This paper considers a multicloud radio access network (M-CRAN), wherein each cloud serves a cluster of base-stations (BS's) which are connected to the clouds through high capacity digital links. The network comprises several remote users, where each user can be connected to one (and only one) cloud. This paper studies the user-to-cloud-assignment problem by maximizing a network-wide utility subject to practical cloud connectivity constraints. The paper solves the problem by using an auction-based iterative algorithm, which can be implemented in a distributed fashion through a reasonable exchange of information between the clouds. The paper further proposes a centralized heuristic algorithm, with low computational complexity. Simulations results show that the proposed algorithms provide appreciable performance improvements as compared to the conventional cloud-less assignment solutions.", "subjects": "Information Theory (cs.IT)", "authors": "Hayssam Dahrouj, Tareq Y. Al-Naffouri, Mohamed-Slim Alouini,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00265", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00265", "title": "\nMulti-Server Coded Caching", "abstract": "In this paper, we consider multiple cache-enabled clients connected to multiple servers through an intermediate network. We design several topology-aware coding strategies for such networks. Based on topology richness of the intermediate network, and types of coding operations at internal nodes, we define three classes of networks, namely, dedicated, flexible, and linear networks. For each class, we propose an achievable coding scheme, analyze its coding delay, and also, compare it with an information theoretic lower bound. For flexible networks, we show that our scheme is order-optimal in terms of coding delay and, interestingly, the optimal memory-delay curve is achieved in certain regimes. In general, our results suggest that, in case of networks with multiple servers, type of network topology can be exploited to reduce service delay.", "subjects": "Information Theory (cs.IT)", "authors": "Seyed Pooya Shariatpanahi, Seyed Abolfazl Motahari, Babak Hossein Khalaj,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00260", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00260", "title": "\nParameter Compilation", "abstract": "In resolving instances of a computational problem, if multiple instances of interest share a feature in common, it may be fruitful to compile this feature into a format that allows for more efficient resolution, even if the compilation is relatively expensive. In this article, we introduce a formal framework for classifying problems according to their compilability. The basic object in our framework is that of a parameterized problem, which here is a language along with a parameterization---a map which provides, for each instance, a so-called parameter on which compilation may be performed. Our framework is positioned within the paradigm of parameterized complexity, and our notions are relatable to established concepts in the theory of parameterized complexity. Indeed, we view our framework as playing a unifying role, integrating together parameterized complexity and compilability theory.", "subjects": "Computational Complexity (cs.CC)", "authors": "Hubie Chen,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00258", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00258", "title": "\nDecidable Horn Systems with Difference Constraints Arithmetic", "abstract": "This paper tackles the problem of the existence of solutions for recursive systems of Horn clauses with second-order variables interpreted as integer relations, and harnessed by a simple first-order theory, such as difference bounds arithmetic. We start by the definition of a simple class of Horn systems with one second-order variable and one non-linear recursive rule, for which we prove the decidability of the problem \"does the system has a solution ?\". The proof relies on a construction of a tree automaton recognizing all cycles in the weighted graph corresponding to every unfolding tree of the Horn system. We constrain the tree to recognize only cycles of negative weight by adding a Presburger formula that harnesses the number of times each rule is fired, and reduce our problem to the universality of a Presburger-constrained tree automaton. We studied the complexity of this problem and found it to be in 2 textsc with a textsc-hard lower bound. In the second part, we drop the univariate restriction and consider multivariate second-order Horn systems with a structural restriction, called flatness. Finally, we show the decidability of the more general class of systems, within the same complexity bounds.", "subjects": "Formal Languages and Automata Theory (cs.FL)", "authors": "Radu Iosif,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00255", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00255", "title": "\nAn Online Convex Optimization Approach to Blackwell's Approachability", "abstract": "The notion of approachability in repeated games with vector payoffs was introduced by Blackwell in the 1950s, along with geometric conditions for approachability and corresponding strategies that rely on computing as projections from the current average payoff vector to the (convex) target set. Recently, Abernethy, Batlett and Hazan (2011) proposed a class of approachability algorithms that rely on the no-regret properties of Online Linear Programming for computing a suitable sequence of steering directions. This is first carried out for target sets that are convex cones, and then generalized to any convex set by embedding it in a higher-dimensional convex cone. In this paper we present a more direct formulation that relies on the support function of the set, along with suitable Online Convex Optimization algorithms, which leads to a general class of approachability algorithms. We further show that Blackwell's original algorithm and its convergence follow as a special case.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Nahum Shimkin,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00249", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00249", "title": "\nImprovement of Control System Performance by Modification of Time Delay", "abstract": "This paper presents a mathematical approach for improving the performance of a control system by modifying the time delay at certain operating conditions. This approach converts a continuous time loop into a discrete time loop. The formula derived is applied successfully to an applicable control system. The results show that the proposed approach efficiently improves the control system performance. The relation between the sampling time and the time delay is obtained. Two different operating conditions are examined to assess the proposed approach in improving the performance of the control system.", "subjects": "Systems and Control (cs.SY)", "authors": "Salem Alkhalaf,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00245", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00245", "title": "\nNovel Metaknowledge-based Processing Technique for Multimedia Big Data  clustering challenges", "abstract": "Past research has challenged us with the task of showing relational patterns between text-based data and then clustering for predictive analysis using Golay Code technique. We focus on a novel approach to extract metaknowledge in multimedia datasets. Our collaboration has been an on-going task of studying the relational patterns between datapoints based on metafeatures extracted from metaknowledge in multimedia datasets. Those selected are significant to suit the mining technique we applied, Golay Code algorithm. In this research paper we summarize findings in optimization of metaknowledge representation for 23-bit representation of structured and unstructured multimedia data in order to", "subjects": "Databases (cs.DB)", "authors": "Nima Bari, Roman Vichr, Kamran Kowsari, Simon Y. Berkovich,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00244", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00244", "title": "\n23-bit Metaknowledge Template Towards Big Data Knowledge Discovery and  Management", "abstract": "The global influence of Big Data is not only growing but seemingly endless. The trend is leaning towards knowledge that is attained easily and quickly from massive pools of Big Data. Today we are living in the technological world that Dr. Usama Fayyad and his distinguished research fellows discussed in the introductory explanations of Knowledge Discovery in Databases (KDD) predicted nearly two decades ago. Indeed, they were precise in their outlook on Big Data analytics. In fact, the continued improvement of the interoperability of machine learning, statistics, database building and querying fused to create this increasingly popular science- Data Mining and Knowledge Discovery. The next generation computational theories are geared towards helping to extract insightful knowledge from even larger volumes of data at higher rates of speed. As the trend increases in popularity, the need for a highly adaptive solution for knowledge discovery will be necessary. In this research paper, we are introducing the investigation and development of 23 bit-questions for a Metaknowledge template for Big Data Processing and clustering purposes. This research aims to demonstrate the construction of this methodology and proves the validity and the beneficial utilization that brings Knowledge Discovery from Big Data.", "subjects": "Databases (cs.DB)", "authors": "Nima Bari, Roman Vichr, Kamran Kowsari, Simon Y. Berkovich,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00237", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00237", "title": "\nTask Allocation in Robotic Swarms: Explicit Communication Based  Approaches", "abstract": "In this paper we study multi robot cooperative task allocation issue in a situation where a swarm of robots is deployed in a confi?ned unknown environment where the number of colored spots which represent tasks and the ratios of them are unknown. The robots should cover this spots as far as possible to do cleaning and sampling actions desirably. It means that they should discover the spots cooperatively and spread proportional to the spots area and avoid from remaining idle. We proposed 4 self-organized distributed methods which are called hybrid methods for coping with this scenario. In two diffe?rent experiments the performance of the methods is analyzed. We compared them with each other and investigated their scalability and robustness in term of single point of failure.", "subjects": "Multiagent Systems (cs.MA)", "authors": "Aryo Jamshidpey, Mohsen Afsharchi,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00208", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00208", "title": "\nGoogle-based Mode Choice Modeling Approach", "abstract": "Microsimulation based frameworks have become very popular in many research areas including travel demand modeling where activity-based models have been in the center of attention for the past decade. Advanced activity-based models synthesize the entire population of the study region and simulate their activities in a way that they can keep track of agents resources as well as their spatial location. However, the models that are built for these frameworks do not take into account this information mainly because they do not have them at the modeling stage. This paper tries to describe the importance of this information by analyzing a travel survey and generate the actual alternatives that individuals had when making their trips. With a focus on transit, the study reveals how transit alternatives are limited unavailable in certain areas which must be taken in to account in our mode choice models. Some statistics regarding available alternatives and the constraints people encounter when making a choice are presented with a comprehensive choice set formation. A mode choice model is then developed based on this approach to represent the importance of such information.", "subjects": "Other Computer Science (cs.OH)", "authors": "Zohreh Ghasemi,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00207", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00207", "title": "\nKnowledge-aided Two-dimensional Autofocus for Spotlight SAR Polar Format  Imagery", "abstract": "Conventional two-dimensional (2-D) autofocus algorithms blindly estimate the phase error in the sense that they do not exploit any a priori information on the structure of the 2-D phase error. As such, they often suffer from low computational efficiency and lack of data redundancy to accurately estimate the 2-D phase error. In this paper, a knowledge-aided (KA) 2-D autofocus algorithm which is based on exploiting a priori knowledge about the 2-D phase error structure, is presented. First, as a prerequisite of the proposed KA method, the analytical structure of residual 2-D phase error in SAR imagery is investigated in the polar format algorithm (PFA) framework. Then, by incorporating this a priori information, a novel 2-D autofocus approach is proposed. The new method only requires an estimate of azimuth phase error and/or residual range cell migration, while the 2-D phase error can then be computed directly from the estimated azimuth phase error or residual range cell migration. This 2-D autofocus method can also be applied to refocus moving targets in PFA imagery. Experimental results clearly demonstrate the effectiveness and robustness of the proposed method.", "subjects": "Information Theory (cs.IT)", "authors": "Xinhua Mao,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00205", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00205", "title": "\nA Game Theoretic Perspective on Self-organizing Optimization for  Cognitive Small Cells", "abstract": "In this article, we investigate self-organizing optimization for cognitive small cells (CSCs), which have the ability to sense the environment, learn from historical information, make intelligent decisions, and adjust their operational parameters. By exploring the inherent features, some fundamental challenges for self-organizing optimization in CSCs are presented and discussed. Specifically, the dense and random deployment of CSCs brings about some new challenges in terms of scalability and adaptation; furthermore, the uncertain, dynamic and incomplete information constraints also impose some new challenges in terms of convergence and robustness. For providing better service to the users and improving the resource utilization, four requirements for self-organizing optimization in CSCs are presented and discussed. Following the attractive fact that the decisions in game-theoretic models are exactly coincident with those in self-organizing optimization, i.e., distributed and autonomous, we establish a framework of game-theoretic solutions for self-organizing optimization in CSCs, and propose some featured game models. Specifically, their basic models are presented, some examples are discussed and future research directions are given.", "subjects": "Information Theory (cs.IT)", "authors": "Yuhua Xu, Jinlong Wang, Qihui Wu, Zhiyong Du, Liang Shen, Alagan Anpalagan,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00202", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00202", "title": "\nOn Integrating Information Visualization Techniques into Data Mining: A  Review", "abstract": "The exploding growth of digital data in the information era and its immeasurable potential value has called for different types of data-driven techniques to exploit its value for further applications. Information visualization and data mining are two research field with such goal. While the two communities advocates different approaches of problem solving, the vision of combining the sophisticated algorithmic techniques from data mining as well as the intuitivity and interactivity of information visualization is tempting. In this paper, we attempt to survey recent researches and real world systems integrating the wisdom in two fields towards more effective and efficient data analytics. More specifically, we study the intersection from a data mining point of view, explore how information visualization can be used to complement and improve different stages of data mining through established theories for optimized visual presentation as well as practical toolsets for rapid development. We organize the survey by identifying three main stages of typical process of data mining, the preliminary analysis of data, the model construction, as well as the model evaluation, and study how each stage can benefit from information visualization.", "subjects": "Graphics (cs.GR)", "authors": "Keqian Li,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00197", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00197", "title": "\nEmerging Methods and Tools for Sparking New Global Creative Networks", "abstract": "Emerging methods and tools are changing the ways participants in global creative networks become aware of each other and proceed to interact. Some web-based resources intended to spark new collaborations in creative networks have been plagued by dependence on fragmented or out-of-date information, having shallow recall (e.g. limited to a list of manually curated keywords), offering poor interconnectivity with other systems, and/or obtaining low end-user adoption. Increased availability of information about creative network participants' activities and outputs (e.g. completed sponsored research projects and published results, aggregated into global databases), coupled with advancement in information processing techniques like Natural Language Processing, enables new web-based technologies for discovering subject matter experts, facilities, and networks of current and potential collaborators. Large-scale data resources and NLP allow modern versions of these tools to avoid the problems of having sparse data and also provide for deep recall across many disciplinary vocabularies. These are \"passive\" technologies, from the perspective of the network participant, because the agent must undertake an action to use the information resources. Emerging \"active\" methods and tools utilize the same types of information and technologies, but actively intervene in the formation of the creative network by suggesting connections and arranging virtual or physical interactions. Active approaches can achieve very high end-user adoption rates. Both active and passive methods strive to use data-driven approaches to form better-than-chance awareness among networks of potential collaborators. Recent case studies suggest the existence of repeatable strategies for facilitating data-driven matching and better-than-chance interactions designed to spark new global creative networks.", "subjects": "Computers and Society (cs.CY)", "authors": "Jeff Horon,", "date": "2015-3-1"}, 
{"urllink": "http://arxiv.org/abs/1503.00193", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00193", "title": "\nRanking Templates for Linear Loops", "abstract": "We present a new method for the constraint-based synthesis of termination arguments for linear loop programs based on linear ranking templates. Linear ranking templates are parameterized, well-founded relations such that an assignment to the parameters gives rise to a ranking function. Our approach generalizes existing methods and enables us to use templates for many different ranking functions with affine-linear components. We discuss templates for multiphase, nested, piecewise, parallel, and lexicographic ranking functions. These ranking templates can be combined to form more powerful templates. Because these ranking templates require both strict and non-strict inequalities, we use Motzkin's transposition theorem instead of Farkas' lemma to transform the generated -constraint into an -constraint.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Jan Leike, Matthias Heizmann,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00190", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00190", "title": "\nComputing with Tangles", "abstract": "Tangles of graphs have been introduced by Robertson and Seymour in the context of their graph minor theory. Tangles may be viewed as describing \"k-connected components\" of a graph (though in a twisted way). They play an important role in graph minor theory. An interesting aspect of tangles is that they cannot only be defined for graphs, but more generally for arbitrary connectivity functions (that is, integer-valued submodular and symmetric set functions). However, tangles are difficult to deal with algorithmically. To start with, it is unclear how to represent them, because they are families of separations and as such may be exponentially large. Our first contribution is a data structure for representing and accessing all tangles of a graph up to some fixed order. Using this data structure, we can prove an algorithmic version of a very general structure theorem due to Carmesin, Diestel, Harman and Hundertmark (for graphs) and Hundertmark (for arbitrary connectivity functions) that yields a canonical tree decomposition whose parts correspond to the maximal tangles. (This may be viewed as a generalisation of the decomposition of a graph into its 3-connected components.)", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Martin Grohe, Pascal Schweitzer,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00185", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00185", "title": "\nWhen Are Tree Structures Necessary for Deep Learning of Representations?", "abstract": "Recursive neural models, which use syntactic parse trees to recursively generate representations bottom-up from parse children, are a popular new architecture, promising to capture structural properties like the scope of negation or long-distance semantic dependencies. But understanding exactly which tasks this parse-based method is appropriate for remains an open question. In this paper we benchmark recursive neural models against sequential recurrent neural models, which are structured solely on word sequences. We investigate 5 tasks: sentiment classification on (1) sentences and (2) syntactic phrases; (3) question answering; (4) discourse parsing; (5) semantic relations (e.g., component-whole between nouns); We find that recurrent models have equal or superior performance to recursive models on all tasks except one: semantic relations between nominals. Our analysis suggests that tasks relying on the scope of negation (like sentiment) are well-handled by sequential models. Recursive models help only with tasks that require representing long-distance relations between words. Our results offer insights on the design of neural architectures for representation learning.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Jiwei Li, Dan Jurafsky, Eudard Hovy,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1503.00184", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00184", "title": "\nTopology Discovery for Linear Wireless Networks with Application to  Train Backbone Inauguration", "abstract": "A train backbone network consists of a sequence of nodes arranged in a linear topology. A key step that enables communication in such a network is that of topology discovery, or train inauguration, whereby nodes learn in a distributed fashion the physical topology of the backbone network. While the current standard for train inauguration assumes wired links between adjacent backbone nodes, this work investigates the more challenging scenario in which the nodes communicate wirelessly. The implementation of topology discovery over wireless channels is made difficult by the broadcast nature of the wireless medium, and by fading and interference. A novel topology discovery protocol is proposed that overcomes these issues and requires relatively minor changes to the wired standard. The protocol is shown via analysis and numerical results to be robust to the impairments caused by the wireless channel including interference from other trains.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Yu Liu, Jianghua Feng, Osvaldo Simeone, Jun Tang, Zheng Wen, Alexander M. Haimovich, MengChu Zhou,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00174", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00174", "title": "\nCSCW Principles to Support Citizen Science", "abstract": "Citizen science changes the way scientific research is pursued. It opens up data collection and analysis to the general public, to the wisdom of crowds. In this emerging area, there is much research to be done to better understand how we can develop citizen science infrastructure and continue the democratization of science. In creating such systems, there is much we can learn from principles that have emerged out of computer-supported cooperative work (CSCW) research. In this paper, I use a nine-step framework to highlight where CSCW knowledge can contribute.", "subjects": "Computers and Society (cs.CY)", "authors": "Julia Katherine Haines,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00173", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00173", "title": "\nSignal Processing on Graphs: Modeling (Causal) Relations in Big Data", "abstract": "Many big data applications collect a large number of time series, for example, the financial data of companies quoted in a stock exchange, the health care data of all patients that visit the emergency room of a hospital, or the temperature sequences continuously measured by weather stations across the US. A first task in the analytics of these data is to derive a low dimensional representation, a graph or discrete manifold, that describes well the interrelations among the time series and their intrarelations across time. This paper presents a computationally tractable algorithm for estimating this graph structure from the available data. This graph is directed and weighted, possibly representing causation relations, not just correlations as in most existing approaches in the literature. The algorithm is demonstrated on random graph and real network time series datasets, and its performance is compared to that of related methods. The adjacency matrices estimated with the new method are close to the true graph in the simulated data and consistent with prior physical knowledge in the real dataset tested.", "subjects": "Information Theory (cs.IT)", "authors": "Jonathan Mei, Jos\u00e9 M. F. Moura,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00168", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00168", "title": "\nThe NLP Engine: A Universal Turing Machine for NLP", "abstract": "It is commonly accepted that machine translation is a more complex task than part of speech tagging. But how much more complex? In this paper we make an attempt to develop a general framework and methodology for computing the informational and/or processing complexity of NLP applications and tasks. We define a universal framework akin to a Turning Machine that attempts to fit (most) NLP tasks into one paradigm. We calculate the complexities of various NLP tasks using measures of Shannon Entropy, and compare `simple' ones such as part of speech tagging to `complex' ones such as machine translation. This paper provides a first, though far from perfect, attempt to quantify NLP tasks under a uniform paradigm. We point out current deficiencies and suggest some avenues for fruitful research.", "subjects": "Computation and Language (cs.CL)", "authors": "Jiwei Li, Eduard Hovy,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00158", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00158", "title": "\nContagious Sets in Dense Graphs", "abstract": "We study the activation process in undirected graphs known as bootstrap percolation: A vertex is active either if it belongs to a set of initially activated vertices or if at some point it had at least r active neighbors, for a threshold r that is identical for all vertices. A contagious set is a vertex set whose activation results with the entire graph being active. Let m(G,r) be the size of a smallest contagious set in a graph G. We examine density conditions that ensure that a given n-vertex graph G=(V,E) has a small contagious set. With respect to the minimum degree, we prove that if G has minimum degree n/2 then m(G,2)=2. We also provide tight upper bounds on the number of rounds until all nodes are active. For n &gt;= k &gt;= l, we denote by M(n,k,l) the maximum number of edges in an n-vertex graph G satisfying m(G,l)&gt;k. We determine the precise value of M(n,k,2) and M(n,k,k) assuming that n is sufficiently large compared to k.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Daniel Freund, Matthias Poloczek, Daniel Reichman,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00141", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00141", "title": "\nMultinational War is Hard", "abstract": "In this paper, we show that the problem of determining whether one player can force a win in a multiplayer version of the children's card game War is PSPACE-hard. The same reduction shows that a related problem, asking whether a player can survive k rounds, is PSPACE-complete when k is polynomial in the size of the input.", "subjects": "Computational Complexity (cs.CC)", "authors": "Jonathan Weed,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1503.00140", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00140", "title": "\nStabilizing Server-Based Storage in Byzantine Asynchronous  Message-Passing Systems", "abstract": "A stabilizing Byzantine single-writer single-reader (SWSR) regular register, which stabilizes after the first invoked write operation, is first presented. Then, new/old ordering inversions are eliminated by the use of a (bounded) sequence number for writes, obtaining a practically stabilizing SWSR atomic register. A practically stabilizing Byzantine single-writer multi-reader (SWMR) atomic register is then obtained by using several copies of SWSR atomic registers. Finally, bounded time-stamps, with a time-stamp per writer, together with SWMR atomic registers, are used to construct a practically stabilizing Byzantine multi-writer multi-reader (MWMR) atomic register. In a system of servers implementing an atomic register, and in addition to transient failures, the constructions tolerate t&lt;n/8 Byzantine servers if communication is asynchronous, and t&lt;n/3 Byzantine servers if it is synchronous. The noteworthy feature of the proposed algorithms is that (to our knowledge) these are the first that build an atomic read/write storage on top of asynchronous servers prone to transient failures, and where up to t of them can be Byzantine.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Silvia Bonomi, Shlomi Dolev, Maria Potop-Butucaru, Michel Raynal,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00121", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00121", "title": "\nRegion-Based Rate-Control for H.264/AVC for Low Bit-Rate Applications", "abstract": "Rate-control plays an important role in video coding. However, in the conventional rate-control algorithms, the number and position of Macroblocks (MBs) inside one basic unit for rate-control is inflexible and predetermined. The different characteristics of the MBs are not fully considered. Also, there is no overall optimization of the coding of basic units. This paper proposes a new region-based rate-control scheme for H.264/AVC to improve the coding efficiency. The inter-frame information is explored to objectively divide one frame into multiple regions based on their rate-distortion behaviors. The MBs with the similar characteristics are classified into the same region, and the entire region instead of a single MB or a group of contiguous MBs is treated as a basic unit for rate-control. A linear rate-quantization stepsize model and a linear distortion-quantization stepsize model are proposed to accurately describe the rate-distortion characteristics for the region-based basic units. Moreover, based on the above linear models, an overall optimization model is proposed to obtain suitable Quantization Parameters (QPs) for the region-based basic units. Experimental results demonstrate that the proposed region-based rate-control approach can achieve both better subjective and objective quality by performing the rate-control adaptively with the content, compared to the conventional rate-control approaches.", "subjects": "Multimedia (cs.MM)", "authors": "Hai-Miao Hu, Bo Li, Weiyao Lin, Wei Li, Ming-Ting Sun,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00118", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00118", "title": "\nAn Efficient Coding Method for Coding Region-of-Interest Locations in  AVS2", "abstract": "Region-of-Interest (ROI) location information in videos has many practical usages in video coding field, such as video content analysis and user experience improvement. Although ROI-based coding has been studied widely by many researchers to improve coding efficiency for video contents, the ROI location information itself is seldom coded in video bitstream. In this paper, we will introduce our proposed ROI location coding tool which has been adopted in surveillance profile of AVS2 video coding standard (surveillance profile). Our tool includes three schemes: direct-coding scheme, differential- coding scheme, and reconstructed-coding scheme. We will illustrate the details of these schemes, and perform analysis of their advantages and disadvantages, respectively.", "subjects": "Multimedia (cs.MM)", "authors": "Mingliang Chen, Weiyao Lin, Xiaozhen Zheng,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00107", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00107", "title": "\nNon-linear Learning for Statistical Machine Translation", "abstract": "Modern statistical machine translation (SMT) systems usually use a linear combination of features to model the quality of each translation hypothesis. The linear combination assumes that all the features are in a linear relationship and constrains that each feature interacts with the rest features in an linear manner, which might limit the expressive power of the model and lead to a under-fit model on the current data. In this paper, we propose a non-linear modeling for the quality of translation hypotheses based on neural networks, which allows more complex interaction between features. A learning framework is presented for training the non-linear models. We also discuss possible heuristics in designing the network structure which may improve the non-linear learning performance. Experimental results show that with the basic features of a hierarchical phrase-based machine translation system, our method produce translations that are better than a linear model.", "subjects": "Computation and Language (cs.CL)", "authors": "Shujian Huang, Huadong Chen, Xinyu Dai, Jiajun Chen,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00102", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00102", "title": "\nContext-Aware Reliability Prediction of Black-Box Services", "abstract": "Reliability prediction is an important research problem in software reliability engineering, which has been widely studied in the last decades. However, modelling and predicting user-perceived reliability of black-box services remain an open problem. Software services, such as Web services and Web APIs, generally provide black-box functionalities to users through the Internet, leading to a lack of their internal information for reliability analysis. Furthermore, the user-perceived service reliability depends not only on the service itself, but also heavily on the invocation context (e.g., service workloads, network conditions), whereby traditional reliability models become ineffective and inappropriate. To address these new challenges posed by black-box services, in this paper, we propose CARP, a context-aware reliability prediction approach that leverages historical usage data from users for reliability prediction. Through context-aware model construction and prediction, CARP is able to alleviate the data sparsity problem that heavily limits the prediction accuracy of other existing approaches. The preliminary evaluation results show that CARP can make significant improvement on reliability prediction accuracy, e.g., 41% for MAE and 38% for RMSE when only 5% of data are available.", "subjects": "Software Engineering (cs.SE)", "authors": "Jieming Zhu, Zibin Zheng, Michael R. Lyu,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00100", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00100", "title": "\nImproved Stability Analysis of Nonlinear Networked Control Systems over  Multiple Communication Links", "abstract": "In this paper, we consider a nonlinear networked control system (NCS) in which controllers, sensors and actuators are connected via several communication links. In each link, networking effects such as the transmission delay, packet loss, sampling jitter and data packet miss-ordering are captured by time-varying delays. Stability analysis is carried out based on the Lyapunov Krasovskii method to obtain a condition for stability of the nonlinear NCS in the form of linear matrix inequality (LMI). The results are applied to a two degrees of freedom robot arm NCS which shows a considerable improvement with respect to the previous works.", "subjects": "Systems and Control (cs.SY)", "authors": "Rahim Delavar, Babak Tavassoli, Mohammad Taghi Hamidi Beheshti,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00095", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00095", "title": "\nTask-Oriented Learning of Word Embeddings for Semantic Relation  Classification", "abstract": "We present a novel learning method for word embeddings designed for relation classification. Our word embeddings are trained by predicting words between noun pairs using lexical relation-specific features on a large unlabeled corpus. This allows us to explicitly incorporate relation-specific information into the word embeddings. The learned word embeddings are then used to construct feature vectors for a relation classification model. On a well-established semantic relation classification task, our method significantly outperforms a baseline based on a previously introduced word embedding method, and compares favorably to previous state-of-the-art models without syntactic information or manually constructed external resources. Furthermore, when incorporating external resources, our method outperforms the previous state of the art.", "subjects": "Computation and Language (cs.CL)", "authors": "Kazuma Hashimoto, Pontus Stenetorp, Makoto Miwa, Yoshimasa Tsuruoka,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00094", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00094", "title": "\nParameter Estimation of Jelinski-Moranda Model Based on Weighted  Nonlinear Least Squares and Heteroscedasticity", "abstract": "Parameter estimation method of Jelinski-Moranda (JM) model based on weighted nonlinear least squares (WNLS) is proposed. The formulae of resolving the parameter WNLS estimation (WNLSE) are derived, and the empirical weight function and heteroscedasticity problem are discussed. The effects of optimization parameter estimation selection based on maximum likelihood estimation (MLE) method, least squares estimation (LSE) method and weighted nonlinear least squares estimation (WNLSE) method are also investigated. Two strategies of heteroscedasticity decision and weighting methods embedded in JM model prediction process are also investigated. The experimental results on standard software reliability analysis database-Naval Tactical Data System (NTDS) and three datasets used by J.D. Musa demonstrate that WNLSE method can be superior to LSE and MLE under the relative error (RE) criterion.", "subjects": "Other Computer Science (cs.OH)", "authors": "Jingwei Liu, Yi Liu, Meizhi Xu,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00091", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00091", "title": "\nEfficient Domination for Some Subclasses of $P_6$-Free Graphs in  Polynomial Time", "abstract": "Let be a finite undirected graph. A vertex itself and all its neighbors in . A vertex set is an ( emph for short) of if every vertex of is dominated by exactly one vertex of . The emph (ED) problem, which asks for the existence of an e.d. in , is known to be NP-complete even for very restricted graph classes such as -free chordal graphs. The ED problem on a graph can be reduced to the Maximum Weight Independent Set (MWIS) problem on the square of . The complexity of the ED problem is an open question for -free graphs and was open even for the subclass of -free chordal graphs. In this paper, we show that squares of -free chordal graphs that have an e.d. are chordal; this even holds for the larger class of (, house, hole, domino)-free graphs. This implies that ED/WeightedED is solvable in polynomial time for (, house, hole, domino)-free graphs; in particular, for -free chordal graphs. Moreover, based on our result that squares of -free graphs that have an e.d. are hole-free and some properties concerning odd antiholes, we show that squares of (, house)-free graphs ((, bull)-free graphs, respectively) that have an e.d. are perfect. This implies that ED/WeightedED is solvable in polynomial time for (, house)-free graphs and for (, bull)-free graphs (the time bound for (, house, hole, domino)-free graphs is better than that for (, house)-free graphs). The complexity of the ED problem for -free graphs remains an open question.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Andreas Brandst\u00e4dt, Elaine M. Eschen, Erik Friese,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00090", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00090", "title": "\nImproved Image Deblurring based on Salient-region Segmentation", "abstract": "Image deblurring techniques play important roles in many image processing applications. As the blur varies spatially across the image plane, it calls for robust and effective methods to deal with the spatially-variant blur problem. In this paper, a Saliency-based Deblurring (SD) approach is proposed based on the saliency detection for salient-region segmentation and a corresponding compensate method for image deblurring. We also propose a PDE-based deblurring method which introduces an anisotropic Partial Differential Equation (PDE) model for latent image prediction and employs an adaptive optimization model in the kernel estimation and deconvolution steps. Experimental results demonstrate the effectiveness of the proposed algorithm.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Chongyang Zhang, Weiyao Lin, Wei Li, Bing Zhou, Jun Xie, Jijia Li,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00088", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00088", "title": "\nFacial Expression Cloning with Elastic and Muscle Models", "abstract": "Expression cloning plays an important role in facial expression synthesis. In this paper, a novel algorithm is proposed for facial expression cloning. The proposed algorithm first introduces a new elastic model to balance the global and local warping effects, such that the impacts from facial feature diversity among people can be minimized, and thus more effective geometric warping results can be achieved. Furthermore, a muscle-distribution-based (MD) model is proposed, which utilizes the muscle distribution of the human face and results in more accurate facial illumination details. In addition, we also propose a new distance-based metric to automatically select the optimal parameters such that the global and local warping effects in the elastic model can be suitably balanced. Experimental results show that our proposed algorithm outperforms the existing methods.", "subjects": "Graphics (cs.GR)", "authors": "Yihao Zhang, Weiyao Lin, Bing Zhou, Zhenzhong Chen, Bin Sheng, Jianxin Wu, Wenjun Zhang,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00087", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00087", "title": "\nMacroblock Classification Method for Video Applications Involving  Motions", "abstract": "In this paper, a macroblock classification method is proposed for various video processing applications involving motions. Based on the analysis of the Motion Vector field in the compressed video, we propose to classify Macroblocks of each video frame into different classes and use this class information to describe the frame content. We demonstrate that this low-computation-complexity method can efficiently catch the characteristics of the frame. Based on the proposed macroblock classification, we further propose algorithms for different video processing applications, including shot change detection, motion discontinuity detection, and outlier rejection for global motion estimation. Experimental results demonstrate that the methods based on the proposed approach can work effectively on these applications.", "subjects": "Multimedia (cs.MM)", "authors": "Weiyao Lin, Ming-Ting Sun, Hongxiang Li, Zhenzhong Chen, Wei Li, Bing Zhou,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00085", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00085", "title": "\nA Fast Sub-Pixel Motion Estimation Algorithm for H.264/AVC Video Coding", "abstract": "Motion Estimation (ME) is one of the most time-consuming parts in video coding. The use of multiple partition sizes in H.264/AVC makes it even more complicated when compared to ME in conventional video coding standards. It is important to develop fast and effective sub-pixel ME algorithms since (a) The computation overhead by sub-pixel ME has become relatively significant while the complexity of integer-pixel search has been greatly reduced by fast algorithms, and (b) Reducing sub-pixel search points can greatly save the computation for sub-pixel interpolation. In this paper, a novel fast sub-pixel ME algorithm is proposed which performs a 'rough' sub-pixel search before the partition selection, and performs a 'precise' sub-pixel search for the best partition. By reducing the searching load for the large number of non-best partitions, the computation complexity for sub-pixel search can be greatly decreased. Experimental results show that our method can reduce the sub-pixel search points by more than 50% compared to existing fast sub-pixel ME methods with negligible quality degradation.", "subjects": "Multimedia (cs.MM)", "authors": "Weiyao Lin, Krit Panusopone, David M. Baylon, Ming-Ting Sun, Zhenzhong Chen, Hongxiang Li,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00083", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00083", "title": "\nA Computation Control Motion Estimation Method for Complexity-Scalable  Video Coding", "abstract": "In this paper, a new Computation-Control Motion Estimation (CCME) method is proposed which can perform Motion Estimation (ME) adaptively under different computation or power budgets while keeping high coding performance. We first propose a new class-based method to measure the Macroblock (MB) importance where MBs are classified into different classes and their importance is measured by combining their class information as well as their initial matching cost information. Based on the new MB importance measure, a complete CCME framework is then proposed to allocate computation for ME. The proposed method performs ME in a one-pass flow. Experimental results demonstrate that the proposed method can allocate computation more accurately than previous methods and thus has better performance under the same computation budget.", "subjects": "Multimedia (cs.MM)", "authors": "Weiyao Lin, Krit Panusopone, David M. Baylon, Ming-Ting Sun,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00082", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00082", "title": "\nGroup Event Detection with a Varying Number of Group Members for Video  Surveillance", "abstract": "This paper presents a novel approach for automatic recognition of group activities for video surveillance applications. We propose to use a group representative to handle the recognition with a varying number of group members, and use an Asynchronous Hidden Markov Model (AHMM) to model the relationship between people. Furthermore, we propose a group activity detection algorithm which can handle both symmetric and asymmetric group activities, and demonstrate that this approach enables the detection of hierarchical interactions between people. Experimental results show the effectiveness of our approach.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Weiyao Lin, Ming-Ting Sun, Radha Poovendran, Zhengyou Zhang,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00081", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00081", "title": "\nActivity Recognition Using A Combination of Category Components And  Local Models for Video Surveillance", "abstract": "This paper presents a novel approach for automatic recognition of human activities for video surveillance applications. We propose to represent an activity by a combination of category components, and demonstrate that this approach offers flexibility to add new activities to the system and an ability to deal with the problem of building models for activities lacking training data. For improving the recognition accuracy, a Confident-Frame- based Recognition algorithm is also proposed, where the video frames with high confidence for recognizing an activity are used as a specialized local model to help classify the remainder of the video frames. Experimental results show the effectiveness of the proposed approach.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Weiyao Lin, Ming-Ting Sun, Radha Poovendran, Zhengyou Zhang,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00075", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00075", "title": "\nImproved Semantic Representations From Tree-Structured Long Short-Term  Memory Networks", "abstract": "A Long Short-Term Memory (LSTM) network is a type of recurrent neural network architecture which has recently obtained strong results on a variety of sequence modeling tasks. The only underlying LSTM structure that has been explored so far is a linear chain. However, natural language exhibits syntactic properties that would naturally combine words to phrases. We introduce the Tree-LSTM, a generalization of LSTMs to tree-structured network topologies. Tree-LSTMs outperform all existing systems and strong LSTM baselines on two tasks: predicting the semantic relatedness of two sentences (SemEval 2014, Task 1) and sentiment classification (Stanford Sentiment Treebank).", "subjects": "Computation and Language (cs.CL)", "authors": "Kai Sheng Tai, Richard Socher, Christopher D. Manning,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1503.00072", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00072", "title": "\nDeepTrack: Learning Discriminative Feature Representations Online for  Robust Visual Tracking", "abstract": "Deep neural networks, albeit their great success on feature learning in various computer vision tasks, are usually considered as impractical for online visual tracking because they require very long training time and a large number of training samples. In this work, we present an efficient and very robust tracking algorithm using a single Convolutional Neural Network (CNN) for learning effective feature representations of the target object, in a purely online manner. Our contributions are multifold: First, we introduce a novel truncated structural loss function that maintains as many training samples as possible and reduces the risk of tracking error accumulation. Second, we enhance the ordinary Stochastic Gradient Descent approach in CNN training with a robust sample selection mechanism. The sampling mechanism randomly generates positive and negative samples from different temporal distributions, which are generated by taking the temporal relations and label noise into account. Finally, a lazy yet effective updating scheme is designed for CNN training. Equipped with this novel updating algorithm, the CNN model is robust to some long-existing difficulties in visual tracking such as occlusion or incorrect detections, without loss of the effective adaption for significant appearance changes. In the experiment, our CNN tracker outperforms all compared state-of-the-art methods on two recently proposed benchmarks which in total involve over 60 video sequences. The remarkable performance improvement over the existing trackers illustrates the superiority of the feature representations which are learned", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Hanxi Li, Yi Li, Fatih Porikli,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00071", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00071", "title": "\nCrowd Congestion and Stampede Management through Multi Robotic Agents", "abstract": "Crowd management is a complex, challenging and crucial task. Lack of appropriate management of crowd has, in past, led to many unfortunate stampedes with significant loss of life. To increase the crowd management efficiency, we deploy automated real time detection of stampede prone areas. Then, we use robotic agents to aid the crowd management police in controlling the crowd in these stampede prone areas. While doing so, we aim for minimum interference by robotic agents in our environment. Thereby not disturbing the ambiance and aesthetics of the place. We evaluate the effectiveness of our model in dealing with difficult scenarios like emergency evacuation and presence of localized congestion. Lastly, we simulate a multi agent system based on our model and use it to illustrate the utility of robotic agents for detecting and reducing congestion.", "subjects": "Multiagent Systems (cs.MA)", "authors": "Garima Ahuja, Kamalakar Karlapalem,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00067", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00067", "title": "\nO(1) Time Generation of Adjacent Multiset Combinations", "abstract": "We solve the problem of designing an O(1) time algorithm for generating adjacent multiset combinations in a different approach from Walsh. By the word adjacent, we mean that two adjacent multiset combinations are different at two places by one in their vector forms. Previous O(1) time algorithms for multiset combinations generated non-adjacent multiset combinations. Our algorithm in this paper can be derived from a general framework of combinatorial Gray code, which we characterise to suit our need for combinations and multiset combinations. The central idea is a twisted lexico tree, which is obtained from the lexicographic tree for the given set of combinatorial objects by twisting branches depending on the parity of each node. An iterative algorithm which traverses this tree will generate the given set of combinatorial objects in constant time as well as with a fixed number of changes from the present combinatorial object to the next.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Tadao Takaoka,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00064", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00064", "title": "\nGenerating Multi-Sentence Lingual Descriptions of Indoor Scenes", "abstract": "This paper proposes a novel framework for generating lingual descriptions of indoor scenes. Whereas substantial efforts have been made to tackle this problem, previous approaches focusing primarily on generating a single sentence for each image, which is not sufficient for describing complex scenes. We attempt to go beyond this, by generating coherent descriptions with multiple sentences. Our approach is distinguished from conventional ones in several aspects: (1) a 3D visual parsing system that jointly infers objects, attributes, and relations; (2) a generative grammar learned automatically from training text; and (3) a text generation algorithm that takes into account the coherence among sentences. Experiments on the augmented NYU-v2 dataset show that our framework can generate natural descriptions with substantially higher ROGUE scores compared to those produced by the baseline.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Dahua Lin, Chen Kong, Sanja Fidler, Raquel Urtasun,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00054", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00054", "title": "\nMulti-Block ADMM for Big Data Optimization in Smart Grid", "abstract": "In this paper, we review the parallel and distributed optimization algorithms based on alternating direction method of multipliers (ADMM) for solving \"big data\" optimization problem in smart grid communication networks. We first introduce the canonical formulation of the large-scale optimization problem. Next, we describe the general form of ADMM and then focus on several direct extensions and sophisticated modifications of ADMM from -block to -block settings to deal with the optimization problem. The iterative schemes and convergence properties of each extension/modification are given, and the implementation on large-scale computing facilities is also illustrated. Finally, we numerate several applications in power system for distributed robust state estimation, network energy management and security constrained optimal power flow problem.", "subjects": "Systems and Control (cs.SY)", "authors": "Lanchao Liu, Zhu Han,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00049", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00049", "title": "\nAlgorithms for Longest Common Abelian Factors", "abstract": "In this paper we consider the problem of computing the longest common abelian factor (LCAF) between two given strings. We present a simple time algorithm, where is the length of the strings and is the alphabet size, and a sub-quadratic running time solution for the binary string case, both having linear space requirement. Furthermore, we present a modified algorithm applying some interesting tricks and experimentally show that the resulting algorithm runs faster.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Ali Alatabbi, Costas S. Iliopoulos, Alessio Langiu, M. Sohel Rahman,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00043", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00043", "title": "\nOn the complexity of Temporal Equilibrium Logic", "abstract": "Temporal Equilibrium Logic (TEL) is a promising framework that extends the knowledge representation and reasoning capabilities of Answer Set Programming with temporal operators in the style of LTL. To our knowledge it is the first nonmonotonic logic that accommodates fully the syntax of a standard temporal logic (specifically LTL) without requiring further constructions. This paper provides a systematic complexity analysis for the (consistency) problem of checking the existence of a temporal equilibrium model of a TEL formula. It was previously shown that this problem in the general case lies somewhere between PSPACE and EXPSPACE. Here we establish a lower bound matching the known EXPSPACE upper bound. Additionally we analyse the complexity for various natural subclasses of TEL formulas, identifying both tractable and intractable fragments. Finally the paper offers some new insights on the logic LTL by addressing satisfiability for minimal LTL models. The complexity results obtained highlight a substantial difference between interpreting LTL over finite or infinite words.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Laura Bozzelli, David Pearce,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00040", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00040", "title": "\nEfficient Upsampling of Natural Images", "abstract": "We propose a novel method of efficient upsampling of a single natural image. Current methods for image upsampling tend to produce high-resolution images with either blurry salient edges, or loss of fine textural detail, or spurious noise artifacts. In our method, we mitigate these effects by modeling the input image as a sum of edge and detail layers, operating upon these layers separately, and merging the upscaled results in an automatic fashion. We formulate the upsampled output image as the solution to a non-convex energy minimization problem, and propose an algorithm to obtain a tractable approximate solution. Our algorithm comprises two main stages. 1) For the edge layer, we use a nonparametric approach by constructing a dictionary of patches from a given image, and synthesize edge regions in a higher-resolution version of the image. 2) For the detail layer, we use a global parametric texture enhancement approach to synthesize detail regions across the image. We demonstrate that our method is able to accurately reproduce sharp edges as well as synthesize photorealistic textures, while avoiding common artifacts such as ringing and haloing. In addition, our method involves no training phase or estimation of model parameters, and is easily parallelizable. We demonstrate the utility of our method on a number of challenging standard test photos.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Chinmay Hegde, Oncel Tuzel, Fatih Porikli,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00038", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00038", "title": "\nSequential Feature Explanations for Anomaly Detection", "abstract": "In many applications, an anomaly detection system presents the most anomalous data instance to a human analyst, who then must determine whether the instance is truly of interest (e.g. a threat in a security setting). Unfortunately, most anomaly detectors provide no explanation about why an instance was considered anomalous, leaving the analyst with no guidance about where to begin the investigation. To address this issue, we study the problems of computing and evaluating sequential feature explanations (SFEs) for anomaly detectors. An SFE of an anomaly is a sequence of features, which are presented to the analyst one at a time (in order) until the information contained in the highlighted features is enough for the analyst to make a confident judgement about the anomaly. Since analyst effort is related to the amount of information that they consider in an investigation, an explanation's quality is related to the number of features that must be revealed to attain confidence. One of our main contributions is to present a novel framework for large scale quantitative evaluations of SFEs, where the quality measure is based on analyst effort. To do this we construct anomaly detection benchmarks from real data sets along with artificial experts that can be simulated for evaluation. Our second contribution is to evaluate several novel explanation approaches within the framework and on traditional anomaly detection benchmarks, offering several insights into the approaches.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Md Amran Siddiqui, Alan Fern, Thomas G. Dietterich, Weng-Keen Wong,", "date": "2015-2-28"}, 
{"urllink": "http://arxiv.org/abs/1503.00036", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00036", "title": "\nNorm-Based Capacity Control in Neural Networks", "abstract": "We investigate the capacity, convexity and characterization of a general family of norm-constrained feed-forward networks.", "subjects": "Learning (cs.LG)", "authors": "Behnam Neyshabur, Ryota Tomioka, Nathan Srebro,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1503.00035", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00035", "title": "\nTransducer Descriptions of DNA Code Properties and Undecidability of  Antimorphic Problems", "abstract": "This work concerns formal descriptions of DNA code properties, and builds on previous work on transducer descriptions of classic code properties and on trajectory descriptions of DNA code properties. This line of research allows us to give a property as input to an algorithm, in addition to any regular language, which can then answer questions about the language and the property. Here we define DNA code properties via transducers and show that this method is strictly more expressive than that of trajectories, without sacrificing the efficiency of deciding the satisfaction question. We also show that the maximality question can be undecidable. Our undecidability results hold not only for the fixed DNA involution but also for any fixed antimorphic permutation. Moreover, we also show the undecidability of the antimorphic version of the Post Corresponding Problem, for any fixed antimorphic permutation.", "subjects": "Formal Languages and Automata Theory (cs.FL)", "authors": "Lila Kari, Stavros Konstantinidis, Steffen Kopecki,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1503.00030", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00030", "title": "\nParsing as Reduction", "abstract": "We reduce phrase-representation parsing to dependency parsing. Our reduction is grounded on a new intermediate representation, \"head-ordered dependency trees\", shown to be isomorphic to constituent trees. By encoding order information in the dependency labels, we show that any off-the-shelf, trainable dependency parser can be used to produce constituents. When this parser is non-projective, we can perform discontinuous parsing in a very natural manner. Despite the simplicity of our approach, experiments show that the resulting parsers are on par with strong baselines, such as the Berkeley parser for English and the best single system in the SPMRL-2014 shared task. Results are particularly striking for discontinuous parsing of German, where we surpass the current state of the art by a wide margin.", "subjects": "Computation and Language (cs.CL)", "authors": "Daniel Fern\u00e1ndez-Gonz\u00e1lez, Andr\u00e9 F. T. Martins,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1503.00024", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00024", "title": "\nInfluence Maximization with Bandits", "abstract": "Most work on influence maximization assumes network influence probabilities are given. The few papers that propose algorithms for learning these probabilities assume the availability of a batch of diffusion cascades and learn the probabilities offline. We tackle the real but difficult problems of (i)learning in influence probabilities and (ii) maximizing influence spread, when no cascades are available as input, by adopting a combinatorial multi-armed bandit (CMAB) paradigm. We formulate the above problems respectively as network exploration, i.e., minimizing the error in learned influence probabilities, and minimization of loss in spread from choosing suboptimal seed sets over the rounds of a CMAB game. We propose algorithms for both problems and establish bounds on their performance. Finally, we demonstrate the effectiveness and usefulness of the proposed algorithms via a comprehensive set of experiments over three real datasets.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Sharan Vaswani, Laks.V.S.Lakshmanan,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1503.00022", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00022", "title": "\nPlagiarism Detection in Polyphonic Music using Monaural Signal  Separation", "abstract": "Given the large number of new musical tracks released each year, automated approaches to plagiarism detection are essential to help us track potential violations of copyright. Most current approaches to plagiarism detection are based on musical similarity measures, which typically ignore the issue of polyphony in music. We present a novel feature space for audio derived from compositional modelling techniques, commonly used in signal separation, that provides a mechanism to account for polyphony without incurring an inordinate amount of computational overhead. We employ this feature representation in conjunction with traditional audio feature representations in a classification framework which uses an ensemble of distance features to characterize pairs of songs as being plagiarized or not. Our experiments on a database of about 3000 musical track pairs show that the new feature space characterization produces significant improvements over standard baselines.", "subjects": "Sound (cs.SD)", "authors": "Soham De, Indradyumna Roy, Tarunima Prabhakar, Kriti Suneja, Sourish Chaudhuri, Rita Singh, Bhiksha Raj,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1503.00021", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00021", "title": "\nMercer kernels and integrated variance experimental design: connections  between Gaussian process regression and polynomial approximation", "abstract": "This paper examines experimental design procedures used to develop surrogates of computational models, exploring the interplay between experimental designs and approximation algorithms. We focus on two widely used approximation approaches, Gaussian process (GP) regression and non-intrusive polynomial approximation. First, we introduce algorithms for minimizing a posterior integrated variance (IVAR) design criterion for GP regression. Our formulation treats design as a continuous optimization problem that can be solved with gradient-based methods on complex input domains, without resorting to greedy approximations. We show that minimizing IVAR in this way yields point sets with good interpolation properties, and that it enables more accurate GP regression than designs based on entropy minimization or mutual information maximization. Second, using a Mercer kernel/eigenfunction perspective on GP regression, we identify conditions under which GP regression coincides with pseudospectral polynomial approximation. Departures from these conditions can be understood as changes either to the kernel or to the experimental design itself. We then show how IVAR-optimal designs, while sacrificing discrete orthogonality of the kernel eigenfunctions, can yield lower approximation error than orthogonalizing point sets. Finally, we compare the performance of adaptive Gaussian process regression and adaptive pseudospectral approximation for several classes of target functions, identifying features that are favorable to the GP + IVAR approach.", "subjects": "Numerical Analysis (cs.NA)", "authors": "Alex A. Gorodetsky, Youssef M. Marzouk,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1503.00013", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00013", "title": "\nMultilevel Diversity Coding with Regeneration", "abstract": "Digital contents in large scale distributed storage systems may have different reliability and access delay requirements, and for this reason, erasure codes with different strengths need to be utilized to achieve the best storage efficiency. At the same time, in such large scale distributed storage systems, nodes fail on a regular basis, and the contents stored on them need to be regenerated and stored on other healthy nodes, the efficiency of which is an important factor affecting the overall quality of service. In this work, we formulate the problem of multilevel diversity coding with regeneration to address these considerations, for which the storage vs. repair-bandwidth tradeoff is investigated. We show that the extreme point on this tradeoff corresponding to the minimum possible storage can be achieved by a simple coding scheme, where contents with different reliability requirements are encoded separately with individual regenerating codes without any mixing. On the other hand, we establish the complete storage-repair-bandwidth tradeoff for the case of four storage nodes, which reveals that codes mixing different contents can strictly improve this tradeoff over the separate coding solution.", "subjects": "Information Theory (cs.IT)", "authors": "Chao Tian, Tie Liu,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1503.00011", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00011", "title": "\nA Note on the Rate Region of Exact-Repair Regenerating Codes", "abstract": "The rate region of the exact-repair regenerating codes is provided. The outer bound is obtained through extension of the computational approach developed in an earlier work, and this region is indeed achievable using the canonical layered codes. This result is part of the online collection of \"Solutions of Computed Information Theoretic Limits (SCITL)\".", "subjects": "Information Theory (cs.IT)", "authors": "Chao Tian,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1503.00010", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1503.00010", "title": "\nA Note on the Fundamental Limits of Coded Caching", "abstract": "The fundamental limit of coded caching is investigated for the case with files and users. An improved outer bound is obtained through the computational approach developed by the author in an earlier work. This result is part of the online collection of \"Solutions of Computed Information Theoretic Limits (SCITL)\".", "subjects": "Information Theory (cs.IT)", "authors": "Chao Tian,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.08053", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.08053", "title": "\nStochastic Dual Coordinate Ascent with Adaptive Probabilities", "abstract": "This paper introduces AdaSDCA: an adaptive variant of stochastic dual coordinate ascent (SDCA) for solving the regularized empirical risk minimization problems. Our modification consists in allowing the method adaptively change the probability distribution over the dual variables throughout the iterative process. AdaSDCA achieves provably better complexity bound than SDCA with the best fixed probability distribution, known as importance sampling. However, it is of a theoretical character as it is expensive to implement. We also propose AdaSDCA+: a practical variant which in our experiments outperforms existing non-adaptive methods.", "subjects": "Optimization and Control (math.OC)", "authors": "Dominik Csiba, Zheng Qu, Peter Richt\u00e1rik,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.08029", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.08029", "title": "\nVideo Description Generation Incorporating Spatio-Temporal Features and  a Soft-Attention Mechanism", "abstract": "Recent progress in using recurrent neural networks (RNNs) for image description has motivated us to explore the application of RNNs to video description. Recent work has also suggested that attention mechanisms may be able to increase performance. To this end, we apply a long short-term memory (LSTM) network in two configurations: with a recently introduced soft-attention mechanism, and without. Our results suggest two things. First, incorporating a soft-attention mechanism into the text generation RNN significantly improves the quality of the descriptions. Second, using a combination of still frame features and dynamic motion-based features can also help. Ultimately, our combined approach exceeds the state-of-art on both BLEU and Meteor on the Youtube2Text dataset. We also present results on a new, larger and more complex dataset of paired video and natural language descriptions based on the use of Descriptive Video Service (DVS) annotations which are now widely available as an additional audio track on many DVDs.", "subjects": "Machine Learning (stat.ML)", "authors": "Li Yao, Atousa Torabi, Kyunghyun Cho, Nicolas Ballas, Christopher Pal, Hugo Larochelle, Aaron Courville,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.08014", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.08014", "title": "\nLocalization theorems for eigenvalues of quaternionic matrices", "abstract": "Ostrowski type and Brauer type theorems are derived for the left eigenvalues of quaternionic matrix. We see that the above theorems for the left eigenvalues are also true for the case of right eigenvalues, when the diagonals of quaternionic matrix are real. Some distribution theorems are given in terms of ovals of Cassini that are sharper than the Ostrowski type theorems, respectively, for the left and right eigenvalues of quaternionic matrix. In addition, generalizations of the Gerschgorin type theorems are discussed for both the left and right eigenvalues of quaternionic matrix, and finally, we see that our framework is so developed that generalizes the existing results in the literatures.", "subjects": "Rings and Algebras (math.RA)", "authors": "Sk. Safique Ahmad, Istkhar Ali,", "date": "2015-1-7"}, 
{"urllink": "http://arxiv.org/abs/1502.08003", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.08003", "title": "\nIllusory Sense of Human Touch from a Warm and Soft Artificial Hand", "abstract": "To touch and be touched are vital to human development, well being, and relationships. However, to those who have lost their arms and hands due to accident or war, touching becomes a serious concern that often leads to psychosocial issues and social stigma. In this paper, we demonstrate that the touch from a warm and soft rubber hand can be perceived by another person as if the touch were coming from a human hand. We describe a three step process toward this goal. First, we made participants select artificial skin samples according to their preferred warmth and softness characteristics. At room temperature, the preferred warmth was found to be 28.4 deg C at the skin surface of a soft silicone rubber material that has a Shore durometer value of 30 at the OO scale. Second, we developed a process to create a rubber hand replica of a human hand. To compare the skin softness of a human hand and artificial hands, a robotic indenter was employed to produce a softness map by recording the displacement data when constant indentation force of 1 N was applied to 780 data points on the palmar side of the hand. Results showed that an artificial hand with skeletal structure is as soft as a human hand. Lastly, the participants arms were touched with human and artificial hands, but they were prevented to see the hand that touched them. Receiver operating characteristic curve analysis suggests that a warm and soft artificial hand can create an illusion that the touch is from a human hand. These findings open the possibilities for prosthetic and robotic hands that are lifelike and are more socially acceptable.", "subjects": "Medical Physics (physics.med-ph)", "authors": "John-John Cabibihan, Deepak Joshi, Yeshwin Mysore Srinivasa, Mark Aaron Chan, Arrchana Muruganantham,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07981", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07981", "title": "\nThe lamplighter group $\\mathbb{Z}_3\\wr\\mathbb{Z}$ generated by a  bireversible automaton", "abstract": "We construct a bireversible self-dual automaton with states over an alphabet with letters which generates the lamplighter group .", "subjects": "Group Theory (math.GR)", "authors": "I. Bondarenko, D. D'Angeli, E. Rodaro,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07977", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07977", "title": "\nR\u00e9nyi generalizations of quantum information measures", "abstract": "Quantum information measures such as the entropy and the mutual information find applications in physics, e.g., as correlation measures. Generalizing such measures based on the R 'enyi entropies is expected to enhance their scope in applications. We prescribe R 'enyi generalizations for any quantum information measure which consists of a linear combination of von Neumann entropies with coefficients chosen from the set . As examples, we describe R 'enyi generalizations of the conditional quantum mutual information, some quantum multipartite information measures, and the topological entanglement entropy. Among these, we discuss the various properties of the R 'enyi conditional quantum mutual information and sketch some potential applications. We conjecture that the proposed R 'enyi conditional quantum mutual informations are monotone increasing in the R 'enyi parameter, and we have proofs of this conjecture for some special cases.", "subjects": "Quantum Physics (quant-ph)", "authors": "Mario Berta, Kaushik P. Seshadreesan, Mark M. Wilde,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07973", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07973", "title": "\nThe Fidelity of Recovery is Multiplicative", "abstract": "Fawzi and Renner (arXiv:1410.0664) recently established a lower bound on the conditional quantum mutual information of tripartite quantum states in terms of the fidelity of recovery, i.e. the maximal fidelity of the state with a state reconstructed from its marginal by acting only on the system. In this brief note we show that the fidelity of recovery is multiplicative by utilizing semi-definite programming duality. This allows us to simplify an operational proof by Brandao et al. (arXiv:1411.4921) of the above-mentioned lower bound that is based on quantum state redistribution. In particular, in contrast to the previous approaches, our proof does not rely on de Finetti reductions.", "subjects": "Quantum Physics (quant-ph)", "authors": "Mario Berta, Marco Tomamichel,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07971", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07971", "title": "\nA simple framework on sorting permutations", "abstract": "In this paper we present a simple framework to study various distance problems of permutations, including the transposition and block-interchange distance of permutations as well as the reversal distance of signed permutations. These problems are very important in the study of the evolution of genomes. We give a general formulation for lower bounds of the transposition and block-interchange distance from which the existing lower bounds obtained by Bafna and Pevzner, and Christie can be easily derived. As to the reversal distance of signed permutations, we translate it into a block-interchange distance problem of permutations so that we obtain a new lower bound. Furthermore, studying distance problems via our framework motivates several interesting combinatorial problems related to product of permutations, some of which are studied in this paper as well.", "subjects": "Combinatorics (math.CO)", "authors": "Ricky X. F. Chen, Christian M. Reidys,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.07838", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07838", "title": "\nRectangular maximum-volume submatrices and their applications", "abstract": "A definition of -volume of rectangular matrices is given. We generalize the results for square maximum-volume submatrices to the case rectangular maximal-volume submatrices and provide estimates for the growth of the coefficients. Three promising applications of such submatrices are presented: recommender systems, finding maximal elements in low-rank matrices and preconditioning of overdetermined linear systems. The code is available online at url.", "subjects": "Numerical Analysis (math.NA)", "authors": "A. Yu. Mikhalev, I. V. Oseledets,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07816", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07816", "title": "\nPuzzle Imaging: Using Large-scale Dimensionality Reduction Algorithms  for Localization", "abstract": "Current high-resolution imaging techniques require an intact sample that preserves spatial relationships. We here present a novel approach, \"puzzle imaging,\" that allows imaging a spatially scrambled sample. This technique takes many spatially disordered samples, and then pieces them back together using local properties embedded within the sample. We show that puzzle imaging can efficiently produce high-resolution images using dimensionality reduction algorithms. We demonstrate the theoretical capabilities of puzzle imaging in three biological scenarios, showing that (1) relatively precise 3-dimensional brain imaging is possible; (2) the physical structure of a neural network can often be recovered based only on the neural connectivity matrix; and (3) a chemical map could be reproduced using bacteria with chemosensitive DNA and conjugative transfer. The ability to reconstruct scrambled images promises to enable imaging based on DNA sequencing of homogenized tissue samples.", "subjects": "Neurons and Cognition (q-bio.NC)", "authors": "Joshua I. Glaser, Bradley M. Zamft, George M. Church, Konrad P. Kording,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.07758", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07758", "title": "\nFast and accurate prediction of numerical relativity waveforms from  binary black hole mergers using surrogate models", "abstract": "Simulating a binary black hole coalescence by solving Einstein's equations is computationally expensive, requiring days to months of supercomputing time. In this paper, we construct an accurate and fast-to-evaluate surrogate model for numerical relativity (NR) waveforms from non-spinning binary black hole coalescences with mass ratios from to and durations corresponding to about orbits before merger. Our surrogate, which is built using reduced order modeling techniques, is distinct from traditional modeling efforts. We find that the full multi-mode surrogate model agrees with waveforms generated by NR to within the numerical error of the NR code. In particular, we show that our modeling strategy produces surrogates which can correctly predict NR waveforms that were used for the surrogate's training. For all practical purposes, then, the surrogate waveform model is equivalent to the high-accuracy, large-scale simulation waveform but can be evaluated in a millisecond to a second depending on the number of output modes and the sampling rate. Our model includes all spherical-harmonic waveform modes that can be resolved by the NR code up to , including modes that are typically difficult to model with other approaches. We assess the model's uncertainty, which could be useful in parameter estimation studies seeking to incorporate model error. We anticipate NR surrogate models to be useful for rapid NR waveform generation in multiple-query applications like parameter estimation, template bank construction, and testing the fidelity of other waveform models.", "subjects": "General Relativity and Quantum Cosmology (gr-qc)", "authors": "Jonathan Blackman, Scott E. Field, Chad R. Galley, Bela Szilagyi, Mark A. Scheel, Manuel Tiglio, Daniel A. Hemberger,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07738", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07738", "title": "\nAchieving Exact Cluster Recovery Threshold via Semidefinite Programming:  Extensions", "abstract": "Recently it has been shown in cite that the semidefinite programming (SDP) relaxation of the maximum likelihood estimator achieves the sharp threshold for exactly recovering the community strucuture under the binary stochastic block model of two equal-sized clusters. Extending the techniques in cite, in this paper we show that SDP relaxations also achieve the sharp recovery threshold in the following cases: (1) Binary stochastic block model with two clusters of sizes proportional to but not necessarily equal; (2) Stochastic block model with a fixed number of equal-sized clusters; (3) Binary censored block model with the background graph being Erd Hs-R 'enyi.", "subjects": "Machine Learning (stat.ML)", "authors": "Bruce Hajek, Yihong Wu, Jiaming Xu,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07697", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07697", "title": "\nA Chaining Algorithm for Online Nonparametric Regression", "abstract": "We consider the problem of online nonparametric regression with arbitrary deterministic sequences. Using ideas from the chaining technique, we design an algorithm that achieves a Dudley-type regret bound similar to the one obtained in a non-constructive fashion by Rakhlin and Sridharan (2014). Our regret bound is expressed in terms of the metric entropy in the sup norm, which yields optimal guarantees when the metric and sequential entropies are of the same order of magnitude. In particular our algorithm is the first one that achieves optimal rates for online regression over Hlder balls. In addition we show for this example how to adapt our chaining algorithm to get a reasonable computational efficiency with similar regret guarantees (up to a log factor).", "subjects": "Machine Learning (stat.ML)", "authors": "Pierre Gaillard, S\u00e9bastien Gerchinovitz,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07645", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07645", "title": "\nPrivacy for Free: Posterior Sampling and Stochastic Gradient Monte Carlo", "abstract": "We consider the problem of Bayesian learning on sensitive datasets and present two simple but somewhat surprising results that connect Bayesian learning to \"differential privacy:, a cryptographic approach to protect individual-level privacy while permiting database-level utility. Specifically, we show that that under standard assumptions, getting one single sample from a posterior distribution is differentially private \"for free\". We will see that estimator is statistically consistent, near optimal and computationally tractable whenever the Bayesian model of interest is consistent, optimal and tractable. Similarly but separately, we show that a recent line of works that use stochastic gradient for Hybrid Monte Carlo (HMC) sampling also preserve differentially privacy with minor or no modifications of the algorithmic procedure at all, these observations lead to an \"anytime\" algorithm for Bayesian learning under privacy constraint. We demonstrate that it performs much better than the state-of-the-art differential private methods on synthetic and real datasets.", "subjects": "Machine Learning (stat.ML)", "authors": "Yu-Xiang Wang, Stephen E. Fienberg, Alex Smola,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07641", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07641", "title": "\nROCKET: Robust Confidence Intervals via Kendall's Tau for  Transelliptical Graphical Models", "abstract": "Undirected graphical models are used extensively in the biological and social sciences to encode a pattern of conditional independences between variables, where the absence of an edge between two nodes and indicates that the corresponding two variables and are believed to be conditionally independent, after controlling for all other measured variables. In the Gaussian case, conditional independence corresponds to a zero entry in the precision matrix (the inverse of the covariance matrix ). Real data often exhibits heavy tail dependence between variables, which cannot be captured by the commonly-used Gaussian or nonparanormal (Gaussian copula) graphical models. In this paper, we study the transelliptical model, an elliptical copula model that generalizes Gaussian and nonparanormal models to a broader family of distributions. We propose the ROCKET method, which constructs an estimator of that we prove to be asymptotically normal under mild assumptions. Empirically, ROCKET outperforms the nonparanormal and Gaussian models in terms of achieving accurate inference on simulated data. We also compare the three methods on real data (daily stock returns), and find that the ROCKET estimator is the only method whose behavior across subsamples agrees with the distribution predicted by the theory.", "subjects": "Statistics Theory (math.ST)", "authors": "Rina Foygel Barber, Mladen Kolar,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07555", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07555", "title": "\nSupport for Eschenmoser's Glyoxylate Scenario", "abstract": "A core topic of research in prebiotic chemistry is the search for plausible synthetic routes that connect the building blocks of modern life such as sugars, nucleotides, amino acids, and lipids to \"molecular food sources\" that have likely been abundant on Early Earth. In a recent contribution, Albert Eschenmoser emphasised the importance of catalytic and autocatalytic cycles in establishing such abiotic synthesis pathways. The accumulation of intermediate products furthermore provides additional catalysts that allow pathways to change over time. We show here that generative models of chemical spaces based on graph grammars make it possible to study such phenomena is a systematic manner. In addition to repro- ducing the key steps of Eschenmoser's hypothesis paper, we discovered previously unexplored potentially autocatalytic pathways from HCN to glyoxylate. A cascading of autocatalytic cycles could efficiently re-route matter, distributed over the combinatorial complex network of HCN hydrolysation chemistry, towards a potential primordial metabolism. The generative approach also has it intrinsic limitations: the unsupervised expansion of the chemical space remains infeasible due to the exponential growth of possible molecules and reactions between them. Here in particular the combinatorial complexity of the HCN polymerisation and hydrolysation networks forms the computational bottleneck. As a consequence, guidance of the computational exploration by chemical experience is indispensable.", "subjects": "Molecular Networks (q-bio.MN)", "authors": "Jakob L. Andersen, Christoph Flamm, Daniel Merkle, Peter F. Stadler,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07523", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07523", "title": "\nCramer-Rao Bound for Sparse Signals Fitting the Low-Rank Model with  Small Number of Parameters", "abstract": "In this paper, we consider signals with a low-rank covariance matrix which reside in a low-dimensional subspace and can be written in terms of a finite (small) number of parameters. Although such signals do not necessarily have a sparse representation in a finite basis, they possess a sparse structure which makes it possible to recover the signal from compressed measurements. We study the statistical performance bound for parameter estimation in the low-rank signal model from compressed measurements. Specifically, we derive the Cramer-Rao bound (CRB) for a generic low-rank model and we show that the number of compressed samples needs to be larger than the number of sources for the existence of an unbiased estimator with finite estimation variance. We further consider the applications to direction-of-arrival (DOA) and spectral estimation which fit into the low-rank signal model. We also investigate the effect of compression on the CRB by considering numerical examples of the DOA estimation scenario, and show how the CRB increases by increasing the compression or equivalently reducing the number of compressed samples.", "subjects": "Statistics Theory (math.ST)", "authors": "Mahdi Shaghaghi, Sergiy A. Vorobyov,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07484", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07484", "title": "\nGraphs with no induced wheel or antiwheel", "abstract": "A wheel is a graph that consists of a chordless cycle of length at least 4 plus a vertex with at least three neighbors on the cycle. It was shown recently that detecting induced wheels is an NP-complete problem. In contrast, it is shown here that graphs that contain no wheel and no antiwheel have a very simple structure and consequently can be recognized in polynomial time.", "subjects": "Combinatorics (math.CO)", "authors": "Fr\u00e9d\u00e9ric Maffray,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07410", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07410", "title": "\nTowards Constructing Ramanujan Graphs Using Shift Lifts", "abstract": "In a breakthrough work, Marcus-Spielman-Srivastava recently showed that every -regular bipartite Ramanujan graph has a 2-lift that is also -regular bipartite Ramanujan. As a consequence, a straightforward iterative brute-force search algorithm leads to the construction of a -regular bipartite Ramanujan graph on vertices in time . Shift -lifts studied by Agarwal-Kolla-Madan lead to a natural approach for constructing Ramanujan graphs more efficiently. The number of possible shift -lifts of a -regular -vertex graph is . Suppose the following holds for : There exists a shift -lift that maintains the Ramanujan property of -regular bipartite graphs on vertices for all . (*) Then, by performing a similar brute-force search algorithm, one would be able to construct an -vertex bipartite Ramanujan graph in time . Furthermore, if (*) holds for all , then one would obtain an algorithm that runs in time. In this work, we take a first step towards proving (*) by showing the existence of shift -lifts that preserve the Ramanujan property in -regular bipartite graphs for .", "subjects": "Combinatorics (math.CO)", "authors": "Karthekeyan Chandrasekaran, Ameya Velingker,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.07363", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07363", "title": "\nEntropy of finite random binary sequences with weak long-range  correlations", "abstract": "We study the N-step binary stationary ergodic Markov chain and analyze its differential entropy. Supposing that the correlations are weak we express the conditional probability function of the chain through the pair correlation function and represent the entropy as a functional of the pair correlator. Since the model uses the two-point correlators instead of the block probability, it makes it possible to calculate the entropy of strings at much longer distances than using standard methods. A fluctuation contribution to the entropy due to finiteness of random chains is examined. This contribution can be of the same order as its regular part even at the relatively short lengths of subsequences. A self-similar structure of entropy with respect to the decimation transformations is revealed for some specific forms of the pair correlation function. Application of the theory to the DNA sequence of the R3 chromosome of Drosophila melanogaster is presented.", "subjects": "Statistical Mechanics (cond-mat.stat-mech)", "authors": "S.S. Melnik, O.V. Usatenko,", "date": "2015-1-19"}, 
{"urllink": "http://arxiv.org/abs/1502.07310", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07310", "title": "\nPantheon: A Dataset for the Study of Global Cultural Production", "abstract": "We present the Pantheon 1.0 dataset: a manually curated dataset of individuals that have transcended linguistic, temporal, and geographic boundaries. The Pantheon 1.0 dataset includes the 11,341 biographies present in more than 25 languages in Wikipedia and is enriched with: (i) manually curated demographic information (place of birth, date of birth, and gender), (ii) a cultural domain classification categorizing each biography at three levels of aggregation (i.e. Arts/Fine Arts/Painting), and (iii) measures of global visibility (fame) including the number of languages in which a biography is present in Wikipedia, the monthly page-views received by a biography (2008-2013), and a global visibility metric we name the Historical Popularity Index (HPI). We validate our measures of global visibility (HPI and Wikipedia language editions) using external measures of accomplishment in several cultural domains: Tennis, Swimming, Car Racing, and Chess. In all of these cases we find that measures of accomplishments and fame (HPI) correlate with an , suggesting that measures of global fame are appropriate proxies for measures of accomplishment.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Amy Zhao Yu, Shahar Ronen, Kevin Hu, Tiffany Lu, C\u00e9sar A. Hidalgo,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07281", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07281", "title": "\nA problem related to the divisibility of exponential sums", "abstract": "Francis Castro, et al computed the exact divisibility of families of exponential sums associated to binomials F(X) = aXd1 + bXd2 over Fp, and a conjecture is presented for related work. Here we study this question.", "subjects": "Number Theory (math.NT)", "authors": "Xiaogang Liu,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.07229", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07229", "title": "\nOnline Pairwise Learning Algorithms with Kernels", "abstract": "Pairwise learning usually refers to a learning task which involves a loss function depending on pairs of examples, among which most notable ones include ranking, metric learning and AUC maximization. In this paper, we study an online algorithm for pairwise learning with a least-square loss function in an unconstrained setting of a reproducing kernel Hilbert space (RKHS), which we refer to as the Online Pairwise lEaRning Algorithm (OPERA). In contrast to existing works cite which require that the iterates are restricted to a bounded domain or the loss function is strongly-convex, OPERA is associated with a non-strongly convex objective function and learns the target function in an unconstrained RKHS. Specifically, we establish a general theorem which guarantees the almost surely convergence for the last iterate of OPERA without any assumptions on the underlying distribution. Explicit convergence rates are derived under the condition of polynomially decaying step sizes. We also establish an interesting property for a family of widely-used kernels in the setting of pairwise learning and illustrate the above convergence results using such kernels. Our methodology mainly depends on the characterization of RKHSs using its associated integral operators and probability inequalities for random variables with values in a Hilbert space.", "subjects": "Machine Learning (stat.ML)", "authors": "Yiming Ying, Ding-Xuan Zhou,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07193", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07193", "title": "\nLocal minimization algorithms for dynamic programming equations", "abstract": "The numerical realization of the dynamic programming principle for continuous-time optimal control leads to nonlinear Hamilton-Jacobi-Bellman equations which require the minimization of a nonlinear mapping over the set of admissible controls. This minimization is often performed by comparison over a finite number of elements of the control set. In this paper we demonstrate the importance of an accurate realization of these minimization problems and propose algorithms by which this can be achieved effectively. The considered class of equations includes nonsmooth control problems with -penalization which lead to sparse controls.", "subjects": "Optimization and Control (math.OC)", "authors": "Dante Kalise, Axel Kr\u00f6ner, Karl Kunisch,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07190", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07190", "title": "\nLatent quality models for document networks", "abstract": "We present the latent quality model (LQM) for joint modeling of topics and citations in document networks. The LQM combines the strengths of the latent Dirichlet allocation (LDA) and the mixed membership stochastic blockmodel (MMB), and associates each document with a latent quality score. This score provides a topic-free measure of the impact of a document, which is different from the raw count of citations. We develop an efficient algorithm for fitting the LQM using variational methods. To scale up to large networks, we develop an online variant using stochastic gradient methods and case-control likelihood approximation. We evaluate the performance of the LQM using the benchmark KDD Cup 2003 dataset with approximately 30,000 high energy physics papers and demonstrate that LQM can improve citation prediction significantly.", "subjects": "Machine Learning (stat.ML)", "authors": "Linda S. L. Tan, Aik Hui Chan, Tian Zheng,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07045", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07045", "title": "\nWhich phylogenetic networks are merely trees with additional arcs?", "abstract": "A binary phylogenetic network may or may not be obtainable from a tree by the addition of directed edges (arcs) between tree arcs. Here, we establish a precise and easily tested criterion (based on `antichains') that efficiently determines whether or not any given network can be realized in this way. Moreover, the proof provides a polynomial-time algorithm for finding one or more trees (when they exist) on which the network can be based. A number of interesting consequences are presented as corollaries; these lead to some further relevant questions and observations, which we outline in the conclusion.", "subjects": "Populations and Evolution (q-bio.PE)", "authors": "Andrew R. Francis, Mike Steel,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07016", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07016", "title": "\nTriadic analysis of affiliation networks", "abstract": "The widely-used notion of triadic closure has been conceptualized and measured in a variety of ways, most famously the clustering coefficient. This paper proposes a measure of triadic closure in affiliation networks designed to control for the influence of bicliques. In order to avoid arbitrariness, the paper introduces a triadic framework for affiliation networks, within which a range of possible statistics can be considered; it then takes an axiomatic approach to narrowing this range. The paper conducts an instrumental assessment of the proposed statistic alongside two previous proposals, for reliability, validity, and usefulness. Finally, these tools demonstrate their collective applicability in a multi-perspective investigation into triadic closure in several empirical social networks.", "subjects": "Combinatorics (math.CO)", "authors": "Jason Cory Brunson,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.06967", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06967", "title": "\nComputing the Degenerate Ground Space of Gapped Spin Chains in  Polynomial Time", "abstract": "Given a gapped Hamiltonian of a spin chain, we give a polynomial-time algorithm for finding the degenerate ground space projector. The output is an orthonormal set of matrix product states that approximate the true ground space projector up to an inverse polynomial error in any Schatten norm, with a runtime exponential in the degeneracy. Our algorithm is an extension of the recent algorithm of Landau, Vazirani, and Vidick for the nondegenerate case, and it includes the recent improvements due to Huang. The main new idea is to incorporate the local distinguishability of ground states on the half-chain to ensure that the algorithm returns a complete set of global ground states.", "subjects": "Quantum Physics (quant-ph)", "authors": "Christopher T. Chubb, Steven T. Flammia,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06910", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06910", "title": "\nThe Spontaneous Emergence of Conventions: An Experimental Study of  Cultural Evolution", "abstract": "How do shared conventions emerge in complex decentralized social systems? This question engages fields as diverse as linguistics, sociology and cognitive science. Previous empirical attempts to solve this puzzle all presuppose that formal or informal institutions, such as incentives for global agreement, coordinated leadership, or aggregated information about the population, are needed to facilitate a solution. Evolutionary theories of social conventions, by contrast, hypothesize that such institutions are not necessary in order for social conventions to form. However, empirical tests of this hypothesis have been hindered by the difficulties of evaluating the real-time creation of new collective behaviors in large decentralized populations. Here, we present experimental results - replicated at several scales - that demonstrate the spontaneous creation of universally adopted social conventions, and show how simple changes in a population's network structure can direct the dynamics of norm formation, driving human populations with no ambition for large scale coordination to rapidly evolve shared social conventions.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Damon Centola, Andrea Baronchelli,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06895", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06895", "title": "\nOn the consistency theory of high dimensional variable screening", "abstract": "Variable screening is a fast dimension reduction technique for assisting high dimensional feature selection. As a preselection method, it selects a moderate size subset of candidate variables for further refining via feature selection to produce the final model. The performance of variable screening depends on both computational efficiency and the ability to dramatically reduce the number of variables without discarding the important ones. When the data dimension is substantially larger than the sample size , variable screening becomes crucial as 1) Faster feature selection algorithms are needed; 2) Conditions guaranteeing selection consistency might fail to hold. par This article studies a class of linear screening methods and establishes consistency theory for this special class. In particular, we prove the weak diagonally dominant (WDD) condition is a necessary and sufficient condition for strong screening consistency. As concrete examples, we show two screening methods and are both strong screening consistent (subject to additional constraints) with large probability if under random designs. In addition, we relate the WDD condition to the irrepresentable condition, and highlight limitations of .", "subjects": "Statistics Theory (math.ST)", "authors": "Xiangyu Wang, Chenlei Leng, David B. Dunson,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06866", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06866", "title": "\nDaily rhythms in mobile telephone communication", "abstract": "Circadian rhythms are known to be important drivers of human activity and the recent availability of electronic records of human behaviour has provided fine-grained data of temporal patterns of activity on a large scale. Further, questionnaire studies have identified important individual differences in circadian rhythms, with people broadly categorised into morning-like or evening-like individuals. However, little is known about the social aspects of these circadian rhythms, or how they vary across individuals. In this study we use a unique 18-month dataset that combines mobile phone calls and questionnaire data to examine individual differences in the daily rhythms of mobile phone activity. We demonstrate clear individual differences in daily patterns of phone calls, and show that these individual differences are persistent despite a high degree of turnover in the individuals' social networks. Further, women's calls were longer than men's calls, especially during the evening and at night, and these calls were typically focused on a small number of emotionally intense relationships. These results demonstrate that individual differences in circadian rhythms are not just related to broad patterns of morningness and eveningness, but have a strong social component, in directing phone calls to specific individuals at specific times of day.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Talayeh Aledavood, Eduardo L\u00f3pez, Sam G. B. Roberts, Felix Reed-Tsochas, Esteban Moro, Robin I. M. Dunbar, Jari Saram\u00e4ki,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06797", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06797", "title": "\nApproximation of high-dimensional parametric PDEs", "abstract": "Parametrized families of PDEs arise in various contexts such as inverse problems, control and optimization, risk assessment, and uncertainty quantification. In most of these applications, the number of parameters is large or perhaps even infinite. Thus, the development of numerical methods for these parametric problems is faced with the possible curse of dimensionality. This article is directed at (i) identifying and understanding which properties of parametric equations allow one to avoid this curse and (ii) developing and analyzing effective numerical methodd which fully exploit these properties and, in turn, are immune to the growth in dimensionality. The first part of this article studies the smoothness and approximability of the solution map, that is, the map where is the parameter value and is the corresponding solution to the PDE. It is shown that for many relevant parametric PDEs, the parametric smoothness of this map is typically holomorphic and also highly anisotropic in that the relevant parameters are of widely varying importance in describing the solution. These two properties are then exploited to establish convergence rates of -term approximations to the solution map for which each term is separable in the parametric and physical variables. These results reveal that, at least on a theoretical level, the solution map can be well approximated by discretizations of moderate complexity, thereby showing how the curse of dimensionality is broken. This theoretical analysis is carried out through concepts of approximation theory such as best -term approximation, sparsity, and -widths. These notions determine a priori the best possible performance of numerical methods and thus serve as a benchmark for concrete algorithms. The second part of this article turns to the development of numerical algorithms based on the theoretically established sparse separable approximations. The numerical methods studied fall into two general categories. The first uses polynomial expansions in terms of the parameters to approximate the solution map. The second one searches for suitable low dimensional spaces for simultaneously approximating all members of the parametric family. The numerical implementation of these approaches is carried out through adaptive and greedy algorithms. An a priori analysis of the performance of these algorithms establishes how well they meet the theoretical benchmarks.", "subjects": "Analysis of PDEs (math.AP)", "authors": "Albert Cohen, Ronald Devore,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.06795", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06795", "title": "\nKolmogorov widths under holomorphic mappings", "abstract": "If is a bounded linear operator mapping the Banach space into the Banach space and is a compact set in , then the Kolmogorov widths of the image do not exceed those of multiplied by the norm of . We extend this result from linear maps to holomorphic mappings from to in the following sense: when the widths of are for some , then those of are for any , We then use these results to prove various theorems about Kolmogorov widths of manifolds consisting of solutions to certain parametrized PDEs. Results of this type are important in the numerical analysis of reduced bases and other reduced modeling methods, since the best possible performance of such methods is governed by the rate of decay of the Kolmogorov widths of the solution manifold.", "subjects": "Analysis of PDEs (math.AP)", "authors": "Albert Cohen, Ronald Devore,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06777", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06777", "title": "\nStatistical efficiency of structured cpd estimation applied to  Wiener-Hammerstein modeling", "abstract": "The computation of a structured canonical polyadic de-composition (CPD) is useful to address several important modeling problems in real-world applications. In this paper, we consider the identification of a nonlinear system by means of a Wiener-Hammerstein model, assuming a high-order Volterra kernel of that system has been previously estimated. Such a kernel, viewed as a tensor, admits a CPD with banded circulant factors which comprise the model parameters. To estimate them, we formulate specialized estimators based on recently proposed algorithms for the computation of struc-tured CPDs. Then, considering the presence of additive white Gaussian noise, we derive a closed-form expression for the Cramer-Rao bound (CRB) associated with this estimation problem. Finally, we assess the statistical performance of the proposed estimators via Monte Carlo simulations, by comparing their mean-square error with the CRB.", "subjects": "Computation (stat.CO)", "authors": "Jos\u00e9 Henrique De Morais Goulart, Maxime Boizard, R\u00e9my Boyer, G\u00e9rard Favier, Pierre Comon,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06759", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06759", "title": "\nA Logic of Quantum Measurement", "abstract": "We present a formulation of quantum mechanics based on a logic representing some aspects of the behaviour of the measurement process. With such an approach, we make no direct mention of quantum states, and thus avoid the problems associated to this rather evasive notion. We then study some properties of the models of this logic, and deduce some characteristics that any model (and hence any formulation of quantum mechanics compatible with its prediction and relying on a notion of measurement) should verify. The main results we obtain are that in the case of a Hilbert space of dimension at least 3, no model can lead to the prediction with certainty of more than one atomic outcome. Moreover, if the Hilbert space is finite dimensional, then we are able to precisely describe the structure of the predictions of any model of our logic. As a consequence, we finally show that all the models of our logic make exactly the same predictions regarding whether a given sequence of outcomes is possible or not.", "subjects": "Quantum Physics (quant-ph)", "authors": "Olivier Brunet,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06644", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06644", "title": "\nOn The Identifiability of Mixture Models from Grouped Samples", "abstract": "Finite mixture models are statistical models which appear in many problems in statistics and machine learning. In such models it is assumed that data are drawn from random probability measures, called mixture components, which are themselves drawn from a probability measure P over probability measures. When estimating mixture models, it is common to make assumptions on the mixture components, such as parametric assumptions. In this paper, we make no assumption on the mixture components, and instead assume that observations from the mixture model are grouped, such that observations in the same group are known to be drawn from the same component. We show that any mixture of m probability measures can be uniquely identified provided there are 2m-1 observations per group. Moreover we show that, for any m, there exists a mixture of m probability measures that cannot be uniquely identified when groups have 2m-2 observations. Our results hold for any sample space with more than one element.", "subjects": "Machine Learning (stat.ML)", "authors": "Robert A. Vandermeulen, Clayton D. Scott,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06631", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06631", "title": "\nPolynomial Interpolation and Identity Testing from High Powers over  Finite Fields", "abstract": "We consider the problem of recovering (that is, interpolating) and identity testing of a \"hidden\" monic polynomial , given an oracle access to for (extension fields access is not permitted). The naive interpolation algorithm needs queries and thus requires . We design algorithms that are asymptotically better in certain cases; requiring only queries to the oracle. In the randomized (and quantum) setting, we give a substantially better interpolation algorithm, that requires only queries. Such results have been known before only for the special case of a linear , called the hidden shifted power problem. We use techniques from algebra, such as effective versions of Hilbert's Nullstellensatz, and analytic number theory, such as results on the distribution of rational functions in subgroups and character sum estimates.", "subjects": "Number Theory (math.NT)", "authors": "Gabor Ivanyos, Marek Karpinski, Miklos Santha, Nitin Saxena, Igor Shparlinski,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06501", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06501", "title": "\nKnowledge Discovery Framework for the Virtual Observatory", "abstract": "We describe a framework that allows a scientist-user to easily query for information across all Virtual Observatory (VO) repositories and pull it back for analysis. This framework hides the gory details of meta-data remediation and data formatting from the user, allowing them to get on with search, retrieval and analysis of VO data as if they were drawn from a single source using a science based terminology rather than a data-centric one.", "subjects": "Instrumentation and Methods for Astrophysics (astro-ph.IM)", "authors": "Brian Thomas, Edward Shaya, Zenping Huang, Peter Teuben,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06492", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06492", "title": "\nA User Interface for Semantically Oriented Data Mining of Astronomy  Repositories", "abstract": "We present a user-friendly, but powerful interface for the data mining of scientific repositories. We present the tool in use with actual astronomy data and show how it may be used to achieve many different types of powerful semantic queries. The tool itself hides the gory details of query formulation, and data retrieval from the user, and allows the user to create workflows which may be used to transform the data into a convenient form.", "subjects": "Instrumentation and Methods for Astrophysics (astro-ph.IM)", "authors": "Brian Thomas, Edward Shaya,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06471", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06471", "title": "\nRestricted density classification in one dimension", "abstract": "The density classification task is to determine which of the symbols appearing in an array has the majority. A cellular automaton solving this task is required to converge to a uniform configuration with the majority symbol at each site. It is not known whether a one-dimensional cellular automaton with binary alphabet can classify all Bernoulli random configurations almost surely according to their densities. We show that any cellular automaton that washes out finite islands in linear time classifies all Bernoulli random configurations with parameters close to 0 or 1 almost surely correctly. The proof is a direct application of a \"percolation\" argument, which goes back to G 'acs (1986).", "subjects": "Probability (math.PR)", "authors": "Siamak Taati,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06434", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06434", "title": "\nANN Model to Predict Stock Prices at Stock Exchange Markets", "abstract": "Stock exchanges are considered major players in financial sectors of many countries. Most Stockbrokers, who execute stock trade, use technical, fundamental or time series analysis in trying to predict stock prices, so as to advise clients. However, these strategies do not usually guarantee good returns because they guide on trends and not the most likely price. It is therefore necessary to explore improved methods of prediction. The research proposes the use of Artificial Neural Network that is feedforward multi-layer perceptron with error backpropagation and develops a model of configuration 5:21:21:1 with 80% training data in 130,000 cycles. The research develops a prototype and tests it on 2008-2012 data from stock markets e.g. Nairobi Securities Exchange and New York Stock Exchange, where prediction results show MAPE of between 0.71% and 2.77%. Validation done with Encog and Neuroph realized comparable results. The model is thus capable of prediction on typical stock markets.", "subjects": "Statistical Finance (q-fin.ST)", "authors": "B. W. Wanjawa, L. Muchemi,", "date": "2014-12-17"}, 
{"urllink": "http://arxiv.org/abs/1502.06430", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06430", "title": "\nA Bottom-up Approach to Opinion Dynamics: a Cognitive Model", "abstract": "The study of opinions - e.g., their formation and change, and their effects on our society - by means of theoretical and numerical models has been one of the main goals of sociophysics until now, but it is one of the defining topics addressed by social psychology and complexity science. Despite the flourishing of different models and theories, several key questions still remain unanswered. Aim of this paper is to provide a cognitively grounded computational model of opinions in which they are described as mental representations and defined in terms of distinctive mental features. We also define how these representations change dynamically through different processes, describing the interplay between mental and social dynamics of opinions. We present two versions of the model, one with discrete opinions (voter model-like), and one with continuous ones (Deffuant-like). By means of numerical simulations, we compare the behaviour of our cognitive model with the classical sociophysical models, showing how consensus is reached in either.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Francesca Giardini, Daniele Vilone, Rosaria Conte,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06381", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06381", "title": "\nThe ALICE analysis train system", "abstract": "In the ALICE experiment hundreds of users are analyzing big datasets on a Grid system. High throughput and short turn-around times are achieved by a centralized system called the LEGO trains. This system combines analysis from different users in so-called analysis trains which are then executed within the same Grid jobs thereby reducing the number of times the data needs to be read from the storage systems. The centralized trains improve the performance, the usability for users and the bookkeeping in comparison to single user analysis. The train system builds upon the already existing ALICE tools, i.e. the analysis framework as well as the Grid submission and monitoring infrastructure. The entry point to the train system is a web interface which is used to configure the analysis and the desired datasets as well as to test and submit the train. Several measures have been implemented to reduce the time a train needs to finish and to increase the CPU efficiency.", "subjects": "High Energy Physics - Experiment (hep-ex)", "authors": "Markus Zimmermann, ALICE collaboration,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06343", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06343", "title": "\nEquistarable bipartite graphs", "abstract": "Recently, Milani v and Trotignon introduced the class of equistarable graphs as graphs without isolated vertices admitting positive weights on the edges such that a subset of edges is of total weight if and only if it forms a maximal star. Based on equistarable graphs, counterexamples to three conjectures on equistable graphs were constructed, in particular to Orlin's conjecture, which states that every equistable graph is a general partition graph. In this paper we characterize equistarable bipartite graphs. We show that a bipartite graph is equistarable if and only if every -matching of the graph extends to a matching covering all vertices of degree at least . As a consequence of this result, we obtain that Orlin's conjecture holds within the class of complements of line graphs of bipartite graphs. We also connect equistarable graphs to the triangle condition, a combinatorial condition known to be necessary (but in general not sufficient) for equistability. We show that the triangle condition implies general partitionability for complements of line graphs of forests, and construct an infinite family of triangle non-equistable graphs within the class of complements of line graphs of bipartite graphs.", "subjects": "Combinatorics (math.CO)", "authors": "Endre Boros, Nina Chiarelli, Martin Milani\u010d,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06309", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06309", "title": "\nLearning with Differential Privacy: Stability, Learnability and the  Sufficiency and Necessity of ERM Principle", "abstract": "While machine learning has proven to be a powerful data-driven solution to many real-life problems, its use in sensitive domains that involve human subjects has been limited due to privacy concerns. The cryptographic approach known as \"differential privacy\" offers provable privacy guarantees. In this paper we study the learnability under Vapnik's general learning setting with differential privacy constraint, and reveal some intricate relationships between privacy, stability and learnability. In particular, we show that a problem is privately learnable emph there is a private algorithm that asymptotically minimizes the empirical risk (AERM). This is rather surprising because for non-private learning, AERM alone is not sufficient for learnability. This result suggests that when searching for private learning algorithms, we can restrict the search to algorithms that are AERM. In light of this, we propose a conceptual procedure that always finds a universally consistent algorithm whenever the problem is learnable under privacy constraint. We also propose a generic and practical algorithm and show that under very general conditions it privately learns a wide class of learning problems.", "subjects": "Machine Learning (stat.ML)", "authors": "Yu-Xiang Wang, Jing Lei, Stephen E. Fienberg,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06287", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06287", "title": "\nAsymptotically Exact Error Analysis for the Generalized $\\ell_2^2$-LASSO", "abstract": "Given an unknown signal and linear noisy measurements , the generalized -LASSO solves . Here, is a convex regularization function (e.g. -norm, nuclear-norm) aiming to promote the structure of (e.g. sparse, low-rank), and, is the regularizer parameter. A related optimization problem, though not as popular or well-known, is often referred to as the generalized -LASSO and takes the form , and has been analyzed in [1]. [1] further made conjectures about the performance of the generalized -LASSO. This paper establishes these conjectures rigorously. We measure performance with the normalized squared error . Assuming the entries of and be i.i.d. standard normal, we precisely characterize the \"asymptotic NSE\" when the problem dimensions tend to infinity in a proportional manner. The role of and is explicitly captured in the derived expression via means of a single geometric quantity, the Gaussian distance to the subdifferential. We conjecture that . We include detailed discussions on the interpretation of our result, make connections to relevant literature and perform computational experiments that validate our theoretical findings.", "subjects": "Statistics Theory (math.ST)", "authors": "Christos Thrampoulidis, Ashkan Panahi, Babak Hassibi,", "date": "2015-2-22"}, 
{"urllink": "http://arxiv.org/abs/1502.06277", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06277", "title": "\nA cut-invariant law of large numbers for random heaps", "abstract": "Heap monoids equipped with Bernoulli measures are a model of probabilistic asynchronous systems. We introduce in this framework the notion of asynchronous stopping time, which is analogous to the notion of stopping time for classical probabilistic processes. A Strong Bernoulli property is proved. A notion of cut-invariance is formulated for convergent ergodic means. Then a version of the Strong law of large numbers is proved for heap monoids with Bernoulli measures. Finally, we study a sub-additive version of the Law of large numbers in this framework based on Kingman sub-additive Ergodic Theorem.", "subjects": "Combinatorics (math.CO)", "authors": "Samy Abbes,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.06256", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06256", "title": "\nSpaced seeds improve metagenomic classification", "abstract": "Metagenomics is a powerful approach to study genetic content of environmental samples that has been strongly promoted by NGS technologies. To cope with massive data involved in modern metagenomic projects, recent tools [4, 39] rely on the analysis of k-mers shared between the read to be classified and sampled reference genomes. Within this general framework, we show in this work that spaced seeds provide a significant improvement of classification capacity as opposed to traditional contiguous k-mers. We support this thesis through a series a different computational experiments, including simulations of large-scale metagenomic projects.", "subjects": "Genomics (q-bio.GN)", "authors": "Karel Brinda, Maciej Sykulski, Gregory Kucherov,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.06236", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06236", "title": "\nSome enumerations of binary digital images", "abstract": "The topology of digital images has been studied much in recent years, but no attempt has been made to exhaustively catalog the structure of binary images of small numbers of points. We produce enumerations of several classes of digital images up to isomorphism and decide which among them are homotopy equivalent to one another. Noting some patterns in the results, we make some conjectures about digital images which are irreducible but not rigid.", "subjects": "Combinatorics (math.CO)", "authors": "P. Christopher Staecker,", "date": "2015-2-22"}, 
{"urllink": "http://arxiv.org/abs/1502.06231", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06231", "title": "\nLarge epidemic thresholds emerge in heterogeneous networks of  heterogeneous nodes", "abstract": "One of the famous results of network science states that networks with heterogeneous connectivity are more susceptible to epidemic spreading than their more homogeneous counterparts. In particular, in networks of identical nodes it has been shown that heterogeneity can lower the epidemic threshold at which epidemics can invade the system. Network heterogeneity can thus allow diseases with lower transmission probabilities to persist and spread. Here, we point out that for real world applications, this result should not be regarded independently of the intra-individual heterogeneity between people. Our results show that, if heterogeneity among people is taken into account, networks that are more heterogeneous in connectivity can be more resistant to epidemic spreading. We study a susceptible-infected-susceptible model with adaptive disease avoidance. Results from this model suggest that this reversal of the effect of network heterogeneity is likely to occur in populations in which the individuals are aware of their subjective disease risk. For epidemiology, this implies that network heterogeneity should not be studied in isolation.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Hui Yang, Ming Tang, Thilo Gross,", "date": "2015-2-22"}, 
{"urllink": "http://arxiv.org/abs/1502.06222", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06222", "title": "\nTropical optimization problems in project scheduling", "abstract": "We consider a project that consists of activities operating in parallel under various temporal constraints, including start-start, start-finish and finish-start precedence relations, early start, late start and late finish time boundaries, and due dates. Scheduling problems are formulated to find optimal schedules for the project under different optimality criteria to minimize, including the project makespan, the maximum deviation from the due dates, the maximum flow-time, and the maximum deviation of finish times. We represent the problems as optimization problems in terms of tropical mathematics, and then solve these problems by applying direct solution methods of tropical optimization. As a result, new direct solutions of the problems are obtained in a compact vector form, which is ready for further analysis and practical implementation.", "subjects": "Optimization and Control (math.OC)", "authors": "Nikolai Krivulin,", "date": "2015-2-22"}, 
{"urllink": "http://arxiv.org/abs/1502.06197", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06197", "title": "\nOn Online Control of False Discovery Rate", "abstract": "Multiple hypotheses testing is a core problem in statistical inference and arises in almost every scientific field. Given a sequence of null hypotheses , Benjamini and Hochberg cite introduced the false discovery rate (FDR) criterion, which is the expected proportion of false positives among rejected null hypotheses, and proposed a testing procedure that controls FDR below a pre-assigned significance level. They also proposed a different criterion, called mFDR, which does not control a property of the realized set of tests; rather it controls the ratio of expected number of false discoveries to the expected number of discoveries. In this paper, we propose two procedures for multiple hypotheses testing that we will call \"LOND\" and \"LORD\". These procedures control FDR and mFDR in an emph. Concretely, we consider an ordered --possibly infinite-- sequence of null hypotheses where, at each step , the statistician must decide whether to reject hypothesis having access only to the previous decisions. To the best of our knowledge, our work is the first that controls FDR in this setting. This model was introduced by Foster and Stine cite whose alpha-investing rule only controls mFDR in online manner. In order to compare different procedures, we develop lower bounds on the total discovery rate under the mixture model and prove that both LOND and LORD have nearly linear number of discoveries. We further propose adjustment to LOND to address arbitrary correlation among the -values. Finally, we evaluate the performance of our procedures on both synthetic and real data comparing them with alpha-investing rule, Benjamin-Hochberg method and a Bonferroni procedure.", "subjects": "Methodology (stat.ME)", "authors": "Adel Javanmard, Andrea Montanari,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.06189", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06189", "title": "\nTwo-stage Sampling, Prediction and Adaptive Regression via Correlation  Screening (SPARCS)", "abstract": "This paper proposes a general adaptive procedure for budget-limited predictor design in high dimensions called two-stage Sampling, Prediction and Adaptive Regression via Correlation Screening (SPARCS). SPARCS can be applied to high dimensional prediction problems in experimental science, medicine, finance, and engineering, as illustrated by the following. Suppose one wishes to run a sequence of experiments to learn a sparse multivariate predictor of a dependent variable (disease prognosis for instance) based on a dimensional set of independent variables (assayed biomarkers). Assume that the cost of acquiring the full set of variables increases linearly in its dimension. SPARCS breaks the data collection into two stages in order to achieve an optimal tradeoff between sampling cost and predictor performance. In the first stage we collect a few () expensive samples , at the full dimension of , winnowing the number of variables down to a smaller dimension using a type of cross-correlation or regression coefficient screening. In the second stage we collect a larger number of cheaper samples of the variables that passed the screening of the first stage. At the second stage, a low dimensional predictor is constructed by solving the standard regression problem using all samples of the selected variables. SPARCS is an adaptive online algorithm that implements false positive control on the selected variables, is well suited to small sample sizes, and is scalable to high dimensions. We establish asymptotic bounds for the Familywise Error Rate (FWER), specify high dimensional convergence rates for support recovery, and establish optimal sample allocation rules to the first and second stages.", "subjects": "Machine Learning (stat.ML)", "authors": "Hamed Firouzi, Bala Rajaratnam, Alfred Hero,", "date": "2015-2-22"}, 
{"urllink": "http://arxiv.org/abs/1502.06144", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06144", "title": "\nDetection of Planted Solutions for Flat Satisfiability Problems", "abstract": "We study the detection problem of finding planted solutions in random instances of flat satisfiability problems, a generalization of boolean satisfiability formulas. We describe the properties of random instances of flat satisfiability, as well of the optimal rates of detection of the associated hypothesis testing problem. We also study the performance of an algorithmically efficient testing procedure. We introduce a modification of our model, the light planting of solutions, and show that it is as hard as the problem of learning parity with noise. This hints strongly at the difficulty of detecting planted flat satisfiability for a wide class of tests.", "subjects": "Statistics Theory (math.ST)", "authors": "Quentin Berthet, Jordan S. Ellenberg,", "date": "2015-2-21"}, 
{"urllink": "http://arxiv.org/abs/1502.06134", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06134", "title": "\nLearning with Square Loss: Localization through Offset Rademacher  Complexity", "abstract": "We consider regression with square loss and general classes of functions without the boundedness assumption. We introduce a notion of offset Rademacher complexity that provides a transparent way to study localization both in expectation and in high probability. For any (possibly non-convex) class, the excess loss of a two-step estimator is shown to be upper bounded by this offset complexity through a novel geometric inequality. In the convex case, the estimator reduces to an empirical risk minimizer. The method recovers the results of citep for the bounded case while also providing guarantees without the boundedness assumption.", "subjects": "Machine Learning (stat.ML)", "authors": "Tengyuan Liang, Alexander Rakhlin, Karthik Sridharan,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.06064", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06064", "title": "\nMILJS : Brand New JavaScript Libraries for Matrix Calculation and  Machine Learning", "abstract": "MILJS is a collection of state-of-the-art, platform-independent, scalable, fast JavaScript libraries for matrix calculation and machine learning. Our core library offering a matrix calculation is called Sushi, which exhibits far better performance than any other leading machine learning libraries written in JavaScript. Especially, our matrix multiplication is 177 times faster than the fastest JavaScript benchmark. Based on Sushi, a machine learning library called Tempura is provided, which supports various algorithms widely used in machine learning research. We also provide Soba as a visualization library. The implementations of our libraries are clearly written, properly documented and thus can are easy to get started with, as long as there is a web browser. These libraries are available from this http URL under the MIT license.", "subjects": "Machine Learning (stat.ML)", "authors": "Ken Miura, Tetsuaki Mano, Atsushi Kanehira, Yuichiro Tsuchiya, Tatsuya Harada,", "date": "2015-2-21"}, 
{"urllink": "http://arxiv.org/abs/1502.06025", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06025", "title": "\nOntoLoki: an automatic, instance-based method for the evaluation of  biological ontologies on the Semantic Web", "abstract": "The delineation of logical definitions for each class in an ontology and the consistent application of these definitions to the assignment of instances to classes are important criteria for ontology evaluation. If ontologies are specified with property-based restrictions on class membership, then such consistency can be checked automatically. If no such logical restrictions are applied, as is the case with many biological ontologies, there are currently no automated methods for measuring the semantic consistency of instance assignment on an ontology-wide scale, nor for inferring the patterns of properties that might define a particular class. We constructed a program that takes as its input an OWL/RDF knowledge base containing an ontology, instances associated with each of the classes in the ontology, and properties of those instances. For each class, it outputs: 1) a rule for determining class membership based on the properties of the instances and 2) a quantitative score for the class that reflects the ability of the identified rule to correctly predict class membership for the instances in the knowledge base. We evaluated this program using both artificial knowledge bases of known quality and real, widely used ontologies. The results indicate that the suggested method can be used to conduct objective, automatic, data-driven evaluations of biological ontologies without formal class definitions in regards to the property-based consistency of instance-assignment. This inductive method complements existing, purely deductive approaches to automatic consistency checking, offering not just the potential to help in the ontology engineering process but also in the knowledge discovery process.", "subjects": "Quantitative Methods (q-bio.QM)", "authors": "Benjamin M. Good, Gavin Ha, Chi K. Ho, Mark D. Wilkinson,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.06021", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06021", "title": "\nA point on fixpoints in posets", "abstract": "Let be a , that is, a non-empty partially ordered set such that every non-empty chain has a least upper bound lub, a chain being a subset of totally ordered by . We are interested in sufficient conditions such that, given an element and a function , there is some ordinal such that , where is the transfinite sequence of iterates of starting from (implying that is a fixpoint of ): begin itemsep=0mm item item if is a limit ordinal, i.e. end This note summarizes known results about this problem and provides a slight generalization of some of them.", "subjects": "Logic (math.LO)", "authors": "Fr\u00e9d\u00e9ric Blanqui,", "date": "2014-12-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06013", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06013", "title": "\nNovel structures in Stanley sequences", "abstract": "Given a set of integers with no three in arithmetic progression, we construct a Stanley sequence by adding integers greedily so that no arithmetic progression is formed. This paper offers two main contributions to the theory of Stanley sequences. First, we characterize well-structured Stanley sequences as solutions to constraints in modular arithmetic, defining the modular Stanley sequences. Second, we introduce the basic Stanley sequences, where elements arise as the sums of subsets of a basis sequence, which in the simplest case is the powers of 3. Applications of our results include the construction of Stanley sequences with arbitrarily large gaps between terms, answering a weak version of a problem by Erd Hs et al. Finally, we generalize many results about Stanley sequences to -free sequences, where is any odd prime.", "subjects": "Combinatorics (math.CO)", "authors": "Richard A. Moy, David Rolnick,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.06004", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06004", "title": "\nThe Impact of Stealthy Attacks on Smart Grid Performance: Tradeoffs and  Implications", "abstract": "The smart grid is envisioned to significantly enhance the efficiency of energy consumption, by utilizing two-way communication channels between consumers and operators. For example, operators can opportunistically leverage the delay tolerance of energy demands in order to balance the energy load over time, and hence, reduce the total operational cost. This opportunity, however, comes with security threats, as the grid becomes more vulnerable to cyber-attacks. In this paper, we study the impact of such malicious cyber-attacks on the energy efficiency of the grid in a simplified setup. More precisely, we consider a simple model where the energy demands of the smart grid consumers are intercepted and altered by an active attacker before they arrive at the operator, who is equipped with limited intrusion detection capabilities. We formulate the resulting optimization problems faced by the operator and the attacker and propose several scheduling and attack strategies for both parties. Interestingly, our results show that, as opposed to facilitating cost reduction in the smart grid, increasing the delay tolerance of the energy demands potentially allows the attacker to force increased costs on the system. This highlights the need for carefully constructed and robust intrusion detection mechanisms at the operator.", "subjects": "Optimization and Control (math.OC)", "authors": "Yara Abdallah, Zizhan Zheng, Ness B. Shroff, Hesham El Gamal,", "date": "2014-12-9"}, 
{"urllink": "http://arxiv.org/abs/1502.05974", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05974", "title": "\nDevelopment of a VO Registry Subject Ontology using Automated Methods", "abstract": "We report on our initial work to automate the generation of a domain ontology using subject fields of resources held in the Virtual Observatory registry. Preliminary results are comparable to more generalized ontology learning software currently in use. We expect to be able to refine our solution to improve both the depth and breadth of the generated ontology.", "subjects": "Instrumentation and Methods for Astrophysics (astro-ph.IM)", "authors": "Brian Thomas,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05925", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05925", "title": "\nFeature-Budgeted Random Forest", "abstract": "We seek decision rules for prediction-time cost reduction, where complete data is available for training, but during prediction-time, each feature can only be acquired for an additional cost. We propose a novel random forest algorithm to minimize prediction error for a user-specified feature acquisition budget. While random forests yield strong generalization performance, they do not explicitly account for feature costs and furthermore require low correlation among trees, which amplifies costs. Our random forest grows trees with low acquisition cost and high strength based on greedy minimax cost-weighted-impurity splits. Theoretically, we establish near-optimal acquisition cost guarantees for our algorithm. Empirically, on a number of benchmark datasets we demonstrate superior accuracy-cost curves against state-of-the-art prediction-time algorithms.", "subjects": "Machine Learning (stat.ML)", "authors": "Feng Nan, Joseph Wang, Venkatesh Saligrama,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05760", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05760", "title": "\nBidirectional selection between two classes in complex social networks", "abstract": "The bidirectional selection between two classes widely emerges in various social lives, such as commercial trading and mate choosing. Until now, the discussions on bidirectional selection in structured human society are quite limited. We demonstrated theoretically that the rate of successfully matching is affected greatly by individuals neighborhoods in social networks, regardless of the type of networks. Furthermore, it is found that the high average degree of networks contributes to increasing rates of successful matches. The matching performance in different types of networks has been quantitatively investigated, revealing that the small-world networks reinforces the matching rate more than scale-free networks at given average degree. In addition, our analysis is consistent with the modeling result, which provides the theoretical understanding of underlying mechanisms of matching in complex networks.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Bin Zhou, Zhe He, Luo-Luo Jiang, Nian-Xin Wang, Bing-Hong Wang,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05680", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05680", "title": "\nFinding One Community in a Sparse Graph", "abstract": "We consider a random sparse graph with bounded average degree, in which a subset of vertices has higher connectivity than the background. In particular, the average degree inside this subset of vertices is larger than outside (but still bounded). Given a realization of such graph, we aim at identifying the hidden subset of vertices. This can be regarded as a model for the problem of finding a tightly knitted community in a social network, or a cluster in a relational dataset. In this paper we present two sets of contributions: We use the cavity method from spin glass theory to derive an exact phase diagram for the reconstruction problem. In particular, as the difference in edge probability increases, the problem undergoes two phase transitions, a static phase transition and a dynamic one. We establish rigorous bounds on the dynamic phase transition and prove that, above a certain threshold, a local algorithm (belief propagation) correctly identify most of the hidden set. Below the same threshold no local algorithm can achieve this goal. However, in this regime the subset can be identified by exhaustive search. For small hidden sets and large average degree, the phase transition for local algorithms takes an intriguingly simple form. Local algorithms succeed with high probability for and fail for (with , the average degrees inside and outside the community). We argue that spectral algorithms are also ineffective in the latter regime. It is an open problem whether any polynomial time algorithms might succeed for .", "subjects": "Machine Learning (stat.ML)", "authors": "Andrea Montanari,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05632", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05632", "title": "\nCapturing k-ary Existential Second Order Logic with k-ary  Inclusion-Exclusion Logic", "abstract": "In this paper we analyze k-ary inclusion-exclusion logic, INEX[k], which is obtained by extending first order logic with k-ary inclusion and exclusion atoms. We show that every formula of INEX[k] can be expressed with a formula of k-ary existential second order logic, ESO[k]. Conversely, every formula of ESO[k] with at most k-ary free relation variables can be expressed with a formula of INEX[k]. From this it follows that, on the level of sentences, INEX[k] captures the expressive power of ESO[k]. We also introduce several useful operators that can be expressed in INEX[k]. In particular, we define inclusion and exclusion quantifiers and so-called term value preserving disjunction. The latter one is needed in the proofs of the main results in this paper.", "subjects": "Logic (math.LO)", "authors": "Raine Ronnholm,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05618", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05618", "title": "\nPreferential Attachment Processes Approaching The Rado Multigraph", "abstract": "We consider a preferential attachment process in which the number of edges added at stage is given by some prescribed function , generalising a model considered by Kleinberg and Kleinberg ([8]). We show that if is asymptotically bounded above and below by linear functions in , then with probability the infinite limit of the process is isomorphic to the Rado multigraph. This structure is the natural multigraph analogue of the famous Rado graph, which we introduce here.", "subjects": "Combinatorics (math.CO)", "authors": "Richard Elwes,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05614", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05614", "title": "\nHow to Hunt an Invisible Rabbit on a Graph", "abstract": "We investigate Hunters &amp; Rabbit game, where a set of hunters tries to catch an invisible rabbit that slides along the edges of a graph. We show that the minimum number of hunters required to win on an (n times m)-grid is lfloor min/2 rfloor+1. We also show that the extremal value of this number on n-vertex trees is between Omega(log n/log log n) and O(log n).", "subjects": "Combinatorics (math.CO)", "authors": "Tatjana V. Abramovskaya, Fedor V. Fomin, Petr A. Golovach, Micha\u0142 Pilipczuk,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.05577", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05577", "title": "\nAdaptive system optimization using (simultaneous) random directions  stochastic approximation", "abstract": "We present the first adaptive random directions Newton algorithm under i.i.d., symmetric, uniformly distributed perturbations for a general problem of optimization under noisy observations. We also present a simple gradient search scheme under the aforementioned perturbation random variates. Our Newton algorithm requires generating perturbation variates and three simulations at each iteration unlike the well studied simultaneous perturbation Newton search algorithm of Spall (2000) that requires 2N iterates and four simulations. We prove the convergence of our algorithms to a local minimum and also present rate of convergence results. Our asymptotic mean square errors (AMSE) analysis indicates that our gradient algorithm requires 60% less number of simulations to achieve a given accuracy as compared to a similar algorithm in 60% less number of simulations to Kushner and Clark (1978); Chin (1997) that incorporates Gaussian perturbations. Moreover, our adaptive Newton search algorithm results in an AMSE that is on par and sometimes even better than the Newton algorithm of Spall (2000). Our experiments are seen to validate the theoretical observations. In particular, our experiments show that our Newton algorithm 2RDSA requires only 75 % of the total number of loss function measurements as required by the Newton algorithm of Spall (2000) while providing the same accuracy levels as the latter.", "subjects": "Optimization and Control (math.OC)", "authors": "Prashanth L.A., Shalabh Bhatnagar,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05556", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05556", "title": "\nRobust Active Ranking from Sparse Noisy Comparisons", "abstract": "From sporting events to sociological surveys, ranking from pairwise comparisons is a tool of choice for many applications. When certain pairs of items are difficult to compare, outcomes can be noisy, and it is necessary to develop robust strategies. In this work, we show how a simple active sampling scheme that uses a standard black box sorting algorithm enables the efficient recovery of the ranking, achieving low error with sparse samples. Both in theory and practice, this active strategy performs systematically better than selecting comparisons at random. As a detour, we show a link between Rank Centrality, a recently proposed algorithm for rank aggregation, and the ML estimator for the Bradley-Terry model. This enables us to develop a new, provably convergent iterative algorithm for computing the ML estimate.", "subjects": "Machine Learning (stat.ML)", "authors": "Lucas Maystre, Matthias Grossglauser,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05511", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05511", "title": "\nQuantum mixing of Markov chains for special distributions", "abstract": "The preparation of the stationary distribution of irreducible, time-reversible Markov chains is a fundamental building block in many heuristic approaches to algorithmically hard problems. It has been conjectured that quantum analogs of classical mixing processes may offer a generic quadratic speed-up in realizing such stationary distributions. Such a speed-up would also imply a speed-up of a broad family of heuristic algorithms. However, a true quadratic speed up has thus far only been demonstrated for special classes of Markov chains. These results often presuppose a regular structure of the underlying graph of the Markov chain, and also a regularity in the transition probabilities. In this work, we demonstrate a true quadratic speed-up for a class of Markov chains where the restriction is only on the form of the stationary distribution, rather than directly on the Markov chain structure itself. In particular, we show efficient mixing can be achieved when it is beforehand known that the distribution is monotonically decreasing relative to a known order on the state space. Following this, we show that our approach extends to a wider class of distributions, where only a fraction of the shape of the distribution is known to be monotonic. Our approach is built on the Szegedy-type quantization of transition operators.", "subjects": "Quantum Physics (quant-ph)", "authors": "Vedran Dunjko, Hans J. Briegel,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05451", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05451", "title": "\nVanishing ideals over rational parameterizations", "abstract": "Let be a field and let (resp. ) be a subset of a projective space (resp. affine space ), over the field , parameterized by rational functions. Let (resp. ) be the vanishing ideal of (resp. ). Some of the main contributions of this paper are in determining formulas for (resp. ) to compute their algebraic invariants using elimination theory and Gr \"obner bases. The formulas for vanishing ideals over finite fields that we give in this paper were discovered by making experiments with Macaulay, we are specially interested in this case because of its relation to algebraic coding theory. Then we use our results to study: the degree and structure of vanishing ideals, the projective closure of , and the basic parameters of affine and projective Reed-Muller-type codes. We recover some results for vanishing ideals over monomial parameterizations.", "subjects": "Commutative Algebra (math.AC)", "authors": "Azucena Tochimani, Rafael H. Villarreal,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05417", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05417", "title": "\nThe Evolution of Popular Music: USA 1960-2010", "abstract": "In modern societies, cultural change seems ceaseless. The flux of fashion is especially obvious for popular music. While much has been written about the origin and evolution of pop, most claims about its history are anecdotal rather than scientific in nature. To rectify this we investigate the US Billboard Hot 100 between 1960 and 2010. Using Music Information Retrieval (MIR) and text-mining tools we analyse the musical properties of ~17,000 recordings that appeared in the charts and demonstrate quantitative trends in their harmonic and timbral properties. We then use these properties to produce an audio-based classification of musical styles and study the evolution of musical diversity and disparity, testing, and rejecting, several classical theories of cultural change. Finally, we investigate whether pop musical evolution has been gradual or punctuated. We show that, although pop music has evolved continuously, it did so with particular rapidity during three stylistic \"revolutions\" around 1964, 1983 and 1991. We conclude by discussing how our study points the way to a quantitative science of cultural change.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Matthias Mauch, Robert M. MacCallum, Mark Levy, Armand M. Leroi,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.05394", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05394", "title": "\nTraffic-driven SIR epidemic model on networks", "abstract": "We propose a novel SIR epidemic model which is driven by the transmission of infection packets in networks. Specifically, infected nodes generate and deliver infection packets causing the spread of the epidemic, while recovered nodes block the delivery of infection packets, and this inhibits the epidemic spreading. The efficient routing protocol governed by a control parameter is used in the packet transmission. We obtain the maximum instantaneous population of infected nodes, the maximum population of ever infected nodes, as well as the corresponding optimal through simulation. We find that generally more balanced load distribution leads to more intense and wide spread of an epidemic in networks. Increasing either average node degree or homogeneity of degree distribution will facilitate epidemic spreading. When packet generation rate is small, increasing favors epidemic spreading. However, when is large enough, traffic congestion appears which inhibits epidemic spreading.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Cunlai Pu, Siyuan Li, Jian Yang,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05370", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05370", "title": "\nCollaborative Compressive Detection with Physical Layer Secrecy  Constraints", "abstract": "This paper considers the problem of detecting a high dimensional signal (not necessarily sparse) based on compressed measurements with physical layer secrecy guarantees. First, we propose a collaborative compressive detection (CCD) framework to compensate for the performance loss due to compression with a single sensor. We characterize the trade-off between dimensionality reduction achieved by a universal compressive sensing (CS) based measurement scheme and the achievable performance of CCD analytically. Next, we consider a scenario where the network operates in the presence of an eavesdropper who wants to discover the state of the nature being monitored by the system. To keep the data secret from the eavesdropper, we propose to use cooperating trustworthy nodes that assist the fusion center (FC) by injecting artificial noise to deceive the eavesdropper. We seek the answers to the questions: Does CS help improve the security performance in such a framework? What are the optimal values of parameters which maximize the CS based collaborative detection performance at the FC while ensuring perfect secrecy at the eavesdropper?", "subjects": "Applications (stat.AP)", "authors": "Bhavya Kailkhura, Thakshila Wimalajeewa, Pramod K. Varshney,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05366", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05366", "title": "\nRSVDPACK: Subroutines for computing partial singular value  decompositions via randomized sampling on single core, multi core, and GPU  architectures", "abstract": "This document describes an implementation in C of a set of randomized algorithms for computing partial Singular Value Decompositions (SVDs). The techniques largely follow the prescriptions in the article \"Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions,\" N. Halko, P.G. Martinsson, J. Tropp, SIAM Review, 53(2), 2011, pp. 217-288, but with some modifications to improve performance. The codes implement a number of low rank SVD computing routines for three different sets of hardware: (1) single core CPU, (2) multi core CPU, and (3) massively multicore GPU.", "subjects": "Numerical Analysis (math.NA)", "authors": "Sergey Voronin, Per-Gunnar Martinsson,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05326", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05326", "title": "\nSuperadditivity of private information for any number of uses of the  channel", "abstract": "The quantum capacity of a quantum channel is always smaller than the capacity of the channel for private communication. However, both quantities are given by the infinite regularization of respectively the coherent and the private information. Here, we construct a family of channels for which the private and coherent information can remain strictly superadditive for unbounded number of uses. We prove this by showing that the coherent information is strictly larger than the private information of a smaller number of uses of the channel. This implies that even though the quantum capacity is upper bounded by the private capacity, the non-regularized quantities can be interleaved. From an operational point of view, the private capacity can be used for gauging the practical value of quantum channels for secure communication and, consequently, for key distribution. We thus show that in order to evaluate the interest a channel for this task it is necessary to optimize the private information over an unlimited number of uses of the channel.", "subjects": "Quantum Physics (quant-ph)", "authors": "David Elkouss, Sergii Strelchuk,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05267", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05267", "title": "\nQuantum MDS Codes over Small Fields", "abstract": "We consider quantum MDS (QMDS) codes for quantum systems of dimension with lengths up to and minimum distances up to . We show how starting from QMDS codes of length based on cyclic and constacyclic codes, new QMDS codes can be obtained by shortening. We provide numerical evidence for our conjecture that almost all admissible lengths, from a lower bound on, are achievable by shortening. Some additional codes that fill gaps in the list of achievable lengths are presented as well along with a construction of a family of QMDS codes of length , where , that appears to be new.", "subjects": "Quantum Physics (quant-ph)", "authors": "Markus Grassl, Martin Roetteler,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05197", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05197", "title": "\nAnalysis and approximation of some Shape-from-Shading models for  non-Lambertian surfaces", "abstract": "The reconstruction of a 3D object or a scene is a classical inverse problem in Computer Vision. In the case of a single image this is called the Shape-from-Shading (SfS) problem and is known to be ill-posed even in a simplified version like the vertical light source case. A huge number of works deals with the orthographic SfS problem based on the Lambertian reflectance model, the most common and simplest model which leads to an eikonal type equation when the light source is on the vertical axis. In this paper we want to overcome this model dealing with non-Lambertian models, more realistic and suitable whenever one has to deal with different kind of surfaces, rough or specular. We will present a unique mathematical formulation for these models, considering oblique light directions. These models lead to more complex nonlinear partial differential equations of Hamilton-Jacobi type which we are able to describe in a unified framework. The construction of approximate (weak) solutions are obtained via semi-Lagrangian schemes for the corresponding stationary Hamilton-Jacobi equations. Numerical simulations on synthetic and real images will illustrate the effectiveness of this approach.", "subjects": "Numerical Analysis (math.NA)", "authors": "Silvia Tozza, Maurizio Falcone,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05041", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05041", "title": "\nAMAS: optimizing the partition and filtration of adaptive seeds to speed  up read mapping", "abstract": "Background: Identifying all possible mapping locations of next-generation sequencing (NGS) reads is highly essential in several applications such as prediction of genomic variants or protein binding motifs located in repeat regions, isoform expression quantification, metagenomics analysis, etc. However, this task is very time-consuming and majority of mapping tools only focus on one or a few best mapping locations. Results: We propose AMAS, an alignment tool specialized in identifying all possible mapping locations of NGS reads in a reference sequence. AMAS features an effective use of adaptive seeds to speed up read mapping while preserving sensitivity. Specifically, an index is designed to pre-store the locations of adaptive seeds in the reference sequence, efficiently reducing the time for seed matching and partitioning. An accurate filtration of adaptive seeds is further applied to substantially tighten the candidate alignment space. As a result, AMAS runs several times faster than other state-of-the-art read mappers while achieving similar accuracy. Conclusions: AMAS provides a valuable resource to speed up the important yet time-consuming task of identifying all mapping locations of NGS reads. AMAS is implemented in C++ based on the SeqAn library and is freely available at this https URL Keywords: next-generation sequencing, read mapping, sequence alignment, adaptive seeds, seed partition, filtration", "subjects": "Genomics (q-bio.GN)", "authors": "Ngoc Hieu Tran, Xin Chen,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05023", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05023", "title": "\nA New Sampling Technique for Tensors", "abstract": "In this paper we propose new techniques to sample arbitrary third-order tensors, with an objective of speeding up tensor algorithms that have recently gained popularity in machine learning. Our main contribution is a new way to select, in a biased random way, only of the possible elements while still achieving each of the three goals: : for a tensor that has to be formed from arbitrary samples, compute very few elements to get a good spectral approximation, and for arbitrary orthogonal tensors recover an exactly low-rank tensor from a small number of samples via alternating least squares, or approximating factors of a low-rank tensor corrupted by noise. Our sampling can be used along with existing tensor-based algorithms to speed them up, removing the computational bottleneck in these methods.", "subjects": "Machine Learning (stat.ML)", "authors": "Srinadh Bhojanapalli, Sujay Sanghavi,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.04873", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04873", "title": "\n$P$-persistent homology of finite topological spaces", "abstract": "Let be a finite poset. We will show that for any reasonable -persistent object in the category of finite topological spaces, there is a weighted graph, whose clique complex has the same -persistent homology as .", "subjects": "Algebraic Topology (math.AT)", "authors": "Francesco Vaccarino, Alice Patania, Giovanni Petri,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04837", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04837", "title": "\nNonparametric Nearest Neighbor Descent Clustering based on Delaunay  Triangulation", "abstract": "In our physically inspired in-tree (IT) based clustering algorithm and the series after it, there is only one free parameter involved in computing the potential value of each point. In this work, based on the Delaunay Triangulation or its dual Voronoi tessellation, we propose a nonparametric process to compute potential values by the local information. This computation, though nonparametric, is relatively very rough, and consequently, many local extreme points will be generated. However, unlike those gradient-based methods, our IT-based methods are generally insensitive to those local extremes. This positively demonstrates the superiority of these parametric (previous) and nonparametric (in this work) IT-based methods.", "subjects": "Machine Learning (stat.ML)", "authors": "Teng Qiu, Yongjie Li,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.04726", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04726", "title": "\nICR: Iterative Convex Refinement for Sparse Signal Recovery Using Spike  and Slab Priors", "abstract": "In this letter, we address sparse signal recovery using spike and slab priors. In particular, we focus on a Bayesian framework where sparsity is enforced on reconstruction coefficients via probabilistic priors. The optimization resulting from spike and slab prior maximization is known to be a hard non-convex problem, and existing solutions involve simplifying assumptions and/or relaxations. We propose an approach called Iterative Convex Refinement (ICR) that aims to solve the aforementioned optimization problem directly allowing for greater generality in the sparse structure. Essentially, ICR solves a sequence of convex optimization problems such that sequence of solutions converges to a sub-optimal solution of the original hard optimization problem. We propose two versions of our algorithm: a.) an unconstrained version, and b.) with a non-negativity constraint on sparse coefficients, which may be required in some real-world problems. Experimental validation is performed on both synthetic data and for a real-world image recovery problem, which illustrates merits of ICR over state of the art alternatives.", "subjects": "Machine Learning (stat.ML)", "authors": "Hojjat S. Mousavi, Vishal Monga, Trac D. Tran,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04700", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04700", "title": "\nClassical-Quantum Mixing in the Random 2-Satisfiability Problem", "abstract": "Classical satisfiability (SAT) and quantum satisfiability (QSAT) are complete problems for the complexity classes NP and QMA which are believed to be intractable for classical and quantum computers, respectively. Statistical ensembles of instances of these problems have been studied previously in an attempt to elucidate their typical, as opposed to worst case, behavior. In this paper we introduce a new statistical ensemble that interpolates between classical and quantum. For the simplest 2-SAT/2-QSAT ensemble we find the exact boundary that separates SAT and UNSAT instances. We do so by establishing coincident lower and upper bounds, in the limit of large instances, on the extent of the UNSAT and SAT regions, respectively.", "subjects": "Quantum Physics (quant-ph)", "authors": "Ionut-Dragos Potirniche, C. R. Laumann, S. L. Sondhi,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04697", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04697", "title": "\nFrom graphs to signals and back: Identification of network structures  using spectral analysis", "abstract": "Many systems comprising entities in interactions can be represented as graphs, whose structure gives significant insights about how these systems work. Network theory has undergone further developments, in particular in relation to detection of communities in graphs, to catch this structure. Recently, an approach has been proposed to transform a graph into a collection of signals: Using a multidimensional scaling technique on a distance matrix representing relations between vertices of the graph, points in a Euclidean space are obtained and interpreted as signals, indexed by the vertices. In this article, we propose several extensions to this approach, developing a framework to study graph structures using signal processing tools. We first extend the current methodology, enabling us to highlight connections between properties of signals and graph structures, such as communities, regularity or randomness, as well as combinations of those. A robust inverse transformation method is next described, taking into account possible changes in the signals compared to original ones. This technique uses, in addition to the relationships between the points in the Euclidean space, the energy of each signal, coding the different scales of the graph structure. These contributions open up new perspectives in the study of graphs, by enabling processing of graphs through the processing of the corresponding collection of signals, using reliable tools from signal processing. A technique of denoising of a graph by filtering of the corresponding signals is then described, suggesting considerable potential of the approach.", "subjects": "Data Analysis, Statistics and Probability (physics.data-an)", "authors": "Ronan Hamon, Pierre Borgnat, Patrick Flandrin, C\u00e9line Robardet,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.04670", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04670", "title": "\nThe Hartley Transform in a Finite Field", "abstract": "The k-trigonometric functions over the Galois Field GF(q) are introduced and their main properties derived. This leads to the definition of the cask(.) function over GF(q), which in turn leads to a finite field Hartley Transform. The main properties of this new discrete transform are presented and areas for possible applications are mentioned.", "subjects": "Number Theory (math.NT)", "authors": "R.M. Campello de Souza, H.M. de Oliveira, A.N. Kauffman,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04656", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04656", "title": "\nA small frame and a certificate of its injectivity", "abstract": "We present a complex frame of eleven vectors in 4-space and prove that it defines injective measurements. That is, any rank-one Hermitian matrix is uniquely determined by its values as a Hermitian form on this collection of eleven vectors. This disproves a recent conjecture of Bandeira, Cahill, Mixon, and Nelson. We use algebraic computations and certificates in order to prove injectivity.", "subjects": "Functional Analysis (math.FA)", "authors": "Cynthia Vinzant,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04643", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04643", "title": "\nBeamforming of the Residuals is the LASSO's Dual", "abstract": "Waves hidden in additive noise are observed by a sensor array. The waves are assumed to originate from a sparse set of sources. We treat the estimation of the sparse set of sources as a generalized complex-valued LASSO problem. The generalized complex-valued LASSO problem is strictly convex and strong duality holds. The corresponding dual problem is interpretable as a weighted conventional beamformer acting on the residuals of the LASSO. Moreover, this establishes a simple linear-affine relation between the dual and primal vectors. The solution path of the complex-valued LASSO is analyzed and three procedures for signal processing are proposed and evaluated which are based on the generalized LASSO and its dual: An order-recursive procedure and two iterative procedures which are based on a further approximation.", "subjects": "Statistics Theory (math.ST)", "authors": "Christoph F. Mecklenbr\u00e4uker, Peter Gerstoft, Erich Z\u00f6chmann,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04638", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04638", "title": "\nInformation Geometric Nonlinear Filtering", "abstract": "This paper develops information geometric representations for nonlinear filters in continuous time. The posterior distribution associated with an abstract nonlinear filtering problem is shown to satisfy a stochastic differential equation on a Hilbert information manifold. This supports the Fisher metric as a pseudo-Riemannian metric. Flows of Shannon information are shown to be connected with the quadratic variation of the process of posterior distributions in this metric. Apart from providing a suitable setting in which to study such information-theoretic properties, the Hilbert manifold has an appropriate topology from the point of view of multi-objective filter approximations. A general class of finite-dimensional exponential filters is shown to fit within this framework, and an intrinsic evolution equation, involving Amari's -covariant derivative, is developed for such filters. Three example systems, one of infinite dimension, are developed in detail.", "subjects": "Probability (math.PR)", "authors": "Nigel J. Newton,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04635", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04635", "title": "\nParameter estimation in softmax decision-making models with linear  objective functions", "abstract": "With an eye towards human-centered automation, this paper contributes to the development of a systematic means to infer features of human decision making from behavioral data. Because softmax selection figures centrally in human decision-making models, we study the maximum likelihood parameter estimation problem for softmax decision-making models with linear objective functions. We derive conditions under which the likelihood function is convex, which allows us to provide sufficient conditions for convergence of the resulting maximum likelihood estimator and construct its asymptotic distribution. To extend these results to models with nonlinear objective functions, we show how the estimator can be applied by linearizing about a nominal parameter value. We apply the estimator to fit the stochastic UCL (Upper Credible Limit) model to human subject data and show statistically significant differences in behavior across related, but distinct, tasks.", "subjects": "Optimization and Control (math.OC)", "authors": "Paul Reverdy, Naomi E. Leonard,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04622", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04622", "title": "\nParticle Gibbs for Bayesian Additive Regression Trees", "abstract": "Additive regression trees are flexible non-parametric models and popular off-the-shelf tools for real-world non-linear regression. In application domains, such as bioinformatics, where there is also demand for probabilistic predictions with measures of uncertainty, the Bayesian additive regression trees (BART) model, introduced by Chipman et al. (2010), is increasingly popular. As data sets have grown in size, however, the standard Metropolis-Hastings algorithms used to perform inference in BART are proving inadequate. In particular, these Markov chains make local changes to the trees and suffer from slow mixing when the data are high-dimensional or the best fitting trees are more than a few layers deep. We present a novel sampler for BART based on the Particle Gibbs (PG) algorithm (Andrieu et al., 2010) and a top-down particle filtering algorithm for Bayesian decision trees (Lakshminarayanan et al., 2013). Rather than making local changes to individual trees, the PG sampler proposes a complete tree to fit the residual. Experiments show that the PG sampler outperforms existing samplers in many settings.", "subjects": "Machine Learning (stat.ML)", "authors": "Balaji Lakshminarayanan, Daniel M. Roy, Yee Whye Teh,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04502", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04502", "title": "\nClustering by Descending to the Nearest Neighbor in the Delaunay Graph  Space", "abstract": "In our previous works, we proposed a physically-inspired rule to organize the data points into an in-tree (IT) structure, in which some undesired edges are allowed to occur. By removing those undesired or redundant edges, this IT structure is divided into several separate parts, each representing one cluster. In this work, we seek to prevent the undesired edges from arising at the source. Before using the physically-inspired rule, data points are at first organized into a proximity graph which restricts each point to select the optimal directed neighbor just among its neighbors. Consequently, separated in-trees or clusters automatically arise, without redundant edges requiring to be removed.", "subjects": "Machine Learning (stat.ML)", "authors": "Teng Qiu, Yongjie Li,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04434", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04434", "title": "\nInvariant backpropagation: how to train a transformation-invariant  neural network", "abstract": "In supervised learning, the nature of data often implies that the vast majority of transformations of the feature vectors, such as translation, scaling and rotation for images, do not change an object's class. At the same time, neural networks are known to be sensitive to such variations of input vectors. We propose an extension of the backpropagation algorithm that incorporates this information in the learning process, so that the neural network predictions are robust to variations and noise in the feature vector. This extension consists of an additional forward pass performed on the derivatives that are obtained in the end of the backward pass. We apply our algorithm to a collection of datasets for image classification, confirm its theoretically established properties and demonstrate an improvement of the classification accuracy with respect to the standard backpropagation algorithm in the majority of cases.", "subjects": "Machine Learning (stat.ML)", "authors": "Sergey Demyanov, James Bailey, Ramamohanarao Kotagiri, Christopher Leckie,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04433", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04433", "title": "\nA Classical Analog to Entanglement Reversibility", "abstract": "In this letter we introduce the problem of secrecy reversibility. This asks when two honest parties can distill secret bits from some tripartite distribution and transform secret bits back into at equal rates using local operation and public communication (LOPC). This is the classical analog to the well-studied problem of reversibly concentrating and diluting entanglement in a quantum state. We identify the structure of distributions possessing reversible secrecy when one of the honest parties holds a binary distribution, and it is possible that all reversible distributions have this form. These distributions are more general than what is obtained by simply constructing a classical analog to the family of quantum states known to have reversible entanglement. An indispensable tool used in our analysis is a conditional form of the G 'cs-K \"rner Common Information.", "subjects": "Quantum Physics (quant-ph)", "authors": "Eric Chitambar, Ben Fortescue, Min-Hsiu Hsieh,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04430", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04430", "title": "\nDistributions Attaining Secret Key at a Rate of the Conditional Mutual  Information", "abstract": "In this paper we consider the problem of extracting secret key from an eavesdropped source at a rate given by the conditional mutual information. We investigate this question under three different scenarios: (i) Alice () and Bob () are unable to communicate but share common randomness with the eavesdropper Eve (), (ii) Alice and Bob are allowed one-way public communication, and (iii) Alice and Bob are allowed two-way public communication. Distributions having a key rate of the conditional mutual information are precisely those in which a \"helping\" Eve offers Alice and Bob no greater advantage for obtaining secret key than a fully adversarial one. For each of the above scenarios, strong necessary conditions are derived on the structure of distributions attaining a secret key rate of . In obtaining our results, we completely solve the problem of secret key distillation under scenario (i) and identify to be the optimal key rate using shared randomness, where is the G 'acs-K \"orner Common Information. We thus provide an operational interpretation of the conditional G 'acs-K \"orner Common Information. Additionally, we introduce simple example distributions in which the rate is achievable if and only if two-way communication is allowed.", "subjects": "Quantum Physics (quant-ph)", "authors": "Eric Chitambar, Ben Fortescue, Min-Hsiu Hsieh,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04381", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04381", "title": "\nRandom Walks, Markov Processes and the Multiscale Modular Organization  of Complex Networks", "abstract": "Most methods proposed to uncover communities in complex networks rely on combinatorial graph properties. Usually an edge-counting quality function, such as modularity, is optimized over all partitions of the graph compared against a null random graph model. Here we introduce a systematic dynamical framework to design and analyze a wide variety of quality functions for community detection. The quality of a partition is measured by its Markov Stability, a time-parametrized function defined in terms of the statistical properties of a Markov process taking place on the graph. The Markov process provides a dynamical sweeping across all scales in the graph, and the time scale is an intrinsic parameter that uncovers communities at different resolutions. This dynamic-based community detection leads to a compound optimization, which favours communities of comparable centrality (as defined by the stationary distribution), and provides a unifying framework for spectral algorithms, as well as different heuristics for community detection, including versions of modularity and Potts model. Our dynamic framework creates a systematic link between different stochastic dynamics and their corresponding notions of optimal communities under distinct (node and edge) centralities. We show that the Markov Stability can be computed efficiently to find multi-scale community structure in large networks.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Renaud Lambiotte, Jean-Charles Delvenne, Mauricio Barahona,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04364", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04364", "title": "\nConsensus on the average in arbitrary directed network topologies with  time-delays", "abstract": "In this preliminary paper we study the stability property of a consensus on the average algorithm in arbitrary directed graphs with respect to communication/sensing time-delays. The proposed algorithm adds a storage variable to the agents' states so that the information about the average of the states is preserved despite the algorithm iterations are performed in an arbitrary strongly connected directed graph. We prove that for any network topology and choice of design parameters the consensus on the average algorithm is stable for sufficiently small delays. We provide simulations and numerical results to estimate the maximum delay allowed by an arbitrary unbalanced directed network topology.", "subjects": "Optimization and Control (math.OC)", "authors": "Mehran Zareh, Carla Seatzu, Mauro Franceschelli,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04301", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04301", "title": "\nThe Unimodular Intersection Problem", "abstract": "We show that finding minimally intersecting paths from to in a directed graph or perfect matchings in a bipartite graph can be done in polynomial time. This holds more generally for unimodular set systems.", "subjects": "Optimization and Control (math.OC)", "authors": "Volker Kaibel, Shmuel Onn, Pauline Sarrabezolles,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.04269", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04269", "title": "\nSupersparse Linear Integer Models for Optimized Medical Scoring Systems", "abstract": "Scoring systems are linear classification models that only require users to add, subtract and multiply a few small numbers in order to make a prediction. These models are in widespread use by the medical community, but are difficult to learn from data because they need to be accurate and sparse, have coprime integer coefficients, and accommodate operational constraints. We present a new method for creating data-driven scoring systems called Supersparse Linear Integer Models (SLIM). SLIM scoring systems are built by solving a discrete optimization problem that directly encodes measures of accuracy (the 0--1 loss) and sparsity (the -seminorm) while restricting coefficients to coprime integers. SLIM can seamlessly incorporate a wide range of operational constraints that are difficult for other methods to accommodate. We provide bounds on the testing and training accuracy of SLIM scoring systems, as well as a new data reduction technique that can improve scalability by discarding a portion of the training data. We present results from an ongoing collaboration with the Massachusetts General Hospital Sleep Apnea Laboratory, where SLIM is being used to construct a highly tailored scoring system for sleep apnea screening.", "subjects": "Machine Learning (stat.ML)", "authors": "Berk Ustun, Cynthia Rudin,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04262", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04262", "title": "\nInformation flow through a model of the C. elegans klinotaxis circuit", "abstract": "Understanding how information about external stimuli is transformed into behavior is one of the central goals of neuroscience. Here we characterize the information flow through a complete sensorimotor circuit: from stimulus, to sensory neurons, to interneurons, to motor neurons, to muscles, to motion. Specifically, we apply a recently developed framework for quantifying information flow to a previously published ensemble of models of salt klinotaxis in the nematode worm C. elegans. The models are grounded in the neuroanatomy and currently known neurophysiology of the worm. The unknown model parameters were optimized to reproduce the worm's behavior. Information flow analysis reveals several key principles underlying how the models operate: (1) Interneuron class AIY is responsible for integrating information about positive and negative changes in concentration, and exhibits a strong left/right information asymmetry. (2) Gap junctions play a crucial role in the transfer of information responsible for the information symmetry observed in interneuron class AIZ. (3) Neck motor neuron class SMB implements an information gating mechanism that underlies the circuit's state-dependent response. (4) The neck carries non-uniform distribution about changes in concentration. Thus, not all directions of movement are equally informative. Each of these findings corresponds to an experimental prediction that could be tested in the worm to greatly refine our understanding of the neural circuit underlying klinotaxis. Information flow analysis also allows us to explore how information flow relates to underlying electrophysiology. Despite large variations in the neural parameters of individual circuits, the overall information flow architecture circuit is remarkably consistent across the ensemble, suggesting that information flow analysis captures general principles of operation for the klinotaxis circuit.", "subjects": "Neurons and Cognition (q-bio.NC)", "authors": "Eduardo J. Izquierdo, Paul L. Williams, Randall D. Beer,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04189", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04189", "title": "\nOn the probability that all eigenvalues of Gaussian and Wishart random  matrices lie within an interval", "abstract": "We derive the probability that all eigenvalues of a random matrix lie within an arbitrary interval , when is a real or complex finite dimensional Wishart, double Wishart, or Gaussian symmetric/hermitian matrix. We give efficient recursive formulas allowing, for instance, the exact evaluation of for Wishart matrices with number of variates and degrees of freedom . We also prove that the probability that all eigenvalues are within the limiting spectral support (given by the Marchenko-Pastur or the semicircle laws) tends for large dimensions to the universal values and for the real and complex cases, respectively. Applications include improved bounds for the probability that a Gaussian measurement matrix has a given restricted isometry constant in compressed sensing.", "subjects": "Statistics Theory (math.ST)", "authors": "Marco Chiani,", "date": "2015-2-14"}, 
{"urllink": "http://arxiv.org/abs/1502.04184", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04184", "title": "\nPromotion and resignation in employee networks", "abstract": "Enterprises have put more and more emphasis on data analysis so as to obtain effective management advices. Managers and researchers are trying to dig out the major factors that lead to employees' promotion and resignation. Most previous analyses were based on questionnaire survey, which usually consists of a small fraction of samples and contains biases caused by psychological defense. In this paper, we successfully collect a data set consisting of all the employees' work-related interactions (action network, AN for short) and online social connections (social network, SN for short) of a company, which inspires us to reveal the correlations between structural features and employees' career development, namely promotion and resignation. Through statistical analysis and prediction, we show that the structural features of both AN and SN are correlated and predictive to employees' promotion and resignation, and the AN has higher correlation and predictability. More specifically, the in-degree in AN is the most relevant indicator for promotion; while the k-shell index in AN and in-degree in SN are both very predictive to resignation. Our results provide a novel and actionable understanding of enterprise management and suggest that to enhance the interplays among employees, no matter work-related or social interplays, can largely improve the loyalty of employees.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Jia Yuan, Qian-Ming Zhang, Jian Gao, Linyan Zhang, Xue-Song Wan, Xiao-Jun Yu, Tao Zhou,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.04081", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04081", "title": "\nA Linear Dynamical System Model for Text", "abstract": "Low dimensional representations of words allow accurate NLP models to be trained on limited annotated data. While most representations ignore words' local context, a natural way to induce context-dependent representations is to perform inference in a probabilistic latent-variable sequence model. Given the recent success of continuous vector space word representations, we provide such an inference procedure for continuous states, where words' representations are given by the posterior mean of a linear dynamical system. Here, efficient inference can be performed using Kalman filtering. Our learning algorithm is extremely scalable, operating on simple cooccurrence counts for both parameter initialization using the method of moments and subsequent iterations of EM. In our experiments, we employ our inferred word embeddings as features in standard tagging tasks, obtaining significant accuracy improvements. Finally, the Kalman filter updates can be seen as a linear recurrent neural network. We demonstrate that using the parameters of our model to initialize a non-linear recurrent neural network language model reduces its training time by a day and yields lower perplexity.", "subjects": "Machine Learning (stat.ML)", "authors": "David Belanger, Sham Kakade,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.03909", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03909", "title": "\nTowards real-world complexity: an introduction to multiplex networks", "abstract": "Many real-world complex systems are best modeled by multiplex networks of interacting network layers. The multiplex network study is one of the newest and hottest themes in the statistical physics of complex networks. Pioneering studies have proven that the multiplexity has broad impact on the system's structure and function. In this Colloquium paper, we present an organized review of the growing body of current literature on multiplex networks by categorizing existing studies broadly according to the type of layer coupling in the problem. Major recent advances in the ?field are surveyed and some outstanding open challenges and future perspectives will be proposed.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Kyu-Min Lee, Byungjoon Min, Kwang-Il Goh,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.03779", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03779", "title": "\nUnchecked strategy diversification and collapse in continuous voluntary  public good games", "abstract": "Cooperation or defection and participation or withdrawal are well-known options of behavior in game-like activities in free societies, yet the co-evolutionary dynamics of these behavioral traits in the individual level are not well understood. Here we investigate the continuous voluntary public good game, in which individuals have two types of continuous-valued options: a probability of joining the public good game and a level of cooperative investment in the game. Our numerical results reveal hitherto unreported phenomena: (i) The evolutionary dynamics are initially characterized by oscillations in individual cooperation and participation levels, in contrast to the population-level oscillations that have previously been reported. (ii) Eventually, the population's average cooperation and participation levels converge to and stabilize at a center. (iii) Then, a most peculiar phenomenon unfolds: The strategies present in the population diversify and give rise to a \"cloud\" of tinkering individuals who each tries out a different strategy, and this process continues unchecked as long as the population's cooperation and participation levels remain balanced. Over time, however, imbalances build up as a consequence of random drift and there is a sudden and abrupt collapse of the strategy-diversity cloud. The process then repeats again in a cyclic manner. To understand the three aforementioned phenomena, we investigate the system analytically using adaptive-dynamics techniques. Our analysis casts light on the mechanisms which underpin the unexpected and surprising evolutionary dynamics.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Tatsuya Sasaki, \u00c5ke Br\u00e4nnstr\u00f6m, Isamu Okada, Tatsuo Unemi,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03762", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03762", "title": "\nRationally inattentive control of Markov processes", "abstract": "The article poses a general model for optimal control subject to information constraints, motivated in part by recent work of Sims and others on information-constrained decision-making by economic agents. In the average-cost optimal control framework, the general model introduced in this paper reduces to a variant of the linear-programming representation of the average-cost optimal control problem, subject to an additional mutual information constraint on the randomized stationary policy. The resulting optimization problem is convex and admits a decomposition based on the Bellman error, which is the object of study in approximate dynamic programming. The theory is illustrated through the example of information-constrained linear-quadratic-Gaussian (LQG) control problem. Some results on the infinite-horizon discounted-cost criterion are also presented.", "subjects": "Optimization and Control (math.OC)", "authors": "Ehsan Shafieepoorfard, Maxim Raginsky, Sean P. Meyn,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03729", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03729", "title": "\nCoherent-Classical Estimation for Linear Quantum Systems", "abstract": "A coherent-classical estimation scheme for a class of linear quantum systems is considered. Here, the estimator is a mixed quantum-classical system that may or may not involve coherent feedback and yields a classical estimate of a variable for the quantum plant. We demonstrate that with no coherent feedback, such coherent-classical estimation provides no improvement over purely-classical estimation, when the quantum plant or the quantum part of the estimator (called the coherent controller) is a passive annihilation operator system. However, when both the quantum plant and the coherent controller are active systems (that cannot be described by annihilation operators only), coherent-classical estimation without coherent feedback can provide improvement over purely-classical estimation in certain cases. Furthermore, we show that with coherent feedback, it is possible to get better estimation accuracies with coherent-classical estimation, as compared to classical-only estimation.", "subjects": "Optimization and Control (math.OC)", "authors": "Shibdas Roy, Ian R. Petersen, Elanor H. Huntington,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03697", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03697", "title": "\nNonlinear state space smoothing using the conditional particle filter", "abstract": "To estimate the smoothing distribution in a nonlinear state space model, we apply the conditional particle filter with ancestor sampling. This gives an iterative algorithm in a Markov chain Monte Carlo fashion, with asymptotic convergence results. The computational complexity is analyzed, and our proposed algorithm is successfully applied to the challenging problem of sensor fusion between ultra-wideband and accelerometer/gyroscope measurements for indoor positioning. It appears to be a competitive alternative to existing nonlinear smoothing algorithms, in particular the forward filtering-backward simulation smoother.", "subjects": "Computation (stat.CO)", "authors": "Andreas Svensson, Thomas B. Sch\u00f6n, Manon kok,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03536", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03536", "title": "\nSpeeding up Permutation Testing in Neuroimaging", "abstract": "Multiple hypothesis testing is a significant problem in nearly all neuroimaging studies. In order to correct for this phenomena, we require a reliable estimate of the Family-Wise Error Rate (FWER). The well known Bonferroni correction method, while simple to implement, is quite conservative, and can substantially under-power a study because it ignores dependencies between test statistics. Permutation testing, on the other hand, is an exact, non-parametric method of estimating the FWER for a given -threshold, but for acceptably low thresholds the computational burden can be prohibitive. In this paper, we show that permutation testing in fact amounts to populating the columns of a very large matrix . By analyzing the spectrum of this matrix, under certain conditions, we see that has a low-rank plus a low-variance residual decomposition which makes it suitable for highly sub--sampled --- on the order of --- matrix completion methods. Based on this observation, we propose a novel permutation testing methodology which offers a large speedup, without sacrificing the fidelity of the estimated FWER. Our evaluations on four different neuroimaging datasets show that a computational speedup factor of roughly can be achieved while recovering the FWER distribution up to very high accuracy. Further, we show that the estimated -threshold is also recovered faithfully, and is stable.", "subjects": "Computation (stat.CO)", "authors": "Chris Hinrichs, Vamsi K Ithapu, Qinyuan Sun, Sterling C Johnson, Vikas Singh,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03492", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03492", "title": "\nGradient-based Hyperparameter Optimization through Reversible Learning", "abstract": "Tuning hyperparameters of learning algorithms is hard because gradients are usually unavailable. We compute exact gradients of cross-validation performance with respect to all hyperparameters by chaining derivatives backwards through the entire training procedure. These gradients allow us to optimize thousands of hyperparameters, including step-size and momentum schedules, weight initialization distributions, richly parameterized regularization schemes, and neural network architectures. We compute hyperparameter gradients by exactly reversing the dynamics of stochastic gradient descent with momentum.", "subjects": "Machine Learning (stat.ML)", "authors": "Dougal Maclaurin, David Duvenaud, Ryan P. Adams,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.03491", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03491", "title": "\nHow to show a probabilistic model is better", "abstract": "We present a simple theoretical framework, and corresponding practical procedures, for comparing probabilistic models on real data in a traditional machine learning setting. This framework is based on the theory of proper scoring rules, but requires only basic algebra and probability theory to understand and verify. The theoretical concepts presented are well-studied, primarily in the statistics literature. The goal of this paper is to advocate their wider adoption for performance evaluation in empirical machine learning.", "subjects": "Machine Learning (stat.ML)", "authors": "Mithun Chakraborty, Sanmay Das, Allen Lavoie,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03471", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03471", "title": "\nA scientometric study of General Relativity and Quantum Cosmology from  2000 to 2012", "abstract": "2015 is the centennial of Einstein General Relativity. On this occasion, we examine the General Relativity and Quantum Cosmology (GRQC) field of research by analysing 38291 papers uploaded on the electronic archives arXiv.org from 2000 to 2012. We establish a map of the countries contributing to GRQC in 2012. We determine the main journals publishing GRQC papers and which countries publish in which journals. We find that more and more papers are written by groups (instead of single) of authors with more and more international collaborations. There are huge differences between countries. Hence Russia is the country where most of papers are written by single authors whereas Canada is one of the countries where the most of papers are written with international collaborations. We also study mobility of researchers, determining how some groups of authors spread worldwide with time for different countries. The largest mobilities (as well as international collaborations) are between USA-UK and USA-Germany. Countries attracting the most of GRQC authors are Netherlands and Canada whereas those undergoing a brain drain are Italy and India. There are few mobility between Europe and Asia contrarily to mobility between USA and Asia.", "subjects": "History and Philosophy of Physics (physics.hist-ph)", "authors": "Stephane Fay, Sebastien Gautrias,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03439", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03439", "title": "\nWhat makes us a community: structure, correlations, and success in  scientific world", "abstract": "We explore the statistical structure of scientific community based on multivariate analysis of publication (or other identifiable metrics) distribution in the author space. Here, we define community based on keywords, i.e. projecting semantic content of the documents on predefined meanings; however, more complex approaches based on semantic clustering of publications are possible. Remarkably, this simple statistical analysis of publication metadata allows understanding of internal interactions with community in general agreement with experience acquired over decades of social interaction within it. We further discuss potential applications of this approach for ranking within the community, reviewer selection, and optimization of community output.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Sergei V. Kalinin, Artem Maksov,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03406", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03406", "title": "\nA survey of results on mobile phone datasets analysis", "abstract": "In this paper, we review some advances made recently in the study of mobile phone datasets. This area of research has emerged a decade ago, with the increasing availability of large-scale anonymized datasets, and has grown into a stand-alone topic. We will survey the contributions made so far on the social networks that can be constructed with such data, the study of personal mobility, geographical partitioning, urban planning, and help towards development as well as security and privacy issues.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Vincent D. Blondel, Adeline Decuyper, Gautier Krings,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03371", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03371", "title": "\nThe Z Transform over Finite Fields", "abstract": "Finite field transforms have many applications and, in many cases, can be implemented with a low computational complexity. In this paper, the Z Transform over a finite field is introduced and some of its properties are presented.", "subjects": "Number Theory (math.NT)", "authors": "R.M. Campello de Souza, H.M. de Oliveira, D. Silva,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03338", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03338", "title": "\nCoevolution of Information Processing and Topology in Hierarchical  Adaptive Random Boolean Networks", "abstract": "Random Boolean networks (RBNs) are frequently employed for modelling complex systems driven by information processing, e.g. for gene regulatory networks (GRNs). Here we propose a hierarchical adaptive RBN (HARBN) as a system consisting of distinct adaptive RBNs - subnetworks - connected by a set of permanent interlinks. Information measures and internal subnetworks topology of HARBN coevolve and reach steady-states that are specific for a given network structure. We investigate mean node information, mean edge information as well as a mean node degree as functions of model parameters and demonstrate HARBN's ability to describe complex hierarchical systems.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Piotr J. Gorski, Agnieszka Czaplicka, Janusz A. Holyst,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.03296", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03296", "title": "\nStatistical laws in linguistics", "abstract": "Zipf's law is just one out of many universal laws proposed to describe statistical regularities in language. Here we review and critically discuss how these laws can be statistically interpreted, fitted, and tested (falsified). The modern availability of large databases of written text allows for tests with an unprecedent statistical accuracy and also a characterization of the fluctuations around the typical behavior. We find that fluctuations are usually much larger than expected based on simplifying statistical assumptions (e.g., independence and lack of correlations between observations).These simplifications appear also in usual statistical tests so that the large fluctuations can be erroneously interpreted as a falsification of the law. Instead, here we argue that linguistic laws are only meaningful (falsifiable) if accompanied by a model for which the fluctuations can be computed (e.g., a generative model of the text). The large fluctuations we report show that the constraints imposed by linguistic laws on the creativity process of text generation are not as tight as one could expect.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Eduardo G. Altmann, Martin Gerlach,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03255", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03255", "title": "\nOff-policy evaluation for MDPs with unknown structure", "abstract": "Off-policy learning in dynamic decision problems is essential for providing strong evidence that a new policy is better than the one in use. But how can we prove superiority without testing the new policy? To answer this question, we introduce the G-SCOPE algorithm that evaluates a new policy based on data generated by the existing policy. Our algorithm is both computationally and sample efficient because it greedily learns to exploit factored structure in the dynamics of the environment. We present a finite sample analysis of our approach and show through experiments that the algorithm scales well on high-dimensional problems with few samples.", "subjects": "Machine Learning (stat.ML)", "authors": "Assaf Hallak, Fran\u00e7ois Schnitzler, Timothy Mann, Shie Mannor,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03224", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03224", "title": "\nEmergent user behavior on Twitter modelled by a stochastic differential  equation", "abstract": "Data from the social-media site, Twitter, is used to study the fluctuations in tweet rates of brand names. The tweet rates are the result of a strongly correlated user behavior, which leads to bursty collective dynamics with a characteristic 1/f noise. Here we use the aggregated \"user interest\" in a brand name to model collective human dynamics by a stochastic differential equation with multiplicative noise. The model is supported by a detailed analysis of the tweet rate fluctuations and it reproduces both the exact bursty dynamics found in the data and the 1/f noise.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Anders Mollgaard, Joachim Mathiesen,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03201", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03201", "title": "\nCombinatorial RNA Design: Designability and Structure-Approximating  Algorithm", "abstract": "In this work, we consider the Combinatorial RNA Design problem, a minimal instance of the RNA design problem which aims at finding a sequence that admits a given target as its unique base pair maximizing structure. We provide complete characterizations for the structures that can be designed using restricted alphabets. Under a classic four-letter alphabet, we provide a complete characterization of designable structures without unpaired bases. When unpaired bases are allowed, we provide partial characterizations for classes of designable/undesignable structures, and show that the class of designable structures is closed under the stutter operation. Membership of a given structure to any of the classes can be tested in linear time and, for positive instances, a solution can be found in linear time. Finally, we consider a structure-approximating version of the problem that allows to extend bands (helices) and, assuming that the input structure avoids two motifs, we provide a linear-time algorithm that produces a designable structure with at most twice more base pairs than the input structure.", "subjects": "Quantitative Methods (q-bio.QM)", "authors": "Jozef Hale\u0161, J\u00e1n Ma\u0148uch, Yann Ponty, Ladislav Stacho,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03175", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03175", "title": "\nProximal Algorithms in Statistics and Machine Learning", "abstract": "In this paper we develop proximal methods for statistical learning. Proximal point algorithms are useful in statistics and machine learning for obtaining optimization solutions for composite functions. Our approach exploits closed-form solutions of proximal operators and envelope representations based on the Moreau, Forward-Backward, Douglas-Rachford and Half-Quadratic envelopes. Envelope representations lead to novel proximal algorithms for statistical optimisation of composite objective functions which include both non-smooth and non-convex objectives. We illustrate our methodology with regularized Logistic and Poisson regression and non-convex bridge penalties with a fused lasso norm. We provide a discussion of convergence of non-descent algorithms with acceleration and for non-convex functions. Finally, we provide directions for future research.", "subjects": "Machine Learning (stat.ML)", "authors": "Nicholas G. Polson, James G. Scott, Brandon T. Willard,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.03169", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03169", "title": "\nReproducible Research Can Still Be Wrong: Adopting a Prevention Approach", "abstract": "Reproducibility, the ability to recompute results, and replicability, the chances other experimenters will achieve a consistent result, are two foundational characteristics of successful scientific research. Consistent findings from independent investigators are the primary means by which scientific evidence accumulates for or against an hypothesis. And yet, of late there has been a crisis of confidence among researchers worried about the rate at which studies are either reproducible or replicable. In order to maintain the integrity of science research and maintain the public's trust in science, the scientific community must ensure reproducibility and replicability by engaging in a more preventative approach that greatly expands data analysis education and routinely employs software tools.", "subjects": "Applications (stat.AP)", "authors": "Jeffrey T. Leek, Roger D. Peng,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03126", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03126", "title": "\nKernel Task-Driven Dictionary Learning for Hyperspectral Image  Classification", "abstract": "Dictionary learning algorithms have been successfully used in both reconstructive and discriminative tasks, where the input signal is represented by a linear combination of a few dictionary atoms. While these methods are usually developed under sparsity constrain (prior) in the input domain, recent studies have demonstrated the advantages of sparse representation using structured sparsity priors in the kernel domain. In this paper, we propose a supervised dictionary learning algorithm in the kernel domain for hyperspectral image classification. In the proposed formulation, the dictionary and classifier are obtained jointly for optimal classification performance. The supervised formulation is task-driven and provides learned features from the hyperspectral data that are well suited for the classification task. Moreover, the proposed algorithm uses a joint () sparsity prior to enforce collaboration among the neighboring pixels. The simulation results illustrate the efficiency of the proposed dictionary learning algorithm.", "subjects": "Machine Learning (stat.ML)", "authors": "Soheil Bahrampour, Nasser M. Nasrabadi, Asok Ray, Kenneth W. Jenkins,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.03103", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03103", "title": "\nOf Matters Condensed", "abstract": "The American Physical Society (APS) March Meeting of condensed matter physics has grown to nearly 10,000 participants, comprises 23 individual APS groups, and even warrants its own hashtag (#apsmarch). Here we analyze the text and data from March Meeting abstracts of the past nine years and discuss trends in condensed matter physics over this time period. We find that in comparison to atomic, molecular, and optical physics, condensed matter changes rapidly, and that condensed matter appears to be moving increasingly toward subject matter that is traditionally in materials science and engineering.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Michael Shulman, Marc Warner,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.03097", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03097", "title": "\nContextuality, Cohomology and Paradox", "abstract": "Contextuality is a key feature of quantum mechanics that provides an important non-classical resource for quantum information and computation. Abramsky and Brandenburger used sheaf theory to give a general treatment of contextuality in quantum theory [New Journal of Physics 13 (2011) 113036]. However, contextual phenomena are found in other fields as well, for example database theory. In this paper, we shall develop this unified view of contextuality. We provide two main contributions: firstly, we expose a remarkable connection between contexuality and logical paradoxes; secondly, we show that an important class of contextuality arguments has a topological origin. More specifically, we show that \"All-vs-Nothing\" proofs of contextuality are witnessed by cohomological obstructions.", "subjects": "Quantum Physics (quant-ph)", "authors": "Samson Abramsky, Rui Soares Barbosa, Kohei Kishida, Raymond Lal, Shane Mansfield,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.03057", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03057", "title": "\nCircuit Level Modeling of Extra Combinational Delays in SRAM FPGAs Due  to Transient Ionizing Radiation", "abstract": "This paper presents a novel circuit level model that explains and confirms the extra combinational delays in a SRAM-FPGA (Virtex-5) due to radiation, which matches the experimental results by proton irradiation at TRIUMF.", "subjects": "Space Physics (physics.space-ph)", "authors": "Mostafa Darvishi, Yves Audet, Yves Blaqui\u00e8re, Claude Thibeault,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.03049", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03049", "title": "\nSparse random graphs: regularization and concentration of the Laplacian", "abstract": "We study random graphs with possibly different edge probabilities in the challenging sparse regime of bounded expected degrees. Unlike in the dense case, neither the graph adjacency matrix nor its Laplacian concentrate around their expectations due to the highly irregular distribution of node degrees. It has been empirically observed that simply adding a constant of order to each entry of the adjacency matrix substantially improves the behavior of Laplacian. Here we prove that this regularization indeed forces Laplacian to concentrate even in sparse graphs. As an immediate consequence in network analysis, we establish the validity of one of the simplest and fastest approaches to community detection -- regularized spectral clustering, under the stochastic block model. Our proof of concentration of regularized Laplacian is based on Grothendieck's inequality and factorization, combined with paving arguments.", "subjects": "Statistics Theory (math.ST)", "authors": "Can M. Le, Elizaveta Levina, Roman Vershynin,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02987", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02987", "title": "\nOn zero-error communication via quantum channels in the presence of  noiseless feedback", "abstract": "We initiate the study of zero-error communication via quantum channels assisted by noiseless feedback link of unlimited quantum capacity, generalizing Shannon's zero-error communication theory with instantaneous feedback. This capacity depends only on the linear span of Kraus operators of the channel, which generalizes the bipartite equivocation graph of a classical channel, and which we dub \"non-commutative bipartite graph\". We go on to show that the feedback-assisted capacity is non-zero (allowing for a constant amount of activating noiseless communication) if and only if the non-commutative bipartite graph is non-trivial, and give a number of equivalent characterizations. This result involves a far-reaching extension of the \"conclusive exclusion\" of quantum states [Pusey/Barrett/Rudolph, Nat Phys 8:475, 2012]. We then present an upper bound on the feedback-assisted zero-error capacity, motivated by a conjecture originally made by Shannon and proved by Ahlswede. We demonstrate that this bound is additive and given by a nice minimax formula. We also prove a coding theorem showing that this quantity is the entanglement-assisted capacity against an adversarially chosen channel from the set of all channels with the same Kraus span, which can also be interpreted as the feedback-assisted unambiguous capacity. The proof relies on a generalization of the \"Postselection Lemma\" (de Finetti reduction) [Christandl/Koenig/Renner, PRL 102:020503, 2009] that allows to reflect additional constraints, and which we believe to be of independent interest. This capacity is a relaxation of the feedback-assisted zero-error capacity; however, we do not know whether they coincide in general. We illustrate our ideas with a number of examples, including classical-quantum channels and Weyl diagonal channels, and close with an extensive discussion of open questions.", "subjects": "Quantum Physics (quant-ph)", "authors": "Runyao Duan, Simone Severini, Andreas Winter,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02908", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02908", "title": "\nFast event-based epidemiological simulations on national scales", "abstract": "We present a computational modeling framework for data-driven simulations and analysis of infectious disease spread in large populations. For the purpose of efficient simulations, we devise a parallel solution algorithm targeting multi-socket shared memory architectures. The model integrates infectious dynamics as continuous-time Markov chains and available data such as animal movements or aging are incorporated as externally defined events. To bring out parallelism and accelerate the computations, we decompose the spatial domain and optimize cross-boundary communication using dependency-aware task scheduling. Using registered livestock data at a high spatio-temporal resolution, we demonstrate that our approach not only is resilient to varying model configurations, but also scales on all physical cores at realistic work loads. Finally, we show that these very features enable the solution of inverse problems on national scales.", "subjects": "Populations and Evolution (q-bio.PE)", "authors": "Pavol Bauer, Stefan Engblom, Stefan Widgren,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02899", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02899", "title": "\nCutting Stock with Binary Patterns: Arc-flow Formulation with Graph  Compression", "abstract": "The cutting stock problem with binary patterns (0-1 CSP) is a variant of CSP that usually appears as a relaxation of 2D and 3D packing problems. We present an exact method, based on an arc-flow formulation with side constraints, for solving 0-1 CSP by simply representing all the patterns in a very compact graph. Gilmore-Gomory's column generation approach is usually used to compute strong lower bounds for 0-1 CSP. We report a computational comparison between the arc-flow approach and the Gilmore-Gomory's approach.", "subjects": "Optimization and Control (math.OC)", "authors": "Filipe Brand\u00e3o, Jo\u00e3o Pedro Pedroso,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02887", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02887", "title": "\nStrict bounding of quantities of interest in computations based on  domain decomposition", "abstract": "This paper deals with bounding the error on the estimation of quantities of interest obtained by finite element and domain decomposition methods. The proposed bounds are written in order to separate the two errors involved in the resolution of reference and adjoint problems : on the one hand the discretization error due to the finite element method and on the other hand the algebraic error due to the use of the iterative solver. Beside practical considerations on the parallel computation of the bounds, it is shown that the interface conformity can be slightly relaxed so that local enrichment or refinement are possible in the subdomains bearing singularities or quantities of interest which simplifies the improvement of the estimation. Academic assessments are given on 2D static linear mechanic problems.", "subjects": "Computational Physics (physics.comp-ph)", "authors": "Valentine Rey, Pierre Gosselet, Christian Rey,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02871", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02871", "title": "\nTalk to the Hand: Generating a 3D Print from Photographs", "abstract": "This manuscript presents a linear algebra-based technique that only requires two unique photographs from a digital camera to mathematically construct a 3D surface representation which can then be 3D printed. Basic computer vision theory and manufacturing principles are also briefly discussed.", "subjects": "History and Overview (math.HO)", "authors": "Edward Aboufadel, Sylvanna V. Krawczyk, Melissa Sherman-Bennett,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02860", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02860", "title": "\nGaussian Processes for Data-Efficient Learning in Robotics and Control", "abstract": "Autonomous learning has been a promising direction in control and robotics for more than a decade since data-driven learning allows to reduce the amount of engineering knowledge, which is otherwise required. However, autonomous reinforcement learning (RL) approaches typically require many interactions with the system to learn controllers, which is a practical limitation in real systems, such as robots, where many interactions can be impractical and time consuming. To address this problem, current learning approaches typically require task-specific knowledge in form of expert demonstrations, realistic simulators, pre-shaped policies, or specific knowledge about the underlying dynamics. In this article, we follow a different approach and speed up learning by extracting more information from data. In particular, we learn a probabilistic, non-parametric Gaussian process transition model of the system. By explicitly incorporating model uncertainty into long-term planning and controller learning our approach reduces the effects of model errors, a key problem in model-based learning. Compared to state-of-the art RL our model-based policy search method achieves an unprecedented speed of learning. We demonstrate its applicability to autonomous learning in real robot and control tasks.", "subjects": "Machine Learning (stat.ML)", "authors": "Marc Peter Deisenroth, Dieter Fox, Carl Edward Rasmussen,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02821", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02821", "title": "\nBuilding a scalable global data processing pipeline for large  astronomical photometric datasets", "abstract": "Astronomical photometry is the science of measuring the flux of a celestial object. Since its introduction, the CCD has been the principle method of measuring flux to calculate the apparent magnitude of an object. Each CCD image taken must go through a process of cleaning and calibration prior to its use. As the number of research telescopes increases the overall computing resources required for image processing also increases. Existing processing techniques are primarily sequential in nature, requiring increasingly powerful servers, faster disks and faster networks to process data. Existing High Performance Computing solutions involving high capacity data centres are complex in design and expensive to maintain, while providing resources primarily to high profile science projects. This research describes three distributed pipeline architectures, a virtualised cloud based IRAF, the Astronomical Compute Node (ACN), a private cloud based pipeline, and NIMBUS, a globally distributed system. The ACN pipeline processed data at a rate of 4 Terabytes per day demonstrating data compression and upload to a central cloud storage service at a rate faster than data generation. The primary contribution of this research is NIMBUS, which is rapidly scalable, resilient to failure and capable of processing CCD image data at a rate of hundreds of Terabytes per day. This pipeline is implemented using a decentralised web queue to control the compression of data, uploading of data to distributed web servers, and creating web messages to identify the location of the data. Using distributed web queue messages, images are downloaded by computing resources distributed around the globe. Rigorous experimental evidence is presented verifying the horizontal scalability of the system which has demonstrated a processing rate of 192 Terabytes per day with clear indications that higher processing rates are possible.", "subjects": "Instrumentation and Methods for Astrophysics (astro-ph.IM)", "authors": "Paul Doyle,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02764", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02764", "title": "\nThe Modeling and Quantification of Rhythmic to Non-rhythmic Phenomenon  in Electrocardiography during Anesthesia", "abstract": "Variations of instantaneous heart rate appears regularly oscillatory in deeper levels of anesthesia and less regular in lighter levels of anesthesia. It is impossible to observe this \"rhythmic-to-non-rhythmic\" phenomenon from raw electrocardiography waveform in current standard anesthesia monitors. To explore the possible clinical value, I proposed the adaptive harmonic model, which fits the descriptive property in physiology, and provides adequate mathematical conditions for the quantification. Based on the adaptive harmonic model, multitaper Synchrosqueezing transform was used to provide time-varying power spectrum, which facilitates to compute the quantitative index: \"Non-rhythmic-to-Rhythmic Ratio\" index (NRR index). I then used a clinical database to analyze the behavior of NRR index and compare it with other standard indices of anesthetic depth. The positive statistical results suggest that NRR index provides addition clinical information regarding motor reaction, which aligns with current standard tools. Furthermore, the ability to indicates the noxious stimulation is an additional finding. Lastly, I have proposed an real-time interpolation scheme to contribute my study further as a clinical application.", "subjects": "Neurons and Cognition (q-bio.NC)", "authors": "Yu-Ting Lin,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02635", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02635", "title": "\nWeight-preserving isomorphisms between spaces of continuous functions:  The scalar case", "abstract": "Let be a finite field and let and be vector spaces of -valued continuous functions defined on locally compact spaces and , respectively. We look at the representation of linear bijections by continuous functions as weighted composition operators. In order to do it, we extend the notion of Hamming metric to infinite spaces. Our main result establishes that under some mild conditions, every Hamming isometry can be represented as a weighted composition operator. Connections to coding theory are also highlighted.", "subjects": "Functional Analysis (math.FA)", "authors": "Marita Ferrer, Margarita Gary, Salvador Hernandez,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02567", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02567", "title": "\nOpinion formation driven by PageRank node influence on directed networks", "abstract": "We study a two states opinion formation model driven by PageRank node influence and report an extensive numerical study on how PageRank affects collective opinion formations in large-scale empirical directed networks. In our model the opinion of a node can be updated by the sum of its neighbor nodes' opinions weighted by the node influence of the neighbor nodes at each step. We consider PageRank probability and its sublinear power as node influence measures and investigate evolution of opinion under various conditions. First, we observe that all networks reach steady state opinion after a certain relaxation time. This time scale is decreasing with the heterogeneity of node influence in the networks. Second, we find that our model shows consensus and non-consensus behavior in steady state depending on types of networks: Web graph, citation network of physics articles, and LiveJournal social network show non-consensus behavior while Wikipedia article network shows consensus behavior. Third, we find that a more heterogeneous influence distribution leads to a more uniform opinion state in the cases of Web graph, Wikipedia, and Livejournal. However, the opposite behavior is observed in the citation network. Finally we identify that a small number of influential nodes can impose their own opinion on significant fraction of other nodes in all considered networks. Our study shows that the effects of heterogeneity of node influence on opinion formation can be significant and suggests further investigations on the interplay between node influence and collective opinion in networks.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Young-Ho Eom, Dima L. Shepelyansky,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02563", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02563", "title": "\nDevice-Independent Verifiable Blind Quantum Computation", "abstract": "As progress on experimental quantum processors continues to advance, the problem of verifying the correct operation of such devices is becoming a pressing concern. Although recent progress has resulted in several protocols which can verify the output of a quantum computation performed by entangled but non-communicating processors, the overhead for such schemes is prohibitive, scaling at least as the 22nd power of the number of gates. We present a new approach based on a combination of verified blind quantum computation and Bell state self-testing. This approach has significantly reduced overhead, with resources scaling as a quartic polynomial in the number of gates.", "subjects": "Quantum Physics (quant-ph)", "authors": "Michal Hajdu\u0161ek, Carlos A. P\u00e9rez-Delgado, Joseph F. Fitzsimons,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02512", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02512", "title": "\nThe Adaptive Mean-Linkage Algorithm: A Bottom-Up Hierarchical Cluster  Technique", "abstract": "In this paper a variant of the classical hierarchical cluster analysis is reported. This agglomerative (bottom-up) cluster technique is referred to as the Adaptive Mean-Linkage Algorithm. It can be interpreted as a linkage algorithm where the value of the threshold is conveniently up-dated at each interaction. The superiority of the adaptive clustering with respect to the average-linkage algorithm follows because it achieves a good compromise on threshold values: Thresholds based on the cut-off distance are sufficiently small to assure the homogeneity and also large enough to guarantee at least a pair of merging sets. This approach is applied to a set of possible substituents in a chemical series.", "subjects": "Methodology (stat.ME)", "authors": "H.M. de Oliveira,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02330", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02330", "title": "\nTensor Canonical Correlation Analysis for Multi-view Dimension Reduction", "abstract": "Canonical correlation analysis (CCA) has proven an effective tool for two-view dimension reduction due to its profound theoretical foundation and success in practical applications. In respect of multi-view learning, however, it is limited by its capability of only handling data represented by two-view features, while in many real-world applications, the number of views is frequently many more. Although the ad hoc way of simultaneously exploring all possible pairs of features can numerically deal with multi-view data, it ignores the high order statistics (correlation information) which can only be discovered by simultaneously exploring all features. Therefore, in this work, we develop tensor CCA (TCCA) which straightforwardly yet naturally generalizes CCA to handle the data of an arbitrary number of views by analyzing the covariance tensor of the different views. TCCA aims to directly maximize the canonical correlation of multiple (more than two) views. Crucially, we prove that the multi-view canonical correlation maximization problem is equivalent to finding the best rank-1 approximation of the data covariance tensor, which can be solved efficiently using the well-known alternating least squares (ALS) algorithm. As a consequence, the high order correlation information contained in the different views is explored and thus a more reliable common subspace shared by all features can be obtained. In addition, a non-linear extension of TCCA is presented. Experiments on various challenge tasks, including large scale biometric structure prediction, internet advertisement classification and web image annotation, demonstrate the effectiveness of the proposed method.", "subjects": "Machine Learning (stat.ML)", "authors": "Yong Luo, Dacheng Tao, Yonggang Wen, Kotagiri Ramamohanarao, Chao Xu,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02310", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02310", "title": "\nOn Subword Complexity of Morphic Sequences", "abstract": "We study structure of pure morphic and morphic sequences and prove the following result: the subword complexity of arbitrary morphic sequence is either for some , or is .", "subjects": "Combinatorics (math.CO)", "authors": "Rostislav Devyatov,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1502.02281", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02281", "title": "\nA Lyapunov Analysis of FISTA with Local Linear Convergence for Sparse  Optimization", "abstract": "We conduct a Lyapunov analysis of the Fast Iterative Shrinkage and Thresholding Algorithm (FISTA) and show that the algorithm obtains local linear convergence for the special case of sparse (-regularized) optimization. We use an appropriate multi-step potential function to determine conditions on the parameters which imply weak convergence of the iterates to a minimizer in a real Hilbert space (strong convergence in ). Our results apply to a modified version of the momentum sequence proposed by Beck and Teboulle [1], for which convergence of the iterates is unknown. The Lyapunov analysis also allows us to show that FISTA achieves local linear convergence for sparse optimization problems. We generalize the analysis by Hale, Yin, and Zhang [2], of the Iterative Shrinkage and Thresholding Algorithm (ISTA) to FISTA. We prove finite convergence to the optimal manifold and determine the local linear convergence rate which holds thereafter. Our results show that the classical choice due to Beck and Teboulle and recent choice due to Chambolle and Dossal [3] for the momentum parameter are not optimal for sparse optimization in terms of the local convergence rate.", "subjects": "Optimization and Control (math.OC)", "authors": "Patrick R. Johnstone, Pierre Moulin,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1502.02259", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02259", "title": "\nContextual Markov Decision Processes", "abstract": "We consider a planning problem where the dynamics and rewards of the environment depend on a hidden static parameter referred to as the context. The objective is to learn a strategy that maximizes the accumulated reward across all contexts. The new model, called Contextual Markov Decision Process (CMDP), can model a customer's behavior when interacting with a website (the learner). The customer's behavior depends on gender, age, location, device, etc. Based on that behavior, the website objective is to determine customer characteristics, and to optimize the interaction between them. Our work focuses on one basic scenario--finite horizon with a small known number of possible contexts. We suggest a family of algorithms with provable guarantees that learn the underlying models and the latent contexts, and optimize the CMDPs. Bounds are obtained for specific naive implementations, and extensions of the framework are discussed, laying the ground for future research.", "subjects": "Machine Learning (stat.ML)", "authors": "Assaf Hallak, Dotan Di Castro, Shie Mannor,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1502.02251", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02251", "title": "\nFrom Pixels to Torques: Policy Learning with Deep Dynamical Models", "abstract": "Data-efficient learning in continuous state-action spaces using very high-dimensional observations remains a key challenge in developing fully autonomous systems. In this paper, we consider one instance of this challenge, the pixels-to-torques problem, where an agent must learn a closed-loop control policy from pixel information only. We introduce a data-efficient, model-based reinforcement learning algorithm that learns such a closed-loop policy directly from pixel information. The key ingredient is a deep dynamical model that uses deep auto-encoders to learn a low-dimensional embedding of images jointly with a prediction model in this low-dimensional feature space. This joint learning ensures that not only static properties of the data are accounted for, but also dynamic properties. This is crucial for long-term predictions, which lie at the core of the adaptive model predictive control strategy that we use for closed-loop control. Compared to state-of-the-art reinforcement learning methods, our approach learns quickly, scales to high-dimensional state spaces and facilitates fully autonomous learning from pixels to torques.", "subjects": "Machine Learning (stat.ML)", "authors": "Niklas Wahlstr\u00f6m, Thomas B. Sch\u00f6n, Marc Peter Deisenroth,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1502.02223", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02223", "title": "\nWill solid-state drives accelerate your bioinformatics? In-depth  profiling, performance analysis, and beyond", "abstract": "Motivation: A wide variety of large-scale data have been produced in bioinformatics. In response, the need for efficient handling of biomedical big data has been partly met by parallel computing. Nevertheless, the time demand of many bioinformatics programs still remains high for large-scale practical uses, due to factors that hinder acceleration by parallelization. Recently, new generations of storage devices are emerging, such as NAND flash solid-state drives (SSDs), and with the renewed interest in near-data processing, they are increasingly becoming acceleration methods that can accompany parallel processing. In certain cases, a simple drop-in replacement of HDDs by SSDs results in dramatic speedup. Despite the various advantages and continuous cost reduction of SSDs, there has been little research on SSD-based profiling and performance exploration of important but time-consuming bioinformatics programs. Results: We perform in-depth profiling and analysis of 23 key bioinformatics programs using multiple types of SSDs. Based on the insight obtained therefrom, we further discuss issues related to design and optimize bioinformatics algorithms and pipelines to fully exploit SSDs. The programs profiled cover traditional and emerging areas of importance, such as alignment, assembly, mapping, expression analysis, variant calling, and metagenomics. We demonstrate how acceleration by parallelization can be combined with SSDs for extra performance and also how using SSDs can expedite important bioinformatics pipelines such as variant calling by the Genome Analysis Toolkit (GATK) and transcriptome analysis using RNA-seq. We hope that this paper can provide useful directions and tips that should accompany future bioinformatics algorithm design procedures that properly consider new generations of powerful storage devices. Availability: this http URL", "subjects": "Genomics (q-bio.GN)", "authors": "Sungmin Lee, Byunghan Lee, Sei Joon Kim, Sunyoung Kwon, Sungroh Yoon,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1502.02174", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02174", "title": "\nOracles with Costs", "abstract": "While powerful tools have been developed to analyze quantum query complexity, there are still many natural problems that do not fit neatly into the black box model of oracles. We create a new model that allows multiple oracles with differing costs. This model captures more of the difficulty of certain natural problems. We test this model on a simple problem, Search with Two Oracles, for which we create a quantum algorithm that we prove is asymptotically optimal. We further give some evidence, using a geometric picture of Grover's algorithm, that our algorithm is exactly optimal.", "subjects": "Quantum Physics (quant-ph)", "authors": "Shelby Kimmel, Cedric Yen-Yu Lin, Han-Hsuan Lin,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02163", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02163", "title": "\nAnalysis of ground state in random bipartite matching", "abstract": "In human society, a lot of social phenomena can be concluded into a mathematical problem called the bipartite matching, one of the most well known model is the marriage problem proposed by Gale and Shapley. In this article, we try to find out some intrinsic properties of the ground state of this model and thus gain more insights and ideas about the matching problem. We apply Kuhn-Munkres Algorithm to find out the numerical ground state solution of the system. The simulation result proves the previous theoretical analysis using replica method. In the result, we also find out the amount of blocking pairs which can be regarded as a representative of the system stability. Furthermore, we discover that the connectivity in the bipartite matching problem has a great impact on the stability of the ground state, and the system will become more unstable if there were more connections between men and women.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Gui-Yuan Shi, Yi-Xiu Kong, Hao Liao, Yi-Cheng Zhang,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02112", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02112", "title": "\nMutual authenticated quantum no-key encryption scheme over private  quantum channel", "abstract": "We realize shamir's no-key protocol via quantum computation of Boolean permutation and private quantum channel. The quantum no-key (QNK) protocol presented here is one with mutual authentications, and proved to be unconditionally secure. An important property of this protocol is that0 its authentication key can be reused permanently.", "subjects": "Quantum Physics (quant-ph)", "authors": "Li Yang, Chenmiao Wu,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02098", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02098", "title": "\nPerformance of a quantum annealer on range-limited constraint  satisfaction problems", "abstract": "The performance of a D-Wave Vesuvius quantum annealer was recently compared to a suite of classical algorithms on a class of constraint satisfaction instances based on frustrated loops. However, the construction of these instances leads the maximum coupling strength to increase with problem size. As a result, larger instances are subject to amplified analog control error, and are effectively annealed at higher temperatures in both hardware and software. We generate similar constraint satisfaction instances with limited range of coupling strength and perform a similar comparison to classical algorithms. On these instances the D-Wave Vesuvius processor, run with a fixed 20s anneal time, shows a scaling advantage over the software solvers for the hardest regime studied. This scaling advantage opens the possibility of quantum speedup on these problems. Our results support the hypothesis that performance of D-Wave Vesuvius processors is heavily influenced by analog control error, which can be reduced and mitigated as the technology matures.", "subjects": "Quantum Physics (quant-ph)", "authors": "Andrew D. King,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02072", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02072", "title": "\nMassively Multitask Networks for Drug Discovery", "abstract": "Massively multitask neural architectures provide a learning framework for drug discovery that synthesizes information from many distinct biological sources. To train these architectures at scale, we gather large amounts of data from public sources to create a dataset of nearly 40 million measurements across more than 200 biological targets. We investigate several aspects of the multitask framework by performing a series of empirical studies and obtain some interesting results: (1) massively multitask networks obtain predictive accuracies significantly better than single-task methods, (2) the predictive power of multitask networks improves as additional tasks and data are added, (3) the total amount of data and the total number of tasks both contribute significantly to multitask improvement, and (4) multitask networks afford limited transferability to tasks not in the training set. Our results underscore the need for greater data sharing and further algorithmic innovation to accelerate the drug discovery process.", "subjects": "Machine Learning (stat.ML)", "authors": "Bharath Ramsundar, Steven Kearnes, Patrick Riley, Dale Webster, David Konerding, Vijay Pande,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.02057", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02057", "title": "\nPatterns in Illinois Educational School Data", "abstract": "We examine Illinois educational data from standardized exams and analyze primary factors affecting the achievement of public school students. We focus on the simplest possible models: representation of data through visualizations and regressions on single variables. Exam scores are shown to depend on school type, location, and poverty concentration. For most schools in Illinois, student test scores decline linearly with poverty concentration. However Chicago must be treated separately. Selective schools in Chicago, as well as some traditional and charter schools, deviate from this pattern based on poverty. For any poverty level, Chicago schools perform better than those in the rest of Illinois. Selective programs for gifted students show high performance at each grade level, most notably at the high school level, when compared to other Illinois school types. The case of Chicago charter schools is more complex. In the last six years, their students' scores overtook those of students in traditional Chicago high schools.", "subjects": "Physics Education (physics.ed-ph)", "authors": "Cacey S. Stevens, Michael P. Marder, Sidney R. Nagel,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1502.02056", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02056", "title": "\nEarly Birds, Night Owls,and Tireless/Recurring Itinerants: An  Exploratory Analysis of Extreme Transit Behaviors in Beijing, China", "abstract": "This paper seeks to understand extreme public transit riders in Beijing using both traditional household survey and emerging new data sources such as Smart Card Data (SCD). We focus on four types of extreme transit behaviors: public transit riders who (1) travel significantly earlier than average riders (the 'early birds'); (2) ride in unusual late hours (the 'night owls'); and (3) commute in excessively long distance (the 'tireless itinerants'); (4) travel over frequently in a day (the 'recurring itinerants). SCD are used to identify the spatiotemporal patterns of these three extreme transit behaviors. In addition, household survey data are employed to supplement the socioeconomic background and provide a tentative profiling of extreme travelers. While the research findings are useful to guide urban governance and planning in Beijing, the methods developed in this paper can be applied to understand travel patterns elsewhere.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Ying Long, Xingjian Liu, Jiangping Zhou, Yanwei Chai,", "date": "2015-1-24"}, 
{"urllink": "http://arxiv.org/abs/1502.02045", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02045", "title": "\nPartition into heapable sequences, heap tableaux and a multiset  extension of Hammersley's process", "abstract": "We investigate partitioning of integer sequences into heapable subsequences (previously defined and established by Mitzenmacher et al). We show that an extension of patience sorting computes the decomposition into a minimal number of heapable subsequences (MHS). We connect this parameter to an interactive particle system, a multiset extension of Hammersley's process, and investigate its expected value on a random permutation. In contrast with the (well studied) case of the longest increasing subsequence, we bring experimental evidence that the correct asymptotic scaling is . Finally we give a heap-based extension of Young tableaux, prove a hook inequality and an extension of the Robinson-Schensted correspondence.", "subjects": "Combinatorics (math.CO)", "authors": "Gabriel Istrate, Cosmin Bonchis,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.02030", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02030", "title": "\nQuantum Iterative Deepening with an application to the Halting problem", "abstract": "Classical models of computation traditionally resort to halting schemes in order to enquire about the state of a computation. In such schemes, a computational process is responsible for signalling an end of a calculation by setting a halt bit, which needs to be systematically checked by an observer. The capacity of quantum computational models to operate on a superposition of states requires an alternative approach. From a quantum perspective, any measurement of an equivalent halt qubit would have the potential to inherently interfere with the computation by provoking a random collapse amongst the states. This issue is exacerbated by undecidable problems such as the textit which require universal computational models, textit the classical Turing machine, to be able to proceed indefinitely. In this work we present an alternative view of quantum computation based on production system theory in conjunction with Grover's amplitude amplification scheme that allows for (1) a detection of halt states without interfering with the final result of a computation; (2) the possibility of non-terminating computation and (3) an inherent speedup to occur during computations susceptible of parallelization. We discuss how such a strategy can be employed in order to simulate classical Turing machines.", "subjects": "Quantum Physics (quant-ph)", "authors": "Lu\u00eds Tarrataca, Andreas Wichert,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.02009", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02009", "title": "\nA General Analysis of the Convergence of ADMM", "abstract": "We provide a new proof of the linear convergence of the alternating direction method of multipliers (ADMM) when one of the objective terms is strongly convex. Our proof is based on a framework for analyzing optimization algorithms introduced in Lessard et al. (2014), reducing algorithm convergence to verifying the stability of a dynamical system. This approach generalizes a number of existing results and obviates any assumptions about specific choices of algorithm parameters. On a numerical example, we demonstrate that minimizing the derived bound on the convergence rate provides a practical approach to selecting algorithm parameters for particular ADMM instances. We complement our upper bound by constructing a nearly-matching lower bound on the worst-case rate of convergence.", "subjects": "Optimization and Control (math.OC)", "authors": "Robert Nishihara, Laurent Lessard, Benjamin Recht, Andrew Packard, Michael I. Jordan,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01920", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01920", "title": "\nQuantization causes waves:Smooth finitely computable functions are  affine", "abstract": "Given an automaton (a letter-to-letter transducer, a dynamical 1-Lipschitz system on the space of -adic integers) whose input and output alphabets are , one visualizes word transformations performed by by a point set in real plane . For a finite-state automaton , it is shown that once some points of constitute a smooth (of a class ) curve in , the curve is a segment of a straight line with a rational slope; and there are only finitely many straight lines whose segments are in . Moreover, when identifying with a subset of a 2-dimensional torus (under a natural mapping of the real unit square onto ) the smooth curves from constitute a collection of torus windings. In cylindrical coordinates either of the windings can be ascribed to a complex-valued function for suitable rational . Since is a standard expression for a matter wave in quantum theory (where ), and since transducers can be regarded as a mathematical formalization for causal discrete systems, the paper might serve as a mathematical reasoning why wave phenomena are inherent in quantum systems: This is because of causality principle and the discreteness of matter.", "subjects": "Dynamical Systems (math.DS)", "authors": "Vladimir Anashin,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01866", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01866", "title": "\nAn Extension of the Dirichlet Density for Sets of Gaussian Integers", "abstract": "Several measures for the density of sets of integers have been proposed, such as the asymptotic density, the Schnirelmann density, and the Dirichlet density. There has been some work in the literature on extending some of these concepts of density to higher dimensional sets of integers. In this work, we propose an extension of the Dirichlet density for sets of Gaussian integers and investigate some of its properties.", "subjects": "Number Theory (math.NT)", "authors": "L. C. R\u00eago, R. J. Cintra,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01780", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01780", "title": "\nSequential Channel State Tracking & SpatioTemporal Channel Prediction in  Mobile Wireless Sensor Networks", "abstract": "We propose a nonlinear filtering framework for approaching the problems of channel state tracking and spatiotemporal channel gain prediction in mobile wireless sensor networks, in a Bayesian setting. We assume that the wireless channel constitutes an observable (by the sensors/network nodes), spatiotemporal, conditionally Gaussian stochastic process, which is statistically dependent on a set of hidden channel parameters, called the channel state. The channel state evolves in time according to a known, non stationary, nonlinear and/or non Gaussian Markov stochastic kernel. This formulation results in a partially observable system, with a temporally varying global state and spatiotemporally varying observations. Recognizing the intractability of general nonlinear state estimation, we advocate the use of grid based approximate filters as an effective and robust means for recursive tracking of the channel state. We also propose a sequential spatiotemporal predictor for tracking the channel gains at any point in time and space, providing real time sequential estimates for the respective channel gain map, for each sensor in the network. Additionally, we show that both estimators converge towards the true respective MMSE optimal estimators, in a common, relatively strong sense. Numerical simulations corroborate the practical effectiveness of the proposed approach.", "subjects": "Applications (stat.AP)", "authors": "Dionysios S. Kalogerias, Athina P. Petropulu,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01734", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01734", "title": "\nThe search for candidate relevant subsets of variables in complex  systems", "abstract": "In this paper we describe a method to identify \"relevant subsets\" of variables, useful to understand the organization of a dynamical system. The variables belonging to a relevant subset should have a strong integration with the other variables of the same relevant subset, and a much weaker interaction with the other system variables. On this basis, extending previous works on neural networks, an information-theoretic measure is introduced, i.e. the Dynamical Cluster Index, in order to identify good candidate relevant subsets. The method does not require any previous knowledge of the relationships among the system variables, but relies on observations of their values in time. We show its usefulness in several application domains, including: (i) random boolean networks, where the whole network is made of different subnetworks with different topological relationships (independent or interacting subnetworks); (ii) leader-follower dynamics, subject to noise and fluctuations; (iii) catalytic reaction networks in a flow reactor; (iv) the MAPK signaling pathway in eukaryotes. The validity of the method has been tested in cases where the data are generated by a known dynamical model and the Dynamical Cluster Index method is applied in order to uncover significant aspects of its organization; however it is important to stress that it can also be applied to time series coming from field data without any reference to a model. Given that it is based on relative frequencies of sets of values, the method could be applied also to cases where the data are not ordered in time. Several indications to improve the scope and effectiveness of the Dynamical Cluster Index to analyze the organization of complex systems are finally given.", "subjects": "Molecular Networks (q-bio.MN)", "authors": "Marco Villani, Andrea Roli, Alessandro Filisetti, Marco Fiorucci, Irene Poli, Roberto Serra,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1502.01730", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01730", "title": "\nA polynomial regularity lemma for semi-algebraic hypergraphs and its  applications in geometry and property testing", "abstract": "Fox, Gromov, Lafforgue, Naor, and Pach proved a regularity lemma for semi-algebraic -uniform hypergraphs of bounded complexity, showing that for each the vertex set can be equitably partitioned into a bounded number of parts (in terms of and the complexity) so that all but an -fraction of the -tuples of parts are homogeneous. We prove that the number of parts can be taken to be polynomial in . Our improved regularity lemma can be applied to geometric problems and to the following general question on property testing: is it possible to decide, with query complexity polynomial in the reciprocal of the approximation parameter, whether a hypergraph has a given hereditary property? We give an affirmative answer for testing typical hereditary properties for semi-algebraic hypergraphs of bounded complexity.", "subjects": "Combinatorics (math.CO)", "authors": "Jacob Fox, Janos Pach, Andrew Suk,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01664", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01664", "title": "\nEstimating Optimal Active Learning via Model Retraining Improvement", "abstract": "A central question for active learning (AL) is: \"what is the optimal selection?\" Defining optimality by classifier loss produces a new characterisation of optimal AL behaviour, by treating expected loss reduction as a statistical target for estimation. This target forms the basis of model retraining improvement (MRI), a novel approach providing a statistical estimation framework for AL. This framework is constructed to address the central question of AL optimality, and to motivate the design of estimation algorithms. MRI allows the exploration of optimal AL behaviour, and the examination of AL heuristics, showing precisely how they make sub-optimal selections. The abstract formulation of MRI is used to provide a new guarantee for AL, that an unbiased MRI estimator should outperform random selection. This MRI framework reveals intricate estimation issues that in turn motivate the construction of new statistical AL algorithms. One new algorithm in particular performs strongly in a large-scale experimental study, compared to standard AL methods. This competitive performance suggests that practical efforts to minimise estimation bias may be important for AL applications.", "subjects": "Machine Learning (stat.ML)", "authors": "Lewis P. G. Evans, Niall M. Adams, Christoforos Anagnostopoulos,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01646", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01646", "title": "\nHeavy context dependence --- decisions of underground soldiers", "abstract": "An attempt is made to simulate the disclosure of underground soldiers in terms of theory of networks. The coupling mechanism between the network nodes is the possibility that a disclosed soldier is going to disclose also his acquaintances. We calculate the fraction of disclosed soldiers as dependent on the fraction of those who, once disclosed, reveal also their colleagues. The simulation is immersed in the historical context of the Polish Home Army under the communist rule in 1946-49.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "K. Ku\u0142akowski, K. Malarz, M. J. Krawczyk,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01643", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01643", "title": "\nPerformance Analysis of Cone Detection Algorithms", "abstract": "Many algorithms have been proposed to help clinicians evaluate cone density and spacing, as these may be related to the onset of retinal diseases. However, there has been no rigorous comparison of the performance of these algorithms. In addition, the performance of such algorithms is typically determined by comparison with human observers. Here we propose a technique to simulate realistic images of the cone mosaic. We use the simulated images to test the performance of two popular cone detection algorithms and we introduce an algorithm which is used by astronomers to detect stars in astronomical images. We use Free Response Operating Characteristic (FROC) curves to evaluate and compare the performance of the three algorithms. This allows us to optimize the performance of each algorithm. We observe that performance is significantly enhanced by up-sampling the images. We investigate the effect of noise and image quality on cone mosaic parameters estimated using the different algorithms, finding that the estimated regularity is the most sensitive parameter. This paper was published in JOSA A and is made available as an electronic reprint with the permission of OSA. The paper can be found at the following URL on the OSA website: this http URL Systematic or multiple reproduction or distribution to multiple locations via electronic or other means is prohibited and is subject to penalties under law.", "subjects": "Medical Physics (physics.med-ph)", "authors": "Letizia Mariotti, Nicholas Devaney,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01601", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01601", "title": "\nA Simplified Self-Consistent Probabilities Framework to Characterize  Percolation Phenomena on Interdependent Networks : An Overview", "abstract": "Interdependent networks are ubiquitous in our society, ranging from infrastructure to economics, and the study of their cascading behaviors using percolation theory has attracted much attention in the recent years. To analyze the percolation phenomena of these systems, different mathematical frameworks have been proposed including generating functions, eigenvalues among some others. These different frameworks approach the phase transition behaviors from different angles, and have been very successful in shaping the different quantities of interest including critical threshold, size of the giant component, order of phase transition and the dynamics of cascading. These methods also vary in their mathematical complexity in dealing with interdependent networks that have additional complexity in terms of the correlation among different layers of networks or links. In this work, we review a particular approach of simple self-consistent probability equations, and illustrate that it can greatly simplify the mathematical analysis for systems ranging from single layer network to various different interdependent networks. We give an overview on the detailed framework to study the nature of the critical phase transition, value of the critical threshold and size of the giant component for these different systems.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Ling Feng, Christopher Pineda Monterola, Yanqing Hu,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01570", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01570", "title": "\nTaylor Series as Wide-sense Biorthogonal Wavelet Decomposition", "abstract": "Pointwise-supported generalized wavelets are introduced, based on Dirac, doublet and further derivatives of delta. A generalized biorthogonal analysis leads to standard Taylor series and new Dual-Taylor series that may be interpreted as Laurent Schwartz distributions. A Parseval-like identity is also derived for Taylor series, showing that Taylor series support an energy theorem. New representations for signals called derivagrams are introduced, which are similar to spectrograms. This approach corroborates the impact of wavelets in modern signal analysis.", "subjects": "Classical Analysis and ODEs (math.CA)", "authors": "H.M. de Oliveira, R.D. Lins,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01563", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01563", "title": "\nA PARTAN-Accelerated Frank-Wolfe Algorithm for Large-Scale SVM  Classification", "abstract": "Frank-Wolfe algorithms have recently regained the attention of the Machine Learning community. Their solid theoretical properties and sparsity guarantees make them a suitable choice for a wide range of problems in this field. In addition, several variants of the basic procedure exist that improve its theoretical properties and practical performance. In this paper, we investigate the application of some of these techniques to Machine Learning, focusing in particular on a Parallel Tangent (PARTAN) variant of the FW algorithm that has not been previously suggested or studied for this type of problems. We provide experiments both in a standard setting and using a stochastic speed-up technique, showing that the considered algorithms obtain promising results on several medium and large-scale benchmark datasets for SVM classification.", "subjects": "Machine Learning (stat.ML)", "authors": "Emanuele Frandi, Ricardo Nanculef, Johan A. K. Suykens,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01493", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01493", "title": "\nA mixture Cox-Logistic model for feature selection from survival and  classification data", "abstract": "This paper presents an original approach for jointly fitting survival times and classifying samples into subgroups. The Coxlogit model is a generalized linear model with a common set of selected features for both tasks. Survival times and class labels are here assumed to be conditioned by a common risk score which depends on those features. Learning is then naturally expressed as maximizing the joint probability of subgroup labels and the ordering of survival events, conditioned to a common weight vector. The model is estimated by minimizing a regularized log-likelihood through a coordinate descent algorithm. Validation on synthetic and breast cancer data shows that the proposed approach outperforms a standard Cox model or logistic regression when both predicting the survival times and classifying new samples into subgroups. It is also better at selecting informative features for both tasks.", "subjects": "Machine Learning (stat.ML)", "authors": "Samuel Branders, Roberto D'Ambrosio, Pierre Dupont,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01480", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01480", "title": "\nRing artifacts correction in compressed sensing tomographic  reconstruction", "abstract": "We present a novel approach to handle ring artifacts correction in compressed sensing tomographic reconstruction. The correction is part of the reconstruction process, which differs from classical sinogram pre-processing and image post-processing techniques. The principle of compressed sensing tomographic reconstruction is presented. Then, we show that the ring artifacts correction can be integrated in the reconstruction problem formalism. We provide numerical results for both simulated and real data. This technique is included in the PyHST2 code which is used at the European Synchrotron Radiation Facility for tomographic reconstruction.", "subjects": "Computational Physics (physics.comp-ph)", "authors": "Pierre Paleo, Alessandro Mirone,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01456", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01456", "title": "\nOnline Electric Vehicle Charging Control with Multistage Stochastic  Programming", "abstract": "With the increasing adoption of plug-in electric vehicles (PEVs), it is critical to develop efficient charging coordination mechanisms that minimize the cost and impact of PEV integration to the power grid. In this paper, we consider the optimal PEV charging scheduling problem in a practical scenario where the non-causal information about future PEV arrivals is not known in advance, but its statistical distribution can be estimated. This leads to an \"online\" charging scheduling problem that is formulated as a multistage stochastic programming (MSP) problem in this paper. Instead of solving the MSP using the standard approaches such as sample average approximation (SAA), we show that solving a deterministic counterpart of the stochastic problem yields significant complexity reduction with negligible performance loss. Compared with the SAA approach, the computational complexity of the proposed algorithm is drastically reduced from to per time stage, where is the total number of the time stages and is a constant related to the accuracy of the solution. More importantly, we show that the proposed algorithm can be made scalable when the random process describing the arrival of charging demands is first-order periodic. That is, the complexity of obtaining the charging schedule at each time stage is and is independent of . Extensive simulations show that the proposed online algorithm performs very closely to the optimal online algorithm. The performance gap is smaller than in most cases. As such, the proposed online algorithm is very appealing for practical implementation due to its scalable computational complexity and close to optimal performance.", "subjects": "Optimization and Control (math.OC)", "authors": "Wanrong Tang, Ying Jun Zhang,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01400", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01400", "title": "\nFast unsupervised Bayesian image segmentation with adaptive spatial  regularisation", "abstract": "This paper presents two new Bayesian estimation techniques for hidden Potts-Markov random fields, with application to fast K-class image segmentation. The techniques are derived by first conducting a small-variance-asymptotic (SVA) analysis of an augmented Bayesian model in which the spatial regularisation and the integer-constrained terms of the Potts model are decoupled. The evaluation of this SVA Bayesian estimator is then relaxed into a partially convex problem that can be computed efficiently by iteratively solving a total-variation denoising problem and a least-squares clustering (K-means) problem, both of which can be solved straightforwardly, even in high-dimensions, and with parallel computing techniques. This leads to a fast semi-supervised Bayesian image segmentation methodology that can be easily applied in large 2D and 3D scenarios or in applications requiring low computing times. Following on from this, we extend the proposed Bayesian model and inference technique to the case where the value of the spatial regularisation parameter is unknown and removed from the model by marginalisation. This leads to a new fully unsupervised fast Bayesian segmentation algorithm in which the strength of the spatial regularisation is adapted automatically to the observed image during the inference procedure. Experimental results on synthetic and real images, as well as extensive comparisons with state-of-the-art algorithms, confirm that the proposed semi-supervised and unsupervised methodologies offer extremely fast convergence and produce accurate segmentation results, with the important additional advantage of self-adjusting regularisation parameters.", "subjects": "Computation (stat.CO)", "authors": "Marcelo Pereyra, Steve McLaughlin,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01272", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01272", "title": "\nMonogamy, Polygamy and other Properties of Entanglement of Purification", "abstract": "For bipartite mixed states, in addition to the mutual information, there is another measure of total correlation, namely, the entanglement of purification. We study the monogamy, polygamy and additivity properties of the entanglement of purification for pure and mixed states. In contrast to the mutual information which is strictly monogamous for any tripartite pure states, the entanglement of purification can be polygamous for the same. This shows that there can be genuinely two types of total correlation across any bipartite cross in a pure tripartite state. Furthermore, we find the lower bound and actual values of the entanglement of purification for different classes of mixed states. Thereafter, we show that if entanglement of purification is not additive on tensor product states, it is actually sub-additive. Using these results we identify some states which are additive on tensor products for entanglement of purification. The implications of these findings on the quantum advantage of dense coding are briefly discussed, where we show that for tripartite pure states, it is strictly monogamous and and if it is non-additive, then it is super-additive on tensor product states.", "subjects": "Quantum Physics (quant-ph)", "authors": "Shrobona Bagchi, Arun Kumar Pati,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01265", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01265", "title": "\nOptimal transport over a linear dynamical system", "abstract": "We consider the problem of steering an initial probability density for the state vector of a linear system to a final one, in finite time, using minimum energy control. In the case where the dynamics correspond to an integrator () this amounts to a Monge-Kantorovich Optimal Mass Transport (OMT) problem. In general, we show that the problem can again be reduced to solving an OMT problem and that it has a unique solution. In parallel, we study the optimal steering of the state-density of a linear stochastic system with white noise disturbance; this is known to correspond to a Schr \"odinger bridge. As the white noise intensity tends to zero, the flow of densities converges to that of the deterministic dynamics and can serve as a way to compute the solution of its deterministic counterpart. The solution can be expressed in closed-form for Gaussian initial and final state densities in both cases.", "subjects": "Optimization and Control (math.OC)", "authors": "Yongxin Chen, Tryphon Georgiou, Michele Pavon,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01241", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01241", "title": "\nA specialized face-processing network consistent with the  representational geometry of monkey face patches", "abstract": "Ample evidence suggests that face processing in human and non-human primates is performed differently compared with other objects. Converging reports, both physiologically and psychophysically, indicate that faces are processed in specialized neural networks in the brain -i.e. face patches in monkeys and the fusiform face area (FFA) in humans. We are all expert face-processing agents, and able to identify very subtle differences within the category of faces, despite substantial visual and featural similarities. Identification is performed rapidly and accurately after viewing a whole face, while significantly drops if some of the face configurations (e.g. inversion, misalignment) are manipulated or if partial views of faces are shown due to occlusion. This refers to a hotly-debated, yet highly-supported concept, known as holistic face processing. We built a hierarchical computational model of face-processing based on evidence from recent neuronal and behavioural studies on faces processing in primates. Representational geometries of the last three layers of the model have characteristics similar to those observed in monkey face patches (posterior, middle and anterior patches). Furthermore, several face-processing-related phenomena reported in the literature automatically emerge as properties of this model. The representations are evolved through several computational layers, using biologically plausible learning rules. The model satisfies face inversion effect, composite face effect, other race effect, view and identity selectivity, and canonical face views. To our knowledge, no models have so far been proposed with this performance and agreement with biological data.", "subjects": "Neurons and Cognition (q-bio.NC)", "authors": "Amirhossein Farzmahdi, Karim Rajaei, Masoud Ghodrati, Reza Ebrahimpour, Seyed-Mahdi Khaligh-Razavi,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01139", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01139", "title": "\nGeneralized modularity matrices", "abstract": "Various modularity matrices appeared in the recent literature on network analysis and algebraic graph theory. Their purpose is to allow writing as quadratic forms certain combinatorial functions appearing in the framework of graph clustering problems. In this paper we put in evidence certain common traits of various modularity matrices and shed light on their spectral properties that are at the basis of various theoretical results and practical spectral-type algorithms for community detection.", "subjects": "Spectral Theory (math.SP)", "authors": "Dario Fasino, Francesco Tudisco,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01094", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01094", "title": "\nMultimodal Task-Driven Dictionary Learning for Image Classification", "abstract": "Dictionary learning algorithms have been successfully used for both reconstructive and discriminative tasks, where an input signal is represented with a sparse linear combination of dictionary atoms. While these methods are mostly developed for single-modality scenarios, recent studies have demonstrated the advantages of feature-level fusion based on the joint sparse representation of the multimodal inputs. In this paper, we propose a multimodal task-driven dictionary learning algorithm under the joint sparsity constraint (prior) to enforce collaborations among multiple homogeneous/heterogeneous sources of information. In this task-driven formulation, the multimodal dictionaries are learned simultaneously with their corresponding classifiers. The resulting multimodal dictionaries can generate discriminative latent features (sparse codes) from the data that are optimized for a given task such as binary or multiclass classification. Moreover, we present an extension of the proposed formulation using a mixed joint and independent sparsity prior which facilitates more flexible fusion of the modalities at feature level. The efficacy of the proposed algorithms for multimodal classification is illustrated on three different applications- multimodal face recognition, multi-view face recognition, and multimodal biometric recognition. It is also shown that, compared to the counterpart reconstructive-based dictionary learning algorithms, the task-driven formulations are more computationally efficient in the sense that they can be equipped with more compact dictionaries and still achieve superior performance.", "subjects": "Machine Learning (stat.ML)", "authors": "Soheil Bahrampour, Nasser M. Nasrabadi, Asok Ray, W. Kenneth Jenkins,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01070", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01070", "title": "\nOptimization of distributed EPR entanglement generated between two  Gaussian fields by the modified steepest descent method", "abstract": "Recent theoretical investigations on quantum coherent feedback networks have found that with the same pump power, the Einstein-Podolski-Rosen (EPR)-like entanglement generated via a dual nondegenerate optical parametric amplifier (NOPA) system placed in a certain coherent feedback loop is stronger than the EPR-like entangled pairs produced by a single NOPA. In this paper, we present a linear quantum system consisting of two NOPAs and a static linear passive network of optical devices. The network has six inputs and six outputs, among which four outputs and four inputs are connected in a coherent feedback loop with the two NOPAs. This passive network is represented by a complex unitary matrix. A modified steepest descent method is used to find a passive complex unitary matrix at which the entanglement of this dual-NOPA network is locally maximized. Here we choose the matrix corresponding to a dual-NOPA coherent feedback network from our previous work as a starting point for the modified steepest descent algorithm. By decomposing the unitary matrix obtained by the algorithm as the product of so-called two-level unitary matrices, we find an optimized configuration in which the complex matrix is realized by a static optical network made of beam splitters.", "subjects": "Quantum Physics (quant-ph)", "authors": "Zhan Shi, Hendra I. Nurdin,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.00996", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00996", "title": "\nLearning from FITS: Limitations in use in modern astronomical research", "abstract": "The Flexible Image Transport System (FITS) standard has been a great boon to astronomy, allowing observatories, scientists and the public to exchange astronomical information easily. The FITS standard, however, is showing its age. Developed in the late 1970s, the FITS authors made a number of implementation choices that, while common at the time, are now seen to limit its utility with modern data. The authors of the FITS standard could not anticipate the challenges which we are facing today in astronomical computing. Difficulties we now face include, but are not limited to, addressing the need to handle an expanded range of specialized data product types (data models), being more conducive to the networked exchange and storage of data, handling very large datasets, and capturing significantly more complex metadata and data relationships. There are members of the community today who find some or all of these limitations unworkable, and have decided to move ahead with storing data in other formats. If this fragmentation continues, we risk abandoning the advantages of broad interoperability, and ready archivability, that the FITS format provides for astronomy. In this paper we detail some selected important problems which exist within the FITS standard today. These problems may provide insight into deeper underlying issues which reside in the format and we provide a discussion of some lessons learned. It is not our intention here to prescribe specific remedies to these issues; rather, it is to call attention of the FITS and greater astronomical computing communities to these problems in the hope that it will spur action to address them.", "subjects": "Instrumentation and Methods for Astrophysics (astro-ph.IM)", "authors": "Brian Thomas, Tim Jenness, Frossie Economou, Perry Greenfield, Paul Hirst, David S. Berry, Erik Bray, Norman Gray, Demitri Muna, James Turner, Miguel de Val-Borro, Juande Santander-Vela, David Shupe, John Good, G. Bruce Berriman, Slava Kitaeff, Jonathan Fay, Omar Laurino, Anastasia Alexov, Walter Landry, Joe Masters, Adam Brazier, Reinhold Schaaf, Kevin Edwards, Russell O. Redman, Thomas R. Marsh, Ole Streicher, Pat Norris, Sergio Pascual, Matthew Davie, Michael Droettboom, Thomas Robitaille, Riccardo Campana, Alex Hagen, Paul Hartogh, Dominik Klaes, Matthew W. Craig, Derek Homeier,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00978", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00978", "title": "\nUndecidable problems for propositional calculi with implication", "abstract": "In this article, we deal with propositional calculi over a signature containing the classical implication with the rules of modus ponens and substitution. For these calculi we consider few recognizing problems such as recognizing derivations, extensions, completeness, and axiomatizations. The main result of this paper is to prove that the problem of recognizing extensions is undecidable for every propositional calculus, and the problems of recognizing axiomatizations and completeness are undecidable for propositional calculi containing the formula . As a corollary, the problem of derivability of a fixed formula is also undecidable for all . Moreover, we give a historical survey of related results.", "subjects": "Logic (math.LO)", "authors": "Grigoriy V. Bokov,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00974", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00974", "title": "\nAn Assessment on the Use of Stationary Vehicles as a Support to  Cooperative Positioning", "abstract": "In this paper, we consider the use of stationary vehicles as tools to enhance the localisation capabilities of moving vehicles in a VANET. We examine the idea in terms of its potential benefits, technical requirements, algorithmic design and experimental evaluation. Simulation results are given to illustrate the efficacy of the technique.", "subjects": "Optimization and Control (math.OC)", "authors": "Rodrigo H. Ord\u00f3\u00f1ez-Hurtado, Emanuele Crisostomi, Wynita M. Griggs, Robert N. Shorten,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00910", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00910", "title": "\nEXIT-Chart Aided Near-Capacity Quantum Turbo Code Design", "abstract": "The design of Quantum Turbo Codes (QTCs) typically relies on the analysis of their distance spectra, followed by Monte-Carlo simulations. By contrast, in this paper we appropriately adapt the conventional non-binary EXtrinsic Information Transfer (EXIT) charts for quantum turbo codes by exploiting the intrinsic quantum-to-classical isomorphism. The EXIT chart analysis not only allows us to dispense with the time-consuming Monte-Carlo simulations, but also facilitates the design of near-capacity codes without resorting to the analysis of their distance spectra. We have demonstrated that our EXIT chart predictions are in line with the Monte-Carlo simulations results. We have also optimized the entanglement-assisted QTC using EXIT charts, which outperforms the existing distance spectra based QTCs. More explicitly, the performance of our optimized QTC is as close as 0.3 dB to the corresponding hashing bound.", "subjects": "Quantum Physics (quant-ph)", "authors": "Zunaira Babar, Soon Xin Ng, Lajos Hanzo,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00890", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00890", "title": "\nImplicitization of rational hypersurfaces via linear syzygies: a  practical overview", "abstract": "We unveil in concrete terms the general machinery of the syzygy-based algorithms for the implicitization of rational surfaces in terms of the monomials in the polynomials defining the parametrization, following and expanding our joint article with M. Dohm. These algebraic techniques, based on the theory of approximation complexes due to J. Herzog, A, Simis and W. Vasconcelos, were introduced for the implicitization problem by J.-P. Jouanolou, L. Bus 'e, and M. Chardin. Their work was inspired by the practical method of moving curves, proposed by T. Sederberg and F. Chen, translated into the language of syzygies by D. Cox. Our aim is to express the theoretical results and resulting algorithms into very concrete terms, avoiding the use of the advanced homological commutative algebra tools which are needed for their proofs.", "subjects": "Algebraic Geometry (math.AG)", "authors": "Nicol\u00e1s Botbol, Alicia Dickenstein,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00858", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00858", "title": "\nDistributed Radio Interferometric Calibration", "abstract": "Increasing data volumes delivered by a new generation of radio interferometers require computationally efficient and robust calibration algorithms. In this paper, we propose distributed calibration as a way of improving both computational cost as well as robustness in calibration. We exploit the data parallelism across frequency that is inherent in radio astronomical observations that are recorded as multiple channels at different frequencies. Moreover, we also exploit the smoothness of the variation of calibration parameters across frequency. Data parallelism enables us to distribute the computing load across a network of compute agents. Smoothness in frequency enables us reformulate calibration as a consensus optimization problem. With this formulation, we enable flow of information between compute agents calibrating data at different frequencies, without actually passing the data, and thereby improving robustness. We present simulation results to show the feasibility as well as the advantages of distributed calibration as opposed to conventional calibration.", "subjects": "Instrumentation and Methods for Astrophysics (astro-ph.IM)", "authors": "Sarod Yatawatta,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00803", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00803", "title": "\nOn the Sample Size of Random Convex Programs with Structured Dependence  on the Uncertainty", "abstract": "Many control design problems subject to uncertainty can be cast as chance constrained optimization programs. The Scenario Approach provides an intuitive way to address these problems by replacing the chance constraint with a finite number of sampled constraints (scenarios). The sample size critically depends on the so-called Helly's dimension, which is always upper bounded by the number of decision variables. However, this standard bound can lead to computationally expensive programs whose solutions are conservative in terms of cost/violation probability. This paper derives improved bounds of Helly's dimension for problems where the chance constraint has certain structural properties. The improved bounds lower the number of scenarios required for these problems, leading both to lower objective value and reduced computational complexity. The efficacy of the proposed bound is demonstrated on an inventory management example, and is in general applicable to randomized Model Predictive Control of chance constrained linear systems with additive uncertain input.", "subjects": "Optimization and Control (math.OC)", "authors": "Xiaojing Zhang, Sergio Grammatico, Georg Schildbach, Paul Goulart, John Lygeros,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00765", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00765", "title": "\nSampled-Data Stabilization of Nonlinear Delay Systems with a Compact  Absorbing Set", "abstract": "We present a methodology for the global sampled-data stabilization of systems with a compact absorbing set and input/measurement delays. The methodology is based on the Inter-Sample-Predictor, Observer, Predictor, Delay-Free Controller (ISP-O-P-DFC) scheme and the stabilization is robust to perturbations of the sampling schedule. The obtained results are novel even for the delay-free case.", "subjects": "Optimization and Control (math.OC)", "authors": "Iasson Karafyllis, Miroslav Krstic,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00725", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00725", "title": "\nCheaper and Better: Selecting Good Workers for Crowdsourcing", "abstract": "Crowdsourcing provides a popular paradigm for data collection at scale. We study the problem of selecting subsets of workers from a given worker pool to maximize the accuracy under a budget constraint. One natural question is whether we should hire as many workers as the budget allows, or restrict on a small number of top-quality workers. By theoretically analyzing the error rate of a typical setting in crowdsourcing, we frame the worker selection problem into a combinatorial optimization problem and propose an algorithm to solve it efficiently. Empirical results on both simulated and real-world datasets show that our algorithm is able to select a small number of high-quality workers, and performs as good as, sometimes even better than, the much larger crowds as the budget allows.", "subjects": "Machine Learning (stat.ML)", "authors": "Hongwei Li, Qiang Liu,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00690", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00690", "title": "\nCoupling Human Mobility and Social Ties", "abstract": "Studies using massive, passively data collected from communication technologies have revealed many ubiquitous aspects of social networks, helping us understand and model social media, information diffusion, and organizational dynamics. More recently, these data have come tagged with geographic information, enabling studies of human mobility patterns and the science of cities. We combine these two pursuits and uncover reproducible mobility patterns amongst social contacts. First, we introduce measures of mobility similarity and predictability and measure them for populations of users in three large urban areas. We find individuals' visitations patterns are far more similar to and predictable by social contacts than strangers and that these measures are positively correlated with tie strength. Unsupervised clustering of hourly variations in mobility similarity identifies three categories of social ties and suggests geography is an important feature to contextualize social relationships. We find that the composition of a user's ego network in terms of the type of contacts they keep is correlated with mobility behavior. Finally, we extend a popular mobility model to include movement choices based on social contacts and compare it's ability to reproduce empirical measurements with two additional models of mobility.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Jameson L. Toole, Carlos Herrera-Yague, Christian M. Schneider, Marta C. Gonzalez,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00679", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00679", "title": "\nCompetition and Coalition Formation of Renewable Power Producers", "abstract": "We investigate group formations and strategic behaviors of renewable power producers in electricity markets. These producers currently bid into the day-ahead market in a conservative fashion because of the real-time risk associated with not meeting their bid amount. It has been suggested in the literature that producers would bid less conservatively if they can form large groups to take advantages of spatial diversity to reduce the uncertainty in their aggregate output. We show that large groups of renewable producers would act strategically to lower the aggregate output because of market power. To maximize renewable power production, we characterize the trade-off between market power and generation uncertainty as a function of the size of the groups. We show there is a sweet spot in the sense that there exists groups that are large enough to achieve the uncertainty reduction of the grand coalition, but are small enough such that they have no significant market power.We consider both independent and correlated forecast errors under a fixed real-time penalty. We also consider a real-time market where both selling and buying of energy are allowed. We validate our claims using PJM and NREL data.", "subjects": "Optimization and Control (math.OC)", "authors": "Baosen Zhang, Ramesh Johari, Ram Rajagopal,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00592", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00592", "title": "\nA Class of DCT Approximations Based on the Feig-Winograd Algorithm", "abstract": "A new class of matrices based on a parametrization of the Feig-Winograd factorization of 8-point DCT is proposed. Such parametrization induces a matrix subspace, which unifies a number of existing methods for DCT approximation. By solving a comprehensive multicriteria optimization problem, we identified several new DCT approximations. Obtained solutions were sought to possess the following properties: (i) low multiplierless computational complexity, (ii) orthogonality or near orthogonality, (iii) low complexity invertibility, and (iv) close proximity and performance to the exact DCT. Proposed approximations were submitted to assessment in terms of proximity to the DCT, coding performance, and suitability for image compression. Considering Pareto efficiency, particular new proposed approximations could outperform various existing methods archived in literature.", "subjects": "Methodology (stat.ME)", "authors": "C. J. Tablada, F. M. Bayer, R. J. Cintra,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00584", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00584", "title": "\nAnderson transition for Google matrix eigenstates", "abstract": "We introduce a number of random matrix models describing the Google matrix G of directed networks. The properties of their spectra and eigenstates are analyzed by numerical matrix diagonalization. We show that for certain models it is possible to have an algebraic decay of PageRank vector with the exponent similar to real directed networks. At the same time the spectrum has no spectral gap and a broad distribution of eigenvalues in the complex plain. The eigenstates of G are characterized by the Anderson transition from localized to delocalized states and a mobility edge curve in the complex plane of eigenvalues.", "subjects": "Disordered Systems and Neural Networks (cond-mat.dis-nn)", "authors": "O.V.Zhirov, D.L.Shepelyansky,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00555", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00555", "title": "\nA Discrete Tchebichef Transform Approximation for Image and Video Coding", "abstract": "In this paper, we introduce a low-complexity approximation for the discrete Tchebichef transform (DTT). The proposed forward and inverse transforms are multiplication-free and require a reduced number of additions and bit-shifting operations. Numerical compression simulations demonstrate the efficiency of the proposed transform for image and video coding. Furthermore, Xilinx Virtex-6 FPGA based hardware realization shows 44.9% reduction in dynamic power consumption and 64.7% lower area when compared to the literature.", "subjects": "Methodology (stat.ME)", "authors": "P. A. M. Oliveira, R. J. Cintra, F. M. Bayer, S. Kulasekera, A. Madanayake,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1502.00549", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00549", "title": "\nA 0.042 mm^2 programmable biphasic stimulator for cochlear implants  suitable for a large number of channels", "abstract": "This paper presents a compact programmable biphasic stimulator for cochlear implants. By employing double-loop negative feedback, the output impedance of the current generator is increased, while maximizing the voltage compliance of the output transistor. To make the stimulator circuit compact, the stimulation current is set by scaling a reference current using a two stage binary-weighted transistor DAC (comprising a 3 bit high-voltage transistor DAC and a 4 bit low-voltage transistor DAC). With this structure the power consumption and the area of the circuit can be minimized. The proposed circuit has been implemented in AMS 0.18um high-voltage CMOS IC technology, using an active chip area of about 0.042mm^2. Measurement results show that proper charge balance of the anodic and cathodic stimulation phases is achieved and a dc blocking capacitor can be omitted. The resulting reduction in the required area makes the proposed system suitable for a large number of channels.", "subjects": "Neurons and Cognition (q-bio.NC)", "authors": "W. Ngamkham, M. N. van Dongen, W. A. Serdijn, C. J. Bes, J. J. Briaire, J. H. M. Frijns,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1502.00536", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00536", "title": "\nInformationally complete measurements from compressed sensing  methodology", "abstract": "Compressed sensing (CS) is a technique to faithfully estimate an unknown signal from relatively few data points when the measurement samples satisfy a restricted isometry property (RIP). Recently, this technique has been ported to quantum information science to perform tomography with a substantially reduced number of measurement settings. In this work we show that the constraint that a physical density matrix is positive semidefinite provides a rigorous connection between the RIP and the informational completeness of a POVM used for state tomography. This enables us to construct informationally complete measurements that are robust to noise using tools provided by the CS methodology. The exact recovery no longer hinges on a particular convex optimization program; solving any optimization, constrained to the cone of positive semidefinite matrices, effectively results in a CS estimation of the state. From a practical point of view, we can therefore employ fast algorithms developed to handle large dimensional matrices for efficient tomography of quantum states of a large dimensional Hilbert space.", "subjects": "Quantum Physics (quant-ph)", "authors": "Amir Kalev, Robert L. Kosut, Ivan H. Deutsch,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00481", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00481", "title": "\nSocial setting, intuition, and experience in lab experiments interact to  shape cooperative decision-making", "abstract": "Recent studies suggest that cooperative decision-making in one-shot interactions is a history-dependent dual process: promoting intuition versus deliberation has typically a positive effect on cooperation (duality) among people living in a cooperative setting and with no previous experience in economic games on cooperation (history-dependence). Here we report a large experiment exploring how these findings transfer to a non-cooperative setting. We find three major results: (i) promoting intuition versus deliberation has no effect on cooperative behavior among inexperienced subjects living in a non-cooperative setting; (ii) experienced subjects are much more cooperative than inexperienced subjects; and (iii) experience has a U-shaped effect on cooperation: subjects with little experience cooperate the least. We also find evidence that the behavioral transition between little experienced subjects and experienced subjects is primarily driven by intuitive responses. These results suggest that cooperation is a slow learning process, rather than an instinctive impulse or a self-controlled choice, and that experience operates primarily via the channel of intuition. In doing so, our findings shed further light on the cognitive basis of human cooperative decision-making and provide further support for the recently proposed Social Heuristics Hypothesis.", "subjects": "Populations and Evolution (q-bio.PE)", "authors": "Valerio Capraro, Giorgia Cococcioni,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00423", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00423", "title": "\nFundamental lemmas for the determination of optimal control strategies  for a class of single machine family scheduling problems", "abstract": "Four lemmas, which constitute the theoretical foundation necessary to determine optimal control strategies for a class of single machine family scheduling problems, are presented in this technical report. The scheduling problem is characterized by the presence of sequence-dependent batch setup and controllable processing times; moreover, the generalized due-date model is adopted in the problem. The lemmas are employed within a constructive procedure (proposed by the Author and based on the application of dynamic programming) that allows determining the decisions which optimally solve the scheduling problem as functions of the system state. Two complete examples of single machine family scheduling problem are included in the technical report with the aim of illustrating the application of the fundamental lemmas in the proposed approach.", "subjects": "Optimization and Control (math.OC)", "authors": "Davide Giglio,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00413", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00413", "title": "\nConstructing Near Spanning Trees with Few Local Inspections", "abstract": "Constructing a spanning tree of a graph is one of the most basic tasks in graph theory. Motivated by several recent studies of local graph algorithms, we consider the following variant of this problem. Let G be a connected bounded-degree graph. Given an edge in we would like to decide whether belongs to a connected subgraph consisting of edges (for a prespecified constant ), where the decision for different edges should be consistent with the same subgraph . Can this task be performed by inspecting only a number of edges in ? Our main results are: (1) We show that if every -vertex subgraph of has expansion then one can (deterministically) construct a sparse spanning subgraph of using few inspections. To this end we analyze a \"local\" version of a famous minimum-weight spanning tree algorithm. (2) We show that the above expansion requirement is sharp even when allowing randomization. To this end we construct a family of -regular graphs of high girth, in which every -vertex subgraph has expansion .", "subjects": "Combinatorics (math.CO)", "authors": "Reut Levi, Guy Moshkovitz, Dana Ron, Ronitt Rubinfeld, Asaf Shapira,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00405", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00405", "title": "\nMonotone Increasing Properties and Their Phase Transitions in Uniform  Random Intersection Graphs", "abstract": "Uniform random intersection graphs have received much interest and been used in diverse applications. A uniform random intersection graph with nodes is constructed as follows: each node selects a set of different items uniformly at random from the same pool of distinct items, and two nodes establish an undirected edge in between if and only if they share at least one item. For such graph denoted by , we present the following results in this paper. First, we provide an exact analysis on the probabilities of having a perfect matching and having a Hamilton cycle respectively, under (all asymptotic notation are understood with ). The analysis reveals that just like (-)connectivity shown in prior work, for both properties of perfect matching containment and Hamilton cycle containment, also exhibits phase transitions: for each property above, as increases, the limit of the probability that has the property increases from to . Second, we compute the phase transition widths of for -connectivity (KC), perfect matching containment (PMC), and Hamilton cycle containment (HCC), respectively. For a graph property and a positive constant , with the phase transition width defined as the difference between the minimal ensuring having property with probability at least or , we show for any positive constants and : (i) If and , then is either or for each sufficiently large. (ii) If , then . (iii) If , then . (iv) If , and are both .", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Jun Zhao, Osman Ya\u011fan, Virgil Gligor,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00404", "category": "Computer Science ", "pdflink": "http://arxiv.org/e-print/1502.00404", "title": "\nA curious gap in one-dimensional geometric random graphs between  connectivity and the absence of isolated node", "abstract": "One-dimensional geometric random graphs are constructed by distributing nodes uniformly and independently on a unit interval and then assigning an undirected edge between any two nodes that have a distance at most . These graphs have received much interest and been used in various applications including wireless networks. A threshold of for connectivity is known as in the literature. In this paper, we prove that a threshold of for the absence of isolated node is (i.e., a half of the threshold ). Our result shows there is a curious gap between thresholds of connectivity and the absence of isolated node in one-dimensional geometric random graphs; in particular, when equals for a constant , a one-dimensional geometric random graph has no isolated node but is not connected. This curious gap in one-dimensional geometric random graphs is in sharp contrast to the prevalent phenomenon in many other random graphs such as two-dimensional geometric random graphs, Erd Hs-R 'enyi graphs, and random intersection graphs, all of which in the asymptotic sense become connected as soon as there is no isolated node.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Jun Zhao, Osman Ya\u011fan, Virgil Gligor,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00400", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00400", "title": "\nk-Connectivity of Random Key Graphs", "abstract": "Random key graphs represent topologies of secure wireless sensor networks that apply the seminal Eschenauer-Gligor random key predistribution scheme to secure communication between sensors. These graphs have received much attention and also been used in diverse application areas beyond secure sensor networks; e.g., cryptanalysis, social networks, and recommender systems. Formally, a random key graph with nodes is constructed by assigning each node keys selected uniformly at random from a pool of keys and then putting an undirected edge between any two nodes sharing at least one key. Considerable progress has been made in the literature to analyze connectivity and -connectivity of random key graphs, where -connectivity of a graph ensures connectivity even after the removal of nodes or edges. Yet, it still remains an open question for -connectivity in random key graphs under and (the case of is trivial). In this paper, we answer the above problem by providing an exact analysis of -connectivity in random key graphs under .", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Jun Zhao, Osman Ya\u011fan, Virgil Gligor,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00395", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00395", "title": "\nThreshold Functions in Random s-Intersection Graphs", "abstract": "Random -intersection graphs have recently received considerable attention in a wide range of application areas. In such a graph, each vertex is equipped with a set of items in some random manner, and any two vertices establish an undirected edge in between if and only if they have at least common items. In particular, in a uniform random -intersection graph, each vertex independently selects a fixed number of items uniformly at random from a common item pool, while in a binomial random -intersection graph, each item in some item pool is independently attached to each vertex with the same probability. For binomial/uniform random -intersection graphs, we establish threshold functions for perfect matching containment, Hamilton cycle containment, and -robustness, where -robustness is in the sense of Zhang and Sundaram [IEEE Conf. on Decision &amp; Control '12]. We show that these threshold functions resemble those of classical Erd Hs-R 'nyi graphs, where each pair of vertices has an undirected edge independently with the same probability.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Jun Zhao, Osman Ya\u011fan, Virgil Gligor,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00392", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00392", "title": "\nEffects of awareness diffusion and self-initiated awareness behavior on  epidemic spreading - an approach based on multiplex networks", "abstract": "In this paper, we study the interplay between the epidemic spreading and the diffusion of awareness in multiplex networks. In the model, an infectious disease can spread in one network representing the paths of epidemic spreading (contact network), leading to the diffusion of awareness in the other network (information network), and then the diffusion of awareness will cause individuals to take social distances, which in turn affects the epidemic spreading. As for the diffusion of awareness, we assume that, on the one hand, individuals can be informed by other aware neighbors in information network, on the other hand, the susceptible individuals can be self-awareness induced by the infected neighbors in the contact networks (local information) or mass media (global information). Through Markov chain approach and numerical computations, we find that the density of infected individuals and the epidemic threshold can be affected by the structures of the two networks and the effective transmission rate of the awareness. However, we prove that though the introduction of the self-awareness can lower the density of infection, which cannot increase the epidemic threshold no matter of the local information or global information. Our finding is remarkably different to many previous results--local information based behavioral response can alter the epidemic threshold.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Jia-Qian Kan, Hai-Feng Zhang,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00362", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00362", "title": "\nDesigning Networks: A Mixed-Integer Linear Optimization Approach", "abstract": "Designing networks with specified collective properties is useful in a variety of application areas, enabling the study of how given properties affect the behavior of network models, the downscaling of empirical networks to workable sizes, and the analysis of network evolution. Despite the importance of the task, there currently exists a gap in our ability to systematically generate networks that adhere to theoretical guarantees for the given property specifications. In this paper, we propose the use of Mixed-Integer Linear Optimization modeling and solution methodologies to address this Network Generation Problem. We present a number of useful modeling techniques and apply them to mathematically express and constrain network properties in the context of an optimization formulation. We then develop complete formulations for the generation of networks that attain specified levels of connectivity, spread, assortativity and robustness, and we illustrate these via a number of computational case studies.", "subjects": "Optimization and Control (math.OC)", "authors": "Chrysanthos E. Gounaris, Karthikeyan Rajendran, Ioannis G. Kevrekidis, Christodoulos A. Floudas,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00353", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00353", "title": "\nComplex networks vulnerability to module-based attacks", "abstract": "In the multidisciplinary field of Network Science, optimization of procedures for efficiently breaking complex networks is attracting much attention from practical points of view. In this contribution we present a module-based method to efficiently break complex networks. The procedure first identifies the communities in which the network can be represented, then it deletes the nodes (edges) that connect different modules by its order in the betweenness centrality ranking list. We illustrate the method by applying it to various well known examples of social, infrastructure, and biological networks. We show that the proposed method always outperforms vertex (edge) attacks which are based on the ranking of node (edge) degree or centrality, with a huge gain in efficiency for some examples. Remarkably, for the US power grid, the present method breaks the original network of 4941 nodes to many fragments smaller than 197 nodes (4% of the original size) by removing mere 164 nodes (~3%) identified by the procedure. By comparison, any degree or centrality based procedure, deleting the same amount of nodes, removes only 22% of the original network, i.e. more than 3800 nodes continue to be connected after that", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Bruno Requi\u00e3o da Cunha, Juan Carlos Gonz\u00e1lez-Avella, Sebasti\u00e1n Gon\u00e7alves,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00348", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00348", "title": "\nA Novel Statistical Channel Model for Turbulence-Induced Fading in  Free-Space Optical Systems", "abstract": "In this paper, we propose a new probability distribution function which accurately describes turbulence-induced fading under a wide range of turbulence conditions. The proposed model, termed Double Generalized Gamma (Double GG), is based on a doubly stochastic theory of scintillation and developed via the product of two Generalized Gamma (GG) distributions. The proposed Double GG distribution generalizes many existing turbulence channel models and provides an excellent fit to the published plane and spherical waves simulation data. Using this new statistical channel model, we derive closed form expressions for the outage probability and the average bit error as well as corresponding asymptotic expressions of free-space optical communication systems over turbulence channels. We demonstrate that our derived expressions cover many existing results in the literature earlier reported for Gamma-Gamma, Double-Weibull and K channels as special cases.", "subjects": "Mathematical Physics (math-ph)", "authors": "Mohammadreza Aminikashani, Murat Uysal, Mohsen Kavehrad,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00318", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00318", "title": "\nSetting the stage for data science: integration of data management  skills in introductory and second courses in statistics", "abstract": "Many have argued that statistics students need additional facility to express statistical computations. By introducing students to commonplace tools for data management, visualization, and reproducible analysis in data science and applying these to real-world scenarios, we prepare them to think statistically. In an era of increasingly big data, it is imperative that students develop data-related capacities, beginning with the introductory course. We believe that the integration of these precursors to data science into our curricula-early and often-will help statisticians be part of the dialogue regarding \"Big Data\" and \"Big Questions\".", "subjects": "Computation (stat.CO)", "authors": "Nicholas J. Horton, Benjamin S. Baumer, Hadley Wickham,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00284", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00284", "title": "\nDefining Least Community as a Homogeneous Group in Complex Networks", "abstract": "This paper introduces a new concept of least community that is as homogeneous as a random graph, and develops a new community detection algorithm from the perspective of homogeneity or heterogeneity. Based on this concept, we adopt head/tail breaks - a newly developed classification scheme for data with a heavy-tailed distribution - and rely on edge betweenness given its heavy-tailed distribution to iteratively partition a network into many heterogeneous and homogeneous communities. Surprisingly, the derived communities for any self-organized and/or self-evolved large networks demonstrate very striking power laws, implying that there are far more small communities than large ones. This notion of far more small things than large ones constitutes a new fundamental way of thinking for community detection. Keywords: head/tail breaks, ht-index, scaling, k-means, natural breaks, and classification", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Bin Jiang, Ding Ma,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00274", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00274", "title": "\nA Gradient Descent Approach to Optimal Coherent Quantum LQG Controller  Design", "abstract": "This paper is concerned with the Coherent Quantum Linear Quadratic Gaussian (CQLQG) control problem of finding a stabilizing measurement-free quantum controller for a quantum plant so as to minimize an infinite-horizon mean square performance index for the fully quantum closed-loop system. In comparison with the observation-actuation structure of classical controllers, the coherent quantum feedback is less invasive to the quantum dynamics and quantum information. Both the plant and the controller are open quantum systems whose dynamic variables satisfy the canonical commutation relations (CCRs) of a quantum harmonic oscillator and are governed by linear quantum stochastic differential equations (QSDEs). In order to correspond to such oscillators, these QSDEs must satisfy physical realizability (PR) conditions, which are organised as quadratic constraints on the controller matrices and reflect the preservation of CCRs in time. The CQLQG problem is a constrained optimization problem for the steady-state quantum covariance matrix of the plant-controller system satisfying an algebraic Lyapunov equation. We propose a gradient descent algorithm equipped with adaptive stepsize selection for the numerical solution of the problem. The algorithm finds a local minimum of the LQG cost over the parameters of the Hamiltonian and coupling operators of a stabilizing PR quantum controller, thus taking the PR constraints into account. A convergence analysis of the proposed algorithm is presented. A numerical example of a locally optimal CQLQG controller design is provided to demonstrate the algorithm performance.", "subjects": "Quantum Physics (quant-ph)", "authors": "Arash Kh. Sichani, Igor G. Vladimirov, Ian R. Petersen,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00207", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00207", "title": "\nQuantum game players can have advantage without discord", "abstract": "The last two decades have witnessed a rapid development of quantum information processing, a new paradigm which studies the power and limit of \"quantum advantages\" in various information processing tasks. Problems such as when quantum advantage exists, and if existing, how much it could be, are at a central position of these studies. In a broad class of scenarios, there are, implicitly or explicitly, at least two parties involved, who share a state, and the correlation in this shared state is the key factor to the efficiency under concern. In these scenarios, the shared emph or emph is usually what accounts for quantum advantage. In this paper, we examine a fundamental problem of this nature from the perspective of game theory, a branch of applied mathematics studying selfish behaviors of two or more players. We exhibit a natural zero-sum game, in which the chance for any player to win the game depends only on the ending correlation. We show that in a certain classical equilibrium, a situation in which no player can further increase her payoff by any local classical operation, whoever first uses a quantum computer has a big advantage over its classical opponent. The equilibrium is fair to both players and, as a shared correlation, it does not contain any discord, yet a quantum advantage still exists. This indicates that at least in game theory, the previous notion of discord as a measure of non-classical correlation needs to be reexamined, when there are two players with different objectives.", "subjects": "Quantum Physics (quant-ph)", "authors": "Zhaohui Wei, Shengyu Zhang,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00190", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00190", "title": "\nRandomized Kaczmarz Algorithm for Inconsistent Linear Systems: An Exact  MSE Analysis", "abstract": "We provide a complete characterization of the randomized Kaczmarz algorithm (RKA) for inconsistent linear systems. The Kaczmarz algorithm, known in some fields as the algebraic reconstruction technique, is a classical method for solving large-scale overdetermined linear systems through a sequence of projection operators; the randomized Kaczmarz algorithm is a recent proposal by Strohmer and Vershynin to randomize the sequence of projections in order to guarantee exponential convergence (in mean square) to the solutions. A flurry of work followed this development, with renewed interest in the algorithm, its extensions, and various bounds on their performance. Earlier, we studied the special case of consistent linear systems and provided an exact formula for the mean squared error (MSE) in the value reconstructed by RKA, as well as a simple way to compute the exact decay rate of the error. In this work, we consider the case of inconsistent linear systems, which is a more relevant scenario for most applications. First, by using a \"lifting trick\", we derive an exact formula for the MSE given a fixed noise vector added to the measurements. Then we show how to average over the noise when it is drawn from a distribution with known first and second-order statistics. Finally, we demonstrate the accuracy of our exact MSE formulas through numerical simulations, which also illustrate that previous upper bounds in the literature may be several orders of magnitude too high.", "subjects": "Numerical Analysis (math.NA)", "authors": "Chuang Wang, Ameya Agaskar, Yue M. Lu,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00186", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00186", "title": "\nAdvanced Mean Field Theory of Restricted Boltzmann Machine", "abstract": "Learning in restricted Boltzmann machine is typically hard due to the computation of gradients of log-likelihood function. To describe the network state statistics of the restricted Boltzmann machine, we develop an advanced mean field theory based on the Bethe approximation. Our theory provides an efficient message passing based method that evaluates not only the partition function (free energy) but also its gradients without requiring statistical sampling. The results are compared with those obtained by the computationally expensive sampling based method.", "subjects": "Statistical Mechanics (cond-mat.stat-mech)", "authors": "Haiping Huang, Taro Toyoizumi,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00154", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00154", "title": "\nBearing-Only Network Localization: Localizability, Sensitivity, and  Distributed Protocols", "abstract": "This paper addresses self-localization of stationary sensor networks based on inter-neighbor bearings and anchor nodes whose locations are known. In our work, we formulate the bearing-only network localization problem as a linear least-squares problem and consider measurement models with and without errors. We provide necessary and sufficient conditions for the localizability of a network with both algebraic and rigidity theoretic interpretations. The proposed conditions fully describe the relationship between the localizability and the bearing rigidity properties of a network. We also analyze the sensitivity of the localization problem to constant measurement errors. Upper bounds for the localization error and the bearing errors that a network can tolerate are presented. Finally, we propose distributed protocols to globally localize bearing-only networks. All the results presented in the paper are applicable to networks in arbitrary dimensions. This work is validated with numerical simulations.", "subjects": "Optimization and Control (math.OC)", "authors": "Shiyu Zhao, Daniel Zelazo,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00141", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00141", "title": "\nAn evaluation framework for event detection using a morphological model  of acoustic scenes", "abstract": "This paper introduces a model of environmental acoustic scenes which adopts a morphological approach by ab-stracting temporal structures of acoustic scenes. To demonstrate its potential, this model is employed to evaluate the performance of a large set of acoustic events detection systems. This model allows us to explicitly control key morphological aspects of the acoustic scene and isolate their impact on the performance of the system under evaluation. Thus, more information can be gained on the behavior of evaluated systems, providing guidance for further improvements. The proposed model is validated using submitted systems from the IEEE DCASE Challenge; results indicate that the proposed scheme is able to successfully build datasets useful for evaluating some aspects the performance of event detection systems, more particularly their robustness to new listening conditions and the increasing level of background sounds.", "subjects": "Machine Learning (stat.ML)", "authors": "Mathieu Lagrange, Gr\u00e9goire Lafay, Mathias Rossignol, Emmanouil Benetos, Axel Roebel,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00139", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00139", "title": "\nSubspace Leakage Analysis and Improved DOA Estimation with Small Sample  Size", "abstract": "Classical methods of DOA estimation such as the MUSIC algorithm are based on estimating the signal and noise subspaces from the sample covariance matrix. For a small number of samples, such methods are exposed to performance breakdown, as the sample covariance matrix can largely deviate from the true covariance matrix. In this paper, the problem of DOA estimation performance breakdown is investigated. We consider the structure of the sample covariance matrix and the dynamics of the root-MUSIC algorithm. The performance breakdown in the threshold region is associated with the subspace leakage where some portion of the true signal subspace resides in the estimated noise subspace. In this paper, the subspace leakage is theoretically derived. We also propose a two-step method which improves the performance by modifying the sample covariance matrix such that the amount of the subspace leakage is reduced. Furthermore, we introduce a phenomenon named as root-swap which occurs in the root-MUSIC algorithm in the low sample size region and degrades the performance of the DOA estimation. A new method is then proposed to alleviate this problem. Numerical examples and simulation results are given for uncorrelated and correlated sources to illustrate the improvement achieved by the proposed methods. Moreover, the proposed algorithms are combined with the pseudo-noise resampling method to further improve the performance.", "subjects": "Statistics Theory (math.ST)", "authors": "Mahdi Shaghaghi, Sergiy A. Vorobyov,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00133", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00133", "title": "\nSparse Dueling Bandits", "abstract": "The dueling bandit problem is a variation of the classical multi-armed bandit in which the allowable actions are noisy comparisons between pairs of arms. This paper focuses on a new approach for finding the \"best\" arm according to the Borda criterion using noisy comparisons. We prove that in the absence of structural assumptions, the sample complexity of this problem is proportional to the sum of the inverse squared gaps between the Borda scores of each suboptimal arm and the best arm. We explore this dependence further and consider structural constraints on the pairwise comparison matrix (a particular form of sparsity natural to this problem) that can significantly reduce the sample complexity. This motivates a new algorithm called Successive Elimination with Comparison Sparsity (SECS) that exploits sparsity to find the Borda winner using fewer samples than standard algorithms. We also evaluate the new algorithm experimentally with synthetic and real data. The results show that the sparsity model and the new algorithm can provide significant improvements over standard approaches.", "subjects": "Machine Learning (stat.ML)", "authors": "Kevin Jamieson, Sumeet Katariya, Atul Deshpande, Robert Nowak,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00093", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00093", "title": "\nDeep learning of fMRI big data: a novel approach to subject-transfer  decoding", "abstract": "As a technology to read brain states from measurable brain activities, brain decoding are widely applied in industries and medical sciences. In spite of high demands in these applications for a universal decoder that can be applied to all individuals simultaneously, large variation in brain activities across individuals has limited the scope of many studies to the development of individual-specific decoders. In this study, we used deep neural network (DNN), a nonlinear hierarchical model, to construct a subject-transfer decoder. Our decoder is the first successful DNN-based subject-transfer decoder. When applied to a large-scale functional magnetic resonance imaging (fMRI) database, our DNN-based decoder achieved higher decoding accuracy than other baseline methods, including support vector machine (SVM). In order to analyze the knowledge acquired by this decoder, we applied principal sensitivity analysis (PSA) to the decoder and visualized the discriminative features that are common to all subjects in the dataset. Our PSA successfully visualized the subject-independent features contributing to the subject-transferability of the trained decoder.", "subjects": "Machine Learning (stat.ML)", "authors": "Sotetsu Koyamada, Yumi Shikauchi, Ken Nakae, Masanori Koyama, Shin Ishii,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00067", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00067", "title": "\nPower of quantum computing with restricted postselections", "abstract": "We consider restricted versions of where postselection probabilities can be efficiently calculated by classical or quantum computers. We show that such restricted classes are in . This result suggests that postselecting an event with an exponentially small probability does not necessarily boost to PP. The best upperbound of is , and therefore restricted classes are other examples of complexity classes \"slightly above \". In [C. M. Lee and J. Barrett, arXiv:1412.8671], it was shown that the computational capacity of a general probabilistic theory which satisfies the tomographic locality is in . Our result therefore implies that quantum physics with restricted postselections is an example of a super quantum theory which seems to be outside of their general probabilistic theory but its computational capacity is also in . Although it is physically natural to expect that such restricted classes are not equivalent to BQP, we show that , which is unlikely to be in BQP, is contained in the restricted classes. Finally, we also consider another restricted class of , where the postselected probability depends only on the size of inputs. We show that this restricted version is contained in , where .", "subjects": "Quantum Physics (quant-ph)", "authors": "Tomoyuki Morimae, Harumichi Nishimura,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00062", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00062", "title": "\nA New Intelligence Based Approach for Computer-Aided Diagnosis of Dengue  Fever", "abstract": "Identification of the influential clinical symptoms and laboratory features that help in the diagnosis of dengue fever in early phase of the illness would aid in designing effective public health management and virological surveillance strategies. Keeping this as our main objective we develop in this paper, a new computational intelligence based methodology that predicts the diagnosis in real time, minimizing the number of false positives and false negatives. Our methodology consists of three major components (i) a novel missing value imputation procedure that can be applied on any data set consisting of categorical (nominal) and/or numeric (real or integer) (ii) a wrapper based features selection method with genetic search for extracting a subset of most influential symptoms that can diagnose the illness and (iii) an alternating decision tree method that employs boosting for generating highly accurate decision rules. The predictive models developed using our methodology are found to be more accurate than the state-of-the-art methodologies used in the diagnosis of the dengue fever.", "subjects": "Machine Learning (stat.ML)", "authors": "Vadrevu Sree Hari Rao, Mallenahalli Naresh Kumar,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00060", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00060", "title": "\nAn Unsupervised Learning Method for Early Event Detection in Smart Grid  with Big Data", "abstract": "Early Event Detection (EED) is becoming increasingly complicated in smart grids, due to the exploration of data with features of volume, velocity, variety, and veracity (i.e. 4Vs data). This paper develops a data-driven unsupervised learning method based on random matrix theory (RMT) to handle this challenge problem. Compared to model-based methods, datadriven ones conduct data analysis requiring no knowledge of the system model/topology based on assumptions or simplifications. On the other hand, compared to supervised learning methods, unsupervised ones extract analysis directly from the raw data without any label. The proposed method using to processing all the raw data rather than only the labeled ones, calculates the mean spectral energy radius (MSR) as high-dimensional statistic and visualize it to form 3D power-map for EED. This method is easier in logic, faster in speed, and more universal and objective. Moreover, it is veracious and robust to traditional EED challenges such as error accumulations, spurious correlations, incidental correlations, and even bad data existence in the core area. Case studies with both simulated data and realistic data validate the effectiveness and higher performance of the proposed method for EED execution in smart grids.", "subjects": "Methodology (stat.ME)", "authors": "Xing He, Robert Caiming Qiu, Qian Ai, Xinyi Xu,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.08048", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.08048", "title": "\nApproximating Nearest Neighbor Distances", "abstract": "Several researchers proposed using non-Euclidean metrics on point sets in Euclidean space for clustering noisy data. Almost always, a distance function is desired that recognizes the closeness of the points in the same cluster, even if the Euclidean cluster diameter is large. Therefore, it is preferred to assign smaller costs to the paths that stay close to the input points. In this paper, we consider the most natural metric with this property, which we call the nearest neighbor metric. Given a point set P and a path , our metric charges each point of with its distance to P. The total charge along determines its nearest neighbor length, which is formally defined as the integral of the distance to the input points along the curve. We describe a -approximation algorithm and a -approximation algorithm to compute the nearest neighbor metric. Both approximation algorithms work in near-linear time. The former uses shortest paths on a sparse graph using only the input points. The latter uses a sparse sample of the ambient space, to find good approximate geodesic paths.", "subjects": "Computational Geometry (cs.CG)", "authors": "Michael B. Cohen, Brittany Terese Fasy, Gary L. Miller, Amir Nayyeri, Donald R. Sheehy, Ameya Velingker,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.08046", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.08046", "title": "\nImage Segmentation in Liquid Argon Time Projection Chamber Detector", "abstract": "The Liquid Argon Time Projection Chamber (LAr-TPC) detectors provide excellent imaging and particle identification ability for studying neutrinos. An efficient and automatic reconstruction procedures are required to exploit potential of this imaging technology. Herein, a novel method for segmentation of images from LAr-TPC detectors is presented. The proposed approach computes a feature descriptor for each pixel in the image, which characterizes amplitude distribution in pixel and its neighbourhood. The supervised classifier is employed to distinguish between pixels representing particle's track and noise. The classifier is trained and evaluated on the hand-labeled dataset. The proposed approach can be a preprocessing step for reconstructing algorithms working directly on detector images.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Piotr P\u0142o\u0144ski, Dorota Stefan, Robert Sulej, Krzysztof Zaremba,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.08040", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.08040", "title": "\nDistancePPG: Robust non-contact vital signs monitoring using a camera", "abstract": "Vital signs such as pulse rate and breathing rate are currently measured using contact probes. But, non-contact methods for measuring vital signs are desirable both in hospital settings (e.g. in NICU) and for ubiquitous in-situ health tracking (e.g. on mobile phone and computers with webcams). Recently, camera-based non-contact vital sign monitoring have been shown to be feasible. However, camera-based vital sign monitoring is challenging for people having darker skin tone, under low lighting conditions, and/or during movement of an individual in front of the camera. In this paper, we propose distancePPG, a new camera-based vital sign estimation algorithm which addresses these challenges. DistancePPG proposes a new method of combining skin-color change signals from different tracked regions of the face using a weighted average, where the weights depend on the blood perfusion and incident light intensity in the region, to improve the signal-to-noise ratio (SNR) of camera-based estimate. One of our key contributions is a new automatic method for determining the weights based only on the video recording of the subject. The gains in SNR of camera-based PPG estimated using distancePPG translate into reduction of the error in vital sign estimation, and thus expand the scope of camera-based vital sign monitoring to potentially challenging scenarios. Further, a dataset will be released, comprising of synchronized video recordings of face and pulse oximeter based ground truth recordings from the earlobe for people with different skin tones, under different lighting conditions and for various motion scenarios.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Mayank Kumar, Ashok Veeraraghavan, Ashutosh Sabharval,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.08039", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.08039", "title": "\nProbabilistic Zero-shot Classification with Semantic Rankings", "abstract": "In this paper we propose a non-metric ranking-based representation of semantic similarity that allows natural aggregation of semantic information from multiple heterogeneous sources. We apply the ranking-based representation to zero-shot learning problems, and present deterministic and probabilistic zero-shot classifiers which can be built from pre-trained classifiers without retraining. We demonstrate their the advantages on two large real-world image datasets. In particular, we show that aggregating different sources of semantic information, including crowd-sourcing, leads to more accurate classification.", "subjects": "Learning (cs.LG)", "authors": "Jihun Hamm, Mikhail Belkin,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.08037", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.08037", "title": "\nDecentralized Abstractions for Feedback Interconnected Multi-Agent  Systems", "abstract": "The purpose of this report is to define abstractions for multi-agent systems under coupled constraints. In the proposed decentralized framework, we specify a finite or countable transition system for each agent which only takes into account the discrete positions of its neighbors. The dynamics of the considered systems consist of two components. An appropriate feedback law which guarantees that certain performance requirements (eg. connectivity) are preserved and induces the coupled constraints and additional free inputs which we exploit in order to accomplish high level tasks. In this work we provide sufficient conditions on the space and time discretization of the system which ensure that we can extract a well posed and hence meaningful finite transition system.", "subjects": "Systems and Control (cs.SY)", "authors": "Dimitris Boskos, Dimos V. Dimarogonas,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.08033", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.08033", "title": "\nSciRecSys: A Recommendation System for Scientific Publication by  Discovering Keyword Relationships", "abstract": "In this work, we propose a new approach for discovering various relationships among keywords over the scientific publications based on a Markov Chain model. It is an important problem since keywords are the basic elements for representing abstract objects such as documents, user profiles, topics and many things else. Our model is very effective since it combines four important factors in scientific publications: content, publicity, impact and randomness. Particularly, a recommendation system (called SciRecSys) has been presented to support users to efficiently find out relevant articles.", "subjects": "Digital Libraries (cs.DL)", "authors": "Vu Le Anh, Vo Hoang Hai, Hung Nghiep Tran, Jason J. Jung,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.08030", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.08030", "title": "\nAuthor Name Disambiguation by Using Deep Neural Network", "abstract": "Author name ambiguity decreases the quality and reliability of information retrieved from digital libraries. Existing methods have tried to solve this problem by predefining a feature set based on expert's knowledge for a specific dataset. In this paper, we propose a new approach which uses deep neural network to learn features automatically from data. Additionally, we propose the general system architecture for author name disambiguation on any dataset. In this research, we evaluate the proposed method on a dataset containing Vietnamese author names. The results show that this method significantly outperforms other methods that use predefined feature set. The proposed method achieves 99.31% in terms of accuracy. Prediction error rate decreases from 1.83% to 0.69%, i.e., it decreases by 1.14%, or 62.3% relatively compared with other methods that use predefined feature set (Table 3).", "subjects": "Digital Libraries (cs.DL)", "authors": "Hung Nghiep Tran, Tin Huynh, Tien Do,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.08010", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.08010", "title": "\nTropical differential equations", "abstract": "Tropical differential equations are introduced and an algorithm is designed which tests solvability of a system of tropical linear differential equations within the complexity polynomial in the size of the system and in its coefficients. Moreover, we show that there exists a minimal solution, and the algorithm constructs it (in case of solvability). This extends a similar complexity bound established for tropical linear systems. In case of tropical linear differential systems in one variable a polynomial complexity algorithm for testing its solvability is designed. We prove also that the problem of solvability of a system of tropical non-linear differential equations in one variable is -hard, and this problem for arbitrary number of variables belongs to . Similar to tropical algebraic equations, a tropical differential equation expresses the (necessary) condition on the dominant term in the issue of solvability of a differential equation in power series.", "subjects": "Symbolic Computation (cs.SC)", "authors": "Dima Grigoriev,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.08009", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.08009", "title": "\nSecond-order Quantile Methods for Experts and Combinatorial Games", "abstract": "We aim to design strategies for sequential decision making that adjust to the difficulty of the learning problem. We study this question both in the setting of prediction with expert advice, and for more general combinatorial decision tasks. We are not satisfied with just guaranteeing minimax regret rates, but we want our algorithms to perform significantly better on easy data. Two popular ways to formalize such adaptivity are second-order regret bounds and quantile bounds. The underlying notions of 'easy data', which may be paraphrased as \"the learning problem has small variance\" and \"multiple decisions are useful\", are synergetic. But even though there are sophisticated algorithms that exploit one of the two, no existing algorithm is able to adapt to both. In this paper we outline a new method for obtaining such adaptive algorithms, based on a potential function that aggregates a range of learning rates (which are essential tuning parameters). By choosing the right prior we construct efficient algorithms and show that they reap both benefits by proving the first bounds that are both second-order and incorporate quantiles.", "subjects": "Learning (cs.LG)", "authors": "Wouter M. Koolen, Tim van Erven,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.08008", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.08008", "title": "\nOptimizing a Certified Proof Checker for a Large-Scale  Computer-Generated Proof", "abstract": "In recent work, we formalized the theory of optimal-size sorting networks with the goal of extracting a verified checker for the large-scale computer-generated proof that 25 comparisons are optimal when sorting 9 inputs, which required more than a decade of CPU time and produced 27 GB of proof witnesses. The checker uses an untrusted oracle based on these witnesses and is able to verify the smaller case of 8 inputs within a couple of days, but it did not scale to the full proof for 9 inputs. In this paper, we describe several non-trivial optimizations of the algorithm in the checker, obtained by appropriately changing the formalization and capitalizing on the symbiosis with an adequate implementation of the oracle. We provide experimental evidence of orders of magnitude improvements to both runtime and memory footprint for 8 inputs, and actually manage to check the full proof for 9 inputs.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Lu\u00eds Cruz-Filipe, Peter Schneider-Kamp,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07999", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07999", "title": "\nOn the Energy Complexity of LDPC Decoder Circuits", "abstract": "It is shown that in a sequence of randomly generated bipartite configurations with number of left nodes approaching infinity, the probability that a particular configuration in the sequence has a minimum bisection width proportional to the number of vertices in the configuration approaches so long as a sufficient condition on the node degree distribution is satisfied. This graph theory result implies an almost sure scaling rule for the energy of capacity-approaching LDPC decoder circuits that directly instantiate their Tanner Graphs and are generated according to a uniform configuration model, where is the block length of the code. For a sequence of circuits that have a full set of check nodes but do not necessarily directly instantiate a Tanner graph, this implies an scaling rule. In another theorem, it is shown that all (as opposed to almost all) capacity-approaching LDPC decoding circuits that directly implement their Tanner graphs must have energy that scales as . These results further imply scaling rules for the energy of LDPC decoder circuits as a function of gap to capacity.", "subjects": "Information Theory (cs.IT)", "authors": "Christopher Blake, Frank R. Kschischang,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07996", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07996", "title": "\nSparse Time-Frequency Representation for Signals with Fast Varying  Instantaneous Frequency", "abstract": "Time-frequency distributions have been used to provide high resolution representation in a large number of signal processing applications. However, high resolution and accurate instantaneous frequency (IF) estimation usually depend on the employed distribution and complexity of signal phase function. To ensure an efficient IF tracking for various types of signals, the class of complex time distributions has been developed. These distributions facilitate analysis in the cases when standard distributions cannot provide satisfactory results (e.g., for highly nonstationary signal phase). In that sense, an ambiguity based form of the forth order complex-time distribution is considered, in a new compressive sensing (CS) context. CS is an intensively growing approach in signal processing that allows efficient analysis and reconstruction of randomly undersampled signals. In this paper, the randomly chosen ambiguity domain coefficients serve as CS measurements. By exploiting sparsity in the time-frequency plane, it is possible to obtain highly concentrated IF using just small number of random coefficients from ambiguity domain. Moreover, in noisy signal case, this CS approach can be efficiently combined with the L-statistics producing robust time-frequency representations. Noisy coefficients are firstly removed using the L-statistics and then reconstructed by using CS algorithm. The theoretical considerations are illustrated using experimental results.", "subjects": "Information Theory (cs.IT)", "authors": "Irena Orovic, Andjela Draganic, Srdjan Stankovic,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07994", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07994", "title": "\nAn Effective Private Data storage and Retrieval System using Secret  sharing scheme based on Secure Multi-party Computation", "abstract": "Privacy of the outsourced data is one of the major challenge.Insecurity of the network environment and untrustworthiness of the service providers are obstacles of making the database as a service.Collection and storage of personally identifiable information is a major privacy concern.On-line public databases and resources pose a significant risk to user privacy, since a malicious database owner may monitor user queries and infer useful information about the customer.The challenge in data privacy is to share data with third-party and at the same time securing the valuable information from unauthorized access and use by third party.A Private Information Retrieval(PIR) scheme allows a user to query database while hiding the identity of the data retrieved.The naive solution for confidentiality is to encrypt data before outsourcing.Query execution,key management and statistical inference are major challenges in this case.The proposed system suggests a mechanism for secure storage and retrieval of private data using the secret sharing technique.The idea is to develop a mechanism to store private information with a highly available storage provider which could be accessed from anywhere using queries while hiding the actual data values from the storage provider.The private information retrieval system is implemented using Secure Multi-party Computation(SMC) technique which is based on secret sharing. Multi-party Computation enable parties to compute some joint function over their private inputs.The query results are obtained by performing a secure computation on the shares owned by the different servers.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Divya G. Nair, V. P. Binu, G. Santhosh Kumar,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07993", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07993", "title": "\nSecret Image Sharing Based CTS with Cheating Detection", "abstract": "Cheque Truncation System(CTS) is an automatic cheque clearance system implemented by RBI.CTS uses cheque image, instead of the physical cheque itself, for cheque clearance thus reducing the turn around time drastically. This approach holds back the physical movement of cheque from presenting bank to the drawee bank. In CTS, digital image of the cheque is protected using standard public key and symmetric key encryptions like RSA, triple DES etc. This involves a lot of computation overhead and key management. The security also depends on the hard mathematical problem and is only computationally secure.Information theoretically secure, secret image sharing techniques can be used in the CTS for the secure and efficient processing of cheque image .In this paper, we propose two simple and efficient secret image sharing schemes and a Cheque Truncation System based on these algorithms . In the proposed scheme,the presenting bank is acting as the dealer and the participants are the customer, and the drawee bank.The dealer should generate the shares of cheque and distributes it to customer and drawee bank.The validity of the shares are important during the reconstruction process. The proposed scheme also suggests a method for cheating detection which identify any invalid shares submitted by the customers, using the hashing technique. The experimental results shows that the proposed scheme is efficient and secure compared with the existing scheme.", "subjects": "Cryptography and Security (cs.CR)", "authors": "S. R. Sreela, G. Santhosh Kumar, V. P. Binu,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07990", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07990", "title": "\nInfinigons of the hyperbolic plane and grossone", "abstract": "In this paper, we study the contribution of the theory of grossone to the study of infinigons in the hyperbolic plane. We can see that the theory of grossone can help us to obtain much more classification for these objects than in the traditional setting.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Maurice Margenstern,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.07979", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07979", "title": "\nTopological Properties and Temporal Dynamics of Place Networks in Urban  Environments", "abstract": "Understanding the spatial networks formed by the trajectories of mobile users can be beneficial to applications ranging from epidemiology to local search. Despite the potential for impact in a number of fields, several aspects of human mobility networks remain largely unexplored due to the lack of large-scale data at a fine spatiotemporal resolution. Using a longitudinal dataset from the location-based service Foursquare, we perform an empirical analysis of the topological properties of place networks and note their resemblance to online social networks in terms of heavy-tailed degree distributions, triadic closure mechanisms and the small world property. Unlike social networks however, place networks present a mixture of connectivity trends in terms of assortativity that are surprisingly similar to those of the web graph. We take advantage of additional semantic information to interpret how nodes that take on functional roles such as `travel hub', or `food spot' behave in these networks. Finally, motivated by the large volume of new links appearing in place networks over time, we formulate the classic link prediction problem in this new domain. We propose a novel variant of gravity models that brings together three essential elements of inter-place connectivity in urban environments: network-level interactions, human mobility dynamics, and geographic distance. We evaluate this model and find it outperforms a number of baseline predictors and supervised learning algorithms on a task of predicting new links in a sample of one hundred popular cities.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Anastasios Noulas, Blake Shaw, Renaud Lambiotte, Cecilia Mascolo,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.07976", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07976", "title": "\nError-Correcting Factorization", "abstract": "Error Correcting Output Codes (ECOC) is a successful technique in multi-class classification, which is a core problem in Pattern Recognition and Machine Learning. A major advantage of ECOC over other methods is that the multi- class problem is decoupled into a set of binary problems that are solved independently. However, literature defines a general error-correcting capability for ECOCs without analyzing how it distributes among classes, hindering a deeper analysis of pair-wise error-correction. To address these limitations this paper proposes an Error-Correcting Factorization (ECF) method, our contribution is three fold: (I) We propose a novel representation of the error-correction capability, called the design matrix, that enables us to build an ECOC on the basis of allocating correction to pairs of classes. (II) We derive the optimal code length of an ECOC using rank properties of the design matrix. (III) ECF is formulated as a discrete optimization problem, and a relaxed solution is found using an efficient constrained block coordinate descent approach. (IV) Enabled by the flexibility introduced with the design matrix we propose to allocate the error-correction on classes that are prone to confusion. Experimental results in several databases show that when allocating the error-correction to confusable classes ECF outperforms state-of-the-art approaches.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Miguel Angel Bautista, Oriol Pujol, Fernando de la Torre, Sergio Escalera,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.07974", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07974", "title": "\nA Convex Feasibility Approach to Anytime Model Predictive Control", "abstract": "This paper proposes to decouple performance optimization and enforcement of asymptotic convergence in Model Predictive Control (MPC) so that convergence to a given terminal set is achieved independently of how much performance is optimized at each sampling step. By embedding an explicit decreasing condition in the MPC constraints and thanks to a novel and very easy-to-implement convex feasibility solver proposed in the paper, it is possible to run an outer performance optimization algorithm on top of the feasibility solver and optimize for an amount of time that depends on the available CPU resources within the current sampling step (possibly going open-loop at a given sampling step in the extreme case no resources are available) and still guarantee convergence to the terminal set. While the MPC setup and the solver proposed in the paper can deal with quite general classes of functions, we highlight the synthesis method and show numerical results in case of linear MPC and ellipsoidal and polyhedral terminal sets.", "subjects": "Systems and Control (cs.SY)", "authors": "Alberto Bemporad, Daniele Bernardini, Panagiotis Patrinos,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07966", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07966", "title": "\nDelay-Aware Uplink Fronthaul Allocation in Cloud Radio Access Networks", "abstract": "In cloud radio access networks (C-RANs), the baseband units and radio units of base stations are separated, which requires high-capacity fronthaul links connecting both parts. In this paper, we consider the delay-aware fronthaul allocation problem for C-RANs. The stochastic optimization problem is formulated as an infinite horizon average cost Markov decision process. To deal with the curse of dimensionality, we derive a closed-form approximate priority function and the associated error bound using perturbation analysis. Based on the closed-form approximate priority function, we propose a low-complexity delay-aware fronthaul allocation algorithm solving the per-stage optimization problem. The proposed solution is further shown to be asymptotically optimal for sufficiently small cross link path gains. Finally, the proposed fronthaul allocation algorithm is compared with various baselines through simulations, and it is shown that significant performance gain can be achieved.", "subjects": "Information Theory (cs.IT)", "authors": "Wei Wang, Vincent K. N. Lau, Mugen Peng,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07948", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07948", "title": "\nQuerying Spreadsheets: An Empirical Study", "abstract": "One of the most important assets of any company is being able to easily access information on itself and on its business. In this line, it has been observed that this important information is often stored in one of the millions of spreadsheets created every year, due to simplicity in using and manipulating such an artifact. Unfortunately, in many cases it is quite difficult to retrieve the intended information from a spreadsheet: information is often stored in a huge unstructured matrix, with no care for readability or comprehensiveness. In an attempt to aid users in the task of extracting information from a spreadsheet, researchers have been working on models, languages and tools to query. In this paper we present an empirical study evaluating such proposals assessing their usage to query spreadsheets. We investigate the use of the Google Query Function, textual model-driven querying, and visual model-driven querying. To compare these different querying approaches we present an empirical study whose results show that the end-users' productivity increases when using model-driven queries, specially using its visual representation.", "subjects": "Software Engineering (cs.SE)", "authors": "J\u00e1come Cunha, Jo\u00e3o Paulo Fernandes, Rui Pereira, Jo\u00e3o Saraiva,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07943", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07943", "title": "\nNon-stochastic Best Arm Identification and Hyperparameter Optimization", "abstract": "Motivated by the task of hyperparameter optimization, we introduce the non-stochastic best-arm identification problem. Within the multi-armed bandit literature, the cumulative regret objective enjoys algorithms and analyses for both the non-stochastic and stochastic settings while to the best of our knowledge, the best-arm identification framework has only been considered in the stochastic setting. We introduce the non-stochastic setting under this framework, identify a known algorithm that is well-suited for this setting, and analyze its behavior. Next, by leveraging the iterative nature of standard machine learning algorithms, we cast hyperparameter optimization as an instance of non-stochastic best-arm identification, and empirically evaluate our proposed algorithm on this task. Our empirical results show that, by allocating more resources to promising hyperparameter settings, we typically achieve comparable test accuracies an order of magnitude faster than baseline methods.", "subjects": "Learning (cs.LG)", "authors": "Kevin Jamieson, Ameet Talwalkar,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07939", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07939", "title": "\nCoding local and global binary visual features extracted from video  sequences", "abstract": "Binary local features represent an effective alternative to real-valued descriptors, leading to comparable results for many visual analysis tasks, while being characterized by significantly lower computational complexity and memory requirements. When dealing with large collections, a more compact representation based on global features is often preferred, which can be obtained from local features by means of, e.g., the Bag-of-Visual-Word (BoVW) model. Several applications, including for example visual sensor networks and mobile augmented reality, require visual features to be transmitted over a bandwidth-limited network, thus calling for coding techniques that aim at reducing the required bit budget, while attaining a target level of efficiency. In this paper we investigate a coding scheme tailored to both local and global binary features, which aims at exploiting both spatial and temporal redundancy by means of intra- and inter-frame coding. In this respect, the proposed coding scheme can be conveniently adopted to support the Analyze-Then-Compress (ATC) paradigm. That is, visual features are extracted from the acquired content, encoded at remote nodes, and finally transmitted to a central controller that performs visual analysis. This is in contrast with the traditional approach, in which visual content is acquired at a node, compressed and then sent to a central unit for further processing, according to the Compress-Then-Analyze (CTA) paradigm. In this paper we experimentally compare ATC and CTA by means of rate-efficiency curves in the context of two different visual analysis tasks: homography estimation and content-based retrieval. Our results show that the novel ATC paradigm based on the proposed coding primitives can be competitive with CTA, especially in bandwidth limited scenarios.", "subjects": "Multimedia (cs.MM)", "authors": "Luca Baroffio, Antonio Canclini, Matteo Cesana, Alessandro Redondi, Marco Tagliasacchi, Stefano Tubaro,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07938", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07938", "title": "\nDocument Clustering using K-Means and K-Medoids", "abstract": "With the huge upsurge of information in day-to-days life, it has become difficult to assemble relevant information in nick of time. But people, always are in dearth of time, they need everything quick. Hence clustering was introduced to gather the relevant information in a cluster. There are several algorithms for clustering information out of which in this paper, we accomplish K-means and K-Medoids clustering algorithm and a comparison is carried out to find which algorithm is best for clustering. On the best clusters formed, document summarization is executed based on sentence weight to focus on key point of the whole document, which makes it easier for people to ascertain the information they want and thus read only those documents which is relevant in their point of view.", "subjects": "Information Retrieval (cs.IR)", "authors": "Rakesh Chandra Balabantaray, Chandrali Sarma, Monica Jha,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07930", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07930", "title": "\nCombinatorial approximation of maximum $k$-vertex cover in bipartite  graphs within ratio~0.7", "abstract": "We propose a textit for mkvc in bipartite graphs, achieving approximation ratio~0.7. The only combinatorial algorithms currently known until now for this problem are the natural greedy algorithm, that achieves ratio 0.632, and an easy~-approximation algorithm presented in cite.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Vangelis Th. Paschos,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.07926", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07926", "title": "\nData-Driven Robust Receding Horizon Fault Estimation", "abstract": "This paper presents a data-driven receding horizon fault estimation method for additive actuator and sensor faults in unknown linear time-invariant systems, with enhanced robustness to stochastic identification errors. State-of-the-art methods construct fault estimators with identified state-space models or Markov parameters, but they do not compensate for identification errors. Motivated by this limitation, we first propose a receding horizon fault estimator parameterized by predictor Markov parameters. This estimator provides (asymptotically) unbiased fault estimates as long as the subsystem from faults to outputs has no unstable transmission zeros. When the identified Markov parameters are used to construct the above fault estimator, zero-mean stochastic identification errors appear as model uncertainty multiplied with unknown fault signals and online system inputs/outputs (I/O). Based on this fault estimation error analysis, we formulate a mixed-norm problem for the offline robust design that regards online I/O data as unknown. An alternative online mixed-norm problem is also proposed that can further reduce estimation errors when the online I/O data have large amplitudes, at the cost of increased computational burden. Based on a geometrical interpretation of the two proposed mixed-norm problems, systematic methods to tune the user-defined parameters therein are given to achieve desired performance trade-offs. Simulation examples illustrate the benefits of our proposed methods compared to recent literature.", "subjects": "Systems and Control (cs.SY)", "authors": "Yiming Wan, Tamas Keviczky, Michel Verhaegen, Fredrik Gustafsson,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07920", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07920", "title": "\nLocal Translation Prediction with Global Sentence Representation", "abstract": "Statistical machine translation models have made great progress in improving the translation quality. However, the existing models predict the target translation with only the source- and target-side local context information. In practice, distinguishing good translations from bad ones does not only depend on the local features, but also rely on the global sentence-level information. In this paper, we explore the source-side global sentence-level features for target-side local translation prediction. We propose a novel bilingually-constrained chunk-based convolutional neural network to learn sentence semantic representations. With the sentence-level feature representation, we further design a feed-forward neural network to better predict translations using both local and global information. The large-scale experiments show that our method can obtain substantial improvements in translation quality over the strong baseline: the hierarchical phrase-based translation model augmented with the neural network joint model.", "subjects": "Computation and Language (cs.CL)", "authors": "Jiajun Zhang,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07889", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07889", "title": "\nExpressiveness of the modal mu-calculus on monotone neighborhood  structures", "abstract": "We characterize the expressive power of the modal mu-calculus on monotone neighborhood structures, in the style of the Janin-Walukiewicz theorem for the standard modal mu-calculus. For this purpose we consider a monadic second-order logic for monotone neighborhood structures. Our main result shows that the monotone modal mu-calculus corresponds exactly to the fragment of this second-order language that is invariant for neighborhood bisimulations.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Sebastian Enqvist, Fatemeh Seifan, Yde Venema,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07888", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07888", "title": "\nIs Nearly-linear the same in Theory and Practice? A Case Study with a  Combinatorial Laplacian Solver", "abstract": "Linear system solving is one of the main workhorses in applied mathematics. Recently, theoretical computer scientists have contributed sophisticated algorithms for solving linear systems with symmetric diagonally dominant matrices (a class to which Laplacian matrices belong) in provably nearly-linear time. While these algorithms are highly interesting from a theoretical perspective, there are no published results how they perform in practice. With this paper we address this gap. We provide the first implementation of the combinatorial solver by [Kelner et al., STOC 2013], which is particularly appealing for implementation due to its conceptual simplicity. The algorithm exploits that a Laplacian matrix corresponds to a graph; solving Laplacian linear systems amounts to finding an electrical flow in this graph with the help of cycles induced by a spanning tree with the low-stretch property. The results of our comprehensive experimental study are ambivalent. They confirm a nearly-linear running time, but for reasonable inputs the constant factors make the solver much slower than methods with higher asymptotic complexity. One other aspect predicted by theory is confirmed by our findings, though: Spanning trees with lower stretch indeed reduce the solver's running time. Yet, simple spanning tree algorithms perform in practice better than those with a guaranteed low stretch.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Daniel Hoske, Dimitar Lukarski, Henning Meyerhenke, Michael Wegner,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07870", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07870", "title": "\nInferring an Indeterminate String from a Prefix Graph", "abstract": "An itbf (or, more simply, just a itbf) on an alphabet is a sequence of nonempty subsets of . We say that and itbf (written ) if and only if . A itbf is an array of integers such that and for every , . A itbf of a string is an array of integers such that, for every , if and only if is the longest substring at position of s that matches a prefix of s. It is known from cite that every feasible array is a prefix table of some indetermintate string. A itbf is a labelled simple graph whose structure is determined by a feasible array s. In this paper we show, given a feasible array s, how to use to construct a lexicographically least indeterminate string on a minimum alphabet whose prefix table .", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Ali Alatabbi, M. Sohel Rahman, W. F. Smyth,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07847", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07847", "title": "\nThe QC Relaxation: Theoretical and Computational Results on Optimal  Power Flow", "abstract": "Convex relaxations of the power flow equations and, in particular, the Semi-Definite Programming (SDP) and Second-Order Cone (SOC) relaxations, have attracted significant interest in recent years. The Quadratic Convex (QC) relaxation is a departure from these relaxations in the sense that it imposes constraints to preserve stronger links between the voltage variables through convex envelopes of the polar representation. This paper is a systematic study of the QC relaxation for AC Optimal Power Flow with realistic side constraints. The main theoretical result shows that the QC relaxation is stronger than the SOC relaxation and neither dominates nor is dominated by the SDP relaxation. In addition, comprehensive computational results show that the QC relaxation may produce significant improvements in accuracy over the SOC relaxation at a reasonable computational cost, especially for networks with tight bounds on phase angle differences. The QC and SOC relaxations are also shown to be significantly faster and reliable compared to the SDP relaxation given the current state of the respective solvers.", "subjects": "Computational Engineering, Finance, and Science (cs.CE)", "authors": "Carleton Coffrin, Hassan L. Hijazi, Pascal Van Hentenryck,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07839", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07839", "title": "\nDAWN: Delay-Aware Wi-Fi Offloading and Network Selection", "abstract": "To accommodate the explosive growth in mobile data traffic, both mobile cellular operators and mobile users are increasingly interested in offloading the traffic from cellular networks to Wi-Fi networks. However, previously proposed offloading schemes mainly focus on reducing the cellular data usage, without paying too much attention on the quality of service (QoS) requirements of the applications. In this paper, we study the Wi-Fi offloading problem with delay-tolerant applications under usage-based pricing. We aim to achieve a good tradeoff between the user's payment and its QoS characterized by the file transfer deadline. We first propose a general Delay-Aware Wi-Fi Offloading and Network Selection (DAWN) algorithm for a general single-user decision scenario. We then analytically establish the sufficient conditions, under which the optimal policy exhibits a threshold structure in terms of both the time and file size. As a result, we propose a monotone DAWN algorithm that approximately solves the general offloading problem, and has a much lower computational complexity comparing to the optimal algorithm. Simulation results show that both the general and monotone DAWN schemes achieve a high probability of completing file transfer under a stringent deadline, and require the lowest payment under a non-stringent deadline as compared with three heuristic schemes.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Man Hon Cheung, Jianwei Huang,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07830", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07830", "title": "\nFile Updates Under Random/Arbitrary Insertions And Deletions", "abstract": "A client/encoder edits a file, as modeled by an insertion-deletion (InDel) process. An old copy of the file is stored remotely at a data-centre/decoder, and is also available to the client. We consider the problem of throughput- and computationally-efficient communication from the client to the data-centre, to enable the server to update its copy to the newly edited file. We study two models for the source files/edit patterns: the random pre-edit sequence left-to-right random InDel (RPES-LtRRID) process, and the arbitrary pre-edit sequence arbitrary InDel (APES-AID) process. In both models, we consider the regime in which the number of insertions/deletions is a small (but constant) fraction of the original file. For both models we prove information-theoretic lower bounds on the best possible compression rates that enable file updates. Conversely, our compression algorithms use dynamic programming (DP) and entropy coding, and achieve rates that are approximately optimal.", "subjects": "Information Theory (cs.IT)", "authors": "Qiwen Wang, Viveck Cadambe, Sidharth Jaggi, Moshe Schwartz, Muriel M\u00e9dard,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07828", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07828", "title": "\nHybrid coding of visual content and local image features", "abstract": "Distributed visual analysis applications, such as mobile visual search or Visual Sensor Networks (VSNs) require the transmission of visual content on a bandwidth-limited network, from a peripheral node to a processing unit. Traditionally, a Compress-Then-Analyze approach has been pursued, in which sensing nodes acquire and encode the pixel-level representation of the visual content, that is subsequently transmitted to a sink node in order to be processed. This approach might not represent the most effective solution, since several analysis applications leverage a compact representation of the content, thus resulting in an inefficient usage of network resources. Furthermore, coding artifacts might significantly impact the accuracy of the visual task at hand. To tackle such limitations, an orthogonal approach named Analyze-Then-Compress has been proposed. According to such a paradigm, sensing nodes are responsible for the extraction of visual features, that are encoded and transmitted to a sink node for further processing. In spite of improved task efficiency, such paradigm implies the central processing node not being able to reconstruct a pixel-level representation of the visual content. In this paper we propose an effective compromise between the two paradigms, namely Hybrid-Analyze-Then-Compress (HATC) that aims at jointly encoding visual content and local image features. Furthermore, we show how a target tradeoff between image quality and task accuracy might be achieved by accurately allocating the bitrate to either visual content or local features.", "subjects": "Multimedia (cs.MM)", "authors": "Luca Baroffio, Matteo Cesana, Alessandro Redondi, Marco Tagliasacchi, Stefano Tubaro,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07823", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07823", "title": "\nCoalition manipulations of the Gale-Shapley algorithm", "abstract": "It is well-known that the Gale-Shapley algorithm is not truthful for all agents. Previous studies on this front mostly focus on blacklist manipulations by a single woman and by the set of all women. Little is known about manipulations by a coalition of women or other types of manipulations, such as manipulation by permuting preference lists. In this paper, we consider the problem of finding an equilibrium for a coalition of women (aka. liars) in the Gale-Shapley algorithm. We restrict attentions on manipulations that induce stable matchings. For the incomplete preference list setting, where liars can truncate their preference lists, we show that a strong Nash equilibrium always exists and the matching from such equilibria is unique. The equilibrium outcome is strongly Pareto dominant for all liars among the set of matchings achievable by manipulation: every woman is matched with the same man as the one she matches in her best single-agent manipulation. For the complete preference list setting where liars can permute their preference list, we first show that a coalition of women can get worse off by manipulating jointly than each performing a single-agent manipulation, thus a strongly Pareto-dominant outcome may not exist by manipulation. We then put forward an efficient algorithm to compute a strong Nash equilibrium that is strongly Pareto-optimal for all liars. We derive connections between the stable marriage problem and stable roommate problem, and use tools there to prove our results for this part. This approach is highly nontrivial and of independent interest.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Yuan Deng, Weiran Shen, Pingzhong Tang,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07813", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07813", "title": "\nMinimum message length estimation of mixtures of multivariate Gaussian  and von Mises-Fisher distributions", "abstract": "Mixture modelling involves explaining some observed evidence using a combination of probability distributions. The crux of the problem is the inference of an optimal number of mixture components and their corresponding parameters. This paper discusses unsupervised learning of mixture models using the Bayesian Minimum Message Length (MML) criterion. To demonstrate the effectiveness of search and inference of mixture parameters using the proposed approach, we select two key probability distributions, each handling fundamentally different types of data: the multivariate Gaussian distribution to address mixture modelling of data distributed in Euclidean space, and the multivariate von Mises-Fisher (vMF) distribution to address mixture modelling of directional data distributed on a unit hypersphere. The key contributions of this paper, in addition to the general search and inference methodology, include the derivation of MML expressions for encoding the data using multivariate Gaussian and von Mises-Fisher distributions, and the analytical derivation of the MML estimates of the parameters of the two distributions. Our approach is tested on simulated and real world data sets. For instance, we infer vMF mixtures that concisely explain experimentally determined three-dimensional protein conformations, providing an effective null model description of protein structures that is central to many inference problems in structural bioinformatics. The experimental results demonstrate that the performance of our proposed search and inference method along with the encoding schemes improve on the state of the art mixture modelling techniques.", "subjects": "Learning (cs.LG)", "authors": "Parthan Kasarapu, Lloyd Allison,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07812", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07812", "title": "\nAnonymous HIBE with Short Ciphertexts: Full Security in Prime Order  Groups", "abstract": "Anonymous Hierarchical Identity-Based Encryption (HIBE) is an extension of Identity-Based Encryption (IBE), and it provides not only a message hiding property but also an identity hiding property. Anonymous HIBE schemes can be applicable to anonymous communication systems and public key encryption systems with keyword searching. However, previous anonymous HIBE schemes have some disadvantages that the security was proven in the weaker model, the size of ciphertexts is not short, or the construction was based on composite order bilinear groups. In this paper, we propose the first efficient anonymous HIBE scheme with short ciphertexts in prime order (asymmetric) bilinear groups, and prove its security in the full model with an efficient reduction. To achieve this, we use the dual system encryption methodology of Waters. We also present the benchmark results of our scheme by measuring the performance of our implementation.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Kwangsu Lee, Jong Hwan Park, Dong Hoon Lee,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07809", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07809", "title": "\nOptimal Energy-Efficient Regular Delivery of Packets in Cyber-Physical  Systems", "abstract": "In cyber-physical systems such as in-vehicle wireless sensor networks, a large number of sensor nodes continually generate measurements that should be received by other nodes such as actuators in a regular fashion. Meanwhile, energy-efficiency is also important in wireless sensor networks. Motivated by these, we develop scheduling policies which are energy efficient and simultaneously maintain \"regular\" deliveries of packets. A tradeoff parameter is introduced to balance these two conflicting objectives. We employ a Markov Decision Process (MDP) model where the state of each client is the time-since-last-delivery of its packet, and reduce it into an equivalent finite-state MDP problem. Although this equivalent problem can be solved by standard dynamic programming techniques, it suffers from a high-computational complexity. Thus we further pose the problem as a restless multi-armed bandit problem and employ the low-complexity Whittle Index policy. It is shown that this problem is indexable and the Whittle indexes are derived. Also, we prove the Whittle Index policy is asymptotically optimal and validate its optimality via extensive simulations.", "subjects": "Systems and Control (cs.SY)", "authors": "Xueying Guo, Rahul Singh, P.R. Kumar, Zhisheng Niu,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07808", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07808", "title": "\nA Secure Cyclic Steganographic Technique for Color Images using  Randomization", "abstract": "Information Security is a major concern in today's modern era. Almost all the communicating bodies want the security, confidentiality and integrity of their personal data. But this security goal cannot be achieved easily when we are using an open network like Internet. Steganography provides one of the best solutions to this problem. This paper represents a new Cyclic Steganographic T echnique (CST) based on Least Significant Bit (LSB) for true color (RGB) images. The proposed method hides the secret data in the LSBs of cover image pixels in a randomized cyclic manner. The proposed technique is evaluated using both subjective and objective analysis using histograms changeability, Peak Signal-to-Noise Ratio (PSNR) and Mean Square Error (MSE). Experimentally it is found that the proposed method gives promising results in terms of security, imperceptibility and robustness as compared to some existent methods and vindicates this new algorithm.", "subjects": "Multimedia (cs.MM)", "authors": "Khan Muhammad, Jamil Ahmad, Naeem Ur Rehman, Zahoor Jan, Rashid Jalal Qureshi,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07802", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07802", "title": "\nModelling Local Deep Convolutional Neural Network Features to Improve  Fine-Grained Image Classification", "abstract": "We propose a local modelling approach using deep convolutional neural networks (CNNs) for fine-grained image classification. Recently, deep CNNs trained from large datasets have considerably improved the performance of object recognition. However, to date there has been limited work using these deep CNNs as local feature extractors. This partly stems from CNNs having internal representations which are high dimensional, thereby making such representations difficult to model using stochastic models. To overcome this issue, we propose to reduce the dimensionality of one of the internal fully connected layers, in conjunction with layer-restricted retraining to avoid retraining the entire network. The distribution of low-dimensional features obtained from the modified layer is then modelled using a Gaussian mixture model. Comparative experiments show that considerable performance improvements can be achieved on the challenging Fish and UEC FOOD-100 datasets.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "ZongYuan Ge, Chris McCool, Conrad Sanderson, Peter Corke,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07796", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07796", "title": "\nGraph Grammars, Insertion Lie Algebras, and Quantum Field Theory", "abstract": "Graph grammars extend the theory of formal languages in order to model distributed parallelism in theoretical computer science. We show here that to certain classes of context-free and context-sensitive graph grammars one can associate a Lie algebra, whose structure is reminiscent of the insertion Lie algebras of quantum field theory. We also show that the Feynman graphs of quantum field theories are graph languages generated by a theory dependent graph grammar.", "subjects": "Formal Languages and Automata Theory (cs.FL)", "authors": "Matilde Marcolli, Alexander Port,", "date": "2015-2-27"}, 
{"urllink": "http://arxiv.org/abs/1502.07792", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07792", "title": "\nVisualizing Cartograms: Goals and Task Taxonomy", "abstract": "Cartograms are maps in which areas of geographic regions (countries, states) appear in proportion to some variable of interest (population, income). Cartograms are popular visualizations for geo-referenced data that have been around for over a century. Newspapers, magazines, textbooks, blogs, and presentations frequently employ cartograms to show voting results, popularity, and in general, geographic patterns. Despite the popularity of cartograms and the large number of cartogram variants, there are very few studies evaluating the effectiveness of cartograms in conveying information. In order to design cartograms as a useful visualization tool and to be able to compare the effectiveness of cartograms generated by different methods, we need to study the nature of information conveyed and the specific tasks that can be performed on cartograms. In this paper we consider a set of cartogram visualization tasks, based on standard taxonomies from cartography and information visualization. We then propose a cartogram task taxonomy that can be used to organize not only the tasks considered here but also other tasks that might be added later.", "subjects": "Human-Computer Interaction (cs.HC)", "authors": "Sabrina Nusrat, Stephen Kobourov,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07790", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07790", "title": "\nExploiting Coplanar Clusters to Enhance 3D Localization in Wireless  Sensor Networks", "abstract": "This thesis studies range-based WSN localization problem in 3D environments that induce coplanarity. In most real-world applications, even though the environment is 3D, the grounded sensor nodes are usually deployed on 2D planar surfaces. Examples of these surfaces include structures seen in both indoor (e.g. floors, doors, walls, tables etc.) and outdoor (e.g. mountains, valleys, hills etc.) environments. In such environments, sensor nodes typically appear as coplanar node clusters. We refer to this type of a deployment as a planar deployment. When there is a planar deployment, the coplanarity causes difficulties to the traditional range-based multilateration algorithms because a node cannot be unambiguously localized if the distance measurements to that node are from coplanar nodes. Thus, many already localized groups of nodes are rendered ineffective in the process just because they are coplanar. We, therefore propose an algorithm called Coplanarity Based Localization (CBL) that can be used as an extension of any localization algorithm to avoid most flips caused by coplanarity. CBL first performs a 2D localization among the nodes that are clustered on the same surface, and then finds the positions of these clusters in 3D. We have carried out experiments using trilateration for 2D localization, and quadrilateration for 3D localization, and experimentally verified that exploiting the clustering information leads to a more precise localization than mere quadrilateration. We also propose a heuristic to extract the clustering information in case it is not available, which is yet to be improved in the future.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Onur Cagirici,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.07788", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07788", "title": "\nAnalysis of Gradient based Algorithm for Signal reconstruction in the  Presence of Noise", "abstract": "Common problem in signal processing is reconstruction of the missing signal samples. Missing samples can occur by intentionally omitting signal coefficients to reduce memory requirements, or to speed up the transmission process. Also, noisy signal coefficients can be considered as missing ones, since they have wrong values due to the noise. The reconstruction of these coefficients is demanding task, considered within the Compressive sensing area. Signal with large number of missing samples can be recovered, if certain conditions are satisfied. There is a number of algorithms used for signal reconstruction. In this paper we have analyzed the performance of iterative gradient-based algorithm for sparse signal reconstruction. The parameters influence on the optimal performances of this algorithm is tested. Two cases are observed: non-noisy and noisy signal case.", "subjects": "Information Theory (cs.IT)", "authors": "Slavoljub Joki\u0107, Ljindita Nikovi\u0107, Jelena Kadovi\u0107,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07787", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07787", "title": "\nProduct Measure Approximation of Symmetric Graph Properties", "abstract": "In the study of random structures we often face a trade-off between realism and tractability, the latter typically enabled by assuming some form of independence. In this work we initiate an effort to bridge this gap by developing tools that allow us to work with independence without assuming it. Let be the set of all graphs on vertices and let be an arbitrary subset of , e.g., the set of graphs with edges. The study of random networks can be seen as the study of properties that are true for most elements of , i.e., that are true with high probability for a uniformly random element of . With this in mind, we pursue the following question: What are general sufficient conditions for the uniform measure on a set of graphs to be approximable by a product measure?", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Dimitris Achlioptas, Paris Siminelakis,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07786", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07786", "title": "\nGenerating 56-bit passwords using Markov Models (and Charles Dickens)", "abstract": "We describe a password generation scheme based on Markov models built from English text (specifically, Charles Dickens' *A Tale Of Two Cities*). We show a (linear-running-time) bijection between random bitstrings of any desired length and generated text, ensuring that all passwords are generated with equal probability. We observe that the generated passwords appear to strike a reasonable balance between memorability and security. Using the system, we get 56-bit passwords like 'The cusay is wither?\" t', rather than passwords like 'tQ", "subjects": "Cryptography and Security (cs.CR)", "authors": "John Clements,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07781", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07781", "title": "\nThe conjugated null space method of blind PSF estimation and  deconvolution optimization", "abstract": "We have shown that the vector of the point spread function (PSF) lexicographical presentation belongs to the left side conjugated null space (NS) of the autoregression (AR) matrix operator on condition the AR parameters are common for original and blurred images. The method of the PSF and inverse PSF (IPSF) evaluation in the basis of the NS eigenfunctions is offered. The optimization of the PSF and IPSF shape with the aim of fluctuation elimination is considered in NS spectral domain and image space domain. The function of surface area was used as the regularization functional. Two methods of original image estimate optimization were designed basing on maximum entropy generalization of sought and blurred images conditional probability density and regularization. The first method uses balanced variations of convolutions with the PSF and IPSF to obtaining iterative schema of image optimization. The variations balance is providing by dynamic regularization basing on condition of the iteration process convergence. The regularization has dynamic character because depends on current and previous image estimate variations. The second method implements the regularization of the deconvolution optimization in curved space with metric defined on image estimate surface. The given iterative schemas have fast convergence and therefore can be used for reconstruction of high resolution images series in real time. The NS can be used for design of denoising bilateral linear filter which does not introduce image smoothing.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Yuriy A. Bunyak, Roman N. Kvetnyy, Olga Yu. Sofina,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07776", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07776", "title": "\nEfficient Geometric-based Computation of the String Subsequence Kernel", "abstract": "Kernel methods are powerful tools in machine learning. They have to be computationally efficient. In this paper, we present a novel Geometric-based approach to compute efficiently the string subsequence kernel (SSK). Our main idea is that the SSK computation reduces to range query problem. We started by the construction of a match list where and are the strings to be compared; such match list contains only the required data that contribute to the result. To compute efficiently the SSK, we extended the layered range tree data structure to a layered range sum tree, a range-aggregation data structure. The whole process takes time and space, where is the size of the match list and is the length of the SSK. We present empiric evaluations of our approach against the dynamic and the sparse programming approaches both on synthetically generated data and on newswire article data. Such experiments show the efficiency of our approach for large alphabet size except for very short strings. Moreover, compared to the sparse dynamic approach, the proposed approach outperforms absolutely for long strings.", "subjects": "Learning (cs.LG)", "authors": "Slimane Bellaouar, Hadda Cherroun, Djelloul Ziadi,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07770", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07770", "title": "\nTotal variation on a tree", "abstract": "We consider the problem of minimizing the continuous valued total variation subject to different unary terms on trees and propose fast direct algorithms based on dynamic programming to solve these problems. We treat both the convex and the non-convex case and derive worst case complexities that are equal or better then existing methods. We show applications to total variation based 2D image processing and computer vision problems based on a Lagrangian decomposition approach. The resulting algorithms are very efficient, offer a high degree of parallelism and come along with memory requirements which are only in the order of the number of image pixels.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Vladimir Kolmogorov, Thomas Pock, Michal Rolinek,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07762", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07762", "title": "\nAirborne Ultrasonic Tactile Display Brain-computer Interface -- A Small  Robotic Arm Online Control Study", "abstract": "We report on an extended robot control application of a contact-less and airborne ultrasonic tactile display (AUTD) stimulus-based brain-computer interface (BCI) paradigm, which received last year The Annual BCI Research Award 2014. In the award winning human communication augmentation paradigm the six palm positions are used to evoke somatosensory brain responses, in order to define a novel contactless tactile BCI. An example application of a small robot management is also presented in which the users control a small robot online.", "subjects": "Human-Computer Interaction (cs.HC)", "authors": "Tomasz M. Rutkowski, Hiromu Mori, Takumi Kodama, Hiroyuki Shinoda,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1502.07744", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07744", "title": "\nDistributed Diagnosability Analysis with Petri Nets", "abstract": "We propose a framework to distributed diagnos- ability analysis of concurrent systems modeled with Petri nets as a collection of components synchronizing on common observable transitions, where faults can occur in several components. The diagnosability analysis of the entire system is done in parallel by verifying the interaction of each component with the fault free versions of the other components. Furthermore, we use existing efficient methods and tools, in particular parallel LTL-X model checking based on unfoldings, for diagnosability verification.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Laura Brand\u00e1n-Briones, Agnes Madalinski, Hern\u00e1n Ponce-de-Le\u00f3n,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07743", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07743", "title": "\nTracking an Object with Unknown Accelerations using a Shadowing Filter", "abstract": "A commonly encountered problem is the tracking of a physical object, like a maneuvering ship, aircraft, land vehicle, spacecraft or animate creature carrying a wireless device. The sensor data is often limited and inaccurate observations of range or bearing. This problem is more difficult than tracking a ballistic trajectory, because an operative affects unknown and arbitrarily changing accelerations. Although stochastic methods of filtering or state estimation (Kalman filters and particle filters) are widely used, out of vogue variational methods are more appropriate in this tracking context, because the objects do not typically display any significant random motions at the length and time scales of interest. This leads us to propose a rather elegant approach based on a emph. The resulting filter is efficient (reduces to the solution of linear equations) and robust (uneffected by missing data and singular correlations that would cause catastrophic failure of Bayesian filters.) The tracking is so robust, that in some common situations it actually performs better by ignoring error correlations that are so vital to Kalman filters.", "subjects": "Systems and Control (cs.SY)", "authors": "Kevin Judd,", "date": "2015-1-21"}, 
{"urllink": "http://arxiv.org/abs/1502.07725", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07725", "title": "\nThe $k$-Leaf Spanning Tree Problem Admits a Klam Value of 39", "abstract": "Given an undirected graph and a parameter , the -Leaf Spanning Tree (-LST) problem asks if contains a spanning tree with at least leaves. This problem has been extensively studied over the past three decades. In 2000, Fellows et al. [FSTTCS'00] explicitly asked whether it admits a klam value of 50. A steady progress towards an affirmative answer continued until 5 years ago, when an algorithm of klam value 37 was discovered. In this paper, we present an -time parameterized algorithm for -LST, which shows that the problem admits a klam value of 39. Our algorithm is based on an interesting application of the well-known bounded search trees technique, where the correctness of rules crucially depends on the history of previously applied rules in a non-standard manner.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Meirav Zehavi,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07718", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07718", "title": "\nAlgorithmic aspects of disjunctive domination in graphs", "abstract": "For a graph , a set is called a emph of if for every vertex , is either adjacent to a vertex of or has at least two vertices in at distance from it. The cardinality of a minimum disjunctive dominating set of is called the emph of graph , and is denoted by . The textsc (MDDP) is to find a disjunctive dominating set of cardinality . Given a positive integer and a graph , the textsc (DDDP) is to decide whether has a disjunctive dominating set of cardinality at most . In this article, we first propose a linear time algorithm for MDDP in proper interval graphs. Next we tighten the NP-completeness of DDDP by showing that it remains NP-complete even in chordal graphs. We also propose a -approximation algorithm for MDDP in general graphs and prove that MDDP can not be approximated within for any unless NP DTIME. Finally, we show that MDDP is APX-complete for bipartite graphs with maximum degree .", "subjects": "Discrete Mathematics (cs.DM)", "authors": "B.S. Panda, Arti Pandey, S. Paul,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.07713", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07713", "title": "\nCoalition Games on Interaction Graphs: A Horticultural Perspective", "abstract": "We examine cooperative games where the viability of a coalition is determined by whether or not its members have the ability to communicate amongst themselves independently of non-members. This necessary condition for viability was proposed by Myerson (1977) and is modeled via an interaction graph ; a coalition is then viable if and only if the induced graph is connected. The non-emptiness of the core of a coalition game can be tested by a well-known covering LP. Moreover, the integrality gap of its dual packing LP defines exactly the multiplicative least-core and the relative cost of stability of the coalition game. This gap is upper bounded by the packing-covering ratio which, for graphical coalition games, is known to be at most the treewidth of the interaction graph plus one (Meir et al. 2013). We examine the packing-covering ratio and integrality gaps of graphical coalition games in more detail. We introduce the thicket parameter of a graph, and prove it precisely measures the packing-covering ratio. It also approximately measures the primal and dual integrality gaps. The thicket number provides an upper bound of both integrality gaps. Moreover we show that for any interaction graph, the primal integrality gap is, in the worst case, linear in terms of the thicket number while the dual integrality gap is polynomial in terms of it. At the heart of our results, is a graph theoretic minmax theorem showing the thicket number is equal to the minimum width of a vine decomposition of the coalition graph (a vine decomposition is a generalization of a tree decomposition). We also explain how the thicket number relates to the VC-dimension of the set system produced by the game.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Nicolas Bousquet, Zhentao Li, Adrian Vetta,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07710", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07710", "title": "\nGlobally Optimal Crowdsourcing Quality Management", "abstract": "We study crowdsourcing quality management, that is, given worker responses to a set of tasks, our goal is to jointly estimate the true answers for the tasks, as well as the quality of the workers. Prior work on this problem relies primarily on applying Expectation-Maximization (EM) on the underlying maximum likelihood problem to estimate true answers as well as worker quality. Unfortunately, EM only provides a locally optimal solution rather than a globally optimal one. Other solutions to the problem (that do not leverage EM) fail to provide global optimality guarantees as well. In this paper, we focus on filtering, where tasks require the evaluation of a yes/no predicate, and rating, where tasks elicit integer scores from a finite domain. We design algorithms for finding the global optimal estimates of correct task answers and worker quality for the underlying maximum likelihood problem, and characterize the complexity of these algorithms. Our algorithms conceptually consider all mappings from tasks to true answers (typically a very large number), leveraging two key ideas to reduce, by several orders of magnitude, the number of mappings under consideration, while preserving optimality. We also demonstrate that these algorithms often find more accurate estimates than EM-based algorithms. This paper makes an important contribution towards understanding the inherent complexity of globally optimal crowdsourcing quality management.", "subjects": "Other Computer Science (cs.OH)", "authors": "Akash Das Sarma, Aditya Parameswaran, Jennifer Widom,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.07693", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07693", "title": "\nGREAT Process Modeller user manual", "abstract": "This report contains instructions to install, uninstall and use GREAT Process Modeller, a tool that supports Communication Analysis, a communication-oriented business process modelling method. GREAT allows creating communicative event diagrams (i.e. business process models), specifying message structures (which describe the messages associated to each communicative event), and automatically generating a class diagram (representing the data model of an information system that would support such organisational communication). This report briefly describes the methodological background of the tool. This handbook explains the modelling techniques in detail: Espa ~na, S., A. Gonz 'alez, 'O. Pastor and M. Ruiz (2012). Communication Analysis modelling techniques. Technical report ProS-TR-2012-02, PROS Research Centre, Universitat Polit `ecnica de Val `encia, Spain, arXiv:1205.0987.", "subjects": "Other Computer Science (cs.OH)", "authors": "Urko Rueda, Sergio Espa\u00f1a, Marcela Ruiz,", "date": "2015-1-7"}, 
{"urllink": "http://arxiv.org/abs/1502.07687", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07687", "title": "\nIncentive Mechanisms for Participatory Sensing: Survey and Research  Challenges", "abstract": "Participatory sensing is a powerful paradigm that leverages information sent by smartphone users to collect fine-grained information on events of interest. Given participatory sensing applications rely completely on the users' willingness to submit up-to-date and reliable information, it is paramount to effectively incentivize users' active and reliable participation. In this paper, we survey existing literature on incentive mechanisms for participatory sensing systems. In particular, we present a systematic and comprehensive taxonomy of existing incentive mechanisms for participatory sensing systems, which are subsequently discussed and compared in depth. Finally, we discuss open problems and future research directions.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Francesco Restuccia, Sajal K. Das, Jamie Payton,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.07666", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07666", "title": "\nLandmark-Guided Elastic Shape Analysis of Human Character Motions", "abstract": "Motions of virtual characters in movies or video games are typically generated by recording actors using motion capturing methods. Animations generated this way often need postprocessing, such as improving the periodicity of cyclic animations or generating entirely new motions by interpolation of existing ones. Furthermore, search and classification of recorded motions becomes more and more important as the amount of recorded motion data grows. In this paper, we will apply methods from shape analysis to the processing of animations. More precisely, we will use the by now classical elastic metric model used in shape matching, and extend it by incorporating additional inexact feature point information, which leads to an improved temporal alignment of different animations.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Martin Bauer, Markus Eslitzbichler, Markus Grasmair,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.07663", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07663", "title": "\nSubmatrix Maximum Queries in Monge Matrices are Equivalent to  Predecessor Search", "abstract": "We present an optimal data structure for submatrix maximum queries in n x n Monge matrices. Our result is a two-way reduction showing that the problem is equivalent to the classical predecessor problem. This gives a data structure of O(n) space that answers submatrix maximum queries in O(loglogn) time. It also gives a matching lower bound, showing that O(loglogn) query-time is optimal for any data structure of size O(n polylog(n)). Our result concludes a line of improvements that started in SODA'12 with O(log^2 n) query-time and continued in ICALP'14 with O(log n) query-time. Finally, we show that partial Monge matrices can be handled in the same bounds as full Monge matrices. In both previous results, partial Monge matrices incurred additional inverse-Ackerman factors.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Pawel Gawrychowski, Shay Mozes, Oren Weimann,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07661", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07661", "title": "\nDetecting Malware with Information Complexity", "abstract": "This work focuses on a specific front of the malware detection arms-race, namely the detection of persistent, disk-resident malware. We exploit normalised compression distance (NCD), an information theoretic measure, applied directly to binaries. Given a zoo of labelled malware and benign-ware, we ask whether a suspect program is more similar to our malware or to our benign-ware. Our approach classifies malware with 97.1% accuracy and a false positive rate of 3%. We achieve our results with off-the-shelf compressors and a standard machine learning classifier and without any specialised knowledge. An end-user need only collect a zoo of malware and benign-ware and then can immediately apply our techniques. We apply statistical rigour to our experiments and our selection of data. We demonstrate that accuracy can be optimised by combining NCD with the compressibility rates of the executables. We demonstrate that malware reported within a more narrow time frame of a few days is more homogenous than malware reported over a longer one of two years but that our method still classifies the latter with 95.2% accuracy and a 5% false positive rate. Due to the use of compression, the time and computation cost of our method is non-trivial. We show that simple approximation techniques can improve the time complexity of our approach by up to 63%. We compare our results to the results of applying the 59 anti-malware programs used on the VirusTotal web site to our malware. Our approach does better than any single one of them as well as the 59 used collectively.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Nadia Alshahwan, Earl T. Barr, David Clark, George Danezis,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07659", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07659", "title": "\nOn the complexity of computing the $k$-restricted edge-connectivity of a  graph", "abstract": "The emph of a graph , denoted by , is defined as the minimum size of an edge set whose removal leaves exactly two connected components each containing at least vertices. This graph invariant, which can be seen as a generalization of a minimum edge-cut, has been extensively studied from a combinatorial point of view. However, very little is known about the complexity of computing . Very recently, in the parameterized complexity community the notion of emph of a graph has been defined, which happens to be essentially the same as the -restricted edge-connectivity. Motivated by the relevance of this invariant from both combinatorial and algorithmic points of view, in this article we initiate a systematic study of its computational complexity, with special emphasis on its parameterized complexity for several choices of the parameters. We provide a number of NP-hardness and W[1]-hardness results, as well as FPT-algorithms.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Luis Pedro Montejano, Ignasi Sau,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07643", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07643", "title": "\nDynamic Belief Fusion for Object Detection", "abstract": "A novel approach for the fusion of detection scores from disparate object detection methods is proposed. In order to effectively integrate the outputs of multiple detectors, the level of ambiguity in each individual detection score (called \"uncertainty\") is estimated using the precision/recall relationship of the corresponding detector. The proposed fusion method, called Dynamic Belief Fusion (DBF), dynamically assigns basic probabilities to propositions (target, non-target, uncertain) based on confidence levels in the detection results of individual approaches. A joint basic probability assignment, containing information from all detectors, is determined using Dempster's combination rule, and is easily reduced to a single fused detection score. Experiments on ARL and PASCAL VOC 07 datasets demonstrate that the detection accuracy of DBF is considerably greater than conventional fusion approaches as well as state-of-the-art individual detectors.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Ryan Robinson,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.07639", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07639", "title": "\nAspect-oriented linearizability proofs", "abstract": "Linearizability of concurrent data structures is usually proved by monolithic simulation arguments relying on the identification of the so-called linearization points. Regrettably, such proofs, whether manual or automatic, are often complicated and scale poorly to advanced non-blocking concurrency patterns, such as helping and optimistic updates. In response, we propose a more modular way of checking linearizability of concurrent queue algorithms that does not involve identifying linearization points. We reduce the task of proving linearizability with respect to the queue specification to establishing four basic properties, each of which can be proved independently by simpler arguments. As a demonstration of our approach, we verify the Herlihy and Wing queue, an algorithm that is challenging to verify by a simulation proof.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Soham Chakraborty, Thomas A. Henzinger, Ali Sezgin, Viktor Vafeiadis,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07634", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07634", "title": "\nSome algebraic results in Description logics : Free model and  inclusions, finite basis theorem, and completion of knowledge bases", "abstract": "We propose a method to complete description logic (DL) knowledge bases. For this, we firstly build a canonical finite model from a given DL knowledge base satisfying some constraints on the form of its axioms. Then, we build a new DL knowledge base that infers all the properties of the canonical model. This latter DL knowledge base necessarily completes (according to the sense given to this notion in the paper) the starting DL knowledge base. This is the use and adaptation of results in universal algebra that allow us to get an effective process for completing DL knowledge bases.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Marc Aiguier, Jamal Atif, Isabelle Bloch, C\u00e9line Hudelot,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07628", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07628", "title": "\nRelaxation-based revision operators in description logics", "abstract": "As ontologies and description logics (DLs) reach out to a broader audience, several reasoning services are developed in this context. Belief revision is one of them, of prime importance when knowledge is prone to change and inconsistency. In this paper we address both the generalization of the well-known AGM postulates, and the definition of concrete and well-founded revision operators in different DL families. We introduce a model-theoretic version of the AGM postulates with a general definition of inconsistency, hence enlarging their scope to a wide family of non-classical logics, in particular negation-free DL families. We propose a general framework for defining revision operators based on the notion of relaxation, introduced recently for defining dissimilarity measures between DL concepts. A revision operator in this framework amounts to relax the set of models of the old belief until it reaches the sets of models of the new piece of knowledge. We demonstrate that such a relaxation-based revision operator defines a faithful assignment and satisfies the generalized AGM postulates. Another important contribution concerns the definition of several concrete relaxation operators suited to the syntax of some DLs (ALC and its fragments EL and ELU).", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Marc Aiguier, Jamal Atif, Isabelle Bloch, C\u00e9line Hudelot,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07617", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07617", "title": "\nOnline Learning with Feedback Graphs: Beyond Bandits", "abstract": "We study a general class of online learning problems where the feedback is specified by a graph. This class includes online prediction with expert advice and the multi-armed bandit problem, but also several learning problems where the online player does not necessarily observe his own loss. We analyze how the structure of the feedback graph controls the inherent difficulty of the induced -round learning problem. Specifically, we show that any feedback graph belongs to one of three classes: strongly observable graphs, weakly observable graphs, and unobservable graphs. We prove that the first class induces learning problems with minimax regret, where is the independence number of the underlying graph; the second class induces problems with minimax regret, where is the domination number of a certain portion of the graph; and the third class induces problems with linear minimax regret. Our results subsume much of the previous work on learning with feedback graphs and reveal new connections to partial monitoring games. We also show how the regret is affected if the graphs are allowed to vary with time.", "subjects": "Learning (cs.LG)", "authors": "Noga Alon, Nicol\u00f2 Cesa-Bianchi, Ofer Dekel, Tomer Koren,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07608", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07608", "title": "\nCppSs -- a C++ Library for Efficient Task Parallelism", "abstract": "We present the C++ library CppSs (C++ super-scalar), which provides efficient task-parallelism without the need for special compilers or other software. Any C++ compiler that supports C++11 is sufficient. CppSs features different directionality clauses for defining data dependencies. While the variable argument lists of the taskified functions are evaluated at compile time, the resulting task dependencies are fixed by the runtime value of the arguments and are thus analysed at runtime. With CppSs, we provide task-parallelism using merely native C++.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Steffen Brinkmann, Jose Gracia,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07601", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07601", "title": "\nData Driven Validation Framework for Multi-agent Activity-based Models", "abstract": "Activity-based models, as a specific instance of agent-based models, deal with agents that structure their activity in terms of (daily) activity schedules. An activity schedule consists of a sequence of activity instances, each with its assigned start time, duration and location, together with transport modes used for travel between subsequent activity locations. A critical step in the development of simulation models is validation. Despite the growing importance of activity-based models in modelling transport and mobility, there has been so far no work focusing specifically on statistical validation of such models. In this paper, we propose a six-step Validation Framework for Activity-based Models (VALFRAM) that allows exploiting historical real-world data to assess the validity of activity-based models. The framework compares temporal and spatial properties and the structure of activity schedules against real-world travel diaries and origin-destination matrices. We confirm the usefulness of the framework on three real-world activity-based transport models.", "subjects": "Multiagent Systems (cs.MA)", "authors": "Jan Drchal, Michal \u010certick\u00fd, Michal Jakob,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.07600", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07600", "title": "\nFactorization of Motion Polynomials", "abstract": "In this paper, we consider the existence of a factorization of a monic, bounded motion polynomial. We prove existence of factorizations, possibly after multiplication with a real polynomial and provide algorithms for computing polynomial factor and factorizations. The first algorithm is conceptually simpler but may require a high degree of the polynomial factor. The second algorithm gives an optimal degree.", "subjects": "Symbolic Computation (cs.SC)", "authors": "Zijia Li, Josef Schicho, Hans-Peter Schr\u00f6cker,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07598", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07598", "title": "\nDistributed Opportunistic Scheduling for Energy Harvesting Based  Wireless Networks: A Two-Stage Probing Approach", "abstract": "This paper considers a heterogeneous ad hoc network with multiple transmitter-receiver pairs, in which all transmitters are capable of harvesting renewable energy from the environment and compete for one shared channel by random access. In particular, we focus on two different scenarios: the constant energy harvesting (EH) rate model where the EH rate remains constant within the time of interest and the i.i.d. EH rate model where the EH rates are independent and identically distributed across different contention slots. To quantify the roles of both the energy state information (ESI) and the channel state information (CSI), a distributed opportunistic scheduling (DOS) framework with two-stage probing and save-then-transmit energy utilization is proposed. Then, the optimal throughput and the optimal scheduling strategy are obtained via one-dimension search, i.e., an iterative algorithm consisting of the following two steps in each iteration: First, assuming that the stored energy level at each transmitter is stationary with a given distribution, the expected throughput maximization problem is formulated as an optimal stopping problem, whose solution is proved to exist and then derived for both models; second, for a fixed stopping rule, the energy level at each transmitter is shown to be stationary and an efficient iterative algorithm is proposed to compute its steady-state distribution. Finally, we validate our analysis by numerical results and quantify the throughput gain compared with the best-effort delivery scheme.", "subjects": "Information Theory (cs.IT)", "authors": "Hang Li, Chuan Huang, Ping Zhang, Shuguang Cui, Junshan Zhang,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07591", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07591", "title": "\nThe phase transition in random regular exact cover", "abstract": "A -uniform, -regular instance of Exact Cover is a family of sets , where each subset has size and each is contained in of the . It is satisfiable if there is a subset such that for all . Alternately, we can consider it a -regular instance of Positive 1-in- SAT, i.e., a Boolean formula with clauses and variables where each clause contains variables and demands that exactly one of them is true. We determine the satisfiability threshold for random instances of this type with . Letting , we show that is satisfiable with high probability if and unsatisfiable with high probability if . We do this with a simple application of the first and second moment methods, boosting the probability of satisfiability below to using the small subgraph conditioning method.", "subjects": "Computational Complexity (cs.CC)", "authors": "Cristopher Moore,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.07586", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07586", "title": "\nJoint Hybrid Backhaul and Access Links Design in Cloud-Radio Access  Networks", "abstract": "The cloud-radio access network (CRAN) is expected to be the core network architecture for next generation mobile radio system. In this paper, we consider the downlink of a CRAN formed of one central processor (the cloud) and several base-station (BS), where each BS is connected to the cloud via either a wireless or capacity-limited wireline backhaul link. The paper addresses the joint design of the hybrid backhaul links (i.e., designing the wireline and wireless backhaul connections from cloud to BSs) and the access links (i.e., determining the sparse beamforming solution from the BSs to the users). The paper formulates the hybrid backhaul and access link design problem by minimizing the total network power consumption. The paper solves the problem using a two-stage heuristic algorithm. At one stage, the sparse beamforming solution is found using a weighted mixed norm minimization approach; the correlation matrix of the quantization noise of the wireline backhaul links is computed using the classical rate-distortion theory. At the second stage, the transmit powers of the wireless backhaul links are found by solving a power minimization problem subject to quality-of-service constraints, based on the principle of conservation of rate by utilizing the rates found in the first stage. Simulation results suggest that the performance of the proposed algorithm approaches the global optimum solution, especially at high SINR.", "subjects": "Information Theory (cs.IT)", "authors": "Oussama Dhifallah, Hayssam Dahrouj, Tareq Y. Al-Naffouri, Mohamed-Slim Alouini,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07577", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07577", "title": "\nSampling Sparse Signals on the Sphere: Algorithms and Applications", "abstract": "We propose a sampling scheme that can perfectly reconstruct a collection of spikes on the sphere from samples of their lowpass-filtered observations. Central to our algorithm is a generalization of the annihilating filter method, a tool widely used in array signal processing and finite-rate-of-innovation (FRI) sampling. The proposed algorithm can reconstruct spikes from spatial samples. This sampling requirement improves over previously known FRI sampling schemes on the sphere by a factor of four for large . We showcase the versatility of the proposed algorithm by applying it to three different problems: 1) sampling diffusion processes induced by localized sources on the sphere, 2) shot noise removal, and 3) sound source localization (SSL) by a spherical microphone array. In particular, we show how SSL can be reformulated as a spherical sparse sampling problem.", "subjects": "Information Theory (cs.IT)", "authors": "Ivan Dokmanic, Yue M. Lu,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.07576", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07576", "title": "\nComparison Issues in Large Graphs: State of the Art and Future  Directions", "abstract": "Graph comparison is fundamentally important for many applications such as the analysis of social networks and biological data and has been a significant research area in the pattern recognition and pattern analysis domains. Nowadays, the graphs are large, they may have billions of nodes and edges. Comparison issues in such huge graphs are a challenging research problem. In this paper, we survey the research advances of comparison problems in large graphs. We review graph comparison and pattern matching approaches that focus on large graphs. We categorize the existing approaches into three classes: partition-based approaches, search space based approaches and summary based approaches. All the existing algorithms in these approaches are described in detail and analyzed according to multiple metrics such as time complexity, type of graphs or comparison concept. Finally, we identify directions for future research.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Hamida Seba, Sofiane Lagraa, Elsen Ronando,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07571", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07571", "title": "\nOnline Fair Division: analysing a Food Bank problem", "abstract": "We study an online model of fair division designed to capture features of a real world charity problem. We consider two simple mechanisms for this model in which agents simply declare what items they like. We analyse several axiomatic properties of these mechanisms like strategy-proofness and envy-freeness. Finally, we perform a competitive analysis and compute the price of anarchy.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Martin Aleksandrov, Haris Aziz, Serge Gaspers, Toby Walsh,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.07567", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07567", "title": "\nA Channel Coding Approach for Physical-Layer Authentication", "abstract": "For physical-layer authentication, the authentication tags are often sent concurrently with messages without much bandwidth expansion. In this paper, we present a channel coding approach for physical-layer authentication. The generation of authentication tags can be formulated as an encoding process for an ensemble of codes, where the shared key between Alice and Bob is considered as the input and the message is used to specify a code from the ensemble of codes. Then, we show that the security of physical-layer authentication schemes can be analyzed through decoding and physical-layer authentication schemes can potentially achieve both information-theoretic and computational securities.", "subjects": "Information Theory (cs.IT)", "authors": "Xiaofu Wu, Zhen Yang,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07565", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07565", "title": "\nA Physical-Layer Authentication Assisted Scheme for Enhancing 3GPP  Authentication", "abstract": "The broadcast nature of radio propagation makes wireless networks vulnerable to eavesdropping attacks. To enhance authentication strength in wireless networks, various physical layer authentication schemes were proposed by exploiting physical layer characteristics. Recently, we proposed a novel PHYsical layer Phase Challenge-Response Authentication Scheme (PHY PCRAS), which exploits both the reciprocity and randomness of the phase responses over independent parallel multicarrier channels. In this paper, we first extend it to more practical Orthogonal Frequency-Division Multiplexing (OFDM) transmission. Then, security analysis is provided, and information-theoretic security is formulated for PHY-PCRAS over both independent and correlated subchannels. Finally, we propose a practical framework for incorporating the mechanism of physical layer authentication into the current Third Generation Partnership Project (3GPP) Authentication and Key Agreement (AKA) protocol. Compared to the conventional 3GPP AKA protocol, the PHY-PCRAS assisted authentication process can ensure some degree of information-theoretic security. It is also possible to further protect the subsequent classic AKA process on the air through the physical layer secure information transmission technique.", "subjects": "Information Theory (cs.IT)", "authors": "Xiaofu Wu, Zhen Yan, Cong Ling, Xiang-Gen Xia,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07549", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07549", "title": "\nModel-checking branching-time properties of probabilistic automata and  probabilistic one-counter automata", "abstract": "This paper studies the problem of model-checking of probabilistic automaton and probabilistic one-counter automata against probabilistic branching-time temporal logics (PCTL and PCTL). We show that it is undecidable for these problems. We first show, by reducing to emptiness problem of probabilistic automata, that the model-checking of probabilistic finite automata against branching-time temporal logics are undecidable. And then, for each probabilistic automata, by constructing a probabilistic one-counter automaton with the same behavior as questioned probabilistic automata the undecidability of model-checking problems against branching-time temporal logics are derived, herein.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "T. Lin,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07545", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07545", "title": "\nThe sequence produced by succinct SAT formula can be greatly compressed", "abstract": "In this paper with two equivalent representations of the information contained by a SAT formula, the reason why sequence generated by succinct SAT formula can be greatly compressed is firstly presented based on Kolmogorov complexity theory. Then what sequences can be greatly compressed was classified and discussed.", "subjects": "Computational Complexity (cs.CC)", "authors": "Feng Pan, Jie Qi,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07541", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07541", "title": "\nEuclidean Distance Matrices: A Short Walk Through Theory, Algorithms and  Applications", "abstract": "Euclidean distance matrices (EDM) are matrices of squared distances between points. The definition is deceivingly simple: thanks to their many useful properties they have found applications in psychometrics, crystallography, machine learning, wireless sensor networks, acoustics, and more. Despite the usefulness of EDMs, they seem to be insufficiently known in the signal processing community. Our goal is to rectify this mishap in a concise tutorial. We review the fundamental properties of EDMs, such as rank or (non)definiteness. We show how various EDM properties can be used to design algorithms for completing and denoising distance data. Along the way, we demonstrate applications to microphone position calibration, ultrasound tomography, room reconstruction from echoes and phase retrieval. By spelling out the essential algorithms, we hope to fast-track the readers in applying EDMs to their own problems. Matlab code for all the described algorithms, and to generate the figures in the paper, is available online. Finally, we suggest directions for further research.", "subjects": "Other Computer Science (cs.OH)", "authors": "Ivan Dokmanic, Reza Parhizkar, Juri Ranieri, Martin Vetterli,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07540", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07540", "title": "\nA hypothesize-and-verify framework for Text Recognition using Deep  Recurrent Neural Networks", "abstract": "Deep LSTM is an ideal candidate for text recognition. However text recognition involves some initial image processing steps like segmentation of lines and words which can induce error to the recognition system. Without segmentation, learning very long range context is difficult and becomes computationally intractable. Therefore, alternative soft decisions are needed at the pre-processing level. This paper proposes a hybrid text recognizer using a deep recurrent neural network with multiple layers of abstraction and long range context along with a language model to verify the performance of the deep neural network. In this paper we construct a multi-hypotheses tree architecture with candidate segments of line sequences from different segmentation algorithms at its different branches. The deep neural network is trained on perfectly segmented data and tests each of the candidate segments, generating unicode sequences. In the verification step, these unicode sequences are validated using a sub-string match with the language model and best first search is used to find the best possible combination of alternative hypothesis from the tree structure. Thus the verification framework using language models eliminates wrong segmentation outputs and filters recognition errors.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Anupama Ray, Sai Rajeswar, Santanu Chaudhury,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07526", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07526", "title": "\nOptimizing Batch Linear Queries under Exact and Approximate Differential  Privacy", "abstract": "Differential privacy is a promising privacy-preserving paradigm for statistical query processing over sensitive data. It works by injecting random noise into each query result, such that it is provably hard for the adversary to infer the presence or absence of any individual record from the published noisy results. The main objective in differentially private query processing is to maximize the accuracy of the query results, while satisfying the privacy guarantees. Previous work, notably cite, has suggested that with an appropriate strategy, processing a batch of correlated queries as a whole achieves considerably higher accuracy than answering them individually. However, to our knowledge there is currently no practical solution to find such a strategy for an arbitrary query batch; existing methods either return strategies of poor quality (often worse than naive methods) or require prohibitively expensive computations for even moderately large domains. Motivated by this, we propose low-rank mechanism (LRM), the first practical differentially private technique for answering batch linear queries with high accuracy. LRM works for both exact (i.e., -) and approximate (i.e., (, )-) differential privacy definitions. We derive the utility guarantees of LRM, and provide guidance on how to set the privacy parameters given the user's utility expectation. Extensive experiments using real data demonstrate that our proposed method consistently outperforms state-of-the-art query processing solutions under differential privacy, by large margins.", "subjects": "Databases (cs.DB)", "authors": "Ganzhao Yuan, Zhenjie Zhang, Marianne Winslett, Xiaokui Xiao, Yin Yang, Zhifeng Hao,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07504", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07504", "title": "\nRational Kernels for Arabic Stemming and Text Classification", "abstract": "In this paper, we address the problems of Arabic Text Classification and stemming using Transducers and Rational Kernels. We introduce a new stemming technique based on the use of Arabic patterns (Pattern Based Stemmer). Patterns are modelled using transducers and stemming is done without depending on any dictionary. Using transducers for stemming, documents are transformed into finite state transducers. This document representation allows us to use and explore rational kernels as a framework for Arabic Text Classification. Stemming experiments are conducted on three word collections and classification experiments are done on the Saudi Press Agency dataset. Results show that our approach, when compared with other approaches, is promising specially in terms of Accuracy, Recall and F1.", "subjects": "Computation and Language (cs.CL)", "authors": "Attia Nehar, Djelloul Ziadi, Hadda Cherroun,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07495", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07495", "title": "\nObject-Oriented Networking", "abstract": "We propose the object-oriented networking (OON) framework, for meeting the generalized interconnection, mobility and technology integration requirements underlining the Internet. In OON, the various objects that need to be accessed through the Internet (content, smart things, services, people, etc.) are viewed as network layer resources, rather than as application layer resources as in the IP communications model. By abstracting them as computing objects -with attributes and methods- they are identified by expressive, discoverable names, while data are exchanged between them in the context of their methods, based on suitably defined system-specific names. An OON-enabled Internet is not only a global data delivery medium but also a universal object discovery and service development platform; service-level interactions can be realized through native network means, without requiring standardized protocols. OON can be realized through existing software-defined networking or network functions virtualization technologies and it can be deployed in an incremental fashion.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Panos Georgatsos, Paris Flegkas, Vasilis Sourlas, Leandros Tassiulas,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07492", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07492", "title": "\nRainbow domination and related problems on some classes of perfect  graphs", "abstract": "Let and let be a graph. A function is a rainbow function if, for every vertex with , . The rainbow domination number is the minimum of over all rainbow functions. We investigate the rainbow domination problem for some classes of perfect graphs.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Wing-Kai Hon, Ton Kloks, Hsian-Hsuan Liu, Hung-Lung Wang,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07481", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07481", "title": "\nCluster Synchronization for Coupled Linear Systems with Nonidentical  Dynamics", "abstract": "For coupled systems with nonidentical dynamics, the cluster synchronization problem requires that states of systems characterized by the same parameters synchronize together. This problem is of both theoretical and applicative importance and is more complicated than clustering for homogeneous systems. This paper considers generic linear dynamical systems whose system parameters are distinct in different clusters. To handle the system heterogeneity, we design for each agent a dynamic control law which utilizes intermediate control variables. Both leaderless and leader-based coupling strategies are investigated. Building on the proposed control models, this paper derives algebraic necessary and sufficient conditions to guarantee cluster synchronization. However, these conditions intricately relate the parameters of the interaction graph with the agents' system parameters. This paper further shows that these algebraic conditions are satisfied if the interaction graph topology admits a directed spanning tree for each cluster and the coupling strength among agents of the same cluster is sufficiently large. Results presented in this paper include those coming from several existing studies for homogeneous systems as special cases.", "subjects": "Systems and Control (cs.SY)", "authors": "Zhongchang Liu, Wing Shing Wong,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07475", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07475", "title": "\nSimple and Efficient Secret Sharing Schemes for Sharing Data and Image", "abstract": "Secret sharing is a new alternative for outsourcing data in a secure way.It avoids the need for time consuming encryption decryption process and also the complexity involved in key management.The data must also be protected from untrusted cloud service providers.Secret sharing based solution provides secure information dispersal by making shares of the original data and distribute them among different servers.Data from the threshold number of servers can be used to reconstruct the original data.It is often impractical to distribute data among large number of servers.We have to achieve a trade off between security and efficiency.An optimal choice is to use a or threshold secret sharing scheme, where the data are distributed as shares among three or four servers and shares from any two can be used to construct the original data.This provides both security,reliability and efficiency.We propose some efficient and easy to implement secret sharing schemes in this regard based on number theory and bitwise XOR.These schemes are also suitable for secure sharing of images.Secret image sharing based on Shamir's schemes are lossy and involves complicated Lagrange interpolation.So the proposed scheme can also be effectively utilized for lossless sharing of secret images.", "subjects": "Cryptography and Security (cs.CR)", "authors": "V. P. Binu, A. Sreekumar,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07469", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07469", "title": "\nAn Improved E-voting scheme using Secret Sharing based Secure  Multi-party Computation", "abstract": "E-voting systems (EVS)are having potential advantages over many existing voting schemes.Security, transparency, accuracy and reliability are the major concern in these systems.EVS continues to grow as the technology advances.It is inexpensive and efficient as the resources become reusable.Fast and accurate computation of results with voter privacy is the added advantage.In the proposed system we make use of secret sharing technique and secure multi party computation(SMC) to achieve security and reliability.Secret sharing is an important technique used for SMC. Multi-party computation is typically accomplished using secret sharing by making shares of the input and manipulating the shares to compute a typical function of the input.The proposed system make use of bitwise representation of votes and only the shares are used for transmission and computation of result.Secure sum evaluation can be done with shares distributed using Shamir's secret sharing scheme.The scheme is hence secure and reliable and does not make any number theoretic assumptions for security.We also propose a unique method which calculates the candidates individual votes keeping the anonymity.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Divya G. Nair, V. P. Binu, G. Santhosh Kumar,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07467", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07467", "title": "\nReachability is in DynFO", "abstract": "We consider the dynamic complexity of some central graph problems such as Reachability and Matching and linear algebraic problems such as Rank and Inverse. As elementary change operations we allow insertion and deletion of edges of a graph and the modification of a single entry in a matrix, and we are interested in the complexity of maintaining a property or query. Our main results are as follows: 1. Rank of a matrix is in DynFO(+,x); 2. Reachability is in DynFO; 3. Maximum Matching (decision) is in non-uniform DynFO. Here, DynFO allows updates of the auxiliary data structure defined in first-order logic, DynFO(+,x) additionally has arithmetics at initialization time and non-uniform DynFO allows arbitrary auxiliary data at initialization time. Alternatively, DynFO(+,x) and non-uniform DynFO allow updates by uniform and non-uniform families of poly-size, bounded-depth circuits, respectively. The second result confirms a two decade old conjecture of Patnaik and Immerman (1997). The proofs rely mainly on elementary Linear Algebra.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Samir Datta, Raghav Kulkarni, Anish Mukherjee, Thomas Schwentick, Thomas Zeume,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07466", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07466", "title": "\nDistributed Analysis for Diagnosability in Concurrent Systems", "abstract": "Complex systems often exhibit unexpected faults that are difficult to handle. Such systems are desirable to be diagnosable, i.e. faults can be automatically detected as they occur (or shortly afterwards), enabling the system to handle the fault or recover. A system is diagnosable if it is possible to detect every fault, in a finite time after they occurred, by only observing the available information from the system. Complex systems are usually built from simpler components running concurrently. We study how to infer the diagnosability property of a complex system (distributed and with multiple faults) from a parallelized analysis of the diagnosability of each of its components synchronizing with fault free versions of the others. In this paper we make the following contributions: (1) we address the diagnosability problem of concurrent systems with arbitrary faults occurring freely in each component. (2) We distribute the diagnosability analysis and illustrate our approach with examples. Moreover, (3) we present a prototype tool that implements our techniques showing promising results.", "subjects": "Software Engineering (cs.SE)", "authors": "Hern\u00e1n Ponce de Le\u00f3n, Gonzalo Bonigo, Laura Brand\u00e1n Briones,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07454", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07454", "title": "\nGeneration and Validation of Custom Multiplication IP Blocks from the  Web", "abstract": "Every CPU carries one or more arithmetical and logical units. One popular operation that is performed by these units is multiplication. Automatic generation of custom VHDL models for performing this operation, allows the designer to achieve a time efficient design space exploration. Although these units are heavily utilized in modern digital circuits and DSP, there is no tool, accessible from the web, to generate the HDL description of such designs for arbitrary and different input bitwidths. In this paper, we present our web accessible tool to construct completely custom optimized multiplication units together with random generated test vectors for their verification. Our novel tool is one of the firsts web based EDA tools to automate the design of such units and simultaneously provide custom testbenches to verify their correctness. Our synthesized circuits on Xilinx Virtex 6 FPGA, operate up to 589 Mhz.", "subjects": "Hardware Architecture (cs.AR)", "authors": "Minas Dasygenis,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07453", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07453", "title": "\nA Holistic Approach for Modeling and Synthesis of Image Processing  Applications for Heterogeneous Computing Architectures", "abstract": "Image processing applications are common in every field of our daily life. However, most of them are very complex and contain several tasks with different complexities which result in varying requirements for computing architectures. Nevertheless, a general processing scheme in every image processing application has a similar structure, called image processing pipeline: (1) capturing an image, (2) pre-processing using local operators, (3) processing with global operators and (4) post-processing using complex operations. Therefore, application-specialized hardware solutions based on heterogeneous architectures are used for image processing. Unfortunately the development of applications for heterogeneous hardware architectures is challenging due to the distribution of computational tasks among processors and programmable logic units. Nowadays, image processing systems are started from scratch which is time-consuming, error-prone and inflexible. A new methodology for modeling and implementing is needed in order to reduce the development time of heterogenous image processing systems. This paper introduces a new holistic top down approach for image processing systems. Two challenges have to be investigated. First, designers ought to be able to model their complete image processing pipeline on an abstract layer using UML. Second, we want to close the gap between the abstract system and the system architecture.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Christian Hartmann, Anna Yupatova, Marc Reichenbach, Dietmar Fey, Reinhard German,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07451", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07451", "title": "\nA Graph-Partition-Based Scheduling Policy for Heterogeneous  Architectures", "abstract": "In order to improve system performance efficiently, a number of systems choose to equip multi-core and many-core processors (such as GPUs). Due to their discrete memory these heterogeneous architectures comprise a distributed system within a computer. A data-flow programming model is attractive in this setting for its ease of expressing concurrency. Programmers only need to define task dependencies without considering how to schedule them on the hardware. However, mapping the resulting task graph onto hardware efficiently remains a challenge. In this paper, we propose a graph-partition scheduling policy for mapping data-flow workloads to heterogeneous hardware. According to our experiments, our graph-partition-based scheduling achieves comparable performance to conventional queue-base approaches.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Hao Wu, Daniel Lohmann, Wolfgang Schr\u00f6der-Preikschat,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07449", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07449", "title": "\nConcept for a CMOS Image Sensor Suited for Analog Image Pre-Processing", "abstract": "A concept for a novel CMOS image sensor suited for analog image pre-processing is presented in this paper. As an example, an image restoration algorithm for reducing image noise is applied as image pre-processing in the analog domain. To supply low-latency data input for analog image preprocessing, the proposed concept for a CMOS image sensor offers a new sensor signal acquisition method in 2D. In comparison to image pre-processing in the digital domain, the proposed analog image pre-processing promises an improved image quality. Furthermore, the image noise at the stage of analog sensor signal acquisition can be used to select the most effective restoration algorithm applied to the analog circuit due to image processing prior to the A/D converter.", "subjects": "Emerging Technologies (cs.ET)", "authors": "Lan Shi, Christopher Soell, Andreas Baenisch, Robert Weigel, J\u00fcrgen Seiler, Thomas Ussmueller,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07448", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07448", "title": "\nAutomatic Optimization of Hardware Accelerators for Image Processing", "abstract": "In the domain of image processing, often real-time constraints are required. In particular, in safety-critical applications, such as X-ray computed tomography in medical imaging or advanced driver assistance systems in the automotive domain, timing is of utmost importance. A common approach to maintain real-time capabilities of compute-intensive applications is to offload those computations to dedicated accelerator hardware, such as Field Programmable Gate Arrays (FPGAs). Programming such architectures is a challenging task, with respect to the typical FPGA-specific design criteria: Achievable overall algorithm latency and resource usage of FPGA primitives (BRAM, FF, LUT, and DSP). High-Level Synthesis (HLS) dramatically simplifies this task by enabling the description of algorithms in well-known higher languages (C/C++) and its automatic synthesis that can be accomplished by HLS tools. However, algorithm developers still need expert knowledge about the target architecture, in order to achieve satisfying results. Therefore, in previous work, we have shown that elevating the description of image algorithms to an even higher abstraction level, by using a Domain-Specific Language (DSL), can significantly cut down the complexity for designing such algorithms for FPGAs. To give the developer even more control over the common trade-off, latency vs. resource usage, we will present an automatic optimization process where these criteria are analyzed and fed back to the DSL compiler, in order to generate code that is closer to the desired design specifications. Finally, we generate code for stereo block matching algorithms and compare it with handwritten implementations to quantify the quality of our results.", "subjects": "Programming Languages (cs.PL)", "authors": "Oliver Reiche, Konrad H\u00e4ublein, Marc Reichenbach, Frank Hannig, J\u00fcrgen Teich, Dietmar Fey,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07447", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07447", "title": "\nA Comparative Study of Scheduling Techniques for Multimedia Applications  on SIMD Pipelines", "abstract": "Parallel architectures are essential in order to take advantage of the parallelism inherent in streaming applications. One particular branch of these employ hardware SIMD pipelines. In this paper, we analyse several scheduling techniques, namely ad hoc overlapped execution, modulo scheduling and modulo scheduling with unrolling, all of which aim to efficiently utilize the special architecture design. Our investigation focuses on improving throughput while analysing other metrics that are important for streaming applications, such as register pressure, buffer sizes and code size. Through experiments conducted on several media benchmarks, we present and discuss trade-offs involved when selecting any one of these scheduling techniques.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Mehmet Ali Arslan, Flavius Gruian, Krzysztof Kuchcinski,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07446", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07446", "title": "\nEstimating the Potential Speedup of Computer Vision Applications on  Embedded Multiprocessors", "abstract": "Computer vision applications constitute one of the key drivers for embedded multicore architectures. Although the number of available cores is increasing in new architectures, designing an application to maximize the utilization of the platform is still a challenge. In this sense, parallel performance prediction tools can aid developers in understanding the characteristics of an application and finding the most adequate parallelization strategy. In this work, we present a method for early parallel performance estimation on embedded multiprocessors from sequential application traces. We describe its implementation in Parana, a fast trace-driven simulator targeting OpenMP applications on the STMicroelectronics' STxP70 Application-Specific Multiprocessor (ASMP). Results for the FAST key point detector application show an error margin of less than 10% compared to the reference cycle-approximate simulator, with lower modeling effort and up to 20x faster execution time.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "V\u00edtor Schwambach, S\u00e9bastien Cleyet-Merle, Alain Issard, St\u00e9phane Mancini,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07439", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07439", "title": "\nQMSampler: Joint Sampling of Multiple Networks with Quality Guarantee", "abstract": "Because Online Social Networks (OSNs) have become increasingly important in the last decade, they have motivated a great deal of research on social network analysis (SNA). Currently, SNA algorithms are evaluated on real datasets obtained from large-scale OSNs, which are usually sampled by Breadth-First-Search (BFS), Random Walk (RW), or some variations of the latter. However, none of the released datasets provides any statistical guarantees on the difference between the crawled datasets and the ground truth. Moreover, all existing sampling algorithms only focus on crawling a single OSN, but each OSN is actually a sampling of a global offline social network. Hence, even if the whole dataset from a single OSN is crawled, the results may still be skewed and may not fully reflect the properties of the global offline social network. To address the above issues, we make the first attempt to explore joint sampling of multiple OSNs and propose an approach called Quality-guaranteed Multi-network Sampler (QMSampler), which can crawl and sample multiple OSNs jointly. QMSampler provides a statistical guarantee on the difference between the crawled real dataset and the ground truth (the perfect integration of all OSNs). Our experimental results demonstrate that the proposed approach generates a much smaller bias than any existing method. QMSampler has been released as a free download.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Hong-Han Shuai, De-Nian Yang, Chih-Ya Shen, Philip S. Yu, Ming-Syan Chen,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.07436", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07436", "title": "\nA Dictionary Approach to EBSD Indexing", "abstract": "We propose a framework for indexing of grain and sub-grain structures in electron backscatter diffraction (EBSD) images of polycrystalline materials. The framework is based on a previously introduced physics-based forward model by Callahan and De Graef (2013) relating measured patterns to grain orientations (Euler angle). The forward model is tuned to the microscope and the sample symmetry group. We discretize the domain of the forward model onto a dense grid of Euler angles and for each measured pattern we identify the most similar patterns in the dictionary. These patterns are used to identify boundaries, detect anomalies, and index crystal orientations. The statistical distribution of these closest matches is used in an unsupervised binary decision tree (DT) classifier to identify grain boundaries and anomalous regions. The DT classifies a pattern as an anomaly if it has an abnormally low similarity to any pattern in the dictionary. It classifies a pixel as being near a grain boundary if the highly ranked patterns in the dictionary differ significantly over the pixels 3x3 neighborhood. Indexing is accomplished by computing the mean orientation of the closest dictionary matches to each pattern. The mean orientation is estimated using a maximum likelihood approach that models the orientation distribution as a mixture of Von Mises-Fisher distributions over the quaternionic 3-sphere. The proposed dictionary matching approach permits segmentation, anomaly detection, and indexing to be performed in a unified manner with the additional benefit of uncertainty quantification. We demonstrate the proposed dictionary-based approach on a Ni-base IN100 alloy.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Yu-Hui Chen, Se Un Park, Dennis Wei, Gregory Newstadt, Michael Jackson, Jeff P. Simmons, Marc De Graef, Alfred O. Hero,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.07432", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07432", "title": "\nCoercive Region-level Registration for Multi-modal Images", "abstract": "We propose a coercive approach to simultaneously register and segment multi-modal images which share similar spatial structure. Registration is done at the region level to facilitate data fusion while avoiding the need for interpolation. The algorithm performs alternating minimization of an objective function informed by statistical models for pixel values in different modalities. Hypothesis tests are developed to determine whether to refine segmentations by splitting regions. We demonstrate that our approach has significantly better performance than the state-of-the-art registration and segmentation methods on microscopy images.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Yu-Hui Chen, Dennis Wei, Gregory Newstadt, Jeffrey Simmons, Alfred hero,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07431", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07431", "title": "\nOptimal commitments in auctions with incomplete information", "abstract": "We are interested in the problem of optimal commitments in rank-and-bid based auctions, a general class of auctions that include first price and all-pay auctions as special cases. Our main contribution is a novel approach to solve for optimal commitment in this class of auctions, for any continuous type distributions. Applying our approach, we are able to solve optimal commitments for first-price and all-pay auctions in closed-form for fairly general distribution settings. The optimal commitments functions in these auctions reveal two surprisingly opposite insights: in the optimal commitment, the leader bids passively when he has a low type. We interpret this as a credible way to alleviate competition and to collude. In sharp contrast, when his type is high enough, the leader sometimes would go so far as to bid above his own value. We interpret this as a credible way to threat. Combing both insights, we show via concrete examples that the leader is indeed willing to do so to secure more utility when his type is in the middle. Our main approach consists of a series of nontrivial innovations. In particular we put forward a concept called equal-bid function that connects both players' strategies, as well as a concept called equal-utility curve that smooths any leader strategy into a continuous and differentiable strategy. We believe these techniques and insights are general and can be applied to similar problems.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Zihe Wang, Pingzhong Tang,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07428", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07428", "title": "\nRepresentative Selection in Non Metric Datasets", "abstract": "This paper considers the problem of representative selection: choosing a subset of data points from a dataset that best represents its overall set of elements. This subset needs to inherently reflect the type of information contained in the entire set, while minimizing redundancy. For such purposes, clustering may seem like a natural approach. However, existing clustering methods are not ideally suited for representative selection, especially when dealing with non-metric data, where only a pairwise similarity measure exists. In this paper we propose -medoids, a novel approach that can be viewed as an extension to the -medoids algorithm and is specifically suited for sample representative selection from non-metric data. We empirically validate -medoids in two domains, namely music analysis and motion analysis. We also show some theoretical bounds on the performance of -medoids and the hardness of representative selection in general.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Elad Liebman, Benny Chor, Peter Stone,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07425", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07425", "title": "\nAnalysis and Optimization of Interference Nulling in Downlink  Multi-Antenna HetNets with Offloading", "abstract": "Heterogeneous networks (HetNets) with offloading is considered as an effective way to meet the high data rate demand of future wireless service. However, the offloaded users suffer from strong inter-tier interference, which reduces the benefits of offloading and is one of the main limiting factors of the system performance. In this paper, we investigate the use of an interference nulling (IN) beamforming scheme to improve the system performance by carefully managing the inter-tier interference to the offloaded users in downlink two-tier HetNets with multi-antenna base stations. Utilizing tools from stochastic geometry, we derive a tractable expression for the rate coverage probability of the IN scheme. Then, we optimize the design parameter, i.e., the degrees of freedom that can be used for IN, to maximize the rate coverage probability. Specifically, in the asymptotic scenario where the rate threshold is small, by studying the order behavior of the rate coverage probability, we characterize the optimal design parameter. For the general scenario, we show some properties of the optimal design parameter. Finally, by numerical simulations, we show the IN scheme can outperform both the simple offloading scheme without interference management and the almost blank subframes scheme in 3GPP LTE, especially in large antenna regime.", "subjects": "Information Theory (cs.IT)", "authors": "Yueping Wu, Ying Cui, Bruno Clerckx,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07424", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07424", "title": "\nMechanical Design, Modelling and Control of a Novel Aerial Manipulator", "abstract": "In this paper a novel aerial manipulation system is proposed. The mechanical structure of the system, the number of thrusters and their geometry will be derived from technical optimization problems. The aforementioned problems are defined by taking into consideration the desired actuation forces and torques applied to the end-effector of the system. The framework of the proposed system is designed in a CAD Package in order to evaluate the system parameter values. Following this, the kinematic and dynamic models are developed and an adaptive backstepping controller is designed aiming to control the exact position and orientation of the end-effector in the Cartesian space. Finally, the performance of the system is demonstrated through a simulation study, where a manipulation task scenario is investigated.", "subjects": "Robotics (cs.RO)", "authors": "Alexandros Nikou, Georgios C. Gavridis, Kostas J. Kyriakopoulos,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07423", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07423", "title": "\nConnections Between Nuclear Norm and Frobenius Norm Based Representation", "abstract": "Several recent works have shown that Frobenius-Norm based Representation (FNR) is comparable with Sparse Representation (SR) and Nuclear-Norm based Representation (NNR) in face recognition and subspace clustering. Despite the success of FNR in experimental studies, less theoretical analysis is provided to understand its working mechanism. In this paper, we fill this gap by bridging FNR and NNR. More specially, we prove that: 1) when the dictionary can provide enough representative capacity, FNR is exactly the NNR; 2) Otherwise, FNR and NNR are two solutions on the column space of the dictionary. The first result provides a novel theoretical explanation towards some existing FNR based methods by crediting their success to low rank property. The second result provides a new insight to understand FNR and NNR under a unified framework.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Xi Peng, Canyi Lu, Zhang Yi, Huajin Tang,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07414", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07414", "title": "\nInterdependent Security with Strategic Agents and Cascades of Infection", "abstract": "We investigate cascades in networks consisting of strategic agents with interdependent security. We assume that the strategic agents have choices between i) investing in protecting themselves, ii) purchasing insurance to transfer (some) risks, and iii) taking no actions. Using a population game model, we study how various system parameters, such as node degrees, infection propagation rate, and the probability with which infected nodes transmit infection to neighbors, affect nodes' choices at Nash equilibria and the resultant price of anarchy/stability. In addition, we examine how the probability that a single infected node can spread the infection to a significant portion of the entire network, called cascade probability, behaves with respect to system parameters. In particular, we demonstrate that, at least for some parameter regimes, the cascade probability increases with the average degree of nodes.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Richard J. La,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07411", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07411", "title": "\nLearning Depth from Single Monocular Images Using Deep Convolutional  Neural Fields", "abstract": "In this article, we tackle the problem of depth estimation from single monocular images. Compared with depth estimation using multiple images such as stereo depth perception, depth from monocular images is much more challenging. Prior work typically focuses on exploiting geometric priors or additional sources of information, most using hand-crafted features. Recently, there is mounting evidence that features from deep convolutional neural networks (CNN) set new records for various vision applications. On the other hand, considering the continuous characteristic of the depth values, depth estimations can be naturally formulated as a continuous conditional random field (CRF) learning problem. Therefore, here we present a deep convolutional neural field model for estimating depths from single monocular images, aiming to jointly explore the capacity of deep CNN and continuous CRF. In particular, we propose a deep structured learning scheme which learns the unary and pairwise potentials of continuous CRF in a unified deep CNN framework. We then further propose an equally effective model based on fully convolutional networks and a novel superpixel pooling method, which is times faster, to speedup the patch-wise convolutions in the deep model. With this more efficient model, we are able to design deeper networks to pursue better performance. Experiments on both indoor and outdoor scene datasets demonstrate that the proposed method outperforms state-of-the-art depth estimation approaches.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Fayao Liu, Chunhua Shen, Guosheng Lin, Ian Reid,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.07406", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07406", "title": "\nImproved Approximation Algorithms for k-Submodular Function Maximization", "abstract": "This paper presents a polynomial-time -approximation algorithm for maximizing nonnegative -submodular functions. This improves upon the previous -approximation by Ward and vivn 'y~(SODA'14), where . We also show that for monotone -submodular functions there is a polynomial-time -approximation algorithm while for any a -approximation algorithm for maximizing monotone -submodular functions would require exponentially many queries. In particular, our hardness result implies that our algorithms are asymptotically tight. We also extend the approach to provide constant factor approximation algorithms for maximizing skew-bisubmodular functions, which were recently introduced as generalizations of bisubmodular functions.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Satoru Iwata, Shin-ichi Tanigawa, Yuichi Yoshida,", "date": "2015-2-26"}, 
{"urllink": "http://arxiv.org/abs/1502.07405", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07405", "title": "\nAn efficient multi-core implementation of a novel HSS-structured  multifrontal solver using randomized sampling", "abstract": "We present a sparse linear system solver that is based on a multifrontal variant of Gaussian elimination, and exploits low-rank approximation of the resulting dense frontal matrices. We use hierarchically semiseparable (HSS) matrices, which have low-rank off-diagonal blocks, to approximate the frontal matrices. For HSS matrix construction, a randomized sampling algorithm is used together with interpolative decompositions. The combination of the randomized compression with a fast ULV HSS factorization leads to a solver with lower computational complexity than the standard multifrontal method for many applications, resulting in speedups up to 7 fold for problems in our test suite. The implementation targets many-core systems by using task parallelism with dynamic runtime scheduling. Numerical experiments show performance improvements over state-of-the-art sparse direct solvers. The implementation achieves high performance and good scalability on a range of modern shared memory parallel systems, including the Intel Xeon Phi (MIC). The code is part of a software package called STRUMPACK -- STRUctured Matrices PACKage, which also has a distributed memory component for dense rank-structured matrices.", "subjects": "Mathematical Software (cs.MS)", "authors": "Pieter Ghysels, Xiaoye S. Li, Francois-Henry Rouet, Samuel Williams, Artem Napov,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07404", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07404", "title": "\nThroughput Analysis for Full-Duplex Wireless Networks with Imperfect  Self-interference Cancellation", "abstract": "This paper investigates the throughput for wireless network with full-duplex radios using stochastic geometry. Full-duplex (FD) radios can exchange data simultaneously with each other. On the other hand, the downside of FD transmission is that it will inevitably cause extra interference to the network compared to half-duplex (HD) transmission. Moreover, the residual self-interference has negative effects on the network throughput. In this paper, we focus on a wireless network of nodes with both HD and FD capabilities and derive and optimize the throughput in such a network. Our analytical result shows that if the network is adapting an ALOHA protocol, the maximal throughput is achieved by scheduling all concurrently transmitting nodes to work in either FD mode or HD mode depending on one simple condition. Moreover, the effects of imperfect self-interference cancellation on the signal-to-interference ratio (SIR) loss and throughput are also analyzed based on our mathematical model. We rigorously quantify the impact of imperfect self-interference cancellation on the throughput gain, transmission range, and other metrics, and we establish the minimum amount of self-interference suppression needed for FD to be beneficial.", "subjects": "Information Theory (cs.IT)", "authors": "Zhen Tong, Martin Haenggi,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07391", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07391", "title": "\nMultiple State EFN Transistors", "abstract": "Electrostatically Formed Nanowire (EFN) based transistors have been suggested in the past as gas sensing devices. These transistors are multiple gate transistors in which the source to drain conduction path is determined by the bias applied to the back gate, and two junction gates. If a specific bias is applied to the side gates, the conduction band electrons between them are confined to a well-defined area forming a narrow channel- the Electrostatically Formed Nanowire. Recent work has shown that by applying non-symmetric bias on the side gates, the lateral position of the EFN can be controlled. We propose a novel Multiple State EFN Transistor (MSET) that utilizes this degree of freedom for the implementation of complete multiplexer functionality in a single transistor like device. The multiplexer functionality allows a very simple implementation of binary and multiple valued logic functions.", "subjects": "Emerging Technologies (cs.ET)", "authors": "Gideon Segev, Iddo Amit, Andrey Godkin, Alex Henning, Yossi Rosenwaks,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.07384", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07384", "title": "\nSpreading Processes over Socio-Technical Networks with Phase-Type  Transmissions", "abstract": "Most theoretical tools available for the analysis of spreading processes over networks assume exponentially distributed transmission and recovery times. In practice, the empirical distribution of transmission times for many real spreading processes, such as the spread of web content through the Internet, are far from exponential. In particular, the inter-arrival time of Twitter messages or the propagation time of news stories on a social media site can be explained using lognormal distributions. To bridge this gap between theory and practice, we propose a methodology to model and analyze spreading processes with arbitrary transmission times using phase-type distributions. Phase-type distributions are a family of distributions that is dense in the set of positive-valued distributions and can be used to approximate any given distributions. To illustrate our methodology, we focus on a popular model of spreading over networks: the susceptible-infected-susceptible (SIS) networked model. In the standard version of this model, individuals informed about a piece of information transmit this piece to its neighbors at an exponential rate. In this paper, we extend this model to the case of transmission rates following a phase-type distribution. Using this extended model, we analyze the dynamics of the spread based on a vectorial representations of phase-type distributions. We illustrate our results by analyzing spreading processes over networks with transmission and recovery rates following a Weibull distribution.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Masaki Ogura, Victor M. Preciado,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.07379", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07379", "title": "\nOn the Griesmer bound for nonlinear codes", "abstract": "Most bounds on the size of codes hold for any code, whether linear or nonlinear. Notably, the Griesmer bound, holds only in the linear case. In this paper we characterize a family of systematic nonlinear codes for which the Griesmer bound holds. Moreover, we show that the Griesmer bound does not necessarily hold for a systematic code by showing explicit counterexamples. On the other hand, we are also able to provide (weaker) versions of the Griesmer bound holding for all systematic codes.", "subjects": "Information Theory (cs.IT)", "authors": "Emanuele Bellini, Eleonora Guerrini, Alessio Meneghetti, Massimiliano Sala,", "date": "2015-1-18"}, 
{"urllink": "http://arxiv.org/abs/1502.07373", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07373", "title": "\nThe Spy in the Sandbox -- Practical Cache Attacks in Javascript", "abstract": "We present the first micro-architectural side-channel attack which runs entirely in the browser. In contrast to other works in this genre, this attack does not require the attacker to install any software on the victim's machine -- to facilitate the attack, the victim needs only to browse to an untrusted webpage with attacker-controlled content. This makes the attack model highly scalable and extremely relevant and practical to today's web, especially since most desktop browsers currently accessing the Internet are vulnerable to this attack. Our attack, which is an extension of the last-level cache attacks of Yarom et al., allows a remote adversary recover information belonging to other processes, other users and even other virtual machines running on the same physical host as the victim web browser. We describe the fundamentals behind our attack, evaluate its performance using a high bandwidth covert channel and finally use it to construct a system-wide mouse/network activity logger. Defending against this attack is possible, but the required countermeasures can exact an impractical cost on other benign uses of the web browser and of the computer.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Yossef Oren, Vasileios P. Kemerlis, Simha Sethumadhavan, Angelos D. Keromytis,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.07364", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07364", "title": "\nOpen Source Remote Monitoring for Rural Solar Electrification Projects", "abstract": "Renewable energy systems are an increasingly popular way to generate electricity around the world. As wind and solar technologies gradually begin to supplant the use of fossil fuels as preferred means of energy production, new challenges are emerging which are unique to the experience of decentralized power generation. One such challenge is the development of effective monitoring technologies to relay diagnostic information from remote energy systems to data analysis centers. The ability to easily obtain, synthesize, and evaluate data pertaining to the behavior of a potentially vast number of individual power sources is of critical importance to the maintainability of the next generation of intelligent grid infrastructure. However, the application space of remote monitoring extends well beyond this. This paper details the development and implementation of an open-source monitoring framework for remote solar energy systems. The necessity for such a framework to be open is much better understood when considered through the lens of the theoretical potential for remote monitoring technologies in developing countries. The United States and other industrialized nations in the so-called 'first world' are likely to be slow to seriously adopt renewable energy on account of the massive investment and infrastructural changes required for its integration into the existing electrical grid. In countries where grid infrastructure is generally inadequate or nonexistent, this barrier is far less of a concern, and renewable energy technologies are viewed more as an enabling tool for progress than as a disruptive and expensive technological tangent. In this context as well, remote monitoring has a role to play.", "subjects": "Computers and Society (cs.CY)", "authors": "Nikolas Wolfe,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.07331", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07331", "title": "\nHighly corrupted image inpainting through hypoelliptic diffusion", "abstract": "We present a new image inpainting algorithm, the Averaging and Hypoelliptic Evolution (AHE) algorithm, inspired by the one presented in [1] and based upon a (semi-discrete) variation of the Citti--Petitot--Sarti model of the primary visual cortex V1. In particular, we focus on reconstructing highly corrupted images (i.e. where more than the 80% of the image is missing). [1] U. Boscain, R. A. Chertovskih, J. P. Gauthier, and A. O. Remizov, Hypoelliptic diffusion and human vision: a semidiscrete new twist, SIAM J. Imaging Sci., vol. 7, no. 2, pp. 669--695, 2014.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Dario Prandi, Alexey Remizov, Roman Chertovskih, Ugo Boscain, Jean-Paul Gauthier,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07327", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07327", "title": "\nThe Complexity of General-Valued CSPs", "abstract": "An instance of the Valued Constraint Satisfaction Problem (VCSP) is given by a finite set of variables, a finite domain of labels, and a sum of functions, each function depending on a subset of the variables. Each function can take finite values specifying costs of assignments of labels to its variables or the infinite value, which indicates infeasible assignments. The goal is to find an assignment of labels to the variables that minimizes the sum. We study (assuming that P NP) how the complexity of this very general problem depends on the set of functions allowed in the instances, the so-called constraint language. The case when all allowed functions take values in corresponds to ordinary CSPs, where one deals only with the feasibility issue and there is no optimization. This case is the subject of the Algebraic CSP Dichotomy Conjecture predicting for which constraint languages CSPs are tractable and for which NP-hard. The case when all allowed functions take only finite values corresponds to finite-valued CSP, where the feasibility aspect is trivial and one deals only with the optimization issue. The complexity of finite-valued CSPs was fully classified by Thapper and vivn 'y. An algebraic necessary condition for tractability of a general-valued CSP with a fixed constraint language was recently given by Kozik and Ochremiak. As our main result, we prove that if a constraint language satisfies this algebraic necessary condition, and the feasibility CSP corresponding to the VCSP with this language is tractable, then the VCSP is tractable. The algorithm is a simple combination of the assumed algorithm for the feasibility CSP and the standard LP relaxation. As a corollary, we obtain that a dichotomy for ordinary CSPs would imply a dichotomy for general-valued CSPs.", "subjects": "Computational Complexity (cs.CC)", "authors": "Vladimir Kolmogorov, Andrei Krokhin, Michal Rolinek,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.07326", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07326", "title": "\nRational fuzzy attribute logic", "abstract": "We present a logic for reasoning with if-then formulas which involve constants for rational truth degrees from the unit interval. We introduce graded semantic and syntactic entailment of formulas. We prove the logic is complete in Pavelka style and depending on the choice of structure of truth degrees, the logic is a decidable fragment of the Rational Pavelka logic (RPL) or the Rational Product Logic (RL). We also present a characterization of the entailment based on least models and study related closure structures.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Vilem Vychodil,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07314", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07314", "title": "\nPath Finding under Uncertainty through Probabilistic Inference", "abstract": "We introduce a new approach to solving path-finding problems under uncertainty by representing them as probabilistic models and applying domain-independent inference algorithms to the models. This approach separates problem representation from the inference algorithm and provides a framework for efficient learning of path-finding policies. We evaluate the new approach on the Canadian Traveler Problem, which we formulate as a probabilistic model, and show how probabilistic inference allows high performance stochastic policies to be obtained for this problem.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "David Tolpin, Brooks Paige, Frank Wood,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07288", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07288", "title": "\nAutomata and Graph Compression", "abstract": "We present a theoretical framework for the compression of automata, which are widely used in speech processing and other natural language processing tasks. The framework extends to graph compression. Similar to stationary ergodic processes, we formulate a probabilistic process of graph and automata generation that captures real world phenomena and provide a universal compression scheme LZA for this probabilistic model. Further, we show that LZA significantly outperforms other compression techniques such as gzip and the UNIX compress command for several synthetic and real data sets.", "subjects": "Information Theory (cs.IT)", "authors": "Mehryar Mohri, Michael Riley, Ananda Theertha Suresh,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07282", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07282", "title": "\nEmpirical Study of Traffic Velocity Distribution and its Effect on  VANETs Connectivity", "abstract": "In this article we use real traffic data to confirm that vehicle velocities follow Gaussian distribution in steady state traffic regimes (free-flow, and congestion). We also show that in the transition between free-flow and congestion, the velocity distribution is better modeled by generalized extreme value distribution (GEV). We study the effect of the different models on estimating the probability distribution of connectivity duration between vehicles in vehicular ad-hoc networks.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Sherif M. Abuelenin, Adel Y. Abul-Magd,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.07267", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07267", "title": "\nAccuracy Enhancement of Pickett Tunnelling Barrier Memristor Model", "abstract": "Titanium dioxide (TiO2) memristors exhibit complex conduction mechanism. Several models of different complexity have been developed in order to mimic the experimental results for physical behaviors observed in memristor devices. Pickett's tunneling barrier model describes the TiO2 memristors, and utilizes complex derivative of tunnel barrier width. It attains a large error in the ON switching region. Variety of research consider it as the reference model for the TiO2 memristors. In this paper, we first analyze the theory of operation of the memristor and discuss Pickett's model. Then, we propose a modification to its derivative functions to provide a lower error and closer agreement with physical behavior. This modification is represented by two additional fitting parameters to damp or accelerate the tunnel width derivative. Also, we incorporate a hard limiter term to limit the tunnel width to its physical extremes 1 nm and 2 nm. We run simulations to test the model modifications and we compare the results to the experimental and original Pickett's model results. The modified model more closely resembles the experimental behavior of TiO2 memristors and potentially enables the memristor to be used as a multilevel memory.", "subjects": "Emerging Technologies (cs.ET)", "authors": "Ahmad Daoud, Ahmed Dessouki, Sherif Abuelenin,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07258", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07258", "title": "\nIdentifying an Honest EXP^NP Oracle Among Many", "abstract": "We provide a general framework to remove short advice by formulating the following computational task for a function f: given two oracles at least one of which is honest (i.e. correctly computes f on all inputs) as well as an input, the task is to compute f on the input with the help of the oracles by a probabilistic polynomial-time machine, which we shall call a selector. We characterize the languages for which short advice can be removed by the notion of selector: a paddable language has a selector if and only if short advice of a probabilistic machine that accepts the language can be removed under any relativized worlds. Previously, instance checkers have served as a useful tool to remove short advice of probabilistic computation. We indicate that existence of instance checkers is a property stronger than that of removing short advice: there exists a selector for EXP^NP-complete languages, whereas no instance checker for these languages exists unless EXP^NP = NEXP.", "subjects": "Computational Complexity (cs.CC)", "authors": "Shuichi Hirahara,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07257", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07257", "title": "\nBreaking Sticks and Ambiguities with Adaptive Skip-gram", "abstract": "Recently proposed Skip-gram model is a powerful method for learning high-dimensional word representations that capture rich semantic relationships between words. However, Skip-gram as well as most prior work on learning word representations does not take into account word ambiguity and maintain only single representation per word. Although a number of Skip-gram modifications were proposed to overcome this limitation and learn multi-prototype word representations, they either require a known number of word meanings or learn them using greedy heuristic approaches. In this paper we propose the Adaptive Skip-gram model which is a nonparametric Bayesian extension of Skip-gram capable to automatically learn the required number of representations for all words at desired semantic resolution. We derive efficient online variational learning algorithm for the model and empirically demonstrate its efficiency on word-sense induction task.", "subjects": "Computation and Language (cs.CL)", "authors": "Sergey Bartunov, Dmitry Kondrashkin, Anton Osokin, Dmitry Vetrov,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07243", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07243", "title": "\nReal-Time System of Hand Detection And Gesture Recognition In Cyber  Presence Interactive System For E-Learning", "abstract": "The development of technologies of multimedia, linked to that of Internet and democratization of high outflow, has made henceforth E-learning possible for learners being in virtual classes and geographically distributed. The quality and quantity of asynchronous and synchronous communications are the key elements for E-learning success. It is important to have a propitious supervision to reduce the feeling of isolation in E-learning. This feeling of isolation is among the main causes of loss and high rates of stalling in E-learning. The researches to be conducted in this domain aim to bring solutions of convergence coming from real time image for the capture and recognition of hand gestures. These gestures will be analyzed by the system and transformed as indicator of participation. This latter is displayed in the table of performance of the tutor as a curve according to the time. In case of isolation of learner, the indicator of participation will become red and the tutor will be informed of learners with difficulties to participate during learning session.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Bousaaid Mourad, Ayaou Tarik, Afdel Karim, Estraillier Pascal,", "date": "2014-12-8"}, 
{"urllink": "http://arxiv.org/abs/1502.07242", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07242", "title": "\nAutonomous Vehicle Public Transportation System: Scheduling and  Admission Control", "abstract": "Technology of autonomous vehicles (AVs) is getting mature and many AVs will appear on the roads in the near future. AVs become connected with the support of various vehicular communication technologies and they possess high degree of control to respond to instantaneous situations cooperatively with high efficiency and flexibility. In this paper, we propose a new public transportation system based on AVs. It manages a fleet of AVs to accommodate transportation requests, offering point-to-point services with ride sharing. We focus on the two major problems of the system: scheduling and admission control. The former is to configure the most economical schedules and routes for the AVs to satisfy the admissible requests while the latter is to determine the set of admissible requests among all requests to produce maximum profit. The scheduling problem is formulated as a mixed-integer linear program and the admission control problem is cast as a bilevel optimization, which embeds the scheduling problem as the major constraint. By utilizing the analytical properties of the problem, we develop an effective genetic-algorithm-based method to tackle the admission control problem. We validate the performance of the algorithm with real-world transportation service data.", "subjects": "Systems and Control (cs.SY)", "authors": "Albert Y.S. Lam, Yiu-Wing Leung, Xiaowen Chu,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07241", "category": "Computer Science ", "pdflink": "http://arxiv.org/html/1502.07241", "title": "\nProceedings of the DATE Friday Workshop on Heterogeneous Architectures  and Design Methods for Embedded Image Systems (HIS 2015)", "abstract": "This volume contains the papers accepted at the DATE Friday Workshop on Heterogeneous Architectures and Design Methods for Embedded Image Systems (HIS 2015), held in Grenoble, France, March 13, 2015. HIS 2015 was co-located with the Conference on Design, Automation and Test in Europe (DATE).", "subjects": "Hardware Architecture (cs.AR)", "authors": "Frank Hannig, Dietmar Fey, Anton Lokhmotov,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.07228", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07228", "title": "\nA Survey of Millimeter Wave (mmWave) Communications for 5G:  Opportunities and Challenges", "abstract": "With the explosive growth of mobile data demand, the fifth generation (5G) mobile network would exploit the enormous amount of spectrum in the millimeter wave (mmWave) bands to greatly increase communication capacity. There are fundamental differences between mmWave communications and existing other communication systems, in terms of high propagation loss, directivity, and sensitivity to blockage. These characteristics of mmWave communications pose several challenges to fully exploit the potential of mmWave communications, including integrated circuits and system design, interference management, spatial reuse, anti-blockage, and dynamics control. To address these challenges, we carry out a survey of existing solutions and standards, and propose design guidelines in architectures and protocols for mmWave communications. We also discuss the potential applications of mmWave communications in the 5G network, including the small cell access, the cellular access, and the wireless backhaul. Finally, we discuss relevant open research issues including the new physical layer technology, software-defined network architecture, measurements of network state information, efficient control mechanisms, and heterogeneous networking, which should be further investigated to facilitate the deployment of mmWave communication systems in the future 5G networks.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Yong Niu, Yong Li, Depeng Jin, Li Su, Athanasios V. Vasilakos,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07220", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07220", "title": "\nGroebner basis in Boolean rings is not polynomial-space", "abstract": "We give an example where the number of elements of a Groebner basis in a Boolean ring is not polynomially bounded in terms of the bitsize and degrees of the input.", "subjects": "Symbolic Computation (cs.SC)", "authors": "Mark van Hoeij,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.07209", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07209", "title": "\nExploiting Feature and Class Relationships in Video Categorization with  Regularized Deep Neural Networks", "abstract": "In this paper, we study the challenging problem of categorizing videos according to high-level semantics such as the existence of a particular human action or a complex event. Although extensive efforts have been devoted in recent years, most existing works combined multiple video features using simple fusion strategies and neglected the utilization of inter-class semantic relationships. This paper proposes a novel unified framework that jointly exploits the feature relationships and the class relationships for improved categorization performance. Specifically, these two types of relationships are estimated and utilized by rigorously imposing regularizations in the learning process of a deep neural network (DNN). Such a regularized DNN (rDNN) can be efficiently realized using a GPU-based implementation with an affordable training cost. Through arming the DNN with better capability of harnessing both the feature and the class relationships, the proposed rDNN is more suitable for modeling video semantics. With extensive experimental evaluations, we show that rDNN produces superior performance over several state-of-the-art approaches. On the well-known Hollywood2 and Columbia Consumer Video benchmarks, we obtain very competitive results: 66.9 % and 73.5 % respectively in terms of mean average precision. In addition, to substantially evaluate our rDNN and stimulate future research on large scale video categorization, we collect and release a new benchmark dataset, called FCVID, which contains 91,223 Internet videos and 239 manually annotated categories.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Yu-Gang Jiang, Zuxuan Wu, Jun Wang, Xiangyang Xue, Shih-Fu Chang,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07206", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07206", "title": "\nIncremental DFS Trees on Arbitrary Directed Graphs", "abstract": "We present a new algorithm for maintaining a DFS tree of an arbitrary directed graph under any sequence of edge insertions. Our algorithm requires a total of time in the worst case to process a sequence of edge insertions, where is the number of vertices in the graph and is the total number of edges in the final graph. We also prove lower bounds for variations of this problem.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Giorgio Ausiello, Paolo G. Franciosa, Giuseppe F. Italiano, Andrea Ribichini,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07191", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07191", "title": "\nConstruction and implementation of asymptotic expansions for  Jacobi--type orthogonal polynomials", "abstract": "We are interested in the asymptotic behavior of orthogonal polynomials of the generalized Jacobi type as their degree goes to . These are defined on the interval with weight function , and a real, analytic and strictly positive function on . This information is available in the work of Kuijlaars, McLaughlin, Van Assche and Vanlessen, where the authors use the Riemann--Hilbert formulation and the Deift--Zhou non-linear steepest descent method. We show that computing higher order terms can be simplified, leading to their efficient construction. The resulting asymptotic expansions in every region of the complex plane are implemented both symbolically and numerically, and the code is made publicly available.", "subjects": "Mathematical Software (cs.MS)", "authors": "Alfredo Dea\u00f1o, Daan Huybrechs, Peter Opsomer,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07169", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07169", "title": "\nHigh-Speed Query Processing over High-Speed Networks", "abstract": "Modern memory-optimized clusters entail two levels of networks: connecting CPUs and NUMA regions inside a single server via QPI in the small and multiple servers via Ethernet or Infiniband in the large. A distributed analytical database system has to optimize both levels holistically to enable high-speed query processing over high-speed networks. Previous work instead focussed on slow interconnects and CPU-intensive algorithms that speed up query processing by reducing network traffic as much as possible. Tuning distributed query processing for the network in the small was not an issue due to the large gap between network throughput and CPU speed. A cluster of machines connected via standard Gigabit Ethernet actually performs worse than a single many-core server. The increased main-memory capacity in the cluster remains the sole benefit of such a scale-out. The economic viability of Infiniband and other high-speed interconnects has changed the game. This paper presents HyPer's distributed query engine that is carefully tailored for both the network in the small and in the large. It facilitates NUMA-aware message buffer management for fast local processing, remote direct memory access (RDMA) for high-throughput communication, and asynchronous operations to overlap computation and communication. An extensive evaluation using the TPC-H benchmark shows that this holistic approach not only allows larger inputs due to the increased main-memory capacity of the cluster, but also speeds up query execution compared to a single server.", "subjects": "Databases (cs.DB)", "authors": "Wolf R\u00f6diger, Tobias M\u00fchlbauer, Alfons Kemper, Thomas Neumann,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07167", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07167", "title": "\nLinear complexity SimRank computation based on the iterative diagonal  estimation", "abstract": "This paper presents a deterministic linear time complexity IDE-SimRank method to approximately compute SimRank with proved error bound. SimRank is a well-known similarity measure between graph vertices which relies on graph topology only and is built on intuition that \"two objects are similar if they are related to similar objects\". The fixed point equation for direct SimRank computation is the discrete Lyapunov equation with specific diagonal matrix in the right hand side. The proposed method is based on estimation of this diagonal matrix with GMRES and use this estimation to compute singe-source and single pairs queries. These computations are executed with the part of series converging to the discrete Lyapunov equation solution.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "I.V. Oseledets, G.V. Ovchinnikov, A. M. Katrutsa,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07162", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07162", "title": "\nMeasuring Online Social Bubbles", "abstract": "Social media have quickly become a prevalent channel to access information, spread ideas, and influence opinions. However, it has been suggested that social and algorithmic filtering may cause exposure to less diverse points of view, and even foster polarization and misinformation. Here we explore and validate this hypothesis quantitatively for the first time, at the collective and individual levels, by mining three massive datasets of web traffic, search logs, and Twitter posts. Our analysis shows that collectively, people access information from a significantly narrower spectrum of sources through social media and email, compared to search. The significance of this finding for individual exposure is revealed by investigating the relationship between the diversity of information sources experienced by users at the collective and individual level. There is a strong correlation between collective and individual diversity, supporting the notion that when we use social media we find ourselves inside \"social bubbles\". Our results could lead to a deeper understanding of how technology biases our exposure to new information.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Dimitar Nikolov, Diego F. M. Oliveira, Alessandro Flammini, Filippo Menczer,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07157", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07157", "title": "\nExploiting a comparability mapping to improve bi-lingual data  categorization: a three-mode data analysis perspective", "abstract": "We address in this paper the co-clustering and co-classification of bilingual data laying in two linguistic similarity spaces when a comparability measure defining a mapping between these two spaces is available. A new approach that we can characterized as a three-mode analysis scheme, is proposed to mix the comparability measure with the two similarity measures. Our aim is to improve jointly the accuracy of classification and clustering tasks performed in each of the two linguistic spaces, as well as the quality of the final alignment of comparable clusters that can be obtained. We used first some purely synthetic random data sets to assess our formal similarity-comparability mixing model. We then propose two variants of the comparability measure that has been defined by (Li and Gaussier 2010) in the context of bilingual lexicon extraction to adapt it to clustering or categorizing tasks. These two variant measures are subsequently used to evaluate our similarity-comparability mixing model in the context of the co-classification and co-clustering of comparable textual data sets collected from Wikipedia categories for the English and French languages. Our experiments show clear improvements in clustering and classification accuracies when mixing comparability with similarity measures, with, as expected, a higher robustness obtained when the two comparability variant measures that we propose are used. We believe that this approach is particularly well suited for the construction of thematic comparable corpora of controllable quality.", "subjects": "Information Retrieval (cs.IR)", "authors": "Pierre-Fran\u00e7ois Marteau, Guiyao Ke,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.07143", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07143", "title": "\nThe VC-Dimension of Similarity Hypotheses Spaces", "abstract": "Given a set and a function which labels each element of with either or , we may define a function to measure the similarity of pairs of points in according to . Specifically, for we define by . This idea can be extended to a set of functions, or hypothesis space by defining a similarity hypothesis space . We show that .", "subjects": "Learning (cs.LG)", "authors": "Mark Herbster, Paul Rubenstein, James Townsend,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07133", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07133", "title": "\nOn the Performance comparison of RIP, OSPF, IS-IS and EIGRP routing  protocols", "abstract": "Nowadays, routing protocols have become a crucial part of the modern communication networks. A routing protocol's responsibility lies in determining the way routers communicate with each other in order to forward any kind of packets, from a source to a destination, using the optimal path that would provide the most efficiency. There are many routing protocols out there today, some old and some new, but all are used for the same purpose. In general, to ideally select routes between any two nodes on a computer network and disseminate information. This paper takes into consideration four of such routing protocols (RIP, OSPF, IS-IS and EIGRP), expresses them and analyzes their way of operation. It also presents the results of a simulation, that took place for the sole purpose of studying the behavior of those four protocols, under the same circumstances, as well as the evaluation of the comparison with one another based on the results of the simulation.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Vasos Hadjioannou,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07123", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07123", "title": "\nDegrees-of-Freedom of the K-User MISO Interference Channel with Delayed  Local CSIT", "abstract": "This paper considers a K-user Multiple-Input-Single-Output (MISO) Interference Channel (IC), where the channel state information obtained by the transmitters (CSIT) is perfect, but completely outdated. A Retrospective Interference Alignment (RIA) using such delayed CSIT was proposed by the authors of [1] for the MISO Broadcast Channel (BC), but the extension to the MISO IC is a non-trivial step as each transmitter only has the message intended for the corresponding user. Recently, [7] focused on a Single-Input-Single-Output (SISO) IC and solved such bottleneck by inventing a distributed higher order symbol generation. Our main work is to extend [7] to the MISO case by integrating some features of the scheme proposed in [1]. The achieved sum Degrees-of-Freedom (DoF) performance is asymptotically given by 64/15 when , outperforming all the previously known results.", "subjects": "Information Theory (cs.IT)", "authors": "Chenxi Hao, Bruno Clerckx,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07120", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07120", "title": "\nRecharging Probably Keeps Batteries Alive", "abstract": "The kinetic battery model is a popular model of the dynamic behavior of a conventional battery, useful to predict or optimize the time until battery depletion. The model however lacks certain obvious aspects of batteries in-the-wild, especially with respect to (i) the effects of random influences and (ii) the behavior when charging up to capacity bounds. This paper considers the kinetic battery model with bounded capacity in the context of piecewise constant yet random charging and discharging. The resulting model enables the time-dependent evaluation of the risk of battery depletion. This is exemplified in a power dependability study of a nano satellite mission.", "subjects": "Systems and Control (cs.SY)", "authors": "Holger Hermanns, Jan Kr\u010d\u00e1l, Gilles Nies,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07118", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07118", "title": "\nLocal Linearizability", "abstract": "Linearizability is the most accepted consistency condition used to describe the semantics of concurrent data structures. One of its benefits is its intuitive definition that is well understandable to system designers and programmers. However, linearizability is very strong and often linearizable implementations show unsatisfactory performance and scalability. To open up possibilities for more efficient implementations of concurrent data structures, a plethora of consistency conditions has been considered in the literature. In this paper, we utilise the idea of a decomposition principle and define local linearizability, a new consistency condition that is closely connected to linearizability. Local linearizability is weaker than linearizability for pools, queues, and stacks. Local linearizability is intuitive, verifiable, and opens up possibilities for new efficient implementations. In particular, we provide new well-performing and scalable implementations of locally linearizable concurrent queues and stacks.", "subjects": "Programming Languages (cs.PL)", "authors": "Andreas Haas, Thomas A. Henzinger, Andreas Holzer, Christoph M. Kirsch, Michael Lippautz, Hannes Payer, Ali Sezgin, Ana Sokolova, Helmut Veith,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07106", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07106", "title": "\nCrowdSurf: Empowering Informed Choices in the Web", "abstract": "When surfing the Internet, individuals leak personal and corporate information to third parties whose (legitimate or not) businesses revolve around the value of collected data. The implications are serious, from a person unwillingly exposing private information to an unknown third party, to a company unable to manage the flow of its information to the outside world. The point is that individuals and companies are more and more kept out of the loop when it comes to control private data. With the goal of empowering informed choices in information leakage through the Internet, we propose CROWDSURF, a system for comprehensive and collaborative auditing of data that flows to Internet services. Similarly to open-source efforts, we enable users to contribute in building awareness and control over privacy and communication vulnerabilities. CROWDSURF provides the core infrastructure and algorithms to let individuals and enterprises regain control on the information exposed on the web. We advocate CROWDSURF as a data processing layer positioned right below HTTP in the host protocol stack. This enables the inspection of clear-text data even when HTTPS is deployed and the application of processing rules that are customizable to fit any need. Preliminary results obtained executing a prototype implementation on ISP traffic traces demonstrate the feasibility of CROWDSURF.", "subjects": "Computers and Society (cs.CY)", "authors": "Hassan Metwalley, Stefano Traverso, Marco Mellia, Stanislav Miskovic, Mario Baldi,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07085", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07085", "title": "\nAn approximation algorithm for the longest cycle problem in solid grid  graphs", "abstract": "Although, the Hamiltonicity of solid grid graphs are polynomial-time decidable, the complexity of the longest cycle problem in these graphs is still open. In this paper, by presenting a linear-time constant-factor approximation algorithm, we show that the longest cycle problem in solid grid graphs is in APX. More precisely, our algorithm finds a cycle of length at least in 2-connected -node solid grid graphs. Keywords: Longest cycle, Hamiltonian cycle, Approximation algorithm, Solid grid graph.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Asghar Asgharian Sardroud, Alireza Bagheri,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07073", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07073", "title": "\nStrongly Adaptive Online Learning", "abstract": "emph are algorithms whose performance on is close to optimal. We present a reduction that can transform standard low-regret algorithms to strongly adaptive. As a consequence, we derive simple, yet efficient, strongly adaptive algorithms for a handful of problems.", "subjects": "Learning (cs.LG)", "authors": "Amit Daniely, Alon Gonen, Shai Shalev-Shwartz,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07066", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07066", "title": "\nRobust MIMO Harvest-and-Jam Helpers and Relaying for Secret  Communications", "abstract": "Cooperative jamming has been demonstrated to be an effective means to provide secret wireless communications and yet this is realized at the expense of the power consumption of the friendly jammers. This paper considers the scenario where friendly jammers harvest energy wirelessly from the signal transmitted by the source, and then use only the harvested energy to transmit the jamming signals for improving the secrecy of the communications of the source to the destination. In particular, we investigate the use of multi-antenna harvest-and-jam (HJ) helpers in a multi-antenna amplify-and-forward (AF) relay wiretap channel assuming that the direct link between the source and destination is broken. Our goal is to maximize the achievable secrecy rate at the destination subject to the transmit power constraints of the AF relay and HJ helpers. In the case of perfect channel state information (CSI), the joint optimization of the artificial noise (AN) covariance for jamming and the AF beamforming matrix is presented as well as a suboptimal solution with lower complexity based on semidefinite relaxation (SDR) which is tight in this case. For the practical case where the CSI is imperfect at both the relay and the HJ helpers, we provide the formulation of the robust optimization for maximizing the worst-case secrecy rate. Using SDR techniques, a near-optimal robust scheme is proposed. Numerical results are provided to validate the effectiveness of the HJ protocol.", "subjects": "Information Theory (cs.IT)", "authors": "Hong Xing, Kai-Kit Wong, Zheng Chu, Arumugam Nallanathan,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07063", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07063", "title": "\nRF-Powered Cognitive Radio Networks: Technical Challenges and  Limitations", "abstract": "The increasing demand for spectral and energy efficient communication networks has spurred a great interest in energy harvesting (EH) cognitive radio networks (CRNs). Such a revolutionary technology represents a paradigm shift in the development of wireless networks, as it can simultaneously enable the efficient use of the available spectrum and the exploitation of radio frequency (RF) energy in order to reduce the reliance on traditional energy sources. This is mainly triggered by the recent advancements in microelectronics that puts forward RF energy harvesting as a plausible technique in the near future. On the other hand, it is suggested that the operation of a network relying on harvested energy needs to be redesigned to allow the network to reliably function in the long term. To this end, the aim of this survey paper is to provide a comprehensive overview of the recent development and the challenges regarding the operation of CRNs powered by RF energy. In addition, the potential open issues that might be considered for the future research are also discussed in this paper.", "subjects": "Information Theory (cs.IT)", "authors": "Lina Mohjazi, Mehrdad Dianati, George K. Karagiannidis, Sami Muhaidat, Mahmoud Al-Qutayri,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07058", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07058", "title": "\nEvaluation of Deep Convolutional Nets for Document Image Classification  and Retrieval", "abstract": "This paper presents a new state-of-the-art for document image classification and retrieval, using features learned by deep convolutional neural networks (CNNs). In object and scene analysis, deep neural nets are capable of learning a hierarchical chain of abstraction from pixel inputs to concise and descriptive representations. The current work explores this capacity in the realm of document analysis, and confirms that this representation strategy is superior to a variety of popular hand-crafted alternatives. Experiments also show that (i) features extracted from CNNs are robust to compression, (ii) CNNs trained on non-document images transfer well to document analysis tasks, and (iii) enforcing region-specific feature-learning is unnecessary given sufficient training data. This work also makes available a new labelled subset of the IIT-CDIP collection, containing 400,000 document images across 16 categories, useful for training new CNNs for document analysis.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Adam W. Harley, Alex Ufkes, Konstantinos G. Derpanis,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07055", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07055", "title": "\nA Novel Architecture of Area Efficient FFT Algorithm for FPGA  Implementation", "abstract": "Fast Fourier transform (FFT) of large number of samples requires huge hardware resources of field programmable gate arrays (FPGA), which needs more area and power. In this paper, we present an area efficient architecture of FFT processor that reuses the butterfly elements several times. The FFT processor is simulated using VHDL and the results are validated on a Virtex-6 FPGA. The proposed architecture outperforms the conventional architecture of a -point FFT processor in terms of area which is reduced by a factor of with negligible increase in processing time.", "subjects": "Hardware Architecture (cs.AR)", "authors": "Atin Mukherjee, Amitabha Sinha, Debesh Choudhury,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07041", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07041", "title": "\nDescribing Colors, Textures and Shapes for Content Based Image Retrieval  - A Survey", "abstract": "Visual media has always been the most enjoyed way of communication. From the advent of television to the modern day hand held computers, we have witnessed the exponential growth of images around us. Undoubtedly it's a fact that they carry a lot of information in them which needs be utilized in an effective manner. Hence intense need has been felt to efficiently index and store large image collections for effective and on- demand retrieval. For this purpose low-level features extracted from the image contents like color, texture and shape has been used. Content based image retrieval systems employing these features has proven very successful. Image retrieval has promising applications in numerous fields and hence has motivated researchers all over the world. New and improved ways to represent visual content are being developed each day. Tremendous amount of research has been carried out in the last decade. In this paper we will present a detailed overview of some of the powerful color, texture and shape descriptors for content based image retrieval. A comparative analysis will also be carried out for providing an insight into outstanding challenges in this field.", "subjects": "Information Retrieval (cs.IR)", "authors": "Jamil Ahmad, Muhammad Sajjad, Irfan Mehmood, Seungmin Rho, Sung Wook Baik,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07038", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07038", "title": "\nWeb-scale Surface and Syntactic n-gram Features for Dependency Parsing", "abstract": "We develop novel first- and second-order features for dependency parsing based on the Google Syntactic Ngrams corpus, a collection of subtree counts of parsed sentences from scanned books. We also extend previous work on surface -gram features from Web1T to the Google Books corpus and from first-order to second-order, comparing and analysing performance over newswire and web treebanks. Surface and syntactic -grams both produce substantial and complementary gains in parsing accuracy across domains. Our best system combines the two feature sets, achieving up to 0.8% absolute UAS improvements on newswire and 1.4% on web text.", "subjects": "Computation and Language (cs.CL)", "authors": "Dominick Ng, Mohit Bansal, James R. Curran,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07027", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07027", "title": "\nVariability in data streams", "abstract": "We consider the problem of tracking with small relative error an integer function defined by a distributed update stream . Existing streaming algorithms with worst-case guarantees for this problem assume to be monotone; there are very large lower bounds on the space requirements for summarizing a distributed non-monotonic stream, often linear in the size of the stream. Input streams that give rise to large space requirements are highly variable, making relatively large jumps from one timestep to the next. However, streams often vary slowly in practice. What has heretofore been lacking is a framework for non-monotonic streams that admits algorithms whose worst-case performance is as good as existing algorithms for monotone streams and degrades gracefully for non-monotonic streams as those streams vary more quickly. In this paper we propose such a framework. We introduce a new stream parameter, the \"variability\" , deriving its definition in a way that shows it to be a natural parameter to consider for non-monotonic streams. It is also a useful parameter. From a theoretical perspective, we can adapt existing algorithms for monotone streams to work for non-monotonic streams, with only minor modifications, in such a way that they reduce to the monotone case when the stream happens to be monotone, and in such a way that we can refine the worst-case communication bounds from to . From a practical perspective, we demonstrate that can be small in practice by proving that is for monotone streams and for streams that are \"nearly\" monotone or that are generated by random walks. We expect to be for many other interesting input classes as well.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "David Felber, Rafail Ostrovsky,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07026", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07026", "title": "\nUndergraduate Signal Processing Laboratories for the Android Operating  System", "abstract": "We present a DSP simulation environment that will enable students to perform laboratory exercises using Android mobile devices and tablets. Due to the pervasive nature of the mobile technology, education applications designed for mobile devices have the potential to stimulate student interest in addition to offering convenient access and interaction capabilities. This paper describes a portable signal processing laboratory for the Android platform. This software is intended to be an educational tool for students and instructors in DSP, and signals and systems courses. The development of Android JDSP (A-JDSP) is carried out using the Android SDK, which is a Java-based open source development platform. The proposed application contains basic DSP functions for convolution, sampling, FFT, filtering and frequency domain analysis, with a convenient graphical user interface. A description of the architecture, functions and planned assessments are presented in this paper.", "subjects": "Computers and Society (cs.CY)", "authors": "Suhas Ranganath, JJ Thiagarajan, KN Ramamurthy, Shuang Hu, Mahesh Banavar, Andreas Spanias,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07019", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07019", "title": "\nBuilding with Drones: Accurate 3D Facade Reconstruction using MAVs", "abstract": "Automatic reconstruction of 3D models from images using multi-view Structure-from-Motion methods has been one of the most fruitful outcomes of computer vision. These advances combined with the growing popularity of Micro Aerial Vehicles as an autonomous imaging platform, have made 3D vision tools ubiquitous for large number of Architecture, Engineering and Construction applications among audiences, mostly unskilled in computer vision. However, to obtain high-resolution and accurate reconstructions from a large-scale object using SfM, there are many critical constraints on the quality of image data, which often become sources of inaccuracy as the current 3D reconstruction pipelines do not facilitate the users to determine the fidelity of input data during the image acquisition. In this paper, we present and advocate a closed-loop interactive approach that performs incremental reconstruction in real-time and gives users an online feedback about the quality parameters like Ground Sampling Distance (GSD), image redundancy, etc on a surface mesh. We also propose a novel multi-scale camera network design to prevent scene drift caused by incremental map building, and release the first multi-scale image sequence dataset as a benchmark. Further, we evaluate our system on real outdoor scenes, and show that our interactive pipeline combined with a multi-scale camera network approach provides compelling accuracy in multi-view reconstruction tasks when compared against the state-of-the-art methods.", "subjects": "Robotics (cs.RO)", "authors": "Shreyansh Daftry, Christof Hoppe, Horst Bischof,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07015", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07015", "title": "\nA framework to discover potential ideas of new product development from  crowdsourcing application", "abstract": "In this paper, we study idea mining from crowdsourcing applications which encourage a group of people, who are usually undefined and very large sized, to generate ideas for new product development (NPD). In order to isolate the relatively small number of potential ones among ideas from crowd, decision makers not only have to identify the key textual information representing the ideas, but they also need to consider online opinions of people who gave comments and votes on the ideas. Due to the extremely large size of text data generated by people on the Internet, identifying textual information has been carried out in manual ways, and has been considered very time consuming and costly. To overcome the ineffectiveness, this paper introduces a novel framework that can help decision makers discover ideas having the potential to be used in an NPD process. To achieve this, a semi-automatic text mining technique that retrieves useful text patterns from ideas posted on crowdsourcing application is proposed. Then, we provide an online learning algorithm to evaluate whether the idea is potential or not. Finally to verify the effectiveness of our algorithm, we conducted experiments on the data, which are collected from an existing crowd sourcing website.", "subjects": "Information Retrieval (cs.IR)", "authors": "Thanh-Cong Dinh, Hyerim Bae, Jaehun Park, Joonsoo Bae,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.07014", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.07014", "title": "\nGrowth rate of binary words avoiding $xxx^R$", "abstract": "Consider the set of those binary words with no non-empty factors of the form . Du, Mousavi, Schaeffer, and Shallit asked whether this set of words grows polynomially or exponentially with length. In this paper, we demonstrate the existence of upper and lower bounds on the number of such words of length , where each of these bounds is asymptotically equivalent to a (different) function of the form , where , are constants.", "subjects": "Formal Languages and Automata Theory (cs.FL)", "authors": "James D. Currie, Narad Rampersad,", "date": "2015-2-25"}, 
{"urllink": "http://arxiv.org/abs/1502.06993", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06993", "title": "\nPrivacy preserving distributed profile matching in mobile social network", "abstract": "In this document, a privacy-preserving distributed profile matching protocol is proposed in a particular network context called emph. Such networks are often deployed in more or less hostile environments, requiring rigorous security mechanisms. In the same time, energy and computational resources are limited as these heterogeneous networks are frequently constituted by wireless components like tablets or mobile phones. This is why a new encryption algorithm having an high level of security while preserving resources is proposed in this paper. The approach is based on elliptic curve cryptography, more specifically on an almost completely homomorphic cryptosystem over a supersingular elliptic curve, leading to a secure and efficient preservation of privacy in distributed profile matching.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Rachid Chergui,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06956", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06956", "title": "\nTransformation of basic probability assignments to probabilities based  on a new entropy measure", "abstract": "Dempster-Shafer evidence theory is an efficient mathematical tool to deal with uncertain information. In that theory, basic probability assignment (BPA) is the basic element for the expression and inference of uncertainty. Decision-making based on BPA is still an open issue in Dempster-Shafer evidence theory. In this paper, a novel approach of transforming basic probability assignments to probabilities is proposed based on Deng entropy which is a new measure for the uncertainty of BPA. The principle of the proposed method is to minimize the difference of uncertainties involving in the given BPA and obtained probability distribution. Numerical examples are given to show the proposed approach.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Xinyang Deng, Yong Deng,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06948", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06948", "title": "\nBounding the Clique-Width of $H$-free Chordal Graphs", "abstract": "A graph is -free if it has no induced subgraph isomorphic to . Brandst \"adt, Engelfriet, Le and Lozin proved that the class of chordal graphs with independence number at most 3 has unbounded clique-width. Brandst \"adt, Le and Mosca erroneously claimed that the gem and the co-gem are the only two 1-vertex -extensions for which the class of -free chordal graphs has bounded clique-width. In fact we prove that bull-free chordal and co-chair-free chordal graphs have clique-width at most 3 and 4, respectively. In particular, we prove that the clique-width is: (i) bounded for four classes of -free chordal graphs; (ii) unbounded for three subclasses of split graphs. Our main result, obtained by combining new and known results, provides a classification of all but two stubborn cases, that is, with two potential exceptions we determine all graphs for which the class of -free chordal graphs has bounded clique-width. We illustrate the usefulness of this classification for classifying other types of graph classes by proving that the class of -free graphs has bounded clique-width via a reduction to -free chordal graphs. Finally, we give a complete classification of the (un)boundedness of clique-width of -free perfect graphs.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Andreas Brandst\u00e4dt, Konrad K. Dabrowski, Shenwei Huang, Dani\u00ebl Paulusma,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06945", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06945", "title": "\nNew extremal binary self-dual codes of lengths 66 and 68 from codes over  r_k,m", "abstract": "In this work, four circulant and quadratic double circulant (QDC) constructions are applied to the family of the rings R_k,m. Self-dual binary codes are obtained as the Gray images of self-dual QDC codes over R_k,m. Extremal binary self-dual codes of length 64 are obtained as Gray images of ?-four circulant codes over R_2,1 and R_2,2. Extremal binary self-dual codes of lengths 66 and 68 are constructed by applying extension theorems to the F_2 and R_2,1 images of these codes. More precisely, 11 new codes of length 66 and 39 new codes of length 68 are discovered. The codes with these weight enumerators are constructed for the ?first time in literature. The results are tabulated.", "subjects": "Information Theory (cs.IT)", "authors": "Abidin Kaya, Nesibe T\u00fcfek\u00e7i,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06938", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06938", "title": "\nTopology Detection in Microgrids with Micro-Synchrophasors", "abstract": "Network topology in distribution networks is often unknown, because most switches are not equipped with measurement devices and communication links. However, knowledge about the actual topology is critical for safe and reliable grid operation. This paper proposes a voting-based topology detection method based on micro-synchrophasor measurements. The minimal difference between measured and calculated voltage angle or voltage magnitude, respectively, indicates the actual topology. Micro-synchrophasors or micro-Phasor Measurement Units (PMU) are high-precision devices that can measure voltage angle differences on the order of ten millidegrees. This accuracy is important for distribution networks due to the smaller angle differences as compared to transmission networks. For this paper, a microgrid test bed is implemented in MATLAB with simulated measurements from PMUs as well as SCADA measurement devices. The results show that topologies can be detected with high accuracy. Additionally, topology detection by voltage angle shows better results than detection by voltage magnitude.", "subjects": "Systems and Control (cs.SY)", "authors": "Reza Arghandeh, Martin Gahr, Alexandra von Meier, Guido Cavraro, Monika Ruh, G\u00f6ran Andersson,", "date": "2015-1-8"}, 
{"urllink": "http://arxiv.org/abs/1502.06934", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06934", "title": "\nAn Optimal Bidimensional Multi-Armed Bandit Auction for Multi-unit  Procurement", "abstract": "We study the problem of a buyer (aka auctioneer) who gains stochastic rewards by procuring multiple units of a service or item from a pool of heterogeneous strategic agents. The reward obtained for a single unit from an allocated agent depends on the inherent quality of the agent; the agent's quality is fixed but unknown. Each agent can only supply a limited number of units (capacity of the agent). The costs incurred per unit and capacities are private information of the agents. The auctioneer is required to elicit costs as well as capacities (making the mechanism design bidimensional) and further, learn the qualities of the agents as well, with a view to maximize her utility. Motivated by this, we design a bidimensional multi-armed bandit procurement auction that seeks to maximize the expected utility of the auctioneer subject to incentive compatibility and individual rationality while simultaneously learning the unknown qualities of the agents. We first assume that the qualities are known and propose an optimal, truthful mechanism 2D-OPT for the auctioneer to elicit costs and capacities. Next, in order to learn the qualities of the agents in addition, we provide sufficient conditions for a learning algorithm to be Bayesian incentive compatible and individually rational. We finally design a novel learning mechanism, 2D-UCB that is stochastic Bayesian incentive compatible and individually rational.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Satyanath Bhat, Shweta Jain, Sujit Gujar, Y. Narahari,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06922", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06922", "title": "\nDeep Sentence Embedding Using the Long Short Term Memory Network:  Analysis and Application to Information Retrieval", "abstract": "This paper develops a model that addresses sentence embedding using recurrent neural networks (RNN) with Long Short Term Memory (LSTM) cells. The proposed LSTM-RNN model sequentially takes each word in a sentence, extracts its information, and embeds it into a semantic vector. Due to its ability to capture long term memory, the LSTM-RNN accumulates increasingly richer information as it goes through the sentence, and when it reaches the last word, the hidden layer of the network provides a semantic representation of the whole sentence. In this paper, the LSTM-RNN is trained in a weakly supervised manner on user click-through data logged by a commercial web search engine. Visualization and analysis are performed to understand how the embedding process works. The model automatically attenuates the unimportant words and detects the salient keywords in the sentence. Furthermore, these detected keywords automatically activate different cells of the LSTM-RNN, where words belonging to a similar topic activate the same cell. As a semantic representation of the sentence, the embedding vector can be used in many different applications. These keyword detection and topic allocation tasks enabled by the LSTM-RNN allow the network to perform web document retrieval, where the similarity between the query and documents can be measured by the distance between their corresponding sentence embedding vectors computed by the LSTM-RNN. On a web search task, the LSTM-RNN embedding is shown to significantly outperform all existing state of the art methods.", "subjects": "Computation and Language (cs.CL)", "authors": "H. Palangi, L. Deng, Y. Shen, J. Gao, X. He, J. Chen, X. Song, R. Ward,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06904", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06904", "title": "\nSmart Socket for Activity Monitoring", "abstract": "In this short paper we consider the problem of monitoring physical activity in the smart house. The authors suggested a simple device that allows medical staff and relatives to monitor the activity for older adults living alone. This sensor monitors the switching-on of electrical devices. The fact of switching is seen as confirmation of physical activity. It is confirmed by SMS notifications to observers.", "subjects": "Computers and Society (cs.CY)", "authors": "Manfred Sneps-Sneppe, Dmitry Namiot,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06899", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06899", "title": "\nTowards a Tractable Analysis of Localization Fundamentals in Cellular  Networks", "abstract": "When dedicated positioning systems, such as GPS, are unavailable, mobile devices have no choice but to fall back on cellular networks for localization. These, however, are designed primarily with communications goals in mind, where ideally only one base station (BS) is hearable at a given location. Since BSs are not placed with the goal of providing favorable geometries for localization, it is appropriate to study cellular localization performance using random geometries. In the literature, however, localization performance is typically only studied analytically for deterministic (and usually favorable) geometries (e.g., using the Cramer-Rao lower bound). Random geometries are studied through simulation, as no tractable approach exists for gaining analytical insights into how system design affects localization performance in nondeterministic setups. In this paper, we develop a new tractable approach where we endow the BS locations with a distribution by modeling them as a Poisson Point Process (PPP), and use tools from stochastic geometry to obtain easy-to-use expressions for key performance metrics. In particular, we focus on the probability of decoding a given number of BSs at the device of interest, which is shown to be closely coupled with the eventual localization performance. Due to the presence of dominant interferers in the form of other BSs, this probability decreases dramatically with an increase in the desired number of decodable BSs. In order to mitigate this excessive interference, we incorporate both BS coordination and frequency reuse in the proposed framework and quantify the resulting performance gains analytically.", "subjects": "Information Theory (cs.IT)", "authors": "Javier Schloemann, Harpreet S. Dhillon, R. Michael Buehrer,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06882", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06882", "title": "\nOn Reducing Linearizability to State Reachability", "abstract": "Efficient implementations of atomic objects such as concurrent stacks and queues are especially susceptible to programming errors, and necessitate automatic verification. Unfortunately their correctness criteria - linearizability with respect to given ADT specifications - are hard to verify. Even on classes of implementations where the usual temporal safety properties like control-state reachability are decidable, linearizability is undecidable. In this work we demonstrate that verifying linearizability for certain fixed ADT specifications is reducible to control-state reachability, despite being harder for arbitrary ADTs. We effectuate this reduction for several of the most popular atomic objects. This reduction yields the first decidability results for verification without bounding the number of concurrent threads. Furthermore, it enables the application of existing safety-verification tools to linearizability verification.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Ahmed Bouajjani, Michael Emmi, Constantin Enea, Jad Hamza,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06878", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06878", "title": "\nSequential Decision Algorithms for Measurement-Based Impromptu  Deployment of a Wireless Relay Network along a Line", "abstract": "We are motivated by the need, in some applications, for impromptu or as-you-go deployment of wireless sensor networks. A person walks along a line, starting from a sink node (e.g., a base-station), and proceeds towards a source node (e.g., a sensor) which is at an a priori unknown location. At equally spaced locations, he makes link quality measurements to the previous relay, and deploys relays at some of these locations, with the aim to connect the source to the sink by a multihop wireless path. In this paper, we consider two approaches for impromptu deployment: (i) the deployment agent can only move forward (which we call a pure as-you-go approach), and (ii) the deployment agent can make measurements over several consecutive steps before selecting a placement location among them (which we call an explore-forward approach). We consider a light traffic regime, and formulate the problem as a Markov decision process, where the trade-off is among the power used by the nodes, the outage probabilities in the links, and the number of relays placed per unit distance. We obtain the structures of the optimal policies for the pure as-you-go approach as well as for the explore-forward approach. We also consider natural heuristic algorithms, for comparison. Numerical examples show that the explore-forward approach significantly outperforms the pure as-you-go approach. Next, we propose two learning algorithms for the explore-forward approach, based on Stochastic Approximation, which asymptotically converge to the set of optimal policies, without using any knowledge of the radio propagation model. We demonstrate numerically that the learning algorithms can converge (as deployment progresses) to the set of optimal policies reasonably fast and, hence, can be practical, model-free algorithms for deployment over large regions.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Arpan Chattopadhyay, Marceau Coupechoux, Anurag Kumar,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06875", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06875", "title": "\nFixed-Dimensional Energy Games are in Pseudo-Polynomial Time", "abstract": "We generalise the hyperplane separation technique (Chatterjee and Velner, 2013) from multi-dimensional mean-payoff to energy games, and achieve an algorithm for solving the latter whose running time is exponential only in the dimension, but not in the number of vertices of the game graph. This answers an open question whether energy games with arbitrary initial credit can be solved in pseudo-polynomial time for fixed dimensions 3 or larger (Chaloupka, 2013). It also improves the complexity of solving multi-dimensional energy games with given initial credit from non-elementary (Br 'azdil, Jan var, and Ku vera, 2010) to 2EXPTIME, thus establishing their 2EXPTIME-completeness.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Marcin Jurdzi\u0144ski, Ranko Lazi\u0107, Sylvain Schmitz,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06874", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06874", "title": "\nAn Upper Bound on the Minimum Distance of LDPC Codes over GF(q)", "abstract": "In [1] a syndrome counting based upper bound on the minimum distance of regular binary LDPC codes is given. In this paper we extend the bound to the case of irregular and generalized LDPC codes over GF(q). The comparison to the lower bound for LDPC codes over GF(q) and to the upper bound for non-binary codes is done. The new bound is shown to lie under the Gilbert-Varshamov bound at high rates.", "subjects": "Information Theory (cs.IT)", "authors": "Alexey Frolov,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06871", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06871", "title": "\nOn the Multiple Threshold Decoding of LDPC codes over GF(q)", "abstract": "We consider the decoding of LDPC codes over GF(q) with the low-complexity majority algorithm from [1]. A modification of this algorithm with multiple thresholds is suggested. A lower estimate on the decoding radius realized by the new algorithm is derived. The estimate is shown to be better than the estimate for a single threshold majority decoder. At the same time the transition to multiple thresholds does not affect the order of complexity.", "subjects": "Information Theory (cs.IT)", "authors": "Alexey Frolov, Victor Zyablov,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06824", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06824", "title": "\nPersonalized Security Indicators to Detect Application Phishing Attacks  in Mobile Platforms", "abstract": "Phishing in mobile applications is a relevant threat with successful attacks reported in the wild. In such attacks, malicious mobile applications masquerade as legitimate ones to steal user credentials. In this paper we categorize application phishing attacks in mobile platforms and possible countermeasures. We show that personalized security indicators can help users to detect phishing attacks and have very little deployment cost. Personalized security indicators, however, rely on the user alertness to detect phishing attacks. Previous work in the context of website phishing has shown that users tend to ignore the absence of security indicators and fall victim of the attacker. Consequently, the research community has deemed personalized security indicators as an ineffective phishing detection mechanism. We evaluate personalized security indicators as a phishing detection solution in the context of mobile applications. We conducted a large-scale user study where a significant amount of participants that used personalized security indicators were able to detect phishing. All participants that did not use indicators could not detect the attack and entered their credentials to a phishing application. We found the difference in the attack detection ratio to be statistically significant. Personalized security indicators can, therefore, help phishing detection in mobile applications and their reputation as an anti-phishing mechanism should be reconsidered. We also propose a novel protocol to setup personalized security indicators under a strong adversarial model and provide details on its performance and usability.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Claudio Marforio, Ramya Jayaram Masti, Claudio Soriente, Kari Kostiainen, Srdjan Capkun,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06823", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06823", "title": "\nCrowdGather: Entity Extraction over Structured Domains", "abstract": "Crowdsourced entity extraction is often used to acquire data for many applications, including recommendation systems, construction of aggregated listings and directories, and knowledge base construction. Current solutions focus on entity extraction using a single query, e.g., only using \"give me another restaurant\", when assembling a list of all restaurants. Due to the cost of human labor, solutions that focus on a single query can be highly impractical. In this paper, we leverage the fact that entity extraction often focuses on , i.e., domains that are described by a collection of attributes, each potentially exhibiting hierarchical structure. Given such a domain, we enable a richer space of queries, e.g., \"give me another Moroccan restaurant in Manhattan that does takeout\". Naturally, enabling a richer space of queries comes with a host of issues, especially since many queries return empty answers. We develop new statistical tools that enable us to reason about the gain of issuing given little to no information, and show how we can exploit the overlaps across the results of queries for different points of the data domain to obtain accurate estimates of the gain. We cast the problem of over large domains as an adaptive optimization problem that seeks to maximize the number of extracted entities, while minimizing the overall extraction costs. We evaluate our techniques with experiments on both synthetic and real-world datasets, demonstrating a yield of up to 4X over competing approaches for the same budget.", "subjects": "Databases (cs.DB)", "authors": "Theodoros Rekatsinas, Amol Deshpande, Aditya Parameswaran,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06821", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06821", "title": "\nAnalysis of the Impact of Impulsive Noise Parameters on BER Performance  of OFDM Power-Line Communications", "abstract": "It is well known that asynchronous impulsive noise is the main source of distortion that drastically affects the power-line communications (PLC) performance. Recently, more realistic models have been proposed in the literature which better fit the physical properties of real impulsive noise. In this paper, we consider a pulse train model and propose a thorough analysis of the impact of impulsive noise parameters, namely impulse width and amplitude as well as inter-arrival time, on the bit error rate (BER) performance of orthogonal frequency division multiplexing (OFDM) broadband PLC. A comparison with the conventional Bernoulli-Gaussian (BG) impulsive noise model exhibits the difference between the two approaches, showing the necessity of more realistic models.", "subjects": "Information Theory (cs.IT)", "authors": "Kassim Khalil, Patrick CORLAY, Fran\u00e7ois-Xavier Coudoux, Marc G. Gazalet, Mohamed Gharbi,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06820", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06820", "title": "\nOptimization Problems in Correlated Networks", "abstract": "Solving the shortest path and the min-cut problems are key in achieving high performance and robust communication networks. Those problems have often beeny studied in deterministic and independent networks both in their original formulations as well as in several constrained variants. However, in real-world networks, link weights (e.g., delay, bandwidth, failure probability) are often correlated due to spatial or temporal reasons, and these correlated link weights together behave in a different manner and are not always additive. In this paper, we first propose two correlated link-weight models, namely (i) the deterministic correlated model and (ii) the (log-concave) stochastic correlated model. Subsequently, we study the shortest path problem and the min-cut problem under these two correlated models. We prove that these two problems are NP-hard under the deterministic correlated model, and even cannot be approximated to arbitrary degree in polynomial time. However, these two problems are polynomial-time solvable under the (constrained) nodal deterministic correlated model, and can be solved by convex optimization under the (log-concave) stochastic correlated model.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Song Yang, Stojan Trajanovski, Fernando A. Kuipers,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06819", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06819", "title": "\nScale-Adaptive Group Optimization for Social Activity Planning", "abstract": "Studies have shown that each person is more inclined to enjoy a group activity when 1) she is interested in the activity, and 2) many friends with the same interest join it as well. Nevertheless, even with the interest and social tightness information available in online social networks, nowadays many social group activities still need to be coordinated manually. In this paper, therefore, we first formulate a new problem, named Participant Selection for Group Activity (PSGA), to decide the group size and select proper participants so that the sum of personal interests and social tightness of the participants in the group is maximized, while the activity cost is also carefully examined. To solve the problem, we design a new randomized algorithm, named Budget-Aware Randomized Group Selection (BARGS), to optimally allocate the computation budgets for effective selection of the group size and participants, and we prove that BARGS can acquire the solution with a guaranteed performance bound. The proposed algorithm was implemented in Facebook, and experimental results demonstrate that social groups generated by the proposed algorithm significantly outperform the baseline solutions.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Hong-Han Shuai, De-Nian Yang, Philip S. Yu, Ming-Syan Chen,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.06818", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06818", "title": "\nTensor SimRank for Heterogeneous Information Networks", "abstract": "We propose a generalization of SimRank similarity measure for heterogeneous information networks. Given the information network, the intraclass similarity score s(a, b) is high if the set of objects that are related with a and the set of objects that are related with b are pair-wise similar according to all imposed relations.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Ben Usman, Ivan Oseledets,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06811", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06811", "title": "\nA Review of Audio Features and Statistical Models Exploited for Voice  Pattern Design", "abstract": "Audio fingerprinting, also named as audio hashing, has been well-known as a powerful technique to perform audio identification and synchronization. It basically involves two major steps: fingerprint (voice pattern) design and matching search. While the first step concerns the derivation of a robust and compact audio signature, the second step usually requires knowledge about database and quick-search algorithms. Though this technique offers a wide range of real-world applications, to the best of the authors' knowledge, a comprehensive survey of existing algorithms appeared more than eight years ago. Thus, in this paper, we present a more up-to-date review and, for emphasizing on the audio signal processing aspect, we focus our state-of-the-art survey on the fingerprint design step for which various audio features and their tractable statistical models are discussed.", "subjects": "Sound (cs.SD)", "authors": "Ngoc Q. K. Duong, Hien-Thanh Duong,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06810", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06810", "title": "\nWhite Paper: Radio y Redes Cognitivas", "abstract": "Traditionally, two different policies to access the radio spectrum have coexisted: licensed regulation, whereby the rights to use specific spectral bands are granted in exclusivity to an individual operator; or unlicensed regulation, according to which certain spectral bands are declared open for free use by any operator or individual following specific rules. While these paradigms have allowed the wireless communications sector to blossom in the past, in recent years they have evidenced shortcomings and given signs of exhaustion. For instance, it is quite usual to encounter fully overloaded mobile communication systems coexisting with unused contiguous spectral bands. This clearly advocates for a more flexible and dynamic allocation of the spectrum resources which can only be achieved with the advent of the so-called cognitive radios and networks. This whitepaper provides an accurate description of priority research activities and open challenges related to the different functionalities of cognitive radios and networks. First, we outline the main open problems related to the theoretical characterization of cognitive radios, spectrum sensing techniques as well as the optimization of physical layer functionalities in these networks. Second, we provide a description of the main research challenges that arise from a system point of view: MAC protocol optimization, traffic modelling, RRM strategies, routing paradigms or security issues. Next, we point out other problems related to the practical hardware implementation of cognitive radios, giving especial emphasis to sensing capabilities, reconfigurability and cognitive control and management. Finally, we succinctly report on a number of current activities related to the standardization of cognitive radio systems.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Carles Anton Haro, Luis Castedo Ribas, Javier del Ser Lorente, Armin Dekorsy, Miguel Egido Cortes, Xavier Gelabert, Lorenza Giupponi, Xavier Mestre, Jose Monserrat, Carlos Mosquera, Miquel Soriano, Liesbet van der Perre, Jon Arambarri, Juan Antonio Romo,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06809", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06809", "title": "\nOptimal Linear and Cyclic Locally Repairable Codes over Small Fields", "abstract": "We consider locally repairable codes over small fields and propose constructions of optimal cyclic and linear codes in terms of the dimension for a given distance and length. Four new constructions of optimal linear codes over small fields with locality properties are developed. The first two approaches give binary cyclic codes with locality two. While the first construction has availability one, the second binary code is characterized by multiple available repair sets based on a binary Simplex code. The third approach extends the first one to q-ary cyclic codes including (binary) extension fields, where the locality property is determined by the properties of a shortened first-order Reed-Muller code. Non-cyclic optimal binary linear codes with locality greater than two are obtained by the fourth construction.", "subjects": "Information Theory (cs.IT)", "authors": "Alexander Zeh, Eitan Yaakobi,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06807", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06807", "title": "\nHands Deep in Deep Learning for Hand Pose Estimation", "abstract": "We introduce and evaluate several architectures for Convolutional Neural Networks to predict the 3D joint locations of a hand given a depth map. We first show that a prior on the 3D pose can be easily introduced and significantly improves the accuracy and reliability of the predictions. We also show how to use context efficiently to deal with ambiguities between fingers. These two contributions allow us to significantly outperform the state-of-the-art on several challenging benchmarks, both in terms of accuracy and computation times.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Markus Oberweger, Paul Wohlhart, Vincent Lepetit,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06800", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06800", "title": "\nOn the Equivalence between Quadrature Rules and Random Features", "abstract": "We show that kernel-based quadrature rules for computing integrals are a special case of random feature expansions for positive definite kernels for a particular decomposition that always exists for such kernels. We provide a theoretical analysis of the number of required samples for a given approximation error, leading to both upper and lower bounds that are based solely on the eigenvalues of the associated integral operator and match up to logarithmic terms. In particular, we show that the upper bound may be obtained from independent and identically distributed samples from a known non-uniform distribution, while the lower bound if valid for any set of points. Applying our results to kernel-based quadrature, while our results are fairly general, we recover known upper and lower bounds for the special cases of Sobolev spaces. Moreover, our results extend to the more general problem of full function approximations (beyond simply computing an integral), with results in L2- and L-norm that match known results for special cases. Applying our results to random features, we show an improvement of the number of random features needed to preserve the generalization guarantees for learning with Lipschitz-continuous losses.", "subjects": "Learning (cs.LG)", "authors": "Francis Bach,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06796", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06796", "title": "\nOnline Tracking by Learning Discriminative Saliency Map with  Convolutional Neural Network", "abstract": "We propose an online visual tracking algorithm by learning discriminative saliency map using Convolutional Neural Network (CNN). Given a CNN pre-trained on a large-scale image repository in offline, our algorithm takes outputs from hidden layers of the network as feature descriptors since they show excellent representation performance in various general visual recognition problems. The features are used to learn discriminative target appearance models using an online Support Vector Machine (SVM). In addition, we construct target-specific saliency map by backpropagating CNN features with guidance of the SVM, and obtain the final tracking result in each frame based on the appearance model generatively constructed with the saliency map. Since the saliency map visualizes spatial configuration of target effectively, it improves target localization accuracy and enable us to achieve pixel-level target segmentation. We verify the effectiveness of our tracking algorithm through extensive experiment on a challenging benchmark, where our method illustrates outstanding performance compared to the state-of-the-art tracking algorithms.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Seunghoon Hong, Tackgeun You, Suha Kwak, Bohyung Han,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06792", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06792", "title": "\nWhat is Usability? A Characterization based on ISO 9241-11 and ISO/IEC  25010", "abstract": "According to Brooke* \"Usability does not exist in any absolute sense; it can only be defined with reference to particular contexts.\" That is, one cannot speak of usability without specifying what that particular usability is characterized by. Driven by the feedback of a reviewer at an international conference, I explore in which way one can precisely specify the kind of usability they are investigating in a given setting. Finally, I come up with a formalism that defines usability as a quintuple comprising the elements level of usability metrics, product, users, goals and context of use. Providing concrete values for these elements then constitutes the investigated type of usability. The use of this formalism is demonstrated in two case studies. * J. Brooke. SUS: A \"quick and dirty\" usability scale. In P. W. Jordan, B. Thomas, B. A. Weerdmeester, and A. L. McClelland, editors, Usability Evaluation in Industry. Taylor and Francis, 1996.", "subjects": "Human-Computer Interaction (cs.HC)", "authors": "Maximilian Speicher,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06791", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06791", "title": "\nJoint Wireless Information and Power Transfer in a Three-Node Autonomous  MIMO Relay Network", "abstract": "This paper investigates a three-node amplify-and-forward (AF) multiple-input multiple-output (MIMO) relay network, where an autonomous relay harvests power from the source information flow and is further helped by an energy flow in the form of a wireless power transfer (WPT) at the destination. An energy-flow-assisted two-phase relaying scheme is proposed, where a source and relay joint optimization is formulated to maximize the rate. By diagonalizing the channel, the problem is simplified to a power optimization, where a relay channel pairing problem is solved by an ordering operation. The proposed algorithm, which iteratively optimizes the relay and source power, is shown to converge. Closed-form solutions can be obtained for the separate relay and source optimizations. Besides, a two-phase relaying without energy flow is also studied. Simulation results show that the energy-flow-assisted scheme is beneficial to the rate enhancement, if the transmit power of the energy flow is adequately larger than that of the information flow. Otherwise, the scheme without energy flow would be preferable.", "subjects": "Information Theory (cs.IT)", "authors": "Yang Huang, Bruno Clerckx,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06775", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06775", "title": "\nLimitations in the spectral method for graph partitioning: detectability  threshold and localization of eigenvectors", "abstract": "Investigating the performance of different methods is a fundamental problem in graph partitioning. In this paper, we estimate the so-called detectability threshold for the spectral method with both unnormalized and normalized Laplacians in sparse graphs. The detectability threshold is the critical point at which the result of the spectral method is completely uncorrelated to the planted partition. We also analyze whether the localization of eigenvectors affects the partitioning performance in the detectable region. We use the replica method, which is often used in the field of spin-glass theory, and focus on the case of bisection. We show that the gap between the estimated threshold for the spectral method and the threshold obtained from Bayesian inference is considerable in sparse graphs, even without eigenvector localization. This gap closes in a dense limit.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Tatsuro Kawamoto, Yoshiyuki Kabashima,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06764", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06764", "title": "\nA deterministic sublinear-time nonadaptive algorithm for metric  $1$-median selection", "abstract": "We give a deterministic -time -approximation nonadaptive algorithm for -median selection in -point metric spaces, where is arbitrary. Our proof generalizes that of Chang.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Ching-Lueh Chang,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06761", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06761", "title": "\nMinimal Distance of Propositional Models", "abstract": "We investigate the complexity of three optimization problems in Boolean propositional logic related to information theory: Given a conjunctive formula over a set of relations, find a satisfying assignment with minimal Hamming distance to a given assignment that satisfies the formula (, ) or that does not need to satisfy it (, ). The third problem asks for two satisfying assignments with a minimal Hamming distance among all such assignments (, ). For all three problems we give complete classifications with respect to the relations admitted in the formula. We give polynomial time algorithms for several classes of constraint languages. For all other cases we prove hardness or completeness regarding APX, APX, NPO, or equivalence to well-known hard optimization problems.", "subjects": "Computational Complexity (cs.CC)", "authors": "Mike Behrisch, Miki Hermann, Stefan Mengel, Gernot Salzer,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06757", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06757", "title": "\nUntangling Fine-Grained Code Changes", "abstract": "After working for some time, developers commit their code changes to a version control system. When doing so, they often bundle unrelated changes (e.g., bug fix and refactoring) in a single commit, thus creating a so-called tangled commit. Sharing tangled commits is problematic because it makes review, reversion, and integration of these commits harder and historical analyses of the project less reliable. Researchers have worked at untangling existing commits, i.e., finding which part of a commit relates to which task. In this paper, we contribute to this line of work in two ways: (1) A publicly available dataset of untangled code changes, created with the help of two developers who accurately split their code changes into self contained tasks over a period of four months; (2) a novel approach, EpiceaUntangler, to help developers share untangled commits (aka. atomic commits) by using fine-grained code change information. EpiceaUntangler is based and tested on the publicly available dataset, and further evaluated by deploying it to 7 developers, who used it for 2 weeks. We recorded a median success rate of 91% and average one of 75%, in automatically creating clusters of untangled fine-grained code changes.", "subjects": "Software Engineering (cs.SE)", "authors": "Mart\u00edn Dias, Alberto Bacchelli, Georgios Gousios, Damien Cassou, St\u00e9phane Ducasse,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06752", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06752", "title": "\nHalf a billion simulations: evolutionary algorithms and distributed  computing for calibrating the SimpopLocal geographical model", "abstract": "Multi-agent geographical models integrate very large numbers of spatial interactions. In order to validate those models large amount of computing is necessary for their simulation and calibration. Here a new data processing chain including an automated calibration procedure is experimented on a computational grid using evolutionary algorithms. This is applied for the first time to a geographical model designed to simulate the evolution of an early urban settlement system. The method enables us to reduce the computing time and provides robust results. Using this method, we identify several parameter settings that minimise three objective functions that quantify how closely the model results match a reference pattern. As the values of each parameter in different settings are very close, this estimation considerably reduces the initial possible domain of variation of the parameters. The model is thus a useful tool for further multiple applications on empirical historical situations.", "subjects": "Computers and Society (cs.CY)", "authors": "Clara Schmitt, S\u00e9bastien Rey-Coyrehourcq, Romain Reuillon, Denise Pumain,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06743", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06743", "title": "\nTraffic Hotspot localization in 3G and 4G wireless networks using OMC  metrics", "abstract": "In recent years, there has been an increasing awareness to traffic localization techniques driven by the emergence of heterogeneous networks (HetNet) with small cells deployment and the green networks. The localization of hotspot data traffic with a very high accuracy is indeed of great interest to know where the small cells should be deployed and how can be managed for sleep mode concept. In this paper, we propose a new traffic localization technique based on the combination of different key performance indicators (KPI) extracted from the operation and maintenance center (OMC). The proposed localization algorithm is composed with five main steps; each one corresponds to the determination of traffic weight per area using only one KPI. These KPIs are Timing Advance (TA), Angle of Arrival (AoA), Neighbor cell level, the load of each cell and the Harmonic mean throughput (HMT) versus the Arithmetic mean throughput (AMT). The five KPIs are finally combined by a function taking as variables the values computed from the five steps. By mixing such KPIs, we show that it is possible to lessen significantly the errors of localization in a high precision attaining small cell dimensions.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Aymen Jaziri, Ridha Nasri, Tijani Chahed,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.06735", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06735", "title": "\nEmpowering Web Service Search with Business Know-How", "abstract": "In this paper, we propose first to start by presenting a state of the art of existing approaches about scientific workflows (including neuroscience workflows) in order to highlight business users\u00e2\u0080\u0099 needs in terms of Web Services combination. Then we discuss about intentional process modeling for scientific workflows especially to search for Web Services. Next we present our approach SATIS to provide reasoning and traceability capabilities on Web Services business combination know-how, in order to bridge the gap between workflows providers and users.", "subjects": "Software Engineering (cs.SE)", "authors": "Isabelle Mirbel, Pierre Crescenzo, Nadia Cerezo,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06733", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06733", "title": "\nMinimizing Energy Consumption of MPI Programs in Realistic Environment", "abstract": "Dynamic voltage and frequency scaling proves to be an efficient way of reducing energy consumption of servers. Energy savings are typically achieved by setting a well-chosen frequency during some program phases. However, determining suitable program phases and their associated optimal frequencies is a complex problem. Moreover, hardware is constrained by non negligible frequency transition latencies. Thus, various heuristics were proposed to determine and apply frequencies, but evaluating their efficiency remains an issue. In this paper, we translate the energy minimization problem into a mixed integer program that specifically models most current hardware limitations. The problem solution then estimates the minimal energy consumption and the associated frequency schedule. The paper provides two different formulations and a discussion on the feasibility of each of them on realistic applications.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Amina Guermouche, Nicolas Triquenaux, Benoit Pradelle, William Jalby,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.06732", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06732", "title": "\nConvergence Analysis using the Edge Laplacian: Robust Consensus of  Nonlinear Multi-agent Systems via ISS Method", "abstract": "This study develops an original and innovative matrix representation with respect to the information flow for networked multi-agent system. To begin with, the general concepts of the edge Laplacian of digraph are proposed with its algebraic properties. Benefit from this novel graph-theoretic tool, we can build a bridge between the consensus problem and the edge agreement problem; we also show that the edge Laplacian sheds a new light on solving the leaderless consensus problem. Based on the edge agreement framework, the technical challenges caused by unknown but bounded disturbances and inherently nonlinear dynamics can be well handled. In particular, we design an integrated procedure for a new robust consensus protocol that is based on a blend of algebraic graph theory and the newly developed cyclic-small-gain theorem. Besides, to highlight the intricate relationship between the original graph and cyclic-small-gain theorem, the concept of edge-interconnection graph is introduced for the first time. Finally, simulation results are provided to verify the theoretical analysis.", "subjects": "Systems and Control (cs.SY)", "authors": "Zhiwen Zeng, Xiangke Wang, Zhiqiang Zheng,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06719", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06719", "title": "\nPresence of an Ecosystem: An Answer to \"Why is Whole Greater than the  Sum of its Parts\" in the Knowledge Building Process", "abstract": "The phenomenal success of certain crowdsourced online platforms, such as Wikipedia, is accredited to their ability to tap the crowd's potential to collaboratively build knowledge. While it is well known that the crowd's collective wisdom surpasses the cumulative individual expertise, little is understood on the dynamics of knowledge building in a crowdsourced environment. Our experiment shows that an important reason for the rapid knowledge building in such an environment is due to variance in expertise. A proper understanding of the dynamics of knowledge building in a crowdsourced environment would enable one in the better designing of wiki styled environments to solicit knowledge from the crowd. We use, as our test bed, a customized Crowdsourced Annotation System (CAS) which provides a group of users the facility to annotate a given document. Our results show the presence of different genres of proficiency which accelerate the process of knowledge building by the synergetic interaction amongst the users. We observe that the crowdsourced knowledge ecosystem comprises of four categories of contributors, namely: Probers, Solvers, Articulators and Explorers. We infer from our experiment that the knowledge garnering mainly happens due to the synergetic interaction across these categories.", "subjects": "Computers and Society (cs.CY)", "authors": "Anamika Chhabra, S. R. S. Iyengar, Poonam Saini, Rajesh Shreedhar Bhat,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06703", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06703", "title": "\nDiscrete Wavelet Transform and Gradient Difference based approach for  text localization in videos", "abstract": "The text detection and localization is important for video analysis and understanding. The scene text in video contains semantic information and thus can contribute significantly to video retrieval and understanding. However, most of the approaches detect scene text in still images or single video frame. Videos differ from images in temporal redundancy. This paper proposes a novel hybrid method to robustly localize the texts in natural scene images and videos based on fusion of discrete wavelet transform and gradient difference. A set of rules and geometric properties have been devised to localize the actual text regions. Then, morphological operation is performed to generate the text regions and finally the connected component analysis is employed to localize the text in a video frame. The experimental results obtained on publicly available standard ICDAR 2003 and Hua dataset illustrate that the proposed method can accurately detect and localize texts of various sizes, fonts and colors. The experimentation on huge collection of video databases reveal the suitability of the proposed method to video databases.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "B.H. Shekar, Smitha M.L., P. Shivakumara,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06691", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06691", "title": "\nSequential Aggregate Signatures with Short Public Keys without Random  Oracles", "abstract": "The notion of aggregate signature has been motivated by applications and it enables any user to compress different signatures signed by different signers on different messages into a short signature. Sequential aggregate signature, in turn, is a special kind of aggregate signature that only allows a signer to add his signature into an aggregate signature in sequential order. This latter scheme has applications in diversified settings such as in reducing bandwidth of certificate chains and in secure routing protocols. Lu, Ostrovsky, Sahai, Shacham, and Waters (EUROCRYPT 2006) presented the first sequential aggregate signature scheme in the standard model. The size of their public key, however, is quite large (i.e., the number of group elements is proportional to the security parameter), and therefore, they suggested as an open problem the construction of such a scheme with short keys. In this paper, we propose the first sequential aggregate signature schemes with short public keys (i.e., a constant number of group elements) in prime order (asymmetric) bilinear groups that are secure under static assumptions in the standard model. Furthermore, our schemes employ a constant number of pairing operations per message signing and message verification operation. Technically, we start with a public-key signature scheme based on the recent dual system encryption technique of Lewko and Waters (TCC 2010). This technique cannot directly provide an aggregate signature scheme since, as we observed, additional elements should be published in a public key to support aggregation. Thus, our constructions are careful augmentation techniques for the dual system technique to allow it to support sequential aggregate signature schemes. We also propose a multi-signature scheme with short public parameters in the standard model.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Kwangsu Lee, Dong Hoon Lee, Moti Yung,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06686", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06686", "title": "\nData-Driven Shape Analysis and Processing", "abstract": "Data-driven methods play an increasingly important role in discovering geometric, structural, and semantic relationships between 3D shapes in collections, and applying this analysis to support intelligent modeling, editing, and visualization of geometric data. In contrast to traditional approaches, a key feature of data-driven approaches is that they aggregate information from a collection of shapes to improve the analysis and processing of individual shapes. In addition, they are able to learn models that reason about properties and relationships of shapes without relying on hard-coded rules or explicitly programmed instructions. We provide an overview of the main concepts and components of these techniques, and discuss their application to shape classification, segmentation, matching, reconstruction, modeling and exploration, as well as scene analysis and synthesis, through reviewing the literature and relating the existing works with both qualitative and numerical comparisons. We conclude our report with ideas that can inspire future research in data-driven shape analysis and processing.", "subjects": "Graphics (cs.GR)", "authors": "Kai Xu, Vladimir G. Kim, Qixing Huang, Evangelos Kalogerakis,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06682", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06682", "title": "\nMaximizing Friend-Making Likelihood for Social Activity Organization", "abstract": "The social presence theory in social psychology suggests that computer-mediated online interactions are inferior to face-to-face, in-person interactions. In this paper, we consider the scenarios of organizing in person friend-making social activities via online social networks (OSNs) and formulate a new research problem, namely, Hop-bounded Maximum Group Friending (HMGF), by modeling both existing friendships and the likelihood of new friend making. To find a set of attendees for socialization activities, HMGF is unique and challenging due to the interplay of the group size, the constraint on existing friendships and the objective function on the likelihood of friend making. We prove that HMGF is NP-Hard, and no approximation algorithm exists unless P = NP. We then propose an error-bounded approximation algorithm to efficiently obtain the solutions very close to the optimal solutions. We conduct a user study to validate our problem formulation and per- form extensive experiments on real datasets to demonstrate the efficiency and effectiveness of our proposed algorithm.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Chih-Ya Shen, De-Nian Yang, Wang-Chien Lee, Ming-Syan Chen,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.06672", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06672", "title": "\nDynamic Spectrum Access with Statistical QoS Provisioning: A Distributed  Learning Approach Beyond Expectation Optimization", "abstract": "This article investigates the problem of dynamic spectrum access with statistical quality of service (QoS) provisioning for dynamic canonical networks, in which the channel states are time-varying from slot to slot. In the existing work with time-varying environment, the commonly used optimization objective is to maximize the expectation of a certain metric (e.g., throughput or achievable rate). However, it is realized that expectation alone is not enough since some applications are sensitive to the channel fluctuations. Effective capacity is a promising metric for time-varying service process since it characterizes the packet delay violating probability (regarded as an important statistical QoS index), by taking into account not only the expectation but also other high-order statistic. We formulate the interactions among the users in the time-varying environment as a non-cooperative game, in which the utility function is defined as the achieved effective capacity. We prove that it is an ordinal potential game which has at least one pure strategy Nash equilibrium. In addition, we propose a multi-agent learning algorithm which is proved to achieve stable solutions with uncertain, dynamic and incomplete information constraints. The convergence of the proposed learning algorithm is verified by simulation results. Also, it is shown that the proposed multi-agent learning algorithm achieves satisfactory performance.", "subjects": "Information Theory (cs.IT)", "authors": "Yuhua Xu, Jinlong Wang, Qihui Wu, Jianchao Zheng, Liang Shen, Alagan Anpalagan,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06671", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06671", "title": "\nMinfer: Inferring Motif Statistics From Sampled Edges", "abstract": "Characterizing motif (i.e., locally connected subgraph patterns) statistics is important for understanding complex networks such as online social networks and communication networks. Previous work made the strong assumption that the graph topology of interest is known, and that the dataset either fits into main memory or stored on disks such that it is not expensive to obtain all neighbors of any given node. In practice, researchers have to deal with the situation where the graph topology is unknown, either because the graph is dynamic, or because it is expensive to collect and store all topological and meta information on disk. Hence, what is available to researchers is only a snapshot of the graph generated by sampling edges from the graph at random, which we called a \"RESampled graph\". Clearly, a RESampled graph's motif statistics may be quite different from the underlying original graph. To solve this challenge, we propose a framework and implement a system called Minfer, which can take the given RESampled graph and accurately infer the underlying graph's motif statistics. We also use Fisher information to bound the error of our estimates. Experiments using large scale datasets show that our method to be accurate.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Pinghui Wang, John C.S. Lui, Don Towsley,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06670", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06670", "title": "\nCentralized-distributed Spectrum Access for Small Cell Networks: A  Cloud-based Game Solution", "abstract": "By employing the advances in wireless cloud technologies, this letter establishes a centralized-distributed optimization architecture for spectrum access in small cell networks. In the centralized aspect, the spectrum access problem is solved in the cloud. In the distributed aspect, the problem is solved by a game-theoretic solution, aiming to address the challenges of heavy computation complexity caused by the densely deployed small cells. The properties of the game, including the existence of pure Nash equilibrium and the achievable lower bound, are rigorously proved and analyzed. Furthermore, a cloud-assisted best response learning algorithm with low computational complexity is proposed, which converges to the global or local optima of the aggregate interference level of the small cell network. It is shown that the cloud-assisted algorithm converges rapidly and is scalable when increasing the number of small cells. Finally, simulation results are presented to validate the proposed cloud-based centralized-distributed solution.", "subjects": "Information Theory (cs.IT)", "authors": "Yuhua Xu, Jinlong Wang, Yitao Xu, Liang Shen, Qihui Wu, Alagan Anpalagan,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06669", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06669", "title": "\nDatabase-assisted Spectrum Access in Dynamic Networks: A Distributed  Learning Solution", "abstract": "This letter investigates the problem of database-assisted spectrum access in dynamic TV white spectrum networks, in which the active user set is varying. Sine there is no central controller and information exchange, it encounters dynamic and incomplete information constraints. To solve this challenge, we formulate a state-based spectrum access game and a robust spectrum access game. It is proved that the two games are ordinal potential games with the (expected) aggregate weighted interference serving as the potential functions. A distributed learning algorithm is proposed to achieve the pure strategy Nash equilibrium (NE) of the games. It is shown that the best NE is almost the same with the optimal solution and the achievable throughput of the proposed learning algorithm is very close to the optimal one, which validates the effectiveness of the proposed game-theoretic solution.", "subjects": "Information Theory (cs.IT)", "authors": "Yuhua Xu, Jinlong Wang, Yitao Xu, Qihui Wu, Alagan Anpalagan,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06668", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06668", "title": "\nLearning Fast-Mixing Models for Structured Prediction", "abstract": "Markov Chain Monte Carlo (MCMC) algorithms are often used for approximate inference inside learning, but their slow mixing can be difficult to diagnose and the approximations can seriously degrade learning. To alleviate these issues, we define a new model family using strong Doeblin Markov chains, whose mixing times can be precisely controlled by a parameter. We also develop an algorithm to learn such models, which involves maximizing the data likelihood under the induced stationary distribution of these chains. We show empirical improvements on two challenging inference tasks.", "subjects": "Learning (cs.LG)", "authors": "Jacob Steinhardt, Percy Liang,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06667", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06667", "title": "\nDistributed Spectrum Access for Cognitive Small Cell Networks: A Robust  Graphical Game Approach", "abstract": "This letter investigates the problem of distributed spectrum access for cognitive small cell networks. Compared with existing work, two inherent features are considered: i) the transmission of a cognitive small cell base station only interferes with its neighbors due to the low power, i.e., the interference is local, and ii) the channel state is time-varying due to fading. We formulate the problem as a robust graphical game, and prove that it is an ordinal potential game which has at least one pure strategy Nash equilibrium (NE). Also, the lower throughput bound of NE solutions is analytically obtained. To cope with the dynamic and incomplete information constraints, we propose a distribute spectrum access algorithm to converge to some stable results. Simulation results validate the effectiveness of the proposed game-theoretic distributed learning solution in time-varying spectrum environment.", "subjects": "Information Theory (cs.IT)", "authors": "Yuhua Xu, Yuli Zhang, Qihui Wu, Liang Shen, Jinlong Wang,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06665", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06665", "title": "\nReified Context Models", "abstract": "A classic tension exists between exact inference in a simple model and approximate inference in a complex model. The latter offers expressivity and thus accuracy, but the former provides coverage of the space, an important property for confidence estimation and learning with indirect supervision. In this work, we introduce a new approach, reified context models, to reconcile this tension. Specifically, we let the amount of context (the arity of the factors in a graphical model) be chosen \"at run-time\" by reifying it---that is, letting this choice itself be a random variable inside the model. Empirically, we show that our approach obtains expressivity and coverage on three natural language tasks.", "subjects": "Learning (cs.LG)", "authors": "Jacob Steinhardt, Percy Liang,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06657", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06657", "title": "\nMulti-Touch Attribution Based Budget Allocation in Online Advertising", "abstract": "Budget allocation in online advertising deals with distributing the campaign (insertion order) level budgets to different sub-campaigns which employ different targeting criteria and may perform differently in terms of return-on-investment (ROI). In this paper, we present the efforts at Turn on how to best allocate campaign budget so that the advertiser or campaign-level ROI is maximized. To do this, it is crucial to be able to correctly determine the performance of sub-campaigns. This determination is highly related to the action-attribution problem, i.e. to be able to find out the set of ads, and hence the sub-campaigns that provided them to a user, that an action should be attributed to. For this purpose, we employ both last-touch (last ad gets all credit) and multi-touch (many ads share the credit) attribution methodologies. We present the algorithms deployed at Turn for the attribution problem, as well as their parallel implementation on the large advertiser performance datasets. We conclude the paper with our empirical comparison of last-touch and multi-touch attribution-based budget allocation in a real online advertising setting.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Sahin Cem Geyik, Abhishek Saxena, Ali Dasdan,", "date": "2015-2-24"}, 
{"urllink": "http://arxiv.org/abs/1502.06654", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06654", "title": "\nVariable-Length Feedback Codes under a Strict Delay Constraint", "abstract": "We study variable-length feedback (VLF) codes under a strict delay constraint to maximize their average transmission rate (ATR) in a discrete memoryless channel (DMC) while considering periodic decoding attempts. We first derive a lower bound on the maximum achievable ATR, and confirm that the VLF code can outperform non-feedback codes with a larger delay constraint. We show that for a given decoding period, as the strict delay constraint, L, increases, the gap between the ATR of the VLF code and the DMC capacity scales at most on the order of O(L^) instead of O(L^) for non-feedback codes as shown in Polyanskiy et al. [\"Channel coding rate in the finite blocklengh regime,\" IEEE Trans. Inf. Theory, vol. 56, no. 5, pp. 2307-2359, May 2010.]. We also develop an approximation indicating that, for a given L, the achievable ATR increases as the decoding period decreases.", "subjects": "Information Theory (cs.IT)", "authors": "Seong Hwan Kim, Dan Keun Sung, Tho Le-Ngoc,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06648", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06648", "title": "\nRecognizing Fine-Grained and Composite Activities using Hand-Centric  Features and Script Data", "abstract": "Activity recognition has shown impressive progress in recent years. However, the challenges of detecting fine-grained activities and understanding how they are combined into composite activities have been largely overlooked. In this work we approach both tasks and present a dataset which provides detailed annotations to address them. The first challenge is to detect fine-grained activities, which are defined by low inter-class variability and are typically characterized by fine-grained body motions. We explore how human pose and hands can help to approach this challenge by comparing two pose-based and two hand-centric features with state-of-the-art holistic features. To attack the second challenge, recognizing composite activities, we leverage the fact that these activities are compositional and that the essential components of the activities can be obtained from textual descriptions or scripts. We show the benefits of our hand-centric approach for fine-grained activity classification and detection. For composite activity recognition we find that decomposition into attributes allows sharing information across composites and is essential to attack this hard task. Using script data we can recognize novel composites without having training data for them.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Marcus Rohrbach, Anna Rohrbach, Michaela Regneri, Sikandar Amin, Mykhaylo Andriluka, Manfred Pinkal, Bernt Schiele,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06641", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06641", "title": "\nSystem Interactive Cyber Presence for E learning to Break Down Learner  Isolation", "abstract": "The development of technologies of multimedia, linked to that of Internet and democratization of high speed, has made henceforth E-learning possible for learners being in virtual classes and geographically distributed. One benefit to taking course online is that the online course structure is typically more student focused than teacher centered and encouraging more active participation by students in collaborative learning activities. The quality and quantity of asynchronous and synchronous communications are the key elements for E-learning success. A potential problem that has received little exploration is student's feeling of isolation. It is important to have a propitious supervision to breaking down learner feeling isolation in E learning environment. This feeling of isolation is among the main causes of loss and high rates of dropout in E-learning. It impacts on their levels of participation, satisfaction and learning. To overcome this feeling of isolation, we aim, by this research, to provide the trainer and each learner with an environment allowing them to behave as if being face to face; in other words, to approach the pedagogy of classroom teaching. Our contribution to reduce the feeling of isolation is to ensure the presence of the teacher in the educational tools. These tools aim to establish a real dialogue with the learner, forcing him to take an active part in their learning. Among the tools we offer, video conference Openmeeting integrated in Moodle providing the possibility of using the notion of class and whiteboard, the indicator of motivation quantification tool based hand gesture that we developed and finally social networks web 2. 0 like Facebook, youtube, twitter to promote collaboration, sharing and communication of the learner with his peers.", "subjects": "Computers and Society (cs.CY)", "authors": "Bousaaid Mourad, Ayaou Tarik, Afdel Karim, Estraillier Pascal,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06626", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06626", "title": "\nOptimal Sparse Linear Auto-Encoders and Sparse PCA", "abstract": "Principal components analysis (PCA) is the optimal linear auto-encoder of data, and it is often used to construct features. Enforcing sparsity on the principal components can promote better generalization, while improving the interpretability of the features. We study the problem of constructing optimal sparse linear auto-encoders. Two natural questions in such a setting are: i) Given a level of sparsity, what is the best approximation to PCA that can be achieved? ii) Are there low-order polynomial-time algorithms which can asymptotically achieve this optimal tradeoff between the sparsity and the approximation quality? In this work, we answer both questions by giving efficient low-order polynomial-time algorithms for constructing asymptotically emph linear auto-encoders (in particular, sparse features with near-PCA reconstruction error) and demonstrate the performance of our algorithms on real data.", "subjects": "Learning (cs.LG)", "authors": "Malik Magdon-Ismail, Christos Boutsidis,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06601", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06601", "title": "\nOptimization-Based Linear Network Coding for General Connections of  Continuous Flows", "abstract": "For general connections, the problem of finding network codes and optimizing resources for those codes is intrinsically difficult and little is known about its complexity. Most of the existing solutions rely on very restricted classes of network codes in terms of the number of flows allowed to be coded together, and are not entirely distributed. In this paper, we consider a new method for constructing linear network codes for general connections of continuous flows to minimize the total cost of edge use based on mixing. We first formulate the minimumcost network coding design problem. To solve the optimization problem, we propose two equivalent alternative formulations with discrete mixing and continuous mixing, respectively, and develop distributed algorithms to solve them. Our approach allows fairly general coding across flows and guarantees no greater cost than any solution without network coding.", "subjects": "Information Theory (cs.IT)", "authors": "Ying Cui, Muriel M\u00e9dard, Edmund Yeh, Douglas Leith, Ken Duffy,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.06593", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06593", "title": "\nSwendsen-Wang Algorithm on the Mean-Field Potts Model", "abstract": "We study the q-state ferromagnetic Potts model on the n-vertex complete graph known as the mean-field (Curie-Weiss) model. We analyze the Swendsen-Wang algorithm which is a Markov chain that utilizes the random cluster representation for the ferromagnetic Potts model to recolor large sets of vertices in one step and potentially overcomes obstacles that inhibit single-site Glauber dynamics. The case q=2 (the Swendsen-Wang algorithm for the ferromagnetic Ising model) undergoes a slow-down at the uniqueness/non-uniqueness critical temperature for the infinite Delta-regular tree (Long et al., 2014) but yet still has polynomial mixing time at all (inverse) temperatures beta&gt;0 (Cooper et al., 2000). In contrast for q geq 3 there are two critical temperatures 0&lt; betau&lt; betarc that are relevant, these two critical points relate to phase transitions in the infinite tree. We prove that the mixing time of the Swendsen-Wang algorithm for the ferromagnetic Potts model on the n-vertex complete graph satisfies: (i) O(log n) for beta&lt; betau, (ii) O(n^) for beta= betau, (iii) exp(n^ Omega(1)) for betau&lt; beta&lt; betarc, and (iv) O(log n) for beta geq betarc. These results complement refined results of Cuff et al. (2012) on the mixing time of the Glauber dynamics for the ferromagnetic Potts model. While previous results have established slow mixing for the Swendsen-Wang algorithm at a single temperature for various classes of graphs, our result is the first to establish slow mixing for an interval of temperatures.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Andreas Galanis, Daniel Stefankovic, Eric Vigoda,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06590", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06590", "title": "\nImproved Sum-of-Squares Lower Bounds for Hidden Clique and Hidden  Submatrix Problems", "abstract": "Given a large data matrix , we consider the problem of determining whether its entries are i.i.d. with some known marginal distribution , or instead contains a principal submatrix whose entries have marginal distribution . As a special case, the hidden (or planted) clique problem requires to find a planted clique in an otherwise uniformly random graph. Assuming unbounded computational resources, this hypothesis testing problem is statistically solvable provided for a suitable constant . However, despite substantial effort, no polynomial time algorithm is known that succeeds with high probability when . Recently Meka and Wigderson cite, proposed a method to establish lower bounds within the Sum of Squares (SOS) semidefinite hierarchy. Here we consider the degree- SOS relaxation, and study the construction of cite to prove that SOS fails unless . An argument presented by Barak implies that this lower bound cannot be substantially improved unless the witness construction is changed in the proof. Our proof uses the moments method to bound the spectrum of a certain random association scheme, i.e. a symmetric random matrix whose rows and columns are indexed by the edges of an Erd \"os-Renyi random graph.", "subjects": "Computational Complexity (cs.CC)", "authors": "Yash Deshpande, Andrea Montanari,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06583", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06583", "title": "\nLeveraging Social Foci for Information Seeking in Social Media", "abstract": "The rise of social media provides a great opportunity for people to reach out to their social connections to satisfy their information needs. However, generic social media platforms are not explicitly designed to assist information seeking of users. In this paper, we propose a novel framework to identify the social connections of a user able to satisfy his information needs. The information need of a social media user is subjective and personal, and we investigate the utility of his social context to identify people able to satisfy it. We present questions users post on Twitter as instances of information seeking activities in social media. We infer soft community memberships of the asker and his social connections by integrating network and content information. Drawing concepts from the social foci theory, we identify answerers who share communities with the asker w.r.t. the question. Our experiments demonstrate that the framework is effective in identifying answerers to social media questions.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Suhas Ranganath, Jiliang Tang, Xia Hu, Hari Sundaram, Huan Liu,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06577", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06577", "title": "\nAn Empirical Study of Mobile Ad Targeting", "abstract": "Advertising, long the financial mainstay of the web ecosystem, has become nearly ubiquitous in the world of mobile apps. While ad targeting on the web is fairly well understood, mobile ad targeting is much less studied. In this paper, we use empirical methods to collect a database of over 225,000 ads on 32 simulated devices hosting one of three distinct user profiles. We then analyze how the ads are targeted by correlating ads to potential targeting profiles using Bayes' rule and Pearson's chi squared test. This enables us to measure the prevalence of different forms of targeting. We find that nearly all ads show the effects of application- and time-based targeting, while we are able to identify location-based targeting in 43% of the ads and user-based targeting in 39%.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Theodore Book, Dan S. Wallach,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06564", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06564", "title": "\nChallenges and characterization of a Biological system on Grid by means  of the PhyloGrid application", "abstract": "In this work we present a new application that is being developed. PhyloGrid is able to perform large-scale phylogenetic calculations as those that have been made for estimating the phylogeny of all the sequences already stored in the public NCBI database. The further analysis has been focused on checking the origin of the HIV-1 disease by means of a huge number of sequences that sum up to 2900 taxa. Such a study has been able to be done by the implementation of a workflow in Taverna.", "subjects": "Computational Engineering, Finance, and Science (cs.CE)", "authors": "Raul Isea, Esther Montes, Antonio J. Rubio-Montero, Rafael Mayo,", "date": "2014-12-5"}, 
{"urllink": "http://arxiv.org/abs/1502.06556", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06556", "title": "\nShannon, Tsallis and Kaniadakis entropies in bi-level image thresholding", "abstract": "The maximum entropy principle is often used for bi-level or multi-level thresholding of images. For this purpose, some methods are available based on Shannon and Tsallis entropies. In this paper, we discuss them and propose a method based on Kaniadakis entropy.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Amelia Carolina Sparavigna,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06531", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06531", "title": "\nScalable Variational Inference in Log-supermodular Models", "abstract": "We consider the problem of approximate Bayesian inference in log-supermodular models. These models encompass regular pairwise MRFs with binary variables, but allow to capture high-order interactions, which are intractable for existing approximate inference techniques such as belief propagation, mean field, and variants. We show that a recently proposed variational approach to inference in log-supermodular models -L-FIELD- reduces to the widely-studied minimum norm problem for submodular minimization. This insight allows to leverage powerful existing tools, and hence to solve the variational problem orders of magnitude more efficiently than previously possible. We then provide another natural interpretation of L-FIELD, demonstrating that it exactly minimizes a specific type of R 'enyi divergence measure. This insight sheds light on the nature of the variational approximations produced by L-FIELD. Furthermore, we show how to perform parallel inference as message passing in a suitable factor graph at a linear convergence rate, without having to sum up over all the configurations of the factor. Finally, we apply our approach to a challenging image segmentation task. Our experiments confirm scalability of our approach, high quality of the marginals, and the benefit of incorporating higher-order potentials.", "subjects": "Learning (cs.LG)", "authors": "Josip Djolonga, Andreas Krause,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.06528", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06528", "title": "\nGreedy Minimization of Weakly Supermodular Set Functions", "abstract": "This paper defines weak--supermodularity for set functions. Many optimization objectives in machine learning and data mining seek to minimize such functions under cardinality constrains. We prove that such problems benefit from a greedy extension phase. Explicitly, let be the optimal set of cardinality that minimizes and let be an initial solution such that . Then, a greedy extension of size yields . As example usages of this framework we give new bicriteria results for -means, sparse regression, and columns subset selection.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Christos Boutsidis, Edo Liberty, Maxim Sviridenko,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06519", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06519", "title": "\nEnhancing Programming Interface to Effectively Meet Multiple Information  Needs of Developers", "abstract": "In the past decades, integrated development environments (IDEs) have been largely advanced to facilitate common software engineering tasks. Yet, with growing information needs driven by increasing complexity in developing modern high-quality software, developers often need to switch among multiple user interfaces, even across different applications, in their development process, which breaks their mental workflow thus tends to adversely affect their working efficiency and productivity. This position paper discusses challenges faced by current IDE designs mainly from working context transitions of developers during the process of seeking multiple information needs for their development tasks. It remarks the primary blockades behind and initially explores some high-level design considerations for overcoming such challenges in the next-generation IDEs. Specifically, a few design enhancements on top of modern IDEs are envisioned, attempting to reduce the overheads of frequent context switching commonly seen in the multitasking of developers.", "subjects": "Software Engineering (cs.SE)", "authors": "Haipeng Cai,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06512", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06512", "title": "\nFrom Seed AI to Technological Singularity via Recursively Self-Improving  Software", "abstract": "Software capable of improving itself has been a dream of computer scientists since the inception of the field. In this work we provide definitions for Recursively Self-Improving software, survey different types of self-improving software, review the relevant literature, analyze limits on computation restricting recursive self-improvement and introduce RSI Convergence Theory which aims to predict general behavior of RSI systems. Finally, we address security implications from self-improving intelligent software.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Roman V. Yampolskiy,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06491", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06491", "title": "\nUnique Factorization and Controllability of Tail-Biting Trellis  Realizations via Controller Granule Decompositions", "abstract": "The Conti-Boston factorization theorem (CBFT) for linear tail-biting trellis realizations is extended to group realizations with a new and simpler proof, based on a controller granule decomposition of the behavior and known controllability results for group realizations. Further controllability results are given; e.g., a trellis realization is controllable if and only if its top (controllability) granule is trivial.", "subjects": "Information Theory (cs.IT)", "authors": "G. David Forney Jr,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06470", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06470", "title": "\nApproximate Message Passing with Restricted Boltzmann Machine Priors", "abstract": "Approximate Message Passing (AMP) has been shown to be an excellent statistical approach to signal inference and compressed sensing problem. The AMP framework provides modularity in the choice of signal prior; here we propose a hierarchical form of the Gauss-Bernouilli prior which utilizes a Restricted Boltzmann Machine (RBM) trained on the signal support to push reconstruction performance beyond that of simple iid priors for signals whose support can be well represented by a trained binary RBM. We present and analyze two methods of RBM factorization and demonstrate how these affect signal reconstruction performance within our proposed algorithm. Finally, using the MNIST handwritten digit dataset, we show experimentally that using an RBM allows AMP to approach oracle-support performance.", "subjects": "Information Theory (cs.IT)", "authors": "Eric W. Tramel, Ang\u00e9lique Dr\u00e9meau, Florent Krzakala,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06464", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06464", "title": "\nRectified Factor Networks", "abstract": "We propose rectified factor networks (RFNs) as generative unsupervised models, which learn robust, very sparse, and non-linear codes with many code units. RFN learning is a variational expectation maximization (EM) algorithm with unknown prior which includes (i) rectified posterior means, (ii) normalized signals of hidden units, and (iii) dropout. Like factor analysis, RFNs explain the data variance by their parameters. For pretraining of deep networks on MNIST, rectangle data, convex shapes, NORB, and CIFAR, RFNs were superior to restricted Boltzmann machines (RBMs) and denoising autoencoders. On CIFAR-10 and CIFAR-100, RFN pretraining always improved the results of deep networks for different architectures like AlexNet, deep supervised net (DSN), and a simple \"Network In Network\" architecture. With RFNs success is guaranteed.", "subjects": "Learning (cs.LG)", "authors": "Djork-Arn\u00e9 Clevert, Thomas Unterthiner, Andreas Mayr, Hubert Ramsauer, Sepp Hochreiter,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06461", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06461", "title": "\nHow to Make Chord Correct (Using a Stable Base)", "abstract": "The Chord distributed hash table (DHT) is well-known and frequently used to implement peer-to-peer systems. Chord peers find other peers, and access their data, through a ring-shaped pointer structure in a large identifier space. Despite claims of proven correctness, i.e., eventual reachability, formal modeling has shown that the Chord ring-maintenance protocol is not correct under its original operating assumptions. It has not, however, discovered whether Chord could be made correct with reasonable operating assumptions. The principle contribution of this paper is to provide the first specification of a correct version of Chord, using the assumption that there is a small \"stable base\" of permanent members. The paper presents a simple, sufficient, and arguably necessary inductive invariant, and a partially automated proof of correctness.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Pamela Zave,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06460", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06460", "title": "\nVisualizing BACnet data to facilitate humans in building-security  decision-making", "abstract": "Building automation systems (BAS) are interlinked networks of hardware and software, which monitor and control events in the buildings. One of the data communication protocols used in BAS is Building Automation and Control networking protocol (BACnet) which is an internationally adopted ISO standard for the communication between BAS devices. Although BAS focus on providing safety for inhabitants, decreasing the energy consumption of buildings and reducing their operational cost, their security suffers due to the inherent complexity of the modern day systems. The issues such as monitoring of BAS effectively present a significant challenge, i.e., BAS operators generally possess only partial situation awareness. Especially in large and inter-connected buildings, the operators face the challenge of spotting meaningful incidents within large amounts of simultaneously occurring events, causing the anomalies in the BAS network to go unobserved. In this paper, we present the techniques to analyze and visualize the data for several events from BAS devices in a way that determines the potential importance of such unusual events and helps with the building-security decision making. We implemented these techniques as a mobile (Android) based application for displaying application data and as tools to analyze the communication flows using directed graphs.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Jernej Tonejc, Jaspreet Kaur, Adrian Karsten, Steffen Wendzel,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.06455", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06455", "title": "\nUpper Bound on the Capacity of the Single-User Nonlinear Schr\u00f6dinger  Channel", "abstract": "It is shown that the capacity of the channel modeled by (a discretized version of) the stochastic nonlinear Schr \"odinger (NLS) equation is upper-bounded by with , where is the average input signal power and is the total noise power up to distance . This implies that the capacity of this model of the single-user optical fiber channel is below the capacity of the corresponding additive white Gaussian noise channel. The result is a consequence of the fact that the deterministic NLS equation is a Hamiltonian energy-preserving dynamical system.", "subjects": "Information Theory (cs.IT)", "authors": "Mansoor I. Yousefi, Gerhard Kramer, Frank R. Kschischang,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06435", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06435", "title": "\nHyperspectral Unmixing via Turbo Bilinear Approximate Message Passing", "abstract": "The goal of hyperspectral unmixing is to decompose an electromagnetic spectral dataset measured over M spectral bands and T pixels into N constituent material spectra (or \"end-members\") with corresponding spatial abundances. In this paper, we propose a novel approach to hyperspectral unmixing based on loopy belief propagation (BP) that enables the exploitation of spectral coherence in the endmembers and spatial coherence in the abundances. In particular, we partition the factor graph into spectral coherence, spatial coherence, and bilinear subgraphs, and pass messages between them using a \"turbo\" approach. To perform message passing within the bilinear subgraph, we employ the bilinear generalized approximate message passing algorithm (BiG-AMP), a recently proposed belief-propagation-based approach to matrix factorization. Furthermore, we propose an expectation-maximization (EM) strategy to tune the prior parameters and a model-order selection strategy to select the number of materials N. Numerical experiments conducted with both synthetic and real-world data show favorable unmixing performance relative to existing methods.", "subjects": "Information Theory (cs.IT)", "authors": "Jeremy Vila, Philip Schniter, Joseph Meola,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06428", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06428", "title": "\nTight Bounds for Symmetric Divergence Measures and a New Inequality  Relating $f$-Divergences", "abstract": "Tight bounds for several symmetric divergence measures are introduced, given in terms of the total variation distance. Each of these bounds is attained by a pair of 2 or 3-element probability distributions. An application of these bounds for lossless source coding is provided, refining and improving a certain bound by Csisz 'ar. A new inequality relating -divergences is derived, and its use is exemplified. The last section of this conference paper is not included in the recent journal paper that was published in the February 2015 issue of the IEEE Trans. on Information Theory (see arXiv:1403.7164), as well as some new paragraphs throughout the paper which are linked to new references.", "subjects": "Information Theory (cs.IT)", "authors": "Igal Sason,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.06422", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06422", "title": "\nRecommendations on Future Operational Environments Command Control and  Cyber Security", "abstract": "It is a well-known fact that today a nation's telecommunication networks, critical infrastructure, and information systems are vulnerable to growing number of attacks in cyberspace. Cyber space contains very different problems involving various sets of threats, targets and costs. Cyber security is not only problem of banking, communication or transportation. It also threatens core systems of army as command control. Some significant recommendations on command control (C2) and cyber security have been suggested for army computing environment in this paper. This study addresses priorities of \"what should be done for a better army cyber future\" to cyber security researchers.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Kerim Goztepe,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06419", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06419", "title": "\nAnalysis of Design Principles and Requirements for Procedural Rigging of  Bipeds and Quadrupeds Characters with Custom Manipulators for Animation", "abstract": "Character rigging is a process of endowing a character with a set of custom manipulators and controls making it easy to animate by the animators. These controls consist of simple joints, handles, or even separate character selection windows.This research paper present an automated rigging system for quadruped characters with custom controls and manipulators for animation.The full character rigging mechanism is procedurally driven based on various principles and requirements used by the riggers and animators. The automation is achieved initially by creating widgets according to the character type. These widgets then can be customized by the rigger according to the character shape, height and proportion. Then joint locations for each body parts are calculated and widgets are replaced programmatically.Finally a complete and fully operational procedurally generated character control rig is created and attached with the underlying skeletal joints. The functionality and feasibility of the rig was analyzed from various source of actual character motion and a requirements criterion was met. The final rigged character provides an efficient and easy to manipulate control rig with no lagging and at high frame rate.", "subjects": "Graphics (cs.GR)", "authors": "Zeeshan Bhatti, Asadullah Shah, Ahmad Waqas, Nadeem Mahmood,", "date": "2015-2-14"}, 
{"urllink": "http://arxiv.org/abs/1502.06398", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06398", "title": "\nBandit Convex Optimization: sqrt{T} Regret in One Dimension", "abstract": "We analyze the minimax regret of the adversarial bandit convex optimization problem. Focusing on the one-dimensional case, we prove that the minimax regret is and partially resolve a decade-old open problem. Our analysis is non-constructive, as we do not present a concrete algorithm that attains this regret rate. Instead, we use minimax duality to reduce the problem to a Bayesian setting, where the convex loss functions are drawn from a worst-case distribution, and then we solve the Bayesian version of the problem with a variant of Thompson Sampling. Our analysis features a novel use of convexity, formalized as a \"local-to-global\" property of convex functions, that may be of independent interest.", "subjects": "Learning (cs.LG)", "authors": "S\u00e9bastien Bubeck, Ofer Dekel, Tomer Koren, Yuval Peres,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06392", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06392", "title": "\nDynamic SLA Negotiation using Bandwidth Broker for Femtocell Networks", "abstract": "Satisfaction level of femtocell users' depends on the availability of requested bandwidth. But the xDSL line that can be used for the backhauling of femtocell traffic cannot always provide sufficient bandwidth due to the inequality between the xDSL capacity and demanded bandwidth of home applications like, IPTV, PC, WiFi, and others. A Service Level Agreement (SLA) between xDSL and femtocell operator (mobile operator) to reserve some bandwidth for the upcoming femtocell calls can increase the satisfaction level for femtocell users. In this paper we propose a SLA negotiation procedure for femtocell networks. The Bandwidth Broker controls the allocated bandwidth for femtocell users. Then we propose the dynamically reserve bandwidth scheme to increase the femtocell user's satisfaction level. Finally, we present our simulation results to validate the proposed scheme.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Mostafa Zaman Chowdhury, Sunwoong Choi, Yeong Min Jang, Kap-Suk Park, Geun Il Yoo,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06388", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06388", "title": "\nCall Admission Control based on Adaptive Bandwidth Allocation for  Multi-Class Services in Wireless Networks", "abstract": "Due to the fact that Quality of Service (QoS) requirements are not as stringent for non-real-time traffic types, as opposed to real-time traffic, more calls can be accommodated by releasing some bandwidth from the existing non-real-time traffic calls. If the released bandwidth to accept a handover call is larger than to accept a new call, then the probability of dropping a call is smaller than the probability of blocking a call. In this paper we propose an efficient Call Admission Control (CAC) that relies on adaptive multi-level bandwidth-allocation scheme for non-real-time calls. The features of the scheme allow reduction of the call dropping probability along with the increase of the bandwidth utilization. The numerical results show that the proposed scheme is able to attain negligible handover call dropping probability without sacrificing bandwidth utilization.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Mostafa Zaman Chowdhury, Yeong Min Jang, andZygmunt J. Haas,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06378", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06378", "title": "\nBibliometrics/Citation networks", "abstract": "In addition to shaping social networks, for example, in terms of co-authorship relations, scientific communications induce and reproduce cognitive structures. Scientific literature is intellectually organized in terms of disciplines and specialties; these structures are reproduced and networked reflexively by making references to the authors, concepts and texts embedded in these literatures. The concept of a cognitive structure was introduced in social network analysis (SNA) in 1987 by David Krackhardt, but the focus in SNA has hitherto been on cognition as a psychological attribute of human agency. In bibliometrics, and in science and technology studies (STS) more generally, socio-cognitive structures refer to intellectual organization at the supra-individual level. This intellectual organization emerges and is reproduced by the collectives of authors who are organized not only in terms of inter-personal relations, but also more abstractly in terms of codes of communication that are field-specific. Citations can serve as indicators of this codification process.", "subjects": "Digital Libraries (cs.DL)", "authors": "Loet Leydesdorff,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06370", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06370", "title": "\nA framework for space-efficient string kernels", "abstract": "String kernels are typically used to compare genome-scale sequences whose length makes alignment impractical, yet their computation is based on data structures that are either space-inefficient, or incur large slowdowns. We show that a number of exact string kernels, like the -mer kernel, the substrings kernels, a number of length-weighted kernels, the minimal absent words kernel, and kernels with Markovian corrections, can all be computed in time and in bits of space in addition to the input, using just a data structure on the Burrows-Wheeler transform of the input strings, which takes time per element in its output. The same bounds hold for a number of measures of compositional complexity based on multiple value of , like the -mer profile and the -th order empirical entropy, and for calibrating the value of using the data.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Djamal Belazzougui, Fabio Cunial,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06369", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06369", "title": "\nNeighbor Cell List Optimization for Femtocell-to-Femtocell Handover in  Dense Femtocellular Networks", "abstract": "Dense femtocells are the ultimate goal of the femtocellular network deployment. Among three types of handovers: femtocell-to-macrocell, macrocell-to-femtocell, and femtocell-to-femtocell, the latter two are the main concern for the dense femtocellular network deployment. For these handover cases, minimum as well appropriate neighbor cell list is the key element for the successful handover. In this paper, we propose an algorithm to make minimum but appropriate number of neighbor femtocell list for the femtocell-to-femtocell handover. Our algorithm considers received signal level from femto APs (FAPs); open and close access cases; and detected frequencyfrom the neighbor femtocells. The simulation results show that the proposed scheme is able to attain minimum but optimal number of neighbor femtocell list for the possible femtocell-to-femtocell handover.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Mostafa Zaman Chowdhury, Bui Minh Trung, Yeong Min Jang,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06362", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06362", "title": "\nContextual Dueling Bandits", "abstract": "We consider the problem of learning to choose actions using contextual information when provided with limited feedback in the form of relative pairwise comparisons. We study this problem in the dueling-bandits framework of Yue et al. (2009), which we extend to incorporate context. Roughly, the learner's goal is to find the best policy, or way of behaving, in some space of policies, although \"best\" is not always so clearly defined. Here, we propose a new and natural solution concept, rooted in game theory, called a von Neumann winner, a randomized policy that beats or ties every other policy. We show that this notion overcomes important limitations of existing solutions, particularly the Condorcet winner which has typically been used in the past, but which requires strong and often unrealistic assumptions. We then present three efficient algorithms for online learning in our setting, and for approximating a von Neumann winner from batch-like data. The first of these algorithms achieves particularly low regret, even when data is adversarial, although its time and space requirements are linear in the size of the policy space. The other two algorithms require time and space only logarithmic in the size of the policy space when provided access to an oracle for solving classification problems on the space.", "subjects": "Learning (cs.LG)", "authors": "Miroslav Dud\u00edk, Katja Hofmann, Robert E. Schapire, Aleksandrs Slivkins, Masrour Zoghi,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06360", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06360", "title": "\nMutually Testing Processes", "abstract": "In the standard testing theory of DeNicola-Hennessy one process is considered to be a refinement of another if every test guaranteed by the former is also guaranteed by the latter. In the domain of web services this has been recast, with processes viewed as servers and tests as clients. In this way the standard refinement preorder between servers is determined by their ability to satisfy clients. But in this setting there is also a natural refinement preorder between clients, determined by their ability to be satisfied by servers. In more general settings where there is no distinction between clients and servers, but all processes are peers, there is a further refinement preorder based on the mutual satisfaction of peers. We give a uniform account of these three preorders. In particular we give two characterisations. The first is behavioural, in terms of traces and ready sets. The second, for finite processes, is equational.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Giovanni Bernardi, Matthew Hennessy,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06359", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06359", "title": "\nA Sound and Complete Axiomatization of Majority-n Logic", "abstract": "Manipulating logic functions via majority operators recently drew the attention of researchers in computer science. For example, circuit optimization based on majority operators enables superior results as compared to traditional logic systems. Also, the Boolean satisfiability problem finds new solving approaches when described in terms of majority decisions. To support computer logic applications based on majority a sound and complete set of axioms is required. Most of the recent advances in majority logic deal only with ternary majority (MAJ- 3) operators because the axiomatization with solely MAJ-3 and complementation operators is well understood. However, it is of interest extending such axiomatization to n-ary majority operators (MAJ-n) from both the theoretical and practical perspective. In this work, we address this issue by introducing a sound and complete axiomatization of MAJ-n logic. Our axiomatization naturally includes existing majority logic systems. Based on this general set of axioms, computer applications can now fully exploit the expressive power of majority logic.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Luca Amaru, Pierre-Emmanuel Gaillardon, Anupam Chattopadhyay, Giovanni De Micheli,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06354", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06354", "title": "\nFirst-order regret bounds for combinatorial semi-bandits", "abstract": "We consider the problem of online combinatorial optimization under semi-bandit feedback, where a learner has to repeatedly pick actions from a combinatorial decision set in order to minimize the total losses associated with its decisions. After making each decision, the learner observes the losses associated with its action, but not other losses. The performance of the learner is measured in terms of its total expected regret against the best fixed action after rounds. In this paper, we propose a computationally efficient algorithm that improves existing worst-case guarantees of to , where is the total loss of the best action. Our algorithm is among the first to achieve such guarantees in a partial-feedback scheme, and the first one to do so in a combinatorial setting.", "subjects": "Learning (cs.LG)", "authors": "Gergely Neu,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06344", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06344", "title": "\nConvolutional Patch Networks with Spatial Prior for Road Detection and  Urban Scene Understanding", "abstract": "Classifying single image patches is important in many different applications, such as road detection or scene understanding. In this paper, we present convolutional patch networks, which are convolutional networks learned to distinguish different image patches and which can be used for pixel-wise labeling. We also show how to incorporate spatial information of the patch as an input to the network, which allows for learning spatial priors for certain categories jointly with an appearance model. In particular, we focus on road detection and urban scene understanding, two application areas where we are able to achieve state-of-the-art results on the KITTI as well as on the LabelMeFacade dataset. Furthermore, our paper offers a guideline for people working in the area and desperately wandering through all the painstaking details that render training CNs on image patches extremely difficult.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Clemens-Alexander Brust, Sven Sickert, Marcel Simon, Erik Rodner, Joachim Denzler,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06329", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06329", "title": "\nQoS Provisioning Using Optimal Call Admission Control for Wireless  Cellular Networks", "abstract": "The increasing demand for advanced services in wireless networks raises the problem for quality of service (QoS) provisioning with proper resource management. In this research, such a provisioning technique for wireless networks is performed by Call Admission Control (CAC). A new approach in CAC named by Uniform Fractional Band (UFB) is proposed in this work for the wireless networks for providing proper priority between new calls and handover calls. This UFB scheme is basically a new style of handover priority scheme. Handover priority is provided by two stages in this scheme which help the network to utilize more resources. In addition, the handover call rate estimation and its impact on QoS provisioning is discussed widely to attain the optimum QoS in proposed handover priority scheme. In multiple services providing wireless network, excessive call blocking of lower priority traffic is very often event at very high traffic rate which is a concerning issue for QoS provisioning. To attain such QoS provisioning for multiple services, another CAC scheme is proposed in this research work. This scheme is recognized by Uniform Band Thinning (UBT) scheme which is based on uniform thinning technique (UTT) and this is quite similar idea as UFB scheme. In this scheme, a set of channels experiences the fractionizing policy. This scheme reduces the call blocking probabilities (CBP) of lower priority traffic classes without notably increasing the CBP of the higher priority traffic classes. The analytical functions of this scheme are deduced in general form which is useful to deduce for any number of traffic classes. In addition, numerical analysis of the proposed UBT scheme shows that the performances in terms of call blocking probability, overall call blocking probability, and channel utilization are improved and optimized compared to the conventional fixed guard channel scheme.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Md. Asadur Rahman,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06327", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06327", "title": "\nIncentive Design and Market Evolution of Mobile User-Provided Networks", "abstract": "An operator-assisted user-provided network (UPN) has the potential to achieve a low cost ubiquitous Internet connectivity, without significantly increasing the network infrastructure investment. In this paper, we consider such a network where the network operator encourages some of her subscribers to operate as mobile Wi-Fi hotspots (hosts), providing Internet connectivity for other subscribers (clients). We formulate the interaction between the operator and mobile users as a two-stage game. In Stage I, the operator determines the usage-based pricing and quota-based incentive mechanism for the data usage. In Stage II, the mobile users make their decisions about whether to be a host, or a client, or not a subscriber at all. We characterize how the users' membership choices will affect each other's payoffs in Stage II, and how the operator optimizes her decision in Stage I to maximize her profit. Our theoretical and numerical results show that the operator's maximum profit increases with the user density under the proposed hybrid pricing mechanism, and the profit gain can be up to 50 % in a dense network comparing with a pricing-only approach with no incentives.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Mohammad Mahdi Khalili, Lin Gao, Jianwei Huang, Babak Hossein Khalaj,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06323", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06323", "title": "\nCSMA-SIC: Carrier Sensing with Successive Interference Cancellation", "abstract": "Successive interference cancellation (SIC) is a physical layer technique that enables the decoders to decode multiple simultaneously transmitted signals. The complicated model of SIC requires careful design of the MAC protocol and accurate adjustment of transmission parameters. We propose a new MAC protocol, known as CSMA-SIC, that employs the multi-packet reception capability of SIC. The proposed protocol adjusts the transmission probabilities to achieve throughput optimality.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Mohsen Mollanoori,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06321", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06321", "title": "\nA Linear Network Code Construction for General Integer Connections Based  on the Constraint Satisfaction Problem", "abstract": "The problem of finding network codes for general connections is inherently difficult. Resource minimization for general connections with network coding is further complicated. The existing solutions mainly rely on very restricted classes of network codes, and are almost all centralized. In this paper, we introduce linear network mixing coefficients for code constructions of general connections that generalize random linear network coding (RLNC) for multicast connections. For such code constructions, we pose the problem of cost minimization for the subgraph involved in the coding solution and relate this minimization to a Constraint Satisfaction Problem (CSP) which we show can be simplified to have a moderate number of constraints. While CSPs are NP-complete in general, we present a probabilistic distributed algorithm with almost sure convergence in finite time by applying Communication Free Learning (CFL). Our approach allows fairly general coding across flows, guarantees no greater cost than routing, and shows a possible distributed implementation.", "subjects": "Information Theory (cs.IT)", "authors": "Ying Cui, Muriel M\u00e9dard, Edmund Yeh, Douglas Leith, Ken Duffy,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06318", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06318", "title": "\nOn the Susceptibility of the Deferred Acceptance Algorithm", "abstract": "The Deferred Acceptance Algorithm (DAA) is the most widely accepted and used algorithm to match students, workers, or residents to colleges, firms or hospitals respectively. In this paper, we consider for the first time, the complexity of manipulating DAA by agents such as colleges that have capacity more than one. For such agents, truncation is not an exhaustive strategy. We present efficient algorithms to compute a manipulation for the colleges when the colleges are proposing or being proposed to. We then conduct detailed experiments on the frequency of manipulable instances in order to get better insight into strategic aspects of two-sided matching markets. Our results bear somewhat negative news: assuming that agents have information other agents' preference, they not only often have an incentive to misreport but there exist efficient algorithms to find such a misreport.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Haris Aziz, Hans Georg Seedig, Jana Karina von Wedel,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06314", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06314", "title": "\nCrowdsourced Live Streaming over the Cloud", "abstract": "Empowered by today's rich tools for media generation and distribution, and the convenient Internet access, crowdsourced streaming generalizes the single-source streaming paradigm by including massive contributors for a video channel. It calls a joint optimization along the path from crowdsourcers, through streaming servers, to the end-users to minimize the overall latency. The dynamics of the video sources, together with the globalized request demands and the high computation demand from each sourcer, make crowdsourced live streaming challenging even with powerful support from modern cloud computing. In this paper, we present a generic framework that facilitates a cost-effective cloud service for crowdsourced live streaming. Through adaptively leasing, the cloud servers can be provisioned in a fine granularity to accommodate geo-distributed video crowdsourcers. We present an optimal solution to deal with service migration among cloud instances of diverse lease prices. It also addresses the location impact to the streaming quality. To understand the performance of the proposed strategies in the realworld, we have built a prototype system running over the planetlab and the Amazon/Microsoft Cloud. Our extensive experiments demonstrate that the effectiveness of our solution in terms of deployment cost and streaming quality.", "subjects": "Multimedia (cs.MM)", "authors": "Fei Chen, Cong Zhang, Feng Wang, Jiangchuan Liu,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06306", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06306", "title": "\nDistortive Effects of Initial-Based Name Disambiguation on Measurements  of Large-Scale Coauthorship Networks", "abstract": "Scholars have often relied on name initials to resolve name ambiguities in large-scale coauthorship network research. This approach bears the risk of incorrectly merging or splitting author identities. The use of initial-based disambiguation has been justified by the assumption that such errors would not affect research findings too much. This paper tests this assumption by analyzing coauthorship networks from five academic fields - biology, computer science, nanoscience, neuroscience, and physics - and an interdisciplinary journal, PNAS. Name instances in datasets of this study were disambiguated based on heuristics gained from previous algorithmic disambiguation solutions. We use disambiguated data as a proxy of ground-truth to test the performance of three types of initial-based disambiguation. Our results show that initial-based disambiguation can misrepresent statistical properties of coauthorship networks: it deflates the number of unique authors, number of component, average shortest paths, clustering coefficient, and assortativity, while it inflates average productivity, density, average coauthor number per author, and largest component size. Also, on average, more than half of top 10 productive or collaborative authors drop off the lists. Asian names were found to account for the majority of misidentification by initial-based disambiguation due to their common surname and given name initials.", "subjects": "Digital Libraries (cs.DL)", "authors": "Jinseok Kim, Jana Diesner,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06297", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06297", "title": "\nElements of style of BPMN language", "abstract": "Several BPMN graphical tools support, at least partly, the OMG's BPMN specification. The BPMN standard is an essential guide for tools' makers when implementing the rules regarding depiction of BPMN diagrammatic constructs. Process modelers should also know how to rigorously use BPMN constructs when depicting business processes either for business or IT purposes. Several already published OMG's standards include the formal specification of well-formedness rules concern-ing the metamodels they address. However, the BPMN standard does not. Instead, the rules regarding BPMN elements are only informally specified in natural language throughout the overall BPMN documentation. Without strict rules concerning the correct usage of BPMN elements, no wonder that plenty of available BPMN tools fail to enforce BPMN process models' correctness. To mitigate this problem, and therefore contribute for achieving BPMN models' correctness, we propose to supplement the BPMN metamodel with well-formedness rules expressed by OCL invariants. So, this document contributes to bring together a set of requirements that tools' makers must comply with, in order to claim a broader BPMN 2 compliance. For the regular process modeler, this report provides an extensive and pragmatic catalog of BPMN elements' usage, to be followed in order to attain correct BPMN process models.", "subjects": "Software Engineering (cs.SE)", "authors": "Anacleto Correia,", "date": "2015-2-23"}, 
{"urllink": "http://arxiv.org/abs/1502.06286", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06286", "title": "\nStarL: Towards a Unified Framework for Programming, Simulating and  Verifying Distributed Robotic Systems", "abstract": "We developed StarL as a framework for programming, simulating, and verifying distributed systems that interacts with physical processes. StarL framework has (a) a collection of distributed primitives for coordination, such as mutual exclusion, registration and geocast that can be used to build sophisticated applications, (b) theory libraries for verifying StarL applications in the PVS theorem prover, and (c) an execution environment that can be used to deploy the applications on hardware or to execute them in a discrete event simulator. The primitives have (i) abstract, nondeterministic specifications in terms of invariants, and assume-guarantee style progress properties, (ii) implementations in Java/Android that always satisfy the invariants and attempt progress using best effort strategies. The PVS theories specify the invariant and progress properties of the primitives, and have to be appropriately instantiated and composed with the application's state machine to prove properties about the application. We have built two execution environments: one for deploying applications on Android/iRobot Create platform and a second one for simulating large instantiations of the applications in a discrete even simulator. The capabilities are illustrated with a StarL application for vehicle to vehicle coordination in a automatic intersection that uses primitives for point-to-point motion, mutual exclusion, and registration.", "subjects": "Programming Languages (cs.PL)", "authors": "Yixiao Lin, Sayan Mitra,", "date": "2015-2-22"}, 
{"urllink": "http://arxiv.org/abs/1502.06274", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06274", "title": "\nPersistent, Global Identity for Scientists via ORCID", "abstract": "Scientists have an inherent interest in claiming their contributions to the scholarly record, but the fragmented state of identity management across the landscape of astronomy, physics, and other fields makes highlighting the contributions of any single individual a formidable and often frustratingly complex task. The problem is exacerbated by the expanding variety of academic research products and the growing footprints of large collaborations and interdisciplinary teams. In this essay, we outline the benefits of a unique scholarly identifier with persistent value on a global scale and we review astronomy and physics engagement with the Open Researcher and Contributor iD (ORCID) service as a solution.", "subjects": "Digital Libraries (cs.DL)", "authors": "August E. Evrard, Christopher Erdmann, Jane Holmquist, James Damon, Dianne Dietrich,", "date": "2015-2-22"}, 
{"urllink": "http://arxiv.org/abs/1502.06260", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06260", "title": "\nCompressive Hyperspectral Imaging with Side Information", "abstract": "A blind compressive sensing algorithm is proposed to reconstruct hyperspectral images from spectrally-compressed measurements.The wavelength-dependent data are coded and then superposed, mapping the three-dimensional hyperspectral datacube to a two-dimensional image. The inversion algorithm learns a dictionary from the measurements via global-local shrinkage priors. By using RGB images as side information of the compressive sensing system, the proposed approach is extended to learn a coupled dictionary from the joint dataset of the compressed measurements and the corresponding RGB images, to improve reconstruction quality. A prototype camera is built using a liquid-crystal-on-silicon modulator. Experimental reconstructions of hyperspectral datacubes from both simulated and real compressed measurements demonstrate the efficacy of the proposed inversion algorithm, the feasibility of the camera and the benefit of side information.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Xin Yuan, Tsung-Han Tsai, Ruoyu Zhu, Patrick Llull, David Brady, Lawrence Carin,", "date": "2015-2-22"}, 
{"urllink": "http://arxiv.org/abs/1502.06254", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06254", "title": "\nThe fundamental nature of the log loss function", "abstract": "The standard loss functions used in the literature on probabilistic prediction are the log loss function and the Brier loss function; however, any proper loss function can be used for comparison of prediction algorithms. This note shows that the log loss function is most selective in that any prediction algorithm that is optimal for a given data sequence (in the sense of the algorithmic theory of randomness) under the log loss function will be optimal under any computable proper mixable loss function; on the other hand, there is a data sequence and a prediction algorithm that is optimal for that sequence under the Brier loss function but not under the log loss function.", "subjects": "Learning (cs.LG)", "authors": "Vladimir Vovk,", "date": "2015-2-22"}, 
{"urllink": "http://arxiv.org/abs/1502.06250", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06250", "title": "\nDerivation of a low multiplicative complexity algorithm for multiplying  hyperbolic octonions", "abstract": "We present an efficient algorithm to multiply two hyperbolic octonions. The direct multiplication of two hyperbolic octonions requires 64 real multiplications and 56 real additions. More effective solutions still do not exist. We show how to compute a product of the hyperbolic octonions with 26 real multiplications and 92 real additions. During synthesis of the discussed algorithm we use the fact that product of two hyperbolic octonions may be represented as a matrix - vector product. The matrix multiplicand that participates in the product calculating has unique structural properties that allow performing its advantageous factorization. Namely this factorization leads to significant reducing of the computational complexity of hyperbolic octonions multiplication.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Aleksandr Cariow, Galina Cariowa, Jaroslaw Knapinski,", "date": "2015-2-22"}, 
{"urllink": "http://arxiv.org/abs/1502.06235", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06235", "title": "\nSpatio-temporal Video Parsing for Abnormality Detection", "abstract": "Abnormality detection in video poses particular challenges due to the infinite size of the class of all irregular objects and behaviors. Thus no (or by far not enough) abnormal training samples are available and we need to find abnormalities in test data without actually knowing what they are. Nevertheless, the prevailing concept of the field is to directly search for individual abnormal local patches or image regions independent of another. To address this problem, we propose a method for joint detection of abnormalities in videos by spatio-temporal video parsing. The goal of video parsing is to find a set of indispensable normal spatio-temporal object hypotheses that jointly explain all the foreground of a video, while, at the same time, being supported by normal training samples. Consequently, we avoid a direct detection of abnormalities and discover them indirectly as those hypotheses which are needed for covering the foreground without finding an explanation for themselves by normal samples. Abnormalities are localized by MAP inference in a graphical model and we solve it efficiently by formulating it as a convex optimization problem. We experimentally evaluate our approach on several challenging benchmark sets, improving over the state-of-the-art on all standard benchmarks both in terms of abnormality classification and localization.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Borislav Anti\u0107, Bj\u00f6rn Ommer,", "date": "2015-2-22"}, 
{"urllink": "http://arxiv.org/abs/1502.06230", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06230", "title": "\nHardware Architecture for Single Iteration Reconstruction Algorithm", "abstract": "A hardware architecture for the single iteration algorithm is proposed in this paper. Single iteration algorithm enables reconstruction of the full signal when small number of signal samples is available. The algorithm is based on the threshold calculation, and allows distinguishing between signal components and noise that appears as a consequence of missing samples. The proposed system for hardware realization is divided into three parts, each part with different functionality. The system is suitable for the FPGA realization. Realization of the blocks for which there are no standard components in FPGA, is discussed as well.", "subjects": "Information Theory (cs.IT)", "authors": "Andjela Draganic, Irena Orovic, Nedjeljko Lekic, Milos Dakovic, Srdjan Stankovic,", "date": "2015-2-22"}, 
{"urllink": "http://arxiv.org/abs/1502.06229", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06229", "title": "\nSales pipeline win propensity prediction: a regression approach", "abstract": "Sales pipeline analysis is fundamental to proactive management of an enterprize's sales pipeline and critical for business success. In particular, win propensity prediction, which involves quantitatively estimating the likelihood that on-going sales opportunities will be won within a specified time window, is a fundamental building block for sales management and lays the foundation for many applications such as resource optimization and sales gap analysis. With the proliferation of big data, the use of data-driven predictive models as a means to drive better sales performance is increasingly widespread, both in business-to-client (B2C) and business-to-business (B2B) markets. However, the relatively small number of B2B transactions (compared with the volume of B2C transactions), noisy data, and the fast-changing market environment pose challenges to effective predictive modeling. This paper proposes a machine learning-based unified framework for sales opportunity win propensity prediction, aimed at addressing these challenges. We demonstrate the efficacy of our proposed system using data from a top-500 enterprize in the business-to-business market.", "subjects": "Computers and Society (cs.CY)", "authors": "Junchi Yan, Min Gong, Changhua Sun, Jin Huang, Stephen M. Chu,", "date": "2015-2-22"}, 
{"urllink": "http://arxiv.org/abs/1502.06221", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06221", "title": "\nSampling with Walsh Transforms", "abstract": "With the advent of massive data outputs at a regular rate, admittedly, signal processing technology plays an increasingly important role. Nowadays, signals are not merely restricted to the physical world, they have been extended to cover a much wider range of statistical sources (including financial signals, graph signals). Under the general assumption of discrete statistical signal sources, in this paper, we propose a practical problem of sampling incomplete signals for which we do not know a priori, with bounded sample size. We approach this sampling problem by Shannon's communication theory. We use an extremal binary channel with high probability of transmission error, which is rare in communication theory. Nonetheless, the channel communication theory translates it into a very useful statistical result. Our main result demonstrates that it is the large Walsh coefficient(s) that characterize(s) discrete statistical signals, regardless of the signal sources. In particular, when sampling incomplete signals of the same source multiple times, one can expect to see repeatedly those large Walsh coefficient(s) of same magnitude(s) at the fixed frequency position(s). By the connection of channel communication theory, we establish the necessary and sufficient condition for our bounded sampling problem.", "subjects": "Information Theory (cs.IT)", "authors": "Yi Lu,", "date": "2015-2-22"}, 
{"urllink": "http://arxiv.org/abs/1502.06220", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06220", "title": "\nBoosting of Image Denoising Algorithms", "abstract": "In this paper we propose a generic recursive algorithm for improving image denoising methods. Given the initial denoised image, we suggest repeating the following \"SOS\" procedure: (i) (S)trengthen the signal by adding the previous denoised image to the degraded input image, (ii) (O)perate the denoising method on the strengthened image, and (iii) (S)ubtract the previous denoised image from the restored signal-strengthened outcome. The convergence of this process is studied for the K-SVD image denoising and related algorithms. Still in the context of K-SVD image denoising, we introduce an interesting interpretation of the SOS algorithm as a technique for closing the gap between the local patch-modeling and the global restoration task, thereby leading to improved performance. In a quest for the theoretical origin of the SOS algorithm, we provide a graph-based interpretation of our method, where the SOS recursive update effectively minimizes a penalty function that aims to denoise the image, while being regularized by the graph Laplacian. We demonstrate the SOS boosting algorithm for several leading denoising methods (K-SVD, NLM, BM3D, and EPLL), showing tendency to further improve denoising performance.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Yaniv Romano, Michael Elad,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.06219", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06219", "title": "\nVideo Text Localization with an emphasis on Edge Features", "abstract": "The text detection and localization plays a major role in video analysis and understanding. The scene text embedded in video consist of high-level semantics and hence contributes significantly to visual content analysis and retrieval. This paper proposes a novel method to robustly localize the texts in natural scene images and videos based on sobel edge emphasizing approach. The input image is preprocessed and edge emphasis is done to detect the text clusters. Further, a set of rules have been devised using morphological operators for false positive elimination and connected component analysis is performed to detect the text regions and hence text localization is performed. The experimental results obtained on publicly available standard datasets illustrate that the proposed method can detect and localize the texts of various sizes, fonts and colors.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "B.H. Shekar, Smitha M.L.,", "date": "2015-2-22"}, 
{"urllink": "http://arxiv.org/abs/1502.06218", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06218", "title": "\nOn Probabilistic Certification of Combined Cancer Therapies Using  Strongly Uncertain Models", "abstract": "This paper proposes a general framework for probabilistic certification of cancer therapies. The certification is defined in terms of two key issues which are the tumor contraction and the lower admissible bound on the circulating lymphocytes which is viewed as indicator of the patient health. The certification is viewed as the ability to guarantee with a predefined high probability the success of the therapy over a finite horizon despite of the unavoidable high uncertainties affecting the dynamic model that is used to compute the optimal scheduling of drugs injection. The certification paradigm can be viewed as a tool for tuning the treatment parameters and protocols as well as for getting a rational use of limited or expensive drugs. The proposed framework is illustrated using the specific problem of combined immunotherapy/chemotherapy of cancer.", "subjects": "Systems and Control (cs.SY)", "authors": "Mazen Alamir,", "date": "2015-2-22"}, 
{"urllink": "http://arxiv.org/abs/1502.06208", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06208", "title": "\nNearly optimal classification for semimetrics", "abstract": "We initiate the rigorous study of classification in semimetric spaces, which are point sets with a distance function that is non-negative and symmetric, but need not satisfy the triangle inequality. For metric spaces, the doubling dimension essentially characterizes both the runtime and sample complexity of classification algorithms --- yet we show that this is not the case for semimetrics. Instead, we define the and discover that it plays a central role in the statistical and algorithmic feasibility of learning in semimetric spaces. We present nearly optimal sample compression algorithms and use these to obtain generalization guarantees, including fast rates. The latter hold for general sample compression schemes and may be of independent interest.", "subjects": "Learning (cs.LG)", "authors": "Lee-Ad Gottlieb, Aryeh Kontorovich,", "date": "2015-2-22"}, 
{"urllink": "http://arxiv.org/abs/1502.06195", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06195", "title": "\nExact Minkowski Sums of Polygons With Holes", "abstract": "We present an efficient algorithm that computes the Minkowski sum of two polygons, which may have holes. The new algorithm is based on the convolution approach. Its efficiency stems in part from a property for Minkowski sums of polygons with holes, which we prove to hold in any dimension. Given two polygons with holes, we can fill in all the holes of one polygon, transforming it into a simple polygon, and still obtain the exactly same Minkowski sum. Obliterating holes in the input summands speeds up the computation of Minkowski sums. We introduce a robust implementation of the new algorithm, which follows the Exact Geometric Computation paradigm and thus guarantees exact results. We also present an empirical comparison of the performance of Minkowski sum constructions, where we show that the implementation of the new algorithm exhibits better performance than all other implementations in many cases. In particular, we compared the implementation of the new algorithm, an implementation of the standard convolution algorithm, and an implementation of the decomposition approach using various convex decomposition methods. The software has been developed as an extension of the \"2D Minkowski Sums\" package of CGAL (Computational Geometry Algorithms Library). Additional information and supplementary material is available at our project page this http URL", "subjects": "Computational Geometry (cs.CG)", "authors": "Alon Baram, Efi Fogel, Michael Hemmer, Dan Halperin, Sebastian Morr,", "date": "2015-2-22"}, 
{"urllink": "http://arxiv.org/abs/1502.06194", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06194", "title": "\nAlgorithm for the k-Position Tree Automaton Construction", "abstract": "The word position automaton was introduced by Glushkov and McNaughton in the early 1960. This automaton is homogeneous and has (|| E||+1) states for a word expression of alphabetic width || E||. This kind of automata is extended to regular tree expressions. In this paper, we give an efficient algorithm that computes the Follow sets, which are used in different algorithms of conversion of a regular expression into tree automata. In the following, we consider the k-position tree automaton construction. We prove that for a regular expression E of a size | E| and alphabetic width || E||, the Follow sets can be computed in O(|| E|| cdot | E|) time complexity.", "subjects": "Formal Languages and Automata Theory (cs.FL)", "authors": "Nadia Ouali Sebti, Djelloul Ziadi,", "date": "2015-2-22"}, 
{"urllink": "http://arxiv.org/abs/1502.06188", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06188", "title": "\nAn empirical performance study of Intra-vehicular Wireless Sensor  Networks under WiFi and Bluetooth interference", "abstract": "Intra-Vehicular Wireless Sensor Network (IVWSN) is a new automotive architecture that applies wireless technologies to the communications between Electrical Control Units (ECUs) and sensors. It can potentially help achieve better fuel economy, reduce wiring complexity, and support additional new applications. In the existing works, most of the popular wireless technologies applied on IVWSNs occupy the same 2.4 GHz ISM frequency bands as WiFi and Bluetooth do. It is therefore essential to evaluate the performance of IVWSNs under interference from WiFi and Bluetooth devices, especially when these devices are inside the vehicle. In this paper, we report the results of a comprehensive experimental study of IVWSNs based on ZigBee and Bluetooth Low Energy under WiFi and Bluetooth interference. The impact of the interference from Bluetooth and WiFi devices can be clearly observed from the experiments. The results of the experiments conducted suggest that Bluetooth Low Energy technology outperforms ZigBee technology in the context of IVWSNs when WiFi interference exists in the car.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Jiun-Ren Lin, Timothy Talty, Ozan K. Tonguz,", "date": "2015-2-22"}, 
{"urllink": "http://arxiv.org/abs/1502.06187", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06187", "title": "\nTeaching and compressing for low VC-dimension", "abstract": "In this work we study the quantitative relation between VC-dimension and two other basic parameters related to learning and teaching. We present relatively efficient constructions of and for classes of low VC-dimension. Let be a finite boolean concept class of VC-dimension . Set . We construct sample compression schemes of size for , with additional information of bits. Roughly speaking, given any list of -labelled examples of arbitrary length, we can retain only labeled examples in a way that allows to recover the labels of all others examples in the list. We also prove that there always exists a concept in with a teaching set (i.e. a list of -labelled examples uniquely identifying ) of size . Equivalently, we prove that the recursive teaching dimension of is at most . The question of constructing sample compression schemes for classes of small VC-dimension was suggested by Littlestone and Warmuth (1986), and the problem of constructing teaching sets for classes of small VC-dimension was suggested by Kuhlmann (1999). Previous constructions for general concept classes yielded size for both questions, even when the VC-dimension is constant.", "subjects": "Learning (cs.LG)", "authors": "Shay Moran, Amir Shpilka, Avi Wigderson, Amir Yehudayoff,", "date": "2015-2-22"}, 
{"urllink": "http://arxiv.org/abs/1502.06177", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06177", "title": "\nSDCA without Duality", "abstract": "Stochastic Dual Coordinate Ascent is a popular method for solving regularized loss minimization for the case of convex losses. In this paper we show how a variant of SDCA can be applied for non-convex losses. We prove linear convergence rate even if individual loss functions are non-convex as long as the expected loss is convex.", "subjects": "Learning (cs.LG)", "authors": "Shai Shalev-Shwartz,", "date": "2015-2-22"}, 
{"urllink": "http://arxiv.org/abs/1502.06176", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06176", "title": "\nNew separation theorems and sub-exponential time algorithms for packing  and piercing of fat objects", "abstract": "For a collection of objects in , let the packing and piercing numbers of , denoted by , and , respectively, be the largest number of pairwise disjoint objects in , and the smallest number of points in that are common to all elements of , respectively. When elements of are fat objects of arbitrary sizes, we derive sub-exponential time algorithms for the NP-hard problems of computing and , respectively, that run in and time, respectively, and storage. Our main tool which is interesting in its own way, is a new separation theorem. The algorithms readily give rise to polynomial time approximation schemes (PTAS) that run in time and storage. The results favorably compare with many related best known results. Specifically, our separation theorem significantly improves the splitting ratio of the previous result of Chan, whereas, the sub-exponential time algorithms significantly improve upon the running times of very recent algorithms of Fox and Pach for packing of spheres.", "subjects": "Computational Geometry (cs.CG)", "authors": "Farhad Shahrokhi,", "date": "2015-2-22"}, 
{"urllink": "http://arxiv.org/abs/1502.06164", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06164", "title": "\nOn mesh restrictions to satisfy comparison principles, maximum  principles, and the non-negative constraint: Recent developments and new  results", "abstract": "This paper concerns with mesh restrictions that are needed to satisfy several important mathematical properties -- maximum principles, comparison principles, and the non-negative constraint -- for a general linear second-order elliptic partial differential equation. We critically review some recent developments in the field of discrete maximum principles, derive new results, and discuss some possible future research directions in this area. In particular, we derive restrictions for a three-node triangular (T3) element and a four-node quadrilateral (Q4) element to satisfy comparison principles, maximum principles, and the non-negative constraint under the standard single-field Galerkin formulation. Analysis is restricted to uniformly elliptic linear differential operators in divergence form with Dirichlet boundary conditions specified on the entire boundary of the domain. Various versions of maximum principles and comparison principles are discussed in both continuous and discrete settings. In the literature, it is well-known that an acute-angled triangle is sufficient to satisfy the discrete weak maximum principle for pure isotropic diffusion. An iterative algorithm is developed to construct simplicial meshes that preserves discrete maximum principles using existing open source mesh generators. Various numerical examples based on different types of triangulations are presented to show the pros and cons of placing restrictions on a computational mesh. We also quantify local and global mass conservation errors using representative numerical examples, and illustrate the performance of metric-based meshes with respect to mass conservation.", "subjects": "Numerical Analysis (cs.NA)", "authors": "M. K. Mudunuru, K. B. Nakshatrala,", "date": "2015-2-22"}, 
{"urllink": "http://arxiv.org/abs/1502.06161", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06161", "title": "\nUsing NLP to measure democracy", "abstract": "This paper uses natural language processing to create the first machine-coded democracy index, which I call Automated Democracy Scores (ADS). The ADS are based on 42 million news articles from 6,043 different sources and cover all independent countries in the 1993-2012 period. Unlike the democracy indices we have today the ADS are replicable and have standard errors small enough to actually distinguish between cases. The ADS are produced with supervised learning. Three approaches are tried: a) a combination of Latent Semantic Analysis and tree-based regression methods; b) a combination of Latent Dirichlet Allocation and tree-based regression methods; and c) the Wordscores algorithm. The Wordscores algorithm outperforms the alternatives, so it is the one on which the ADS are based. There is a web application where anyone can change the training set and see how the results change: democracy-scores.org", "subjects": "Computation and Language (cs.CL)", "authors": "Thiago Marzag\u00e3o,", "date": "2015-2-22"}, 
{"urllink": "http://arxiv.org/abs/1502.06160", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06160", "title": "\nMathematical foundations of inconsistency analysis in pairwise  comparisons", "abstract": "This study, based on contemporary mathematical foundations, presents an abelian group approach to analyzing inconsistency in pairwise comparisons. A general and precise notion of an inconsistency indicator map on a group, taking values in an abelian linearly ordered group, is introduced. For it, metrics and generalized metrics are investigated. Every inconsistency indicator map generates an inconsistency index of a pairwise comparisons matrix. The inconsistency analysis in pairwise comparisons has broad applications in multi-criteria decision making.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Waldemar W. Koczkodaj, Jacek Szybowski, Eliza Wajch,", "date": "2015-2-22"}, 
{"urllink": "http://arxiv.org/abs/1502.06152", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06152", "title": "\nOn Sequences, Rational Functions and Decomposition", "abstract": "Our overall goal is to unify and extend some results in the literature related to the approximation of generating functions of finite and infinite sequences over a field by rational functions. In our approach, numerators play a significant role. We revisit a theorem of Niederreiter on (i) linear complexities and (ii) ' minimal polynomials' of an infinite sequence, proved using partial quotients. We prove (i) and its converse from first principles and generalise (ii) to rational functions where the denominator need not have minimal degree. We prove (ii) in two parts: firstly for geometric sequences and then for sequences with a jump in linear complexity. The basic idea is to decompose the denominator as a sum of polynomial multiples of two polynomials of minimal degree; there is a similar decomposition for the numerators. The decomposition is unique when the denominator has degree at most the length of the sequence. The proof also applies to rational functions related to finite sequences, generalising a result of Massey. We give a number of applications to rational functions associated to sequences.", "subjects": "Symbolic Computation (cs.SC)", "authors": "Graham H. Norton,", "date": "2015-2-21"}, 
{"urllink": "http://arxiv.org/abs/1502.06149", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06149", "title": "\nEfficient Algorithms for the Data Exchange Problem", "abstract": "In this paper we study the data exchange problem where a set of users is interested in gaining access to a common file, but where each has only partial knowledge about it as side-information. Assuming that the file is broken into packets, the side-information considered is in the form of linear combinations of the file packets. Given that the collective information of all the users is sufficient to allow recovery of the entire file, the goal is for each user to gain access to the file while minimizing some communication cost. We assume that users can communicate over a noiseless broadcast channel, and that the communication cost is a sum of each user's cost function over the number of bits it transmits. For instance, the communication cost could simply be the total number of bits that needs to be transmitted. In the most general case studied in this paper, each user can have any arbitrary convex cost function. We provide deterministic, polynomial-time algorithms (in the number of users and packets) which find an optimal communication scheme that minimizes the communication cost. To further lower the complexity, we also propose a simple randomized algorithm inspired by our deterministic algorithm which is based on a random linear network coding scheme.", "subjects": "Information Theory (cs.IT)", "authors": "Nebojsa Milosavljevic, Sameer Pawar, Salim El Rouayheb, Michael Gastpar, Kannan Ramchandran,", "date": "2015-2-21"}, 
{"urllink": "http://arxiv.org/abs/1502.06133", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06133", "title": "\nA Multi-phase Approach for Improving Information Diffusion in Social  Networks", "abstract": "For maximizing influence spread in a social network, given a certain budget on the number of seed nodes, we investigate the effects of selecting and activating the seed nodes in multiple phases. In particular, we formulate an appropriate objective function for two-phase influence maximization under the independent cascade model, investigate its properties, and propose algorithms for determining the seed nodes in the two phases. We also study the problem of determining an optimal budget-split and delay between the two phases.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Swapnil Dhamal, Prabuchandran K. J., Y. Narahari,", "date": "2015-2-21"}, 
{"urllink": "http://arxiv.org/abs/1502.06132", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06132", "title": "\nUniversal Memory Architectures for Autonomous Machines", "abstract": "We propose a self-organizing memory architecture for perceptual experience, capable of supporting autonomous learning and goal-directed problem solving in the absence of any prior information about the agent's environment. The architecture is simple enough to ensure (1) a quadratic bound (in the number of available sensors) on space requirements, and (2) a quadratic bound on the time-complexity of the update-execute cycle. At the same time, it is sufficiently complex to provide the agent with an internal representation which is (3) minimal among all representations of its class which account for every sensory equivalence class subject to the agent's belief state; (4) capable, in principle, of recovering the homotopy type of the system's state space; (5) learnable with arbitrary precision through a random application of the available actions. The provable properties of an effectively trained memory structure exploit a duality between weak poc sets -- a symbolic (discrete) representation of subset nesting relations -- and non-positively curved cubical complexes, whose rich convexity theory underlies the planning cycle of the proposed architecture.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Dan P. Guralnik, Daniel E. Koditschek,", "date": "2015-2-21"}, 
{"urllink": "http://arxiv.org/abs/1502.06124", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06124", "title": "\nUnified vector space mapping for knowledge representation systems", "abstract": "One of the most significant problems which inhibits further developments in the areas of Knowledge Representation and Artificial Intelligence is a problem of semantic alignment or knowledge mapping. The progress in its solution will be greatly beneficial for further advances of information retrieval, ontology alignment, relevance calculation, text mining, natural language processing etc. In the paper the concept of multidimensional global knowledge map, elaborated through unsupervised extraction of dependencies from large documents corpus, is proposed. In addition, the problem of direct Human - Knowledge Representation System interface is addressed and a concept of adaptive decoder proposed for the purpose of interaction with previously described unified mapping model. In combination these two approaches are suggested as basis for a development of a new generation of knowledge representation systems.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Dmytro Filatov, Taras Filatov,", "date": "2015-2-21"}, 
{"urllink": "http://arxiv.org/abs/1502.06111", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06111", "title": "\nOn the representation of the search region in multi-objective  optimization", "abstract": "Given a finite set of feasible points of a multi-objective optimization (MOO) problem, the search region corresponds to the part of the objective space containing all the points that are not dominated by any point of , i.e. the part of the objective space which may contain further nondominated points. In this paper, we consider a representation of the search region by a set of tight local upper bounds (in the minimization case) that can be derived from the points of . Local upper bounds play an important role in methods for generating or approximating the nondominated set of an MOO problem, yet few works in the field of MOO address their efficient incremental determination. We relate this issue to the state of the art in computational geometry and provide several equivalent definitions of local upper bounds that are meaningful in MOO. We discuss the complexity of this representation in arbitrary dimension, which yields an improved upper bound on the number of solver calls in epsilon-constraint-like methods to generate the nondominated set of a discrete MOO problem. We analyze and enhance a first incremental approach which operates by eliminating redundancies among local upper bounds. We also study some properties of local upper bounds, especially concerning the issue of redundant local upper bounds, that give rise to a new incremental approach which avoids such redundancies. Finally, the complexities of the incremental approaches are compared from the theoretical and empirical points of view.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Kathrin Klamroth, Renaud Lacour, Daniel Vanderpooten,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.06108", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06108", "title": "\nDon't Just Listen, Use Your Imagination: Leveraging Visual Common Sense  for Non-Visual Tasks", "abstract": "Artificial agents today can answer factual questions. But they fall short on questions that require common sense reasoning. Perhaps this is because most existing common sense databases rely on text to learn and represent knowledge. But much of common sense knowledge is unwritten - partly because it tends not to be interesting enough to talk about, and partly because some common sense is unnatural to articulate in text. While unwritten, it is not unseen. In this paper we leverage semantic common sense knowledge learned from images - i.e. visual common sense - in two textual tasks: fill-in-the-blank and visual paraphrasing. We propose to \"imagine\" the scene behind the text, and leverage visual cues from the \"imagined\" scenes in addition to textual cues while answering these questions. We imagine the scenes as a visual abstraction. Our approach outperforms a strong text-only baseline on these tasks. Our proposed tasks can serve as benchmarks to quantitatively evaluate progress in solving tasks that go \"beyond recognition\". Our code and datasets will be made publicly available.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Xiao Lin, Devi Parikh,", "date": "2015-2-21"}, 
{"urllink": "http://arxiv.org/abs/1502.06105", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06105", "title": "\nRegularization and Kernelization of the Maximin Correlation Approach", "abstract": "Robust classification becomes challenging when classes contain multiple subclasses. Examples include multi-font optical character recognition and automated protein function prediction. In correlation-based nearest-neighbor classification, the maximin correlation approach (MCA) provides the worst-case optimal solution by minimizing the maximum misclassification risk through an iterative procedure. Despite the optimality, the original MCA has drawbacks that have limited its wide applicability in practice. That is, the MCA tends to be sensitive to outliers, cannot effectively handle nonlinearities in datasets, and suffers from having high computational complexity. To address these limitations, we propose an improved solution, named regularized maximin correlation approach (R-MCA). We first reformulate MCA as a quadratically constrained linear programming (QCLP) problem, incorporate regularization by introducing slack variables into the primal problem of the QCLP, and derive the corresponding Lagrangian dual. The dual formulation enables us to apply the kernel trick to R-MCA so that it can better handle nonlinearities. Our experimental results demonstrate that the regularization and kernelization make the proposed R-MCA more robust and accurate for various classification tasks than the original MCA. Furthermore, when the data size or dimensionality grows, R-MCA runs substantially faster by solving either the primal or dual (whichever has a smaller variable dimension) of the QCLP.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Taehoon Lee, Taesup Moon, Seung Jean Kim, Sungroh Yoon,", "date": "2015-2-21"}, 
{"urllink": "http://arxiv.org/abs/1502.06104", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06104", "title": "\nMinimal Switch Step Tracking Control of Switched Systems with  Application to Induction Motor Control", "abstract": "The problem of step tracking control with a switching input and without any continuous-valued inputs is considered. The control objective is to reduce the number of switchings to a minimal value. This approach finds interesting applications when switching comprises costs and should be avoided. To solve the problem, a state dependent switching strategy should be designed and the resulting closed loop is indeed a hybrid system. Therefore, first we investigate the conditions on a hybrid system for being the desired solution. Then, we propose a method for designing the switching strategy such that the closed loop as a hybrid system solves the problem. The proposed method is applied to the induction motor control problem which results in relatively simple and efficient control algorithm. Comparison with the direct torque control for induction motors show that our method has a superior performance in reducing the number of mode switches.", "subjects": "Systems and Control (cs.SY)", "authors": "Babak Tavassoli,", "date": "2015-2-21"}, 
{"urllink": "http://arxiv.org/abs/1502.06103", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06103", "title": "\nCompressive sensing based velocity estimation in video data", "abstract": "This paper considers the use of compressive sensing based algorithms for velocity estimation of moving vehicles. The procedure is based on sparse reconstruction algorithms combined with time-frequency analysis applied to video data. This algorithm provides an accurate estimation of object's velocity even in the case of a very reduced number of available video frames. The influence of crucial parameters is analysed for different types of moving vehicles.", "subjects": "Multimedia (cs.MM)", "authors": "Ana Miletic, Nemanja Ivanovic,", "date": "2015-2-21"}, 
{"urllink": "http://arxiv.org/abs/1502.06096", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06096", "title": "\nReinforcement Learning in a Neurally Controlled Robot Using Dopamine  Modulated STDP", "abstract": "Recent work has shown that dopamine-modulated STDP can solve many of the issues associated with reinforcement learning, such as the distal reward problem. Spiking neural networks provide a useful technique in implementing reinforcement learning in an embodied context as they can deal with continuous parameter spaces and as such are better at generalizing the correct behaviour to perform in a given context. In this project we implement a version of DA-modulated STDP in an embodied robot on a food foraging task. Through simulated dopaminergic neurons we show how the robot is able to learn a sequence of behaviours in order to achieve a food reward. In tests the robot was able to learn food-attraction behaviour, and subsequently unlearn this behaviour when the environment changed, in all 50 trials. Moreover we show that the robot is able to operate in an environment whereby the optimal behaviour changes rapidly and so the agent must constantly relearn. In a more complex environment, consisting of food-containers, the robot was able to learn food-container attraction in 95% of trials, despite the large temporal distance between the correct behaviour and the reward. This is achieved by shifting the dopamine response from the primary stimulus (food) to the secondary stimulus (food-container). Our work provides insights into the reasons behind some observed biological phenomena, such as the bursting behaviour observed in dopaminergic neurons. As well as demonstrating how spiking neural network controlled robots are able to solve a range of reinforcement learning tasks.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "Richard Evans,", "date": "2015-2-21"}, 
{"urllink": "http://arxiv.org/abs/1502.06095", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06095", "title": "\nBialgebraic Semantics for Logic Programming", "abstract": "Bialgebrae provide an abstract framework encompassing the semantics of different kinds of computational models. In this paper we propose a bialgebraic approach to the semantics of logic programming. Our methodology is to study logic programs as reactive systems and exploit abstract techniques developed in that setting. First we use saturation to model the operational semantics of logic programs as coalgebrae on presheaves. Then, we make explicit the underlying algebraic structure by using bialgebrae on presheaves. The resulting semantics turns out to be compositional with respect to conjunction and term substitution. Also, it encodes a parallel model of computation, whose soundness is guaranteed by a built-in notion of synchronisation between different threads.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Filippo Bonchi, Fabio Zanasi,", "date": "2015-2-21"}, 
{"urllink": "http://arxiv.org/abs/1502.06094", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06094", "title": "\nPositive Neural Networks in Discrete Time Implement Monotone-Regular  Behaviors", "abstract": "Many works have investigated the expressive power of various kinds of neural networks. We continue this study with inspiration from biologically plausible models. In particular, we study positive neural networks with multiple input neurons, and where neurons only excite each other and do not inhibit each other. Different behaviors can be expressed by varying the connection strengths between the neurons. We show that in discrete time, and in absence of noise, the class of positive neural networks captures the so-called monotone-regular behaviors, that are based on regular languages. A finer picture emerges if one takes into account the delay by which a monotone-regular behavior is implemented. Each monotone-regular behavior can be implemented by a positive neural network with a delay of one time unit. Some monotone-regular behaviors can be implemented with zero delay. And, interestingly, some simple monotone-regular behaviors can not be implemented with zero delay.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "Tom J. Ameloot,", "date": "2015-2-21"}, 
{"urllink": "http://arxiv.org/abs/1502.06086", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06086", "title": "\nDCAFE: Dynamic load-balanced loop Chunking & Aggressive Finish  Elimination for Recursive Task Parallel Programs", "abstract": "In this paper, we present two symbiotic optimizations to optimize recursive task parallel (RTP) programs by reducing the task creation and termination overheads. Our first optimization Aggressive Finish-Elimination (AFE) helps reduce the redundant join operations to a large extent. The second optimization Dynamic Load-Balanced loop Chunking (DLBC) extends the prior work on loop chunking to decide on the number of parallel tasks based on the number of available worker threads, at runtime. Further, we discuss the impact of exceptions on our optimizations and extend them to handle RTP programs that may throw exceptions. We implemented DCAFE (= DLBC+AFE) in the X10v2.3 compiler and tested it over a set of benchmark kernels on two different hardwares (a 16-core Intel system and a 64-core AMD system). With respect to the base X10 compiler extended with loop-chunking of Nandivada et al [Nandivada et al.(2013)Nandivada, Shirako, Zhao, and Sarkar](LC), DCAFE achieved a geometric mean speed up of 5.75x and 4.16x on the Intel and AMD system, respectively. We also present an evaluation with respect to the energy consumption on the Intel system and show that on average, compared to the LC versions, the DCAFE versions consume 71.2% less energy.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Suyash Gupta, Rahul Shrivastava, V. Krishna Nandivada,", "date": "2015-2-21"}, 
{"urllink": "http://arxiv.org/abs/1502.06085", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06085", "title": "\nOpportunistic Cooperative Channel Access in Distributed Wireless  Networks with Decode-and-Forward Relays", "abstract": "This letter studies distributed opportunistic channel access in a wireless network with decode-and-forward relays. All the sources use channel contention to get transmission opportunity. If a source wins the contention, the channel state information in the first-hop channel (from the source to its relay) is estimated, and a decision is made for the winner source to either give up the transmission opportunity and let all sources start a new contention, or transmit to the relay. Once the relay gets the traffic, it may have a sequence of probings of the second-hop channel (from the relay to the destination). After each probing, if the second-hop channel is good enough, the relay transmits to the destination and completes the transmission process of the source; otherwise, the relay decides either to give up and let all sources start a new contention, or to continue to probe the second-hop channel. The optimal decision strategies for the two hops are derived in this letter. The first-hop strategy is a pure-threshold strategy, i.e., when the first-hop channel signal-to-noise ratio (SNR) is more than a threshold, the winner source should transmit to the relay, and subsequently the second-hop strategy should let the relay keep probing the second-hop channel until a good enough second-hop channel is observed. Simulation results show that our scheme is beneficial when the second-hop channels have larger average SNR.", "subjects": "Information Theory (cs.IT)", "authors": "Zhou Zhang, Shuai Zhou, Hai Jiang,", "date": "2015-2-21"}, 
{"urllink": "http://arxiv.org/abs/1502.06084", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06084", "title": "\nA Privacy-Preserving QoS Prediction Framework for Web Service  Recommendation", "abstract": "QoS-based Web service recommendation has recently gained much attention for providing a promising way to help users find high-quality services. To facilitate such recommendations, existing studies suggest the use of collaborative filtering techniques for personalized QoS prediction. These approaches, by leveraging partially observed QoS values from users, can achieve high accuracy of QoS predictions on the unobserved ones. However, the requirement to collect users' QoS data likely puts user privacy at risk, thus making them unwilling to contribute their usage data to a Web service recommender system. As a result, privacy becomes a critical challenge in developing practical Web service recommender systems. In this paper, we make the first attempt to cope with the privacy concerns for Web service recommendation. Specifically, we propose a simple yet effective privacy-preserving framework by applying data obfuscation techniques, and further extend two representative privacy-preserving QoS prediction approaches based on this framework. Evaluation results from a publicly-available QoS dataset of real-world Web services demonstrate the feasibility and effectiveness of our privacy-preserving QoS prediction approaches. We believe our work can serve as a good starting point to inspire more research efforts on privacy-preserving Web service recommendation.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Jieming Zhu, Pinjia He, Zibin Zheng, Michael R. Lyu,", "date": "2015-2-21"}, 
{"urllink": "http://arxiv.org/abs/1502.06081", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06081", "title": "\nStudy of a Robust Algorithm Applied in the Optimal Position Tuning for  the Camera Lens in Automated Visual Inspection Systems", "abstract": "This paper present the mathematical fundaments and experimental study of an algorithm used to find the optimal position for the camera lens to obtain a maximum of details. This information can be further applied to a appropriate system to automatically correct this position. The algorithm is based on the evaluation of a so called resolution function who calculates the maximum of gradient in a certain zone of the image. The paper also presents alternative forms of the function, results of measurements and set up a set of practical rules for the right application of the algorithm.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Radu Arsinte,", "date": "2015-2-21"}, 
{"urllink": "http://arxiv.org/abs/1502.06080", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06080", "title": "\nIntra-and-Inter-Constraint-based Video Enhancement based on Piecewise  Tone Mapping", "abstract": "Video enhancement plays an important role in various video applications. In this paper, we propose a new intra-and-inter-constraint-based video enhancement approach aiming to 1) achieve high intra-frame quality of the entire picture where multiple region-of-interests (ROIs) can be adaptively and simultaneously enhanced, and 2) guarantee the inter-frame quality consistencies among video frames. We first analyze features from different ROIs and create a piecewise tone mapping curve for the entire frame such that the intra-frame quality of a frame can be enhanced. We further introduce new inter-frame constraints to improve the temporal quality consistency. Experimental results show that the proposed algorithm obviously outperforms the state-of-the-art algorithms.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Yuanzhe Chen, Weiyao Lin, Chongyang Zhang, Zhenzhong Chen, Ning Xu, Jun Xie,", "date": "2015-2-21"}, 
{"urllink": "http://arxiv.org/abs/1502.06079", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06079", "title": "\nFinding Pairwise Intersections Inside a Query Range", "abstract": "We study the following problem: preprocess a set O of objects into a data structure that allows us to efficiently report all pairs of objects from O that intersect inside an axis-aligned query range Q. We present data structures of size and with query time time, where k is the number of reported pairs, for two classes of objects in the plane: axis-aligned rectangles and objects with small union complexity. For the 3-dimensional case where the objects and the query range are axis-aligned boxes in R^3, we present a data structures of size and query time . When the objects and query are fat, we obtain query time using storage.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Mark de Berg, Joachim Gudmundsson, Ali D. Mehrabi,", "date": "2015-2-21"}, 
{"urllink": "http://arxiv.org/abs/1502.06078", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06078", "title": "\nEvaluating QoS Parameters for IPTV Distribution in Heterogeneous  Networks", "abstract": "The present work presents an architecture developed to evaluate the QoS parameters for the IPTV heterogeneous network. At its very basic level lie two software technologies: Video LAN and Windows Media Services with two operating systems: Windows and Linux. Three types of streams are analyzed, which will be transmitted to a Linux VLC client through means of the aggregation and access servers. The first stream is generated in real time by a capture camera, processed by the encapsulated VC-1 encoder and sent to the Media Server, while the second one is of VoD(Video on Demand) type and the third one will be handled by DVBViewer through the MPEG TS form. The first stream is transcoded in H.264-AAC such that the Linux stations will recognize its format. Through the simultaneous transmission of the three streams, we are analyzing their performance from a QoS parameters point of view by means of an application implemented in C programming language. The stream transporting the DVB-S television content was proven to ensure the best performance regarding loss of packets, delays and jitter.", "subjects": "Multimedia (cs.MM)", "authors": "Ioan Sorin Comsa, Radu Arsinte,", "date": "2015-2-21"}, 
{"urllink": "http://arxiv.org/abs/1502.06076", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06076", "title": "\nA Heat-Map-based Algorithm for Recognizing Group Activities in Videos", "abstract": "In this paper, a new heat-map-based (HMB) algorithm is proposed for group activity recognition. The proposed algorithm first models human trajectories as series of \"heat sources\" and then applies a thermal diffusion process to create a heat map (HM) for representing the group activities. Based on this heat map, a new key-point based (KPB) method is used for handling the alignments among heat maps with different scales and rotations. And a surface-fitting (SF) method is also proposed for recognizing group activities. Our proposed HM feature can efficiently embed the temporal motion information of the group activities while the proposed KPB and SF methods can effectively utilize the characteristics of the heat map for activity recognition. Experimental results demonstrate the effectiveness of our proposed algorithms.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Weiyao Lin, Hang Chu, Jianxin Wu, Bin Sheng, Zhenzhong Chen,", "date": "2015-2-21"}, 
{"urllink": "http://arxiv.org/abs/1502.06075", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06075", "title": "\nA new network-based algorithm for human activity recognition in video", "abstract": "In this paper, a new network-transmission-based (NTB) algorithm is proposed for human activity recognition in videos. The proposed NTB algorithm models the entire scene as an error-free network. In this network, each node corresponds to a patch of the scene and each edge represents the activity correlation between the corresponding patches. Based on this network, we further model people in the scene as packages while human activities can be modeled as the process of package transmission in the network. By analyzing these specific \"package transmission\" processes, various activities can be effectively detected. The implementation of our NTB algorithm into abnormal activity detection and group activity recognition are described in detail in the paper. Experimental results demonstrate the effectiveness of our proposed algorithm.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Weiyao Lin, Yuanzhe Chen, Jianxin Wu, Hanli Wang, Bin Sheng, Hongxiang Li,", "date": "2015-2-21"}, 
{"urllink": "http://arxiv.org/abs/1502.06073", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06073", "title": "\nStudy on Sparse Representation based Classification for Biometric  Verification", "abstract": "In this paper, we propose a multimodal verification system integrating face and ear based on sparse representation based classification (SRC). The face and ear query samples are first encoded separately to derive sparsity-based match scores, and which are then combined with sum-rule fusion for verification. Apart from validating the encouraging performance of SRC-based multimodal verification, this paper also dedicates to provide a clear understanding about the characteristics of SRC-based biometric verification. To this end, two sparsity-based metrics, i.e. spare coding error (SCE) and sparse contribution rate (SCR), are involved, together with face and ear unimodal SRC-based verification. As for the issue that SRC-based biometric verification may suffer from heavy computational burden and verification accuracy degradation with increase of enrolled subjects, we argue that it could be properly resolved by exploiting small random dictionary for sparsity-based score computation, which consists of training samples from a limited number of randomly selected subjects. Experimental results demonstrate the superiority of SRC-based multimodal verification compared to the state-of-the-art multimodal methods like likelihood ratio (LLR), support vector machine (SVM), and the sum-rule fusion methods using cosine similarity, meanwhile the idea of using small random dictionary is feasible in both effectiveness and efficiency.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Zengxi Huang, Yiguang Liu, Xiaoming Wang, Jinrong Hu,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.06062", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06062", "title": "\nMulti-level Loop-less Algorithm for Multi-set Permutations", "abstract": "We present an algorithm that generates multiset permutations in O(1) time for each permutation, that is, by a loop-less algorithm with O(n) extra memory requirement. There already exist several such algorithms that generate multiset permutations in various orders. For multiset permutations, we combine two loop-less algorithms that are designed in the same principle of tree traversal. Our order of generation is different from any existing order, and the algorithm is simpler and faster than the previous ones. We also apply the new algorithm to parking functions.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Tadao Takaoka,", "date": "2015-2-21"}, 
{"urllink": "http://arxiv.org/abs/1502.06030", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06030", "title": "\nDecentralized Control of Partially Observable Markov Decision Processes  using Belief Space Macro-actions", "abstract": "The focus of this paper is on solving multi-robot planning problems in continuous spaces with partial observability. Decentralized partially observable Markov decision processes (Dec-POMDPs) are general models for multi-robot coordination problems, but representing and solving Dec-POMDPs is often intractable for large problems. To allow for a high-level representation that is natural for multi-robot problems and scalable to large discrete and continuous problems, this paper extends the Dec-POMDP model to the decentralized partially observable semi-Markov decision process (Dec-POSMDP). The Dec-POSMDP formulation allows asynchronous decision-making by the robots, which is crucial in multi-robot domains. We also present an algorithm for solving this Dec-POSMDP which is much more scalable than previous methods since it can incorporate closed-loop belief space macro-actions in planning. These macro-actions are automatically constructed to produce robust solutions. The proposed method's performance is evaluated on a complex multi-robot package delivery problem under uncertainty, showing that our approach can naturally represent multi-robot problems and provide high-quality solutions for large-scale problems.", "subjects": "Multiagent Systems (cs.MA)", "authors": "Shayegan Omidshafiei, Ali-akbar Agha-mohammadi, Christopher Amato, Jonathan P. How,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.06029", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06029", "title": "\nAchieving Autonomous Compressive Spectrum Sensing for Cognitive Radios", "abstract": "Compressive sensing (CS) technologies present many advantages over other existing approaches for implementing wideband spectrum sensing in cognitive radios (CRs), such as reduced sampling rate and computational complexity. However, there are two significant challenges: 1) choosing an appropriate number of sub-Nyquist measurements, and 2) deciding when to terminate the greedy recovery algorithm that reconstructs wideband spectrum. In this paper, an autonomous compressive spectrum sensing (ACSS) framework is presented that enables a CR to automatically choose the number of measurements while guaranteeing the wideband spectrum recovery with a small predictable recovery error. This is realized by the proposed measurement infrastructure and the validation technique. The proposed ACSS can find a good spectral estimate with high confidence by using only a small testing subset in both noiseless and noisy environments. Furthermore, a sparsity-aware spectral recovery algorithm is proposed to recover the wideband spectrum without requiring knowledge of the instantaneous spectral sparsity level. Such an algorithm bridges the gap between CS theory and practical spectrum sensing. Simulation results show that ACSS can not only recover the spectrum using an appropriate number of measurements, but can also considerably improve the spectral recovery performance compared with existing CS approaches. The proposed recovery algorithm can autonomously adopt a proper number of iterations, therefore solving the problems of under-fitting or over-fitting which commonly exist in most greedy recovery algorithms.", "subjects": "Information Theory (cs.IT)", "authors": "Jing Jiang, Hongjian Sun, David Baglee, H. Vincent Poor,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.06007", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.06007", "title": "\nDegrees of Freedom and Secrecy in Wireless Relay Networks", "abstract": "We translate the problem of designing a secure communications protocol for several users communicating through a relay in a wireless network into understanding certain subvarieties of products of Grassmannians. We calculate the dimension of these subvarieties and provide various results concerning their defning equations. When the relay and all of the users have the same number of antennas, this approach places fundamental limits on the amount of data that can be passed through such a network.", "subjects": "Information Theory (cs.IT)", "authors": "Arsenia Chorti, Ragnar Freij, David Karpuk,", "date": "2014-12-12"}, 
{"urllink": "http://arxiv.org/abs/1502.05988", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05988", "title": "\nDeep Learning for Multi-label Classification", "abstract": "In multi-label classification, the main focus has been to develop ways of learning the underlying dependencies between labels, and to take advantage of this at classification time. Developing better feature-space representations has been predominantly employed to reduce complexity, e.g., by eliminating non-helpful feature attributes from the input space prior to (or during) training. This is an important task, since many multi-label methods typically create many different copies or views of the same input data as they transform it, and considerable memory can be saved by taking advantage of redundancy. In this paper, we show that a proper development of the feature space can make labels less interdependent and easier to model and predict at inference time. For this task we use a deep learning approach with restricted Boltzmann machines. We present a deep network that, in an empirical evaluation, outperforms a number of competitive methods from the literature", "subjects": "Learning (cs.LG)", "authors": "Jesse Read, Fernando Perez-Cruz,", "date": "2014-12-17"}, 
{"urllink": "http://arxiv.org/abs/1502.05983", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05983", "title": "\nSorting Networks: The Final Countdown", "abstract": "In this paper we extend the knowledge on the problem of empirically searching for sorting networks of minimal depth. We present new search space pruning techniques for the last four levels of a candidate sorting network by considering only the output set representation of a network. We present an algorithm for checking whether an -input sorting network of depth exists by considering the minimal up to permutation and reflection itemsets at each level and using the pruning at the last four levels. We experimentally evaluated this algorithm to find the optimal depth sorting networks for all .", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Martin Marinov, David Gregg,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05980", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05980", "title": "\nCompressive Sensing Reconstruction for Sparse 2D Data", "abstract": "In this paper we study the compressive sensing effects on 2D signals exhibiting sparsity in 2D DFT domain. A simple algorithm for reconstruction of randomly under-sampled data is proposed. It is based on the analytically determined threshold that precisely separates signal and non-signal components in the 2D DFT domain. The proposed solution shows promising results in ISAR imaging, where the reconstruction is achieved even in the case when less than 10% of data is available.", "subjects": "Information Theory (cs.IT)", "authors": "Srdjan Stankovic, Irena Orovic,", "date": "2014-12-21"}, 
{"urllink": "http://arxiv.org/abs/1502.05968", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05968", "title": "\nScheduling Storms and Streams in the Cloud", "abstract": "Motivated by emerging big streaming data processing paradigms (e.g., Twitter Storm, Streaming MapReduce), we investigate the problem of scheduling graphs over a large cluster of servers. Each graph is a job, where nodes represent compute tasks and edges indicate data-flows between these compute tasks. Jobs (graphs) arrive randomly over time, and upon completion, leave the system. When a job arrives, the scheduler needs to partition the graph and distribute it over the servers to satisfy load balancing and cost considerations. Specifically, neighboring compute tasks in the graph that are mapped to different servers incur load on the network; thus a mapping of the jobs among the servers incurs a cost that is proportional to the number of \"broken edges\". We propose a low complexity randomized scheduling algorithm that, without service preemptions, stabilizes the system with graph arrivals/departures; more importantly, it allows a smooth trade-off between minimizing average partitioning cost and average queue lengths. Interestingly, to avoid service preemptions, our approach does not rely on a Gibbs sampler; instead, we show that the corresponding limiting invariant measure has an interpretation stemming from a loss system.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Javad Ghaderi, Sanjay Shakkottai, R Srikant,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05957", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05957", "title": "\nWeb Similarity", "abstract": "Normalized web distance (NWD) is a similarity or normalized semantic distance based on the World Wide Web or any other large electronic database, for instance Wikipedia, and a search engine that returns reliable aggregate page counts. For sets of search terms the NWD gives a similarity on a scale from 0 (identical) to 1 (completely different). The NWD approximates the similarity according to all (upper semi)computable properties. We develop the theory and give applications. The derivation of the NWD method is based on Kolmogorov complexity.", "subjects": "Information Retrieval (cs.IR)", "authors": "Andrew R. Cohen, Paul M.B. Vitanyi,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05955", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05955", "title": "\nStream Sampling for Frequency Cap Statistics", "abstract": "Unaggregated data streams are prevalent and come from diverse application domains which include interactions of users with web services and IP traffic. The elements of the stream have (cookies, users, queries) and elements with different keys interleave in the stream. Analytics on such data typically utilizes statistics stated in terms of the frequencies of keys. The two most common statistics are , which is the number of active keys in a specified segment, and , which is the sum of the frequencies of keys in the segment. These are two special cases of statistics, defined as the sum of frequencies by a parameter , which are popular in online advertising platforms. We propose a novel general framework for sampling unaggregated streams which provides the first effective stream sampling solution for general frequency cap statistics. Our -capped samples provide estimates with tight statistical guarantees for cap statistics with and nonnegative unbiased estimates of monotone non-decreasing frequency statistics. Our algorithms and estimators are simple and practical and we demonstrate their effectiveness using extensive simulations. An added benefit of our unified design is facilitating , which provide estimates with statistical guarantees for a specified set of different statistics, using a single, smaller sample.", "subjects": "Information Retrieval (cs.IR)", "authors": "Edith Cohen,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05947", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05947", "title": "\nFunctorial Data Migration: From Theory to Practice", "abstract": "In this paper we describe a functorial data migration scenario about the manufacturing service capability of a distributed supply chain. The scenario is a category-theoretic analog of an OWL ontology-based semantic enrichment scenario developed at the National Institute of Standards and Technology (NIST). The scenario is presented using, and is included with, the open-source FQL tool, available for download at categoricaldata.net/fql.html.", "subjects": "Databases (cs.DB)", "authors": "Ryan Wisnesky, David I. Spivak, Patrick Schultz, Eswaran Subrahmanian,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05943", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05943", "title": "\nRefining Adverse Drug Reactions using Association Rule Mining for  Electronic Healthcare Data", "abstract": "Side effects of prescribed medications are a common occurrence. Electronic healthcare databases present the opportunity to identify new side effects efficiently but currently the methods are limited due to confounding (i.e. when an association between two variables is identified due to them both being associated to a third variable). In this paper we propose a proof of concept method that learns common associations and uses this knowledge to automatically refine side effect signals (i.e. exposure-outcome associations) by removing instances of the exposure-outcome associations that are caused by confounding. This leaves the signal instances that are most likely to correspond to true side effect occurrences. We then calculate a novel measure termed the confounding-adjusted risk value, a more accurate absolute risk value of a patient experiencing the outcome within 60 days of the exposure. Tentative results suggest that the method works. For the four signals (i.e. exposure-outcome associations) investigated we are able to correctly filter the majority of exposure-outcome instances that were unlikely to correspond to true side effects. The method is likely to improve when tuning the association rule mining parameters for specific health outcomes. This paper shows that it may be possible to filter signals at a patient level based on association rules learned from considering patients' medical histories. However, additional work is required to develop a way to automate the tuning of the method's parameters.", "subjects": "Databases (cs.DB)", "authors": "Jenna M. Reps, Uwe Aickelin, Jiangang Ma, Yanchun Zhang,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05938", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05938", "title": "\nIncorporating Spontaneous Reporting System Data to Aid Causal Inference  in Longitudinal Healthcare Data", "abstract": "Inferring causality using longitudinal observational databases is challenging due to the passive way the data are collected. The majority of associations found within longitudinal observational data are often non-causal and occur due to confounding. The focus of this paper is to investigate incorporating information from additional databases to complement the longitudinal observational database analysis. We investigate the detection of prescription drug side effects as this is an example of a causal relationship. In previous work a framework was proposed for detecting side effects only using longitudinal data. In this paper we combine a measure of association derived from mining a spontaneous reporting system database to previously proposed analysis that extracts domain expertise features for causal analysis of a UK general practice longitudinal database. The results show that there is a significant improvement to the performance of detecting prescription drug side effects when the longitudinal observation data analysis is complemented by incorporating additional drug safety sources into the framework. The area under the receiver operating characteristic curve (AUC) for correctly classifying a side effect when other data were considered was 0.967, whereas without it the AUC was 0.923 However, the results of this paper may be biased by the evaluation and future work should overcome this by developing an unbiased reference set.", "subjects": "Computational Engineering, Finance, and Science (cs.CE)", "authors": "Jenna Reps, Uwe Aickelin,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05934", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05934", "title": "\nAchieving All with No Parameters: Adaptive NormalHedge", "abstract": "We study the classic online learning problem of predicting with expert advice, and propose a truly parameter-free and adaptive algorithm that achieves several objectives simultaneously without using any prior information. The main component of this work is an improved version of the NormalHedge.DT algorithm (Luo and Schapire, 2014), called AdaNormalHedge. On one hand, this new algorithm ensures small regret when the competitor has small loss and almost constant regret when the losses are stochastic. On the other hand, the algorithm is able to compete with any convex combination of the experts simultaneously, with a regret in terms of the relative entropy of the prior and the competitor. This resolves an open problem proposed by Chaudhuri et al. (2009) and Chernov and Vovk (2010). Moreover, we extend the results to the sleeping expert setting and provide two applications to illustrate the power of AdaNormalHedge: 1) competing with time-varying unknown competitors and 2) predicting almost as well as the best pruning tree. Our results on these applications significantly improve previous work from different aspects, and a special case of the first application resolves another open problem proposed by Warmuth and Koolen (2014) on whether one can simultaneously achieve optimal shifting regret for both adversarial and stochastic losses.", "subjects": "Learning (cs.LG)", "authors": "Haipeng Luo, Robert E. Schapire,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05931", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05931", "title": "\nImproved Model for Wire-Length Estimation in Stochastic Wiring  Distribution", "abstract": "This paper presents a pair of improved stochastic wiring distribution model for better estimation of on-chip wire lengths. The proposed models provide 28 - 50% reduction in error when estimating the average on-chip wire length compared to the estimation using the existing models. The impact of Rent's exponent on the average wire length estimation is also investigated to demonstrate limitations of the approximations used in some of the current models. To improve the approximations of the model a new threshold for Rent's constant is recommended. Simulation results demonstrate that proposed models with the new threshold reduce the error of estimation by 38 to 75 percent compared to the previous works.", "subjects": "Other Computer Science (cs.OH)", "authors": "Mohamed S. Hefeida, Masud H. Chowdhury,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05928", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05928", "title": "\nSupervised Dictionary Learning and Sparse Representation-A Review", "abstract": "Dictionary learning and sparse representation (DLSR) is a recent and successful mathematical model for data representation that achieves state-of-the-art performance in various fields such as pattern recognition, machine learning, computer vision, and medical imaging. The original formulation for DLSR is based on the minimization of the reconstruction error between the original signal and its sparse representation in the space of the learned dictionary. Although this formulation is optimal for solving problems such as denoising, inpainting, and coding, it may not lead to optimal solution in classification tasks, where the ultimate goal is to make the learned dictionary and corresponding sparse representation as discriminative as possible. This motivated the emergence of a new category of techniques, which is appropriately called supervised dictionary learning and sparse representation (S-DLSR), leading to more optimal dictionary and sparse representation in classification tasks. Despite many research efforts for S-DLSR, the literature lacks a comprehensive view of these techniques, their connections, advantages and shortcomings. In this paper, we address this gap and provide a review of the recently proposed algorithms for S-DLSR. We first present a taxonomy of these algorithms into six categories based on the approach taken to include label information into the learning of the dictionary and/or sparse representation. For each category, we draw connections between the algorithms in this category and present a unified framework for them. We then provide guidelines for applied researchers on how to represent and learn the building blocks of an S-DLSR solution based on the problem at hand. This review provides a broad, yet deep, view of the state-of-the-art methods for S-DLSR and allows for the advancement of research and development in this emerging area of research.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Mehrdad J. Gangeh, Ahmed K. Farahat, Ali Ghodsi, Mohamed S. Kamel,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05912", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05912", "title": "\nLimitations of Algebraic Approaches to Graph Isomorphism Testing", "abstract": "We investigate the power of graph isomorphism algorithms based on algebraic reasoning techniques like Gr \"obner basis computation. The idea of these algorithms is to encode two graphs into a system of equations that are satisfiable if and only if if the graphs are isomorphic, and then to (try to) decide satisfiability of the system using, for example, the Gr \"obner basis algorithm. In some cases this can be done in polynomial time, in particular, if the equations admit a bounded degree refutation in an algebraic proof systems such as Nullstellensatz or polynomial calculus. We prove linear lower bounds on the polynomial calculus degree over all fields of characteristic different from 2 and also linear lower bounds for the degree of Positivstellensatz calculus derivations. We compare this approach to recently studied linear and semidefinite programming approaches to isomorphism testing, which are known to be related to the combinatorial Weisfeiler-Lehman algorithm. We exactly characterise the power of the Weisfeiler-Lehman algorithm in terms of an algebraic proof system that lies between degree-k Nullstellensatz and degree-k polynomial calculus.", "subjects": "Computational Complexity (cs.CC)", "authors": "Christoph Berkholz, Martin Grohe,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05911", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05911", "title": "\nA Data Mining framework to model Consumer Indebtedness with  Psychological Factors", "abstract": "Modelling Consumer Indebtedness has proven to be a problem of complex nature. In this work we utilise Data Mining techniques and methods to explore the multifaceted aspect of Consumer Indebtedness by examining the contribution of Psychological Factors, like Impulsivity to the analysis of Consumer Debt. Our results confirm the beneficial impact of Psychological Factors in modelling Consumer Indebtedness and suggest a new approach in analysing Consumer Debt, that would take into consideration more Psychological characteristics of consumers and adopt techniques and practices from Data Mining.", "subjects": "Learning (cs.LG)", "authors": "Alexandros Ladas, Eamonn Ferguson, Uwe Aickelin, Jon Garibaldi,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05910", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05910", "title": "\nFixed-parameter Tractable Distances to Sparse Graph Classes", "abstract": "We show that for various classes C of sparse graphs, and several measures of distance to such classes (such as edit distance and elimination distance), the problem of determining the distance of a given graph G to C is fixed-parameter tractable. The results are based on two general techniques. The first of these, building on recent work of Grohe et al. establishes that any class of graphs that is slicewise nowhere dense and slicewise first-order definable is FPT. The second shows that determining the elimination distance of a graph G to a minor-closed class C is FPT.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Jannis Bulian, Anuj Dawar,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05908", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05908", "title": "\nLearning Descriptors for Object Recognition and 3D Pose Estimation", "abstract": "Detecting poorly textured objects and estimating their 3D pose reliably is still a very challenging problem. We introduce a simple but powerful approach to computing descriptors for object views that efficiently capture both the object identity and 3D pose. By contrast with previous manifold-based approaches, we can rely on the Euclidean distance to evaluate the similarity between descriptors, and therefore use scalable Nearest Neighbor search methods to efficiently handle a large number of objects under a large range of poses. To achieve this, we train a Convolutional Neural Network to compute these descriptors by enforcing simple similarity and dissimilarity constraints between the descriptors. We show that our constraints nicely untangle the images from different objects and different views into clusters that are not only well-separated but also structured as the corresponding sets of poses: The Euclidean distance between descriptors is large when the descriptors are from different objects, and directly related to the distance between the poses when the descriptors are from the same object. These important properties allow us to outperform state-of-the-art object views representations on challenging RGB and RGB-D data.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Paul Wohlhart, Vincent Lepetit,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05888", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05888", "title": "\nMajority-preserving judgment aggregation rules", "abstract": "The literature on judgment aggregation has now been moving from studying impossibility results regarding aggregation rules towards studying specific judgment aggregation rules. Here we focus on a family of rules that is the natural counterpart of the family of Condorcet-consistent voting rules: majority-preserving judgment aggregation rules. A judgment aggregation rule is majority-preserving if whenever issue-wise majority is consistent, the rule should output the majoritarian opinion on each issue. We provide a formal setting for relating judgment aggregation rules to voting rules and propose some basic properties for judgment aggregation rules. We consider six such rules some of which have already appeared in the literature, some others are new. For these rules we consider their relation to known voting rules, to each other, with respect to their discriminating power, and analyse them with respect to the considered properties.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Jer\u00f4me Lang, Gabriella Pigozzi, Marija Slavkovik, Leendert van der Torre, Srdjan Vesic,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05886", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05886", "title": "\nOn predictability of rare events leveraging social media: a machine  learning perspective", "abstract": "Information extracted from social media streams has been leveraged to forecast the outcome of a large number of real-world events, from political elections to stock market fluctuations. An increasing amount of studies demonstrates how the analysis of social media conversations provides cheap access to the wisdom of the crowd. However, extents and contexts in which such forecasting power can be effectively leveraged are still unverified at least in a systematic way. It is also unclear how social-media-based predictions compare to those based on alternative information sources. To address these issues, here we develop a machine learning framework that leverages social media streams to automatically identify and predict the outcomes of soccer matches. We focus in particular on matches in which at least one of the possible outcomes is deemed as highly unlikely by professional bookmakers. We argue that sport events offer a systematic approach for testing the predictive power of social media, and allow to compare such power against the rigorous baselines set by external sources. Despite such strict baselines, our framework yields above 8% marginal profit when used to inform simple betting strategies. The system is based on real-time sentiment analysis and exploits data collected immediately before the games, allowing for informed bets. We discuss the rationale behind our approach, describe the learning framework, its prediction performance and the return it provides as compared to a set of betting strategies. To test our framework we use both historical Twitter data from the 2014 FIFA World Cup games, and real-time Twitter data collected by monitoring the conversations about all soccer matches of four major European tournaments (FA Premier League, Serie A, La Liga, and Bundesliga), and the 2014 UEFA Champions League, during the period between Oct. 25th 2014 and Nov. 26th 2014.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Lei Le, Emilio Ferrara, Alessandro Flammini,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05881", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05881", "title": "\nOrthogonal Multilevel Spreading Sequence Design", "abstract": "Finite field transforms are offered as a new tool of spreading sequence design. This approach exploits orthogonality properties of synchronous non-binary sequences defined over a complex finite field. It is promising for channels supporting a high signal-to-noise ratio. New digital multiplex schemes based on such sequences have also been introduced, which are multilevel Code Division Multiplex. These schemes termed Galois-field Division Multiplex (GDM) are based on transforms for which there exists fast algorithms. They are also convenient from the hardware viewpoint since they can be implemented by a Digital Signal Processor. A new Efficient-bandwidth code-division-multiple-access (CDMA) is introduced, which is based on multilevel spread spectrum sequences over a Galois field. The primary advantage of such schemes regarding classical multiple access digital schemes is their better spectral efficiency. Galois-Fourier transforms contain some redundancy and only cyclotomic coefficients are needed to be transmitted yielding compact spectrum requirements.", "subjects": "Information Theory (cs.IT)", "authors": "H.M. de Oliveira, R.M. Campello de Souza,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05880", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05880", "title": "\nA Flexible Implementation of a Matrix Laurent Series-Based 16-Point Fast  Fourier and Hartley Transforms", "abstract": "This paper describes a flexible architecture for implementing a new fast computation of the discrete Fourier and Hartley transforms, which is based on a matrix Laurent series. The device calculates the transforms based on a single bit selection operator. The hardware structure and synthesis are presented, which handled a 16-point fast transform in 65 nsec, with a Xilinx SPARTAN 3E device.", "subjects": "Numerical Analysis (cs.NA)", "authors": "R.C. de Oliveira, H.M. de Oliveira, R.M. Campello de Souza, E.J.P. Santos,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05879", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05879", "title": "\nWavelet Analysis as an Information Processing Technique", "abstract": "A new interpretation for the wavelet analysis is reported, which can is viewed as an information processing technique. It was recently proposed that every basic wavelet could be associated with a proper probability density, allowing defining the entropy of a wavelet. Introducing now the concept of wavelet mutual information between a signal and an analysing wavelet fulfils the foundations of a wavelet information theory (WIT). Both continuous and discrete time signals are considered. Finally, we showed how to compute the information provided by a multiresolution analysis by means of the inhomogeneous wavelet expansion. Highlighting ideas behind the WIT are presented.", "subjects": "Information Theory (cs.IT)", "authors": "H.M. de Oliveira, D.F. de Souza,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05871", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05871", "title": "\nRobust CS reconstruction based on appropriate minimization norm", "abstract": "Noise robust compressive sensing algorithm is considered. This algorithm allows an efficient signal reconstruction in the presence of different types of noise due to the possibility to change minimization norm. For instance, the commonly used l1 and l2 norms, provide good results in case of Laplace and Gaussian noise. However, when the signal is corrupted by Cauchy or Cubic Gaussian noise, these norms fail to provide accurate reconstruction. Therefore, in order to achieve accurate reconstruction, the application of l3 minimization norm is analyzed. The efficiency of algorithm will be demonstrated on examples.", "subjects": "Information Theory (cs.IT)", "authors": "Maja Lakicevic, Mitar Moracanin, Nadja Djerkovic,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05864", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05864", "title": "\nPseudo Fuzzy Set", "abstract": "Here a novel idea to handle imprecise or vague set viz. Pseudo fuzzy set has been proposed. Pseudo fuzzy set is a triplet of element and its two membership functions. Both the membership functions may or may not be dependent. The hypothesis is that every positive sense has some negative sense. So, one membership function has been considered as positive and another as negative. Considering this concept, here the development of Pseudo fuzzy set and its property along with Pseudo fuzzy numbers has been discussed.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Sukanta Nayak, Snehashish Chakraverty,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05844", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05844", "title": "\nAn Approach For Transforming of Relational Databases to OWL Ontology", "abstract": "Rapid growth of documents, web pages, and other types of text content is a huge challenge for the modern content management systems. One of the problems in the areas of information storage and retrieval is the lacking of semantic data. Ontologies can present knowledge in sharable and repeatedly usable manner and provide an effective way to reduce the data volume overhead by encoding the structure of a particular domain. Metadata in relational databases can be used to extract ontology from database in a special domain. According to solve the problem of sharing and reusing of data, approaches based on transforming relational database to ontology are proposed. In this paper we propose a method for automatic ontology construction based on relational database. Mining and obtaining further components from relational database leads to obtain knowledge with high semantic power and more expressiveness. Triggers are one of the database components which could be transformed to the ontology model and increase the amount of power and expressiveness of knowledge by presenting part of the knowledge dynamically", "subjects": "Databases (cs.DB)", "authors": "Mona Dadjoo, Esmaeil Kheirkhah,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05840", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05840", "title": "\nA General Multi-Graph Matching Approach via Graduated  Consistency-regularized Boosting", "abstract": "This paper addresses the problem of matching weighted graphs referring to an identical object or category. More specifically, matching the common node correspondences among graphs. This multi-graph matching problem involves two ingredients affecting the overall accuracy: i) the local pairwise matching affinity score among graphs; ii) the global matching consistency that measures the uniqueness of the pairwise matching results by different chaining orders. Previous studies typically either enforce the matching consistency constraints in the beginning of iterative optimization, which may propagate matching error both over iterations and across graph pairs; or separate affinity optimizing and consistency regularization in two steps. This paper is motivated by the observation that matching consistency can serve as a regularizer in the affinity objective function when the function is biased due to noises or inappropriate modeling. We propose multi-graph matching methods to incorporate the two aspects by boosting the affinity score, meanwhile gradually infusing the consistency as a regularizer. Furthermore, we propose a node-wise consistency/affinity-driven mechanism to elicit the common inlier nodes out of the irrelevant outliers. Extensive results on both synthetic and public image datasets demonstrate the competency of the proposed algorithms.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Junchi Yan, Minsu Cho, Hongyuan Zha, Xiaokang Yang, Stephen Chu,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05838", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05838", "title": "\nAutomated Reasoning for Robot Ethics", "abstract": "Deontic logic is a very well researched branch of mathematical logic and philosophy. Various kinds of deontic logics are considered for different application domains like argumentation theory, legal reasoning, and acts in multi-agent systems. In this paper, we show how standard deontic logic can be used to model ethical codes for multi-agent systems. Furthermore we show how Hyper, a high performance theorem prover, can be used to prove properties of these ethical codes.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Ulrich Furbach, Claudia Schon, Frieder Stolzenburg,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05834", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05834", "title": "\nBimodal logics with a `weakly connected' component without the finite  model property", "abstract": "There are two known general results on the finite model property (fmp) of commutators [L,L'] (bimodal logics with commuting and confluent modalities). If L is finitely axiomatisable by modal formulas having universal Horn first-order correspondents, then both [L,K] and [L,S5] are determined by classes of frames that admit filtration, and so have the fmp. On the negative side, if both L and L' are determined by transitive frames and have frames of arbitrarily large depth, then [L,L'] does not have the fmp. In this paper we show that commutators with a `weakly connected' component often lack the fmp. Our results imply that the above positive result does not generalise to universally axiomatisable component logics, and even commutators without `transitive' components such as [K.3,K] can lack the fmp. We also generalise the above negative result to cases where one of the component logics has frames of depth one only, such as [S4.3,S5] and the decidable product logic S4.3xS5. We also show cases when already half of commutativity is enough to force infinite frames.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Agi Kurucz,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05832", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05832", "title": "\nA provably convergent alternating minimization method for mean field  inference", "abstract": "Mean-Field is an efficient way to approximate a posterior distribution in complex graphical models and constitutes the most popular class of Bayesian variational approximation methods. In most applications, the mean field distribution parameters are computed using an alternate coordinate minimization. However, the convergence properties of this algorithm remain unclear. In this paper, we show how, by adding an appropriate penalization term, we can guarantee convergence to a critical point, while keeping a closed form update at each step. A convergence rate estimate can also be derived based on recent results in non-convex optimization.", "subjects": "Learning (cs.LG)", "authors": "Pierre Baqu\u00e9, Jean-Hubert Hours, Fran\u00e7ois Fleuret, Pascal Fua,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05831", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05831", "title": "\nXFT: Practical fault tolerance beyond crashes", "abstract": "Despite 30+ years of intensive research, the distributed computing community still does not have a practical answer to non-crash faults of the machines that comprise a distributed system. In particular, Byzantine fault-tolerance (BFT), that promises to handle such faults, has not lived to expectations due to its resource and operation overhead with respect to its crash fault-tolerant(CFT) counterparts. This overhead comes from the worst-case assumption about Byzantine faults, in the sense that some coordinated adversarial activity controls the faulty machines and the entire network at will. To practitioners, however, such strong attacks appear irrelevant. In this paper, we introduce XFT ( cross fault tolerance\"), a novel approach to building reliable distributed systems, that decouples the fault space across the machine and network faults dimensions, treating machine faults and network asynchrony separately. This is in sharp contrast to the existing CFT and BFT models that discern system faults only along the machine fault dimension. XFT offers much more flexibility than traditional synchronous and asynchronous models that (too strictly) fix the network fault model of interest regardless of the machine faults. As the showcase for XFT, we present Paxos++: the first state machine replication protocol in the XFT model. Paxos++ tolerates faults beyond crashes in an efficient and practical way, featuring many more nines of reliability than the celebrated crash-tolerant Paxos protocol, without impacting its resource/operation costs while maintaining the same performance (common-case communication complexity among replicas). Surprisingly, Paxos++ sometimes (depending on the system environment) even offers strictly stronger reliability guarantees than state-of-the-art BFT replication protocols.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Shengyun Liu, Christian Cachin, Vivien Qu\u00e9ma, Marko Vukoli\u0107,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05828", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05828", "title": "\nTime-Approximation Trade-offs for Inapproximable Problems", "abstract": "In this paper we focus on problems which do not admit a constant-factor approximation in polynomial time and explore how quickly their approximability improves as the allowed running time is gradually increased from polynomial to (sub-)exponential. We tackle a number of problems: For Min Independent Dominating Set, Max Induced Path, Forest and Tree, for any , a simple, known scheme gives an approximation ratio of in time roughly . We show that, for most values of , if this running time could be significantly improved the ETH would fail. For Max Minimal Vertex Cover we give a non-trivial -approximation in time . We match this with a similarly tight result. We also give a -approximation for Min ATSP in time and an -approximation for Max Grundy Coloring in time . Furthermore, we show that Min Set Cover exhibits a curious behavior in this super-polynomial setting: for any it admits an -approximation, where is the number of sets, in just quasi-polynomial time. We observe that if such ratios could be achieved in polynomial time, the ETH or the Projection Games Conjecture would fail.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "\u00c9douard Bonnet, Michael Lampis, Vangelis Th. Paschos,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05825", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05825", "title": "\nSelf-Inverse Functions and Palindromic Circuits", "abstract": "We investigate the subclass of reversible functions that are self-inverse and relate them to reversible circuits that are equal to their reverse circuit, which are called palindromic circuits. We precisely determine which self-inverse functions can be realized as a palindromic circuit. For those functions that cannot be realized as a palindromic circuit, we find alternative palindromic representations that require an extra circuit line or quantum gates in their construction. Our analyses make use of involutions in the symmetric group which are isomorphic to self-inverse reversible function on variables.", "subjects": "Emerging Technologies (cs.ET)", "authors": "Mathias Soeken, Michael Kirkedal Thomsen, Gerhard W. Dueck, D. Michael Miller,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05818", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05818", "title": "\nCo-Primary Multi-Operator Resource Sharing for Small Cell Networks", "abstract": "To tackle the challenge of providing higher data rates within limited spectral resources we consider the case of multiple operators sharing a common pool of radio resources. Four algorithms are proposed to address co-primary multi-operator radio resource sharing under heterogeneous traffic in both centralized and distributed scenarios. The performance of these algorithms is assessed through extensive system-level simulations for two indoor small cell layouts. It is assumed that the spectral allocations of the small cells are orthogonal to the macro network layer and thus, only the small cell traffic is modeled. The main performance metrics are user throughput and the relative amount of shared spectral resources. The numerical results demonstrate the importance of coordination among co-primary operators for an optimal resource sharing. Also, maximizing the spectrum sharing percentage generally improves the achievable throughput gains over non-sharing.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Petri Luoto, Pekka Pirinen, Mehdi Bennis, Sumudu Samarakoon, Simon Scott, Matti Latva-aho,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05817", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05817", "title": "\nA Hybrid Model to Extend Vehicular Intercommunication V2V through D2D  Architecture", "abstract": "In the recent years, many solutions for Vehicle to Vehicle (V2V) communication were proposed to overcome failure problems (also known as dead ends). This paper proposes a novel framework for V2V failure recovery using Device-to-Device (D2D) communications. Based on the unified Intelligent Transportation Systems (ITS) architecture, LTE-based D2D mechanisms can improve V2V dead ends failure recovery delays. This new paradigm of hybrid V2V-D2D communications overcomes the limitations of traditional V2V routing techniques. According to NS2 simulation results, the proposed hybrid model decreases the end to end delay (E2E) of messages delivery. A complete comparison of different D2D use cases (best &amp; worst scenarios) is presented to show the enhancements brought by our solution compared to traditional V2V techniques.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Emad Abd-Elrahman, Adel Mounir Said, Thouraya Toukabri, Hossam Afifi, Michel Marot,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05808", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05808", "title": "\nMatrix Codes as Ideals for Grassmannian Codes and their Weight  Properties", "abstract": "A systematic way of constructing Grassmannian codes endowed with the subspace distance as lifts of matrix codes over the prime field is introduced. The matrix codes are -subspaces of the ring of matrices over on which the rank metric is applied, and are generated as one-sided proper principal ideals by idempotent elements of . Furthermore a weight function on the non-commutative matrix ring , a power of , is studied in terms of the egalitarian and homogeneous conditions. The rank weight distribution of is completely determined by the general linear group . Finally a weight function on subspace codes is analogously defined and its egalitarian property is examined.", "subjects": "Information Theory (cs.IT)", "authors": "Bryan Hernandez, Virgilio Sison,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05807", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05807", "title": "\nNoise-shaping Quantization Methods for Frame-based and Compressive  Sampling Systems", "abstract": "Noise shaping refers to an analog-to-digital conversion methodology in which quantization error is arranged to lie mostly outside the signal spectrum by means of oversampling and feedback. Recently it has been successfully applied to more general redundant linear sampling and reconstruction systems associated with frames as well as non-linear systems associated with compressive sampling. This chapter reviews some of the recent progress in this subject.", "subjects": "Information Theory (cs.IT)", "authors": "Evan Chou, C. Sinan G\u00fcnt\u00fcrk, Felix Krahmer, Rayan Saab, \u00d6zg\u00fcr Y\u0131lmaz,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05803", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05803", "title": "\nVisual object tracking performance measures revisited", "abstract": "The problem of visual tracking evaluation is sporting a large variety of performance measures, and largely suffers from lack of consensus about which measures should be used in experiments. This makes the cross-paper tracker comparison difficult. Furthermore, as some measures may be less effective than others, the tracking results may be skewed or biased towards particular tracking aspects. In this paper we revisit the popular performance measures and tracker performance visualizations and analyze them theoretically and experimentally. We show that several measures are equivalent from the point of information they provide for tracker comparison and, crucially, that some are more brittle than the others. Based on our analysis we narrow down the set of potential measures to only two complementary ones, describing accuracy and robustness, thus pushing towards homogenization of the tracker evaluation methodology. These two measures can be intuitively interpreted and visualized and have been employed by the recent Visual Object Tracking (VOT) challenges as the foundation for the evaluation methodology.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Luka \u010cehovin, Ale\u0161 Leonardis, Matej Kristan,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05789", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05789", "title": "\nLocation Identification of Power Line Outages Using PMU Measurements  with Bad Data", "abstract": "The use of phasor angle measurements provided by phasor measurement units (PMUs) in fault detection is regarded as a promising method in identifying locations of power line outages. However, communication errors or system malfunctions may introduce errors to the measurements and thus yield bad data. Most of the existing methods on line outage identification fail to consider such error. This paper develops a framework for identifying multiple power line outages based on the PMUs' measurements in the presence of bad data. In particular, we design an algorithm to identify locations of line outage and recover the faulty measurements simultaneously. The proposed algorithm does not require any prior information on the number of line outages and the noise variance. Case studies carried out on test systems of different sizes validate the effectiveness and efficiency of the proposed approach.", "subjects": "Systems and Control (cs.SY)", "authors": "Wen-Tai Li, Chao-Kai Wen, Jung-Chieh Chen, Kai-Kit Wong, Jen-Hao Teng, Chau Yuen,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05786", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05786", "title": "\nRandomized Assignment of Jobs to Servers in Heterogeneous Clusters of  Shared Servers for Low Delay", "abstract": "We consider the job assignment problem in a multi-server system consisting of parallel processor sharing servers, categorized into () different types according to their processing capacity or speed. Jobs of random sizes arrive at the system according to a Poisson process with rate . Upon each arrival, a small number of servers from each type is sampled uniformly at random. The job is then assigned to one of the sampled servers based on a selection rule. We propose two schemes, each corresponding to a specific selection rule that aims at reducing the mean sojourn time of jobs in the system. We first show that both methods achieve the maximal stability region. We then analyze the system operating under the proposed schemes as which corresponds to the mean field. Our results show that asymptotic independence among servers holds even when is finite and exchangeability holds only within servers of the same type. We further establish the existence and uniqueness of stationary solution of the mean field and show that the tail distribution of server occupancy decays doubly exponentially for each server type. When the estimates of arrival rates are not available, the proposed schemes offer simpler alternatives to achieving lower mean sojourn time of jobs, as shown by our numerical studies.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Arpan Mukhopadhyay, A. Karthik, Ravi R. Mazumdar,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05784", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05784", "title": "\nLDPC Code Design for Noncoherent Physical Layer Network Coding", "abstract": "This work considers optimizing LDPC codes in the physical-layer network coded two-way relay channel using noncoherent FSK modulation. The error-rate performance of channel decoding at the relay node during the multiple-access phase was improved through EXIT-based optimization of Tanner graph variable node degree distributions. Codes drawn from the DVB-S2 and WiMAX standards were used as a basis for design and performance comparison. The computational complexity characteristics of the standard codes were preserved in the optimized codes by maintaining the extended irregular repeat-accumulate (eIRA). The relay receiver performance was optimized considering two modulation orders M = using iterative decoding in which the decoder and demodulator refine channel estimates by exchanging information. The code optimization procedure yielded unique optimized codes for each case of modulation order and available channel state information. Performance of the standard and optimized codes were measured using Monte Carlo simulation in the flat Rayleigh fading channel, and error rate improvements up to 1.2 dB are demonstrated depending on system parameters.", "subjects": "Information Theory (cs.IT)", "authors": "Terry Ferrett, Matthew C. Valenti,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05782", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05782", "title": "\nImpact of Metro Cell Antenna Pattern and Downtilt in Heterogeneous  Networks", "abstract": "This article discusses the positive impact metro cell antennas with narrow vertical beamwidth and electrical downtilt can have on heterogeneous cellular networks. Using a model of random cell placement based on Poisson distribution, along with an innovative 3D building model that quantifies blockage due to shadowing, it is demonstrated that network spectral efficiency and average user throughput both increase as vertical beamwidth is decreased and downtilt is applied to metro cell transmission. Moreover, the network becomes more energy efficient. Importantly, these additional gains in network performance can be achieved without any cooperation or exchange of information between macro cell base stations and metro cells.", "subjects": "Information Theory (cs.IT)", "authors": "Xiao Li, Robert W. Heath Jr., Kevin Linehan, Ray Butler,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05777", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05777", "title": "\nSpike Event Based Learning in Neural Networks", "abstract": "A scheme is derived for learning connectivity in spiking neural networks. The scheme learns instantaneous firing rates that are conditional on the activity in other parts of the network. The scheme is independent of the choice of neuron dynamics or activation function, and network architecture. It involves two simple, online, local learning rules that are applied only in response to occurrences of spike events. This scheme provides a direct method for transferring ideas between the fields of deep learning and computational neuroscience. This learning scheme is demonstrated using a layered feedforward spiking neural network trained self-supervised on a prediction and classification task for moving MNIST images collected using a Dynamic Vision Sensor.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "James A. Henderson, TingTing A. Gibson, Janet Wiles,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05775", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05775", "title": "\nCommon Information Duality in Relation to Bounds on the Secret Key Rate", "abstract": "We explore the duality between the simulation and extraction of secret common randomness in light of a similar well-known operational duality between the two notions of common information due to Wyner, and G 'acs and K \"rner. For the inverse problem of simulating a tripartite noisy correlation from a noiseless secret key and unlimited public communication, we show that Winter's (2005) single-letter result for the secret key cost of formation can be simply reexpressed in terms of the existence of a bipartite protocol monotone. For the forward problem of key distillation from noisy correlations without public discussion, we show that for a class of decomposable distributions, the conditional G 'acs and K \"rner common information achieves a tight bound on the secret key rate.", "subjects": "Information Theory (cs.IT)", "authors": "Pradeep Kr. Banerjee,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05774", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05774", "title": "\nActively Purchasing Data for Learning", "abstract": "We design mechanisms for online procurement of data held by strategic agents for machine learning tasks. The challenge is to use past data to actively price future data and give learning guarantees even when an agent's cost for revealing her data may depend arbitrarily on the data itself. We achieve this goal by showing how to convert a large class of no-regret algorithms into online posted-price and learning mechanisms. Our results in a sense parallel classic sample complexity guarantees, but with the key resource being money rather than quantity of data: With a budget constraint , we give robust risk (predictive error) bounds on the order of . Because we use an active approach, we can often guarantee to do significantly better by leveraging correlations between costs and data. Our algorithms and analysis go through a model of no-regret learning with arriving pairs (cost, data) and a budget constraint of . Our regret bounds for this model are on the order of and we give lower bounds on the same order.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Jacob Abernethy, Yiling Chen, Chien-Ju Ho, Bo Waggoner,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05773", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05773", "title": "\nMultipartite Monotones for Secure Sampling by Public Discussion From  Noisy Correlations", "abstract": "We address the problem of quantifying the cryptographic content of probability distributions, in relation to an application to secure multi-party sampling against a passive t-adversary. We generalize a recently introduced notion of assisted common information of a pair of correlated sources to that of K sources and define a family of monotone rate regions indexed by K. This allows for a simple characterization of all t-private distributions that can be statistically securely sampled without any auxiliary setup of pre-shared noisy correlations. We also give a new monotone called the residual total correlation that admits a simple operational interpretation. Interestingly, for sampling with non-trivial setups (K &gt; 2) in the public discussion model, our definition of a monotone region differs from the one by Prabhakaran and Prabhakaran (ITW 2012).", "subjects": "Information Theory (cs.IT)", "authors": "Pradeep Kr. Banerjee,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05767", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05767", "title": "\nAutomatic differentiation in machine learning: a survey", "abstract": "Derivatives, mostly in the form of gradients and Hessians, are ubiquitous in machine learning. Automatic differentiation (AD) is a technique for calculating derivatives efficiently and accurately, established in fields such as computational fluid dynamics, nuclear engineering, and atmospheric sciences. Despite its advantages and use in other fields, machine learning practitioners have been little influenced by AD and make scant use of available tools. We survey the intersection of AD and machine learning, cover applications where AD has the potential to make a big impact, and report on the recent developments in the adoption this technique. We also aim to dispel some misconceptions that we think have impeded the widespread awareness of AD within the machine learning community.", "subjects": "Symbolic Computation (cs.SC)", "authors": "Atilim Gunes Baydin, Barak A. Pearlmutter, Alexey Andreyevich Radul,", "date": "2015-2-20"}, 
{"urllink": "http://arxiv.org/abs/1502.05752", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05752", "title": "\nPairwise Constraint Propagation: A Survey", "abstract": "As one of the most important types of (weaker) supervised information in machine learning and pattern recognition, pairwise constraint, which specifies whether a pair of data points occur together, has recently received significant attention, especially the problem of pairwise constraint propagation. At least two reasons account for this trend: the first is that compared to the data label, pairwise constraints are more general and easily to collect, and the second is that since the available pairwise constraints are usually limited, the constraint propagation problem is thus important. This paper provides an up-to-date critical survey of pairwise constraint propagation research. There are two underlying motivations for us to write this survey paper: the first is to provide an up-to-date review of the existing literature, and the second is to offer some insights into the studies of pairwise constraint propagation. To provide a comprehensive survey, we not only categorize existing propagation techniques but also present detailed descriptions of representative methods within each category.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Zhenyong Fu, Zhiwu Lu,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05751", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05751", "title": "\nEfficient Synthesis of Room Acoustics via Scattering Delay Networks", "abstract": "An acoustic reverberator consisting of a network of delay lines connected via scattering junctions is proposed. All parameters of the reverberator are derived from physical properties of the enclosure it simulates. It allows for simulation of unequal and frequency-dependent wall absorption, as well as directional sources and microphones. The reverberator renders the first-order reflections exactly, while making progressively coarser approximations of higher-order reflections. The rate of energy decay is close to that obtained with the image method (IM) and consistent with the predictions of Sabine and Eyring equations. The time evolution of the normalized echo density, which was previously shown to be correlated with the perceived texture of reverberation, is also close to that of IM. However, its computational complexity is one to two orders of magnitude lower, comparable to the computational complexity of a feedback delay network (FDN), and its memory requirements are negligible.", "subjects": "Sound (cs.SD)", "authors": "Enzo De Sena, Huseyin Hacihabiboglu, Zoran Cvetkovic, Julius O. Smith III,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05748", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05748", "title": "\nApplying Fuzzy Logic to the Design, Verification and Analysis of Binary  Hardware Circuits", "abstract": "We present a novel approach for digital hardware simulation based on many-valued (fuzzy) logic (MVL). Binary designs can be automatically transformed into MVL designs, and simulations performed in the more informative MVL setting may reveal details which are either invisible or hard to detect through binary simulations. Two circuits which are supposed to be binary equivalent may behave differently under MVL simulations, and analyzing these differences may lead to the discovery of a genuine binary nonequivalence, or in some cases, to a qualitative gap between the designs. By performing an MVL simulation, a combinational design becomes a union of trajectories, where each trajectory starts at some input variable and all the nodes along the trajectory are of the same degree of veracity or falsehood. With sequential synchronous designs one can incorporate temporal data into the simulation, so that the state of the design at a given time reports besides the degree of truth of each variable also the place and date of birth of its value. Applications include equivalence verification, initialization, assertions generation and verification, stuck-at-values, partial control on the flow of data by prioritizing, block-oriented simulations. Some procedures and general directions towards achieving these goals are presented.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Amnon Rosenmann,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05746", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05746", "title": "\nBinary Embedding: Fundamental Limits and Fast Algorithm", "abstract": "Binary embedding is a nonlinear dimension reduction methodology where high dimensional data are embedded into the Hamming cube while preserving the structure of the original space. Specifically, for an arbitrary distinct points in , our goal is to encode each point using -dimensional binary strings such that we can reconstruct their geodesic distance up to uniform distortion. Existing binary embedding algorithms either lack theoretical guarantees or suffer from running time . We make three contributions: (1) we establish a lower bound that shows any binary embedding oblivious to the set of points requires bits and a similar lower bound for non-oblivious embeddings into Hamming distance; (2) we propose a novel fast binary embedding algorithm with provably optimal bit complexity and near linear running time whenever , with a slightly worse running time for larger ; (3) we also provide an analytic result about embedding a general set of points with even infinite size. Our theoretical findings are supported through experiments on both synthetic and real data sets.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Xinyang Yi, Constantine Caramanis, Eric Price,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05745", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05745", "title": "\nPolylogarithmic-Time Leader Election in Population Protocols Using  Polylogarithmic States", "abstract": "Population protocols are networks of finite-state agents, interacting randomly, and updating their states using simple rules. Despite their extreme simplicity, these systems have been shown to cooperatively perform complex computational tasks, such as simulating register machines to compute standard arithmetic functions. The election of a unique leader agent is a key requirement in such computational constructions. Yet, the fastest currently known population protocol for electing a leader only has linear convergence time, and, it has recently been shown that no population protocol using a constant number of states per node may overcome this linear bound. In this paper, we give the first population protocol for leader election with polylogarithmic convergence time, using polylogarithmic memory states per node. The protocol structure is quite simple: each node has an associated value, and is either a leader (still in contention) or a minion (following some leader). A leader keeps incrementing its value and \"defeats\" other leaders in one-to-one interactions, and will drop from contention and become a minion if it meets a leader with higher value. Importantly, a leader also drops out if it meets a minion with higher absolute value. While these rules are quite simple, the proof that this algorithm achieves polylogarithmic convergence time is non-trivial. In particular, the argument combines careful use of concentration inequalities with anti-concentration bounds, showing that the leaders' values become spread apart as the execution progresses, which in turn implies that straggling leaders get quickly eliminated. We complement our analysis with empirical results, showing that our protocol converges extremely fast, even for large network sizes.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Dan Alistarh, Rati Gelashvili,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05744", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05744", "title": "\nScale-Free Algorithms for Online Linear Optimization", "abstract": "Online linear optimization problem models a situation where an algorithm repeatedly has to make a decision before it sees the loss function, which is a linear function of the decision. The performance of an algorithm is measured by the so-called regret, which is the difference between the cumulative loss of the algorithm and the cumulative loss of the best fixed decision in hindsight. We present algorithms for online linear optimization that are oblivious to the scaling of the losses. That is, the algorithms make the exactly the same sequence of decisions if the loss functions are scaled by an arbitrary positive constant. Consequence of the scale invariance is that the algorithms do not need to know an upper bound on the norm of the loss vectors as an input. The bound on algorithms' regret is within constant factor of the previously known optimal bound for the situation where the scaling is known. Coincidentally, the algorithms do not need to know the number of rounds and do not have any other tuning parameters.", "subjects": "Learning (cs.LG)", "authors": "Francesco Orabona, David Pal,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05742", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05742", "title": "\nApplication of Independent Component Analysis Techniques in Speckle  Noise Reduction of Single-Shot Retinal OCT Images", "abstract": "Optical Coherence Tomography (OCT) is an emerging technique in the field of biomedical imaging, with applications in ophthalmology, dermatology, coronary imaging etc. OCT images usually suffer from a granular pattern, called speckle noise, which restricts the process of interpretation. To the best of knowledge, use of Independent Component Analysis (ICA) techniques has never been explored for speckle reduction of OCT images. Here, a comparative study of several ICA techniques is provided for noise reduction of single-shot retinal OCT images. Having multiple B-scans of the same location, the eye movements are compensated using a rigid registration technique. Then, different ICA techniques are applied to the aggregated set of B-scans for extracting the noise-free image. Signal-to-Noise-Ratio (SNR), Contrast-to-Noise-Ratio (CNR) and Equivalent-Number-of-Looks (ENL), as well as analysis on the computational complexity of the methods, are considered as metrics for comparison. The results show that use of ICA can be beneficial, especially in case of having fewer number of B-scans.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Ahmadreza Baghaie, Roshan M. D'souza, Zeyun Yu,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05730", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05730", "title": "\nDesigning Applications with Distributed Databases in a Hybrid Cloud", "abstract": "Designing applications for use in a hybrid cloud has many features. These include dynamic virtualization management and an unknown route switching customers. This makes it impossible to evaluate the query and hence the optimal distribution of data. In this paper, we formulate the main challenges of designing and simulation offer installation for processing.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Evgeniy Pluzhnik, Oleg Lukyanchikov, Evgeny Nikulchev, Simon Payain,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05729", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05729", "title": "\nQuicksort, Largest Bucket, and Min-Wise Hashing with Limited  Independence", "abstract": "Randomized algorithms and data structures are often analyzed under the assumption of access to a perfect source of randomness. The most fundamental metric used to measure how \"random\" a hash function or a random number generator is, is its independence: a sequence of random variables is said to be -independent if every variable is uniform and every size subset is independent. In this paper we consider three classic algorithms under limited independence. We provide new bounds for randomized quicksort, min-wise hashing and largest bucket size under limited independence. Our results can be summarized as follows. -Randomized quicksort. When pivot elements are computed using a -independent hash function, Karloff and Raghavan, J.ACM'93 showed expected worst-case running time for a special version of quicksort. We improve upon this, showing that the same running time is achieved with only -independence. -Min-wise hashing. For a set , consider the probability of a particular element being mapped to the smallest hash value. It is known that -independence implies the optimal probability . Broder et al., STOC'98 showed that -independence implies it is . We show a matching lower bound as well as new tight bounds for - and -independent hash functions. -Largest bucket. We consider the case where balls are distributed to buckets using a -independent hash function and analyze the largest bucket size. Alon et. al, STOC'97 showed that there exists a -independent hash function implying a bucket of size . We generalize the bound, providing a -independent family of functions that imply size .", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Mathias B\u00e6k Tejs Knudsen, Morten St\u00f6ckel,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05701", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05701", "title": "\nInterpreting \"altmetrics\": viewing acts on social media through the lens  of citation and social theories", "abstract": "More than 30 years after Cronin's seminal paper on \"the need for a theory of citing\" (Cronin, 1981), the metrics community is once again in need of a new theory, this time one for so-called \"altmetrics\". Altmetrics, short for alternative (to citation) metrics -- and as such a misnomer -- refers to a new group of metrics based (largely) on social media events relating to scholarly communication. As current definitions of altmetrics are shaped and limited by active platforms, technical possibilities, and business models of aggregators such as Altmetric.com, ImpactStory, PLOS, and Plum Analytics, and as such constantly changing, this work refrains from defining an umbrella term for these very heterogeneous new metrics. Instead a framework is presented that describes acts leading to (online) events on which the metrics are based. These activities occur in the context of social media, such as discussing on Twitter or saving to Mendeley, as well as downloading and citing. The framework groups various types of acts into three categories -- accessing, appraising, and applying -- and provides examples of actions that lead to visibility and traceability online. To improve the understanding of the acts, which result in online events from which metrics are collected, select citation and social theories are used to interpret the phenomena being measured. Citation theories are used because the new metrics based on these events are supposed to replace or complement citations as indicators of impact. Social theories, on the other hand, are discussed because there is an inherent social aspect to the measurements.", "subjects": "Digital Libraries (cs.DL)", "authors": "Stefanie Haustein, Timothy D. Bowman, Rodrigo Costas,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05698", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05698", "title": "\nTowards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks", "abstract": "One long-term goal of machine learning research is to produce methods that are applicable to reasoning and natural language, in particular building an intelligent dialogue agent. To measure progress towards that goal, we argue for the usefulness of a set of proxy tasks that evaluate reading comprehension via question answering. Our tasks measure understanding in several ways: whether a system is able to answer questions via chaining facts, simple induction, deduction and many more. The tasks are designed to be prerequisites for any system that aims to be capable of conversing with a human. We believe many existing learning systems can currently not solve them, and hence our aim is to classify these tasks into skill sets, so that researchers can identify (and then rectify) the failings of their systems. We also extend and improve the recently introduced Memory Networks model, and show it is able to solve some, but not all, of the tasks.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.05696", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05696", "title": "\nApproval Voting and Incentives in Crowdsourcing", "abstract": "The growing need for labeled training data has made crowdsourcing an important part of machine learning. The quality of crowdsourced labels is, however, adversely affected by three factors: (1) the workers are not experts; (2) the incentives of the workers are not aligned with those of the requesters; and (3) the interface does not allow workers to convey their knowledge accurately, by forcing them to make a single choice among a set of options. In this paper, we address these issues by introducing approval voting to utilize the expertise of workers who have partial knowledge of the true answer, and coupling it with a (\"strictly proper\") incentive-compatible compensation mechanism. We show rigorous theoretical guarantees of optimality of our mechanism together with a simple axiomatic characterization. We also conduct empirical studies on Amazon Mechanical Turk which validate our approach.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Nihar B. Shah, Dengyong Zhou, Yuval Peres,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05689", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05689", "title": "\nUnsupervised Deep Network Pretraining via Human Design", "abstract": "Over the years, computer vision researchers have spent an immense amount of effort on designing image features for visual object recognition tasks. We propose to leverage this valuable experience to guide the task of training deep neural networks. Specifically, we propose a new unsupervised pretraining method for deep neural networks. Our idea is to pretrain the network through the task of replicating classic hand-designed features. By learning to replicate these features, the deep network integrates previous research knowledge and learns to model visual objects in a way similar to the hand-designed features. In the succeeding finetuning step, it further learns object-specific representations from labeled data and this boosts its classification power. We demonstrate the application of our method on the pedestrian detection task. We pretrain two deep convolutional neural networks where one replicates the histogram of oriented gradients feature, and the other replicates the region covariance feature. After finetuning, we achieve substantially better performance than those networks pretrained using existing methods.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Ming-Yu Liu, Arun Mallya, Oncel C. Tuzel, Xi Chen,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05678", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05678", "title": "\nVIP: Finding Important People in Images", "abstract": "People preserve memories of events such as birthday party, weddings, or vacations by capturing photos, often depicting groups of people. Invariably, some persons in the image are more important than others given the context of the event. This paper analyzes the concept of the importance of specific individuals in photos of multiple people. Two questions that have several practical applications are addressed -- Who are the most important person(s) in an image? And, given multiple images of a person, which one depicts the person in the most important role? We introduce an importance measure of people in images and investigate the correlation between importance and visual saliency. We find that not only can we automatically predict the importance of people from purely visual cues, incorporating this predicted importance results in significant improvement in applications such as im2text (generating sentences that describe images of groups of people).", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Clint Solomon Mathialagan, Andrew C. Gallagher, Dhruv Batra,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05676", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05676", "title": "\nJournal Portfolio Analysis for Countries, Cities, and Organizations:  Maps and Comparisons", "abstract": "Using Web-of-Science data, portfolio analysis in terms of journal coverage can be projected on a base map for units of analysis such as countries, cities, universities, and firms. The units of analysis under study can be compared statistically across the 10,000+ journals. The interdisciplinarity of the portfolios is measured using Rao-Stirling diversity or Zhang et al.'s (in press) improved measure 2D3. At the country level we find regional differentiation (e.g., Latin-American or Asian countries), but also a major divide between advanced and less-developed countries. Israel and Israeli cities outperform other nations and cities in terms of diversity. Universities appear to be specifically related to firms when a number of these units are exploratively compared. The instrument is relatively simple and straightforward, and one can generalize the application to any document set retrieved from WoS. Further instruction is provided online at this http URL", "subjects": "Digital Libraries (cs.DL)", "authors": "Loet Leydesdorff, Gaston Heimeriks, Daniele Rotolo,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.05675", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05675", "title": "\nNP-Hardness and Inapproximability of Sparse PCA", "abstract": "We give a reduction from to establish that sparse PCA is NP-hard. The reduction has a gap which we use to exclude an FPTAS for sparse PCA (unless P=NP). Under weaker complexity assumptions, we also exclude polynomial constant-factor approximation algorithms.", "subjects": "Learning (cs.LG)", "authors": "Malik Magdon-Ismail,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.05623", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05623", "title": "\nPlanar Linkages Following a Prescribed Motion", "abstract": "Designing mechanical devices, called linkages, that draw a given plane curve has been a topic that interested engineers and mathematicians for hundreds of years, and recently also computer scientists. Already in 1876, Kempe proposed a procedure for solving the problem in full generality, but his constructions tend to be extremely complicated. We provide a novel algorithm that produces much simpler linkages, but works only for parametric curves. Our approach is to transform the problem into a factorization task over some noncommutative algebra. We show how to compute such a factorization, and how to use it to construct a linkage tracing a given curve.", "subjects": "Symbolic Computation (cs.SC)", "authors": "Matteo Gallet, Christoph Koutschan, Zijia Li, Georg Regensburger, Josef Schicho, Nelly Villamizar,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05615", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05615", "title": "\nForgetting and consolidation for incremental and cumulative knowledge  acquisition systems", "abstract": "The application of cognitive mechanisms to support knowledge acquisition is, from our point of view, crucial for making the resulting models coherent, efficient, credible, easy to use and understandable. In particular, there are two characteristic features of intelligence that are essential for knowledge development: forgetting and consolidation. Both plays an important role in knowledge bases and learning systems to avoid possible information overflow and redundancy, and in order to preserve and strengthen important or frequently used rules and remove (or forget) useless ones. We present an incremental, long-life view of knowledge acquisition which tries to improve task after task by determining what to keep, what to consolidate and what to forget, overcoming The Stability-Plasticity dilemma. In order to do that, we rate rules by introducing several metrics through the first adaptation, to our knowledge, of the Minimum Message Length (MML) principle to a coverage graph, a hierarchical assessment structure which treats evidence and rules in a unified way. The metrics are not only used to forget some of the worst rules, but also to set a consolidation process to promote those selected rules to the knowledge base, which is also mirrored by a demotion system. We evaluate the framework with a series of tasks in a chess rule learning domain.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Fernando Mart\u00ednez-Plumed, C\u00e8sar Ferri, Jos\u00e9 Hern\u00e1ndez-Orallo, Mar\u00eda Jos\u00e9 Ram\u00edrez-Quintana,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05599", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05599", "title": "\nSpread of Influence in Weighted Networks under Time and Budget  Constraints", "abstract": "Given a network represented by a weighted directed graph G, we consider the problem of finding a bounded cost set of nodes S such that the influence spreading from S in G, within a given time bound, is as large as possible. The dynamic that governs the spread of influence is the following: initially only elements in S are influenced; subsequently at each round, the set of influenced elements is augmented by all nodes in the network that have a sufficiently large number of already influenced neighbors. We prove that the problem is NP-hard, even in simple networks like complete graphs and trees. We also derive a series of positive results. We present exact pseudo-polynomial time algorithms for general trees, that become polynomial time in case the trees are unweighted. This last result improves on previously published results. We also design polynomial time algorithms for general weighted paths and cycles, and for unweighted complete graphs.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Ferdinando Cicalese, Gennaro Cordasco, Luisa Gargano, Martin Milanic, Joseph Peters, Ugo Vaccaro,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.05597", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05597", "title": "\nOn Detection Issues in the SC-based Uplink of a MU-MIMO System with a  Large Number of BS Antennas", "abstract": "This paper deals with SC/FDE within a MU-MIMO system where a large number of BS antennas is adopted. In this context, either linear or reduced-complexity iterative DF detection techniques are considered. Regarding performance evaluation by simulation, appropriate semi-analytical methods are proposed. This paper includes a detailed evaluation of BER performances for uncoded 4-Quadrature Amplitude Modulation (4-QAM) schemes and a MU-MIMO channel with uncorrelated Rayleigh fading. The accuracy of performance results obtained through the semi-analytical simulation methods is assessed by means of parallel conventional Monte Carlo simulations, under the assumptions of perfect power control and perfect channel estimation. The performance results are discussed in detail, with the help of selected performance bounds. We emphasize that a moderately large number of BS antennas is enough to closely approximate the SIMO MFB performance, especially when using the suggested low-complexity iterative DF technique, which does not require matrix inversion operations. We also emphasize the achievable \"massive MIMO\" effects, even for strongly reduced-complexity linear detection techniques, provided that the number of BS antennas is much higher than the number of antennas which are jointly employed in the terminals of the multiple autonomous users.", "subjects": "Information Theory (cs.IT)", "authors": "Paulo Torres, Luis Charrua, Antonio Gusmao,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05591", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05591", "title": "\nRadial Fuzzy Systems", "abstract": "The class of radial fuzzy systems is introduced. The fuzzy systems in this class use radial functions to implement membership functions of fuzzy sets and exhibit a shape preservation property in antecedents of their rules. The property is called the radial property. It enables the radial fuzzy systems to have their computational model mathematically tractable under both conjunctive and implicative representations of their rule bases. Coherence of radial implicative fuzzy systems is discussed and a sufficient condition for coherence is stated.", "subjects": "Systems and Control (cs.SY)", "authors": "David Coufal,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05578", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05578", "title": "\nNetwork Geometry Inference using Common Neighbors", "abstract": "We introduce and explore a new method for inferring hidden geometric coordinates of nodes in complex networks based on the number of common neighbors between the nodes. We compare this approach to the one in [1], which is based on the connections (and disconnections) between the nodes, i.e., on the links that the nodes have (or do not have). We find that for high degree nodes the common-neighbors approach yields a more accurate inference than the link-based method, unless heuristic periodic adjustments (or \"correction steps\") are used in the latter. The common-neighbors approach is computationally intensive, requiring running time to map a network of nodes, versus in the link-based method. But we also develop a hybrid method with running time, which combines the common-neighbors and link-based approaches, and explore a heuristic that reduces its running time further to , without significant reduction in the mapping accuracy. We apply this method to the Autonomous Systems (AS) Internet, and reveal how soft communities of ASes evolve over time in the similarity space. We further demonstrate the method's predictive power by forecasting future links between ASes. Taken altogether, our results advance our understanding of how to efficiently and accurately map real networks to their latent geometric spaces, which is an important necessary step towards understanding the laws that govern the dynamics of nodes in these spaces, and the fine-grained dynamics of network connections.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Fragkiskos Papadopoulos, Dmitri Krioukov,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05565", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05565", "title": "\nMulti-valued Color Representation Based on Frank t-norm Properties", "abstract": "In this paper two knowledge representation models are proposed, FP4 and FP6. Both combine ideas from fuzzy sets and four-valued and hexa-valued logics. Both represent imprecise properties whose accomplished degree is unknown or contradictory for some objects. A possible application in the color analysis and color image processing is discussed.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Vasile Patrascu,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05562", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05562", "title": "\nA New Penta-valued Logic Based Knowledge Representation", "abstract": "In this paper a knowledge representation model are proposed, FP5, which combine the ideas from fuzzy sets and penta-valued logic. FP5 represents imprecise properties whose accomplished degree is undefined, contradictory or indeterminate for some objects. Basic operations of conjunction, disjunction and negation are introduced. Relations to other representation models like fuzzy sets, intuitionistic, paraconsistent and bipolar fuzzy sets are discussed.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Vasile Patrascu,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05561", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05561", "title": "\nPositive Inductive-Recursive Definitions", "abstract": "A new theory of data types which allows for the definition of types as initial algebras of certain functors Fam(C) -&gt; Fam(C) is presented. This theory, which we call positive inductive-recursive definitions, is a generalisation of Dybjer and Setzer's theory of inductive-recursive definitions within which C had to be discrete -- our work can therefore be seen as lifting this restriction. This is a substantial endeavour as we need to not only introduce a type of codes for such data types (as in Dybjer and Setzer's work), but also a type of morphisms between such codes (which was not needed in Dybjer and Setzer's development). We show how these codes are interpreted as functors on Fam(C) and how these morphisms of codes are interpreted as natural transformations between such functors. We then give an application of positive inductive-recursive definitions to the theory of nested data types and we give concrete examples of recursive functions defined on universes by using their elimination principle. Finally we justify the existence of positive inductive-recursive definitions by adapting Dybjer and Setzer's set-theoretic model to our setting.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Neil Ghani, Lorenzo Malatesta, Fredrik Nordvall Forsberg,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05558", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05558", "title": "\nIt's a Tough Nanoworld: in Tile Assembly, Cooperation is not (strictly)  more Powerful than Competition", "abstract": "We present a strict separation between the class of \"mismatch free\" self-assembly systems and general aTAM systems. Mismatch free systems are those systems in which concurrently grown parts must always agree with each other. Tile self-assembly is a model of the formation of crystal growth, in which a large number of particles concurrently and selectively stick to each other, forming complex shapes and structures. It is useful in nanotechnologies, and more generally in the understanding of these processes, ubiquitous in natural systems. The other property of the local assembly process known to change the power of the model is cooperation between two tiles to attach another. We show that disagreement (mismatches) and cooperation are incomparable: neither can be used to simulate the other one. The fact that mismatches are a hard property is especially surprising, since no known, explicit construction of a computational device in tile assembly uses mismatches, except for the recent construction of an intrinsically universal tileset, i.e. a tileset capable of simulating any other tileset up to rescaling. This work shows how to use intrinsic universality in a systematic way to highlight the essence of different features of tile assembly. Moreover, even the most recent experimental realizations do not use competition, which, in view of our results, suggests that a large part of the natural phenomena behind DNA self-assembly remains to be understood experimentally.", "subjects": "Computational Geometry (cs.CG)", "authors": "Florent Becker, Pierre-\u00c9tienne Meunier,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05552", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05552", "title": "\nComputing Real Numbers using DNA Self-Assembly", "abstract": "DNA Self-Assembly has emerged as an interdisciplinary field with many intriguing applications such DNA bio-sensor, DNA circuits, DNA storage, drug delivery etc. Tile assembly model of DNA has been studied for various computational primitives such as addition, subtraction, multiplication, and division. Xuncai et. al. gave computational DNA tiles to perform division of a number but the output had integer quotient. In this work, we simply modify their method of division to improve its compatibility with further computation and this modification has found its application in computing rational numbers, both recurring and terminating, with computational tile complexity of and respectively. Additionally, we also propose a method to compute square-root of a number with computational tile complexity of for an n bit number. Finally, after combining tiles of division and square-root, we propose a simple way to compute the ubiquitously used irrational number, , using its infinite series.", "subjects": "Emerging Technologies (cs.ET)", "authors": "Shalin Shah, Parth Dave, Manish K Gupta,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05551", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05551", "title": "\nPrivately Information Sharing with Delusive Paths for Data Forwarding in  Vehicular Networks", "abstract": "We discuss how to efficiently forward data in vehicular networks. Existing solutions do not make full use of trajectory planning of nearby vehicles, or social attributes. The development of onboard navigation system provides drivers some traveling route information. The main novelty of our approach is to envision sharing partial traveling information to the encountered vehicles for better service. Our data forwarding algorithm utilizes this lightweight information under the delusive paths privacy preservation together with the social community structure in vehicular networks. We assume that data transmission is carried by vehicles and road side units (RSUs), while cellular network manages and coordinates relevant global information. The approximate destination set is the set of RSUs that are often passed by the destination vehicle. RSU importance is raised by summing encounter ratios of RSUs in the same connected component. We first define a concept of space-time approachability which is derived from shared partial traveling route and encounter information. It describes the capability of a vehicle to advance messages toward destination. Then, we design a novel data forwarding algorithm, called approachability based algorithm, which combines the space-time approachability with the social community attribute in vehicular networks. We evaluate our approachability based algorithm on data sets from San Francisco Cabspotting and Shanghai Taxi Movement. Results show that the partially shared traveling information plays a positive role in data forwarding in vehicular networks. Approachability based data forwarding algorithm achieves a better performance than existing social based algorithms in vehicular networks.", "subjects": "Other Computer Science (cs.OH)", "authors": "Zhong Li, Cheng Wang, Lu Shao, Changjun Jiang,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05548", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05548", "title": "\nFacility location with double-peaked preference", "abstract": "We study the problem of locating a single facility on a real line based on the reports of self-interested agents, when agents have double-peaked preferences, with the peaks being on opposite sides of their locations. We observe that double-peaked preferences capture real-life scenarios and thus complement the well-studied notion of single-peaked preferences. We mainly focus on the case where peaks are equidistant from the agents' locations and discuss how our results extend to more general settings. We show that most of the results for single-peaked preferences do not directly apply to this setting; this makes the problem essentially more challenging. As our main contribution, we present a simple truthful-in-expectation mechanism that achieves an approximation ratio of 1+b/c for both the social and the maximum cost, where b is the distance of the agent from the peak and c is the minimum cost of an agent. For the latter case, we provide a 3/2 lower bound on the approximation ratio of any truthful-in-expectation mechanism. We also study deterministic mechanisms under some natural conditions, proving lower bounds and approximation guarantees. We prove that among a large class of reasonable mechanisms, there is no deterministic mechanism that outperforms our truthful-in-expectation mechanism.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Aris Filos-Ratsikas, Minming Li, Jie Zhang, Qiang Zhang,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05545", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05545", "title": "\nOn the power of one bit: How to explore a graph when you cannot  backtrack?", "abstract": "We consider the problem of exploration of an anonymous, port-labelled, undirected graph with nodes, edges, by a single mobile agent. Initially the agent does not know the topology of the graph nor any of the global parameters. Moreover, the agent does not know the incoming port when entering to a vertex thus it cannot backtrack its moves. We study a -agent model with two types of memory: bits of internal memory at the agent and bits of local memory at each node that is modifiable by the agent upon its visit to that node. In such a model, condition has to be satisfied at each node of degree for the agent to be able to traverse each edge of the graph. As our main result we show an algorithm for -agent exploring any graph with return in optimal time . We also show that exploration using -agent sometimes requires steps. On the other hand, any algorithm for -agent is a subject to known lower bounds for Universal Traversal Sequence thus requires steps in some graphs. We also observe that neither -agent nor -agent can stop after completing the task without the knowledge of some global parameter of the graph. This shows separation between the model with two types of memory and the models with only one in terms of exploration time and the stop property.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Artur Menc, Dominik Paj\u0105k, Przemys\u0142aw Uzna\u0144ski,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05543", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05543", "title": "\nPrioritized Metric Structures and Embedding", "abstract": "Metric data structures (distance oracles, distance labeling schemes, routing schemes) and low-distortion embeddings provide a powerful algorithmic methodology, which has been successfully applied for approximation algorithms cite, online algorithms cite, distributed algorithms cite and for computing sparsifiers cite. However, this methodology appears to have a limitation: the worst-case performance inherently depends on the cardinality of the metric, and one could not specify in advance which vertices/points should enjoy a better service (i.e., stretch/distortion, label size/dimension) than that given by the worst-case guarantee. In this paper we alleviate this limitation by devising a suit of metric data structures and embeddings. We show that given a priority ranking of the graph vertices (respectively, metric points) one can devise a metric data structure (respectively, embedding) in which the stretch (resp., distortion) incurred by any pair containing a vertex will depend on the rank of the vertex. We also show that other important parameters, such as the label size and (in some sense) the dimension, may depend only on . In some of our metric data structures (resp., embeddings) we achieve both prioritized stretch (resp., distortion) and label size (resp., dimension) . The worst-case performance of our metric data structures and embeddings is typically asymptotically no worse than of their non-prioritized counterparts.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Michael Elkin, Arnold Filtser, Ofer Neiman,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05535", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05535", "title": "\nEvolutionary algorithm based adaptive navigation in information  retrieval interfaces", "abstract": "In computer interfaces in general, especially in information retrieval tasks, it is important to be able to quickly find and retrieve information. State of the art approach, used, for example, in search engines, is not effective as it introduces losses of meanings due to context to keywords back and forth translation. Authors argue it increases the time and reduces the accuracy of information retrieval compared to what it could be in the system that employs modern information retrieval and text mining methods while presenting results in an adaptive human- computer interface where system effectively learns what operator needs through iterative interaction. In current work, a combination of adaptive navigational interface and real time collaborative feedback analysis for documents relevance weighting is proposed as an viable alternative to prevailing \"telegraphic\" approach in information retrieval systems. Adaptive navigation is provided through a dynamic links panel controlled by an evolutionary algorithm. Documents relevance is initially established with standard information retrieval techniques and is further refined in real time through interaction of users with the system. Introduced concepts of multidimensional Knowledge Map and Weighted Point of Interest allow finding relevant documents and users with common interests through a trivial calculation. Browsing search approach, the ability of the algorithm to adapt navigation to users interests, collaborative refinement and the self-organising features of the system are the main factors making such architecture effective in various fields where non-structured knowledge shall be represented to the users.", "subjects": "Information Retrieval (cs.IR)", "authors": "Dmytro Filatov, Taras Filatov,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05534", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05534", "title": "\nNeuroSVM: A Graphical User Interface for Identification of Liver  Patients", "abstract": "Diagnosis of liver infection at preliminary stage is important for better treatment. In todays scenario devices like sensors are used for detection of infections. Accurate classification techniques are required for automatic identification of disease samples. In this context, this study utilizes data mining approaches for classification of liver patients from healthy individuals. Four algorithms (Naive Bayes, Bagging, Random forest and SVM) were implemented for classification using R platform. Further to improve the accuracy of classification a hybrid NeuroSVM model was developed using SVM and feed-forward artificial neural network (ANN). The hybrid model was tested for its performance using statistical parameters like root mean square error (RMSE) and mean absolute percentage error (MAPE). The model resulted in a prediction accuracy of 98.83%. The results suggested that development of hybrid model improved the accuracy of prediction. To serve the medicinal community for prediction of liver disease among patients, a graphical user interface (GUI) has been developed using R. The GUI is deployed as a package in local repository of R platform for users to perform prediction.", "subjects": "Learning (cs.LG)", "authors": "Kalyan Nagaraj, Amulyashree Sridhar,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05533", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05533", "title": "\nGreatest Fixed Points of Probabilistic Min/Max Polynomial Equations, and  Reachability for Branching Markov Decision Processes", "abstract": "We give polynomial time algorithms for quantitative (and qualitative) reachability analysis for Branching Markov Decision Processes (BMDPs). Specifically, given a BMDP, and given an initial population, where the objective of the controller is to maximize (or minimize) the probability of eventually reaching a population that contains an object of a desired (or undesired) type, we give algorithms for approximating the supremum (infimum) reachability probability, within desired precision epsilon &gt; 0, in time polynomial in the encoding size of the BMDP and in log(1/epsilon). We furthermore give P-time algorithms for computing epsilon-optimal strategies for both maximization and minimization of reachability probabilities. We also give P-time algorithms for all associated qualitative analysis problems, namely: deciding whether the optimal (supremum or infimum) reachability probabilities are 0 or 1. Prior to this paper, approximation of optimal reachability probabilities for BMDPs was not even known to be decidable. Our algorithms exploit the following basic fact: we show that for any BMDP, its maximum (minimum) non-reachability probabilities are given by the greatest fixed point (GFP) solution g* in [0,1]^n of a corresponding monotone max (min) Probabilistic Polynomial System of equations (max/min-PPS), x=P(x), which are the Bellman optimality equations for a BMDP with non-reachability objectives. We show how to compute the GFP of max/min PPSs to desired precision in P-time.", "subjects": "Computational Complexity (cs.CC)", "authors": "Kousha Etessami, Alistair Stewart, Mihalis Yannakakis,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.05532", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05532", "title": "\nComparing Decision Support Approaches for Cyber Security Investment", "abstract": "When investing in cyber security resources, information security managers have to follow effective decision-making strategies. We refer to this as the cyber security investment challenge. In this paper, we consider three possible decision-support methodologies for security managers to tackle this challenge. We consider methods based on game theory, combinatorial optimisation and a hybrid of the two. Our modelling starts by building a framework where we can investigate the effectiveness of a cyber security control regarding the protection of different assets seen as targets in presence of commodity threats. In terms of game theory we consider a 2-person control game between the security manager who has to choose among different implementation levels of a cyber security control, and a commodity attacker who chooses among different targets to attack. The pure game theoretical methodology consists of a large game including all controls and all threats. In the hybrid methodology the game solutions of individual control-games along with their direct costs (e.g. financial) are combined with a knapsack algorithm to derive an optimal investment strategy. The combinatorial optimisation technique consists of a multi-objective multiple choice knapsack based strategy. We compare these approaches on a case study that was built on SANS top critical controls. The main achievements of this work is to highlight the weaknesses and strengths of different investment methodologies for cyber security, the benefit of their interaction, and the impact that indirect costs have on cyber security investment.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Andrew Fielder, Emmanouil Panaousis, Pasquale Malacaria, Chris Hankin, Fabrizio Smeraldi,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05516", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05516", "title": "\nOutage Capacity of Rayleigh Product Channels: a Free Probability  Approach", "abstract": "The Rayleigh product channel model is useful in capturing the performance degradation due to rank deficiency of MIMO channels. In this paper, such a performance degradation is investigated via the channel outage probability assuming slowly varying channel with delay-constrained decoding. Using techniques of free probability theory, the asymptotic variance of channel capacity is derived when the dimensions of the channel matrices approach infinity. In this asymptotic regime, the channel capacity is rigorously proven to be Gaussian distributed. Using the obtained results, a fundamental tradeoff between multiplexing gain and diversity gain of Rayleigh product channels can be characterized by closed-form expression at any finite signal-to-noise ratio. Numerical results are provided to compare the relative outage performance between Rayleigh product channels and conventional Rayleigh MIMO channels.", "subjects": "Information Theory (cs.IT)", "authors": "Zhong Zheng, Lu Wei, Roland Speicher, Ralf M\u00fcller, Jyri H\u00e4m\u00e4l\u00e4inen, Jukka Corander,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05507", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05507", "title": "\nOn asymptotically good ramp secret sharing schemes", "abstract": "Asymptotically good sequences of ramp secret sharing schemes have been intensively studied by Cramer et al. in [4, 5, 6, 7, 8, 9, 10, 11]. In those works the focus is on full privacy and full reconstruction. We propose an alternative definition of asymptotically good sequences of ramp secret sharing schemes where a small amount of information leakage is allowed (and possibly also non-full recovery). By a non-constructive proof we demonstrate the existence of sequences that - following our definition of goodness - have parameters arbitrary close to the optimal ones. Moreover - still using our definition - we demonstrate how to concretely construct asymptotically good sequences of schemes from sequences of algebraic geometric codes related to a tower of function fields. Our study involves a detailed treatment of the relative generalized Hamming weights of the involved codes.", "subjects": "Information Theory (cs.IT)", "authors": "Olav Geil, Stefano Martin, Umberto Mart\u00ednez-Pe\u00f1as, Ryutaroh Matsumoto, Diego Ruano,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.05501", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05501", "title": "\nNRCL - A Model Building Approach to the Bernays-Sch\u00f6nfinkel Fragment  (Full Paper)", "abstract": "We combine key ideas from first-order superposition and propositional CDCL to create the new calculus NRCL deciding the Bernays-Sch \"onfinkel fragment. It inherits the abstract redundancy criterion and the monotone model operator from superposition. CDCL adds to NRCL the dynamic, conflict-driven search for an atom ordering inducing a model. As a result, in NRCL a false clause can be effectively found modulo the current model assumption. It guides the derivation of a first-order ordered resolvent that is never redundant. Similar to 1UIP-learning in CDCL, the learned resolvent induces backtracking and via propagation blocks the previous conflict state for the rest of the search. Since learned clauses are never redundant, only finitely many can be generated by NRCL on the Bernays-Sch \"onfinkel fragment, which provides a nice argument for termination.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "G\u00e1bor Alagi, Christoph Weidenbach,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05491", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05491", "title": "\nOptimizing Text Quantifiers for Multivariate Loss Functions", "abstract": "We address the problem of emph, a supervised learning task whose goal is, given a class, to estimate the relative frequency (or emph) of the class in a dataset of unlabelled items. Quantification has several applications in data and text mining, such as estimating the prevalence of positive reviews in a set of reviews of a given product, or estimating the prevalence of a given support issue in a dataset of transcripts of phone calls to tech support. So far, quantification has been addressed by learning a general-purpose classifier, counting the unlabelled items which have been assigned the class, and tuning the obtained counts according to some heuristics. In this paper we depart from the tradition of using general-purpose classifiers, and use instead a supervised learning model for emph, capable of generating classifiers directly optimized for the (multivariate and non-linear) function used for evaluating quantification accuracy. The experiments that we have run on 5500 binary high-dimensional datasets (averaging more than 14,000 documents each) show that this method is more accurate, more stable, and more efficient than existing, state-of-the-art quantification methods.", "subjects": "Learning (cs.LG)", "authors": "Andrea Esuli, Fabrizio Sebastiani,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05487", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05487", "title": "\nPerformance Evaluation of netfilter: A Study on the Performance Loss  When Using netfilter as a Firewall", "abstract": "Since GNU/Linux became a popular operating system on computer network routers, its packet routing mechanisms attracted more interest. This does not only concern 'big' Linux servers acting as a router but more and more small and medium network access devices, such as DSL or cable access devices. Although there are a lot of documents dealing with high performance routing with GNU/Linux, only a few offer experimental results to prove the given advices. This study evaluates the throughput performance of Linux' routing subsystem netfilter under various conditions like different data transport protocols in combination with different IP address families and transmission strategies. Those conditions were evaluated with two different types of netfilter rules for a high number in the rule tables. In addition to this, our experiments allowed us to evaluate two prominent client connection handling techniques (threads and the epoll() facility). The evaluation of the 1.260 different combinations of our test parameters shows a nearly linear but small throughput loss with the number of rules which is independant from the transport protocol and framesize. However, this evaluation identifies another issue concerning the throughput loss when it comes to the address family, i.e. IPv4 and IPv6.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Raik Niemann, Udo Pfingst, Richard G\u00f6bel,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05484", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05484", "title": "\nRobust Adaptive Sparse Channel Estimation in the Presence of Impulsive  Noises", "abstract": "Broadband wireless channels usually have the sparse nature. Based on the assumption of Gaussian noise model, adaptive filtering algorithms for reconstruction sparse channels were proposed to take advantage of channel sparsity. However, impulsive noises are often existed in many advance broadband communications systems. These conventional algorithms are vulnerable to deteriorate due to interference of impulsive noise. In this paper, sign least mean square algorithm (SLMS) based robust sparse adaptive filtering algorithms are proposed for estimating channels as well as for mitigating impulsive noise. By using different sparsity-inducing penalty functions, i.e., zero-attracting (ZA), reweighted ZA (RZA), reweighted L1-norm (RL1) and Lp-norm (LP), the proposed SLMS algorithms are termed as SLMS-ZA, SLMS-RZA, LSMS-RL1 and SLMS-LP. Simulation results are given to validate the proposed algorithms.", "subjects": "Information Theory (cs.IT)", "authors": "Guan Gui, Li Xu, Wentao Ma, Badong Chen,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05477", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05477", "title": "\nTrust Region Policy Optimization", "abstract": "We propose a family of trust region policy optimization (TRPO) algorithms for learning control policies. We first develop a policy update scheme with guaranteed monotonic improvement, and then we describe a finite-sample approximation to this scheme that is practical for large-scale problems. In our experiments, we evaluate the method on two different and very challenging sets of tasks: learning simulated robotic swimming, hopping, and walking gaits, and playing Atari games using images of the screen as input. For these tasks, the policies are neural networks with tens of thousands of parameters, mapping from observations to actions.", "subjects": "Learning (cs.LG)", "authors": "John Schulman, Sergey Levine, Philipp Moritz, Michael I. Jordan, Pieter Abbeel,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05472", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05472", "title": "\nOn the Effects of Low-Quality Training Data on Information Extraction  from Clinical Reports", "abstract": "In the last five years there has been a flurry of work on information extraction from clinical documents, i.e., on algorithms capable of extracting, from the informal and unstructured texts that are generated during everyday clinical practice, mentions of concepts relevant to such practice. Most of this literature is about methods based on supervised learning, i.e., methods for training an information extraction system from manually annotated examples. While a lot of work has been devoted to devising learning methods that generate more and more accurate information extractors, no work has been devoted to investigating the effect of the quality of training data on the learning process. Low quality in training data often derives from the fact that the person who has annotated the data is different from the one against whose judgment the automatically annotated data must be evaluated. In this paper we test the impact of such data quality issues on the accuracy of information extraction systems as applied to the clinical domain. We do this by comparing the accuracy deriving from training data annotated by the authoritative coder (i.e., the one who has also annotated the test data, and by whose judgment we must abide), with the accuracy deriving from training data annotated by a different coder. The results indicate that, although the disagreement between the two coders (as measured on the training set) is substantial, the difference is (surprisingly enough) not always statistically significant.", "subjects": "Learning (cs.LG)", "authors": "Diego Marcheggiani, Fabrizio Sebastiani,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.05461", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05461", "title": "\nVisualizing Object Detection Features", "abstract": "We introduce algorithms to visualize feature spaces used by object detectors. Our method works by inverting a visual feature back to multiple natural images. We found that these visualizations allow us to analyze object detection systems in new ways and gain new insight into the detector's failures. For example, when we visualize the features for high scoring false alarms, we discovered that, although they are clearly wrong in image space, they do look deceptively similar to true positives in feature space. This result suggests that many of these false alarms are caused by our choice of feature space, and supports that creating a better learning algorithm or building bigger datasets is unlikely to correct these errors. By visualizing feature spaces, we can gain a more intuitive understanding of recognition systems.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Carl Vondrick, Aditya Khosla, Hamed Pirsiavash, Tomasz Malisiewicz, Antonio Torralba,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05450", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05450", "title": "\nThe (Final) countdown", "abstract": "The Countdown game is one of the oldest TV show running in the world. It started broadcasting in 1972 on the french television and in 1982 on British channel 4, and it has been running since in both countries. The game, while extremely popular, never received any serious scientific attention, probably because it seems too simple at first sight. We present in this article an in-depth analysis of the numbers round of the countdown game. This includes a complexity analysis of the game, an analysis of existing algorithms, the presentation of a new algorithm that increases resolution speed by a factor of 20. It also includes some leads on how to turn the game into a more difficult one, both for a human player and for a computer, and even to transform it into a probably undecidable problem.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Jean-Marc Alliot,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05448", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05448", "title": "\nDistributed Inference in the Presence of Eavesdroppers: A Survey", "abstract": "The distributed inference framework comprises of a group of spatially distributed nodes which acquire observations about a phenomenon of interest. Due to bandwidth and energy constraints, the nodes often quantize their observations into a finite-bit local message before sending it to the fusion center (FC). Based on the local summary statistics transmitted by nodes, the FC makes a global decision about the presence of the phenomenon of interest. The distributed and broadcast nature of such systems makes them quite vulnerable to different types of attacks. This paper addresses the problem of secure communication in the presence of eavesdroppers. In particular, we focus on efficient mitigation schemes to mitigate the impact of eavesdropping. We present an overview of the distributed inference schemes under secrecy constraints and describe the currently available approaches in the context of distributed detection and estimation followed by a discussion on avenues for future research.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Bhavya Kailkhura, V. Sriram Siddhardh Nadendla, Pramod K. Varshney,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05447", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05447", "title": "\nLower Bounds for the Graph Homomorphism Problem", "abstract": "The graph homomorphism problem (HOM) asks whether the vertices of a given -vertex graph can be mapped to the vertices of a given -vertex graph such that each edge of is mapped to an edge of . The problem generalizes the graph coloring problem and at the same time can be viewed as a special case of the -CSP problem. In this paper, we prove several lower bound for HOM under the Exponential Time Hypothesis (ETH) assumption. The main result is a lower bound . This rules out the existence of a single-exponential algorithm and shows that the trivial upper bound is almost asymptotically tight. We also investigate what properties of graphs and make it difficult to solve HOM. An easy observation is that an upper bound can be improved to where is the minimum size of a vertex cover of . The second lower bound shows that the upper bound is asymptotically tight. As to the properties of the \"right-hand side\" graph , it is known that HOM can be solved in time and where is the maximum degree of and is the treewidth of . This gives single-exponential algorithms for graphs of bounded maximum degree or bounded treewidth. Since the chromatic number does not exceed and , it is natural to ask whether similar upper bounds with respect to can be obtained. We provide a negative answer to this question by establishing a lower bound for any function . We also observe that similar lower bounds can be obtained for locally injective homomorphisms.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Fedor V. Fomin, Alexander Golovnev, Alexander S. Kulikov, Ivan Mihajlin,", "date": "2015-2-19"}, 
{"urllink": "http://arxiv.org/abs/1502.05443", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05443", "title": "\nInfluence-Optimistic Local Values for Multiagent Planning --- Extended  Version", "abstract": "Recent years have seen the development of a number of methods for multiagent planning under uncertainty that scale to tens or even hundreds of agents. However, most of these methods either make restrictive assumptions on the problem domain, or provide approximate solutions without any guarantees on quality. To allow for meaningful benchmarking through measurable quality guarantees on a very general class of problems, this paper introduces a family of influence-optimistic upper bounds for factored Dec-POMDPs. Intuitively, we derive bounds on very large multiagent planning problems by subdividing them in sub-problems, and at each of these sub-problems making optimistic assumptions with respect to the influence that will be exerted by the rest of the system. We numerically compare the different upper bounds and demonstrate how, for the first time ever, we can achieve a non-trivial guarantee that the heuristic solution of problems with hundreds of agents is close to optimal. Furthermore, we provide evidence that the upper bounds may improve the effectiveness of heuristic influence search, and discuss further potential applications to multiagent planning.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Frans A. Oliehoek, Matthijs T.J. Spaan, Stefan Witwicki,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05441", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05441", "title": "\nRule-and Dictionary-based Solution for Variations in Written Arabic  Names in Social Networks, Big Data, Accounting Systems and Large Databases", "abstract": "This paper investigates the problem that some Arabic names can be written in multiple ways. When someone searches for only one form of a name, neither exact nor approximate matching is appropriate for returning the multiple variants of the name. Exact matching requires the user to enter all forms of the name for the search, and approximate matching yields names not among the variations of the one being sought. In this paper, we attempt to solve the problem with a dictionary of all Arabic names mapped to their different (alternative) writing forms. We generated alternatives based on rules we derived from reviewing the first names of 9.9 million citizens and former citizens of Jordan. This dictionary can be used for both standardizing the written form when inserting a new name into a database and for searching for the name and all its alternative written forms. Creating the dictionary automatically based on rules resulted in at least 7% erroneous acceptance errors and 7.9% erroneous rejection errors. We addressed the errors by manually editing the dictionary. The dictionary can be of help to real world-databases, with the qualification that manual editing does not guarantee 100% correctness.", "subjects": "Databases (cs.DB)", "authors": "Ahmad B.A. Hassanat, Ghada Awad Altarawneh,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05435", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05435", "title": "\nFusion of Image Segmentation Algorithms using Consensus Clustering", "abstract": "A new segmentation fusion method is proposed that ensembles the output of several segmentation algorithms applied on a remotely sensed image. The candidate segmentation sets are processed to achieve a consensus segmentation using a stochastic optimization algorithm based on the Filtered Stochastic BOEM (Best One Element Move) method. For this purpose, Filtered Stochastic BOEM is reformulated as a segmentation fusion problem by designing a new distance learning approach. The proposed algorithm also embeds the computation of the optimum number of clusters into the segmentation fusion problem.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Mete Ozay, Fatos T. Yarman Vural, Sanjeev R. Kulkarni, H. Vincent Poor,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05433", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05433", "title": "\nPilot Reuse for Massive MIMO Transmission over Spatially Correlated  Rayleigh Fading Channels", "abstract": "We propose pilot reuse (PR) in single cell for massive multiuser multiple-input multiple-output (MIMO) transmission to reduce the pilot overhead. For spatially correlated Rayleigh fading channels, we establish a relationship between channel spatial correlations and channel power angle spectrum when the base station antenna number tends to infinity. With this channel model, we show that sum mean square error (MSE) of channel estimation can be minimized provided that channel angle of arrival intervals of the user terminals reusing the pilots are non-overlapping, which shows feasibility of PR over spatially correlated massive MIMO channels with constrained channel angular spreads. Regarding that channel estimation performance might degrade due to PR, we also develop the closed-form robust multiuser uplink receiver and downlink precoder that minimize sum MSE of signal detection, and reveal a duality between them. Subsequently, we investigate pilot scheduling, which determines the PR pattern, under two minimum MSE related criteria, and propose a low complexity pilot scheduling algorithm which relies on the channel statistics only. Simulation results show that the proposed PR scheme provides significant performance gains over the conventional orthogonal training scheme in terms of net spectral efficiency.", "subjects": "Information Theory (cs.IT)", "authors": "Li You, Xiqi Gao, Xiang-Gen Xia, Ni Ma, Yan Peng,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05428", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05428", "title": "\nMatched Multiuser Gaussian Source-Channel Communications via Uncoded  Schemes", "abstract": "We investigate whether uncoded schemes are optimal for Gaussian sources on multiuser Gaussian channels. Particularly, we consider two problems: the first is to send correlated Gaussian sources on a Gaussian broadcast channel where each receiver is interested in reconstructing only one source component (or one specific linear function of the sources) under the mean squared error distortion measure; the second is to send vector Gaussian sources on a Gaussian multiple-access channel, where each transmitter observes a noisy combination of the source, and the receiver wishes to reconstruct the individual source components (or individual linear functions) under the mean squared error distortion measure. It is shown that when the channel parameters match certain general conditions, the induced distortion tuples are on the boundary of the achievable distortion region, and thus optimal. Instead of following the conventional approach of attempting to characterize the achievable distortion region, we ask the question whether and how a match can be effectively determined. This decision problem formulation helps to circumvent the difficult optimization problem often embedded in region characterization problems, and also leads us to focus on the critical conditions in the outer bounds that make the inequalities become equalities, which effectively decouples the overall problem into several simpler sub-problems.", "subjects": "Information Theory (cs.IT)", "authors": "Chao Tian, Jun Chen, Suhas Diggavi, Shlomo Shamai,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05375", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05375", "title": "\nOn learning k-parities with and without noise", "abstract": "We first consider the problem of learning -parities in the on-line mistake-bound model: given a hidden vector with and a sequence of \"questions\" , where the algorithm must reply to each question with , what is the best tradeoff between the number of mistakes made by the algorithm and its time complexity? We improve the previous best result of Buhrman et al. by an factor in the time complexity. Second, we consider the problem of learning -parities in the presence of classification noise of rate . A polynomial time algorithm for this problem (when and ) is a longstanding challenge in learning theory. Grigorescu et al. showed an algorithm running in time . Note that this algorithm inherently requires time even when the noise rate is polynomially small. We observe that for sufficiently small noise rate, it is possible to break the barrier. In particular, if for some function and , and , then there is an algorithm for the problem with running time .", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Arnab Bhattacharyya, Ameet Gadekar, Ninad Rajgopal,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05361", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05361", "title": "\nExtended Formulation for CSP that is Compact for Instances of Bounded  Treewidth", "abstract": "In this paper we provide an extended formulation for the class of constraint satisfaction problems and prove that its size is polynomial for instances whose constraint graph has bounded treewidth. This implies new upper bounds on extension complexity of several important NP-hard problems on graphs of bounded treewidth.", "subjects": "Computational Complexity (cs.CC)", "authors": "Petr Kolman, Martin Kouteck\u00fd,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05347", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05347", "title": "\nThe Penn Jerboa: A Platform for Exploring Parallel Composition of  Templates", "abstract": "We have built a 12DOF, passive-compliant legged, tailed biped actuated by four brushless DC motors. We anticipate that this machine will achieve varied modes of quasistatic and dynamic balance, enabling a broad range of locomotion tasks including sitting, standing, walking, hopping, running, turning, leaping, and more. Achieving this diversity of behavior with a single under-actuated body, requires a correspondingly diverse array of controllers, motivating our interest in compositional techniques that promote mixing and reuse of a relatively few base constituents to achieve a combinatorially growing array of available choices. Here we report on the development of one important example of such a behavioral programming method, the construction of a novel monopedal sagittal plane hopping gait through parallel composition of four decoupled 1DOF base controllers. For this example behavior, the legs are locked in phase and the body is fastened to a boom to restrict motion to the sagittal plane. The platform's locomotion is powered by the hip motor that adjusts leg touchdown angle in flight and balance in stance, along with a tail motor that adjusts body shape in flight and drives energy into the passive leg shank spring during stance. The motor control signals arise from the application in parallel of four simple, completely decoupled 1DOF feedback laws that provably stabilize in isolation four corresponding 1DOF abstract reference plants. Each of these abstract 1DOF closed loop dynamics represents some simple but crucial specific component of the locomotion task at hand. We present a partial proof of correctness for this parallel composition of template reference systems along with data from the physical platform suggesting these templates are anchored as evidenced by the correspondence of their characteristic motions with a suitably transformed image of traces from the physical platform.", "subjects": "Robotics (cs.RO)", "authors": "Avik De, Daniel E. Koditschek,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05337", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05337", "title": "\nControlled Data Sharing for Collaborative Predictive Blacklisting", "abstract": "Although sharing data across organizational boundaries has often been advocated as a promising way to enhance security, collaborative initiatives are rarely put into practice owing to confidentiality, trust, and liability challenges. In this paper, we investigate whether collaborative threat mitigation can be realized via a controlled data sharing approach, whereby organizations make informed decisions as to whether or not, and how much, to share. Using appropriate cryptographic tools, entities can estimate the benefits of collaborating and agree on what to share in a privacy-preserving way, without having to disclose their entire datasets. We focus on collaborative predictive blacklisting, i.e., forecasting attack sources also based on logs contributed by other organizations and study the impact of different sharing strategies by experimenting on a real-world dataset of two billion suspicious IP addresses collected from Dshield over two months. We find that controlled data sharing yields up to an average 105% accuracy improvement, while also reducing the false positive rate.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Julien Freudiger, Emiliano De Cristofaro, Alex Brito,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05334", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05334", "title": "\nD3-Reducible Graphs", "abstract": "We describe two local reduction rules that can be used to recognize Halin graphs in linear time, avoiding the general-purpose planarity testing step of previous linear time Halin graph recognition algorithms. The same two rules can also be used to recognize a broader class of polyhedral graphs, which we call D3-reducible graphs. These graphs are the dual graphs of the polyhedra formed by gluing pyramids together on their triangular faces; their treewidth is bounded, and they necessarily have Lombardi drawings.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "David Eppstein,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05332", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05332", "title": "\nThe number of non-crossing perfect plane matchings is minimized (almost)  only by point sets in convex position", "abstract": "It is well-known that the number of non-crossing perfect matchings of points in convex position in the plane is , the th Catalan number. Garc 'ia, Noy, and Tejel proved in 2000 that for any set of points in general position, the number of such matchings is at least . We show that the equality holds only for sets of points in convex position, and for one exceptional configuration of points.", "subjects": "Computational Geometry (cs.CG)", "authors": "Andrei Asinowski,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05321", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05321", "title": "\nOn Mobile Bluetooth Tags", "abstract": "This paper presents a new approach for hyper-local data sharing and delivery on the base of discoverable Bluetooth nodes. Our approach allows customers to associate user-defined data with network nodes and use a special mobile application (context-aware browser) for presenting this information to mobile users in proximity. Alternatively, mobile services can request and share local data in M2M applications rely on network proximity. Bluetooth nodes in cars are among the best candidates for the role of the bearing nodes.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Dmitry Namiot, Manfred Sneps-Sneppe,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05301", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05301", "title": "\nSherali-Adams relaxations for valued CSPs", "abstract": "We consider Sherali-Adams linear programming relaxations for solving valued constraint satisfaction problems to optimality. The utility of linear programming relaxations in this context have previously been demonstrated using the lowest possible level of this hierarchy under the name of the basic linear programming relaxation (BLP). It has been shown that valued constraint languages containing only finite-valued weighted relations are tractable if, and only if, the integrality gap of the BLP is 1. In this paper, we demonstrate that almost all of the known tractable languages with arbitrary weighted relations have an integrality gap 1 for the Sherali-Adams relaxation with parameters (2,3). The result is closely connected to the notion of bounded relational width for the ordinary constraint satisfaction problem and its recent characterisation.", "subjects": "Computational Complexity (cs.CC)", "authors": "Johan Thapper, Stanislav Zivny,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05292", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05292", "title": "\nDynamic subtrees queries revised: the Depth First Tour Tree", "abstract": "In the dynamic tree problem the goal is the maintenance of an arbitrary n-vertex forest, where the trees are subject to joining and splitting by, respectively, adding and removing edges. Depending on the application, information can be associated to nodes or edges (or both), and queries might require to combine values in path or (sub)trees. In this paper we present a novel data structure, called the Depth First Tour Tree, based on a linearization of a DFS visit of the tree. Despite the simplicity of the approach, similar to the ET-Trees (based on a Euler Tour), our data structure is able to answer queries related to both paths and (sub)trees. In particular, focusing on subtree computations, we show how to customize the data structure in order to answer queries for three distinct applications: impact of the removal of an articulation point from a graph, betweenness centrality and closeness centrality of a dynamic tree.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Gabriele Farina, Luigi Laura,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05279", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05279", "title": "\nThe Price of Local Power Control in Wireless Scheduling", "abstract": "We consider the problem of scheduling wireless links in the physical model, where we seek an assignment of power levels and a partition of the given set of links into the minimum number of subsets satisfying the signal-to-interference-and-noise-ratio (SINR) constraints. Specifically, we are interested in the efficiency of local power assignment schemes, or oblivious power schemes, in approximating wireless scheduling. Oblivious power schemes are motivated by networking scenarios when power levels must be decided in advance, and not as part of the scheduling computation. We first show that the known algorithms fail to obtain sub-logarithmic bounds; that is, their approximation ratio are , where is the number of links, is the ratio of the maximum and minimum link lengths, and hides doubly-logarithmic factors. We then present the first -approximation algorithm, which is known to be best possible (in terms of ) for oblivious power schemes. We achieve this by representing interference by a conflict graph, which allows the application of graph-theoretic results for a variety of related problems, including the weighted capacity problem. We explore further the contours of approximability, and find the choice of power assignment matters; that not all metric spaces are equal; and that the presence of weak links makes the problem harder. Combined, our result resolve the price of oblivious power for wireless scheduling, or the value of allowing unfettered power control.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Magnus M. Halldorsson, Tigran Tonoyan,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05275", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05275", "title": "\nCross-bifix-free sets in two dimensions", "abstract": "A bidimensional bifix (in short bibifix) of a square matrix T is a square submatrix of T which occurs in the top-left and bottom-right corners of T. This allows us to extend the definition of bifix-free words and cross-bifix-free set of words to bidimensional structures. In this paper we exhaustively generate all the bibifix-free square matrices and we construct a particular non-expandable cross-bibifix-free set of square matrices. Moreover, we provide a Gray code for listing this set.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Elena Barcucci, Antonio Bernini, Stefano Bilotta, Renzo Pinzani,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05273", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05273", "title": "\nHow to Bootstrap Anonymous Communication", "abstract": "We ask whether it is possible to anonymously communicate a large amount of data using only public (non-anonymous) communication together with a small anonymous channel. We think this is a central question in the theory of anonymous communication and to the best of our knowledge this is the first formal study in this direction. To solve this problem, we introduce the concept of anonymous steganography: think of a leaker Lea who wants to leak a large document to Joe the journalist. Using anonymous steganography Lea can embed this document in innocent looking communication on some popular website (such as cat videos on YouTube or funny memes on 9GAG). Then Lea provides Joe with a short key which, when applied to the entire website, recovers the document while hiding the identity of Lea among the large number of users of the website. Our contributions include: - Introducing and formally defining anonymous steganography, - A construction showing that anonymous steganography is possible (which uses recent results in circuits obfuscation), - A lower bound on the number of bits which are needed to bootstrap anonymous communication.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Sune K. Jakobsen, Claudio Orlandi,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05264", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05264", "title": "\nMeasuring Creativity of Wikipedia Editors", "abstract": "Our paper explores contribution patterns of creativity and collaboration of Wikipedia editors as manifestations of social dynamics between the editors. We find support for existence of four socially constructed personas among the editors and difference in distribution of personas in articles of different qualities.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Pentti Launonen, KC Kern, Sanna Tiilikainen,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05263", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05263", "title": "\nComparing Online Community Structure of Patients of Chronic Diseases", "abstract": "In this paper we compare the social network structure of people talking about Crohn's disease, Cystic Fibrosis, and Type 1 diabetes on Facebook and Twitter. We find that the Crohn's community's contributors are most emotional on Facebook and Twitter and most negative on Twitter, while the T1D community's communication network structure is most cohesive.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Hanuma Teja Maddali, Peter A. Gloor, Peter Margolis,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05260", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05260", "title": "\nLessons from the Coinseminar", "abstract": "This paper describes lessons learned from teaching a distributed virtual course on COINs (Collaborative Innovation Networks) over the last 12 years at five different sites located in four different time zones.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Peter Gloor, Maria Paasivaara, Christine Miller,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05256", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05256", "title": "\nCultural Anthropology Through the Lens of Wikipedia - A Comparison of  Historical Leadership Networks in the English, Chinese, Japanese and German  Wikipedia", "abstract": "In this paper we study the differences in historical worldview between Western and Eastern cultures, represented through the English, Chinese, Japanese, and German Wikipedia. In particular, we analyze the historical networks of the World's leaders since the beginning of written history, comparing them in the four different Wikipedias.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Peter Gloor, Patrick De Boer, Wei Lo, Stefan Wagner, Keiichi Nemoto, Hauke Fuehres,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05243", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05243", "title": "\nSA-CNN: Dynamic Scene Classification using Convolutional Neural Networks", "abstract": "The task of classifying videos of natural dynamic scenes into appropriate classes has gained lot of attention in recent years. The problem especially becomes challenging when the camera used to capture the video is dynamic.In this paper, we propose a statistical aggregation (SA) solution based on convolutional neural networks (CNNs) to address this problem. We call our approach as SA-CNN. The algorithm works by extracting CNN activation features for a number of frames in a video and then uses a statistical aggregation scheme in order to obtain a robust feature descriptor for the video. We show through results that the proposed approach performs better than the-state-of-the art algorithm for the Maryland dataset. The final descriptor obtained is powerful enough to distinguish among dynamic scenes and is even capable of addressing the scenario where the camera motion is dominant and the scene dynamics are complex. Further, this paper shows an extensive study on the performance of various statistical aggregation methods and their combinations in order to obtain minimal classification error. We compare the proposed approach with other dynamic scene classification algorithms on two publicly available datasets - Maryland and YUPenn to demonstrate the superior performance of the proposed approach.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Aalok Gangopadhyay, Shivam Mani Tripathi, Ishan Jindal, Shanmuganathan Raman,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.05241", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05241", "title": "\nNEFI: Network Extraction From Images", "abstract": "Networks and network-like structures are amongst the central building blocks of many technological and biological systems. Given a mathematical graph representation of a network, methods from graph theory enable a precise investigation of its properties. Software for the analysis of graphs is widely available and has been applied to graphs describing large scale networks such as social networks, protein-interaction networks, etc. In these applications, graph acquisition, i.e., the extraction of a mathematical graph from a network, is relatively simple. However, for many network-like structures, e.g. leaf venations, slime molds and mud cracks, data collection relies on images where graph extraction requires domain-specific solutions or even manual. Here we introduce Network Extraction From Images, NEFI, a software tool that automatically extracts accurate graphs from images of a wide range of networks originating in various domains. While there is previous work on graph extraction from images, theoretical results are fully accessible only to an expert audience and ready-to-use implementations for non-experts are rarely available or insufficiently documented. NEFI provides a novel platform allowing practitioners from many disciplines to easily extract graph representations from images by supplying flexible tools from image processing, computer vision and graph theory bundled in a convenient package. Thus, NEFI constitutes a scalable alternative to tedious and error-prone manual graph extraction and special purpose tools. We anticipate NEFI to enable the collection of larger datasets by reducing the time spent on graph extraction. The analysis of these new datasets may open up the possibility to gain new insights into the structure and function of various types of networks. NEFI is open source and available this http URL", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Michael Dirnberger, Adrian Neumann, Tim Kehl,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05224", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05224", "title": "\nCross-Modality Hashing with Partial Correspondence", "abstract": "Learning a hashing function for cross-media search is very desirable due to its low storage cost and fast query speed. However, the data crawled from Internet cannot always guarantee good correspondence among different modalities which affects the learning for hashing function. In this paper, we focus on cross-modal hashing with partially corresponded data. The data without full correspondence are made in use to enhance the hashing performance. The experiments on Wiki and NUS-WIDE datasets demonstrates that the proposed method outperforms some state-of-the-art hashing approaches with fewer correspondence information.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Yun Gu, Haoyang Xue, Jie Yang,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1502.05222", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05222", "title": "\nHierarchical Oracles for Time-Dependent Networks", "abstract": "We present novel oracles for networks that obey time-dependent metrics with two unique features: (i) they provably achieve subquadratic preprocessing time and space that is emph of the metric; (ii) they provably achieve query time that is sublinear either on the network size, or on the actual emph of the query at hand.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Spyros Kontogiannis, Dorothea Wagner, Christos Zaroliagis,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05216", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05216", "title": "\nTwofold exp and log", "abstract": "This article is about twofold arithmetic. Here I introduce algorithms and experimental code for twofold variant of C/C++ standard functions exp() and log(), and expm1() and log1p(). Twofold function is nearly 2x-precise so can assess accuracy of standard one. Performance allows assessing on-fly: twofold texp() over double is ~10x times faster than expq() by GNU quadmath.", "subjects": "Mathematical Software (cs.MS)", "authors": "Evgeny Latkin,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.05213", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05213", "title": "\nF0 Modeling In Hmm-Based Speech Synthesis System Using Deep Belief  Network", "abstract": "In recent years multilayer perceptrons (MLPs) with many hid- den layers Deep Neural Network (DNN) has performed sur- prisingly well in many speech tasks, i.e. speech recognition, speaker verification, speech synthesis etc. Although in the context of F0 modeling these techniques has not been ex- ploited properly. In this paper, Deep Belief Network (DBN), a class of DNN family has been employed and applied to model the F0 contour of synthesized speech which was generated by HMM-based speech synthesis system. The experiment was done on Bengali language. Several DBN-DNN architectures ranging from four to seven hidden layers and up to 200 hid- den units per hidden layer was presented and evaluated. The results were compared against clustering tree techniques pop- ularly found in statistical parametric speech synthesis. We show that from textual inputs DBN-DNN learns a high level structure which in turn improves F0 contour in terms of ob- jective and subjective tests.", "subjects": "Learning (cs.LG)", "authors": "Sankar Mukherjee, Shyamal Kumar Das Mandal,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05212", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05212", "title": "\nIAT - Image Annotation Tool: Manual", "abstract": "The annotation of image and video data of large datasets is a fundamental task in multimedia information retrieval and computer vision applications. In order to support the users during the image and video annotation process, several software tools have been developed to provide them with a graphical environment which helps drawing object contours, handling tracking information and specifying object metadata. Here we introduce a preliminary version of the image annotation tools developed at the Imaging and Vision Laboratory.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Gianluigi Ciocca, Paolo Napoletano, Raimondo Schettini,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05209", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05209", "title": "\nFormalizing Size-Optimal Sorting Networks: Extracting a Certified Proof  Checker", "abstract": "Since the proof of the four color theorem in 1976, computer-generated proofs have become a reality in mathematics and computer science. During the last decade, we have seen formal proofs using verified proof assistants being used to verify the validity of such proofs. In this paper, we describe a formalized theory of size-optimal sorting networks. From this formalization we extract a certified checker that successfully verifies computer-generated proofs of optimality on up to 8 inputs. The checker relies on an untrusted oracle to shortcut the search for witnesses on more than 1.6 million NP-complete subproblems.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Lu\u00eds Cruz-Filipe, Peter Schneider-Kamp,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1502.05204", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05204", "title": "\nClustered Integer 3SUM via Additive Combinatorics", "abstract": "We present a collection of new results on problems related to 3SUM, including: 1. The first truly subquadratic algorithm for 1a. computing the (min,+) convolution for monotone increasing sequences with integer values bounded by , 1b. solving 3SUM for monotone sets in 2D with integer coordinates bounded by , and 1c. preprocessing a binary string for histogram indexing (also called jumbled indexing). The running time is: with randomization, or deterministically. This greatly improves the previous time bound obtained from Williams' recent result on all-pairs shortest paths [STOC'14], and answers an open question raised by several researchers studying the histogram indexing problem. 2. The first algorithm for histogram indexing for any constant alphabet size that achieves truly subquadratic preprocessing time and truly sublinear query time. 3. A truly subquadratic algorithm for integer 3SUM in the case when the given set can be partitioned into clusters each covered by an interval of length , for any constant . 4. An algorithm to preprocess any set of integers so that subsequently 3SUM on any given subset can be solved in time. All these results are obtained by a surprising new technique, based on the Balog--Szemer 'edi--Gowers Theorem from additive combinatorics.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Timothy M. Chan, Moshe Lewenstein,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05191", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05191", "title": "\nDetermining Training Needs for Cloud Infrastructure Investigations using  I-STRIDE", "abstract": "As more businesses and users adopt cloud computing services, security vulnerabilities will be increasingly found and exploited. There are many technological and political challenges where investigation of potentially criminal incidents in the cloud are concerned. Security experts, however, must still be able to acquire and analyze data in a methodical, rigorous and forensically sound manner. This work applies the STRIDE asset-based risk assessment method to cloud computing infrastructure for the purpose of identifying and assessing an organization's ability to respond to and investigate breaches in cloud computing environments. An extension to the STRIDE risk assessment model is proposed to help organizations quickly respond to incidents while ensuring acquisition and integrity of the largest amount of digital evidence possible. Further, the proposed model allows organizations to assess the needs and capacity of their incident responders before an incident occurs.", "subjects": "Computers and Society (cs.CY)", "authors": "Joshua I. James, Ahmed F. Shosha, Pavel Gladyshev,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05186", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05186", "title": "\nMeasuring Accuracy of Automated Parsing and Categorization Tools and  Processes in Digital Investigations", "abstract": "This work presents a method for the measurement of the accuracy of evidential artifact extraction and categorization tasks in digital forensic investigations. Instead of focusing on the measurement of accuracy and errors in the functions of digital forensic tools, this work proposes the application of information retrieval measurement techniques that allow the incorporation of errors introduced by tools and analysis processes. This method uses a `gold standard' that is the collection of evidential objects determined by a digital investigator from suspect data with an unknown ground truth. This work proposes that the accuracy of tools and investigation processes can be evaluated compared to the derived gold standard using common precision and recall values. Two example case studies are presented showing the measurement of the accuracy of automated analysis tools as compared to an in-depth analysis by an expert. It is shown that such measurement can allow investigators to determine changes in accuracy of their processes over time, and determine if such a change is caused by their tools or knowledge.", "subjects": "Computers and Society (cs.CY)", "authors": "Joshua I. James, Alejandra Lopez-Fernandez, Pavel Gladyshev,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05183", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05183", "title": "\nPractically Stabilizing Virtual Synchrony", "abstract": "Virtual synchrony is an important abstraction that is proven to be extremely useful when implemented over asynchronous, typically large, message-passing distributed systems. Fault tolerant design is a key criterion for the success of such implementations. This is because large distributed systems can be highly available as long as they do not depend on the full operational status of every system participant. That is, when using redundancy in numbers to overcome non-optimal behavior of participants and to gain global robustness and high availability. Self-stabilizing systems can tolerate transient faults that drive the system to an arbitrary unpredicted configuration. Such systems automatically regain consistency from any such arbitrary configuration, and then produce the desired system behavior. Practically self-stabilizing systems ensure the desired system behavior for practically infinite number of successive steps e.g., steps. We present the first practically self-stabilizing virtual synchrony algorithm. The algorithm is a combination of several new techniques that may be of independent interest. In particular, we present a new counter algorithm that establishes an efficient practically unbounded counter, that in turn can be directly used to implement a self-stabilizing Multiple-Writer Multiple-Reader (MWMR) register emulation. Other components include self-stabilizing group membership, self-stabilizing multicast, and self-stabilizing emulation of replicated state machine. As we base the replicated state machine implementation on virtual synchrony, rather than consensus, the system progresses in more extreme asynchronous executions with relation to consensus-based replicated state machine.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Shlomi Dolev, Chryssis Georgiou, Ioannis Marcoullis, Elad Michael Schiller,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05179", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05179", "title": "\nDependability Tests Selection Based on the Concept of Layered Networks", "abstract": "Nowadays, the consequences of failure and downtime of distributed systems have become more and more severe. As an obvious solution, these systems incorporate protection mechanisms to tolerate faults that could cause systems failures and system dependability must be validated to ensure that protection mechanisms have been implemented correctly and the system will provide the desired level of reliable service. This paper presents a systematic approach for identifying (1) characteristic sets of critical system elements for dependability testing (single points of failure and recovery groups) based on the concept of layered networks; and (2) the most important combinations of components from each recovery group based on a combinatorial technique. Based on these combinations, we determine a set of test templates to be performed to demonstrate system dependability.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Andrey A. Shchurov, Radek Marik,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05168", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05168", "title": "\nQuery Expansion Strategy based on Pseudo Relevance Feedback and Term  Weight Scheme for Monolingual Retrieval", "abstract": "Query Expansion using Pseudo Relevance Feedback is a useful and a popular technique for reformulating the query. In our proposed query expansion method, we assume that relevant information can be found within a document near the central idea. The document is normally divided into sections, paragraphs and lines. The proposed method tries to extract keywords that are closer to the central theme of the document. The expansion terms are obtained by equi-frequency partition of the documents obtained from pseudo relevance feedback and by using tf-idf scores. The idf factor is calculated for number of partitions in documents. The group of words for query expansion is selected using the following approaches: the highest score, average score and a group of words that has maximum number of keywords. As each query behaved differently for different methods, the effect of these methods in selecting the words for query expansion is investigated. From this initial study, we extend the experiment to develop a rule-based statistical model that automatically selects the best group of words incorporating the tf-idf scoring and the 3 approaches explained here, in the future. The experiments were performed on FIRE 2011 Adhoc Hindi and English test collections on 50 queries each, using Terrier as retrieval engine.", "subjects": "Information Retrieval (cs.IR)", "authors": "Rekha Vaidyanathan, Sujoy Das, Namita Srivastava,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05167", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05167", "title": "\nDengue disease prediction using weka data mining tool", "abstract": "Dengue is a life threatening disease prevalent in several developed as well as developing countries like India.In this paper we discuss various algorithm approaches of data mining that have been utilized for dengue disease prediction. Data mining is a well known technique used by health organizations for classification of diseases such as dengue, diabetes and cancer in bioinformatics research. In the proposed approach we have used WEKA with 10 cross validation to evaluate data and compare results. Weka has an extensive collection of different machine learning and data mining algorithms. In this paper we have firstly classified the dengue data set and then compared the different data mining techniques in weka through Explorer, knowledge flow and Experimenter interfaces. Furthermore in order to validate our approach we have used a dengue dataset with 108 instances but weka used 99 rows and 18 attributes to determine the prediction of disease and their accuracy using classifications of different algorithms to find out the best performance. The main objective of this paper is to classify data and assist the users in extracting useful information from data and easily identify a suitable algorithm for accurate predictive model from it. From the findings of this paper it can be concluded that Na \"ive Bayes and J48 are the best performance algorithms for classified accuracy because they achieved maximum accuracy= 100% with 99 correctly classified instances, maximum ROC = 1, had least mean absolute error and it took minimum time for building this model through Explorer and Knowledge flow results", "subjects": "Computers and Society (cs.CY)", "authors": "Kashish Ara Shakil, Shadma Anis, Mansaf Alam,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05156", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05156", "title": "\nAssessing the effectiveness of real-world network simplification", "abstract": "Many real-world networks are large, complex and thus hard to understand, analyze or visualize. The data about networks is not always complete, their structure may be hidden or they change quickly over time. Therefore, understanding how incomplete system differs from complete one is crucial. In this paper, we study the changes in networks under simplification (i.e., reduction in size). We simplify 30 real-world networks with six simplification methods and analyze the similarity between original and simplified networks based on preservation of several properties, for example degree distribution, clustering coefficient, betweenness centrality, density and degree mixing. We propose an approach for assessing the effectiveness of simplification process to define the most appropriate size of simplified networks and to determine the method, which preserves the most properties of original networks. The results reveal the type and size of original networks do not influence the changes of networks under simplification process, while the size of simplified networks does. Moreover, we investigate the performance of simplification methods when the size of simplified networks is 10% of the original networks. The findings show that sampling methods outperform merging ones, particularly random node selection based on degree and breadth-first sampling perform the best.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Neli Blagus, Lovro \u0160ubelj, Marko Bajec,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05153", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05153", "title": "\nNeural Synchronization based Secret Key Exchange over Public Channels: A  survey", "abstract": "Exchange of secret keys over public channels based on neural synchronization using a variety of learning rules offer an appealing alternative to number theory based cryptography algorithms. Though several forms of attacks are possible on this neural protocol e.g. geometric, genetic and majority attacks, our survey finds that deterministic algorithms that synchronize with the end-point networks have high time complexity, while probabilistic and population-based algorithms have demonstrated ability to decode the key during its exchange over the public channels. Our survey also discusses queries, heuristics, erroneous information, group key exchange, synaptic depths, etc, that have been proposed to increase the time complexity of algorithmic interception or decoding of the key during exchange. The Tree Parity Machine and its variants, neural networks with tree topologies incorporating parity checking of state bits, appear to be one of the most secure and stable models of the end-point networks. Our survey also mentions some noteworthy studies on neural networks applied to other necessary aspects of cryptography. We conclude that discovery of neural architectures with very high synchronization speed, and designing the encoding and entropy of the information exchanged during mutual learning, and design of extremely sensitive chaotic maps for transformation of synchronized states of the networks to chaotic encryption keys, are the primary issues in this field.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Sandip Chakraborty, Jiban Dalal, Bikramjit Sarkar, Debaprasad Mukherjee,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05149", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05149", "title": "\nUsing multiple-criteria methods to evaluate community partitions", "abstract": "Community detection is one of the most studied problems on complex networks. Although hundreds of methods have been proposed so far, there is still no universally accepted formal definition of what is a good community. As a consequence, the problem of the evaluation and the comparison of the quality of the solutions produced by these algorithms is still an open question, despite constant progress on the topic. In this article, we investigate how using a multi-criteria evaluation can solve some of the existing problems of community evaluation, in particular the question of multiple equally-relevant solutions of different granularity. After exploring several approaches, we introduce a new quality function, called MDensity, and propose a method that can be related both to a widely used community detection metric, the Modularity, and to the Precision/Recall approach, ubiquitous in information retrieval.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Remy Cazabet, Rathachai Chawuthai, Hideaki Takeda,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05147", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05147", "title": "\nFinitary semantics of linear logic and higher-order model-checking", "abstract": "This article is concerned with semantic methods for higher-order verification. Given an alternating parity automaton A, we introduce a variant of the Scott semantics of linear logic extended with a colouring modality and a fixed point operator. We prove that the interpretation of a higher-order recursion scheme in the resulting model of the lambdaY-calculus is the set of states from which the tree it generates is accepted by A. The finiteness of the model therefore leads to a new proof of the decidability of MSO formulas at the root of trees generated by higher-order recursion schemes. By using a connection between the denotations in this model and an appropriate type system, together with the finiteness of the semantics, we also obtain a new decidability proof of the selection problem.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Charles Grellois, Paul-Andr\u00e9 Melli\u00e8s,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05145", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05145", "title": "\nKnowledge-generating Efficiency in Innovation Systems: The relation  between structural and temporal effects", "abstract": "Using time series of US patents per million inhabitants, knowledge-generating cycles can be distinguished. These cycles partly coincide with Kondratieff long waves. The changes in the slopes between them indicate discontinuities in the knowledge-generating paradigms. The knowledge-generating paradigms can be modeled in terms of interacting dimensions (for example, in university-industry-government relations) that set limits to the maximal efficiency of innovation systems. The maximum values of the parameters in the model are of the same order as the regression coefficients of the empirical waves. The mechanism of the increase in the dimensionality is specified as self-organization which leads to the breaking of existing relations into the more diversified structure of a fractal-like network. This breaking can be modeled in analogy to 2D and 3D (Koch) snowflakes. The boost of knowledge generation leads to newly emerging technologies that can be expected to be more diversified and show shorter life cycles than before. Time spans of the knowledge-generating cycles can also be analyzed in terms of Fibonacci numbers. This perspective allows for forecasting expected dates of future possible paradigm changes. In terms of policy implications, this suggests a shift in focus from the manufacturing technologies to developing new organizational technologies and formats of human interactions", "subjects": "Computers and Society (cs.CY)", "authors": "Inga Ivanova, Loet Leydesdorff,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05142", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05142", "title": "\nModels, Statistics, and Rates of Binary Correlated Sources", "abstract": "This paper discusses and analyzes various models of binary correlated sources, which may be relevant in several distributed communication scenarios. These models are statistically characterized in terms of joint Probability Mass Function (PMF) and covariance. Closed-form expressions for the joint entropy of the sources are also presented. The asymptotic entropy rate for very large number of sources is shown to converge to a common limit for all the considered models. This fact generalizes recent results on the information-theoretic performance limit of communication schemes which exploit the correlation among sources at the receiver.", "subjects": "Information Theory (cs.IT)", "authors": "Marco Martalo', Riccardo Raheli,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05137", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05137", "title": "\nPrediction of Search Targets From Fixations in Open-world Settings", "abstract": "Previous work on predicting the target of visual search from human fixations only considered closed-world settings in which training labels are available and predictions are performed for a known set of potential targets. In this work we go beyond the state-of-the-art by studying search target prediction in an open-world setting. To this end, we present a dataset containing fixation data of 18 users searching for natural images from three image categories within image collages of about 80 images. In a closed-world baseline experiment we show that we can predict the correct mental image out of a candidate set of five images. In an open-world experiment we no longer assume potential search targets to be part of the training set and we also no longer assume that we have fixation data for these targets. We present a new problem formulation for search target recognition in the open-world setting, which is based on learning compatibilities between fixations and potential targets.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Hosnieh Sattar, Sabine M\u00fcller, Mario Fritz, Andreas Bulling,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1502.05134", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05134", "title": "\nSupervised cross-modal factor analysis", "abstract": "In this paper we study the problem of learning from multiple modal data for purpose of document classification. In this problem, each document is composed two different modals of data, i.e., an image and a text. Cross-modal factor analysis (CFA) has been proposed to project the two different modals of data to a shared data space, so that the classification of a image or a text can be performed directly in this space. A disadvantage of CFA is that it has ignored the supervision information. In this paper, we improve CFA by incorporating the supervision information to represent and classify both image and text modals of documents. We project both image and text data to a shared data space by factor analysis, and then train a class label predictor in the shared space to use the class label information. The factor analysis parameter and the predictor parameter are learned jointly by solving one single objective function. With this objective function, we minimize the distance between the projections of image and text of the same document, and the classification error of the projection measured by hinge loss function. The objective function is optimized by an alternate optimization strategy in an iterative algorithm. Experiments in two different multiple modal document data sets show the advantage of the proposed algorithm over other CFA methods.", "subjects": "Learning (cs.LG)", "authors": "Jingbin Wang, Haoxiang Wang, Yujin Tu, Kanghong Duan, Zhenxin Zhan, Srikanth Chekuri,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05131", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05131", "title": "\nAffective Music Information Retrieval", "abstract": "Much of the appeal of music lies in its power to convey emotions/moods and to evoke them in listeners. In consequence, the past decade witnessed a growing interest in modeling emotions from musical signals in the music information retrieval (MIR) community. In this article, we present a novel generative approach to music emotion modeling, with a specific focus on the valence-arousal (VA) dimension model of emotion. The presented generative model, called emph (AEG), better accounts for the subjectivity of emotion perception by the use of probability distributions. Specifically, it learns from the emotion annotations of multiple subjects a Gaussian mixture model in the VA space with prior constraints on the corresponding acoustic features of the training music pieces. Such a computational framework is technically sound, capable of learning in an online fashion, and thus applicable to a variety of applications, including user-independent (general) and user-dependent (personalized) emotion recognition and emotion-based music retrieval. We report evaluations of the aforementioned applications of AEG on a larger-scale emotion-annotated corpora, AMG1608, to demonstrate the effectiveness of AEG and to showcase how evaluations are conducted for research on emotion-based MIR. Directions of future work are also discussed.", "subjects": "Information Retrieval (cs.IR)", "authors": "Ju-Chiang Wang, Yi-Hsuan Yang, Hsin-Min Wang,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05113", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05113", "title": "\nTemporal Embedding in Convolutional Neural Networks for Robust Learning  of Abstract Snippets", "abstract": "The prediction of periodical time-series remains challenging due to various types of data distortions and misalignments. Here, we propose a novel model called Temporal embedding-enhanced convolutional neural Network (TeNet) to learn repeatedly-occurring-yet-hidden structural elements in periodical time-series, called abstract snippets, for predicting future changes. Our model uses convolutional neural networks and embeds a time-series with its potential neighbors in the temporal domain for aligning it to the dominant patterns in the dataset. The model is robust to distortions and misalignments in the temporal domain and demonstrates strong prediction power for periodical time-series. We conduct extensive experiments and discover that the proposed model shows significant and consistent advantages over existing methods on a variety of data modalities ranging from human mobility to household power consumption records. Empirical results indicate that the model is robust to various factors such as number of samples, variance of data, numerical ranges of data etc. The experiments also verify that the intuition behind the model can be generalized to multiple data types and applications and promises significant improvement in prediction performances across the datasets studied.", "subjects": "Learning (cs.LG)", "authors": "Jiajun Liu, Kun Zhao, Brano Kusy, Ji-rong Wen, Raja Jurdak,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05111", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05111", "title": "\nCSAL: Self-adaptive Labeling based Clustering Integrating Supervised  Learning on Unlabeled Data", "abstract": "Supervised classification approaches can predict labels for unknown data because of the supervised training process. The success of classification is heavily dependent on the labeled training data. Differently, clustering is effective in revealing the aggregation property of unlabeled data, but the performance of most clustering methods is limited by the absence of labeled data. In real applications, however, it is time-consuming and sometimes impossible to obtain labeled data. The combination of clustering and classification is a promising and active approach which can largely improve the performance. In this paper, we propose an innovative and effective clustering framework based on self-adaptive labeling (CSAL) which integrates clustering and classification on unlabeled data. Clustering is first employed to partition data and a certain proportion of clustered data are selected by our proposed labeling approach for training classifiers. In order to refine the trained classifiers, an iterative process of Expectation-Maximization algorithm is devised into the proposed clustering framework CSAL. Experiments are conducted on publicly data sets to test different combinations of clustering algorithms and classification models as well as various training data labeling methods. The experimental results show that our approach along with the self-adaptive method outperforms other methods.", "subjects": "Learning (cs.LG)", "authors": "Fangfang Li, Guandong Xu, Longbing Cao,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05110", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05110", "title": "\nCDStore: Toward Reliable, Secure, and Cost-Efficient Cloud Storage via  Convergent Dispersal", "abstract": "We present CDStore, which disperses users' backup data across multiple clouds and provides a unified multi-cloud storage solution with reliability, security, and cost-efficiency guarantees. CDStore builds on an augmented secret sharing scheme called convergent dispersal, which supports deduplication by using deterministic content-derived hashes as inputs to secret sharing. We present the design of CDStore, and in particular, describe how it combines convergent dispersal with two-stage deduplication to achieve both bandwidth and storage savings and be robust against side-channel attacks. We evaluate the performance of our CDStore prototype using real-world workloads on LAN and commercial cloud testbeds. Our cost analysis also demonstrates that CDStore achieves a monetary cost saving of 70% over a baseline cloud storage solution using state-of-the-art secret sharing.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Mingqiang Li, Chuan Qin, Patrick P. C. Lee,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05106", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05106", "title": "\n\"The Whole Is Greater Than the Sum of Its Parts\": Optimization in  Collaborative Crowdsourcing", "abstract": "In this work, we initiate the investigation of optimization opportunities in collaborative crowdsourcing. Many popular applications, such as collaborative document editing, sentence translation, or citizen science resort to this special form of human-based computing, where, crowd workers with appropriate skills and expertise are required to form groups to solve complex tasks. Central to any collaborative crowdsourcing process is the aspect of successful collaboration among the workers, which, for the first time, is formalized and then optimized in this work. Our formalism considers two main collaboration-related human factors, affinity and upper critical mass, appropriately adapted from organizational science and social theories. Our contributions are (a) proposing a comprehensive model for collaborative crowdsourcing optimization, (b) rigorous theoretical analyses to understand the hardness of the proposed problems, (c) an array of efficient exact and approximation algorithms with provable theoretical guarantees. Finally, we present a detailed set of experimental results stemming from two real-world collaborative crowdsourcing application us- ing Amazon Mechanical Turk, as well as conduct synthetic data analyses on scalability and qualitative aspects of our proposed algorithms. Our experimental results successfully demonstrate the efficacy of our proposed solutions.", "subjects": "Databases (cs.DB)", "authors": "Habibur Rahman, Senjuti Basu Roy, Saravanan Thirumuruganathan, Sihem Amer-Yahia, Gautam Das,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05102", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05102", "title": "\nEmergent Behavior in Cybersecurity", "abstract": "We argue that emergent behavior is inherent to cybersecurity.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Shouhuai Xu,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05100", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05100", "title": "\nCybersecurity Dynamics", "abstract": "We explore the emerging field of , a candidate foundation for the Science of Cybersecurity.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Shouhuai Xu,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05096", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05096", "title": "\nThe Behavior of Epidemics under Bounded Susceptibility", "abstract": "We investigate the sensitivity of epidemic behavior to a bounded susceptibility constraint -- susceptible nodes are infected by their neighbors via the regular SI/SIS dynamics, but subject to a cap on the infection rate. Such a constraint is motivated by modern social networks, wherein messages are broadcast to all neighbors, but attention spans are limited. Bounded susceptibility also arises in distributed computing applications with download bandwidth constraints, and in human epidemics under quarantine policies. Network epidemics have been extensively studied in literature; prior work characterizes the graph structures required to ensure fast spreading under the SI dynamics, and long lifetime under the SIS dynamics. In particular, these conditions turn out to be meaningful for two classes of networks of practical relevance -- dense, uniform (i.e., clique-like) graphs, and sparse, structured (i.e., star-like) graphs. We show that bounded susceptibility has a surprising impact on epidemic behavior in these graph families. For the SI dynamics, bounded susceptibility has no effect on star-like networks, but dramatically alters the spreading time in clique-like networks. In contrast, for the SIS dynamics, clique-like networks are unaffected, but star-like networks exhibit a sharp change in extinction times under bounded susceptibility. Our findings are useful for the design of disease-resistant networks and infrastructure networks. More generally, they show that results for existing epidemic models are sensitive to modeling assumptions in non-intuitive ways, and suggest caution in directly using these as guidelines for real systems.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Subhashini Krishnasamy, Siddhartha Banerjee, Sanjay Shakkottai,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05094", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05094", "title": "\nObservationally Cooperative Multithreading", "abstract": "Despite widespread interest in multicore computing, concur- rency models in mainstream languages often lead to subtle, error-prone code. Observationally Cooperative Multithreading (OCM) is a new approach to shared-memory parallelism. Programmers write code using the well-understood cooperative (i.e., nonpreemptive) multithreading model for uniprocessors. OCM then allows threads to run in parallel, so long as results remain consistent with the cooperative model. Programmers benefit because they can reason largely sequentially. Remaining interthread interactions are far less chaotic than in other models, permitting easier reasoning and debugging. Programmers can also defer the choice of concurrency-control mechanism (e.g., locks or transactions) until after they have written their programs, at which point they can compare concurrency-control strategies and choose the one that offers the best performance. Implementers and researchers also benefit from the agnostic nature of OCM -- it provides a level of abstraction to investigate, compare, and combine a variety of interesting concurrency-control techniques.", "subjects": "Programming Languages (cs.PL)", "authors": "Christopher A. Stone, Melissa E. O'Neill, Sonja A. Bohr, Adam M. Cozzette, M. Joe DeBlasio, Julia Matsieva, Stuart A. Pernsteiner, Ari D. Schumer,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05090", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05090", "title": "\nReal time clustering of time series using triangular potentials", "abstract": "Motivated by the problem of computing investment portfolio weightings we investigate various methods of clustering as alternatives to traditional mean-variance approaches. Such methods can have significant benefits from a practical point of view since they remove the need to invert a sample covariance matrix, which can suffer from estimation error and will almost certainly be non-stationary. The general idea is to find groups of assets which share similar return characteristics over time and treat each group as a single composite asset. We then apply inverse volatility weightings to these new composite assets. In the course of our investigation we devise a method of clustering based on triangular potentials and we present associated theoretical results as well as various examples based on synthetic data.", "subjects": "Learning (cs.LG)", "authors": "Aldo Pacchiano, Oliver Williams,", "date": "2015-2-18"}, 
{"urllink": "http://arxiv.org/abs/1502.05086", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05086", "title": "\nA Galois Connection for Valued Constraint Languages of Infinite Size", "abstract": "A Galois connection between clones and relational clones on a fixed finite domain is one of the cornerstones of the so-called algebraic approach to the computational complexity of non-uniform Constraint Satisfaction Problems (CSPs). Cohen et al. established a Galois connection between finitely-generated weighted clones and finitely-generated weighted relational clones [SICOMP'13], and asked whether this connection holds in general. We answer this question in the affirmative for weighted (relational) clones with real weights and show that the complexity of the corresponding Valued CSPs is preserved.", "subjects": "Computational Complexity (cs.CC)", "authors": "Peter Fulla, Stanislav Zivny,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.05082", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05082", "title": "\nWhat makes for effective detection proposals?", "abstract": "Current top performing object detectors employ detection proposals to guide the search for objects, thereby avoiding exhaustive sliding window search across images. Despite the popularity and widespread use of detection proposals, it is unclear which trade-offs are made when using them during object detection. We provide an in-depth analysis of twelve proposal methods along with four baselines regarding proposal repeatability, ground truth annotation recall on PASCAL and ImageNet, and impact on DPM and R-CNN detection performance. Our analysis shows that for object detection improving proposal localisation accuracy is as important as improving recall. We introduce a novel metric, the average recall (AR), which rewards both high recall and good localisation and correlates surprisingly well with detector performance. Our findings show common strengths and weaknesses of existing methods, and provide insights and metrics for selecting and tuning proposal methods.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Jan Hosang, Rodrigo Benenson, Piotr Doll\u00e1r, Bernt Schiele,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.05067", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05067", "title": "\nNode mixing and group structure of complex software networks", "abstract": "Large software projects are among most sophisticated human-made systems consisting of a network of interdependent parts. Past studies of software systems from the perspective of complex networks have already led to notable discoveries with different applications. Nevertheless, our comprehension of the structure of software networks remains to be only partial. We here investigate correlations or mixing between linked nodes and show that software networks reveal dichotomous node degree mixing similar to that recently observed in biological networks. We further show that software networks also reveal characteristic clustering profiles and mixing. Hence, node mixing in software networks significantly differs from that in, e.g., the Internet or social networks. We explain the observed mixing through the presence of groups of nodes with common linking pattern. More precisely, besides densely linked groups known as communities, software networks also consist of disconnected groups denoted modules, core/periphery structures and other. Moreover, groups coincide with the intrinsic properties of the underlying software projects, which promotes practical applications in software engineering.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Lovro \u0160ubelj, Slavko \u017ditnik, Neli Blagus, Marko Bajec,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.05061", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05061", "title": "\nNetwork-based statistical comparison of citation topology of  bibliographic databases", "abstract": "Modern bibliographic databases provide the basis for scientific research and its evaluation. While their content and structure differ substantially, there exist only informal notions on their reliability. Here we compare the topological consistency of citation networks extracted from six popular bibliographic databases including Web of Science, CiteSeer and arXiv.org. The networks are assessed through a rich set of local and global graph statistics. We first reveal statistically significant inconsistencies between some of the databases with respect to individual statistics. For example, the introduced field bow-tie decomposition of DBLP Computer Science Bibliography substantially differs from the rest due to the coverage of the database, while the citation information within arXiv.org is the most exhaustive. Finally, we compare the databases over multiple graph statistics using the critical difference diagram. The citation topology of DBLP Computer Science Bibliography is the least consistent with the rest, while, not surprisingly, Web of Science is significantly more reliable from the perspective of consistency. This work can serve either as a reference for scholars in bibliometrics and scientometrics or a scientific evaluation guideline for governments and research agencies.", "subjects": "Digital Libraries (cs.DL)", "authors": "Lovro \u0160ubelj, Dalibor Fiala, Marko Bajec,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.05058", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05058", "title": "\nTensor Spectral Clustering for Partitioning Higher-order Network  Structures", "abstract": "Spectral graph theory-based methods represent an important class of tools for studying the structure of networks. Spectral methods are based on a first-order Markov chain derived from a random walk on the graph and thus they cannot take advantage of important higher-order network substructures such as triangles, cycles, and feed-forward loops. Here we propose a Tensor Spectral Clustering (TSC) algorithm that allows for modeling higher-order network structures in a graph partitioning framework. Our TSC algorithm allows the user to specify which higher-order network structures (cycles, feed-forward loops, etc.) should be preserved by the network clustering. Higher-order network structures of interest are represented using a tensor, which we then partition by developing a multilinear spectral method. Our framework can be applied to discovering layered flows in networks as well as graph anomaly detection, which we illustrate on synthetic networks. In directed networks, a higher-order structure of particular interest is the directed 3-cycle, which captures feedback loops in networks. We demonstrate that our TSC algorithm produces large partitions that cut fewer directed 3-cycles than standard spectral clustering algorithms.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Austin R. Benson, David F. Gleich, Jure Leskovec,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.05056", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05056", "title": "\nOn Sex, Evolution, and the Multiplicative Weights Update Algorithm", "abstract": "We consider a recent innovative theory by Chastain et al. on the role of sex in evolution [PNAS'14]. In short, the theory suggests that the evolutionary process of gene recombination implements the celebrated multiplicative weights updates algorithm (MWUA). They prove that the population dynamics induced by sexual reproduction can be precisely modeled by genes that use MWUA as their learning strategy in a particular coordination game. The result holds in the environments of emph, under the assumption that the population frequencies remain a product distribution. We revisit the theory, eliminating both the requirement of weak selection and any assumption on the distribution of the population. Removing the assumption of product distributions is crucial, since as we show, this assumption is inconsistent with the population dynamics. We show that the marginal allele distributions induced by the population dynamics precisely match the marginals induced by a multiplicative weights update algorithm in this general setting, thereby affirming and substantially generalizing these earlier results. We further revise the implications for convergence and utility or fitness guarantees in coordination games. In contrast to the claim of Chastain et al.[PNAS'14], we conclude that the sexual evolutionary dynamics does not entail any property of the population distribution, beyond those already implied by convergence.", "subjects": "Learning (cs.LG)", "authors": "Reshef Meir, David Parkes,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.05040", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05040", "title": "\nDesign of a Framework to Facilitate Decisions Using Information Fusion", "abstract": "Information fusion is an advanced research area which can assist decision makers in enhancing their decisions. This paper aims at designing a new multi-layer framework that can support the process of performing decisions from the obtained beliefs using information fusion. Since it is not an easy task to cross the gap between computed beliefs of certain hypothesis and decisions, the proposed framework consists of the following layers in order to provide a suitable architecture (ordered bottom up): 1. A layer for combination of basic belief assignments using an information fusion approach. Such approach exploits Dezert-Smarandache Theory, DSmT, and proportional conflict redistribution to provide more realistic final beliefs. 2. A layer for computation of pignistic probability of the underlying propositions from the corresponding final beliefs. 3. A layer for performing probabilistic reasoning using a Bayesian network that can obtain the probable reason of a proposition from its pignistic probability. 4. Ranking the system decisions is ultimately used to support decision making. A case study has been accomplished at various operational conditions in order to prove the concept, in addition it pointed out that: 1. The use of DSmT for information fusion yields not only more realistic beliefs but also reliable pignistic probabilities for the underlying propositions. 2. Exploiting the pignistic probability for the integration of the information fusion with the Bayesian network provides probabilistic inference and enable decision making on the basis of both belief based probabilities for the underlying propositions and Bayesian based probabilities for the corresponding reasons. A comparative study of the proposed framework with respect to other information fusion systems confirms its superiority to support decision making.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Tamer M. Abo Neama, Ismail A. Ismail, Tarek S. Sobh, M. Zaki,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.05021", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.05021", "title": "\nInductive Learning for Rule Generation from Ontology", "abstract": "This paper presents an idea of inductive learning use for rule generation from ontologies. The main purpose of the paper is to evaluate the possibility of inductive learning use in rule generation from ontologies and to develop the way how this can be done. Generated rules are necessary to supplement or even to develop the Semantic Web Expert System (SWES) knowledge base. The SWES emerges as the result of evolution of expert system concept toward the Web, and the SWES is based on the Semantic Web technologies. Available publications show that the problem of rule generation from ontologies based on inductive learning is not investigated deeply enough.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Olegs Verhodubs,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04997", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04997", "title": "\nMeasuring Organizational Consciousness Through E-Mail Based Social  Network Analysis", "abstract": "This paper describes first experiments measuring organizational consciousness by comparing six \"honest signals\" of interpersonal communication within organizations with organizational metrics of performance.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Peter A. Gloor, Andrea Fronzetti Colladon,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04983", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04983", "title": "\nContext Tricks for Cheap Semantic Segmentation", "abstract": "Accurate semantic labeling of image pixels is difficult because intra-class variability is often greater than inter-class variability. In turn, fast semantic segmentation is hard because accurate models are usually too complicated to also run quickly at test-time. Our experience with building and running semantic segmentation systems has also shown a reasonably obvious bottleneck on model complexity, imposed by small training datasets. We therefore propose two simple complementary strategies that leverage context to give better semantic segmentation, while scaling up or down to train on different-sized datasets. As easy modifications for existing semantic segmentation algorithms, we introduce Decorrelated Semantic Texton Forests, and the Context Sensitive Image Level Prior. The proposed modifications are tested using a Semantic Texton Forest (STF) system, and the modifications are validated on two standard benchmark datasets, MSRC-21 and PascalVOC-2010. In Python based comparisons, our system is insignificantly slower than STF at test-time, yet produces superior semantic segmentations overall, with just push-button training.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Thanapong Intharah, Gabriel J. Brostow,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04981", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04981", "title": "\nSemi-supervised Segmentation Fusion of Multi-spectral and Aerial Images", "abstract": "A Semi-supervised Segmentation Fusion algorithm is proposed using consensus and distributed learning. The aim of Unsupervised Segmentation Fusion (USF) is to achieve a consensus among different segmentation outputs obtained from different segmentation algorithms by computing an approximate solution to the NP problem with less computational complexity. Semi-supervision is incorporated in USF using a new algorithm called Semi-supervised Segmentation Fusion (SSSF). In SSSF, side information about the co-occurrence of pixels in the same or different segments is formulated as the constraints of a convex optimization problem. The results of the experiments employed on artificial and real-world benchmark multi-spectral and aerial images show that the proposed algorithms perform better than the individual state-of-the art segmentation algorithms.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Mete Ozay,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.04980", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04980", "title": "\nAn Empirical Study of Finding Approximate Equilibria in Bimatrix Games", "abstract": "While there have been a number of studies about the efficacy of methods to find exact Nash equilibria in bimatrix games, there has been little empirical work on finding approximate Nash equilibria. Here we provide such a study that compares a number of approximation methods and exact methods. In particular, we explore the trade-off between the quality of approximate equilibrium and the required running time to find one. We found that the existing library GAMUT, which has been the de facto standard that has been used to test exact methods, is insufficient as a test bed for approximation methods since many of its games have pure equilibria or other easy-to-find good approximate equilibria. We extend the breadth and depth of our study by including new interesting families of bimatrix games, and studying bimatrix games upto size . Finally, we provide new close-to-worst-case examples for the best-performing algorithms for finding approximate Nash equilibria.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "John Fearnley, Tobenna Peter Igwe, Rahul Savani,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.04972", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04972", "title": "\nMeasuring and Understanding Sensory Representations within Deep Networks  Using a Numerical Optimization Framework", "abstract": "A central challenge in sensory neuroscience is describing how the activity of populations of neurons can represent useful features of the external environment. However, while neurophysiologists have long been able to record the responses of neurons in awake, behaving animals, it is another matter entirely to say what a given neuron does. A key problem is that in many sensory domains, the space of all possible stimuli that one might encounter is effectively infinite; in vision, for instance, natural scenes are combinatorially complex, and an organism will only encounter a tiny fraction of possible stimuli. As a result, even describing the response properties of sensory neurons is difficult, and investigations of neuronal functions are almost always critically limited by the number of stimuli that can be considered. In this paper, we propose a closed-loop, optimization-based experimental framework for characterizing the response properties of sensory neurons, building on past efforts in closed-loop experimental methods, and leveraging recent advances in artificial neural networks to serve as as a proving ground for our techniques. Specifically, using deep convolutional neural networks, we asked whether modern black-box optimization techniques can be used to interrogate the \"tuning landscape\" of an artificial neuron in a deep, nonlinear system, without imposing significant constraints on the space of stimuli under consideration. We introduce a series of measures to quantify the tuning landscapes, and show how these relate to the performances of the networks in an object recognition task. To the extent that deep convolutional neural networks increasingly serve as de facto working hypotheses for biological vision, we argue that developing a unified approach for studying both artificial and biological systems holds great potential to advance both fields together.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "Chuan-Yung Tsai, David D. Cox,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04963", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04963", "title": "\nExact bounds for distributed graph colouring", "abstract": "We prove exact bounds on the time complexity of distributed graph colouring. If we are given a directed path that is properly coloured with colours, by prior work it is known that we can find a proper 3-colouring in communication rounds. We close the gap between upper and lower bounds: we show that for infinitely many the time complexity is precisely communication rounds.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Joel Rybicki, Jukka Suomela,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.04956", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04956", "title": "\nThe Linearization of Pairwise Markov Networks", "abstract": "Belief Propagation (BP) allows to approximate exact probabilistic inference in graphical models, such as Markov networks (also called Markov random fields, or undirected graphical models). However, no exact convergence guarantees for BP are known, in general. Recent work has proposed to approximate BP by linearizing the update equations around default values for the special case when all edges in the Markov network carry the same symmetric, doubly stochastic potential. This linearization has led to exact convergence guarantees, considerable speed-up, while maintaining high quality results in network-based classification (i.e. when we only care about the most likely label or class for each node and not the exact probabilities). The present paper generalizes our prior work on Linearized Belief Propagation (LinBP) with an approach that approximates Loopy Belief Propagation on any pairwise Markov network with the problem of solving a linear equation system.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Wolfgang Gatterbauer,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04938", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04938", "title": "\nA Survey of Word Reordering in Statistical Machine Translation:  Computational Models and Language Phenomena", "abstract": "Word reordering is one of the most difficult aspects of statistical machine translation (SMT), and an important factor of its quality and efficiency. Despite the vast amount of research published to date, the interest of the community in this problem has not decreased, and no single method appears to be strongly dominant across language pairs. Instead, the choice of the optimal approach for a new translation task still seems to be mostly driven by empirical trials. To orientate the reader in this vast and complex research area, we present a comprehensive survey of word reordering viewed as a statistical modeling challenge and as a natural language phenomenon. The survey describes in detail how word reordering is modeled within different string-based and tree-based SMT frameworks and as a stand-alone task, including systematic overviews of the literature in advanced reordering modeling. We then question why some approaches are more successful than others in different language pairs. We argue that, besides measuring the amount of reordering, it is important to understand which kinds of reordering occur in a given language pair. To this end, we conduct a qualitative analysis of word reordering phenomena in a diverse sample of language pairs, based on a large collection of linguistic knowledge. Empirical results in the SMT literature are shown to support the hypothesis that a few linguistic facts can be very useful to anticipate the reordering characteristics of a language pair and to select the SMT framework that best suits them.", "subjects": "Computation and Language (cs.CL)", "authors": "Arianna Bisazza, Marcello Federico,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04933", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04933", "title": "\nBlock-Level Unitary Query: Incorporating Orthogonal-like Space-time Code  with Query Diversity for MIMO Backscatter RFID", "abstract": "Because of the emerging field of Internet of Things (IoT), future backscatter RFID is required to be more reliable and data intensive. Motivated by this, orthogonal space-time block code (OSTBC), which is very successful in mobile communications for its low complexity and high performance, has already been investigated for backscatter RFID. On the other hand, a recently proposed scheme called unitary query was shown to be able to considerably improve the reliability of backscatter radio by exploiting query diversity. Therefore incorporating the classical OSTBC (at the tag end) with the recently proposed unitary query (at the query end) seems to be promising. However, in this paper, we show that simple, direct employment of OSTBC together with unitary query incurs a linear decoding problem and eventually leads to a severe performance degradation. As a re-design of the recently proposed unitary query and the classical OSTBC specifically for MIMO backscatter RFID, we present a BUTQ-mOSTBC design pair idea by proposing the block-level unitary query (BUTQ) at the query end and the corresponding modified OSTBC (mOSTBC) at the tag end. The proposed BUTQ-mOSTBC can resolve the linear decoding problem, keep the simplicity and high performance properties of the classical OSTBC, and achieve the query diversity for the MIMO backscatter RFID channel.", "subjects": "Information Theory (cs.IT)", "authors": "Chen He, Z. Jane Wang, Victor C.M. Leung,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04925", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04925", "title": "\nPoint sets with many non-crossing matchings", "abstract": "The maximum number of non-crossing straight-line perfect matchings that a set of points in the plane can have is known to be and . The lower bound, due to Garc 'ia, Noy, and Tejel (2000) is attained by the double chain, which has such matchings. We reprove this bound in a simplified way that uses the novel notion of down-free matching, and apply this approach on several other constructions. As a result, we improve the lower bound. First we show that double zigzag chain with points has such matchings with . Next we analyze further generalizations of double zigzag chains - double -chains. The best choice of parameters leads to a construction with matchings, with . The derivation of this bound requires an analysis of a coupled dynamic-programming recursion between two infinite vectors.", "subjects": "Computational Geometry (cs.CG)", "authors": "Andrei Asinowski, G\u00fcnter Rote,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04918", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04918", "title": "\nA PTAS for the Weighted Unit Disk Cover Problem", "abstract": "We are given a set of weighted unit disks and a set of points in Euclidean plane. The minimum weight unit disk cover ( UDC) problem asks for a subset of disks of minimum total weight that covers all given points. UDC is one of the geometric set cover problems, which have been studied extensively for the past two decades (for many different geometric range spaces, such as (unit) disks, halfspaces, rectangles, triangles). It is known that the unweighted UDC problem is NP-hard and admits a polynomial-time approximation scheme (PTAS). For the weighted UDC problem, several constant approximations have been developed. However, whether the problem admits a PTAS has been an open question. In this paper, we answer this question affirmatively by presenting the first PTAS for UDC. Our result implies the first PTAS for the minimum weight dominating set problem in unit disk graphs. Combining with existing ideas, our result can also be used to obtain the first PTAS for the maxmimum lifetime coverage problem and an improved constant approximation ratio for the connected dominating set problem in unit disk graphs.", "subjects": "Computational Geometry (cs.CG)", "authors": "Jian Li, Yifei Jin,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04908", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04908", "title": "\nProgressive Transactional Memory in Time and Space", "abstract": "Transactional memory (TM) allows concurrent processes to organize sequences of operations on shared emph into atomic transactions. A transaction may commit, in which case it appears to have executed sequentially or it may emph, in which case no data item is updated. The TM programming paradigm emerged as an alternative to conventional fine-grained locking techniques, offering ease of programming and compositionality. Though typically themselves implemented using locks, TMs hide the inherent issues of lock-based synchronization behind a nice transactional programming interface. In this paper, we explore inherent time and space complexity of lock-based TMs, with a focus of the most popular class of emph lock-based TMs. We derive that a progressive TM might enforce a read-only transaction to perform a quadratic (in the number of the data items it reads) number of steps and access a linear number of distinct memory locations, closing the question of inherent cost of emph in TMs. We then show that the total number of emph (RMRs) that take place in an execution of a progressive TM in which concurrent processes perform transactions on a single data item might reach , which appears to be the first RMR complexity lower bound for transactional memory.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Petr Kuznetsov, Srivatsan Ravi,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04898", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04898", "title": "\nRecognisable languages over monads", "abstract": "The principle behind algebraic language theory for various kinds of structures, such as words or trees, is to use a compositional function from the structures into a finite set. To talk about compositionality, one needs some way of composing structures into bigger structures. It so happens that category theory has an abstract concept for this, namely a monad. The goal of this paper is to propose monads as a unifying framework for discussing existing algebras and designing new algebras.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Miko\u0142aj Boja\u0144czyk,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04896", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04896", "title": "\nOptimal non-adaptive solutions for the counterfeit coin problem", "abstract": "We give optimal solutions to all versions of the popular counterfeit coin problem obtained by varying whether (i) we know if the counterfeit coin is heavier or lighter than the genuine ones, (ii) we know if the counterfeit coin exists, (iii) we have access to additional genuine coins, and (iv) we need to determine if the counterfeit coin is heavier or lighter than the genuine ones. Moreover, our solutions are non-adaptive.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "C. Thach Nguyen,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04888", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04888", "title": "\nEquilibria Under the Probabilistic Serial Rule", "abstract": "The probabilistic serial (PS) rule is a prominent randomized rule for assigning indivisible goods to agents. Although it is well known for its good fairness and welfare properties, it is not strategyproof. In view of this, we address several fundamental questions regarding equilibria under PS. Firstly, we show that Nash deviations under the PS rule can cycle. Despite the possibilities of cycles, we prove that a pure Nash equilibrium is guaranteed to exist under the PS rule. We then show that verifying whether a given profile is a pure Nash equilibrium is coNP-complete, and computing a pure Nash equilibrium is NP-hard. For two agents, we present a linear-time algorithm to compute a pure Nash equilibrium which yields the same assignment as the truthful profile. Finally, we conduct experiments to evaluate the quality of the equilibria that exist under the PS rule, finding that the vast majority of pure Nash equilibria yield social welfare that is at least that of the truthful profile.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Haris Aziz, Serge Gaspers, Simon Mackenzie, Nicholas Mattei, Nina Narodytska, Toby Walsh,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04885", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04885", "title": "\nCount-Min-Log sketch: Approximately counting with approximate counters", "abstract": "Count-Min Sketch is a widely adopted algorithm for approximate event counting in large scale processing. However, the original version of the Count-Min-Sketch (CMS) suffers of some deficiences, especially if one is interested by the low-frequency items, such as in text-mining related tasks. Several variants of CMS have been proposed to compensate for the high relative error for low-frequency events, but the proposed solutions tend to correct the errors instead of preventing them. In this paper, we propose the Count-Min-Log sketch, which uses logarithm-based, approximate counters instead of linear counters to improve the average relative error of CMS at constant memory footprint.", "subjects": "Information Retrieval (cs.IR)", "authors": "Guillaume Pitel, Geoffroy Fouquier,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04870", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04870", "title": "\nEvaluation of Security Solutions for Android Systems", "abstract": "With the increasing usage of smartphones a plethora of security solutions are being designed and developed. Many of the security solutions fail to cope with advanced attacks and are not aways properly designed for smartphone platforms. Therefore, there is a need for a methodology to evaluate their effectiveness. Since the Android operating system has the highest market share today, we decided to focus on it in this study in which we review some of the state-of-the-art security solutions for Android-based smartphones. In addition, we present a set of evaluation criteria aiming at evaluating security mechanisms that are specifically designed for Android-based smartphones. We believe that the proposed framework will help security solution designers develop more effective solutions and assist security experts evaluate the effectiveness of security solutions for Android-based smartphones.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Asaf Shabtai, Dudu Mimran, Yuval Elovici,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04868", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04868", "title": "\nProper Complex Gaussian Processes for Regression", "abstract": "Complex-valued signals are used in the modeling of many systems in engineering and science, hence being of fundamental interest. Often, random complex-valued signals are considered to be proper. A proper complex random variable or process is uncorrelated with its complex conjugate. This assumption is a good model of the underlying physics in many problems, and simplifies the computations. While linear processing and neural networks have been widely studied for these signals, the development of complex-valued nonlinear kernel approaches remains an open problem. In this paper we propose Gaussian processes for regression as a framework to develop 1) a solution for proper complex-valued kernel regression and 2) the design of the reproducing kernel for complex-valued inputs, using the convolutional approach for cross-covariances. In this design we pay attention to preserve, in the complex domain, the measure of similarity between near inputs. The hyperparameters of the kernel are learned maximizing the marginal likelihood using Wirtinger derivatives. Besides, the approach is connected to the multiple output learning scenario. In the experiments included, we first solve a proper complex Gaussian process where the cross-covariance does not cancel, a challenging scenario when dealing with proper complex signals. Then we successfully use these novel results to solve some problems previously proposed in the literature as benchmarks, reporting a remarkable improvement in the estimation error.", "subjects": "Learning (cs.LG)", "authors": "Rafael Boloix-Tortosa, F. Javier Pay\u00e1n-Somet, Eva Arias-de-Reyna, Juan Jos\u00e9 Murillo-Fuentes,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.04861", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04861", "title": "\nRank-Two Beamforming and Power Allocation in Multicasting Relay Networks", "abstract": "In this paper, we propose a novel single-group multicasting relay beamforming scheme. We assume a source that transmits common messages via multiple amplify-and-forward relays to multiple destinations. To increase the number of degrees of freedom in the beamforming design, the relays process two received signals jointly and transmit the Alamouti space-time block code over two different beams. Furthermore, in contrast to the existing relay multicasting scheme of the literature, we take into account the direct links from the source to the destinations. We aim to maximize the lowest received quality-of-service by choosing the proper relay weights and the ideal distribution of the power resources in the network. To solve the corresponding optimization problem, we propose an iterative algorithm which solves sequences of convex approximations of the original non-convex optimization problem. Simulation results demonstrate significant performance improvements of the proposed methods as compared with the existing relay multicasting scheme of the literature and an algorithm based on the popular semidefinite relaxation technique.", "subjects": "Information Theory (cs.IT)", "authors": "Adrian Schad, Ka L. Law, Marius Pesavento,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04860", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04860", "title": "\nLow-Complexity QL-QR Decomposition Based Beamforming Design for Two-Way  MIMO Relay Networks", "abstract": "In this paper, we investigate the optimization problem of joint source and relay beamforming matrices for a twoway amplify-and-forward (AF) multi-input multi-output (MIMO) relay system. The system consisting of two source nodes and two relay nodes is considered and the linear minimum meansquare- error (MMSE) is employed at both receivers. We assume individual relay power constraints and study an important design problem, a so-called determinant maximization (DM) problem. Since this DM problem is nonconvex, we consider an efficient iterative algorithm by using an MSE balancing result to obtain at least a locally optimal solution. The proposed algorithm is developed based on QL, QR and Choleskey decompositions which differ in the complexity and performance. Analytical and simulation results show that the proposed algorithm can significantly reduce computational complexity compared with their existing two-way relay systems and have equivalent bit-error-rate (BER) performance to the singular value decomposition (SVD) based on a regular block diagonal (RBD) scheme.", "subjects": "Information Theory (cs.IT)", "authors": "Wei Duan, Wei Song, Moon Ho Lee,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04844", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04844", "title": "\nThe Complexity of Synthesis from Probabilistic Components", "abstract": "The synthesis problem asks for the automatic construction of a system from its specification. In the traditional setting, the system is \"constructed from scratch\" rather than composed from reusable components. However, this is rare in practice, and almost every non-trivial software system relies heavily on the use of libraries of reusable components. Recently, Lustig and Vardi introduced dataflow and controlflow synthesis from libraries of reusable components. They proved that dataflow synthesis is undecidable, while controlflow synthesis is decidable. The problem of controlflow synthesis from libraries of probabilistic components was considered by Nain, Lustig and Vardi, and was shown to be decidable for qualitative analysis (that asks that the specification be satisfied with probability 1). Our main contributions for controlflow synthesis from probabilistic components are to establish better complexity bounds for the qualitative analysis problem, and to show that the more general quantitative problem is undecidable. For the qualitative analysis, we show that the problem (i) is EXPTIME-complete when the specification is given as a deterministic parity word automaton, improving the previously known 2EXPTIME upper bound; and (ii) belongs to UP coUP and is parity-games hard, when the specification is given directly as a parity condition on the components, improving the previously known EXPTIME upper bound.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Krishnendu Chatterjee, Laurent Doyen, Moshe Y. Vardi,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04843", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04843", "title": "\nGeneralized Gradient Learning on Time Series under Elastic  Transformations", "abstract": "The majority of machine learning algorithms assumes that objects are represented as vectors. But often the objects we want to learn on are more naturally represented by other data structures such as sequences and time series. For these representations many standard learning algorithms are unavailable. We generalize gradient-based learning algorithms to time series under dynamic time warping. To this end, we introduce elastic functions, which extend functions on time series to matrix spaces. Necessary conditions are presented under which generalized gradient learning on time series is consistent. We indicate how results carry over to arbitrary elastic distance functions and to sequences consisting of symbolic elements. Specifically, four linear classifiers are extended to time series under dynamic time warping and applied to benchmark datasets. Results indicate that generalized gradient learning via elastic functions have the potential to complement the state-of-the-art in statistical pattern recognition on time series.", "subjects": "Learning (cs.LG)", "authors": "Brijnesh Jain,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04827", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04827", "title": "\nCorrigendum to \"Random grid-based visual secret sharing with abilities  of OR and XOR decryptions\"[Journal of Visual Communication and Image  Representation. 24(2013) 48-62]", "abstract": "It has been observed that the contrast values for (2, 3) VSS scheme, (2, 4) VSS scheme, (3, 5) VSS scheme and (4, 5) VSS scheme claimed by Wu and Sun (2013) are found to be incorrect. Since the same values are cited and compared by many other researchers in their works, we have calculated and presented the correct values of contrast in this note.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Saurabh Bora, Aparajita Ojha,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04824", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04824", "title": "\nRandomized LU decomposition: An Algorithm for Dictionaries Construction", "abstract": "In recent years, distinctive-dictionary construction has gained importance due to his usefulness in data processing. Usually, one or more dictionaries are constructed from a training data and then they are used to classify signals that did not participate in the training process. A new dictionary construction algorithm is introduced. It is based on a low-rank matrix factorization being achieved by the application of the randomized LU decomposition to a training data. This method is fast, scalable, parallelizable, consumes low memory, outperforms SVD in these categories and works also extremely well on large sparse matrices. In contrast to existing methods, the randomized LU decomposition constructs an under-complete dictionary, which simplifies both the construction and the classification processes of newly arrived signals. The dictionary construction is generic and general that fits different applications. We demonstrate the capabilities of this algorithm for file type identification, which is a fundamental task in digital security arena, performed nowadays for example by sandboxing mechanism, deep packet inspection, firewalls and anti-virus systems. We propose a content-based method that detects file types that neither depend on file extension nor on metadata. Such approach is harder to deceive and we show that only a few file fragments from a whole file are needed for a successful classification. Based on the constructed dictionaries, we show that the proposed method can effectively identify execution code fragments in PDF files. Dictionary construction, classification, LU decomposition, randomized LU decomposition, content-based file detection, computer security.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Aviv Rotbart, Gil Shabat, Yaniv Shmueli, Amir Averbuch,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04823", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04823", "title": "\nTopic Level Disambiguation for Weak Queries", "abstract": "Despite limited success, information retrieval (IR) systems today are not intelligent or reliable. IR systems return poor search results when users formulate their information needs into incomplete or ambiguous queries (i.e., weak queries). Therefore, one of the main challenges in modern IR research is to provide consistent results across all queries by improving the performance on weak queries. However, existing IR approaches such as query expansion are not overly effective because they make little effort to analyze and exploit the meanings of the queries. Furthermore, word sense disambiguation approaches, which rely on textual context, are ineffective against weak queries that are typically short. Motivated by the demand for a robust IR system that can consistently provide highly accurate results, the proposed study implemented a novel topic detection that leveraged both the language model and structural knowledge of Wikipedia and systematically evaluated the effect of query disambiguation and topic-based retrieval approaches on TREC collections. The results not only confirm the effectiveness of the proposed topic detection and topic-based retrieval approaches but also demonstrate that query disambiguation does not improve IR as expected.", "subjects": "Information Retrieval (cs.IR)", "authors": "Hui Zhang, Kiduk Yang, Elin Jacob,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04820", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04820", "title": "\nCryptanalysis of A Secure Remote User Authentication Scheme Using Smart  Cards", "abstract": "Smart card based authentication schemes are used in various fields like e-banking, e-commerce, wireless sensor networks, medical system and so on to authenticate the both remote user and the application server during the communication via internet. Recently, Karuppiah and Saravanan proposed an authentication scheme which is based on password and one-way cryptographic hash function. They have used a secure identity mechanism i.e., users' and server's identity are not public. Thus, the user and the server do not send their identity directly to each other during communications. In this paper, we have found out that their scheme does not overcome the reply attack and also there is a fault in the login phase, which makes their scheme is not perfect for practical use.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Tanmoy Maitra,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04806", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04806", "title": "\nOn the Noisy Feedback Capacity of Gaussian Broadcast Channels", "abstract": "It is well known that, in general, feedback may enlarge the capacity region of Gaussian broadcast channels. This has been demonstrated even when the feedback is noisy (or partial-but-perfect) and only from one of the receivers. The only case known where feedback has been shown not to enlarge the capacity region is when the channel is physically degraded (El Gamal 1978, 1981). In this paper, we show that for a class of two-user Gaussian broadcast channels (not necessarily physically degraded), passively feeding back the stronger user's signal over a link corrupted by Gaussian noise does not enlarge the capacity region if the variance of feedback noise is above a certain threshold.", "subjects": "Information Theory (cs.IT)", "authors": "Sibi Raj B. Pillai, Vinod M. Prabhakaran,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04803", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04803", "title": "\nReconfiguration on sparse graphs", "abstract": "A vertex-subset graph problem Q defines which subsets of the vertices of an input graph are feasible solutions. A reconfiguration variant of a vertex-subset problem asks, given two feasible solutions S and T of size k, whether it is possible to transform S into T by a sequence of vertex additions and deletions such that each intermediate set is also a feasible solution of size bounded by k. We study reconfiguration variants of two classical vertex-subset problems, namely Independent Set and Dominating Set. We denote the former by ISR and the latter by DSR. Both ISR and DSR are PSPACE-complete on graphs of bounded bandwidth and W[1]-hard parameterized by k on general graphs. We show that ISR is fixed-parameter tractable parameterized by k when the input graph is of bounded degeneracy or nowhere-dense. As a corollary, we answer positively an open question concerning the parameterized complexity of the problem on graphs of bounded treewidth. Moreover, our techniques generalize recent results showing that ISR is fixed-parameter tractable on planar graphs and graphs of bounded degree. For DSR, we show the problem fixed-parameter tractable parameterized by k when the input graph does not contain large bicliques, a class of graphs which includes graphs of bounded degeneracy and nowhere-dense graphs.", "subjects": "Computational Complexity (cs.CC)", "authors": "Daniel Lokshtanov, Amer E. Mouawad, Fahad Panolan, M.S. Ramanujan, Saket Saurabh,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04801", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04801", "title": "\nAn IDS scheme against Black hole Attack to Secure AOMDV Routing in MANET", "abstract": "In Mobile Ad hoc Network (MANET) all the nodes are freely moves in the absence of without ant centralized coordination system. Due to that the attackers or malicious nodes are easily affected that kind of network and responsible for the routing misbehavior. The routing is network is mandatory to deliver data in between source and destination. In this research we work on security field in MANET and proposed a novel security scheme against routing misbehavior through Black hole attack. The Ad hoc On demand Multipath Routing (AOMDV) protocol is consider for routing and also to improves the routing quality as compare to single path routing protocol. The attacker is affected all the possible paths that is selected by sender for sending data in network. The malicious nodes are forward optimistic reply at the time of routing by that their identification is also a complex procedure. The proposed Intrusion Detection System (IDS) scheme is identified the attacker information through hop count mechanism. The routing information of actual data is reached to which intermediate node and the next hop information is exist at that node is confirm by IDS scheme. The black hole attacker node Identification (ID) is forward in network by that in future attacker is not participating in routing procedure. The proposed security scheme detects and provides the deterrence against routing misbehavior through malicious attack. Here we compare the routing performance of AOMDV, Attack and IDS scheme. The performance of normal multipath routing and proposed IDS scheme is almost equal. The attacker has degrades the whole routing performance but observed that in presence of attacker, routing misbehavior is completely block by the proposed IDS scheme and recovers 95 % of data as compare to normal routing. Keywords- -AOMDV, MANET, IDS, Black hole attack, Routing misbehavior.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Sonal Shrivastava, Chetan Agrawal, Anurag Jain,", "date": "2015-2-14"}, 
{"urllink": "http://arxiv.org/abs/1502.04798", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04798", "title": "\nTechnical solutions to resources allocation for distributed virtual  machine systems", "abstract": "Virtual machine is built on group of real servers which are scattered globally and connect together through the telecommunications systems, it has an increasingly important role in the operation, providing the ability to exploit virtual resources. The latest technique helps to use computing resources more effectively and has many benefits, such as cost reduction of power, cooling and, hence, contributes to the Green Computing. To ensure the supply of these resources to demand processes correctly and promptly, avoiding any duplication or conflict, especially remote resources, it is necessary to study and propose a reliable solution appropriate to be the foundation for internal control systems in the cloud. In the scope of this paper, we find a way to produce efficient distributed resources which emphasizes solutions preventing deadlock and proposing methods to avoid resource shortage issue. With this approach, the outcome result is the checklist of re-sources state which has the possibility of deadlock and lack of resources, by sending messages to the servers, the server would know the situation and have corresponding reaction.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Ha Huy Cuong Nguyen, Van Thuan Dang, Van Son Le,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04797", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04797", "title": "\nImpact of network size on the performance of incremental LMS adaptive  networks", "abstract": "In this paper we study the impact of network size on the performance of incremental least mean square (ILMS) adaptive networks. Specifically, we consider two ILMS networks with different number of nodes and compare their performance in two different cases including (i) ideal links and (ii) noisy links. We show that when the links between nodes are ideal, increasing the network size improves the steady-state error. On the other hand, in the presence of noisy links, we see different behavior and the ILMS adaptive network with more nodes necessarily has not better steady-state performance. Simulation results are also provided to illustrate the discussions.", "subjects": "Information Theory (cs.IT)", "authors": "Azam Khalili, Amir Rastegarnia,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04791", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04791", "title": "\nAdvances in Artificial Intelligence: Are you sure, we are on the right  track?", "abstract": "Over the past decade, AI has made a remarkable progress. It is agreed that this is due to the recently revived Deep Learning technology. Deep Learning enables to process large amounts of data using simplified neuron networks that simulate the way in which the brain works. However, there is a different point of view, which posits that the brain is processing information, not data. This unresolved duality hampered AI progress for years. In this paper, I propose a notion of Integrated information that hopefully will resolve the problem. I consider integrated information as a coupling between two separate entities - physical information (that implies data processing) and semantic information (that provides physical information interpretation). In this regard, intelligence becomes a product of information processing. Extending further this line of thinking, it can be said that information processing does not require more a human brain for its implementation. Indeed, bacteria and amoebas exhibit intelligent behavior without any sign of a brain. That dramatically removes the need for AI systems to emulate the human brain complexity! The paper tries to explore this shift in AI systems design philosophy.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Emanuel Diamant,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04780", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04780", "title": "\nComputational Curiosity (A Book Draft)", "abstract": "This book discusses computational curiosity, from the psychology of curiosity to the computational models of curiosity, and then showcases several interesting applications of computational curiosity. A brief overview of the book is given as follows. Chapter 1 discusses the underpinnings of curiosity in human beings, including the major categories of curiosity, curiosity-related emotions and behaviors, and the benefits of curiosity. Chapter 2 reviews the arousal theories of curiosity in psychology and summarizes a general two-step process model for computational curiosity. Base on the perspective of the two-step process model, Chapter 3 reviews and analyzes some of the traditional computational models of curiosity. Chapter 4 introduces a novel generic computational model of curiosity, which is developed based on the arousal theories of curiosity. After the discussion of computational models of curiosity, we outline the important applications where computational curiosity may bring significant impacts in Chapter 5. Chapter 6 discusses the application of the generic computational model of curiosity in a machine learning framework. Chapter 7 discusses the application of the generic computational model of curiosity in a recommender system. In Chapter 8 and Chapter 9, the generic computational model of curiosity is studied in two types of pedagogical agents. In Chapter 8, a curious peer learner is studied. It is a non-player character that aims to provide a believable virtual learning environment for users. In Chapter 9, a curious learning companion is studied. It aims to enhance users' learning experience through providing meaningful interactions with them. Chapter 10 discusses open questions in the research field of computation curiosity.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Qiong Wu,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04775", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04775", "title": "\nGeometry of Resource Interaction - A Minimalist Approach", "abstract": "The Resource -calculus is a variation of the -calculus where arguments can be superposed and must be linearly used. Hence it is a model for linear and non-deterministic programming languages, and the target language of Ehrhard-Taylor expansion of -terms. In a strictly typed restriction of the Resource -calculus, we study the notion of path persistence, and we define a Geometry of Interaction that characterises it, is invariant under reduction, and counts addends in normal forms.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Marco Solieri,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04774", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04774", "title": "\nWave-Style Token Machines and Quantum Lambda Calculi", "abstract": "Particle-style token machines are a way to interpret proofs and programs, when the latter are written following the principles of linear logic. In this paper, we show that token machines also make sense when the programs at hand are those of a simple quantum lambda-calculus with implicit qubits. This, however, requires generalising the concept of a token machine to one in which more than one particle travel around the term at the same time. The presence of multiple tokens is intimately related to entanglement and allows us to give a simple operational semantics to the calculus, coherently with the principles of quantum computation.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Ugo Dal Lago, Margherita Zorzi,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04773", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04773", "title": "\nLudics without Designs I: Triads", "abstract": "In this paper, we introduce the concept of triad. Using this notion, we study, revisit, discover and rediscover some basic properties of ludics from a very general point of view.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Michele Basaldella,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04772", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04772", "title": "\nType Classes for Lightweight Substructural Types", "abstract": "Linear and substructural types are powerful tools, but adding them to standard functional programming languages often means introducing extra annotations and typing machinery. We propose a lightweight substructural type system design that recasts the structural rules of weakening and contraction as type classes; we demonstrate this design in a prototype language, Clamp. Clamp supports polymorphic substructural types as well as an expressive system of mutable references. At the same time, it adds little additional overhead to a standard Damas-Hindley-Milner type system enriched with type classes. We have established type safety for the core model and implemented a type checker with type inference in Haskell.", "subjects": "Programming Languages (cs.PL)", "authors": "Edward Gan, Jesse A. Tov, Greg Morrisett,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04771", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04771", "title": "\nCut Elimination in Multifocused Linear Logic", "abstract": "We study cut elimination for a multifocused variant of full linear logic in the sequent calculus. The multifocused normal form of proofs yields problems that do not appear in a standard focused system, related to the constraints in grouping rule instances in focusing phases. We show that cut elimination can be performed in a sensible way even though the proof requires some specific lemmas to deal with multifocusing phases, and discuss the difficulties arising with cut elimination when considering normal forms of proofs in linear logic.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Taus Brock-Nannestad, Nicolas Guenot,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04770", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04770", "title": "\nA Linear/Producer/Consumer Model of Classical Linear Logic", "abstract": "This paper defines a new proof- and category-theoretic framework for classical linear logic that separates reasoning into one linear regime and two persistent regimes corresponding to ! and ?. The resulting linear/producer/consumer (LPC) logic puts the three classes of propositions on the same semantic footing, following Benton's linear/non-linear formulation of intuitionistic linear logic. Semantically, LPC corresponds to a system of three categories connected by adjunctions reflecting the linear/producer/consumer structure. The paper's metatheoretic results include admissibility theorems for the cut and duality rules, and a translation of the LPC logic into category theory. The work also presents several concrete instances of the LPC model.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Jennifer Paykin, Steve Zdancewic,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04769", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04769", "title": "\nUndecidability of Multiplicative Subexponential Logic", "abstract": "Subexponential logic is a variant of linear logic with a family of exponential connectives\u00e2\u0080\u0094called subexponentials\u00e2\u0080\u0094that are indexed and arranged in a pre-order. Each subexponential has or lacks associated structural properties of weakening and contraction. We show that classical propositional multiplicative linear logic extended with one unrestricted and two incomparable linear subexponentials can encode the halting problem for two register Minsky machines, and is hence undecidable.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Kaustuv Chaudhuri,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04754", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04754", "title": "\n3D Structure from Detections", "abstract": "We present a novel method to infer, in closed-form, the 3D spatial occupancy of a collection of rigid objects given 2D image detections from a sequence of images. In particular, starting from 2D ellipses fitted to bounding boxes, this novel multi-view problem can be reformulated as the estimation of a quadric (ellipsoid) in 3D. We show that an efficient solution exists in the dual-space using a minimum of three views. This algebraic solution can be negatively affected in the presence of gross inaccuracies in the bounding boxes estimation. To this end, we also propose a robust regularization method and a robust ellipse fitting algorithm able to improve performance in the presence of errors in the detected objects. Results on synthetic tests and on different real datasets, involving real challenging scenarios, demonstrate the applicability and potential of our method.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Cosimo Rubino, Marco Crocco, Alessandro Perina, Vittorio Murino, Alessio Del Bue,", "date": "2015-2-17"}, 
{"urllink": "http://arxiv.org/abs/1502.04749", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04749", "title": "\nImproved Monte Carlo Variance Reduction for Space and Energy  Self-Shielding", "abstract": "Continued demand for accurate and computationally efficient transport methods to solve optically thick, fixed-source transport problems has inspired research on variance-reduction (VR) techniques for Monte Carlo (MC). Methods that use deterministic results to create VR maps for MC constitute a dominant branch of this research, with Forward Weighted-Consistent Adjoint Driven Importance Sampling (FW-CADIS) being a particularly successful example. However, locations in which energy and spatial self-shielding are combined, such as thin plates embedded in concrete, challenge FW-CADIS. In these cases the deterministic flux cannot appropriately capture transport behavior, and the associated VR parameters result in high variance in and following the plate. This work presents a new method that improves performance in transport calculations that contain regions of combined space and energy self-shielding without significant impact on the solution quality in other parts of the problem. This method is based on FW-CADIS and applies a Resonance Factor correction to the adjoint source. The impact of the Resonance Factor method is investigated in this work through an example problem. It is clear that this new method dramatically improves performance in terms of lowering the maximum 95% confidence interval relative error and reducing the compute time. Based on this work, we recommend that the Resonance Factor method be used when the accuracy of the solution in the presence of combined space and energy self-shielding is important.", "subjects": "Numerical Analysis (cs.NA)", "authors": "S. C. Wilson, R. N. Slaybaugh,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04748", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04748", "title": "\nThe Takeoff Towards Optimal Sorting Networks", "abstract": "A complete set of filters for the optimal-depth -input sorting network problem is such that if there exists an -input sorting network of depth then there exists one of the form for some . Previous work on the topic presents a method for finding complete set of filters and that consists only of networks of depths one and two respectively, whose outputs are minimal and representative up to permutation and reflection. Our main contribution is a practical approach for finding a complete set of filters containing only networks of depth three whose outputs are minimal and representative up to permutation and reflection. In previous work, we have developed a highly efficient algorithm for finding extremal sets ( i.e. outputs of comparator networks; itemsets; ) up to permutation. In this paper we present a modification to this algorithm that identifies the representative itemsets up to permutation and reflection. Hence, the presented practical approach is the successful combination of known theory and practice that we apply to the domain of sorting networks. For , we empirically compute the complete set of filters , , and of the representative minimal up to permutation and reflection -input networks, where all but are novel to this work.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Martin Marinov, David Gregg,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.04744", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04744", "title": "\nWhere's My Drink? Enabling Peripheral Real World Interactions While  Using HMDs", "abstract": "Head Mounted Displays (HMDs) allow users to experience virtual reality with a great level of immersion. However, even simple physical tasks like drinking a beverage can be difficult and awkward while in a virtual reality experience. We explore mixed reality renderings that selectively incorporate the physical world into the virtual world for interactions with physical objects. We conducted a user study comparing four rendering techniques that balances immersion in a virtual world with ease of interaction with the physical world. Finally, we discuss the pros and cons of each approach, suggesting guidelines for future rendering techniques that bring physical objects into virtual reality.", "subjects": "Human-Computer Interaction (cs.HC)", "authors": "Pulkit Budhiraja, Rajinder Sodhi, Brett Jones, Kevin Karsch, Brian Bailey, David Forsyth,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04727", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04727", "title": "\nWireless Power Transfer: Survey and Roadmap", "abstract": "Wireless power transfer (WPT) technologies have been widely used in many areas, e.g., the charging of electric toothbrush, mobile phones, and electric vehicles. This paper introduces fundamental principles of three WPT technologies, i.e., inductive coupling-based WPT, magnetic resonant coupling-based WPT, and electromagnetic radiation-based WPT, together with discussions of their strengths and weaknesses. Main research themes are then presented, i.e., improving the transmission efficiency and distance, and designing multiple transmitters/receivers. The state-of-the-art techniques are reviewed and categorised. Several WPT applications are described. Open research challenges are then presented with a brief discussion of potential roadmap.", "subjects": "Information Theory (cs.IT)", "authors": "Xiaolin Mou, Hongjian Sun,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04696", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04696", "title": "\nEnhancing Information Awareness Through Directed Qualification of  Semantic Relevancy Scoring Operations", "abstract": "Successfully managing analytics-based semantic relationships and their provenance enables determinations of document importance and priority, furthering capabilities for machine-based relevancy scoring operations. Semantic technologies are well suited for modeling explicit and fully qualified relationships but struggle with modeling relationships that are qualified in nature, or resultant from applied analytics. Our work seeks to implement the autonomous Directed Qualification of analytic-based relationships by pairing the Prov-O Ontology (W3C Recommendation) with a relevancy ontology supporting analytics terminology. This work results in the capability for any semantically referenced document, concept, or named graph to be associated with the results of applied analytics as Direct Qualification (DQ) modeled relational nodes. This new capability will enable role, identity, or any other content-based measures of relevancy and analytics-based metrics for semantically described documents.", "subjects": "Information Retrieval (cs.IR)", "authors": "Jason Bryant, Gregory Hasseler, Timothy Lebo, Matthew Paulini,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04689", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04689", "title": "\nExact tensor completion using t-SVD", "abstract": "In this paper we focus on the problem of completion of multidimensional arrays (also referred to as tensors) from limited sampling. Our approach is based on a recently proposed tensor-Singular Value Decomposition (t-SVD) [1]. Using this factorization one can derive notion of tensor rank, referred to as the tensor tubal rank, which has optimality properties similar to that of matrix rank derived from SVD. As shown in [2] some multidimensional data, such as panning video sequences exhibit low tensor tubal rank and we look at the problem of completing such data under random sampling of the data cube. We show that by solving a convex optimization problem, which minimizes the tensor nuclear norm obtained as the convex relaxation of tensor tubal rank, one can guarantee recovery with overwhelming probability as long as samples in proportion to the degrees of freedom in t-SVD are observed. In this sense our results are order-wise optimal. The conditions under which this result holds are very similar to the incoherency conditions for the matrix completion, albeit we define incoherency under the algebraic set-up of t-SVD. We show the performance of the algorithm on some real data sets and compare it with other existing approaches based on tensor flattening and Tucker decomposition.", "subjects": "Learning (cs.LG)", "authors": "Zemin Zhang, Shuchin Aeron,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.04687", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04687", "title": "\nPhysical Biomodeling: a new field enabled by 3-D printing in biomodeling", "abstract": "3D printing technology opens the door for a new field at the intersection of experimental data, computational biology and physical modeling for study of biological systems, such as protein folding at nano-scale. Key insights: * 3D-printing enabled new possibilities for scientific modeling: We explore a new domain of precision physical modeling and correlate it with existing visualization and computational systems. * Dynamic physical models of biomolecular models can be designed to- scale that can serve as research tools along with existing biocomputational tools and databases. * Accurate physical modeling with 3D-printing techniques will lead to new approaches to study dynamics of biological systems complementing computational methods.", "subjects": "Other Computer Science (cs.OH)", "authors": "Promita Chakraborty,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04681", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04681", "title": "\nUnsupervised Learning of Video Representations using LSTMs", "abstract": "We use multilayer Long Short Term Memory (LSTM) networks to learn representations of video sequences. Our model uses an encoder LSTM to map an input sequence into a fixed length representation. This representation is decoded using single or multiple decoder LSTMs to perform different tasks, such as reconstructing the input sequence, or predicting the future sequence. We experiment with two kinds of input sequences - patches of image pixels and high-level representations (\"percepts\") of video frames extracted using a pretrained convolutional net. We explore different design choices such as whether the decoder LSTMs should condition on the generated output. We analyze the outputs of the model qualitatively to see how well the model can extrapolate the learned video representation into the future and into the past. We try to visualize and interpret the learned features. We stress test the model by running it on longer time scales and on out-of-domain data. We further evaluate the representations by finetuning them for a supervised learning problem - human action recognition on the UCF-101 and HMDB-51 datasets. We show that the representations help improve classification accuracy, especially when there are only a few training examples. Even models pretrained on unrelated datasets (300 hours of YouTube videos) can help action recognition performance.", "subjects": "Learning (cs.LG)", "authors": "Nitish Srivastava, Elman Mansimov, Ruslan Salakhutdinov,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04676", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04676", "title": "\nOptimal Scanning Bandwidth Strategy Incorporating Uncertainty about  Adversary's Characteristics", "abstract": "In this paper we investigate the problem of designing a spectrum scanning strategy to detect an intelligent Invader who wants to utilize spectrum undetected for his/her unapproved purposes. To deal with this problem we model the situation as two games, between a Scanner and an Invader, and solve them sequentially. The first game is formulated to design the optimal (in maxmin sense) scanning algorithm, while the second one allows one to find the optimal values of the parameters for the algorithm depending on parameters of the network. These games provide solutions for two dilemmas that the rivals face. The Invader's dilemma consists of the following: the more bandwidth the Invader attempts to use leads to a larger payoff if he is not detected, but at the same time also increases the probability of being detected and thus fined. Similarly, the Scanner faces a dilemma: the wider the bandwidth scanned, the higher the probability of detecting the Invader, but at the expense of increasing the cost of building the scanning system. The equilibrium strategies are found explicitly and reveal interesting properties. In particular, we have found a discontinuous dependence of the equilibrium strategies on the network parameters, fine and the type of the Invader's award. This discontinuity of the fine means that the network provider has to take into account a human/social factor since some threshold values of fine could be very sensible for the Invader, while in other situations simply increasing the fine has minimal deterrence impact. Also we show how incomplete information about the Invader's technical characteristics and reward (e.g. motivated by using different type of application, say, video-streaming or downloading files) can be incorporated into scanning strategy to increase its efficiency.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Andrey Garnaev, Wade Trappe,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04666", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04666", "title": "\nOn Crowdsourced Interactive Live Streaming: A Twitch.TV-Based  Measurement Study", "abstract": "Empowered by today's rich tools for media generation and collaborative production, the multimedia service paradigm is shifting from the conventional single source, to multi-source, to many sources, and now toward . Such crowdsourced live streaming platforms as Twitch.tv allow general users to broadcast their content to massive viewers, thereby greatly expanding the content and user bases. The resources available for these non-professional broadcasters however are limited and unstable, which potentially impair the streaming quality and viewers' experience. The diverse live interactions among the broadcasters and viewers can further aggravate the problem. In this paper, we present an initial investigation on the modern crowdsourced live streaming systems. Taking Twitch as a representative, we outline their inside architecture using both crawled data and captured traffic of local broadcasters/viewers. Closely examining the access data collected in a two-month period, we reveal that the view patterns are determined by both events and broadcasters' sources. Our measurements explore the unique source- and event-driven views, showing that the current delay strategy on the viewer's side substantially impacts the viewers' interactive experience, and there is significant disparity between the long broadcast latency and the short live messaging latency. On the broadcaster's side, the dynamic uploading capacity is a critical challenge, which noticeably affects the smoothness of live streaming for viewers.", "subjects": "Multimedia (cs.MM)", "authors": "Cong Zhang, Jiangchuan Liu,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.04665", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04665", "title": "\nOptimizations for Decision Making and Planning in Description Logic  Dynamic Knowledge Bases", "abstract": "Artifact-centric models for business processes recently raised a lot of attention as they manage to combine structural (i.e. data related) with dynamical (i.e. process related) aspects in a seamless way. This developed in parallel with declarative approaches for modelling processes, where activities are not burdened by over-specified constrains like in traditional process-centric approaches, but try to adapt the internal system to the humans involved and the input they receive. In this paper, we try to merge these two aspects by proposing a framework aimed at describing rich business domains through Description Logic-based ontologies, and where a set of actions allows the system to evolve by modifying such ontologies. We then propose an evolution of such framework by introducing action rewriting and knowledge partialization: the resulting framework represents a viable and formal environment to develop decision making and planning techniques for DL-based artifact-centric business domains.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Michele Stawowy,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.04662", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04662", "title": "\nTimeMachine: Timeline Generation for Knowledge-Base Entities", "abstract": "We present a method called TIMEMACHINE to generate a timeline of events and relations for entities in a knowledge base. For example for an actor, such a timeline should show the most important professional and personal milestones and relationships such as works, awards, collaborations, and family relationships. We develop three orthogonal timeline quality criteria that an ideal timeline should satisfy: (1) it shows events that are relevant to the entity; (2) it shows events that are temporally diverse, so they distribute along the time axis, avoiding visual crowding and allowing for easy user interaction, such as zooming in and out; and (3) it shows events that are content diverse, so they contain many different types of events (e.g., for an actor, it should show movies and marriages and awards, not just movies). We present an algorithm to generate such timelines for a given time period and screen size, based on submodular optimization and web-co-occurrence statistics with provable performance guarantees. A series of user studies using Mechanical Turk shows that all three quality criteria are crucial to produce quality timelines and that our algorithm significantly outperforms various baseline and state-of-the-art methods.", "subjects": "Databases (cs.DB)", "authors": "Tim Althoff, Xin Luna Dong, Kevin Murphy, Safa Alai, Van Dang, Wei Zhang,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.04661", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04661", "title": "\nExperimental Characterization of a Bearing-only Sensor for Use With the  PHD Filter", "abstract": "This report outlines the procedure and results of an experiment to characterize a bearing-only sensor for use with PHD filter. The resulting detection, measurement, and clutter models are used for hardware and simulated experiments with a team of mobile robots autonomously seeking an unknown number of objects of interest in an office environment.", "subjects": "Robotics (cs.RO)", "authors": "Philip Dames, Vijay Kumar,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04658", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04658", "title": "\nHEp-2 Cell Classification via Fusing Texture and Shape Information", "abstract": "Indirect Immunofluorescence (IIF) HEp-2 cell image is an effective evidence for diagnosis of autoimmune diseases. Recently computer-aided diagnosis of autoimmune diseases by IIF HEp-2 cell classification has attracted great attention. However the HEp-2 cell classification task is quite challenging due to large intra-class variation and small between-class variation. In this paper we propose an effective and efficient approach for the automatic classification of IIF HEp-2 cell image by fusing multi-resolution texture information and richer shape information. To be specific, we propose to: a) capture the multi-resolution texture information by a novel Pairwise Rotation Invariant Co-occurrence of Local Gabor Binary Pattern (PRICoLGBP) descriptor, b) depict the richer shape information by using an Improved Fisher Vector (IFV) model with RootSIFT features which are sampled from large image patches in multiple scales, and c) combine them properly. We evaluate systematically the proposed approach on the IEEE International Conference on Pattern Recognition (ICPR) 2012, IEEE International Conference on Image Processing (ICIP) 2013 and ICPR 2014 contest data sets. The experimental results for the proposed methods significantly outperform the winners of ICPR 2012 and ICIP 2013 contest, and achieve comparable performance with the winner of the newly released ICPR 2014 contest.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Xianbiao Qi, Guoying Zhao, Chun-Guang Li, Jun Guo, Matti Pietik\u00e4inen,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04653", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04653", "title": "\nRewriting Higher-Order Stack Trees", "abstract": "Higher-order pushdown systems and ground tree rewriting systems can be seen as extensions of suffix word rewriting systems. Both classes generate infinite graphs with interesting logical properties. Indeed, the model-checking problem for monadic second order logic (respectively first order logic with a reachability predicate) is decidable on such graphs. We unify both models by introducing the notion of stack trees, trees whose nodes are labelled by higher-order stacks, and define the corresponding class of higher-order ground tree rewriting systems. We show that these graphs retain the decidability properties of ground tree rewriting graphs while generalising the pushdown hierarchy of graphs.", "subjects": "Formal Languages and Automata Theory (cs.FL)", "authors": "Vincent Penelle,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04652", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04652", "title": "\nInferring 3D Object Pose in RGB-D Images", "abstract": "The goal of this work is to replace objects in an RGB-D scene with corresponding 3D models from a library. We approach this problem by first detecting and segmenting object instances in the scene using the approach from Gupta et al. [13]. We use a convolutional neural network (CNN) to predict the pose of the object. This CNN is trained using pixel normals in images containing rendered synthetic objects. When tested on real data, it outperforms alternative algorithms trained on real data. We then use this coarse pose estimate along with the inferred pixel support to align a small number of prototypical models to the data, and place the model that fits the best into the scene. We observe a 48% relative improvement in performance at the task of 3D detection over the current state-of-the-art [33], while being an order of magnitude faster at the same time.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Saurabh Gupta, Pablo Arbel\u00e1ez, Ross Girshick, Jitendra Malik,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04650", "category": "Computer Science ", "pdflink": "http://arxiv.org/e-print/1502.04650", "title": "\nLower Bound for General Circuits Computing Clique Function", "abstract": "We prove an exponential lower bound for general circuits computing the clique function and hereby confirm that NP != P.", "subjects": "Computational Complexity (cs.CC)", "authors": "Weimin Chen,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.04649", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04649", "title": "\nNoisy Channel-Output Feedback Capacity of the Linear Deterministic  Interference Channel", "abstract": "In this paper, the capacity region of the two-user linear deterministic (LD) interference channel with noisy output feedback (IC-NOF) is fully characterized. This result allows the identification of several asymmetric scenarios in which imple- menting channel-output feedback in only one of the transmitter- receiver pairs is as beneficial as implementing it in both links, in terms of achievable individual rate and sum-rate improvements w.r.t. the case without feedback. In other scenarios, the use of channel-output feedback in any of the transmitter-receiver pairs benefits only one of the two pairs in terms of achievable individual rate improvements or simply, it turns out to be useless, i.e., the capacity regions with and without feedback turn out to be identical even in the full absence of noise in the feedback links.", "subjects": "Information Theory (cs.IT)", "authors": "Victor Quintero, Samir M. Perlaza, Jean-Marie Gorce,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04645", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04645", "title": "\nSynthesis of Attributed Feature Models From Product Descriptions:  Foundations", "abstract": "Feature modeling is a widely used formalism to characterize a set of products (also called configurations). As a manual elaboration is a long and arduous task, numerous techniques have been proposed to reverse engineer feature models from various kinds of artefacts. But none of them synthesize feature attributes (or constraints over attributes) despite the practical relevance of attributes for documenting the different values across a range of products. In this report, we develop an algorithm for synthesizing attributed feature models given a set of product descriptions. We present sound, complete, and parametrizable techniques for computing all possible hierarchies, feature groups, placements of feature attributes, domain values, and constraints. We perform a complexity analysis w.r.t. number of features, attributes, configurations, and domain size. We also evaluate the scalability of our synthesis procedure using randomized configuration matrices. This report is a first step that aims to describe the foundations for synthesizing attributed feature models.", "subjects": "Software Engineering (cs.SE)", "authors": "Guillaume B\u00e9can, Razieh Behjati, Arnaud Gotlieb, Mathieu Acher,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04644", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04644", "title": "\nBeyond the Runs Theorem", "abstract": "Recently, a short and elegant proof was presented showing that a binary word of length contains at most runs. Here we show, using the same technique and a computer search, that the number of runs in a binary word of length is at most .", "subjects": "Formal Languages and Automata Theory (cs.FL)", "authors": "\u0160t\u011bp\u00e1n Holub,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04634", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04634", "title": "\nThe Exp-Log Normal Form of Types and Canonical Terms for Lambda Calculus  with Sums", "abstract": "In the presence of sum types, the eta-long beta-normal form of terms of lambda calculus is not canonical. Natural deduction systems for intuitionistic logic (with disjunction) suffer the same defect, thanks to the Curry-Howard correspondence. This canonicity problem has been open in Proof Theory since the 1960s, while it has been addressed in Computer Science, since the 1990s, by a number of authors using decision procedures: instead of deriving a notion of syntactic canonical normal form, one gives a procedure based on program analysis to decide when any two terms of the lambda calculus with sum types are essentially the same one. In this paper, we show the canonicity problem is difficult because it is too specialized: rather then picking a canonical representative out of a class of beta-eta-equal terms of a given type, one should do so for the enlarged class of terms that are of a type isomorphic to the given one. We isolate a type normal form, ENF, generalizing the usual disjunctive normal form to handle exponentials, and we show that the eta-long beta-normal form of terms at ENF type is canonical, when the eta axiom for sums is expressed via evaluation contexts. By coercing terms from a given type to its isomorphic ENF type, our technique gives unique canonical representatives for examples that had previously been handled using program analysis.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Danko Ilik, Zakaria Chihani,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04625", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04625", "title": "\nCompressed Tree Canonization", "abstract": "Straight-line (linear) context-free tree (SLT) grammars have been used to compactly represent ordered trees. It is well known that equivalence of SLT grammars is decidable in polynomial time. Here we extend this result and show that isomorphism of unordered trees given as SLT grammars is decidable in polynomial time. The proof constructs a compressed version of the canonical form of the tree represented by the input SLT grammar. The result is generalized to unrooted trees by \"re-rooting\" the compressed trees in polynomial time. We further show that bisimulation equivalence of unrooted unordered trees represented by SLT grammars is decidable in polynomial time. For non-linear SLT grammars which can have double-exponential compression ratios, we prove that unordered isomorphism is PSPACE-hard and in EXPTIME. The same complexity bounds are shown for bisimulation equivalence.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Markus Lohrey, Sebastian Maneth, Fabian Peternek,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04623", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04623", "title": "\nDRAW: A Recurrent Neural Network For Image Generation", "abstract": "This paper introduces the Deep Recurrent Attentive Writer (DRAW) neural network architecture for image generation. DRAW networks combine a novel spatial attention mechanism that mimics the foveation of the human eye, with a sequential variational auto-encoding framework that allows for the iterative construction of complex images. The system substantially improves on the state of the art for generative models on MNIST, and, when trained on the Street View House Numbers dataset, it generates images that cannot be distinguished from real data with the naked eye.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Karol Gregor, Ivo Danihelka, Alex Graves, Daan Wierstra,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04617", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04617", "title": "\nDeep Transform: Error Correction via Probabilistic Re-Synthesis", "abstract": "Errors in data are usually unwelcome and so some means to correct them is useful. However, it is difficult to define, detect or correct errors in an unsupervised way. Here, we train a deep neural network to re-synthesize its inputs at its output layer for a given class of data. We then exploit the fact that this abstract transformation, which we call a deep transform (DT), inherently rejects information (errors) existing outside of the abstract feature space. Using the DT to perform probabilistic re-synthesis, we demonstrate the recovery of data that has been subject to extreme degradation.", "subjects": "Learning (cs.LG)", "authors": "Andrew J.R. Simpson,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04609", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04609", "title": "\nTextLuas: Tracking and Visualizing Document and Term Clusters in Dynamic  Text Data", "abstract": "For large volumes of text data collected over time, a key knowledge discovery task is identifying and tracking clusters. These clusters may correspond to emerging themes, popular topics, or breaking news stories in a corpus. Therefore, recently there has been increased interest in the problem of clustering dynamic data. However, there exists little support for the interactive exploration of the output of these analysis techniques, particularly in cases where researchers wish to simultaneously explore both the change in cluster structure over time and the change in the textual content associated with clusters. In this paper, we propose a model for tracking dynamic clusters characterized by the evolutionary events of each cluster. Motivated by this model, the TextLuas system provides an implementation for tracking these dynamic clusters and visualizing their evolution using a metro map metaphor. To provide overviews of cluster content, we adapt the tag cloud representation to the dynamic clustering scenario. We demonstrate the TextLuas system on two different text corpora, where they are shown to elucidate the evolution of key themes. We also describe how TextLuas was applied to a problem in bibliographic network research.", "subjects": "Information Retrieval (cs.IR)", "authors": "Derek Greene, Daniel Archambault, V\u00e1clav Bel\u00e1k, P\u00e1draig Cunningham,", "date": "2014-11-3"}, 
{"urllink": "http://arxiv.org/abs/1502.04600", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04600", "title": "\nStructural Properties of an Open Problem in Preemptive Scheduling", "abstract": "Structural properties of optimal preemptive schedules have been studied in a number of recent papers with a primary focus on two structural parameters: the minimum number of preemptions necessary, and a tight lower bound on `shifts', i.e., the sizes of intervals bounded by the times created by preemptions, job starts, or completions. So far only rough bounds for these parameters have been derived for specific problems. This paper sharpens the bounds on these structural parameters for a well-known open problem in the theory of preemptive scheduling: Instances consist of in-trees of unit-execution-time jobs with release dates, and the objective is to minimize the total completion time on two processors. This is among the current, tantalizing `threshold' problems of scheduling theory: Our literature survey reveals that any significant generalization leads to an NP-hard problem, but that any significant simplification leads to tractable problem. For the above problem, we show that the number of preemptions necessary for optimality need not exceed ; that the number must be of order for some instances; and that the minimum shift need not be less than . These bounds are obtained by combinatorial analysis of optimal schedules rather than by the analysis of polytope corners for linear-program formulations, an approach to be found in earlier papers. The bounds immediately follow from a fundamental structural property called `normality', by which minimal shifts of a job are exponentially decreasing functions. In particular, the first interval between a preempted job's start and its preemption is a multiple of 1/2, the second such interval is a multiple of 1/4, and in general, the -th preemption occurs at a multiple of . We expect the new structural properties to play a prominent role in finally settling a vexing, still-open question of complexity.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Bo Chen, Ed Coffman, Dariusz Dereniowski, Wieslaw Kubiak,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04593", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04593", "title": "\nExplaining robust additive utility models by sequences of preference  swaps", "abstract": "Multicriteria decision analysis aims at supporting a person facing a decision problem involving conflicting criteria. We consider an additive utility model which provides robust conclusions based on preferences elicited from the decision maker. The recommendations based on these robust conclusions are even more convincing if they are complemented by explanations. We propose a general scheme, based on sequence of preference swaps, in which explanations can be computed. We show first that the length of explanations can be unbounded in the general case. However, in the case of binary reference scales, this length is bounded and we provide an algorithm to compute the corresponding explanation.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "K. Belahcene, C. Labreuche, N. Maudet, V. Mousseau, W. Ouerdane,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04588", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04588", "title": "\nA $(1 + {\\varepsilon})$-Embedding of Low Highway Dimension Graphs into  Bounded Treewidth Graphs", "abstract": "Graphs with bounded highway dimension were introduced in [Abraham et al., SODA 2010] as a model of transportation networks. We show that any such graph can be embedded into a distribution over bounded treewidth graphs with arbitrarily small distortion. More concretely, if the highway dimension of is constant we show how to randomly compute a subgraph of the shortest path metric of the input graph with the following two properties: it distorts the distances of by a factor of in expectation and has a treewidth that is polylogarithmic in the aspect ratio of . In particular, this result implies quasi-polynomial time approximation schemes for a number of optimization problems that naturally arise on transportation networks, including Travelling Salesman, Steiner Tree, and Facility Location. To construct our embedding for low highway dimension graphs we extend Talwar's [STOC 2004] embedding of low doubling dimension metrics into bounded treewidth graphs, which generalizes known results for Euclidean metrics. We add several non-trivial ingredients to Talwar's techniques, and in particular thoroughly analyze the structure of low highway dimension graphs. Thus we demonstrate that the geometric toolkit used for Euclidean metrics extends beyond the class of low doubling metrics.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Andreas Emil Feldmann, Wai Shing Fung, Jochen K\u00f6nemann, Ian Post,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04585", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04585", "title": "\nThe Ladder: A Reliable Leaderboard for Machine Learning Competitions", "abstract": "The organizer of a machine learning competition faces the problem of maintaining an accurate leaderboard that faithfully represents the quality of the best submission of each competing team. What makes this estimation problem particularly challenging is its sequential and adaptive nature. As participants are allowed to repeatedly evaluate their submissions on the leaderboard, they may begin to overfit to the holdout data that supports the leaderboard. Few theoretical results give actionable advice on how to design a reliable leaderboard. Existing approaches therefore often resort to poorly understood heuristics such as limiting the bit precision of answers and the rate of re-submission. In this work, we introduce a notion of \"leaderboard accuracy\" tailored to the format of a competition. We introduce a natural algorithm called \"the Ladder\" and demonstrate that it simultaneously supports strong theoretical guarantees in a fully adaptive model of estimation, withstands practical adversarial attacks, and achieves high utility on real submission files from an actual competition hosted by Kaggle. Notably, we are able to sidestep a powerful recent hardness result for adaptive risk estimation that rules out algorithms such as ours under a seemingly very similar notion of accuracy. On a practical note, we provide a completely parameter-free variant of our algorithm that can be deployed in a real competition with no tuning required whatsoever.", "subjects": "Learning (cs.LG)", "authors": "Avrim Blum, Moritz Hardt,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04579", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04579", "title": "\nDesigning and Testing Temporally Connected Graphs", "abstract": "We study the issues of testing and designing (nearly cost-optimal) temporal networks that are temporally connected. We follow the temporal (di)graphs abstraction, where each edge of a (di)graph is associated with a set of discrete time instances of availability (labels).We call the resulting ,where ,a temporal (di)graph and denote it by .Journeys in such temporal graphs are paths with a single label per each edge of the path, chosen from the respective , such that the labels from the start to the end of the path are in strictly increasing order.A temporally connected temporal (di)graph is a temporal (di)graph in which,for any pair of vertices , there exists both a -journey and a -journey.In this case,we say that the graph satisfies the property REACH.We present a strongly polynomial time,almost optimal,algorithm to decide REACH.For any given connected undirected graph ,we show that at least labels are needed in any labeling to satisfy REACH and we give a labeling of labels that satisfies REACH. We introduce the notion of minimal labelings on a graph , where satisfies REACH. In minimal labelings the removal of any label destroys the property REACH. We present 2 infinite classes of minimal temporal graphs. We show that the complete undirected graph cannot be minimal under any labeling that assigns one label per edge, so that different edges have different labels.We define the removal cost of a given labeling on ,with respect to REACH,as the maximum number of labels that can be removed from without violating REACH and show that computing it is APX-hard.We show that in the complete graph and in instances of the Erd \"s-Renyi model of random graphs with random labels,one per edge,one can remove many labels and still maintain REACH whp.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Eleni C. Akrida, Leszek Gasieniec, George B. Mertzios, Paul G. Spirakis,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04578", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04578", "title": "\nThe MSO+U theory of (N, <) is undecidable", "abstract": "We consider the logic MSO+U, which is monadic second-order logic extended with the unbounding quantifier. The unbounding quantifier is used to say that a property of finite sets holds for sets of arbitrarily large size. We prove that the logic is undecidable on infinite words, i.e. the MSO+U theory of (N,&lt;) is undecidable. This settles an open problem about the logic, and improves a previous undecidability result, which used infinite trees and additional axioms from set theory.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Miko\u0142aj Boja\u0144czyk, Pawe\u0142 Parys, Szymon Toru\u0144czyk,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.04569", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04569", "title": "\nImage Specificity", "abstract": "For some images, descriptions written by multiple people are consistent with each other. But for other images, descriptions across people vary considerably. In other words, some images are specific they elicit consistent descriptions from different people while other images are ambiguous. Applications involving images and text can benefit from an understanding of which images are specific and which ones are ambiguous. For instance, consider text-based image retrieval. If a query description is moderately similar to the caption (or reference description) of an ambiguous image, that query may be considered a decent match to the image. But if the image is very specific, a moderate similarity between the query and the reference description may not be sufficient to retrieve the image. In this paper, we introduce the notion of image specificity. We present two mechanisms to measure specificity given multiple descriptions of an image: an automated measure and a measure that relies on human judgement. We analyze image specificity with respect to image content and properties to better understand what makes an image specific. We then train models to automatically predict the specificity of an image from image features alone without requiring textual descriptions of the image. Finally, we show that modeling image specificity leads to improvements in a text-based image retrieval application.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Mainak Jas, Devi Parikh,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04551", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04551", "title": "\nSmaller Selection Networks for Cardinality Constraints Encoding", "abstract": "Selection comparator networks have been studied for many years. Recently, they have been successfully applied to encode cardinality constraints for SAT-solvers. To decrease the size of generated formula there is a need for constructions of selection networks that can be efficiently generated and produce networks of small sizes for the practical range of their two parameters: n - the number of inputs (boolean variables) and k - the number of selected items (a cardinality bound). In this paper we give and analyze a new construction of smaller selection networks that are based on the pairwise selection networks introduced by Codish and Zanon-Ivry. We prove also that standard encodings of cardinality constraints with selection networks preserve arc-consistency.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Micha\u0142 Karpi\u0144ski, Marek Piotr\u00f3w,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04548", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04548", "title": "\nReal-Time Stochastic Optimal Control for Multi-agent Quadrotor Swarms", "abstract": "This paper presents a novel method for controlling swarms of unmanned aerial vehicles using Stochastic Optimal Control (SOC) theory. The approach consists of a centralized high-level controller that computes optimal state trajectories as velocity sequences, and a platform-specific low-level controller which ensures that these velocity sequences are met. The high-level control task is expressed as a centralized Path Integral control problem, for which optimal control computation corresponds to a probabilistic inference problem that can be solved by efficient sampling methods. Through simulation we show that our SOC approach (a) has significant benefits compared to deterministic control and other SOC methods in multi-modal problems with noise-dependent optimal solutions, (b) is capable of controlling a large number of platforms in real-time, and (c) yields collective emergent behavior in the form of flight formations. Finally, we show that our approach works for real platforms, by controlling a swarm of three quadrotors.", "subjects": "Systems and Control (cs.SY)", "authors": "Vicen\u00e7 G\u00f3mez, Sep Thijssen, Hilbert J. Kappen, Stephen Hailes, Andrew Symington,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04545", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04545", "title": "\nParallel Identity Testing for Skew Circuits with Big Powers and  Applications", "abstract": "Powerful skew arithmetic circuits are introduced. These are skew arithmetic circuits with variables, where input gates can be labelled with powers for binary encoded numbers . It is shown that polynomial identity testing for powerful skew arithmetic circuits belongs to , which generalizes a corresponding result for (standard) skew circuits. Two applications of this result are presented: (i) Equivalence of higher-dimensional straight-line programs can be tested in ; this result is even new in the one-dimensional case, where the straight-line programs produce strings. (ii) The compressed word problem (or circuit evaluation problem) for certain wreath products of finitely generated abelian groups belongs to .", "subjects": "Computational Complexity (cs.CC)", "authors": "Daniel K\u00f6nig, Markus Lohrey,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04544", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04544", "title": "\nA Note On Boneh-Gentry-Waters Broadcast Encryption Scheme and Its Like", "abstract": "Key establishment is any process whereby a shared secret key becomes available to two or more parties, for subsequent cryptographic use such as symmetric-key encryption. Though it is widely known that the primitive of encryption is different from key establishment, we find some researchers have confused the two primitives. In this note, we shall clarify the fundamental difference between the two primitives, and point out that the Boneh-Gentry-Waters broadcast encryption scheme and its like are key establishment schemes, not encryption schemes.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Zhengjun Cao, Lihua Liu,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04539", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04539", "title": "\nHybrid Centralized-Distributed Resource Allocation for Device-to-Device  Communication Underlaying Cellular Networks", "abstract": "The basic idea of device-to-device (D2D) communication is that pairs of suitably selected wireless devices reuse the cellular spectrum to establish direct communication links, provided that the adverse effects of D2D communication on cellular users is minimized and cellular users are given a higher priority in using limited wireless resources. Despite its great potential in terms of coverage and capacity performance, implementing this new concept poses some challenges, in particular with respect to radio resource management. The main challenges arise from a strong need for distributed D2D solutions that operate in the absence of precise channel and network knowledge. In order to address this challenge, this paper studies a resource allocation problem in a single-cell wireless network with multiple D2D users sharing the available radio frequency channels with cellular users. We consider a realistic scenario where the base station (BS) is provided with strictly limited channel knowledge while D2D and cellular users have no information. We prove a lower-bound for the cellular aggregate utility in the downlink with fixed BS power, which allows for decoupling the channel allocation and D2D power control problems. An efficient graph-theoretical approach is proposed to perform the channel allocation, which offers flexibility with respect to allocation criterion (aggregate utility maximization, fairness, quality of service guarantee). We model the power control problem as a multi-agent learning game. We show that the game is an exact potential game with noisy rewards, defined on a discrete strategy set, and characterize the set of Nash equilibria. Q-learning better-reply dynamics is then used to achieve equilibrium.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Setareh Maghsudi, Slawomir Stanczak,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04538", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04538", "title": "\nLearning Dynamic Compressive Sensing Models", "abstract": "Random sampling in compressive sensing (CS) enables to compress large amounts of input signals in efficient manner, which becomes useful for many applications. CS reconstructs the compressed signals exactly with overwhelming probability when incoming data can be sparsely represented with a fixed number of principal components, which is one of drawbacks of CS frameworks because the signal sparsity in many dynamic systems changes over time. We present the first CS framework that handles signals without the fixed sparsity assumption by incorporating the distribution of signal sparsity. We prove the beta distribution modeling of signal recovery success is more accurate than the success probability analysis in the CS framework, which is also confirmed by experiments. For signals that cannot be exactly represented with the sparse representation, we show the numbers of principal components included in their signal recoveries can be represented with a probability distribution. We show this distribution is skewed to the right and naturally represented by the gamma distribution.", "subjects": "Information Theory (cs.IT)", "authors": "Dongeun Lee, Jaesik Choi,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04533", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04533", "title": "\nOn the Minimum Cost Range Assignment Problem", "abstract": "We study the problem of assigning transmission ranges to radio stations placed arbitrarily in a -dimensional (-D) Euclidean space in order to achieve a strongly connected communication network with minimum total power consumption. The power required for transmitting in range is proportional to , where is typically between and , depending on various environmental factors. While this problem can be solved optimally in D, in higher dimensions it is known to be -hard for any . For the D version of the problem, i.e., radio stations located on a line and , we propose an optimal -time algorithm. This improves the running time of the best known algorithm by a factor of . Moreover, we show a polynomial-time algorithm for finding the minimum cost range assignment in D whose induced communication graph is a -spanner, for any . In higher dimensions, finding the optimal range assignment is -hard; however, it can be approximated within a constant factor. The best known approximation ratio is for the case , where the approximation ratio is . We show a new approximation algorithm with improved approximation ratio of , where is a small constant.", "subjects": "Computational Geometry (cs.CG)", "authors": "Paz Carmi, Lilach Chaitman-Yerushalmi,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04514", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04514", "title": "\nMaximal Independent Sets in Generalised Caterpillar Graphs", "abstract": "A caterpillar graph is a tree which on removal of all its pendant vertices leaves a chordless path. The chordless path is called the backbone of the graph. The edges from the backbone to the pendant vertices are called the hairs of the caterpillar graph. Ortiz and Villanueva (C.Ortiz and M.Villanueva, Discrete Applied Mathematics, 160(3): 259-266, 2012) describe an algorithm, linear in the size of the output, for finding a family of maximal independent sets in a caterpillar graph. In this paper, we propose an algorithm, again linear in the output size, for a generalised caterpillar graph, where at each vertex of the backbone, there can be any number of hairs of length one and at most one hair of length two.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Neethi K.S., Sanjeev Saxena,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04511", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04511", "title": "\nLocally Optimal Load Balancing", "abstract": "This work studies distributed algorithms for locally optimal load-balancing: We are given a graph of maximum degree , and each node has up to units of load. The task is to distribute the load more evenly so that the loads of adjacent nodes differ by at most . If the graph is a path (), it is easy to solve the fractional version of the problem in communication rounds, independently of the number of nodes. We show that this is tight, and we show that it is possible to solve also the discrete version of the problem in rounds in paths. For the general case (), we show that fractional load balancing can be solved in rounds and discrete load balancing in rounds for some function , independently of the number of nodes.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Laurent Feuilloley, Juho Hirvonen, Jukka Suomela,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04500", "category": "Computer Science ", "pdflink": "http://arxiv.org/e-print/1502.04500", "title": "\nBi-Level Image Thresholding obtained by means of Kaniadakis Entropy", "abstract": "In this paper we are proposing the use of Kaniadakis entropy in the bi-level thresholding of images, in the framework of a maximum entropy principle. We discuss the role of its entropic index in determining the threshold and in driving an \"image transition\", that is, an abrupt transition in the appearance of the corresponding bi-level image. Some examples are proposed to illustrate the method and for comparing it to the approach which is using the Tsallis entropy.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Amelia Carolina Sparavigna,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.04499", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04499", "title": "\nColor Image Enhancement Using the lrgb Coordinates in the Context of  Support Fuzzification", "abstract": "Image enhancement is an important stage in the image-processing domain. The most known image enhancement method is the histogram equalization. This method is an automated one, and realizes a simultaneous modification for brightness and contrast in the case of monochrome images and for brightness, contrast, saturation and hue in the case of color images. Simple and efficient methods can be obtained if affine transforms within logarithmic models are used. A very important thing in the affine transform determination for color images is the coordinate system that is used for color space representation. Thus, the using of the RGB coordinates leads to a simultaneous modification of luminosity and saturation. In this paper using the lrgb perceptual coordinates one can define affine transforms, which allow a separated modification of luminosity l and saturation s (saturation being calculated with the component rgb in the chromatic plane). Better results can be obtained if partitions are defined on the image support and then the pixels are separately processed in each window belonging to the defined partition. Classical partitions frequently lead to the appearance of some discontinuities at the boundaries between these windows. In order to avoid all these drawbacks the classical partitions may be replaced by fuzzy partitions. Their elements will be fuzzy windows and in each of them there will be defined an affine transform induced by parameters using the fuzzy mean, fuzzy variance and fuzzy saturation computed for the pixels that belong to the analyzed window. The final image is obtained by summing up in a weight way the images of every fuzzy window.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Vasile Patrascu,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04496", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04496", "title": "\nDon't Trust the Cloud, Verify: Integrity and Consistency for Cloud  Object Stores", "abstract": "Cloud services have turned remote computation into a commodity and enable convenient online collaboration. However, they require that clients fully trust the service provider in terms of confidentiality, integrity, and availability. Towards reducing this dependency, this paper introduces a protocol for verification of integrity and consistency for cloud object storage (VICOS), which enables a group of mutually trusting clients to detect data-integrity and consistency violations for cloud storage. It aims at services where multiple clients cooperate on data stored remotely on a potentially misbehaving service. VICOS enforces the consistency notion of fork-linearizability, supports wait-free client semantics for most operations, and reduces the computation and communication overhead compared to previous protocols. VICOS is based in a generic way on any authenticated data structure. A prototype of VICOS that works with the key-value store interface of commodity cloud storage has been implemented, and an evaluation demonstrates its advantage compared to existing systems.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Marcus Brandenburger, Christian Cachin, Nikola Kne\u017eevi\u0107,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04495", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04495", "title": "\nA Generalization of Gustafson-Kessel Algorithm Using a New Constraint  Parameter", "abstract": "In this paper one presents a new fuzzy clustering algorithm based on a dissimilarity function determined by three parameters. This algorithm can be considered a generalization of the Gustafson-Kessel algorithm for fuzzy clustering.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Vasile Patrascu,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04492", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04492", "title": "\nTowards Building Deep Networks with Bayesian Factor Graphs", "abstract": "We propose a Multi-Layer Network based on the Bayesian framework of the Factor Graphs in Reduced Normal Form (FGrn) applied to a two-dimensional lattice. The Latent Variable Model (LVM) is the basic building block of a quadtree hierarchy built on top of a bottom layer of random variables that represent pixels of an image, a feature map, or more generally a collection of spatially distributed discrete variables. The multi-layer architecture implements a hierarchical data representation that, via belief propagation, can be used for learning and inference. Typical uses are pattern completion, correction and classification. The FGrn paradigm provides great flexibility and modularity and appears as a promising candidate for building deep networks: the system can be easily extended by introducing new and different (in cardinality and in type) variables. Prior knowledge, or supervised information, can be introduced at different scales. The FGrn paradigm provides a handy way for building all kinds of architectures by interconnecting only three types of units: Single Input Single Output (SISO) blocks, Sources and Replicators. The network is designed like a circuit diagram and the belief messages flow bidirectionally in the whole system. The learning algorithms operate only locally within each block. The framework is demonstrated in this paper in a three-layer structure applied to images extracted from a standard data set.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Amedeo Buonanno, Francesco A.N. Palmieri,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04488", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04488", "title": "\nGeneral Rank Multiuser Downlink Beamforming With Shaping Constraints  Using Real-valued OSTBC", "abstract": "In this paper we consider optimal multiuser downlink beamforming in the presence of a massive number of arbitrary quadratic shaping constraints. We combine beamforming with full-rate high dimensional real-valued orthogonal space time block coding (OSTBC) to increase the number of beamforming weight vectors and associated degrees of freedom in the beamformer design. The original multi-constraint beamforming problem is converted into a convex optimization problem using semidefinite relaxation (SDR) which can be solved efficiently. In contrast to conventional (rank-one) beamforming approaches in which an optimal beamforming solution can be obtained only when the SDR solution (after rank reduction) exhibits the rank-one property, in our approach optimality is guaranteed when a rank of eight is not exceeded. We show that our approach can incorporate up to 79 additional shaping constraints for which an optimal beamforming solution is guaranteed as compared to a maximum of two additional constraints that bound the conventional rank-one downlink beamforming designs. Simulation results demonstrate the flexibility of our proposed beamformer design.", "subjects": "Information Theory (cs.IT)", "authors": "Ka Lung Law, Xin Wen, Minh Thanh Vu, Marius Pesavento,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.04485", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04485", "title": "\nPolyMorph: Increasing P300 Spelling Efficiency by Selection Matrix  Polymorphism and Sentence-Based Predictions", "abstract": "P300 is an electric signal emitted by brain about 300 milliseconds after a rare, but relevant-for-the-user event. One of the applications of this signal is sentence spelling that enables subjects who lost the control of their motor pathways to communicate by selecting characters in a matrix containing all the alphabet symbols. Although this technology has made considerable progress in the last years, it still suffers from both low communication rate and high error rate. This article presents a P300 speller, named PolyMorph, that introduces two major novelties in the field: the selection matrix polymorphism, that reduces the size of the selection matrix itself by removing useless symbols, and sentence-based predictions, that exploit all the spelt characters of a sentence to determine the probability of a word. In order to measure the effectiveness of the presented speller, we describe two sets of tests: the first one in vivo and the second one in silico. The results of these experiments suggest that the use of PolyMorph in place of the naive character-by-character speller both increases the number of spelt characters per time unit and reduces the error rate.", "subjects": "Human-Computer Interaction (cs.HC)", "authors": "Alberto Casagrande, Joanna Jarmolowska, Marcello Turconi, Francesco Fabris, Pierpaolo Busan, Piero Paolo Battaglini,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.04469", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04469", "title": "\nClassification and its applications for drug-target interaction  identification", "abstract": "Classification is one of the most popular and widely used supervised learning tasks, which categorizes objects into predefined classes based on known knowledge. Classification has been an important research topic in machine learning and data mining. Different classification methods have been proposed and applied to deal with various real-world problems. Unlike unsupervised learning such as clustering, a classifier is typically trained with labeled data before being used to make prediction, and usually achieves higher accuracy than unsupervised one. In this paper, we first define classification and then review several representative methods. After that, we study in details the application of classification to a critical problem in drug discovery, i.e., drug-target prediction, due to the challenges in predicting possible interactions between drugs and targets.", "subjects": "Learning (cs.LG)", "authors": "Jian-Ping Mei, Chee-Keong Kwoh, Peng Yang, Xiao-Li Li,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.04464", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04464", "title": "\nOn Counterexample Guided Quantifier Instantiation for Synthesis in CVC4", "abstract": "This paper presents the first program synthesis engine implemented inside an SMT solver. We formulate our technique as support for synthesis conjectures. We present an approach that extracts solution functions from unsatisfiability proofs of the negated form of synthesis conjectures. To make finding such proofs feasible, we present counterexample-guided techniques for quantifier instantiation. A particularly important class of specifications are single-invocation properties, for which we present a dedicated algorithm. To support syntax restrictions on generated solutions, our approach can transform a solution found without restrictions into the desired syntactic format. As an alternative, we show how to use evaluation function axioms to embed syntactic restrictions into constraints over inductive datatypes, then use an inductive data type decision procedure to drive synthesis. Our experimental evaluation on syntax-guided synthesis benchmarks shows that our implementation in CVC4 is competitive with state-of-the-art tools for synthesis.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Andrew Reynolds, Morgan Deters, Viktor Kuncak, Clark Barrett, Cesare Tinelli,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04428", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04428", "title": "\nCommunity detection in bipartite networks using weighted symmetric  binary matrix factorization", "abstract": "In this paper we propose weighted symmetric binary matrix factorization (wSBMF) framework to detect overlapping communities in bipartite networks, which describe relationships between two types of nodes. Our method improves performance by recognizing the distinction between two types of missing edges---ones among the nodes in each node type and the others between two node types. Our method can also explicitly assign community membership and distinguish outliers from overlapping nodes, as well as incorporating existing knowledge on the network. We propose a generalized partition density for bipartite networks as a quality function, which identifies the most appropriate number of communities. The experimental results on both synthetic and real-world networks demonstrate the effectiveness of our method.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Zhong-Yuan Zhang, Yong-Yeol Ahn,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04423", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04423", "title": "\nExploring Transfer Function Nonlinearity in Echo State Networks", "abstract": "Supralinear and sublinear pre-synaptic and dendritic integration is considered to be responsible for nonlinear computation power of biological neurons, emphasizing the role of nonlinear integration as opposed to nonlinear output thresholding. How, why, and to what degree the transfer function nonlinearity helps biologically inspired neural network models is not fully understood. Here, we study these questions in the context of echo state networks (ESN). ESN is a simple neural network architecture in which a fixed recurrent network is driven with an input signal, and the output is generated by a readout layer from the measurements of the network states. ESN architecture enjoys efficient training and good performance on certain signal-processing tasks, such as system identification and time series prediction. ESN performance has been analyzed based on the connectivity pattern in the network structure and the input bias. However, the effects of the transfer function in the network have not been studied systematically. Here, we use an approach based on the Taylor expansion of a frequently used transfer function, the hyperbolic tangent function, to systematically study the effect of increasing nonlinearity of the transfer function on the memory, nonlinear capacity, and signal processing performance of the ESN. Interestingly, we find that a quadratic approximation is enough to capture the computational power of a ESN with sigmoid function. The results of this study can have application to both software and hardware implementation of ESN.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "Alireza Goudarzi, Alireza Shabani, Darko Stefanovic,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04419", "category": "Computer Science ", "pdflink": "http://arxiv.org/html/1502.04419", "title": "\nProceedings Third International Workshop on Linearity", "abstract": "This volume contains the papers presented at LINEARITY 2014, the Third International Workshop on Linearity, held on July 13, 2014 in Vienna, Austria. The workshop was a one-day satellite event of FLoC 2014, the sixth Federated Logic Conference. It was held as part of the 2014 Vienna Summer of Logic. The aim of this workshop was to bring together researchers who are exploring theory and applications of linear calculi, to foster their interaction and provide a forum for presenting new ideas and work in progress, and enable newcomers to learn about current activities in this area. Of interest were new results that made a central use of linearity, ranging from foundational work to applications in any field. This included: sub-linear logics, linear term calculi, linear type systems, linear proof-theory, linear programming languages, applications to concurrency, interaction-based systems, verification of linear systems, quantum models of computation, and biological and chemical models of computation.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Sandra Alves, Iliano Cervesato,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04395", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04395", "title": "\nApplication-Aware Consistency: An Application to Social Network", "abstract": "This work weakens well-known consistency models using graphs that capture applications' characteristics. The weakened models not only respect application semantic, but also yield a performance benefit. We introduce a notion of dependency graphs, which specify relations between events that are important with respect to application semantic, and then weaken traditional consistency models (e.g., causal consistency) using these graphs. Particularly, we consider two types of graphs: intra-process and inter-process dependency graphs, where intra-process dependency graphs specify how events in a single process are related, and inter-process dependency graphs specify how events across multiple processes are related. Then, based on these two types of graphs, we define new consistency model, namely consistency. We also discuss why such application-aware consistency can be useful in social network applications. This is a work in progress, and we present early ideas regarding application-aware consistency here.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Lewis Tseng, Alec Benzer, Nitin Vaidya,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04390", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04390", "title": "\nRMSProp and equilibrated adaptive learning rates for non-convex  optimization", "abstract": "Parameter-specific adaptive learning rate methods are computationally efficient ways to reduce the ill-conditioning problems encountered when training large deep networks. Following recent work that strongly suggests that most of the critical points encountered when training such networks are saddle points, we find how considering the presence of negative eigenvalues of the Hessian could help us design better suited adaptive learning rate schemes, i.e., diagonal preconditioners. We show that the optimal preconditioner is based on taking the absolute value of the Hessian's eigenvalues, which is not what Newton and classical preconditioners like Jacobi's do. In this paper, we propose a novel adaptive learning rate scheme based on the equilibration preconditioner and show that RMSProp approximates it, which may explain some of its success in the presence of saddle points. Whereas RMSProp is a biased estimator of the equilibration preconditioner, the proposed stochastic estimator, ESGD, is unbiased and only adds a small percentage to computing time. We find that both schemes yield very similar step directions but that ESGD sometimes surpasses RMSProp in terms of convergence speed, always clearly improving over plain stochastic gradient descent.", "subjects": "Learning (cs.LG)", "authors": "Yann N. Dauphin, Harm de Vries, Junyoung Chung, Yoshua Bengio,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04383", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04383", "title": "\nA Comprehensive Survey on Pose-Invariant Face Recognition", "abstract": "The capacity to recognize faces under varied poses is a fundamental human ability that presents a unique challenge for computer vision systems. Compared to frontal face recognition, which has been intensively studied and has gradually matured in the past few decades, pose-invariant face recognition (PIFR) remains a largely unsolved problem. However, PIFR is crucial to realizing the full potential of face recognition for real-world applications, since face recognition is intrinsically a passive biometric technology for recognizing uncooperative subjects. In this paper, we discuss the inherent difficulties in PIFR and present a comprehensive review of established techniques. Existing PIFR methods can be grouped into four categories, i.e., pose-robust feature extraction approaches, multi-view subspace learning approaches, face synthesis approaches, and hybrid approaches. The motivations, strategies, pros/cons, and performance of representative approaches are described and compared. Moreover, promising directions for future research are discussed.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Changxing Ding, Dacheng Tao,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04382", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04382", "title": "\nTemporal Network Optimization Subject to Connectivity Constraints", "abstract": "In this work we consider emph, i.e. networks defined by a emph assigning to each edge of an emph a set of emph time-labels. The labels of an edge, which are natural numbers, indicate the discrete time moments at which the edge is available. We focus on emph of temporal networks. In particular, we consider emph paths, i.e. paths whose edges are assigned by a strictly increasing sequence of labels. We begin by giving two efficient algorithms for computing shortest time-respecting paths on a temporal network. We then prove that there is a emph holding for arbitrary temporal networks. Finally, we propose two emph for temporal network design. One is the emph of , in which the goal is to minimize the maximum number of labels of an edge, and the other is the emph of , in which the goal is to minimize the total number of labels used. Optimization of these parameters is performed subject to some emph. We prove several lower and upper bounds for the temporality and the temporal cost of some very basic graph families such as rings, directed acyclic graphs, and trees.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "George B. Mertzios, Othon Michail, Paul G. Spirakis,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04380", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04380", "title": "\nLink Prediction in Networks with Nodes Attributes by Similarity  Propagation", "abstract": "The problem of link prediction has attracted considerable recent attention from various domains such as sociology, anthropology, information science, and computer sciences. A link prediction algorithm is proposed based on link similarity score propagation by a random walk in networks with nodes attributes. In the algorithm, each link in the network is assigned a transmission probability according to the similarity of the attributes on the nodes connected by the link. The link similarity score between the nodes are then propagated via the links according to their transmission probability. Our experimental results show that it can obtain higher quality results on the networks with node attributes than other algorithms.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Maosheng Jiang, Yonxiang Chen, Ling Chen,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04368", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04368", "title": "\nReversible Causal Graph Dynamics", "abstract": "Causal Graph Dynamics extend Cellular Automata to arbitrary, bounded-degree, time-varying graphs. The whole graph evolves in discrete time steps, and this global evolution is required to have a number of physics-like symmetries: shift-invariance (it acts everywhere the same) and causality (information has a bounded speed of propagation). We add a further physics-like symmetry, namely reversibility.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Pablo Arrighi, Simon Martiel, Simon Perdrix,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04367", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04367", "title": "\nCoset codes for communicating over non-additive channels", "abstract": "We present a case for the use of codes possessing algebraic closure properties - coset codes - in developing coding techniques and characterizing achievable rate regions for generic multi-terminal channels. In particular, we consider three diverse communication scenarios - user interference channel (many-to-many), user broadcast channel (one-to-many), and multiple access with distributed states (many-to-one) - and identify non-additive examples for which coset codes are analytically proven to yield strictly larger achievable rate regions than those achievable using iid codes. On the one hand, our findings motivate the need for multi-terminal information theory to step beyond iid codes. On the other, it encourages current research of linear code-based techniques to go beyond particular additive communication channels. Detailed proofs of our results are available in [1]-[3].", "subjects": "Information Theory (cs.IT)", "authors": "Arun Padakandla, S. Sandeep Pradhan,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04354", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04354", "title": "\nSample Complexity for Winner Prediction in Elections", "abstract": "Predicting the winner of an election is a favorite problem both for news media pundits and computational social choice theorists. Since it is often infeasible to elicit the preferences of all the voters in a typical prediction scenario, a common algorithm used for winner prediction is to run the election on a small sample of randomly chosen votes and output the winner as the prediction. We analyze the performance of this algorithm for many common voting rules. More formally, we introduce the -winner determination problem, where given an election on voters and candidates in which the margin of victory is at least votes, the goal is to determine the winner with probability at least . The margin of victory of an election is the smallest number of votes that need to be modified in order to change the election winner. We show interesting lower and upper bounds on the number of samples needed to solve the -winner determination problem for many common voting rules, including scoring rules, approval, maximin, Copeland, Bucklin, plurality with runoff, and single transferable vote. Moreover, the lower and upper bounds match for many common voting rules in a wide range of practically appealing scenarios.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Arnab Bhattacharyya, Palash Dey,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.04348", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04348", "title": "\nSemantic Modeling of Analytic-based Relationships with Direct  Qualification", "abstract": "Successfully modeling state and analytics-based semantic relationships of documents enhances representation, importance, relevancy, provenience, and priority of the document. These attributes are the core elements that form the machine-based knowledge representation for documents. However, modeling document relationships that can change over time can be inelegant, limited, complex or overly burdensome for semantic technologies. In this paper, we present Direct Qualification (DQ), an approach for modeling any semantically referenced document, concept, or named graph with results from associated applied analytics. The proposed approach supplements the traditional subject-object relationships by providing a third leg to the relationship; the qualification of how and why the relationship exists. To illustrate, we show a prototype of an event-based system with a realistic use case for applying DQ to relevancy analytics of PageRank and Hyperlink-Induced Topic Search (HITS).", "subjects": "Information Retrieval (cs.IR)", "authors": "Norman Ahmed, Jason Bryant, Gregory Hasseler, Matthew Paulini,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04344", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04344", "title": "\nOptimal Cell Clustering and Activation for Energy Saving in Load-Coupled  Wireless Networks", "abstract": "Optimizing activation and deactivation of base station transmissions provides an instrument for improving energy efficiency in cellular networks. In this paper, we study optimal cell clustering and scheduling of activation duration for each cluster, with the objective of minimizing the sum energy, subject to a time constraint of delivering the users' traffic demand. The cells within a cluster are simultaneously in transmission and napping modes, with cluster activation and deactivation, respectively. Our optimization framework accounts for the coupling relation among cells due to the mutual interference. Thus, the users' achievable rates in a cell depend on the cluster composition. On the theoretical side, we provide mathematical formulation and structural characterization for the energy-efficient cell clustering and scheduling optimization problem, and prove its NP hardness. On the algorithmic side, we first show how column generation facilitates problem solving, and then present our notion of local enumeration as a flexible and effective means for dealing with the trade-off between optimality and the combinatorial nature of cluster formation, as well as for the purpose of gauging the deviation from optimality. Numerical results demonstrate that our solutions achieve more than 60% energy saving over existing schemes, and that the solutions we obtain are within a few percent of deviation from global optimum.", "subjects": "Information Theory (cs.IT)", "authors": "Lei Lei, Di Yuan, Chin Keong Ho, Sumei Sun,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04341", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04341", "title": "\nOn topological lower bounds for algebraic computation trees", "abstract": "We prove that the height of any algebraic computation tree for deciding membership in a semialgebraic set is bounded from below (up to a multiplicative constant) by the logarithm of m-th Betti number (with respect to singular homology) of the set, divided by m+1. This result complements the well known lower bound by Yao for locally closed semialgebraic sets in terms of the total Borel-Moore Betti number. We also prove that the height is bounded from below by the logarithm of m-th Betti number of a projection of the set onto a coordinate subspace, divided by (m+1)^2. We illustrate these general results by examples of lower complexity bounds for some specific computational problems.", "subjects": "Computational Complexity (cs.CC)", "authors": "Nicolai Vorobjov, Andrei Gabrielov,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04336", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04336", "title": "\nLattices with non-Shannon Inequalities", "abstract": "We study the existence or absence of non-Shannon inequalities for variables that are related by functional dependencies. Although the power-set on four variables is the smallest Boolean lattice with non-Shannon inequalities there exist lattices with many more variables without non-Shannon inequalities. We search for conditions that ensures that no non-Shannon inequalities exist. It is demonstrated that 3-dimensional distributive lattices cannot have non-Shannon inequalities and planar modular lattices cannot have non-Shannon inequalities. The existence of non-Shannon inequalities is related to the question of whether a lattice is isomorphic to a lattice of subgroups of a group.", "subjects": "Information Theory (cs.IT)", "authors": "Peter Harremo\u00ebs,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04331", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04331", "title": "\nTwo-Stage Document Length Normalization for Information Retrieval", "abstract": "The standard approach for term frequency normalization is based only on the document length. However, it does not distinguish the verbosity from the scope, these being the two main factors determining the document length. Because the verbosity and scope have largely different effects on the increase in term frequency, the standard approach can easily suffer from insufficient or excessive penalization depending on the specific type of long document. To overcome these problems, this paper proposes two-stage normalization by performing verbosity and scope normalization separately, and by employing different penalization functions. In verbosity normalization, each document is pre-normalized by dividing the term frequency by the verbosity of the document. In scope normalization, an existing retrieval model is applied in a straightforward manner to the pre-normalized document, finally leading us to formulate our proposed verbosity normalized (VN) retrieval model. Experimental results carried out on standard TREC collections demonstrate that the VN model leads to marginal but statistically significant improvements over standard retrieval models.", "subjects": "Information Retrieval (cs.IR)", "authors": "Seung-Hoon Na,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04328", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04328", "title": "\nGeometric Spanning Cycles in Bichromatic Point Sets", "abstract": "Given a set of points in the plane each colored either red or blue, we find non-self-intersecting geometric spanning cycles of the red points and of the blue points such that each edge of the red spanning cycle is crossed at most three times by the blue spanning cycle and vice-versa.", "subjects": "Computational Geometry (cs.CG)", "authors": "Benson Joeris, Isabel Urrutia, Jorge Urrutia,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04326", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04326", "title": "\nInterface Transformation from Ruling to Obedience", "abstract": "This article is about one feature which was partly introduced 30 years ago with the development of multi windows operating systems. It is about the movability of screen objects not according to some predetermined algorithm but by the direct user action. Many years ago it was introduced on a very limited basis and nothing was improved since then. Smartphones and tablets give direct access to screen elements but on a very limited set of commands (scroll and zoom). There is an easy to use algorithm which turns any screen object into movable / resizable. This algorithm uses only mouse to turn screens of normal PCs into touchscreens, but this simple change means a revolution in our work with computers.", "subjects": "Human-Computer Interaction (cs.HC)", "authors": "Sergey Andreyev,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04321", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04321", "title": "\nEvolution of Directed Triangle Motifs in the Google+ OSN", "abstract": "Motifs are a fundamental building block and distinguishing feature of networks. While characteristic motif distribution have been found in many networks, very little is known today about the evolution of network motifs. This paper studies the most important motifs in social networks, triangles, and how directed triangle motifs change over time. Our chosen subject is one of the largest Online Social Networks, Google+. Google+ has two distinguishing features that make it particularly interesting: (1) it is a directed network, which yields a rich set of triangle motifs, and (2) it is a young and fast evolving network, whose role in the OSN space is still not fully understood. For the purpose of this study, we crawled the network over a time period of six weeks, collecting several snapshots. We find that some triangle types display significant dynamics, e.g., for some specific initial types, up to 20% of the instances evolve to other types. Due to the fast growth of the OSN in the observed time period, many new triangles emerge. We also observe that many triangles evolve into less-connected motifs (with less edges), suggesting that growth also comes with pruning. We complement the topological study by also considering publicly available user profile data (mostly geographic locations). The corresponding results shed some light on the semantics of the triangle motifs. Indeed, we find that users in more symmetric triangle motifs live closer together, indicating more personal relationships. In contrast, asymmetric links in motifs often point to faraway users with a high in-degree (celebrities).", "subjects": "Social and Information Networks (cs.SI)", "authors": "Doris Schi\u00f6berg, Fabian Schneider, Stefan Schmid, Steve Uhlig, Anja Feldmann,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.04316", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04316", "title": "\nImproving Routing Efficiency through Intermediate Target Based  Geographic Routing", "abstract": "The greedy strategy of geographical routing may cause the local minimum problem when there is a hole in the routing area. It depends on other strategies such as perimeter routing to find a detour path, which can be long and result in inefficiency of the routing protocol. In this paper, we propose a new approach called Intermediate Target based Geographic Routing (ITGR) to solve the long detour path problem. The basic idea is to use previous experience to determine the destination areas that are shaded by the holes. The novelty of the approach is that a single forwarding path can be used to determine a shaded area that may cover many destination nodes. We design an efficient method for the source to find out whether a destination node belongs to a shaded area. The source then selects an intermediate node as the tentative target and greedily forwards packets to it, which in turn forwards the packet to the final destination by greedy routing. ITGR can combine multiple shaded areas to improve the efficiency of representation and routing. We perform simulations and demonstrate that ITGR significantly reduces the routing path length, compared with existing geographic routing protocols.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Zongming Fei, Jianjun Yang, Hui Lu,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04312", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04312", "title": "\nWIKI THANKS: Cultural Differences in Thanks Network of  Different-Language Wikipedias", "abstract": "Wikipedia introduced a new social function \"wiki-thanks\". \"Wiki-thanks\" enable editors to send thanks to other editors' contributions. In this paper, we aim to investigate this new social tool from different cultural perspectives. To achieve this goal, we analyze \"wiki-thanks\" log events and compared the English, German, Spanish, Chinese, Japanese, Korean, and Finish language Wikipedias.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Keiichi Nemoto, Ken-ichi Okada,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04300", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04300", "title": "\nMandarin Singing Voice Synthesis Based on Harmonic Plus Noise Model and  Singing Expression Analysis", "abstract": "The purpose of this study is to investigate how humans interpret musical scores expressively, and then design machines that sing like humans. We consider six factors that have a strong influence on the expression of human singing. The factors are related to the acoustic, phonetic, and musical features of a real singing signal. Given real singing voices recorded following the MIDI scores and lyrics, our analysis module can extract the expression parameters from the real singing signals semi-automatically. The expression parameters are used to control the singing voice synthesis (SVS) system for Mandarin Chinese, which is based on the harmonic plus noise model (HNM). The results of perceptual experiments show that integrating the expression factors into the SVS system yields a notable improvement in perceptual naturalness, clearness, and expressiveness. By one-to-one mapping of the real singing signal and expression controls to the synthesizer, our SVS system can simulate the interpretation of a real singer with the timbre of a speaker.", "subjects": "Sound (cs.SD)", "authors": "Ju-Chiang Wang, Hung-Yan Gu, Hsin-Min Wang,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04297", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04297", "title": "\nA Conceptual Framework for Web Development Projects Based on Project  Management and Agile Development Principles", "abstract": "Companies implement different frameworks and best practices with the objective to improve the project management success rate and improve the business adaptability to the changing business environment. Project management framework (PRINCE2) and agile development framework (Scrum) proved in many cases that they can meet these objectives. However, both frameworks are based on different principles and the use of both frameworks together should be carefully considered. A large amount of money and effort has been invested by companies into establishing their project management environment and processes that follow the classical phased approach where requirements are defined upfront and fixed. But companies want to react more quickly to new global challenges and to the changing business environment. These business requirements then result in the failure of many running projects. Therefore there is a need to enhance the current project management environment so that it is more agile and adoptive to changes. The objective of this paper is to create a conceptual framework that aggregates principles and processes from both frameworks (PRINCE2 and Scrum) with emphasis on their use in web development projects. This paper will discuss the advantages and disadvantages of using the two abovementioned frameworks. Different groups of readers can benefit from the results of this paper. It will help corporate management to decide how a company should set up its own specific framework for managing agile product development projects. Project managers will have a better understanding of agile development principles and how it fits in the classic project management framework. Last but not least, it will help product developers to work in more agile ways and survive in the controlled and complex project environment.", "subjects": "Software Engineering (cs.SE)", "authors": "Martin Tomanek, Radim Cermak, Zdenek Smutny,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04281", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04281", "title": "\nFrogWild! -- Fast PageRank Approximations on Graph Engines", "abstract": "We propose FrogWild, a novel algorithm for fast approximation of high PageRank vertices, geared towards reducing network costs of running traditional PageRank algorithms. Our algorithm can be seen as a quantized version of power iteration that performs multiple parallel random walks over a directed graph. One important innovation is that we introduce a modification to the GraphLab framework that only partially synchronizes mirror vertices. This partial synchronization vastly reduces the network traffic generated by traditional PageRank algorithms, thus greatly reducing the per-iteration cost of PageRank. On the other hand, this partial synchronization also creates dependencies between the random walks used to estimate PageRank. Our main theoretical innovation is the analysis of the correlations introduced by this partial synchronization process and a bound establishing that our approximation is close to the true PageRank vector. We implement our algorithm in GraphLab and compare it against the default PageRank implementation. We show that our algorithm is very fast, performing each iteration in less than one second on the Twitter graph and can be up to 7x faster compared to the standard GraphLab PageRank implementation.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Ioannis Mitliagkas, Michael Borokhovich, Alexandros G. Dimakis, Constantine Caramanis,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04280", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04280", "title": "\nCounterexample-Guided Polynomial Loop Invariant Generation by Lagrange  Interpolation", "abstract": "We apply multivariate Lagrange interpolation to synthesizing polynomial quantitative loop invariants for probabilistic programs. We reduce the computation of an quantitative loop invariant to solving constraints over program variables and unknown coefficients. Lagrange interpolation allows us to find constraints with less unknown coefficients. Counterexample-guided refinement furthermore generates linear constraints that pinpoint the desired quantitative invariants. We evaluate our technique by several case studies with polynomial quantitative loop invariants in the experiments.", "subjects": "Software Engineering (cs.SE)", "authors": "Yu-Fang Chen, Chih-Duo Hong, Bow-Yaw Wang, Lijun Zhang,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04275", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04275", "title": "\nsegDeepM: Exploiting Segmentation and Context in Deep Neural Networks  for Object Detection", "abstract": "In this paper, we propose an approach that exploits object segmentation in order to improve the accuracy of object detection. We frame the problem as inference in a Markov Random Field, in which each detection hypothesis scores object appearance as well as contextual information using Convolutional Neural Networks, and allows the hypothesis to choose and score a segment out of a large pool of accurate object segmentation proposals. This enables the detector to incorporate additional evidence when it is available and thus results in more accurate detections. Our experiments show an improvement of 4.1% in mAP over the R-CNN baseline on PASCAL VOC 2010, and 3.4% over the current state-of-the-art, demonstrating the power of our approach.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Yukun Zhu, Raquel Urtasun, Ruslan Salakhutdinov, Sanja Fidler,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04273", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04273", "title": "\nMulticoding Schemes for Interference Channels", "abstract": "The best known inner bound for the 2-user discrete memoryless interference channel is the Han-Kobayashi rate region. The coding schemes that achieve this region are based on rate-splitting and superposition coding. In this paper, we develop a multicoding scheme to achieve the same rate region. A key advantage of the multicoding nature of the proposed coding scheme is that it can be naturally extended to more general settings, such as when encoders have state information or can overhear each other. In particular, we extend our coding scheme to characterize the capacity region of the state-dependent deterministic Z-interference channel when noncausal state information is available at the interfering transmitter. We specialize our results to the case of the linear deterministic model with on/off interference which models a wireless system where a cognitive transmitter is noncausally aware of the times it interferes with a primary transmission. For this special case, we provide an explicit expression for the capacity region and discuss some interesting properties of the optimal strategy. We also extend our multicoding scheme to find the capacity region of the deterministic Z-interference channel when the signal of the interfering transmitter can be overheard at the other transmitter (a.k.a. unidirectional partial cribbing).", "subjects": "Information Theory (cs.IT)", "authors": "Ritesh Kolte, Ayfer \u00d6zg\u00fcr, Haim Permuter,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04272", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04272", "title": "\nSpatial Stimuli Gradient Sketch Model", "abstract": "The inability of automated edge detection methods inspired from primal sketch models to accurately calculate object edges under the influence of pixel noise is an open problem. Extending the principles of image perception i.e. Weber-Fechner law, and Sheperd similarity law, we propose a new edge detection method and formulation that use perceived brightness and neighbourhood similarity calculations in the determination of robust object edges. The robustness of the detected edges is benchmark against Sobel, SIS, Kirsch, and Prewitt edge detection methods in an example face recognition problem showing statistically significant improvement in recognition accuracy and pixel noise tolerance.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Joshin John Mathew, Alex Pappachen James,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04268", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04268", "title": "\nRelative Squared Distances to a Conic Berserkless 8-Connected Midpoint  Algorithm", "abstract": "The midpoint method or technique is a measurement and as each measurement it has a tolerance, but worst of all it can be invalid, called Out-of-Control or OoC. The core of all midpoint methods is the accurate measurement of the difference of the squared distances of two points to the polar of their midpoint with respect to the conic. When this measurement is valid, it also measures the difference of the squared distances of these points to the conic, although it may be inaccurate, called Out-of-Accuracy or OoA. The primary condition is the necessary and sufficient condition that a measurement is valid. It is comletely new and it can be checked ultra fast and before the actual measurement starts. Modeling an incremental algorithm, shows that the curve must be subdivided into piecewise monotonic sections, the start point must be optimal, and it explains that the 2D-incremental method can find, locally, the global Least Square Distance. Locally means that there are at most three candidate points for a given monotonic direction; therefore the 2D-midpoint method has, locally, at most three measurements. When all the possible measurements are invalid, the midpoint method cannot be applied, and in that case the ultra fast OoC-rule selects the candidate point. This guarantees, for the first time, a 100% stable, ultra-fast, berserkless midpoint algorithm, which can be easily transformed to hardware.", "subjects": "Graphics (cs.GR)", "authors": "Valere Huypens,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04266", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04266", "title": "\nConstrained Nonlinear Model Predictive Control of an MMA Polymerization  Process via Evolutionary Optimization", "abstract": "In this work, a nonlinear model predictive controller is developed for a batch polymerization process. The physical model of the process is parameterized along a desired trajectory resulting in a trajectory linearized piecewise model (a multiple linear model bank) and the parameters are identified for an experimental polymerization reactor. Then, a multiple model adaptive predictive controller is designed for thermal trajectory tracking of the MMA polymerization. The input control signal to the process is constrained by the maximum thermal power provided by the heaters. The constrained optimization in the model predictive controller is solved via genetic algorithms to minimize a DMC cost function in each sampling interval.", "subjects": "Systems and Control (cs.SY)", "authors": "Masoud Abbaszadeh, Reza Solgi,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04265", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04265", "title": "\nSolving $k$-means on High-dimensional Big Data", "abstract": "In recent years, there have been major efforts to develop data stream algorithms that process inputs in one pass over the data with little memory requirement. For the -means problem, this has led to the development of several -approximations (under the assumption that is a constant), but also to the design of algorithms that are extremely fast in practice and compute solutions of high accuracy. However, when not only the length of the stream is high but also the dimensionality of the input points, then current methods reach their limits. We propose two algorithms, piecy and piecy-mr that are based on the recently developed data stream algorithm BICO that can process high dimensional data in one pass and output a solution of high quality. While piecy is suited for high dimensional data with a medium number of points, piecy-mr is meant for high dimensional data that comes in a very long stream. We provide an extensive experimental study to evaluate piecy and piecy-mr that shows the strength of the new algorithms.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Jan-Philipp W. Kappmeier, Daniel R. Schmidt, Melanie Schmidt,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.04264", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04264", "title": "\nThe robustness of democratic consensus", "abstract": "In linear models of consensus dynamics, the state of the various agents converges to a value which is a convex combination of the agents' initial states. We call it democratic if in the large scale limit (number of agents going to infinity) the vector of convex weights converges to 0 uniformly. Democracy is a relevant property which naturally shows up when we deal with opinion dynamic models and cooperative algorithms such as consensus over a network: it says that each agent's measure/opinion is going to play a negligeable role in the asymptotic behavior of the global system. It can be seen as a relaxation of average consensus, where all agents have exactly the same weight in the final value, which becomes negligible for a large number of agents.", "subjects": "Systems and Control (cs.SY)", "authors": "Fabio Fagnani, Jean-Charles Delvenne,", "date": "2015-2-15"}, 
{"urllink": "http://arxiv.org/abs/1502.04254", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04254", "title": "\nSparse Attack Construction and State Estimation in the Smart Grid:  Centralized and Distributed Models", "abstract": "New methods that exploit sparse structures arising in smart grid networks are proposed for the state estimation problem when data injection attacks are present. First, construction strategies for unobservable sparse data injection attacks on power grids are proposed for an attacker with access to all network information and nodes. Specifically, novel formulations for the optimization problem that provide a flexible design of the trade-off between performance and false alarm are proposed. In addition, the centralized case is extended to a distributed framework for both the estimation and attack problems. Different distributed scenarios are proposed depending on assumptions that lead to the spreading of the resources, network nodes and players. Consequently, for each of the presented frameworks a corresponding optimization problem is introduced jointly with an algorithm to solve it. The validity of the presented procedures in real settings is studied through extensive simulations in the IEEE test systems.", "subjects": "Information Theory (cs.IT)", "authors": "Mete Ozay, Inaki Esnaola, Fatos T. Yarman Vural, Sanjeev R. Kulkarni, H. Vincent Poor,", "date": "2015-2-14"}, 
{"urllink": "http://arxiv.org/abs/1502.04252", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04252", "title": "\nCardiac MR Image Segmentation Techniques: an overview", "abstract": "Broadly speaking, the objective in cardiac image segmentation is to delineate the outer and inner walls of the heart to segment out either the entire or parts of the organ boundaries. This paper will focus on MR images as they are the most widely used in cardiac segmentation -- as a result of the accurate morphological information and better soft tissue contrast they provide. This cardiac segmentation information is very useful as it eases physical measurements that provides useful metrics for cardiac diagnosis such as infracted volumes, ventricular volumes, ejection fraction, myocardial mass, cardiac movement, and the like. But, this task is difficult due to the intensity and texture similarities amongst the different cardiac and background structures on top of some noisy artifacts present in MR images. Thus far, various researchers have proposed different techniques to solve some of the pressing issues. This seminar paper presents an overview of representative medical image segmentation techniques. The paper also highlights preferred approaches for segmentation of the four cardiac chambers: the left ventricle (LV), right ventricle (RV), left atrium (LA) and right atrium (RA), on short axis image planes.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Tizita Nesibu Shewaye,", "date": "2015-2-14"}, 
{"urllink": "http://arxiv.org/abs/1502.04250", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04250", "title": "\nHyperlinks embedded in Twitter as a proxy for total external inlinks to  international university websites", "abstract": "This article analyzes Twitter as a potential alternative source of external links for use in webometric analysis because of its capacity to embed hyperlinks in different tweets. Given the limitations on searching Twitter's public API, we decided to use the Topsy search engine as a source for compiling tweets. To this end, we took a global sample of 200 universities and compiled all the tweets with hyperlinks to any of these institutions. Further link data was obtained from alternative sources (MajesticSEO and OpenSiteExplorer) in order to compare the results. Thereafter, various statistical tests were performed to determine the correlation between the indicators and the ability to predict external links from the collected tweets. The results indicate a high volume of tweets, although they are skewed by the presence and performance of specific universities and countries. The data provided by Topsy correlated significantly with all link indicators, particularly with OpenSiteExplorer (r=0.769). Finally, prediction models do not provide optimum results because of high error rates, which fall slightly in nonlinear models applied to specific environments. We conclude that the use of Twitter (via Topsy) as a source of hyperlinks to universities produces promising results due to its high correlation with link indicators, though limited by policies and culture regarding use and presence in social networks.", "subjects": "Digital Libraries (cs.DL)", "authors": "Enrique Orduna-Malea, Daniel Torres-Salinas, Emilio Delgado Lopez-Cozar,", "date": "2015-2-14"}, 
{"urllink": "http://arxiv.org/abs/1502.04248", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04248", "title": "\nAsymptotic Justification of Bandlimited Interpolation of Graph signals  for Semi-Supervised Learning", "abstract": "Graph-based methods play an important role in unsupervised and semi-supervised learning tasks by taking into account the underlying geometry of the data set. In this paper, we consider a statistical setting for semi-supervised learning and provide a formal justification of the recently introduced framework of bandlimited interpolation of graph signals. Our analysis leads to the interpretation that, given enough labeled data, this method is very closely related to a constrained low density separation problem as the number of data points tends to infinity. We demonstrate the practical utility of our results through simple experiments.", "subjects": "Learning (cs.LG)", "authors": "Aamir Anis, Aly El Gamal, A. Salman Avestimehr, Antonio Ortega,", "date": "2015-2-14"}, 
{"urllink": "http://arxiv.org/abs/1502.04247", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04247", "title": "\nSupporting Instructors in Collaborating with Researchers using MOOClets", "abstract": "Most education and workplace learning takes place in classroom contexts far removed from laboratories or field sites with special arrangements for scientific research. But digital online resources provide a novel opportunity for large scale efforts to bridge the real world and laboratory settings which support data collection and randomized A/B experiments comparing different versions of content or interactions [2]. However, there are substantial technological and practical barriers in aligning instructors and researchers to use learning technologies like blended lessons/exercises &amp; MOOCs as both a service for students and a realistic context to conduct research. This paper explains how the concept of a MOOClet can facilitate research-practitioner collaborations. MOOClets [3] are defined as modular components of a digital resource that can be implemented in technology to: (1) allow modification to create multiple versions, (2) allow experimental comparison and personalization of different versions, (3) reliably specify what data are collected. We suggest a framework in which instructors specify what kinds of changes to lessons, exercises, and emails they would be willing to adopt, and what data they will collect and make available. Researchers can then: (1) specify or design experiments that compare the effects of different versions on quantifiable outcomes. (2) Explore algorithms for maximizing particular outcomes by choosing alternative versions of a MOOClet based on the input variables available. We present a prototype survey tool for instructors intended to facilitate practitioner researcher matches and successful collaborations.", "subjects": "Computers and Society (cs.CY)", "authors": "Joseph Jay Williams, Juho Kim, Brian C. Keegan,", "date": "2015-2-14"}, 
{"urllink": "http://arxiv.org/abs/1502.04246", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04246", "title": "\nStable leader election in population protocols requires linear time", "abstract": "A population protocol *stably elects a leader* if, for all , starting from an initial configuration with agents each in an identical state, with probability 1 it reaches a configuration that is correct (exactly one agent is in a special leader state ) and stable (every configuration reachable from also has a single agent in state ). We show that any population protocol that stably elects a leader requires expected \"parallel time\" --- expected total pairwise interactions --- to reach such a stable configuration. Our result also informs the understanding of the time complexity of chemical self-organization by showing an essential difficulty in generating exact quantities of molecular species quickly.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "David Doty, David Soloveichik,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.04245", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04245", "title": "\nUsing and Designing Platforms for In Vivo Education Experiments", "abstract": "In contrast to typical laboratory experiments, the everyday use of online educational resources by large populations and the prevalence of software infrastructure for A/B testing leads us to consider how platforms can embed in vivo experiments that do not merely support research, but ensure practical improvements to their educational components. Examples are presented of randomized experimental comparisons conducted by subsets of the authors in three widely used online educational platforms Khan Academy, edX, and ASSISTments. We suggest design principles for platform technology to support randomized experiments that lead to practical improvements enabling Iterative Improvement and Collaborative Work and explain the benefit of their implementation by WPI co-authors in the ASSISTments platform.", "subjects": "Human-Computer Interaction (cs.HC)", "authors": "Joseph Jay Williams, Korinn Ostrow, Xiaolu Xiong, Elena Glassman, Juho Kim, Samuel G. Maldonado, Na Li, Justin Reich, Neil Hefferman,", "date": "2015-2-14"}, 
{"urllink": "http://arxiv.org/abs/1502.04244", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04244", "title": "\nOptimal cyclic codes with generalized Niho type zeroes and the weight  distribution", "abstract": "In this paper we extend the works cite further in two directions and compute the weight distribution of these cyclic codes under more relaxed conditions. It is interesting to note that many cyclic codes in the family are optimal and have only a few non-zero weights. Besides using similar ideas from cite, we carry out some subtle manipulation of certain exponential sums.", "subjects": "Information Theory (cs.IT)", "authors": "Maosheng Xiong, Nian Li,", "date": "2015-2-14"}, 
{"urllink": "http://arxiv.org/abs/1502.04240", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04240", "title": "\nBatch processing of unit-length jobs with cubic incompatibility graphs  on three uniform machines", "abstract": "In the paper we consider the problem of scheduling identical jobs on 3 uniform batch machines with speeds and to minimize schedule length. We assume that jobs are restricted by mutual exclusion constraints modeled by a cubic incompatibility graph. We show that if the graph is 2-chromatic then the problem can be solved in time. If the graph is 3-chromatic, the problem becomes NP-hard even if . However, in this case there exists an approximation -time algorithm with performance ratio less than 4/3. Moreover, this algorithm solves the problem almost surely to optimality if .", "subjects": "Discrete Mathematics (cs.DM)", "authors": "H. Furma\u0144czyk, M. Kubale,", "date": "2015-2-14"}, 
{"urllink": "http://arxiv.org/abs/1502.04236", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04236", "title": "\nImpacts of Bad Data on the PMU based Line Outage Detection", "abstract": "An increasing number of Phasor Measurement Unit(PMU) have been deployed in power grids to increase the observability. Recent studies have shown that PMU data can be used to detect the outage of lines. On the other side, modern power system becomes more prone to cyber attacks due to the highly integration of information technology and communication network. In this paper, we demonstrated that an attacker can mask the outage of a single line by attacking a set of critical measurements. A mixed integer linear programming model is proposed to minimize the number of attacked measurements. The IEEE 39-bus system is used to demonstrate the masking scheme.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Xuan Liu, Zhiyi Li, Zuyi Li,", "date": "2015-2-14"}, 
{"urllink": "http://arxiv.org/abs/1502.04232", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04232", "title": "\nSketch-based Shape Retrieval using Pyramid-of-Parts", "abstract": "We present a multi-scale approach to sketch-based shape retrieval. It is based on a novel multi-scale shape descriptor called Pyramidof- Parts, which encodes the features and spatial relationship of the semantic parts of query sketches. The same descriptor can also be used to represent 2D projected views of 3D shapes, allowing effective matching of query sketches with 3D shapes across multiple scales. Experimental results show that the proposed method outperforms the state-of-the-art method, whether the sketch segmentation information is obtained manually or automatically by considering each stroke as a semantic part.", "subjects": "Graphics (cs.GR)", "authors": "Changqing Zou, Zhe Huang, Rynson W. H. Lau, Jianzhuang Liu, Hongbo Fu,", "date": "2015-2-14"}, 
{"urllink": "http://arxiv.org/abs/1502.04226", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04226", "title": "\nWidth Hierarchy for k-OBDD of Small Width", "abstract": "In this paper was explored well known model k-OBDD. There are proven width based hierarchy of classes of boolean functions which computed by k-OBDD. The proof of hierarchy is based on sufficient condition of Boolean function's non representation as k-OBDD and complexity properties of Boolean function SAF. This function is modification of known Pointer Jumping (PJ) and Indirect Storage Access (ISA) functions.", "subjects": "Computational Complexity (cs.CC)", "authors": "Kamil Khadiev,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.04221", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04221", "title": "\nA Row-parallel 8$\\times$8 2-D DCT Architecture Using Algebraic Integer  Based Exact Computation", "abstract": "An algebraic integer (AI) based time-multiplexed row-parallel architecture and two final-reconstruction step (FRS) algorithms are proposed for the implementation of bivariate AI-encoded 2-D discrete cosine transform (DCT). The architecture directly realizes an error-free 2-D DCT without using FRSs between row-column transforms, leading to an 88 2-D DCT which is entirely free of quantization errors in AI basis. As a result, the user-selectable accuracy for each of the coefficients in the FRS facilitates each of the 64 coefficients to have its precision set independently of others, avoiding the leakage of quantization noise between channels as is the case for published DCT designs. The proposed FRS uses two approaches based on (i) optimized Dempster-Macleod multipliers and (ii) expansion factor scaling. This architecture enables low-noise high-dynamic range applications in digital video processing that requires full control of the finite-precision computation of the 2-D DCT. The proposed architectures and FRS techniques are experimentally verified and validated using hardware implementations that are physically realized and verified on FPGA chip. Six designs, for 4- and 8-bit input word sizes, using the two proposed FRS schemes, have been designed, simulated, physically implemented and measured. The maximum clock rate and block-rate achieved among 8-bit input designs are 307.787 MHz and 38.47 MHz, respectively, implying a pixel rate of 8307.7872.462 GHz if eventually embedded in a real-time video-processing system. The equivalent frame rate is about 1187.35 Hz for the image size of 19201080. All implementations are functional on a Xilinx Virtex-6 XC6VLX240T FPGA device.", "subjects": "Hardware Architecture (cs.AR)", "authors": "A. Madanayake, R. J. Cintra, D. Onen, V. S. Dimitrov, N. T. Rajapaksha, L. T. Bruton, A. Edirisuriya,", "date": "2015-2-14"}, 
{"urllink": "http://arxiv.org/abs/1502.04220", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04220", "title": "\nExploring Hierarchies in Online Social Networks", "abstract": "Social hierarchy (i.e., pyramid structure of societies) is a fundamental concept in sociology and social network analysis. The importance of social hierarchy in a social network is that the topological structure of the social hierarchy is essential in both shaping the nature of social interactions between individuals and unfolding the structure of the social networks. The social hierarchy found in a social network can be utilized to improve the accuracy of link prediction, provide better query results, rank web pages, and study information flow and spread in complex networks. In this paper, we model a social network as a directed graph G, and consider the social hierarchy as DAG (directed acyclic graph) of G, denoted as GD. By DAG, all the vertices in G can be partitioned into different levels, the vertices at the same level represent a disjoint group in the social hierarchy, and all the edges in DAG follow one direction. The main issue we study in this paper is how to find DAG GD in G. The approach we take is to find GD by removing all possible cycles from G such that G = U(G) + GD where U(G) is a maximum Eulerian subgraph which contains all possible cycles. We give the reasons for doing so, investigate the properties of GD found, and discuss the applications. In addition, we develop a novel two-phase algorithm, called Greedy-&amp;-Refine, which greedily computes an Eulerian subgraph and then refines this greedy solution to find the maximum Eulerian subgraph. We give a bound between the greedy solution and the optimal. The quality of our greedy approach is high. We conduct comprehensive experimental studies over 14 real-world datasets. The results show that our algorithms are at least two orders of magnitude faster than the baseline algorithm.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Can Lu, Jeffrey Xu Yu, Rong-Hua Li, Hao Wei,", "date": "2015-2-14"}, 
{"urllink": "http://arxiv.org/abs/1502.04210", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04210", "title": "\nGrassmannian Codes as Lifts of Matrix Codes Derived as Images of Linear  Block Codes over Finite Fields", "abstract": "Let be a prime such that or mod . Linear block codes over the non-commutative matrix ring of matrices over the prime field endowed with the Bachoc weight are derived as isometric images of linear block codes over the Galois field endowed with the Hamming metric. When seen as rank metric codes, this family of matrix codes satisfies the Singleton bound and thus are maximum rank distance codes, which are then lifted to form a special class of subspace codes, the Grassmannian codes, that meet the anticode bound. These so-called anticode-optimal Grassmannian codes are associated in some way with complete graphs. New examples of these maximum rank distance codes and anticode-optimal Grassmannian codes are given.", "subjects": "Information Theory (cs.IT)", "authors": "Bryan Hernandez, Virgilio Sison,", "date": "2015-2-14"}, 
{"urllink": "http://arxiv.org/abs/1502.04205", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04205", "title": "\nLeader-follower Tracking Control with Guaranteed Consensus Performance  for Interconnected Systems with Linear Dynamic Uncertain Coupling", "abstract": "This paper considers the leader-follower tracking control problem for linear interconnected systems with undirected topology and linear dynamic coupling. Interactions between the systems are treated as linear dynamic uncertainty and are described in terms of integral quadratic constraints (IQCs). A consensus-type tracking control protocol is proposed for each system based on its state relative its neighbors. In addition a selected set of subsystems uses for control their relative states with respect to the leader. Two methods are proposed for the design of this control protocol. One method uses a coordinate transformation to recast the protocol design problem as a decentralized robust control problem for an auxiliary interconnected large scale system. Another method is direct, it does not employ coordinate transformation; it also allows for more general linear uncertain interactions. Using these methods, sufficient conditions are obtained which guarantee that the system tracks the leader. These conditions guarantee a suboptimal bound on the system consensus and tracking performance. The proposed methods are compared using a simulation example, and their effectiveness is discussed. Also, algorithms are proposed for computing suboptimal controllers.", "subjects": "Systems and Control (cs.SY)", "authors": "Yi Cheng, V. Ugrinovskii,", "date": "2015-2-14"}, 
{"urllink": "http://arxiv.org/abs/1502.04204", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04204", "title": "\nGray-Level Image Transitions Driven by Tsallis Entropic Index", "abstract": "The maximum entropy principle is largely used in thresholding and segmentation of images. Among the several formulations of this principle, the most effectively applied is that based on Tsallis non-extensive entropy. Here, we discuss the role of its entropic index in determining the thresholds. When this index is spanning the interval (0,1), for some images, the values of thresholds can have large leaps. In this manner, we observe abrupt transitions in the appearance of corresponding bi-level or multi-level images. These gray-level image transitions are analogous to order or texture transitions observed in physical systems, transitions which are driven by the temperature or by other physical quantities.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Amelia Carolina Sparavigna,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.04190", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04190", "title": "\nAn Adaptive Sampling Approach to 3D Reconstruction of Weld Joint", "abstract": "We present an adaptive sampling approach to 3D reconstruction of the welding joint using the point cloud that is generated by a laser sensor. We start with a randomized strategy to approximate the surface of the volume of interest through selection of a number of pivotal candidates. Furthermore, we introduce three proposal distributions over the neighborhood of each of these pivots to adaptively sample from their neighbors to refine the original randomized approximation to incrementally reconstruct this welding space. We prevent our algorithm from being trapped in a neighborhood via permanently labeling the visited samples. In addition, we accumulate the accepted candidates along with their selected neighbors in a queue structure to allow every selected sample to contribute to the evolution of the reconstructed welding space as the algorithm progresses. We analyze the performance of our adaptive sampling algorithm in contrast to the random sampling, with and without replacement, to show a significant improvement in total number of samples that are drawn to identify the region of interest, thereby expanding upon neighboring samples to extract the entire region in a fewer iterations and a shorter computation time.", "subjects": "Robotics (cs.RO)", "authors": "Soheil Keshmiri, Syeda Mariam Ahmed, Yue Wu, Chee Meng Chew, Chee Khiang Pang,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.04187", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04187", "title": "\nApplication of Deep Neural Network in Estimation of the Weld Bead  Parameters", "abstract": "We present a deep learning approach to estimation of the bead parameters in welding tasks. Our model is based on a four-hidden-layer neural network architecture. More specifically, the first three hidden layers of this architecture utilize Sigmoid function to produce their respective intermediate outputs. On the other hand, the last hidden layer uses a linear transformation to generate the final output of this architecture. This transforms our deep network architecture from a classifier to a non-linear regression model. We compare the performance of our deep network with a selected number of results in the literature to show a considerable improvement in reducing the errors in estimation of these values. Furthermore, we show its scalability on estimating the weld bead parameters with same level of accuracy on combination of datasets that pertain to different welding techniques. This is a nontrivial result that is counter-intuitive to the general belief in this field of research.", "subjects": "Learning (cs.LG)", "authors": "Soheil Keshmiri, Xin Zheng, Chee Meng Chew, Chee Khiang Pang,", "date": "2015-2-14"}, 
{"urllink": "http://arxiv.org/abs/1502.04186", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04186", "title": "\nSpectrum Allocation for Multi-Operator Device-to-Device Communication", "abstract": "In order to harvest the business potential of device-to-device (D2D) communication, direct communication between devices subscribed to different mobile operators should be supported. This would also support meeting requirements resulting from D2D relevant scenarios, like vehicle-to-vehicle communication. In this paper, we propose to allocate the multi-operator D2D communication over dedicated cellular spectral resources contributed from both operators. Ideally, the operators should negotiate about the amount of spectrum to contribute, without revealing proprietary information to each other and/or to other parties. One possible way to do that is to use the sequence of operators' best responses, i.e., the operators make offers about the amount of spectrum to contribute using a sequential updating procedure until reaching consensus. Besides spectrum allocation, we need a mode selection scheme for the multi-operator D2D users. We use a stochastic geometry framework to capture the impact of mode selection on the distribution of D2D users and assess the performance of the best response iteration algorithm. With the performance metrics considered in the paper, we show that the best response iteration has a unique Nash equilibrium that can be reached from any initial strategy. In general, asymmetric operators would contribute unequal amounts of spectrum for multi-operator D2D communication. Provided that the multi-operator D2D density is not negligible, we show that both operators may experience significant performance gains as compared to the scheme without spectrum sharing.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Byungjin Cho, Konstantinos Koufos, Riku J\u00e4ntti, Zexian Li, Mikko A. Uusitalo,", "date": "2015-2-14"}, 
{"urllink": "http://arxiv.org/abs/1502.04174", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04174", "title": "\nProbabilistic Models for High-Order Projective Dependency Parsing", "abstract": "This paper presents generalized probabilistic models for high-order projective dependency parsing and an algorithmic framework for learning these statistical models involving dependency trees. Partition functions and marginals for high-order dependency trees can be computed efficiently, by adapting our algorithms which extend the inside-outside algorithm to higher-order cases. To show the effectiveness of our algorithms, we perform experiments on three languages---English, Chinese and Czech, using maximum conditional likelihood estimation for model training and L-BFGS for parameter estimation. Our methods achieve competitive performance for English, and outperform all previously reported dependency parsers for Chinese and Czech.", "subjects": "Computation and Language (cs.CL)", "authors": "Xuezhe Ma, Hai Zhao,", "date": "2015-2-14"}, 
{"urllink": "http://arxiv.org/abs/1502.04170", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04170", "title": "\nHuman Factors in Agile Software Development", "abstract": "Through our four years experiments on students' Scrum based agile software development (ASD) process, we have gained deep understanding into the human factors of agile methodology. We designed an agile project management tool - the HASE collaboration development platform to support more than 400 students self-organized into 80 teams to practice ASD. In this thesis, Based on our experiments, simulations and analysis, we contributed a series of solutions and insights in this researches, including 1) a Goal Net based method to enhance goal and requirement management for ASD process, 2) a novel Simple Multi-Agent Real-Time (SMART) approach to enhance intelligent task allocation for ASD process, 3) a Fuzzy Cognitive Maps (FCMs) based method to enhance emotion and morale management for ASD process, 4) the first large scale in-depth empirical insights on human factors in ASD process which have not yet been well studied by existing research, and 5) the first to identify ASD process as a human-computation system that exploit human efforts to perform tasks that computers are not good at solving. On the other hand, computers can assist human decision making in the ASD process.", "subjects": "Software Engineering (cs.SE)", "authors": "Jun Lin,", "date": "2015-2-14"}, 
{"urllink": "http://arxiv.org/abs/1502.04169", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04169", "title": "\nComputationally Tractable Algorithms for Finding a Subset of  Non-defective Items from a Large Population", "abstract": "In the classical non-adaptive group testing setup, pools of items are tested together, and the main goal of a recovery algorithm is to identify the \"complete defective set\" given the outcomes of different group tests. In contrast, the main goal of a \"non-defective subset recovery\" algorithm is to identify a \"subset\" of non-defective items given the test outcomes. In this paper, we present a bouquet of computationally efficient and analytically tractable non-defective subset recovery algorithms. By analyzing the probability of error of the algorithms, we obtain bounds on the number of tests required for non-defective subset recovery with arbitrarily small probability of error. Our analysis accounts for the impact of both the additive noise (false positives) and dilution noise (false negatives). By comparing with the information theoretic lower bounds, we show that the upper bounds on the number of tests are order-wise tight up to a factor, where is the number of defective items. We also provide simulation results that compare the relative performance of the different algorithms and provide further insights into their practical utility. The proposed algorithms significantly outperform the straightforward approaches of testing items one-by-one, and of first identifying the defective set and then choosing the non-defective items from the complement set, in terms of the number of measurements required to ensure a given success rate.", "subjects": "Information Theory (cs.IT)", "authors": "Abhay Sharma, Chandra R. Murthy,", "date": "2015-2-14"}, 
{"urllink": "http://arxiv.org/abs/1502.04168", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04168", "title": "\nNonparametric regression using needlet kernels for spherical data", "abstract": "Needlets have been recognized as state-of-the-art tools to tackle spherical data, due to their excellent localization properties in both spacial and frequency domains. This paper considers developing kernel methods associated with the needlet kernel for nonparametric regression problems whose predictor variables are defined on a sphere. Due to the localization property in the frequency domain, we prove that the regularization parameter of the kernel ridge regression associated with the needlet kernel can decrease arbitrarily fast. A natural consequence is that the regularization term for the kernel ridge regression is not necessary in the sense of rate optimality. Based on the excellent localization property in the spacial domain further, we also prove that all the kernel regularization estimates associated with the needlet kernel, including the kernel lasso estimate and the kernel bridge estimate, possess almost the same generalization capability for a large range of regularization parameters in the sense of rate optimality. This finding tentatively reveals that, if the needlet kernel is utilized, then the choice of might not have a strong impact in terms of the generalization capability in some modeling contexts. From this perspective, can be arbitrarily specified, or specified merely by other no generalization criteria like smoothness, computational complexity, sparsity, etc..", "subjects": "Learning (cs.LG)", "authors": "Shaobo Lin,", "date": "2015-2-14"}, 
{"urllink": "http://arxiv.org/abs/1502.04165", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04165", "title": "\nCoexistence of Wi-Fi and Heterogeneous Small Cell Networks Sharing  Unlicensed Spectrum", "abstract": "As two major players in terrestrial wireless communications, Wi-Fi systems and cellular networks have different origins and have largely evolved separately. Motivated by the exponentially increasing wireless data demand, cellular networks are evolving towards a heterogeneous and small cell network architecture, wherein small cells are expected to provide very high capacity. However, due to the limited licensed spectrum for cellular networks, any effort to achieve capacity growth through network densification will face the challenge of severe inter-cell interference. In view of this, recent standardization developments have started to consider the opportunities for cellular networks to use the unlicensed spectrum bands, including the 2.4 GHz and 5 GHz bands that are currently used by Wi-Fi, Zigbee and some other communication systems. In this article, we look into the coexistence of Wi-Fi and 4G cellular networks sharing the unlicensed spectrum. We introduce a network architecture where small cells use the same unlicensed spectrum that Wi-Fi systems operate in without affecting the performance of Wi-Fi systems. We present an almost blank subframe (ABS) scheme without priority to mitigate the co-channel interference from small cells to Wi-Fi systems, and propose an interference avoidance scheme based on small cells estimating the density of nearby Wi-Fi access points to facilitate their coexistence while sharing the same unlicensed spectrum. Simulation results show that the proposed network architecture and interference avoidance schemes can significantly increase the capacity of 4G heterogeneous cellular networks while maintaining the service quality of Wi-Fi systems.", "subjects": "Information Theory (cs.IT)", "authors": "Haijun Zhang, Xiaoli Chu, Weisi Guo, Siyi Wang,", "date": "2015-2-14"}, 
{"urllink": "http://arxiv.org/abs/1502.04163", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04163", "title": "\nA Distributional Representation Model For Collaborative Filtering", "abstract": "In this paper, we propose a very concise deep learning approach for collaborative filtering that jointly models distributional representation for users and items. The proposed framework obtains better performance when compared against current state-of-art algorithms and that made the distributional representation model a promising direction for further research in the collaborative filtering.", "subjects": "Information Retrieval (cs.IR)", "authors": "Zhang Junlin, Cai Heng, Huang Tongwen, Xue Huiping,", "date": "2015-2-14"}, 
{"urllink": "http://arxiv.org/abs/1502.04156", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04156", "title": "\nTowards Biologically Plausible Deep Learning", "abstract": "Neuroscientists have long criticised deep learning algorithms as incompatible with current knowledge of neurobiology. We explore more biologically plausible versions of deep representation learning, focusing here mostly on unsupervised learning but developing a learning mechanism that could account for supervised, unsupervised and reinforcement learning. The starting point is that the basic learning rule believed to govern synaptic weight updates (Spike-Timing-Dependent Plasticity) can be interpreted as gradient descent on some objective function so long as the neuronal dynamics push firing rates towards better values of the objective function (be it supervised, unsupervised, or reward-driven). The second main idea is that this corresponds to a form of the variational EM algorithm, i.e., with approximate rather than exact posteriors, implemented by neural dynamics. Another contribution of this paper is that the gradients required for updating the hidden states in the above variational interpretation can be estimated using an approximation that only requires propagating activations forward and backward, with pairs of layers learning to form a denoising auto-encoder. Finally, we extend the theory about the probabilistic interpretation of auto-encoders to justify improved sampling schemes based on the generative interpretation of denoising auto-encoders, and we validate all these ideas on generative learning tasks.", "subjects": "Learning (cs.LG)", "authors": "Yoshua Bengio, Dong-Hyun Lee, Jorg Bornschein, Zhouhan Lin,", "date": "2015-2-14"}, 
{"urllink": "http://arxiv.org/abs/1502.04154", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04154", "title": "\nExtracting Hidden Groups and their Structure from Streaming Interaction  Data", "abstract": "When actors in a social network interact, it usually means they have some general goal towards which they are collaborating. This could be a research collaboration in a company or a foursome planning a golf game. We call such groups emph. In many social contexts, it might be possible to observe the emph between actors, even if the actors do not explicitly declare what groups they belong too. When groups are not explicitly declared, we call them emph. Our particular focus is hidden planning groups. By virtue of their need to further their goal, the actors within such groups must interact in a manner which differentiates their communications from random background communications. In such a case, one can infer (from these interactions) the composition and structure of the hidden planning groups. We formulate the problem of hidden group discovery from streaming interaction data, and we propose efficient algorithms for identifying the hidden group structures by isolating the hidden group's non-random, planning-related, communications from the random background communications. We validate our algorithms on real data (the Enron email corpus and Blog communication data). Analysis of the results reveals that our algorithms extract meaningful hidden group structures.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Mark K. Goldberg, Mykola Hayvanovych, Malik Magdon-Ismail, William A. Wallace,", "date": "2015-2-14"}, 
{"urllink": "http://arxiv.org/abs/1502.04149", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04149", "title": "\nJoint Optimization of Masks and Deep Recurrent Neural Networks for  Monaural Source Separation", "abstract": "Monaural source separation is important for many real world applications. It is challenging in that, given only single channel information is available, there is an infinite number of solutions without proper constraints. In this paper, we explore joint optimization of masking functions and deep recurrent neural networks for monaural source separation tasks, including the monaural speech separation task, monaural singing voice separation task, and speech denoising task. The joint optimization of the deep recurrent neural networks with an extra masking layer enforces a reconstruction constraint. Moreover, we explore a discriminative training criterion for the neural networks to further enhance the separation performance. We evaluate our proposed system on TSP, MIR-1K, and TIMIT dataset for speech separation, singing voice separation, and speech denoising tasks, respectively. Our approaches achieve 2.30~4.98 dB SDR gain compared to NMF models in the speech separation task, 2.30~2.48 dB GNSDR gain and 4.32~5.42 dB GSIR gain compared to previous models in the singing voice separation task, and outperform NMF and DNN baseline in the speech denoising task.", "subjects": "Sound (cs.SD)", "authors": "Po-Sen Huang, Minje Kim, Mark Hasegawa-Johnson, Paris Smaragdis,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.04148", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04148", "title": "\nOptimal Recovery in Noisy ICA", "abstract": "Independent Component Analysis (ICA) is a popular model for blind signal separation. The ICA model assumes that a number of independent source signals are linearly mixed to form the observed signal. Traditional ICA algorithms typically aim to recover the mixing matrix, the inverse of which can be applied to data in order to recover the latent independent signals. However, in the presence of noise, this demixing process is non-optimal for signal recovery as measured by signal-to-interference-plus-noise ratio (SINR), even if the mixing matrix is recovered exactly. This paper has two main contributions. First, we show how any solution to the mixing matrix reconstruction problem can be used to construct an SINR-optimal ICA demixing. The proposed method is optimal for any noise model and applies in the underdetermined setting when there are more source signals than observed signals. Second, we improve the recently proposed Gradient Iteration ICA algorithm to obtain provable and practical SINR optimal signal recovery for Gaussian noise with an arbitrary covariance matrix. We also simplify the original algorithm making the cumbersome quasi-orthogonalization step unnecessary, leading to improved computational performance.", "subjects": "Learning (cs.LG)", "authors": "James Voss, Mikhail Belkin, Luis Rademacher,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.04147", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04147", "title": "\nBayesian Incentive-Compatible Bandit Exploration", "abstract": "Individual decision-makers consume information revealed by the previous decision makers, and produce information that may help in future decision makers. This phenomena is common in a wide range of scenarios in the Internet economy, as well as elsewhere, such as medical decisions. Each decision maker when required to select an action, would individually prefer to exploit, select the highest expected reward action given her information. At the same time, each decision maker would prefer previous decision makes to explore, producing information about the rewards of various actions. A social planner, by means of carefully designed information disclosure, can incentivize the agents to balance the exploration and exploitation, and maximize social welfare. We formulate this problem as a multi-arm bandit problem (and various generalizations thereof) under incentive-compatibility constraints induced by agents' Bayesian priors. We design an incentive-compatible bandit algorithm for the social planner with asymptotically optimal regret. Further, we provide a black-box reduction from an arbitrary multi-arm bandit algorithm to an incentive-compatible one, with only a constant multiplicative increase in regret. This reduction works for very general bandit settings, even ones that incorporates contexts and arbitrary partial feedback.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Yishay Mansour, Aleksandrs Slivkins, Vasilis Syrgkanis,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.04137", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04137", "title": "\nNon-Adaptive Learning a Hidden Hipergraph", "abstract": "We give a new deterministic algorithm that non-adaptively learns a hidden hypergraph from edge-detecting queries. All previous non-adaptive algorithms either run in exponential time or have non-optimal query complexity. We give the first polynomial time non-adaptive learning algorithm for learning hypergraph that asks almost optimal number of queries.", "subjects": "Learning (cs.LG)", "authors": "Hasan Abasi, Nader H. Bshouty, Hanna Mazzawi,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.04132", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04132", "title": "\nLong-short Term Motion Feature for Action Classification and Retrieval", "abstract": "We propose a method for representing motion information for video classification and retrieval. We improve upon local descriptor based methods that have been among the most popular and successful models for representing videos. The desired local descriptors need to satisfy two requirements: 1) to be representative, 2) to be discriminative. Therefore, they need to occur frequently enough in the videos and to be be able to tell the difference among different types of motions. To generate such local descriptors, the video blocks they are based on must contain just the right amount of motion information. However, current state-of-the-art local descriptor methods use video blocks with a single fixed size, which is insufficient for covering actions with varying speeds. In this paper, we introduce a long-short term motion feature that generates descriptors from video blocks with multiple lengths, thus covering motions with large speed variance. Experimental results show that, albeit simple, our model achieves state-of-the-arts results on several benchmark datasets.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Zhenzhong Lan, Xuanchong Li, Ming Lin, Alexander G. Hauptmann,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.04120", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04120", "title": "\nAbout Tau-Chain", "abstract": "Tau-chain is a decentralized peer-to-peer network having three unified faces: Rules, Proofs, and Computer Programs, allowing a generalization of virtually any centralized or decentralized P2P network, together with many new abilities, as we present on this note.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Ohad Asor,", "date": "2015-2-16"}, 
{"urllink": "http://arxiv.org/abs/1502.04117", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04117", "title": "\nOverlapped-MIMO Radar Waveform Design for Coexistence With Communication  Systems", "abstract": "This paper explores an overlapped-multiple-input multiple-output (MIMO) antenna architecture and a spectrum sharing algorithm via null space projection (NSP) for radar-communications coexistence. In the overlapped-MIMO architecture, the transmit array of a collocated MIMO radar is partitioned into a number of subarrays that are allowed to overlap. Each of the antenna elements in these subarrays have signals orthogonal to each other and to the elements of the other subarrays. The proposed architecture not only improves sidelobe suppression to reduce interference to communications system, but also enjoys the advantages of MIMO radar without sacrificing the main desirable characteristics. The radar-centric spectrum sharing algorithm then projects the radar signal onto the null space of the communications system's interference channel, which helps to avoid interference from the radar. Numerical results are presented which show the performance of the proposed waveform design algorithm in terms of overall beampattern and sidelobe levels of the radar waveform and finally shows a comparison of the proposed system with existing collocated MIMO radar architectures.", "subjects": "Information Theory (cs.IT)", "authors": "Chowdhury Shahriar, Ahmed Abdelhadi, T. Charles Clancy,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.04110", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04110", "title": "\nModeling Brain Circuitry over a Wide Range of Scales", "abstract": "If we are ever to unravel the mysteries of brain function at its most fundamental level, we will need a precise understanding of how its component neurons connect to each other. Electron Microscopes (EM) can now provide the nanometer resolution that is needed to image synapses, and therefore connections, while Light Microscopes (LM) see at the micrometer resolution required to model the 3D structure of the dendritic network. Since both the topology and the connection strength are integral parts of the brain's wiring diagram, being able to combine these two modalities is critically important. In fact, these microscopes now routinely produce high-resolution imagery in such large quantities that the bottleneck becomes automated processing and interpretation, which is needed for such data to be exploited to its full potential. In this paper, we briefly review the Computer Vision techniques we have developed at EPFL to address this need. They include delineating dendritic arbors from LM imagery, segmenting organelles from EM, and combining the two into a consistent representation.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Pascal Fua, Graham Knott,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.04108", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04108", "title": "\nStructured Descriptions of Roles, Activities,and Procedures in the Roman  Constitution", "abstract": "A highly structured description of entities and events in histories can support flexible exploration of those histories by users and, ultimately, support richly-linked full-text digital libraries. Here, we apply the Basic Formal Ontology (BFO) to structure a passage about the Roman Constitution from Gibbon's Decline and Fall of the Roman Empire. Specifically, we consider the specification of Roles such as Consuls, Activities associated with those Roles, and Procedures for accomplishing those Activities.", "subjects": "Digital Libraries (cs.DL)", "authors": "Yoonmi Chu, Robert B. Allen,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.04100", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04100", "title": "\nAssigning UPDRS Scores in the Leg Agility Task of Parkinsonians: Can It  Be Done through BSN-based Kinematic Variables?", "abstract": "In this paper, by characterizing the Leg Agility (LA) task, which contributes to the evaluation of the degree of severity of the Parkinson's Disease (PD), through kinematic variables (including the angular amplitude and speed of thighs' motion), we investigate the link between these variables and Unified Parkinson's Disease Rating Scale (UPDRS) scores. Our investigation relies on the use of a few body-worn wireless inertial nodes and represents a first step in the design of a portable system, amenable to be integrated in Internet of Things (IoT) scenarios, for automatic detection of the degree of severity (in terms of UPDRS score) of PD. The experimental investigation is carried out considering 24 PD patients.", "subjects": "Computers and Society (cs.CY)", "authors": "Matteo Giuberti, Gianluigi Ferrari, Laura Contin, Veronica Cimolin, Corrado Azzaro, Giovanni Albani, Alessandro Mauro,", "date": "2014-10-31"}, 
{"urllink": "http://arxiv.org/abs/1502.04099", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04099", "title": "\nPower vs. Spectrum 2-D Sensing in Energy Harvesting Cognitive Radio  Networks", "abstract": "Energy harvester based cognitive radio is a promising solution to address the shortage of both spectrum and energy. Since the spectrum access and power consumption patterns are interdependent, and the power value harvested from certain environmental sources are spatially correlated, the new power dimension could provide additional information to enhance the spectrum sensing accuracy. In this paper, the Markovian behavior of the primary users is considered, based on which we adopt a hidden input Markov model to specify the primary vs. secondary dynamics in the system. Accordingly, we propose a 2-D spectrum and power (harvested) sensing scheme to improve the primary user detection performance, which is also capable of estimating the primary transmit power level. Theoretical and simulated results demonstrate the effectiveness of the proposed scheme, in term of the performance gain achieved by considering the new power dimension. To the best of our knowledge, this is the first work to jointly consider the spectrum and power dimensions for the cognitive primary user detection problem.", "subjects": "Information Theory (cs.IT)", "authors": "Yanyan Zhang, Weijia Han, Di Li, Ping Zhang, Shuguang Cui,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.04095", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04095", "title": "\nSequences of formation width $4$ and alternation length $5$", "abstract": "Sequence pattern avoidance is a central topic in combinatorics. A sequence contains a sequence if some subsequence of can be changed into by a one-to-one renaming of its letters. If does not contain , then avoids . A widely studied extremal function related to pattern avoidance is , the maximum length of an -letter sequence that avoids and has every consecutive letters pairwise distinct, where is the number of distinct letters in . We bound using the formation width function, , which is the minimum for which there exists such that any concatenation of permutations, each on the same letters, contains . In particular, we identify every sequence such that and contains . The significance of this result lies in its implication that, for every such sequence , we have , where denotes the incredibly slow-growing inverse Ackermann function. We have thus identified the extremal function of many infinite classes of previously unidentified sequences.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Jesse Geneson, Peter Tian,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.04071", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04071", "title": "\nThe generalized Lasso with non-linear observations", "abstract": "We study the problem of signal estimation from non-linear observations when the signal belongs to a low-dimensional set buried in a high-dimensional space. A rough heuristic often used in practice postulates that non-linear observations may be treated as noisy linear observations, and thus the signal may be estimated using the generalized Lasso. This is appealing because of the abundance of efficient, specialized solvers for this program. Just as noise may be diminished by projecting onto the lower dimensional space, the error from modeling non-linear observations with linear observations will be greatly reduced when using the signal structure in the reconstruction. We allow general signal structure, only assuming that the signal belongs to some set K in R^n. Our theory tolerates general non-linearity, which may be discontinuous, not one-to-one and even unknown. We assume a random Gaussian model for the measurement matrix, but allow the rows to have an unknown covariance matrix. As special cases of our results, we recover near-optimal theory for noisy linear observations, and also give the first theoretical accuracy guarantee for 1-bit compressed sensing with unknown covariance matrix of the measurement vectors.", "subjects": "Information Theory (cs.IT)", "authors": "Yaniv Plan, Roman Vershynin,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.04069", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04069", "title": "\nEvaluating Open Access Paper Repository In Higher Education For Asean  Region", "abstract": "Paper repository at higher education is a collection of scientific articles created by the academic society. This study took as many as 80 universities in the Webometrics ranking of repositories in the Southeast Asia region. The tools used in this research is Google for number of web page and Google Scholar for number of document paper repository and Ahrefs for referring page, backlink and reffering domain. The result of this study, Eprints is the most widely used tools in higher education, as many as 37 higher educations (46,25%). Institut Teknologi Sepuluh November got the highest score in number of web page in Google (2.010.000), Bogor Agricultural University Scientific Repository got the highest score for number of document paper (44.300). University of Sumatera Utara Repository got the highest score for reffering page (82588) and backlink (86421). Universiti Teknologi Malaysia Institutional Repository got the highest score for reffering domain (532).", "subjects": "Digital Libraries (cs.DL)", "authors": "Reza Chandra, Arif Purwo Nugroho, Fikri Saleh,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.04068", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04068", "title": "\nBuilding Nim", "abstract": "The game of nim, with its simple rules, its elegant solution and its historical importance is the quintessence of a combinatorial game, which is why it led to so many generalizations and modifications. We present a modification with a new spin: building nim. With given finite numbers of tokens and stacks, this two-player game is played in two stages (thus belonging to the same family of games as e.g. nine-men's morris): first building, where players alternate to put one token on one of the, initially empty, stacks until all tokens have been used. Then, the players play nim. Of course, because the solution for the game of nim is known, the goal of the player who starts nim play is a placement of the tokens so that the Nim-sum of the stack heights at the end of building is different from 0. This game is trivial if the total number of tokens is odd as the Nim-sum could never be 0, or if both the number of tokens and the number of stacks are even, since a simple mimicking strategy results in a Nim-sum of 0 after each of the second player's moves. We present the solution for this game for some non-trivial cases and state a general conjecture.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Eric Duch\u00eane, Matthieu Dufour, Silvia Heubach, Urban Larsson,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.04054", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04054", "title": "\nSensor Assisted Movement Identification and Prediction for Beamformed 60  GHz Links: A Report", "abstract": "Large available bandwidth in 60 ,GHz band promises very high data rates -- in the order of Gb/s. However, high free-space path loss makes it necessary to employ beamforming capable directional antennas. When beamforming is used, the links are sensitive to misalignment in antenna directionality because of movement of devices. To identify and circumvent the misalignments, we propose to use the motion sensors (i.e., accelerometer and gyroscope) which are already present in most of the modern mobile devices. By finding the extent of misaligned beams, corrective actions are carried out to reconfigure the antennas. Motion sensors on mobile devices provide means to estimate the extent of misalignments. We collected real data from motion sensors and steer the beams appropriately. The results from our study show that the sensors are capable of detecting the cause of errors as translational or rotational movements. Furthermore it is also shown that the sensor data can be used to predict the next location of the user. This can be used to reconfigure the directional antenna to switch the antenna beam directions and hence avoid frequent link disruptions. This decreases the number of beam searches thus lowering the MAC overhead.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "A.W. Doff, Kishor Chandra, R. Venkatesha Prasad,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.04052", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04052", "title": "\nComputer-aided verification in mechanism design", "abstract": "In mechanism design, the gold standard solution concepts are emph, and emph. These simple solution concepts relieve the (possibly unsophisticated) bidders from the need to engage in complicated strategizing. This is a clean story when the mechanism is \"obviously\" incentive compatible, as with a simple second price auction. However, when the proof of incentive compatibility is complex, unsophisticated agents may strategize in unpredictable ways if they are not emph of the incentive properties. In practice, this concern may limit the mechanism designer to emph mechanisms, simple enough that agents can easily understand. To alleviate this problem, we propose to use techniques from computer-aided verification in order to construct formal proofs of incentive properties. Because formal proofs can be automatically checked by (trustworthy) computer programs, agents do not need to verify complicated paper proofs by themselves. To confirm the viability of this approach, we present the verification of one sophisticated mechanism: the generic reduction from Bayesian incentive compatible mechanism design to algorithm design given by Hartline, Kleinberg, and Malekian (2011). This mechanism presents new challenges for formal verification, including essential use of randomness from both the execution of the mechanism and from prior type distributions. As a by-product, we also verify the entire family of mechanisms derived via this reduction.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Gilles Barthe, Marco Gaboardi, Emilio Jes\u00fas Gallego Arias, Justin Hsu, Aaron Roth, Pierre-Yves Strub,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.04049", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04049", "title": "\nHow essential are unstructured clinical narratives and information  fusion to clinical trial recruitment?", "abstract": "Electronic health records capture patient information using structured controlled vocabularies and unstructured narrative text. While structured data typically encodes lab values, encounters and medication lists, unstructured data captures the physician's interpretation of the patient's condition, prognosis, and response to therapeutic intervention. In this paper, we demonstrate that information extraction from unstructured clinical narratives is essential to most clinical applications. We perform an empirical study to validate the argument and show that structured data alone is insufficient in resolving eligibility criteria for recruiting patients onto clinical trials for chronic lymphocytic leukemia (CLL) and prostate cancer. Unstructured data is essential to solving 59% of the CLL trial criteria and 77% of the prostate cancer trial criteria. More specifically, for resolving eligibility criteria with temporal constraints, we show the need for temporal reasoning and information integration with medical events within and across unstructured clinical narratives and structured data.", "subjects": "Computers and Society (cs.CY)", "authors": "Preethi Raghavan, James L. Chen, Eric Fosler-Lussier, Albert M. Lai,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.04048", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04048", "title": "\nEfficient Algorithms for Envy-Free Stick Division With Fewest Cuts", "abstract": "Segal-Halevi, Hassidim, and Aumann (AAMAS, 2015) propose the problem of cutting sticks so that at least k sticks have equal length and no other stick is longer. This allows for an envy-free allocation of sticks to k players, one each. The resulting number of sticks should also be minimal. We analyze the structure of this problem and devise a linearithmic algorithm for it.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Raphael Reitzig, Sebastian Wild,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.04044", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04044", "title": "\nDownlink Throughput Driven Channel Access Framework for Cognitive LTE  Femto-Cells", "abstract": "This paper proposes an optimized sensing based channel access framework for the LTE cognitive femto-cells, with an objective of maximizing the femto-cells downlink throughput. Cognitive femto-cells opportunistically transmit on the macro-cell channels when they are free of use. Those free channels are located by means of spectrum sensing using energy detection. Moreover, periodic sensing is adopted to detect any changes of the sensing outcomes. The maximum attainable femto-cell downlink throughput varies with the macro-cell channel occupancy statistics. Therefore, the LTE macro-cell occupancy is empirically modeled using exponential distributions mixture. The LTE cognitive femto-cell downlink throughput is maximized by compromising the transmission efficiency, the explored spectrum opportunities and the interference from the macro-cell. An analytical solution for the optimal periodic sensing interval that maximizes the throughput is found and verified by simulations. The obtained results show that there is indeed a single periodic sensing interval value that maximizes the LTE cognitive femto-cell downlink throughput. At the peak of the macro-cell traffic, our framework increases the femto-cell throughput by around 15% compared to the senseless case. The impact of the available number of channels for opportunistic access is studied and no significant impact is found for more than three channels.", "subjects": "Information Theory (cs.IT)", "authors": "Mohamed Hamid, Slimane Ben Slimane, Niclas Bj\u00f6rsell,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.04042", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04042", "title": "\nAbstract Learning via Demodulation in a Deep Neural Network", "abstract": "Inspired by the brain, deep neural networks (DNN) are thought to learn abstract representations through their hierarchical architecture. However, at present, how this happens is not well understood. Here, we demonstrate that DNN learn abstract representations by a process of demodulation. We introduce a biased sigmoid activation function and use it to show that DNN learn and perform better when optimized for demodulation. Our findings constitute the first unambiguous evidence that DNN perform abstract learning in practical use. Our findings may also explain abstract learning in the human brain.", "subjects": "Learning (cs.LG)", "authors": "Andrew J.R. Simpson,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.04033", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04033", "title": "\nThe Responsibility Weighted Mahalanobis Kernel for Semi-Supervised  Training of Support Vector Machines for Classification", "abstract": "Kernel functions in support vector machines (SVM) are needed to assess the similarity of input samples in order to classify these samples, for instance. Besides standard kernels such as Gaussian (i.e., radial basis function, RBF) or polynomial kernels, there are also specific kernels tailored to consider structure in the data for similarity assessment. In this article, we will capture structure in data by means of probabilistic mixture density models, for example Gaussian mixtures in the case of real-valued input spaces. From the distance measures that are inherently contained in these models, e.g., Mahalanobis distances in the case of Gaussian mixtures, we derive a new kernel, the responsibility weighted Mahalanobis (RWM) kernel. Basically, this kernel emphasizes the influence of model components from which any two samples that are compared are assumed to originate (that is, the \"responsible\" model components). We will see that this kernel outperforms the RBF kernel and other kernels capturing structure in data (such as the LAP kernel in Laplacian SVM) in many applications where partially labeled data are available, i.e., for semi-supervised training of SVM. Other key advantages are that the RWM kernel can easily be used with standard SVM implementations and training algorithms such as sequential minimal optimization, and heuristics known for the parametrization of RBF kernels in a C-SVM can easily be transferred to this new kernel. Properties of the RWM kernel are demonstrated with 20 benchmark data sets and an increasing percentage of labeled samples in the training data.", "subjects": "Learning (cs.LG)", "authors": "Tobias Reitmaier, Bernhard Sick,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.04032", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04032", "title": "\nOn Projection Based Operators in Lp space for Exact Similarity Search", "abstract": "We investigate exact indexing for high dimensional Lp norms based on the 1-Lipschitz property and projection operators. The orthogonal projection that satisfies the 1-Lipschitz property for the Lp norm is described. The adaptive projection defined by the first principal component is introduced.", "subjects": "Information Retrieval (cs.IR)", "authors": "Andreas Wichert, Catarina Moreira,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.04025", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04025", "title": "\nQPACE 2 and Domain Decomposition on the Intel Xeon Phi", "abstract": "We give an overview of QPACE 2, which is a custom-designed supercomputer based on Intel Xeon Phi processors, developed in a collaboration of Regensburg University and Eurotech. We give some general recommendations for how to write high-performance code for the Xeon Phi and then discuss our implementation of a domain-decomposition-based solver and present a number of benchmarks.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Paul Arts, Jacques Bloch, Peter Georg, Benjamin Glaessle, Simon Heybrock, Yu Komatsubara, Robert Lohmayer, Simon Mages, Bernhard Mendl, Nils Meyer, Alessio Parcianello, Dirk Pleiter, Florian Rappl, Mauro Rossi, Stefan Solbrig, Giampietro Tecchiolli, Tilo Wettig, Gianpaolo Zanier,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.04023", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04023", "title": "\nThe Meaning of Attack-Resistant Programs", "abstract": "In this paper, we introduce a formal notion of partial compliance, called attack-resistance, of a computer program w.r.t a non- exploitability specification. In our setting, a program may contain exploitable vulnerabilities, such as buffer overflows, but appropriate defense mechanisms built into the program or the operating system render such vulnerabilities hard to exploit by resource bounded attackers, usually relying on the strength of the randomness of a probabilistic transformation of the environment or the program. We are motivated by the reality that most large-scale programs have vulnerabilities despite our best efforts to get rid of them. Security researchers have responded to this state of affairs by coming up with ingenious defense mechanisms such as address space layout randomization (ASLR) or instruction set randomization (ISR) that provide some protection against exploitation. By formalizing this notion of attack-resistance we pave the way towards addressing the questions: \"How do we formally analyze these defense mechanisms? Is there a mathematical way of distinguishing effective defense mechanisms from ineffective ones? Can we quantify and show that these defense mechanisms provide formal security guarantees, albeit partial, even in the presence of exploitable vulnerabilities?\". To illustrate our approach we discuss informally why an enhancement to PointGuard complies with the attack-resistance definition.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Vijay Ganesh, Sebastian Banescu, Mart\u00edn Ochoa,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.04022", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04022", "title": "\nLocal Computation Algorithms for Graphs of Non-Constant Degrees", "abstract": "In the model of emph (LCAs), we aim to compute the queried part of the output by examining only a small (sublinear) portion of the input. Many recently developed LCAs on graph problems achieve time and space complexities with very low dependence on , the number of vertices. Nonetheless, these complexities are generally at least exponential in , the upper bound on the degree of the input graph. Instead, we consider the case where parameter can be moderately dependent on , and aim for complexities with subexponential dependence on , while maintaining polylogarithmic dependence on . We present: a randomized LCA for computing maximal independent sets whose time and space complexities are quasi-polynomial in and polylogarithmic in ; for constant , a randomized LCA that provides a -approximation to maximum matching whose time and space complexities are polynomial in and polylogarithmic in .", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Reut Levi, Ronitt Rubinfeld, Anak Yodpinyanee,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.04019", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04019", "title": "\nInducing Approximately Optimal Flow Using Truthful Mediators", "abstract": "We revisit a classic coordination problem from the perspective of mechanism design: how can we coordinate a social welfare maximizing flow in a network congestion game with selfish players? The classical approach, which computes tolls as a function of known demands, fails when the demands are unknown to the mechanism designer, and naively eliciting them does not necessarily yield a truthful mechanism. Instead, we introduce a weak mediator that can provide suggested routes to players and set tolls as a function of reported demands. However, players can choose to ignore or misreport their type to this mediator. Using techniques from differential privacy, we show how to design a weak mediator such that it is an asymptotic ex-post Nash equilibrium for all players to truthfully report their types to the mediator and faithfully follow its suggestion, and that when they do, they end up playing a nearly optimal flow. Notably, our solution works in settings of incomplete information even in the absence of a prior distribution on player types. Along the way, we develop new techniques for privately solving convex programs which may be of independent interest.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Ryan Rogers, Aaron Roth, Jonathan Ullman, Zhiwei Steven Wu,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.04015", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04015", "title": "\nDecentralized Trusted Timestamping using the Crypto Currency Bitcoin", "abstract": "Trusted timestamping is a process for proving that certain information existed at a given point in time. This paper presents a trusted timestamping concept and its implementation in form of a web-based service that uses the decentralized Bitcoin block chain to store anonymous, tamper-proof timestamps for digital content. The service allows users to hash files, such as text, photos or videos, and store the created hashes in the Bitcoin block chain. Users can then retrieve and verify the timestamps that have been committed to the block chain. The non-commercial service enables anyone, e.g., researchers, authors, journalists, students, or artists, to prove that they were in possession of certain information at a given point in time. Common use cases include proving that a contract has been signed, a photo taken, a video recorded, or a task completed prior to a certain date. All procedures maintain complete privacy of the user's data.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Bela Gipp, Norman Meuschke, Andr\u00e9 Gernandt,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.04014", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04014", "title": "\nStakeholders, Viewpoints and Languages of a Modelling Framework for the  Design and Development of Data-Intensive Mobile Apps", "abstract": "Today millions of mobile apps are downloaded and used all over the world. Guidelines and best practices on how to design and develop mobile apps are being periodically released, mainly by mobile platform vendors and researchers. They cover different concerns, and refer to different technical and non-technical stakeholders. Still, mobile applications are developed with ad-hoc development processes, and on-paper best practices. In this paper we discuss a multi-view modelling framework supporting the collaborative design and development of mobile apps. The proposed framework embraces the Model-Driven Engineering methodology. This paper provides an overall view of the modelling framework in terms of its main stakeholders, viewpoints, and modelling languages.", "subjects": "Software Engineering (cs.SE)", "authors": "Mirco Franzago, Ivano Malavolta, Henry Muccini,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.04013", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04013", "title": "\nDeep Neural Programs for Adaptive Control in Cyber-Physical Systems", "abstract": "We introduce Deep Neural Programs (DNP), a novel programming paradigm for writing adaptive controllers for cy-ber-physical systems (CPS). DNP replace if and while statements, whose discontinuity is responsible for undecidability in CPS analysis, intractability in CPS design, and frailness in CPS implementation, with their smooth, neural nif and nwhile counterparts. This not only makes CPS analysis decidable and CPS design tractable, but also allows to write robust and adaptive CPS code. In DNP the connection between the sigmoidal guards of the nif and nwhile statements has to be given as a Gaussian Bayesian network, which reflects the partial knowledge, the CPS program has about its environment. To the best of our knowledge, DNP are the first approach linking neural networks to programs, in a way that makes explicit the meaning of the network. In order to prove and validate the usefulness of DNP, we use them to write and learn an adaptive CPS controller for the parallel parking of the Pioneer rovers available in our CPS lab.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Konstantin Selyunin, Denise Ratasich, Ezio Bartocci, Radu Grosu,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.04010", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.04010", "title": "\nFinding Structural Information of RF Power Amplifiers using an  Orthogonal Non-Parametric Kernel Smoothing Estimator", "abstract": "A non-parametric technique to model the behavior of power amplifiers is presented. The proposed technique relies on the principles of density estimation using the kernel method and it is suited for the application of power amplifier modeling. The proposed methodology transforms the input domain to an orthogonal memory domain. In such a domain, non-parametric static functions are discovered using the kernel estimator. These orthogonal non-parametric functions can be fitted with any desired mathematical structure, e.g., facilitating its implementation. Furthermore, due to the orthogonality, the non-parametric functions can be analyzed and discarded individually, which eases pruning basis functions and trading off complexity and performance. The results show that the methodology can be employed to model power amplifiers yielding error performance similarly to state-of-art parametric models. Furthermore, a parameter efficient model structure with 6 coefficients was derived for a Doherty PA, significantly reducing the deployment computational complexity. Finally, the methodology can be as well exploited in digital linearization techniques.", "subjects": "Information Theory (cs.IT)", "authors": "Efrain Zenteno, Zain Ahmed Khan, Magnus Isaksson, Peter Handel,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.03990", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03990", "title": "\nNonlinear Attitude Filtering: A Comparison Study", "abstract": "This paper contains a concise comparison of a number of nonlinear attitude filtering methods that have attracted attention in the robotics and aviation literature. With the help of previously published surveys and comparison studies, the vast literature on the subject is narrowed down to a small pool of competitive attitude filters. Amongst these filters is a second-order optimal minimum-energy filter recently proposed by the authors. Easily comparable discretized unit quaternion implementations of the selected filters are provided. We conduct a simulation study and compare the transient behaviour and asymptotic convergence of these filters in two scenarios with different initialization and measurement errors inspired by applications in unmanned aerial robotics and space flight. The second-order optimal minimum-energy filter is shown to have the best performance of all filters, including the industry standard multiplicative extended Kalman filter (MEKF).", "subjects": "Systems and Control (cs.SY)", "authors": "M. Zamani, J. Trumpf, R. Mahony,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.03989", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03989", "title": "\nParameterized Complexity of Secluded Connectivity Problems", "abstract": "The Secluded Path problem models a situation where a sensitive information has to be transmitted between a pair of nodes along a path in a network. The measure of the quality of a selected path is its exposure, which is the total weight of vertices in its closed neighborhood. In order to minimize the risk of intercepting the information, we are interested in selecting a secluded path, i.e. a path with a small exposure. Similarly, the Secluded Steiner Tree problem is to find a tree in a graph connecting a given set of terminals such that the exposure of the tree is minimized. The problems were introduced by Chechik et al. in [ESA 2013]. Among other results, Chechik et al. have shown that Secluded Path is fixed-parameter tractable (FPT) on unweighted graphs being parameterized by the maximum vertex degree of the graph and that Secluded Steiner Tree is FPT parameterized by the treewidth of the graph. In this work, we obtain the following results about parameterized complexity of secluded connectivity problems. We give FPT-algorithms deciding if a graph G with a given cost function contains a secluded path and a secluded Steiner tree of exposure at most k with the cost at most C. We initiate the study of \"above guarantee\" parameterizations for secluded problems, where the lower bound is given by the size of a Steiner tree. We investigate Secluded Steiner Tree from kernelization perspective and provide several lower and upper bounds when parameters are the treewidth, the size of a vertex cover, maximum vertex degree and the solution size. Finally, we refine the algorithmic result of Chechik et al. by improving the exponential dependence from the treewidth of the input graph.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Fedor V. Fomin, Petr A. Golovach, Nikolay Karpov, Alexander S. Kulikov,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.03986", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03986", "title": "\nSUNNY-CP 2: a Parallel CP Portfolio Solver", "abstract": "In Constraint Programming (CP), a portfolio solver uses a variety of different solvers for solving a given Constraint Satisfaction / Optimization Problem. In this paper we introduce sunny-cp2: the first parallel CP portfolio solver that enables a dynamic, cooperative, and simultaneous execution of its solvers in a multicore setting. It incorporates state-of-the-art solvers, providing also a usable and configurable framework. Empirical results are very promising. sunny-cp2 can even outperform the performance of the oracle solver which always selects the best solver of the portfolio for a given problem.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Roberto Amadini, Maurizio Gabbrielli, Jacopo Mauro,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.03985", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03985", "title": "\nA local strategy for cleaning expanding cellular domains by simple  robots", "abstract": "We present a strategy SEP for finite state machines tasked with cleaning a cellular environment in which a contamination spreads. Initially, the contaminated area is of height and width . It may be bounded by four monotonic chains, and contain rectangular holes. The robot does not know the initial contamination, sensing only the eight cells in its neighborhood. It moves from cell to cell, times faster than the contamination spreads, and is able to clean its current cell. A speed of is in general not sufficient to contain the contamination. Our strategy SEP succeeds if holds. It ensures that the contaminated cells stay connected. Greedy strategies violating this principle need speed at least ; all bounds are up to small additive constants.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Rolf Klein, David Kriesel, Elmar Langetepe,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.03974", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03974", "title": "\nA Note on Semi-Algebraic Proofs and Gaussian Elimination over Prime  Fields", "abstract": "In this note we show that unsatisfiable systems of linear equations with a constant number of variables per equation over prime finite fields have polynomial-size constant-degree semi-algebraic proofs of unsatisfiability. These are proofs that manipulate polynomial inequalities over the reals with variables ranging in . This upper bound is to be put in contrast with the known fact that, for certain explicit systems of linear equations over the two-element field, such refutations require linear degree and exponential size if they are restricted to so-called static semi-algebraic proofs, and even tree-like semi-algebraic and sums-of-squares proofs. Our upper bound is a more or less direct translation of an argument due to Grigoriev, Hirsch and Pasechnik (Moscow Mathematical Journal, 2002) who did it for a family of linear systems of interest in propositional proof complexity. We point out that their method is more general and can be thought of as simulating Gaussian elimination.", "subjects": "Computational Complexity (cs.CC)", "authors": "Albert Atserias,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.03971", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03971", "title": "\nNear-optimal adjacency labeling scheme for power-law graphs", "abstract": "An adjacency labeling scheme is a method that assigns labels to the vertices of a graph such that adjacency between vertices can be inferred directly from the assigned label, without using a centralized data structure. We devise adjacency labeling schemes for the family of power-law graphs. This family that has been used to model many types of networks, e.g. the Internet AS-level graph. Furthermore, we prove an almost matching lower bound for this family. We also provide an asymptotically near- optimal labeling scheme for sparse graphs. Finally, we validate the efficiency of our labeling scheme by an experimental evaluation using both synthetic data and real-world networks of up to hundreds of thousands of vertices.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Casper Petersen, Noy Rotbart, Jakob Grue Simonsen, Christian Wulff-Nilsen,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.03967", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03967", "title": "\nExtractions: Computable and Visible Analogues of Localizations for  Polynomial Ideals", "abstract": "When studying local properties of a polynomial ideal, one usually needs a theoretic technique called localization. For most cases, in spite of its importance, the computation in a localized ring cannot be algorithmically preformed. On the other hand, the standard basis method is very effective for the computation in a special kind of localized rings, but for a general semigroup order the geometry of the localization of a positive-dimensional ideal is difficult to interpret. In this paper, we introduce a new ideal operation called extraction. For an ideal in a polynomial ring over a field , we use another ideal to control the primary components of and the result is called the extraction of by . It is still a polynomial ideal and has a concrete geometric meaning in , i.e., we keep the branches of that intersect with and delete others, where is the algebraic closure of . This is what we mean by visible. On the other hand, we can use the standard basis method to compute a localized ideal corresponding to without a complete primary decomposition, and can do further computation in the localized ring such as determining the membership problem of . Moreover, we prove that extractions are as powerful as localizations in the sense that for any multiplicatively closed subset of and any polynomial ideal , there always exists a polynomial ideal such that .", "subjects": "Symbolic Computation (cs.SC)", "authors": "Ye Liang,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.03965", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03965", "title": "\nUniform Kernelization Complexity of Hitting Forbidden Minors", "abstract": "The F-Minor-Free Deletion problem asks, for a fixed set F and an input consisting of a graph G and integer k, whether k vertices can be removed from G such that the resulting graph does not contain any member of F as a minor. This paper analyzes to what extent provably effective and efficient preprocessing is possible for F-Minor-Free Deletion. Fomin et al. (FOCS 2012) showed that the special case Planar F-Deletion (when F contains at least one planar graph) has a kernel of size f(F) * k^ for some functions f and g. The degree g of the polynomial grows very quickly; it is not even known to be computable. Fomin et al. left open whether Planar F-Deletion has kernels whose size is uniformly polynomial, i.e., of the form f(F) * k^c for some universal constant c that does not depend on F. Our results in this paper are twofold. (1) We prove that some Planar F-Deletion problems do not have uniformly polynomial kernels (unless NP is in coNP/poly). In particular, we prove that Treewidth-Eta Deletion does not have a kernel with O(k^ - eps) vertices for any eps &gt; 0, unless NP is in coNP/poly. In fact, we even prove the kernelization lower bound for the larger parameter vertex cover number. This resolves an open problem of Cygan et al. (IPEC 2011). It is a natural question whether further restrictions on F lead to uniformly polynomial kernels. However, we prove that even when F contains a path, the degree of the polynomial must, in general, depend on the set F. (2) A canonical F-Minor-Free Deletion problem when F contains a path is Treedepth-eta Deletion: can k vertices be removed to obtain a graph of treedepth at most eta? We prove that Treedepth-eta Deletion admits uniformly polynomial kernels with O(k^6) vertices for every fixed eta. In order to develop the kernelization we prove several new results about the structure of optimal treedepth-decompositions.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Archontia C. Giannopoulou, Bart M. P. Jansen, Daniel Lokshtanov, Saket Saurabh,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.03951", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03951", "title": "\nVarieties", "abstract": "This text is devoted to the theory of varieties, which provides an important tool, based in universal algebra, for the classification of regular languages. In the introductory section, we present a number of examples that illustrate and motivate the fundamental concepts. We do this for the most part without proofs, and often without precise definitions, leaving these to the formal development of the theory that begins in Section 2. Our presentation of the theory draws heavily on the work of Gehrke, Grigorieff and Pin (2008) on the equational theory of lattices of regular languages. In the subsequent sections we consider in more detail aspects of varieties that were only briefly evoked in the introduction: Decidability, operations on languages, and characterizations in formal logic.", "subjects": "Formal Languages and Automata Theory (cs.FL)", "authors": "Howard Straubing, Pascal Weil,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.03946", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03946", "title": "\nPrimal-dual and dual-fitting analysis of online scheduling algorithms  for generalized flow-time problems", "abstract": "We study a variety of online scheduling problems on a single processor that can be viewed as extensions of the well-studied problem of minimizing total weighted flow time. Most previous work on this class of problems has relied on amortized analysis and the use of complicated potential-function arguments. In this paper we follow a different approach based on the primal-dual and dual-fitting paradigms. In particular, we provide a framework of analysis that is derived by duality properties, does not rely on potential functions, gives insights for new algorithms, and is applicable to a variety of scheduling problems. We begin with an interpretation of the algorithm Highest-Density-First (HDF) as a primal-dual algorithm, and a proof that HDF is optimal for total weighted fractional flow time, which directly implies that it is scalable for the integral objective. Building upon the salient ideas of the proof, we show how to apply and extend this analysis to the more general problem of minimizing the objective , where is the weight of a job, is the flow time of the schedule and is a non-decreasing cost function. For the case in which is a concave function and the case of same-density jobs but general cost functions, we obtain scalable algorithms. We further apply our framework of analysis to the following two scheduling problems: i) the online weighted completion time problem with general cost functions and ii) the problem of scheduling under polyhedral constraints, in which we seek to minimize flow time subject to packing constraints over the set of rates of the outstanding jobs. Last, for the even broader objective , i.e., when each job is associated with a distinct concave differentiable function , we give a scalable algorithm (using dual-fitting analysis) that relies on an extension of recent work of Im et al. [FOCS'14].", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Spyros Angelopoulos, Giorgio Lucarelli, Nguyen Kim Thang,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.03945", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03945", "title": "\nEfficiency and complexity of price competition among single-product  vendors", "abstract": "Motivated by recent progress on pricing in the AI literature, we study marketplaces that contain multiple vendors offering identical or similar products and unit-demand buyers with different valuations on these vendors. The objective of each vendor is to set the price of its product to a fixed value so that its profit is maximized. The profit depends on the vendor's price itself and the total volume of buyers that find the particular price more attractive than the price of the vendor's competitors. We model the behaviour of buyers and vendors as a two-stage full-information game and study a series of questions related to the existence, efficiency (price of anarchy) and computational complexity of equilibria in this game. To overcome situations where equilibria do not exist or exist but are highly inefficient, we consider the scenario where some of the vendors are subsidized in order to keep prices low and buyers highly satisfied.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Ioannis Caragiannis, Xenophon Chatzigeorgiou, Panagiotis Kanellopoulos, George A. Krimpas, Nikos Protopapas, Alexandros A. Voudouris,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.03943", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03943", "title": "\nImproving Access to Digitized Historical Newspapers with Text Mining,  Coordinated Models, and Formative User Interface Design", "abstract": "Most tools for accessing digitized historical newspapers emphasize relatively simple search; but, as increasing numbers of digitized historical newspapers and other historical resources become available we can consider much richer modes of interaction with these collections. For instance, users might use exploratory search for looking at larger issues and events such as elections and campaigns or to get a sense of \"the texture of the city\" or \"what the city was thinking\". To take full advantage of rich interface tools, the content of the newspapers needs to be described systematically and accurately. Moreover, collections of multiple newspapers need to be richly cross-indexed across titles and even with historical resources beyond the newspapers.", "subjects": "Digital Libraries (cs.DL)", "authors": "Robert B. Allen,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.03942", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03942", "title": "\nCommunication Efficient Algorithms for Top-k Selection Problems", "abstract": "We present scalable parallel algorithms with sublinear communication volume and low latency for several fundamental problems related to finding the most relevant elements in a set: the classical selection problem with unsorted input, its variant with locally sorted input, bulk parallel priority queues, multicriteria selection using threshold algorithms, and finding the most frequent objects. All of these algorithms push the owner-computes rule to extremes. The output of these algorithms might unavoidably be unevenly distributed over the processors. We therefore also explain how to redistribute this data with minimal communication.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Lorenz H\u00fcbschle-Schneider, Peter Sanders, Ingo M\u00fcller,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.03919", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03919", "title": "\nPolicy Gradient for Coherent Risk Measures", "abstract": "We provide sampling-based algorithms for optimization under a coherent-risk objective. The class of coherent-risk measures is widely accepted in finance and operations research, among other fields, and encompasses popular risk-measures such as the conditional value at risk (CVaR) and the mean-semi-deviation. Our approach is suitable for problems in which the tunable parameters control the distribution of the cost, such as in reinforcement learning with a parameterized policy; such problems cannot be solved using previous approaches. We consider both static risk measures, and time-consistent dynamic risk measures. For static risk measures, our approach is in the spirit of policy gradient algorithms, while for the dynamic risk measures our approach is actor-critic style.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Aviv Tamar, Yinlam Chow, Mohammad Ghavamzadeh, Shie Mannor,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.03918", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03918", "title": "\nGradient Difference based approach for Text Localization in Compressed  domain", "abstract": "In this paper, we propose a gradient difference based approach to text localization in videos and scene images. The input video frame/ image is first compressed using multilevel 2-D wavelet transform. The edge information of the reconstructed image is found which is further used for finding the maximum gradient difference between the pixels and then the boundaries of the detected text blocks are computed using zero crossing technique. We perform logical AND operation of the text blocks obtained by gradient difference and the zero crossing technique followed by connected component analysis to eliminate the false positives. Finally, the morphological dilation operation is employed on the detected text blocks for scene text localization. The experimental results obtained on publicly available standard datasets illustrate that the proposed method can detect and localize the texts of various sizes, fonts and colors.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "B.H. Shekar, Smitha M.L,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.03913", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03913", "title": "\nSkeleton Matching based approach for Text Localization in Scene Images", "abstract": "In this paper, we propose a skeleton matching based approach which aids in text localization in scene images. The input image is preprocessed and segmented into blocks using connected component analysis. We obtain the skeleton of the segmented block using morphology based approach. The skeletonized images are compared with the trained templates in the database to categorize into text and non-text blocks. Further, the newly designed geometrical rules and morphological operations are employed on the detected text blocks for scene text localization. The experimental results obtained on publicly available standard datasets illustrate that the proposed method can detect and localize the texts of various sizes, fonts and colors.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "B.H. Shekar, Smitha M.L,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.03908", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03908", "title": "\nCustomer Engagement Plans for Peak Load Reduction in Residential Smart  Grids", "abstract": "In this paper, we propose and study the effectiveness of customer engagement plans that clearly specify the amount of intervention in customer's load settings by the grid operator for peak load reduction. We suggest two different types of plans, including Constant Deviation Plans (CDPs) and Proportional Deviation Plans (PDPs). We define an adjustable reference temperature for both CDPs and PDPs to limit the output temperature of each thermostat load and to control the number of devices eligible to participate in Demand Response Program (DRP). We model thermostat loads as power throttling devices and design algorithms to evaluate the impact of power throttling states and plan parameters on peak load reduction. Based on the simulation results, we recommend PDPs to the customers of a residential community with variable thermostat set point preferences, while CDPs are suitable for customers with similar thermostat set point preferences. If thermostat loads have multiple power throttling states, customer engagement plans with less temperature deviations from thermostat set points are recommended. Contrary to classical ON/OFF control, higher temperature deviations are required to achieve similar amount of peak load reduction. Several other interesting tradeoffs and useful guidelines for designing mutually beneficial incentives for both the grid operator and customers can also be identified.", "subjects": "Systems and Control (cs.SY)", "authors": "Naveed Ul Hassan, Yawar Ismail Khalid, Chau Yuen, Wayes Tushar,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.03903", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03903", "title": "\nCoding for Network-Coded Slotted ALOHA", "abstract": "Slotted ALOHA can benefit from physical-layer network coding (PNC) by decoding one or multiple linear combinations of the packets simultaneously transmitted in a timeslot, forming a system of linear equations. Different systems of linear equations are recovered in different timeslots. A message decoder then recovers the original packets of all the users by jointly solving multiple systems of linear equations obtained over different timeslots. We propose the batched BP decoding algorithm that combines belief propagation (BP) and local Gaussian elimination. Compared with pure Gaussian elimination decoding, our algorithm reduces the decoding complexity from cubic to linear function of the number of users. Compared with the ordinary BP decoding algorithm for low-density generator-matrix codes, our algorithm has better performance and the same order of computational complexity. We analyze the performance of the batched BP decoding algorithm by generalizing the tree-based approach and provide an approach to optimize the system performance.", "subjects": "Information Theory (cs.IT)", "authors": "Shenghao Yang, Yi Chen, Soung Chang Liew, Lizhao You,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.03890", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03890", "title": "\nDecision Maker using Coupled Incompressible-Fluid Cylinders", "abstract": "The multi-armed bandit problem (MBP) is the problem of finding, as accurately and quickly as possible, the most profitable option from a set of options that gives stochastic rewards by referring to past experiences. Inspired by fluctuated movements of a rigid body in a tug-of-war game, we formulated a unique search algorithm that we call the `tug-of-war (TOW) dynamics' for solving the MBP efficiently. The cognitive medium access, which refers to multi-user channel allocations in cognitive radio, can be interpreted as the competitive multi-armed bandit problem (CMBP); the problem is to determine the optimal strategy for allocating channels to users which yields maximum total rewards gained by all users. Here we show that it is possible to construct a physical device for solving the CMBP, which we call the `TOW Bombe', by exploiting the TOW dynamics existed in coupled incompressible-fluid cylinders. This analog computing device achieves the `socially-maximum' resource allocation that maximizes the total rewards in cognitive medium access without paying a huge computational cost that grows exponentially as a function of the problem size.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Song-Ju Kim, Masashi Aono,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.03879", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03879", "title": "\nSemi-supervised Data Representation via Affinity Graph Learning", "abstract": "We consider the general problem of utilizing both labeled and unlabeled data to improve data representation performance. A new semi-supervised learning framework is proposed by combing manifold regularization and data representation methods such as Non negative matrix factorization and sparse coding. We adopt unsupervised data representation methods as the learning machines because they do not depend on the labeled data, which can improve machine's generation ability as much as possible. The proposed framework forms the Laplacian regularizer through learning the affinity graph. We incorporate the new Laplacian regularizer into the unsupervised data representation to smooth the low dimensional representation of data and make use of label information. Experimental results on several real benchmark datasets indicate that our semi-supervised learning framework achieves encouraging results compared with state-of-art methods.", "subjects": "Learning (cs.LG)", "authors": "Weiya Ren,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.03874", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03874", "title": "\nFurther results on differentially 4-uniform permutations over  $\\F_{2^{2m}}$", "abstract": "In this paper, we present several new constructions of differentially 4-uniform permutations over by modifying the values of the inverse function on some subsets of . The resulted differentially 4-uniform permutations have high nonlinearities and algebraic degrees, which provide more choices for the design of cryptographic substitution boxes.", "subjects": "Information Theory (cs.IT)", "authors": "Zhengbang Zha, Lei Hu, Siwei Sun, Jinyong Shan,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.03872", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03872", "title": "\nMalicious web script-based cyber attack protection technology", "abstract": "Recent web-based cyber attacks are evolving into a new form of attacks such as private information theft and DDoS attack exploiting JavaScript within a web page. These attacks can be made just by accessing a web site without distribution of malicious codes and infection. Script-based cyber attacks are hard to detect with traditional security equipments such as Firewall and IPS because they inject malicious scripts in a response message for a normal web request. Furthermore, they are hard to trace because attacks such as DDoS can be made just by visiting a web page. Due to these reasons, it is expected that they could result in direct damages and great ripple effects. To cope with these issues, in this article, a proposal is made for techniques that are used to detect malicious scripts through real-time web content analysis and to automatically generate detection signatures for malicious JavaScript.", "subjects": "Cryptography and Security (cs.CR)", "authors": "JongHun Jung, Hwan-Kuk Kim, Soojin Yoon,", "date": "2015-2-13"}, 
{"urllink": "http://arxiv.org/abs/1502.03851", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03851", "title": "\nDiscovering Human Interactions in Videos with Limited Data Labeling", "abstract": "We present a novel approach for discovering human interactions in videos. Activity understanding techniques usually require a large number of labeled examples, which are not available in many practical cases. Here, we focus on recovering semantically meaningful clusters of human-human and human-object interaction in an unsupervised fashion. A new iterative solution is introduced based on Maximum Margin Clustering (MMC), which also accepts user feedback to refine clusters. This is achieved by formulating the whole process as a unified constrained latent max-margin clustering problem. Extensive experiments have been carried out over three challenging datasets, Collective Activity, VIRAT, and UT-interaction. Empirical results demonstrate that the proposed algorithm can efficiently discover perfect semantic clusters of human interactions with only a small amount of labeling effort.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Mehran Khodabandeh, Arash Vahdat, Guang-Tong Zhou, Hossein Hajimirsadeghi, Mehrsan Javan Roshtkhari, Greg Mori, Stephen Se,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03849", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03849", "title": "\nWelfare Ratios in One-Sided Matching Mechanisms", "abstract": "We study the Price of Anarchy of mechanisms for the fundamental problem of social welfare maximization in one-sided matching settings, when agents have general cardinal preferences over a finite set of items. We consider both the complete and incomplete information settings and show that the two most well-studied mechanisms in literature, Probabilistic Serial and Random Priority have a Price of Anarchy of . We complement our results with a lower bound of on the Price of Anarchy of emph mechanisms. As a result, we conclude that these mechanisms are optimal.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "George Christodoulou, Aris Filos-Ratsikas, Soren Kristoffer Stiil Frederiksen, Paul W. Goldberg, Jie Zhang, Jinshan Zhang,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03847", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03847", "title": "\nA Constant Factor Approximation for Orthogonal Order Preserving Layout  Adjustment", "abstract": "Given an initial placement of a set of rectangles in the plane, we consider the problem of finding a disjoint placement of the rectangles that minimizes the area of the bounding box and preserves the orthogonal order i.e. maintains the sorted ordering of the rectangle centers along both -axis and -axis with respect to the initial placement. This problem is known as Layout Adjustment for Disjoint Rectangles(LADR). It was known that LADR is -hard, but only heuristics were known for it. We show that a certain decision version of LADR is -hard, and give a constant factor approximation for LADR.", "subjects": "Computational Geometry (cs.CG)", "authors": "Sayan Bandyapadhyay, Santanu Bhowmick, Kasturi Varadarajan,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.03845", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03845", "title": "\nAdaptive Search over Sorted Sets", "abstract": "We revisit the classical algorithms for searching over sorted sets to introduce an algorithm refinement, called Adaptive Search, that combines the good features of Interpolation search and those of Binary search. W.r.t. Interpolation search, only a constant number of extra comparisons is introduced. Yet, under diverse input data distributions our algorithm shows costs comparable to that of Interpolation search, i.e., O(log log n) while the worst-case cost is always in O(log n), as with Binary search. On benchmarks drawn from large datasets, both synthetic and real-life, Adaptive search scores better times and lesser memory accesses even than Santoro and Sidney's Interpolation-Binary search.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Biagio Bonasera, Emilio Ferrara, Giacomo Fiumara, Francesco Pagano, Alessandro Provetti,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03817", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03817", "title": "\nAchieving Max-Min Fairness for MU-MISO with Partial CSIT: A Multicast  Assisted Transmission", "abstract": "We address the max-min fairness design problem for a MU-MISO system with partial Channel State Information (CSI) at the Base Station (BS), consisting of an imperfect channel estimate and statistical knowledge of the estimation error, and perfect CSI at the receivers. The objective is to maximize the minimum Average Rate (AR) among users subject to a transmit power constraint. An unconventional transmission scheme is adopted where the Base Station (BS) transmits a common message in addition to the conventional private messages. In situations where the CSIT is not accurate enough to perform interference nulling, individual rates are assisted by allocating parts of the common message to different users according to their needs. The AR problem is transformed into an augmented Average Weighted Mean Square Error (AWMSE) problem, solved using Alternating Optimization (AO). The benefits of incorporating the common message are demonstrated through simulations.", "subjects": "Information Theory (cs.IT)", "authors": "Hamdi Joudeh, Bruno Clerckx,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03805", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03805", "title": "\neOMP: Finding Sparser Representation by Recursively Orthonormalizing the  Remaining Atoms", "abstract": "Greedy algorithms for minimizing L0-norm of sparse decomposition have profound application impact on many signal processing problems. In the sparse coding setup, given the observations and the redundant dictionary , one would seek the most sparse coefficient (signal) with a constraint on approximation fidelity. In this work, we propose a greedy algorithm based on the classic orthogonal matching pursuit (OMP) with improved sparsity on and better recovery rate, which we name as eOMP. The key ingredient of the eOMP is recursively performing one-step orthonormalization on the remaining atoms, and evaluating correlations between residual and orthonormalized atoms. We show a proof that the proposed eOMP guarantees to maximize the residual reduction at each iteration. Through extensive simulations, we show the proposed algorithm has better exact recovery rate on i.i.d. Gaussian ensembles with Gaussian signals, and more importantly yields smaller L0-norm under the same approximation fidelity compared to the original OMP, for both synthetic and practical scenarios. The complexity analysis and real running time result also show a manageable complexity increase over the original OMP. We claim that the proposed algorithm has better practical perspective for finding more sparse representations than existing greedy algorithms.", "subjects": "Numerical Analysis (cs.NA)", "authors": "Yuanyi Xue, Yao Wang,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03802", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03802", "title": "\nA two-stage video coding framework with both self-adaptive redundant  dictionary and adaptively orthonormalized DCT basis", "abstract": "In this work, we propose a two-stage video coding framework, as an extension of our previous one-stage framework in [1]. The two-stage frameworks consists two different dictionaries. Specifically, the first stage directly finds the sparse representation of a block with a self-adaptive dictionary consisting of all possible inter-prediction candidates by solving an L0-norm minimization problem using an improved orthogonal matching pursuit with embedded orthonormalization (eOMP) algorithm, and the second stage codes the residual using DCT dictionary adaptively orthonormalized to the subspace spanned by the first stage atoms. The transition of the first stage and the second stage is determined based on both stages' quantization stepsizes and a threshold. We further propose a complete context adaptive entropy coder to efficiently code the locations and the coefficients of chosen first stage atoms. Simulation results show that the proposed coder significantly improves the RD performance over our previous one-stage coder. More importantly, the two-stage coder, using a fixed block size and inter-prediction only, outperforms the H.264 coder (x264) and is competitive with the HEVC reference coder (HM) over a large rate range.", "subjects": "Multimedia (cs.MM)", "authors": "Yuanyi Xue, Yi Zhou, Yao Wang,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03796", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03796", "title": "\nVariable and value elimination in binary constraint satisfaction via  forbidden patterns", "abstract": "Variable or value elimination in a constraint satisfaction problem (CSP) can be used in preprocessing or during search to reduce search space size. A variable elimination rule (value elimination rule) allows the polynomial-time identification of certain variables (domain elements) whose elimination, without the introduction of extra compensatory constraints, does not affect the satisfiability of an instance. We show that there are essentially just four variable elimination rules and three value elimination rules defined by forbidding generic sub-instances, known as irreducible existential patterns, in arc-consistent CSP instances. One of the variable elimination rules is the already-known Broken Triangle Property, whereas the other three are novel. The three value elimination rules can all be seen as strict generalisations of neighbourhood substitution.", "subjects": "Computational Complexity (cs.CC)", "authors": "David A. Cohen, Martin C. Cooper, Guillaume Escamocher, Stanislav Zivny,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03794", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03794", "title": "\nSum Rate Maximization for MU-MISO with Partial CSIT using Joint  Multicasting and Broadcasting", "abstract": "In this paper, we consider a MU-MISO system where users have highly accurate Channel State Information (CSI), while the Base Station (BS) has partial CSI consisting of an imperfect channel estimate and statistical knowledge of the CSI error. With the objective of maximizing the Average Sum Rate (ASR) subject to a power constraint, a special transmission scheme is considered where the BS transmits a common symbol in a multicast fashion, in addition to the conventional private symbols. This scheme is termed Joint Multicasting and Broadcasting (JMB). The ASR problem is transformed into an augmented Average Weighted Sum Mean Square Error (AWSMSE) problem which is solved using Alternating Optimization (AO). The enhanced rate performance accompanied with the incorporation of the multicast part is demonstrated through simulations.", "subjects": "Information Theory (cs.IT)", "authors": "Hamdi Joudeh, Bruno Clerckx,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03790", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03790", "title": "\nOn the Entropy Computation of Large Gaussian Mixture Distributions", "abstract": "The entropy computation of Gaussian mixture distributions with a large number of components has a prohibitive computational complexity. In this paper, we propose a novel approach exploiting the sphere decoding concept to bound and approximate such entropy terms with reduced complexity and good accuracy. Moreover, we propose an SNR region based enhancement of the approximation method to reduce the complexity even further. Using Monte-Carlo simulations, the proposed methods are numerically demonstrated for the computation of the mutual information including the entropy term of various channels with finite constellation modulations such as binary and quadratic amplitude modulation (QAM) inputs for communication applications.", "subjects": "Information Theory (cs.IT)", "authors": "Su Min Kim, Tan Tai Do, Tobias J. Oechtering, Gunnar Peters,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03784", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03784", "title": "\nCoherent-to-Diffuse Power Ratio Estimation for Dereverberation", "abstract": "The estimation of the time- and frequency-dependent coherent-to-diffuse power ratio (CDR) from the measured spatial coherence between two omnidirectional microphones is investigated. Known CDR estimators are formulated in a common framework, illustrated using a geometric interpretation in the complex plane, and investigated with respect to bias and robustness towards model errors. Several novel unbiased CDR estimators are proposed, and it is shown that knowledge of either the direction of arrival (DOA) of the target source or the coherence of the noise field is sufficient for unbiased CDR estimation. The validity of the model for the application of CDR estimates to dereverberation is investigated using measured and simulated impulse responses. A CDR-based dereverberation system is presented and evaluated using signal-based quality measures as well as automatic speech recognition accuracy. The results show that the proposed unbiased estimators have a practical advantage over existing estimators, and that the proposed DOA-independent estimator can be used for effective blind dereverberation.", "subjects": "Sound (cs.SD)", "authors": "Andreas Schwarz, Walter Kellermann,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.03780", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03780", "title": "\nAn Open-Source Monitoring System for Remote Solar Power Applications", "abstract": "Renewable energy systems are an increasingly popular way to generate electricity. As with any new technological paradigm, new challenges have emerged which are unique to the utilization of renewable energy systems. One of these challenges in particular is the development of effective monitoring technologies to compensate for the decentralized nature of remote power generation. This project details the development of an open-source monitoring system for remote solar power systems. The problem space that this project is specifically concerned with deals with the reduction of cost and the use of open platforms to make solar monitoring viable in developing countries where both the resources and general knowledge required to undertake such efforts are particularly scarce. Currently, solar monitoring technologies are expensive, limited in their application, and for the most part proprietary. It is arguable that such systems can be developed using non-customized hardware and open-source software that can be obtained and run anywhere in the world. This project is one such argument. This proof of concept is sufficient to show that solar remote monitoring is neither expensive nor particularly cumbersome to implement and thus warrants further investigation and development by the open source community.", "subjects": "Computers and Society (cs.CY)", "authors": "Nikolas Wolfe,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03774", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03774", "title": "\nDiagnosis of diabetes using classification mining techniques", "abstract": "Diabetes has affected over 246 million people worldwide with a majority of them being women. According to the WHO report, by 2025 this number is expected to rise to over 380 million. The disease has been named the fifth deadliest disease in the United States with no imminent cure in sight. With the rise of information technology and its continued advent into the medical and healthcare sector, the cases of diabetes as well as their symptoms are well documented. This paper aims at finding solutions to diagnose the disease by analyzing the patterns found in the data through classification analysis by employing Decision Tree and Na \"ive Bayes algorithms. The research hopes to propose a quicker and more efficient technique of diagnosing the disease, leading to timely treatment of the patients.", "subjects": "Computational Engineering, Finance, and Science (cs.CE)", "authors": "Aiswarya Iyer, S. Jeyalatha, Ronak Sumbaly,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03772", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03772", "title": "\nA Story of Suo Motos, Judicial Activism, and Article 184 (3)", "abstract": "The synergy between Big Data and Open Data has the potential to revolutionize information access in the developing world. Following this mantra, we present the analysis of more than a decade worth of open judgements and orders from the Supreme Court of Pakistan. Our overarching goal is to discern the presence of judicial activism in the country in the wake of the Lawyers' Movement. Using Apache Spark as the processing engine we analyze hundreds of unstructured PDF documents to sketch the evolution and various organs of judicial activism in Pakistan since 2009. Our results show that the judiciary has indeed been pursuing matters of public interest, especially those that pertain to the fundamental rights of the citizens. Furthermore, we show how the size of the presiding bench in a case and citations of Articles from the Constitution and prior judgements can aid in classifying legal judgements. Throughout the analysis we also highlight the challenges that anyone who aims to apply Big Data techniques to Open Data will face. We hope that this work will be one in a series of community efforts to use Open Data as a lens to analyze real-world events and phenomena in the developing world.", "subjects": "Computers and Society (cs.CY)", "authors": "Zubair Nabi,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03752", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03752", "title": "\nA new hybrid metric for verifying parallel corpora of Arabic-English", "abstract": "This paper discusses a new metric that has been applied to verify the quality in translation between sentence pairs in parallel corpora of Arabic-English. This metric combines two techniques, one based on sentence length and the other based on compression code length. Experiments on sample test parallel Arabic-English corpora indicate the combination of these two techniques improves accuracy of the identification of satisfactory and unsatisfactory sentence pairs compared to sentence length and compression code length alone. The new method proposed in this research is effective at filtering noise and reducing mis-translations resulting in greatly improved quality.", "subjects": "Computation and Language (cs.CL)", "authors": "Saad Alkahtani, Wei Liu, William J. Teahan,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03726", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03726", "title": "\nA Novel Approach for Clone Group Mapping by using Topic Modeling", "abstract": "Clone group mapping has a very important significance in the evolution of code clone. The topic modeling techniques were applied into code clone firstly and a new clone group mapping method was proposed. The method is very effective for not only Type-1 and Type-2 clone but also Type-3 clone .By making full use of the source text and structure information, topic modeling techniques transform the mapping problem of high-dimensional code space into a low-dimensional topic space, the goal of clone group mapping was indirectly reached by mapping clone group topics. Experiments on four open source software show that the recall and precision are up to 0.99, thus the method can effectively and accurately reach the goal of clone group mapping.", "subjects": "Software Engineering (cs.SE)", "authors": "Ruixia Zhang, Liping Zhang, Huan Wang, Zhuo Chen,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03723", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03723", "title": "\nSimulation of Color Blindness and a Proposal for Using Google Glass as  Color-correcting Tool", "abstract": "The human visual color response is driven by specialized cells called cones, which exist in three types, viz. R, G, and B. Software is developed to simulate how color images are displayed for different types of color blindness. Specified the default color deficiency associated with a user, it generates a preview of the rainbow (in the visible range, from red to violet) and shows up, side by side with a colorful image provided as input, the display correspondent colorblind. The idea is to provide an image processing after image acquisition to enable a better perception ofcolors by the color blind. Examples of pseudo-correction are shown for the case of Protanopia (red blindness). The system is adapted into a screen of an i-pad or a cellphone in which the colorblind observe the camera, the image processed with color detail previously imperceptible by his naked eye. As prospecting, wearable computer glasses could be manufactured to provide a corrected image playback. The approach can also provide augmented reality for human vision by adding the UV or IR responses as a new feature of Google Glass.", "subjects": "Human-Computer Interaction (cs.HC)", "authors": "H.M. de Oliveira, J. Ranhel, R.B.A. Alves,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03722", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03722", "title": "\nOptimal sequential fingerprinting: Wald vs. Tardos", "abstract": "We study sequential collusion-resistant fingerprinting, where the fingerprinting code is generated in advance but accusations may be made between rounds, and show that in this setting both the dynamic Tardos scheme and schemes building upon Wald's sequential probability ratio test (SPRT) are asymptotically optimal. We further compare these two approaches to sequential fingerprinting, highlighting differences between the two schemes. Based on these differences, we argue that Wald's scheme should in general be preferred over the dynamic Tardos scheme, even though both schemes have their merits. As a side result, we derive an optimal sequential group testing method for the classical model, which can easily be generalized to different group testing models.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Thijs Laarhoven,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03715", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03715", "title": "\nReassembling trees for the traveling salesman", "abstract": "Many recent approximation algorithms for different variants of the traveling salesman problem (asymmetric TSP, graph TSP, s-t-path TSP) exploit the well-known fact that a solution of the natural linear programming relaxation can be written as convex combination of spanning trees. The main argument then is that randomly sampling a tree from such a distribution and then completing the tree to a tour at minimum cost yields a better approximation guarantee than simply taking a minimum cost spanning tree (as in Christofides' algorithm). We argue that an additional step can help: reassembling the spanning trees before sampling. Exchanging two edges in a pair of spanning trees can improve their properties under certain conditions. We demonstrate the usefulness for the metric s-t-path TSP by devising a deterministic polynomial-time algorithm that improves on Seb H's previously best approximation ratio of 8/5.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Jens Vygen,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03708", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03708", "title": "\nProvably weak instances of Ring-LWE", "abstract": "The ring and polynomial learning with errors problems (Ring-LWE and Poly-LWE) have been proposed as hard problems to form the basis for cryptosystems, and various security reductions to hard lattice problems have been presented. So far these problems have been stated for general (number) rings but have only been closely examined for cyclotomic number rings. In this paper, we state and examine the Ring-LWE problem for general number rings and demonstrate provably weak instances of Ring-LWE. We construct an explicit family of number fields for which we have an efficient attack. We demonstrate the attack in both theory and practice, providing code and running times for the attack. The attack runs in time linear in q, where q is the modulus. Our attack is based on the attack on Poly-LWE which was presented in [Eisentr \"ager-Hallgren-Lauter]. We extend the EHL-attack to apply to a larger class of number fields, and show how it applies to attack Ring-LWE for a heuristically large class of fields. Certain Ring-LWE instances can be transformed into Poly-LWE instances without distorting the error too much, and thus provide the first weak instances of the Ring-LWE problem. We also provide additional examples of fields which are vulnerable to our attacks on Poly-LWE, including power-of- cyclotomic fields, presented using the minimal polynomial of .", "subjects": "Cryptography and Security (cs.CR)", "authors": "Yara Elias, Kristin E. Lauter, Ekin Ozman, Katherine E. Stange,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03699", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03699", "title": "\nAnalysis of Solution Quality of a Multiobjective Optimization-based  Evolutionary Algorithm for Knapsack Problem", "abstract": "Multi-objective optimisation is regarded as one of the most promising ways for dealing with constrained optimisation problems in evolutionary optimisation. This paper presents a theoretical investigation of a multi-objective optimisation evolutionary algorithm for solving the 0-1 knapsack problem. Two initialisation methods are considered in the algorithm: local search initialisation and greedy search initialisation. Then the solution quality of the algorithm is analysed in terms of the approximation ratio.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "Jun He, Yong Wang, Yuren Zhou,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03698", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03698", "title": "\nOn Galois-Division Multiple Access Systems: Figures of Merit and  Performance Evaluation", "abstract": "A new approach to multiple access based on finite field transforms is investigated. These schemes, termed Galois-Division Multiple Access (GDMA), offer compact bandwidth requirements. A new digital transform, the Finite Field Hartley Transform (FFHT) requires to deal with fields of characteristic p, p neq 2. A binary-to-p-ary (p neq 2) mapping based on the opportunistic secondary channel is introduced. This allows the use of GDMA in conjunction with available digital systems. The performance of GDMA is also evaluated.", "subjects": "Information Theory (cs.IT)", "authors": "J.P.C.L. Miranda, H.M. de Oliveira,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03690", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03690", "title": "\nSemi-dynamic connectivity in the plane", "abstract": "Motivated by a path planning problem we consider the following procedure. Assume that we have two points and in the plane and take . At each step we add to a compact convex set that does not contain nor . The procedure terminates when the sets in separate and . We show how to add one set to in amortized time plus the time needed to find all sets of intersecting the newly added set, where is the cardinality of , is the number of sets in intersecting the newly added set, and is the inverse of the Ackermann function.", "subjects": "Computational Geometry (cs.CG)", "authors": "Sergio Cabello, Michael Kerber,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03683", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03683", "title": "\nComputing rational beliefs under limited foresight", "abstract": "We study extensive form games where players might not be able to foresee the possible consequences of their actions and try to exploit the opponents' believed weaknesses in order to improve upon the final outcome. We build upon existing models of games with limited foresight, endowing players with the ability of higher-order reasoning, and proposing a novel solution concept to address intuitions coming from real game play. We analyse the resulting equilibria, devising an effective procedure to compute them.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Johan van Benthem, Chanjuan Liu, Paolo Turrini,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03682", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03682", "title": "\nApplying deep learning techniques on medical corpora from the World Wide  Web: a prototypical system and evaluation", "abstract": "BACKGROUND: The amount of biomedical literature is rapidly growing and it is becoming increasingly difficult to keep manually curated knowledge bases and ontologies up-to-date. In this study we applied the word2vec deep learning toolkit to medical corpora to test its potential for identifying relationships from unstructured text. We evaluated the efficiency of word2vec in identifying properties of pharmaceuticals based on mid-sized, unstructured medical text corpora available on the web. Properties included relationships to diseases ('may treat') or physiological processes ('has physiological effect'). We compared the relationships identified by word2vec with manually curated information from the National Drug File - Reference Terminology (NDF-RT) ontology as a gold standard. RESULTS: Our results revealed a maximum accuracy of 49.28% which suggests a limited ability of word2vec to capture linguistic regularities on the collected medical corpora compared with other published results. We were able to document the influence of different parameter settings on result accuracy and found and unexpected trade-off between ranking quality and accuracy. Pre-processing corpora to reduce syntactic variability proved to be a good strategy for increasing the utility of the trained vector models. CONCLUSIONS: Word2vec is a very efficient implementation for computing vector representations and for its ability to identify relationships in textual data without any prior domain knowledge. We found that the ranking and retrieved results generated by word2vec were not of sufficient quality for automatic population of knowledge bases and ontologies, but could serve as a starting point for further manual curation.", "subjects": "Computation and Language (cs.CL)", "authors": "Jose Antonio Mi\u00f1arro-Gim\u00e9nez, Oscar Mar\u00edn-Alonso, Matthias Samwald,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03678", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03678", "title": "\nassistME: A Platform for Assisting Engineers in Maintaining the Factory  Pipeline", "abstract": "In this position paper, we present our approach of utilizing mobile devices (i.e., mobile phones and tablets) for assisting engineers and experts in understanding and maintaining the factory pipelines. For this, we present a platform, called assistME, that is composed of three main components: the assistME Server, the assistME mobile infrastructure, and the co-assistME collaborative environment. In order to get full utilization of the assistME platform, we assume that an initial setup is made in the factory in such a way that it is equipped with different sensors to collect data about specific events in the factory pipeline together with the corresponding locations of these events. The assistME Server works as a central control unit in the platform and collects data from the installed sensors in the factory pipeline. In the case of any unexpected behavior or any critical situation in the factory pipeline, notification and other details are sent to the related group of engineers and experts through the assistME mobile app. Further, the co-assistME collaborative environment, equipped with a large shared screen and multiple mobile devices, helps the engineers and experts to collaborate with to understand and analyze the current situation in the factory pipeline in order to maintain it accurately.", "subjects": "Human-Computer Interaction (cs.HC)", "authors": "Ragaad AlTarawneh, Jens Bauer, Nicole Menck, Shah Rukh Humayoun, Achim Ebert,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03671", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03671", "title": "\nPhrase-based Image Captioning", "abstract": "Generating a novel textual description of an image is an interesting problem that connects computer vision and natural language processing. In this paper, we present a simple model that is able to generate descriptive sentences given a sample image. This model has a strong focus on the syntax of the descriptions. We train a purely bilinear model that learns a metric between an image representation (generated from a previously trained Convolutional Neural Network) and phrases that are used to described them. The system is then able to infer phrases from a given image sample. Based on caption syntax statistics, we propose a simple language model that can produce relevant descriptions for a given test image using the phrases inferred. Our approach, which is considerably simpler than state-of-the-art models, achieves comparable results in two popular datasets for the task: Flickr30k and the recently proposed Microsoft COCO.", "subjects": "Computation and Language (cs.CL)", "authors": "R\u00e9mi Lebret, Pedro O. Pinheiro, Ronan Collobert,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03666", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03666", "title": "\nFundamental Limits of CDF-Based Scheduling: Throughput, Fairness, and  Feedback Overhead", "abstract": "In this paper, we investigate fundamental performance limits of cumulative distribution function (CDF)-based scheduling (CS) in downlink cellular networks. CS is known as an efficient scheduling method that can assign different time fractions for users or, equivalently, satisfy different channel access ratio (CAR) requirements of users while exploiting multi-user diversity. We first mathematically analyze the throughput characteristics of CS in arbitrary fading statistics and data rate functions. It is shown that the throughput gain of CS increases as the CAR of a user decreases or the number of users in a cell increases. For Nakagami-m fading channels, we obtain the average throughput in closed-form and investigate the effects of the average signal-to-noise ratio, the shape parameter m, and the CAR on the throughput performance. In addition, we propose a threshold-based opportunistic feedback technique in order to reduce feedback overhead while satisfying the CAR requirements of users. We prove that the average feedback overhead of the proposed technique is upper bounded by -ln(p), where p is the probability that no user satisfies the threshold condition in a cell. Finally, we adopt a novel fairness criterion, called qualitative fairness, which considers not only the quantity of the allocated resources to users but also the quality of the resources. It is observed that CS provides a better qualitative fairness than other scheduling algorithms designed for controlling CARs of users.", "subjects": "Information Theory (cs.IT)", "authors": "Hu Jin, Bang Chul Jung, Victor C. M. Leung,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03654", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03654", "title": "\nRegularized ZF in Cooperative Broadcast Channels under Distributed CSIT:  A Large System Analysis", "abstract": "Obtaining accurate Channel State Information (CSI) at the transmitters (TX) is critical to many cooperation schemes such as Network MIMO, Interference Alignment etc. Practical CSI feedback and limited backhaul-based sharing inevitably creates degradations of CSI which are specific to each TX, giving rise to a distributed form of CSI. In the Distributed CSI (D-CSI) broadcast channel setting, the various TXs design elements of the precoder based on their individual estimates of the global multiuser channel matrix, which intuitively degrades performance when compared with the commonly used centralized CSI assumption. This paper tackles this challenging scenario and presents a first analysis of the rate performance for the distributed CSI multi-TX broadcast channel setting, in the large number of antenna regime. Using Random Matrix Theory (RMT) tools, we derive deterministic equivalents of the Signal to Interference plus Noise Ratio (SINR) for the popular regularized Zero-Forcing (ZF) precoder, allowing to unveil the price of distributedness for such cooperation methods.", "subjects": "Information Theory (cs.IT)", "authors": "Paul de Kerret, David Gesbert, Umer Salim,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03648", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03648", "title": "\nOver-Sampling in a Deep Neural Network", "abstract": "Deep neural networks (DNN) are the state of the art on many engineering problems such as computer vision and audition. A key factor in the success of the DNN is scalability - bigger networks work better. However, the reason for this scalability is not yet well understood. Here, we interpret the DNN as a discrete system, of linear filters followed by nonlinear activations, that is subject to the laws of sampling theory. In this context, we demonstrate that over-sampled networks are more selective, learn faster and learn more robustly. Our findings may ultimately generalize to the human brain.", "subjects": "Learning (cs.LG)", "authors": "Andrew J.R. Simpson,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03645", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03645", "title": "\nNumerical simulation of skin transport using Parareal", "abstract": "In-silico investigations of skin permeation are an important but also computationally demanding problem. To resolve all involved scales in full detail will probably not only require exascale computing capacities but also suitable parallel algorithms. This article investigates the applicability of the time-parallel Parareal algorithm to a brick and mortar setup, a precursory problem to skin permeation. A C++ library implementing Parareal is combined with the UG4 simulation framework, which provides the spatial discretization and parallelization. The combination's performance is studied with respect to convergence and speedup. While limited speedup from the time parallelization is shown to be possible, load balancing is identified as an important issue in the application of Parareal with implicit integrators to complex PDEs.", "subjects": "Computational Engineering, Finance, and Science (cs.CE)", "authors": "Andreas Kreienbuehl, Arne Naegel, Daniel Ruprecht, Robert Speck, Gabriel Wittum, Rolf Krause,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03641", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03641", "title": "\nA Wavelength Broker for Markets of Competing Optical Transport Networks", "abstract": "The current trend in optical networks is to open the entire wholesale market to competition. As a result, we will see, instead of a single big market player, optical transport networks competing with each other to attract customer demand. This paper presents a wavelength broker who acts on behalf of enterprises, web host companies, financial firm etc. to buy certain number of wavelengths from such market. We present the system model, the interaction protocol and provide analysis of the competition. The simulation results of a business scenario are also recorded in the paper", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Abdulsalam Yassine,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03636", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03636", "title": "\nAxiomatizing L\u00fcttgen and Vogler's ready simulation for finite  processes in $\\text{CLL}_R$", "abstract": "In the framework of logic labelled transition system, a variant of weak ready simulation has been presented by L \"ttgen and Vogler. It has been shown that such behavioural preorder is the largest precongruence w.r.t parallel and conjunction composition satisfying desired properties. This paper offers a ground-complete axiomatization for this precongruence over processes containing no recursion in the calculus . Compared with usual inference system for process calculus, in addition to axioms about process operators, such system contains a number of axioms to characterize the interaction between process operators and logical operators.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Yan Zhang, Zhaohui Zhu, Jinjin Zhang,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03634", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03634", "title": "\nActivity recognition for a smartphone and web based travel survey", "abstract": "In transport modeling and prediction, trip purposes play an important role since mobility choices (e.g. modes, routes, departure times) are made in order to carry out specific activities. Activity based models, which have been gaining popularity in recent years, are built from a large number of observed trips and their purposes. However, data acquired through traditional interview-based travel surveys lack the accuracy and quantity required by such models. Smartphones and interactive web interfaces have emerged as an attractive alternative to conventional travel surveys. A smartphone-based travel survey, Future Mobility Survey (FMS), was developed and field-tested in Singapore and collected travel data from more than 1000 participants for multiple days. To provide a more intelligent interface, inferring the activities of a user at a certain location is a crucial challenge. This paper presents a learning model that infers the most likely activity associated to a certain visited place. The data collected in FMS contain errors or noise due to various reasons, so a robust approach via ensemble learning is used to improve generalization performance. Our model takes advantage of cross-user historical data as well as user-specific information, including socio-demographics. Our empirical results using FMS data demonstrate that the proposed method contributes significantly to our travel survey application.", "subjects": "Computers and Society (cs.CY)", "authors": "Youngsung Kim, Francisco C. Pereira, Fang Zhao, Ajinkya Ghorpade, P. Christopher Zegras, Moshe Ben-Akiva,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03630", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03630", "title": "\nOrdering-sensitive and Semantic-aware Topic Modeling", "abstract": "Topic modeling of textual corpora is an important and challenging problem. In most previous work, the \"bag-of-words\" assumption is usually made which ignores the ordering of words. This assumption simplifies the computation, but it unrealistically loses the ordering information and the semantic of words in the context. In this paper, we present a Gaussian Mixture Neural Topic Model (GMNTM) which incorporates both the ordering of words and the semantic meaning of sentences into topic modeling. Specifically, we represent each topic as a cluster of multi-dimensional vectors and embed the corpus into a collection of vectors generated by the Gaussian mixture model. Each word is affected not only by its topic, but also by the embedding vector of its surrounding words and the context. The Gaussian mixture components and the topic of documents, sentences and words can be learnt jointly. Extensive experiments show that our model can learn better topics and more accurate word distributions for each topic. Quantitatively, comparing to state-of-the-art topic modeling approaches, GMNTM obtains significantly better performance in terms of perplexity, retrieval accuracy and classification accuracy.", "subjects": "Learning (cs.LG)", "authors": "Min Yang, Tianyi Cui, Wenting Tu,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03629", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03629", "title": "\nOn the greatest solution of equations in $\\text{CLL}_R$", "abstract": "It is shown that, for any equation in the LLTS-oriented process calculus , if is strongly guarded in , then the recursive term is the greatest solution of this equation w.r.t L \"ttgen and Vogler's ready simulation.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Yan Zhang, Zhaohui Zhu, Jinjin Zhang,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03628", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03628", "title": "\nSeparation of sinusoidal and chirp components using Compressive sensing  approach", "abstract": "In this paper we deal with the linear frequency modulated signals and radar signals that are affected by disturbance which is the inevitable phenomenon in everyday communications. The considered cases represent the cases when the signals of interest overlap with other signals or with noise. In order to successfully separate these signals we propose the compressive sensing method, which states that the useful signal part can be separated successfully from a small amount of measurements as long as the acquired signal can be presented as sparse in a certain transformation domain. The effectiveness of our approach is proven experimentally through examples.", "subjects": "Information Theory (cs.IT)", "authors": "Zoja Vulaj, Faris Kardovic,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03620", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03620", "title": "\nMultiresolution Division Multiplex (MRDM): A New Wavelet-based Multiplex  System", "abstract": "An original multiplex scheme is introduced, which is based on Mallat's multiresolution formulation of wavelet systems. This system is adaptable and its implementation is well matched to digital signal processors and computers. The approach termed multiresolution division multiplex (MRDM) is intensive in signal processing (SP) tools, extremely flexible and can combine a variety of tributaries at different bit rates. A broad variety of orthogonal wavelet systems can endow with MRDM and the channel waveforms, and consequently the spectral shape and system performance depend upon the selected wavelets. Demultiplex can be done efficiently, since the number of floating multiplications and additions increase only linearly with the length of signals. A Haar-based MRDM scheme is presented to illustrate the versatility of this new multiplex approach.", "subjects": "Information Theory (cs.IT)", "authors": "H.M. de Oliveira, E.A. Bouton,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03612", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03612", "title": "\nA Method of Evaluating Effect of QoS Degradation on Multidimensional QoE  of Web Service with ISO - based Usability", "abstract": "This paper studies a method of investigating effect of IP performance (QoS) degradation on quality of experience (QoE) for a Web service; it considers the usability based on the ISO 9241-11 as multidimensional QoE of a Web service (QoE-Web) and the QoS parameters standardized by the IETF. Moreover, the paper tackles clarification of the relationship between ISO-based QoE-Web and IETF-based QoS by the multiple regression analysis. The experiment is intended for the two actual Japanese online shopping services and utilizes 35 subjects. From the results, the paper quantitatively discusses how the QoE-Web deteriorates owing to the QoS degradation and shows that it is appropriate to evaluate the proposed method.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "D. Yamauchi, Y. Ito,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.03601", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03601", "title": "\nA Predictive System for detection of Bankruptcy using Machine Learning  techniques", "abstract": "Bankruptcy is a legal procedure that claims a person or organization as a debtor. It is essential to ascertain the risk of bankruptcy at initial stages to prevent financial losses. In this perspective, different soft computing techniques can be employed to ascertain bankruptcy. This study proposes a bankruptcy prediction system to categorize the companies based on extent of risk. The prediction system acts as a decision support tool for detection of bankruptcy Keywords: Bankruptcy, soft computing, decision support tool", "subjects": "Learning (cs.LG)", "authors": "Kalyan Nagaraj, Amulyashree Sridhar,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03596", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03596", "title": "\nTowards zero-configuration condition monitoring based on dictionary  learning", "abstract": "Condition-based predictive maintenance can significantly improve overall equipment effectiveness provided that appropriate monitoring methods are used. Online condition monitoring systems are customized to each type of machine and need to be reconfigured when conditions change, which is costly and requires expert knowledge. Basic feature extraction methods limited to signal distribution functions and spectra are commonly used, making it difficult to automatically analyze and compare machine conditions. In this paper, we investigate the possibility to automate the condition monitoring process by continuously learning a dictionary of optimized shift-invariant feature vectors using a well-known sparse approximation method. We study how the feature vectors learned from a vibration signal evolve over time when a fault develops within a ball bearing of a rotating machine. We quantify the adaptation rate of learned features and find that this quantity changes significantly in the transitions between normal and faulty states of operation of the ball bearing.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Sergio Martin-del-Campo, Fredrik Sandin,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03595", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03595", "title": "\nProject Risk Management Model Based on PRINCE2 and Scrum Frameworks", "abstract": "There is a lack of formal risk management techniques in agile software development methods Scrum. The need to manage risks in agile project management is also identified by various authors. Authors of this paper conducted a survey to find out the current practices in agile project management. Furthermore authors discuss the new integrated framework of Scrum and PRINCE2 with focus on risk management. Enrichment of Scrum with selected practices from the heavy-weight project management framework PRINCE2 promises better results in delivering software products especially in global development projects.", "subjects": "Software Engineering (cs.SE)", "authors": "Martin Tomanek, Jan Juricek,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03581", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03581", "title": "\nWeb spam classification using supervised artificial neural network  algorithms", "abstract": "Due to the rapid growth in technology employed by the spammers, there is a need of classifiers that are more efficient, generic and highly adaptive. Neural Network based technologies have high ability of adaption as well as generalization. As per our knowledge, very little work has been done in this field using neural network. We present this paper to fill this gap. This paper evaluates performance of three supervised learning algorithms of artificial neural network by creating classifiers for the complex problem of latest web spam pattern classification. These algorithms are Conjugate Gradient algorithm, Resilient Backpropagation learning, and Levenberg-Marquardt algorithm.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "Ashish Chandra, Mohammad Suaib, Dr. Rizwan Beg,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03578", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03578", "title": "\nLower Bounds for Cover-Free Families", "abstract": "Let be a set of blocks of a -set . is called -cover-free family (CFF) provided that, the intersection of any blocks in is not contained in the union of any other blocks in . We give new asymptotic lower bounds for the number of minimum points in a -CFF when for some constant .", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Ali Z. Abdi, Nader H. Bshouty,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03573", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03573", "title": "\nAutomata and rational expressions", "abstract": "This text is an extended version of the chapter 'Automata and rational expressions' in the AutoMathA Handbook that will appear soon, published by the European Science Foundation and edited by JeanEricPin.", "subjects": "Formal Languages and Automata Theory (cs.FL)", "authors": "Jacques Sakarovitch,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03561", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03561", "title": "\nConcepts and evolution of research in the field of wireless sensor  networs", "abstract": "The field of Wireless Sensor Networks (WSNs) is experiencing a resurgence of interest and a continuous evolution in the scientific and industrial community. The use of this particular type of ad hoc network is becoming increasingly important in many contexts, regardless of geographical position and so, according to a set of possible application. WSNs offer interesting low cost and easily deployable solutions to perform a remote real time monitoring, target tracking and recognition of physical phenomenon. The uses of these sensors organized into a network continue to reveal a set of research questions according to particularities target applications. Despite difficulties introduced by sensor resources constraints, research contributions in this field are growing day by day. In this paper, we present a comprehensive review of most recent literature of WSNs and outline open research issues in this field.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Ado Adamou Abba Ari, Abdelhak Gueroui, Nabila Labraoui, Blaise Omer Yenke,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03556", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03556", "title": "\nAn Efficient Metric of Automatic Weight Generation for Properties in  Instance Matching Technique", "abstract": "The proliferation of heterogeneous data sources of semantic knowledge base intensifies the need of an automatic instance matching technique. However, the efficiency of instance matching is often influenced by the weight of a property associated to instances. Automatic weight generation is a non-trivial, however an important task in instance matching technique. Therefore, identifying an appropriate metric for generating weight for a property automatically is nevertheless a formidable task. In this paper, we investigate an approach of generating weights automatically by considering hypotheses: (1) the weight of a property is directly proportional to the ratio of the number of its distinct values to the number of instances contain the property, and (2) the weight is also proportional to the ratio of the number of distinct values of a property to the number of instances in a training dataset. The basic intuition behind the use of our approach is the classical theory of information content that infrequent words are more informative than frequent ones. Our mathematical model derives a metric for generating property weights automatically, which is applied in instance matching system to produce re-conciliated instances efficiently. Our experiments and evaluations show the effectiveness of our proposed metric of automatic weight generation for properties in an instance matching technique.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Md. Hanif Seddiqui, Rudra Pratap Deb Nath, Masaki Aono,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03552", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03552", "title": "\nApplications of Artificial Intelligence Techniques to Combating Cyber  Crimes: A Review", "abstract": "With the advances in information technology (IT) criminals are using cyberspace to commit numerous cyber crimes. Cyber infrastructures are highly vulnerable to intrusions and other threats. Physical devices and human intervention are not sufficient for monitoring and protection of these infrastructures; hence, there is a need for more sophisticated cyber defense systems that need to be flexible, adaptable and robust, and able to detect a wide variety of threats and make intelligent real-time decisions. Numerous bio-inspired computing methods of Artificial Intelligence have been increasingly playing an important role in cyber crime detection and prevention. The purpose of this study is to present advances made so far in the field of applying AI techniques for combating cyber crimes, to demonstrate how these techniques can be an effective tool for detection and prevention of cyber attacks, as well as to give the scope for future work.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Selma Dilek, H\u00fcseyin \u00c7ak\u0131r, Mustafa Ayd\u0131n,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03544", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03544", "title": "\nA New DNA-Based Approach of Generating Key-dependent ShiftRows  Transformation", "abstract": "The use of key-dependent shiftRows can be considered as one of the applied methods for altering the quality of a cryptographic algorithm. This article describes one approach for changing the ShiftRows transformation employed in the algorithm AES. The approach employs methods inspired from DNA processes and structure which depended on the key while the parameters of the created new ShiftRows have characteristics identical to those of the original algorithm AES in addition to increase its resistance against attacks. The proposed new ShiftRows were tested for coefficient correlation for dynamic and static independence between the input and output. The NIST Test Suite tests were used to test the randomness for the block cipher that used the new transformation.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Auday H. Al-Wattar, Ramlan Mahmod, Zuriati Ahmad Zukarnain, Nur Izura Udzir,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.03543", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03543", "title": "\nPrimal Dual Affine Scaling on GPUs", "abstract": "Here we present an implementation of Primal-Dual Affine scaling method to solve linear optimization problem on GPU based systems. Strategies to convert the system generated by complementary slackness theorem into a symmetric system are given. A new CUDA friendly technique to solve the resulting symmetric positive definite subsystem is also developed. Various strategies to reduce the memory transfer and storage requirements were also explored.", "subjects": "Numerical Analysis (cs.NA)", "authors": "Nithish Divakar,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03540", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03540", "title": "\nEvaluating Matrix Circuits", "abstract": "The circuit evaluation problem (also known as the compressed word problem) for finitely generated linear groups is studied. The best upper bound for this problem is , which is shown by a reduction to polynomial identity testing. Conversely, the compressed word problem for the linear group is equivalent to polynomial identity testing. In the paper, it is shown that the compressed word problem for every finitely generated nilpotent group is in . Within the larger class of polycyclic groups we find examples where the compressed word problem is at least as hard as polynomial identity testing for skew arithmetic circuits.", "subjects": "Computational Complexity (cs.CC)", "authors": "Daniel K\u00f6nig, Markus Lohrey,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03537", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03537", "title": "\nConvergence of gradient based pre-training in Denoising autoencoders", "abstract": "The success of deep architectures is at least in part attributed to the layer-by-layer unsupervised pre-training that initializes the network. Various papers have reported extensive empirical analysis focusing on the design and implementation of good pre-training procedures. However, an understanding pertaining to the consistency of parameter estimates, the convergence of learning procedures and the sample size estimates is still unavailable in the literature. In this work, we study pre-training in classical and distributed denoising autoencoders with these goals in mind. We show that the gradient converges at the rate of and has a sub-linear dependence on the size of the autoencoder network. In a distributed setting where disjoint sections of the whole network are pre-trained synchronously, we show that the convergence improves by at least , where corresponds to the size of the sections. We provide a broad set of experiments to empirically evaluate the suggested behavior.", "subjects": "Learning (cs.LG)", "authors": "Vamsi K Ithapu, Sathya Ravi, Vikas Singh,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03532", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03532", "title": "\nAn equalised global graphical model-based approach for multi-camera  object tracking", "abstract": "Multi-camera non-overlapping visual object tracking system typically consists of two tasks: single camera object tracking and inter-camera object tracking. Since the state-of-the-art approaches are yet not perform perfectly in real scenes, the errors in single camera object tracking module would propagate into the module of inter-camera object tracking, resulting much lower overall performance. In order to address this problem, we develop an approach that jointly optimise the single camera object tracking and inter-camera object tracking in an equalised global graphical model. Such an approach has the advantage of guaranteeing a good overall tracking performance even when there are limited amount of false tracking in single camera object tracking. Besides, the similarity metrics used in our approach improve the compatibility of the metrics used in the two different tasks. Results show that our approach achieve the state-of-the-art results in multi-camera non-overlapping tracking datasets.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Lijun Cao, Weihua Chen, Xiaotang Chen, Shuai Zheng, Kaiqi Huang,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03531", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03531", "title": "\nA State Estimation and Malicious Attack Game in Multi-Sensor Dynamic  Systems", "abstract": "In this paper, the problem of false information injection attack and defense on state estimation in dynamic multi-sensor systems is investigated from a game theoretic perspective. The relationship between the Kalman filter and the adversary can be regarded as a two-person zero-sum game. Under which condition both sides of the game will reach the Nash equilibrium is investigated in the paper. The multi-sensor Kalman filter system and the adversary are supposed to be rational players. The Kalman filter and the adversary have to choose their respective subsets of sensors to perform system state estimation and false information injection. It is shown how both sides pick their strategies in order to gain more and lose less. The optimal solutions are achieved by solving the minimax problem. Numerical results are also provided in order to illustrate the effectiveness of the derived optimal strategies.", "subjects": "Systems and Control (cs.SY)", "authors": "Jingyang Lu, Ruixin Niu,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03530", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03530", "title": "\nSingle Page Application and Canvas Drawing", "abstract": "Recently, with the impact of AJAX a new way of web development techniques have been emerged. Hence, with the help of this model, single-page web application was introduced which can be updated/replaced independently. Today we have a new challenge of building a powerful single-page application using the currently emerged technologies. Gaining an understanding of navigational model and user interface structure of the source application is the first step to successfully build a single- page application. In this paper, it explores not only building powerful single-page application but also Two Dimensional (2D) drawings on images and videos. Moreover, in this research it clearly express the findings on 2D multi-points polygon drawing concepts on client side; real-time data binding in between drawing module on image, video and view pages.", "subjects": "Human-Computer Interaction (cs.HC)", "authors": "Renien John Joseph,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03529", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03529", "title": "\nScalable Stochastic Alternating Direction Method of Multipliers", "abstract": "Stochastic alternating direction method of multipliers (ADMM), which visits only one sample or a mini-batch of samples each time, has recently been proved to achieve better performance than batch ADMM. However, most stochastic methods can only achieve a convergence rate on general convex problems,where T is the number of iterations. Hence, these methods are not scalable with respect to convergence rate (computation cost). There exists only one stochastic method, called SA-ADMM, which can achieve convergence rate on general convex problems. However, an extra memory is needed for SA-ADMM to store the historic gradients on all samples, and thus it is not scalable with respect to storage cost. In this paper, we propose a novel method, called scalable stochastic ADMM(SCAS-ADMM), for large-scale optimization and learning problems. Without the need to store the historic gradients, SCAS-ADMM can achieve the same convergence rate as the best stochastic method SA-ADMM and batch ADMM on general convex problems. Experiments on graph-guided fused lasso show that SCAS-ADMM can achieve state-of-the-art performance in real applications", "subjects": "Learning (cs.LG)", "authors": "Shen-Yi Zhao, Wu-Jun Li, Zhi-Hua Zhou,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.03526", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03526", "title": "\nAn Empirical Evaluation of Impact of Refactoring On Internal and  External Measures of Code Quality", "abstract": "Refactoring is the process of improving the design of existing code by changing its internal structure without affecting its external behaviour, with the main aims of improving the quality of software product. Therefore, there is a belief that refactoring improves quality factors such as understandability, flexibility, and reusability. However, there is limited empirical evidence to support such assumptions. The objective of this study is to validate/invalidate the claims that refactoring improves software quality. The impact of selected refactoring techniques was assessed using both external and internal measures. Ten refactoring techniques were evaluated through experiments to assess external measures: Resource Utilization, Time Behaviour, Changeability and Analysability which are ISO external quality factors and five internal measures: Maintainability Index, Cyclomatic Complexity, Depth of Inheritance, Class Coupling and Lines of Code. The result of external measures did not show any improvements in code quality after the refactoring treatment. However, from internal measures, maintainability index indicated an improvement in code quality of refactored code than non-refactored code and other internal measures did not indicate any positive effect on refactored code", "subjects": "Software Engineering (cs.SE)", "authors": "S. H. Kannangara, W.M.J.I. Wijayanayake,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03520", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03520", "title": "\nRandom Walks on Context Spaces: Towards an Explanation of the Mysteries  of Semantic Word Embeddings", "abstract": "The papers of Mikolov et al. 2013 as well as subsequent works have led to dramatic progress in solving word analogy tasks using semantic word embeddings. This leverages linear structure that is often found in the word embeddings, which is surprising since the training method is usually nonlinear. There were attempts ---notably by Levy and Goldberg and Pennington et al.--- to explain how this linear structure arises. The current paper points out the gaps in these explanations and provides a more complete explanation using a loglinear generative model for the corpus that directly models the latent semantic structure in words. The novel methodological twist is that instead of trying to fit the best model parameters to the data, a rigorous mathematical analysis is performed using the model priors to arrive at a simple closed form expression that approximately relates co-occurrence statistics and word embeddings. This expression closely corresponds to ---and a bit simpler than--- the existing training methods, and leads to good solutions to analogy tasks. Empirical support is provided also for the validity of the modeling assumptions. This methodology of letting some mathematical analysis substitute for some of the computational difficulty may be useful in other settings with generative models.", "subjects": "Learning (cs.LG)", "authors": "Sanjeev Arora, Yuanzhi Li, Yingyu Liang, Tengyu Ma, Andrej Risteski,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.03519", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03519", "title": "\nKnowledge-Based Trust: Estimating the Trustworthiness of Web Sources", "abstract": "The quality of web sources has been traditionally evaluated using exogenous signals such as the hyperlink structure of the graph. We propose a new approach that relies on endogenous signals, namely, the correctness of factual information provided by the source. A source that has few false facts is considered to be trustworthy. The facts are automatically extracted from each source by information extraction methods commonly used to construct knowledge bases. We propose a way to distinguish errors made in the extraction process from factual errors in the web source per se, by using joint inference in a novel multi-layer probabilistic model. We call the trustworthiness score we computed Knowledge-Based Trust (KBT). On synthetic data, we show that our method can reliably compute the true trustworthiness levels of the sources. We then apply it to a database of 2.8B facts extracted from the web, and thereby estimate the trustworthiness of 119M webpages. Manual evaluation of a subset of the results confirms the effectiveness of the method.", "subjects": "Databases (cs.DB)", "authors": "Xin Luna Dong, Evgeniy Gabrilovich, Kevin Murphy, Van Dang, Wilko Horn, Camillo Lugaresi, Shaohua Sun, Wei Zhang,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03518", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03518", "title": "\nEstimating Minimum Sum-rate for Cooperative Data Exchange", "abstract": "This paper considers how to accurately estimate the minimum sum-rate so as to reduce the complexity of solving cooperative data exchange (CDE) problems. The CDE system contains a number of geographically close clients who send packets to help the others recover an entire packet set. The minimum sum-rate is the minimum value of total number of transmissions that achieves universal recovery (the situation when all the clients recover the whole packet set). Based on a necessary and sufficient condition for a supermodular base polyhedron to be nonempty, we show that the minimum sum-rate for a CDE system can be determined by a maximization over all possible partitions of the client set. Due to the high complexity of solving this maximization problem, we propose a deterministic algorithm to approximate a lower bound on the minimum sum-rate. We show by experiments that this lower bound is much tighter than those lower bounds derived in the existing literature. We also show that the deterministic algorithm prevents from repetitively running the existing algorithms for solving CDE problems so that the overall complexity can be reduced accordingly.", "subjects": "Information Theory (cs.IT)", "authors": "Ni Ding, Rodney A. Kennedy, Parastoo Sadeghi,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.03517", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03517", "title": "\nFairest Constant Sum-rate Transmission for Cooperative Data Exchange: An  M-convex Minimization Approach", "abstract": "We consider the fairness in cooperative data exchange (CDE) problem among a set of wireless clients. In this system, each client initially obtains a subset of the packets. They exchange packets in order to reconstruct the entire packet set. We study the problem of how to find a transmission strategy that distributes the communication load most evenly in all strategies that have the same sum-rate (the total number of transmissions) and achieve universal recovery (the situation when all clients recover the packet set). We formulate this problem by a discrete minimization problem and prove its -convexity. We show that our results can also be proved by the submodularity of the feasible region shown in previous works and are closely related to the resource allocation problems under submodular constraints. To solve this problem, we propose to use a steepest descent algorithm (SDA) based on -convexity. By varying the number of clients and packets, we compare SDA with a deterministic algorithm (DA) based on submodularity in terms of convergence performance and complexity. The results show that for the problem of finding the fairest and minimum sum-rate strategy for the CDE problem SDA is more efficient than DA when the number of clients is up to five.", "subjects": "Information Theory (cs.IT)", "authors": "Ni Ding, Rodney A. Kennedy, Parastoo Sadeghi,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03515", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03515", "title": "\nVerifying the correct composition of distributed components:  Formalisation and Tool", "abstract": "This article provides formal definitions characterizing well-formed composition of components in order to guarantee their safe deployment and execution. Our work focuses on the structural aspects of component composition; it puts together most of the concepts common to many component models, but never formalized as a whole. Our formalization characterizes correct component architectures made of functional and non-functional aspects, both structured as component assemblies. Interceptor chains can be used for a safe and controlled interaction between the two aspects. Our well-formed components guarantee a set of properties ensuring that the deployed component system has a correct architecture and can run safely. Finally, those definitions constitute the formal basis for our Eclipse-based environment for the development and specification of component-based applications.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Ludovic Henrio, Oleksandra Kulankhina, Dongqian Liu, Eric Madelaine,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03514", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03514", "title": "\nOn Synchronous and Asynchronous Monitor Instrumentation for Actor-based  systems", "abstract": "We study the impact of synchronous and asynchronous monitoring instrumentation on runtime overheads in the context of a runtime verification framework for actor-based systems. We show that, in such a context, asynchronous monitoring incurs substantially lower overhead costs. We also show how, for certain properties that require synchronous monitoring, a hybrid approach can be used that ensures timely violation detections for the important events while, at the same time, incurring lower overhead costs that are closer to those of an asynchronous instrumentation.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Ian Cassar, Adrian Francalanza,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03513", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03513", "title": "\nOn Distributed Density in Tuple-based Coordination Languages", "abstract": "Inspired by the chemical metaphor, this paper proposes an extension of Linda-like languages in the aim of modeling the coordination of complex distributed systems. The new language manipulates finite sets of tuples and distributes a density among them. This new concept adds to the non-determinism inherent in the selection of matched tuples a non-determinism to the tell, ask and get primitives on the consideration of different tuples. Furthermore, thanks to de Boer and Palamidessi's notion of modular embedding, we establish that this new language strictly increases the expressiveness of the Dense Bach language introduced earlier and, consequently, Linda-like languages.", "subjects": "Programming Languages (cs.PL)", "authors": "Denis Darquennes, Jean-Marie Jacquet, Isabelle Linden,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03512", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03512", "title": "\nDistributed Enforcement of Service Choreographies", "abstract": "Modern service-oriented systems are often built by reusing, and composing together, existing services distributed over the Internet. Service choreography is a possible form of service composition whose goal is to specify the interactions among participant services from a global perspective. In this paper, we formalize a method for the distributed and automated enforcement of service choreographies, and prove its correctness with respect to the realization of the specified choreography. The formalized method is implemented as part of a model-based tool chain released to support the development of choreography-based systems within the EU CHOReOS project. We illustrate our method at work on a distributed social proximity network scenario.", "subjects": "Software Engineering (cs.SE)", "authors": "Marco Autili, Massimo Tivoli,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03509", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03509", "title": "\nMADE: Masked Autoencoder for Distribution Estimation", "abstract": "There has been a lot of recent interest in designing neural network models to estimate a distribution from a set of examples. We introduce a simple modification for autoencoder neural networks that yields powerful generative models. Our method masks the autoencoder's parameters to respect autoregressive constraints: each input is reconstructed only from previous inputs in a given ordering. Constrained this way, the autoencoder outputs can be interpreted as a set of conditional probabilities, and their product, the full joint probability. We can also train a single network that can decompose the joint probability in multiple different orderings. Our simple framework can be applied to multiple architectures, including deep ones. Vectorized implementations, such as on GPUs, are simple and fast. Experiments demonstrate that this approach is competitive with state-of-the-art tractable distribution estimators. At test time, the method is significantly faster and scales better than other autoregressive estimators.", "subjects": "Learning (cs.LG)", "authors": "Mathieu Germain, Karol Gregor, Iain Murray, Hugo Larochelle,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03508", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03508", "title": "\nAdding vs. Averaging in Distributed Primal-Dual Optimization", "abstract": "Distributed optimization algorithms for large-scale machine learning suffer from a communication bottleneck. Reducing communication makes the efficient aggregation of partial work from different machines more challenging. In this paper we present a novel generalization of the recent communication efficient primal-dual coordinate ascent framework (CoCoA). Our framework, CoCoA+, allows for additive combination of local updates to the global parameters at each iteration, whereas previous schemes only allowed conservative averaging. We give stronger (primal-dual) convergence rate guarantees for both CoCoA as well as our new variants, and generalize the theory for both methods to also cover non-smooth convex loss functions. We provide an extensive experimental comparison on several real-world distributed datasets, showing markedly improved performance, especially when scaling up the number of machines.", "subjects": "Learning (cs.LG)", "authors": "Chenxin Ma, Virginia Smith, Martin Jaggi, Michael I. Jordan, Peter Richt\u00e1rik, Martin Tak\u00e1\u010d,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03505", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03505", "title": "\nSupervised LogEuclidean Metric Learning for Symmetric Positive Definite  Matrices", "abstract": "Metric learning has been shown to be highly effective to improve the performance of nearest neighbor classification. In this paper, we address the problem of metric learning for Symmetric Positive Definite (SPD) matrices such as covariance matrices, which arise in many real-world applications. Naively using standard Mahalanobis metric learning methods under the Euclidean geometry for SPD matrices is not appropriate, because the difference of SPD matrices can be a non-SPD matrix and thus the obtained solution can be uninterpretable. To cope with this problem, we propose to use a properly parameterized LogEuclidean distance and optimize the metric with respect to kernel-target alignment, which is a supervised criterion for kernel learning. Then the resulting non-trivial optimization problem is solved by utilizing the Riemannian geometry. Finally, we experimentally demonstrate the usefulness of our LogEuclidean metric learning algorithm on real-world classification tasks for EEG signals and texture patches.", "subjects": "Learning (cs.LG)", "authors": "Florian Yger, Masashi Sugiyama,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03504", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03504", "title": "\nLocally-Oriented Programming: A Simple Programming Model for  Stencil-Based Computations on Multi-Level Distributed Memory Architectures", "abstract": "Emerging hybrid accelerator architectures for high performance computing are often suited for the use of a data-parallel programming model. Unfortunately, programmers of these architectures face a steep learning curve that frequently requires learning a new language (e.g., OpenCL). Furthermore, the distributed (and frequently multi-level) nature of the memory organization of clusters of these machines provides an additional level of complexity. This paper presents preliminary work examining how programming with a local orientation can be employed to provide simpler access to accelerator architectures. A locally-oriented programming model is especially useful for the solution of algorithms requiring the application of a stencil or convolution kernel. In this programming model, a programmer codes the algorithm by modifying only a single array element (called the local element), but has read-only access to a small sub-array surrounding the local element. We demonstrate how a locally-oriented programming model can be adopted as a language extension using source-to-source program transformations.", "subjects": "Programming Languages (cs.PL)", "authors": "Craig Rasmussen, Matthew Sottile, Daniel Nagle, Soren Rasmussen,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03496", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03496", "title": "\nSpectral Sparsification of Random-Walk Matrix Polynomials", "abstract": "We consider a fundamental algorithmic question in spectral graph theory: Compute a spectral sparsifier of random-walk matrix-polynomial L_ alpha(G)=D- sum_^d alpha_rD(D^A)^r where is the adjacency matrix of a weighted, undirected graph, is the diagonal matrix of weighted degrees, and are nonnegative coefficients with . Recall that is the transition matrix of random walks on the graph. The sparsification of appears to be algorithmically challenging as the matrix power is defined by all paths of length , whose precise calculation would be prohibitively expensive. In this paper, we develop the first nearly linear time algorithm for this sparsification problem: For any with vertices and edges, coefficients , and , our algorithm runs in time to construct a Laplacian matrix with non-zeros such that . Matrix polynomials arise in mathematical analysis of matrix functions as well as numerical solutions of matrix equations. Our work is particularly motivated by the algorithmic problems for speeding up the classic Newton's method in applications such as computing the inverse square-root of the precision matrix of a Gaussian random field, as well as computing the th-root transition (for ) in a time-reversible Markov model. The key algorithmic step for both applications is the construction of a spectral sparsifier of a constant degree random-walk matrix-polynomials introduced by Newton's method. Our algorithm can also be used to build efficient data structures for effective resistances for multi-step time-reversible Markov models, and we anticipate that it could be useful for other tasks in network analysis.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Dehua Cheng, Yu Cheng, Yan Liu, Richard Peng, Shang-Hua Teng,", "date": "2015-2-12"}, 
{"urllink": "http://arxiv.org/abs/1502.03493", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03493", "title": "\nOn the Potential of Bluetooth Low Energy Technology for Vehicular  Applications", "abstract": "With the increasing number of sensors in modern vehicles, using an Intra-Vehicular Wireless Sensor Network (IVWSN) is a possible solution for the automotive industry to address the potential issues that arise from additional wiring harness. Such a solution could help car manufacturers develop vehicles that have better fuel economy and performance, in addition to supporting new applications. However, which wireless technology for IVWSNs should be used for maximizing the aforementioned benefits is still an open issue. In this paper, we propose to use a new wireless technology known as Bluetooth Low Energy (BLE) and highlight a new architecture for IVWSN. Based on a comprehensive study which encompasses an example application, it is shown that BLE is an excellent option that can be used in IVWSNs for certain applications mainly due to its good performance and low-power, low-complexity, and low-cost attributes.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Jiun-Ren Lin, Timothy Talty, Ozan K. Tonguz,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03487", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03487", "title": "\nWeakening the Isolation Assumption of Tamper-proof Hardware Tokens", "abstract": "Recent results have shown the usefulness of tamper-proof hardware tokens as a setup assumption for building UC-secure two-party computation protocols, thus providing broad security guarantees and allowing the use of such protocols as buildings blocks in the modular design of complex cryptography protocols. All these works have in common that they assume the tokens to be completely isolated from their creator, but this is a strong assumption. In this work we investigate the feasibility of cryptographic protocols in the setting where the isolation of the hardware token is weakened. We consider two cases: (1) the token can relay messages to its creator, or (2) the creator can send messages to the token after it is sent to the receiver. We provide a detailed characterization for both settings, presenting both impossibilities and information-theoretically secure solutions.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Rafael Dowsley, J\u00f6rn M\u00fcller-Quade, Tobias Nilges,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03482", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03482", "title": "\nNecessary conditions for tractability of valued CSPs", "abstract": "The connection between constraint languages and clone theory has been a fruitful line of research on the complexity of constraint satisfaction problems. In a recent result, Cohen et al. [SICOMP'13] have characterised a Galois connection between valued constraint languages and so-called weighted clones. In this paper, we study the structure of weighted clones. We extend the results of Creed and Zivny from [CP'11/SICOMP'13] and provide necessary conditions for tractability of weighted clones and thus valued constraint languages. We demonstrate that some of the necessary conditions are also sufficient for tractability, while others are provably not.", "subjects": "Computational Complexity (cs.CC)", "authors": "Johan Thapper, Stanislav Zivny,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03475", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03475", "title": "\nStochastic and Adversarial Combinatorial Bandits", "abstract": "This paper investigates stochastic and adversarial combinatorial multi-armed bandit problems. In the stochastic setting, we first derive problem-specific regret lower bounds, and analyze how these bounds scale with the dimension of the decision space. We then propose COMBUCB, algorithms that efficiently exploit the combinatorial structure of the problem, and derive finite-time upper bound on their regrets. These bounds improve over regret upper bounds of existing algorithms, and we show numerically thatCOMBUCB significantly outperforms any other algorithm. In the adversarial setting, we propose two simple algorithms, namely COMBEXP-1 and COMBEXP-2 for semi-bandit and bandit feedback, respectively. Their regrets have similar scaling as state-of-the-art algorithms, in spite of the simplicity of their implementation.", "subjects": "Learning (cs.LG)", "authors": "Richard Combes, Marc Lelarge, Alexandre Proutiere, M. Sadegh Talebi,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03473", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03473", "title": "\nData-Dependent Clustering in Exploration-Exploitation Algorithms", "abstract": "We investigate two data-dependent clustering techniques for content recommendation based on exploration-exploitation strategies in contextual multiarmed bandit settings. Our algorithms dynamically group users based on the items under consideration and, possibly, group items based on the similarity of the clusterings induced over the users. The resulting algorithm thus takes advantage of preference patterns in the data in a way akin to collaborative filtering methods. We provide an empirical analysis on extensive real-world datasets, showing scalability and increased prediction performance over state-of-the-art methods for clustering bandits. For one of the two algorithms we also give a regret analysis within a standard linear stochastic noise setting.", "subjects": "Learning (cs.LG)", "authors": "Shuai Li, Claudio Gentile, Alexandros Karatzoglou, Giovanni Zappella,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.03469", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03469", "title": "\nOptimizing Average-Maximum TTR Trade-off for Cognitive Radio Rendezvous", "abstract": "In cognitive radio (CR) networks, \"TTR\", a.k.a. time-to-rendezvous, is one of the most important metrics for evaluating the performance of a channel hopping (CH) rendezvous protocol, and it characterizes the rendezvous delay when two CRs perform channel hopping. There exists a trade-off of optimizing the average or maximum TTR in the CH rendezvous protocol design. On one hand, the random CH protocol leads to the best \"average\" TTR without ensuring a finite \"maximum\" TTR (two CRs may never rendezvous in the worst case), or a high rendezvous diversity (multiple rendezvous channels). On the other hand, many sequence-based CH protocols ensure a finite maximum TTR (upper bound of TTR) and a high rendezvous diversity, while they inevitably yield a larger average TTR. In this paper, we strike a balance in the average-maximum TTR trade-off for CR rendezvous by leveraging the advantages of both random and sequence-based CH protocols. Inspired by the neighbor discovery problem, we establish a design framework of creating a wake-up schedule whereby every CR follows the sequence-based (or random) CH protocol in the awake (or asleep) mode. Analytical and simulation results show that the hybrid CH protocols under this framework are able to achieve a greatly improved average TTR as well as a low upper-bound of TTR, without sacrificing the rendezvous diversity.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Lin Chen, Shuyu Shi, Kaigui Bian, Yusheng Ji,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03455", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03455", "title": "\nDynamic Bandwidth-Efficient BCube Topologies for Virtualized Data Center  Networks", "abstract": "Software-defined networking (SDN) enables network and data center (DC) providers with a flexible management of networking resources. SDN is also an appropriate solution for network virtualization since in this way each network component can be placed in a software container. In this paper, we address some of the existing issues with the classic DC network topologies to be used in virtualized environment, and then investigate a group of DC network topologies with the capability of providing dynamic structures according to the service-level required depending on the active traffic in a virtual DC network. In particular, we propose three main approaches to modify the structure of a classic BCube topology used as a benchmark. The associated structural features and maximum achievable interconnected bandwidth of these modifications is studied for various routing scenarios. Finally, we run an extensive simulation program to check the performance of the proposed modified topologies in a simulation environment which considers failure of components and also traffic congestion. Our simulation experiments show the efficiency of the proposed modified topologies compared to the classic BCube in terms of the available bandwidth and failure resiliency, as expected.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Vahid Asghari, Reza Farrahi Moghaddam, Fereydoun Farrahi Moghaddam, Mohamed Cheriet,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03451", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03451", "title": "\nCornerstones of Sampling of Operator Theory", "abstract": "This paper reviews some results on the identifiability of classes of operators whose Kohn-Nirenberg symbols are band-limited (called band-limited operators), which we refer to as sampling of operators. We trace the motivation and history of the subject back to the original work of the third-named author in the late 1950s and early 1960s, and to the innovations in spread-spectrum communications that preceded that work. We give a brief overview of the NOMAC (Noise Modulation and Correlation) and Rake receivers, which were early implementations of spread-spectrum multi-path wireless communication systems. We examine in detail the original proof of the third-named author characterizing identifiability of channels in terms of the maximum time and Doppler spread of the channel, and do the same for the subsequent generalization of that work by Bello. The mathematical limitations inherent in the proofs of Bello and the third author are removed by using mathematical tools unavailable at the time. We survey more recent advances in sampling of operators and discuss the implications of the use of periodically-weighted delta-trains as identifiers for operator classes that satisfy Bello's criterion for identifiability, leading to new insights into the theory of finite-dimensional Gabor systems. We present novel results on operator sampling in higher dimensions, and review implications and generalizations of the results to stochastic operators, MIMO systems, and operators with unknown spreading domains.", "subjects": "Information Theory (cs.IT)", "authors": "David Walnut, G\u00f6tz E. Pfander, Thomas Kailath,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03436", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03436", "title": "\nFast Neural Networks with Circulant Projections", "abstract": "The basic computation of a fully-connected neural network layer is a linear projection of the input signal followed by a non-linear transformation. The linear projection step consumes the bulk of the processing time and memory footprint. In this work, we propose to replace the conventional linear projection with the circulant projection. The circulant structure enables the use of the Fast Fourier Transform to speed up the computation. Considering a neural network layer with input nodes, and output nodes, this method improves the time complexity from to and space complexity from to . We further show that the gradient computation and optimization of the circulant projections can be performed very efficiently. Our experiments on three standard datasets show that the proposed approach achieves this significant gain in efficiency and storage with minimal loss of accuracy compared to neural networks with unstructured projections.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Yu Cheng, Felix X. Yu, Rogerio S. Feris, Sanjiv Kumar, Alok Choudhary, Shih-Fu Chang,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03431", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03431", "title": "\nTime Petri Net Models for a New Queuless and Uncentralized Resource  Discovery System", "abstract": "In this report, we detail the model using Petri Nets of a new fully distributed resource reservation system. The basic idea of the considered distributed system is to let a user reserve a set of resources on a local network and to use them, without any specific, central administration component such as a front-end node. Resources can be, for instance, computing resources (cores, nodes, GPUs...) or some memory on a server. In order to verify some qualitative and quantitative properties provided by this system, we need to model it. We detail the algorithms used by this system and the Petri Net models we made of it.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Camille Coti, Sami Evangelista, Kais Klai,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03430", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03430", "title": "\nTimeability of Extensive-Form Games", "abstract": "Extensive-form games constitute the standard representation scheme for games with a temporal component. But do all extensive-form games correspond to protocols that we can implement in the real world? We often rule out games with imperfect recall, which prescribe that an agent forget something that she knew before. In this paper, we show that even some games with perfect recall can be problematic to implement. Specifically, we show that if the agents have a sense of time passing (say, access to a clock), then some extensive-form games can no longer be implemented; no matter how we attempt to time the game, some information will leak to the agents that they are not supposed to have. We say such a game is not exactly timeable. We provide easy-to-check necessary and sufficient conditions for a game to be exactly timeable. Most of the technical depth of the paper concerns how to approximately time games, which we show can always be done, though it may require large amounts of time. Specifically, we show that for some games the time required to approximately implement the game grows as a power tower of height proportional to the number of players and with a parameter that measures the precision of the approximation at the top of the power tower. In practice, that makes the games untimeable. Besides the conceptual contribution to game theory, we believe our methodology can have applications to preventing information leakage in security protocols.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Sune K. Jakobsen, Troels B. S\u00f8rensen, Vincent Conitzer,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03426", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03426", "title": "\nSolution sets for equations over free groups are EDT0L languages", "abstract": "We show that, given a word equation over a finitely generated free group, the set of all solutions in reduced words forms an EDT0L language. In particular, it is an indexed language in the sense of Aho. The question whether a formal language description of solution sets in reduced words as indexed language is possible has been been open for some years, apparently without much hope that a positive answer could hold. Nevertheless, our positive answer goes far beyond: they are EDT0L, which is a proper subclass of indexed languages. We can additionally handle the existential theory of equations with rational constraints in free products , where each is either a free or finite group, or a free monoid with involution. In all cases the result is the same: the set of all solutions in reduced words is EDT0L. This was known only for quadratic word equations by Fert 'e, Marin and S 'enizergues (ToCS 2014), which is a very restricted case. Our general result became possible due to the recently invented recompression technique of Je .z. In this paper we use a new way to integrate solutions of linear Diophantine equations into the process and obtain more general results than in the related paper (arXiv 1405.5133). For example, we improve the complexity from quadratic nondeterministic space to quasi-linear nondeterministic space, and the new bound has the potential to be optimal. This implies an improved complexity for deciding the existential theory of non-abelian free groups: NSPACE(). The conjectured complexity is NP; however, we believe that our results are optimal with respect to space complexity, independent of the conjectured NP.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Laura Ciobanu, Volker Diekert, Murray Elder,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03409", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03409", "title": "\nLarge-Scale Deep Learning on the YFCC100M Dataset", "abstract": "We present a work-in-progress snapshot of learning with a 15 billion parameter deep learning network on HPC architectures applied to the largest publicly available natural image and video dataset released to-date. Recent advancements in unsupervised deep neural networks suggest that scaling up such networks in both model and training dataset size can yield significant improvements in the learning of concepts at the highest layers. We train our three-layer deep neural network on the Yahoo! Flickr Creative Commons 100M dataset. The dataset comprises approximately 99.2 million images and 800,000 user-created videos from Yahoo's Flickr image and video sharing platform. Training of our network takes eight days on 98 GPU nodes at the High Performance Computing Center at Lawrence Livermore National Laboratory. Encouraging preliminary results and future research directions are presented and discussed.", "subjects": "Learning (cs.LG)", "authors": "Karl Ni, Roger Pearce, Kofi Boakye, Brian Van Essen, Damian Borth, Barry Chen, Eric Wang,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03407", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03407", "title": "\nAlbatross: a Privacy-Preserving Location Sharing System", "abstract": "Social networking services are increasingly accessed through mobile devices. This trend has prompted services such as Facebook and Google+ to incorporate location as a de facto feature of user interaction. At the same time, services based on location such as Foursquare and Shopkick are also growing as smartphone market penetration increases. In fact, this growth is happening despite concerns (growing at a similar pace) about security and third-party use of private location information (e.g., for advertising). Nevertheless, service providers have been unwilling to build truly private systems in which they do not have access to location information. In this paper, we describe an architecture and a trial implementation of a privacy-preserving location sharing system called Albatross. The system protects location information from the service provider and yet enables fine-grained location-sharing. One main feature of the system is to protect an individual's social network structure. The pattern of location sharing preferences towards contacts can reveal this structure without any knowledge of the locations themselves. Albatross protects locations sharing preferences through protocol unification and masking. Albatross has been implemented as a standalone solution, but the technology can also be integrated into location-based services to enhance privacy.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Gokay Saldamli, Richard Chow, Hongxia Jin,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03387", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03387", "title": "\nA Full Frequency Masking Vocoder for Legal Eavesdropping Conversation  Recording", "abstract": "This paper presents a new approach for a vocoder design based on full frequency masking by octaves in addition to a technique for spectral filling via beta probability distribution. Some psycho-acoustic characteristics of human hearing - inaudibility masking in frequency and phase - are used as a basis for the proposed algorithm. The results confirm that this technique may be useful to save bandwidth in applications requiring intelligibility. It is recommended for the legal eavesdropping of long voice conversations.", "subjects": "Sound (cs.SD)", "authors": "R.F.B. Sotero Filho, H.M. de Oliveira, R.M. Campello de Souza,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03379", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03379", "title": "\nLocating a Tree in a Phylogenetic Network in Quadratic Time", "abstract": "A fundamental problem in the study of phylogenetic networks is to determine whether or not a given phylogenetic network contains a given phylogenetic tree. We develop a quadratic-time algorithm for this problem for binary nearly-stable phylogenetic networks. We also show that the number of reticulations in a reticulation visible or nearly stable phylogenetic network is bounded from above by a function linear in the number of taxa.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Philippe Gambette, Andreas D. M. Gunawan, Anthony Labarre, St\u00e9phane Vialette, Louxin Zhang,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03372", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03372", "title": "\nA Fast Distributed Algorithm for $\u03b1$-Fair Packing Problems", "abstract": "Over the past two decades, fair resource allocation problems received considerable attention in a variety of application areas. While polynomial time distributed algorithms have been designed for max-min fair resource allocation, the design of distributed algorithms with convergence guarantees for the more general fair allocations received little attention. In this paper, we study weighted -fair packing problems, that is, the problems of maximizing the objective functions when and when over linear constraints , , where are positive weights and and are non-negative. We consider the distributed computation model that was used for packing linear programs and network utility maximization problems. Under this model, we provide a distributed algorithm for general . The algorithm uses simple local update rules and is stateless (namely, it allows asynchronous updates, is self-stabilizing, and allows incremental and local adjustments). It converges to approximate solutions in running times that have an inverse polynomial dependence on the approximation parameter . The convergence time has polylogarithmic dependence on the problem size for , and a nearly-linear dependence on the number of variables for . These are the best convergence times known for these problems.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Jelena Marasevic, Cliff Stein, Gil Zussman,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03358", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03358", "title": "\nThe CEO Problem with Secrecy Constraints", "abstract": "We study a lossy source coding problem with secrecy constraints in which a remote information source should be transmitted to a single destination via multiple agents in the presence of a passive eavesdropper. The agents observe noisy versions of the source and independently encode and transmit their observations to the destination via noiseless rate-limited links. The destination should estimate the remote source based on the information received from the agents within a certain mean distortion threshold. The eavesdropper, with access to side information correlated to the source, is able to listen in on one of the links from the agents to the destination in order to obtain as much information as possible about the source. This problem can be viewed as the so-called CEO problem with additional secrecy constraints. We establish inner and outer bounds on the rate-distortion-equivocation region of this problem. We also obtain the region in special cases where the bounds are tight. Furthermore, we study the quadratic Gaussian case and provide the optimal rate-distortion-equivocation region when the eavesdropper has no side information and an achievable region for a more general setup with side information at the eavesdropper.", "subjects": "Information Theory (cs.IT)", "authors": "Farshad Naghibi, Somayeh Salimi, Mikael Skoglund,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03346", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03346", "title": "\nHow well do you blend into the crowd? - d-convergence: A novel paradigm  for quantifying privacy in the age of Big-Data", "abstract": "The advent of the Big-Data paradigm and the thereby emerging personalized tracking and monetization of personal information have amplified the privacy concerns of Internet users. Privacy-enhancing technologies struggle to keep pace with this Internet-scale development, and currently lack even the basic methodology to assess privacy in this world of rapid dissemination of unstructured, heterogeneous data with many involved actors. We refer to this problem as Big-Data privacy. Existing privacy models (k-anonymity, t-closeness, or the currently most popular notion of Differential Privacy) are inherently inadequate to reason about Big-Data privacy: they require an a-priori structure and classification of the data under consideration, and they disregard adversaries that utilize ubiquitously available background knowledge to infer further privacy-sensitive information. In this paper, we develop a user-centric privacy model for reasoning about Big-Data privacy. Our model constitutes a reinterpretation of statistical language models that are predominantly used in the information retrieval (IR) community to characterize documents with regard to their information content, and it explicitly leverages ideas from IR to cope with arbitrary (unstructured, heterogeneous) data in dynamically changing contexts. At the core of the model is our new notion of d-convergence, which measures the similarity of entities in a given setting, and hence allows us to derive bounds on the probability for a given entity to be singled out from its peers. This in particular entails a novel definition of Big-Data privacy based on indistinguishability of entities. We demonstrate the applicability of our privacy model on a collection of 40 million comments collected from the Online Social Network Reddit, which we stripped down to 15 million comments for our evaluation.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Michael Backes, Pascal Berrang, Praveen Manoharan,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03343", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03343", "title": "\nRequirements Analysis of a Quad-Redundant Flight Control System", "abstract": "In this paper we detail our effort to formalize and prove requirements for the Quad-redundant Flight Control System (QFCS) within NASA's Transport Class Model (TCM). We use a compositional approach with assume-guarantee contracts that correspond to the requirements for software components embedded in an AADL system architecture model. This approach is designed to exploit the verification effort and artifacts that are already part of typical software verification processes in the avionics domain. Our approach is supported by an AADL annex that allows specification of contracts along with a tool, called AGREE, for performing compositional verification. The goal of this paper is to show the benefits of a compositional verification approach applied to a realistic avionics system and to demonstrate the effectiveness of the AGREE tool in performing this analysis.", "subjects": "Software Engineering (cs.SE)", "authors": "John Backes, Darren Cofer, Steven Miller, Mike Whalen,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03337", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03337", "title": "\nA Mechanism for Fair Distribution of Resources with Application to  Sponsored Search", "abstract": "There is a rapid shift of advertisement from the traditional media to the Internet. A large portion of the traffic created by publicity is due to search engines through sponsored search. Advertisers pay the search engine to show their content, usually in order to get traffic to their own websites (where they may even feature more publicity). Search engines provide limited space for publicity (i.e. slots) for each keyword search. Since the demand is high they are conducting auctions to determine the advertisers for each keyword search. Designing an auction mechanism one must specify how to assign bidders to goods (or vice versa) and how to set the price for each good won in the auction. This work proposes a new auction mechanism were the slots are distributed among the advertisers depending on how much each advertiser values appearing in a keyword search slot at a specific time. The proposed approach makes payment to the search engine independent of these values. In particular, we propose that payments take the form of a flat fee. We show that this auction mechanism fairly distributes resources (or goods, e.g., slots) in an online fashion, based on the users' declared preferences, while being socially efficient. While the main motivation for this work was sponsored search, the proposed mechanism can be used in general for the fair distribution of resources in an online fashion among a set of users. Hence, we refer to this mechanism as Fair and Efficient Distribution of Resources (FEDoR). FEDoR can be used even when the auction is done in a distributed fashion (i.e., without central authority), and it provides fairness, social efficiency and incentive compatibility. Essentially, letting the search engine adjust its revenue through the flat fee paid by the advertisers, FEDoR allows it to achieve the maximum gain while being competitive in the search engines' market.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Evgenia Christoforou, Antonio Fern\u00e1ndez Anta, Agust\u00edn Santos,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03332", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03332", "title": "\nInertial Hegselmann-Krause Systems", "abstract": "Inertial HK systems form a variant of the classic Hegselmann-Krause model of opinion dynamics in which agents may give themselves arbitrary weights at each step. We bound the kinetic 2-energy of these systems and use this result to prove the convergence of HK systems with static agents, thus settling an open question of long standing.", "subjects": "Systems and Control (cs.SY)", "authors": "Bernard Chazelle, Chu Wang,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03322", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03322", "title": "\nBoost Phrase-level Polarity Labelling with Review-level Sentiment  Classification", "abstract": "Sentiment analysis on user reviews helps to keep track of user reactions towards products, and make advices to users about what to buy. State-of-the-art review-level sentiment classification techniques could give pretty good precisions of above 90%. However, current phrase-level sentiment analysis approaches might only give sentiment polarity labelling precisions of around 70%~80%, which is far from satisfaction and restricts its application in many practical tasks. In this paper, we focus on the problem of phrase-level sentiment polarity labelling and attempt to bridge the gap between phrase-level and review-level sentiment analysis. We investigate the inconsistency between the numerical star ratings and the sentiment orientation of textual user reviews. Although they have long been treated as identical, which serves as a basic assumption in previous work, we find that this assumption is not necessarily true. We further propose to leverage the results of review-level sentiment classification to boost the performance of phrase-level polarity labelling using a novel constrained convex optimization framework. Besides, the framework is capable of integrating various kinds of information sources and heuristics, while giving the global optimal solution due to its convexity. Experimental results on both English and Chinese reviews show that our framework achieves high labelling precisions of up to 89%, which is a significant improvement from current approaches.", "subjects": "Computation and Language (cs.CL)", "authors": "Yongfeng Zhang, Min Zhang, Yiqun Liu, Shaoping Ma,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03320", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03320", "title": "\nConstruction and impromptu repair of an MST in a distributed network  with o(m) communication", "abstract": "In the CONGEST model, a communications network is an undirected graph whose nodes are processors and whose edges are the communications links between processors. At any given time step, a message of size may be sent by each node to each of its neighbors. We show for the synchronous model: If all nodes start in the same round, and each node knows its ID and the ID's of its neighbors, or in the case of MST, the distinct weights of its incident edges and knows , then there are Monte Carlo algorithms which succeed w.h.p. to determine a minimum spanning forest (MST) and a spanning forest (ST) using messages for MST and messages for ST, resp. These results contradict the \"folk theorem\" noted in Awerbuch, et.al., JACM 1990 that the distributed construction of a broadcast tree requires messages. This lower bound has been shown there and in other papers for some CONGEST models; our protocol demonstrates the limits of these models. A dynamic distributed network is one which undergoes online edge insertions or deletions. We also show how to repair an MST or ST in a dynamic network with asynchronous communication. An edge deletion can be processed in expected messages in the MST, and expected messages for the ST problem, while an edge insertion uses messages in the worst case. We call this \"impromptu\" updating as we assume that between processing of edge updates there is no preprocessing or storage of additional information. Previous algorithms for this problem that use an amortized messages per update require substantial preprocessing and additional local storage between updates.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Valerie King, Shay Kutten, Mikkel Thorup,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03316", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03316", "title": "\nThe Hardness of Approximation of Euclidean k-means", "abstract": "The Euclidean -means problem is a classical problem that has been extensively studied in the theoretical computer science, machine learning and the computational geometry communities. In this problem, we are given a set of points in Euclidean space , and the goal is to choose centers in so that the sum of squared distances of each point to its nearest center is minimized. The best approximation algorithms for this problem include a polynomial time constant factor approximation for general and a -approximation which runs in time . At the other extreme, the only known computational complexity result for this problem is NP-hardness [ADHP'09]. The main difficulty in obtaining hardness results stems from the Euclidean nature of the problem, and the fact that any point in can be a potential center. This gap in understanding left open the intriguing possibility that the problem might admit a PTAS for all . In this paper we provide the first hardness of approximation for the Euclidean -means problem. Concretely, we show that there exists a constant such that it is NP-hard to approximate the -means objective to within a factor of . We show this via an efficient reduction from the vertex cover problem on triangle-free graphs: given a triangle-free graph, the goal is to choose the fewest number of vertices which are incident on all the edges. Additionally, we give a proof that the current best hardness results for vertex cover can be carried over to triangle-free graphs. To show this we transform , a known hard vertex cover instance, by taking a graph product with a suitably chosen graph , and showing that the size of the (normalized) maximum independent set is almost exactly preserved in the product graph using a spectral analysis, which might be of independent interest.", "subjects": "Computational Complexity (cs.CC)", "authors": "Pranjal Awasthi, Moses Charikar, Ravishankar Krishnaswamy, Ali Kemal Sinop,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03302", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03302", "title": "\nUsing Distance Estimation and Deep Learning to Simplify Calibration in  Food Calorie Measurement", "abstract": "High calorie intake in the human body on the one hand, has proved harmful in numerous occasions leading to several diseases and on the other hand, a standard amount of calorie intake has been deemed essential by dieticians to maintain the right balance of calorie content in human body. As such, researchers have proposed a variety of automatic tools and systems to assist users measure their calorie in-take. In this paper, we consider the category of those tools that use image processing to recognize the food, and we propose a method for fully automatic and user-friendly calibration of the dimension of the food portion sizes, which is needed in order to measure food portion weight and its ensuing amount of calories. Experimental results show that our method, which uses deep learning, mobile cloud computing, distance estimation and size calibration inside a mobile device, leads to an accuracy improvement to 95% on average compared to previous work", "subjects": "Computers and Society (cs.CY)", "authors": "Pallavi Kuhad, Abdulsalam Yassine, Shervin Shirmohammadi,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03288", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03288", "title": "\nA Compressed-Gap Data-Aware Measure for Indexable Dictionaries", "abstract": "We consider the problem of building a compressed fully-indexable dictionary over a set of items out of a universe . We use gap-encoding combined with entropy compression in order to reduce the space of our structures. Let be the zero-order empirical entropy of the gap stream. We observe that if the gaps are highly compressible, and prove that bits. This upper bound is smaller than the worst-case size of the Elias -encoded gap stream. Our aim is, therefore, to obtain a data structure having as leading term in its space complexity. We propose a fully-indexable dictionary that supports rank and select queries in time and requires bits of space. If and (e.g. regularly spaced items), ours is the first solution answering all queries in time while requiring only bits of space.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Nicola Prezza,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03276", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03276", "title": "\nEnhancing the Delay Performance of Dynamic Backpressure Algorithms", "abstract": "For general multi-hop queueing networks, delay optimal network control has unfortunately been an outstanding problem. The dynamic backpressure (BP) algorithm elegantly achieves throughput optimality, but does not yield good delay performance in general. In this paper, we obtain an asymptotically delay optimal control policy, which resembles the BP algorithm in basing resource allocation and routing on a backpressure calculation, but differs from the BP algorithm in the form of the backpressure calculation employed. The difference suggests a possible reason for the unsatisfactory delay performance of the BP algorithm, i.e., the myopic nature of the BP control. Motivated by this new connection, we introduce a new class of enhanced backpressure-based algorithms which incorporate a general queue-dependent bias function into the backpressure term of the traditional BP algorithm to improve delay performance. These enhanced algorithms exploit queue state information beyond one hop. We prove the throughput optimality and characterize the utility-delay tradeoff of the enhanced algorithms. We further focus on two specific distributed algorithms within this class, which have demonstrably improved delay performance as well as acceptable implementation complexity.", "subjects": "Information Theory (cs.IT)", "authors": "Ying Cui, Edmund M. Yeh, Ran Liu,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.03273", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03273", "title": "\nImage denoising based on improved data-driven sparse representation", "abstract": "Sparse representation of images under certain transform domain has been playing a fundamental role in image restoration tasks. One such representative method is the widely used wavelet tight frame systems. Instead of adopting fixed filters for constructing a tight frame to sparsely model any input image, a data-driven tight frame was proposed for the sparse representation of images, and shown to be very efficient for image denoising very recently. However, in this method the number of framelet filters used for constructing a tight frame is the same as the length of filters. In fact, through further investigation it is found that part of these filters are unnecessary and even harmful to the recovery effect due to the influence of noise. Therefore, an improved data-driven sparse representation systems constructed with much less number of filters are proposed. Numerical results on denoising experiments demonstrate that the proposed algorithm overall outperforms the original data-driven tight frame construction scheme on both the recovery quality and computational time.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Dai-Qiang Chen,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03258", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03258", "title": "\nStructural characterizations of the navigational expressiveness of  relation algebras on a tree", "abstract": "Given a document D in the form of an unordered node-labeled tree, we study the expressiveness on D of various basic fragments of XPath, the core navigational language on XML documents. Working from the perspective of these languages as fragments of Tarski's relation algebra, we give characterizations, in terms of the structure of D, for when a binary relation on its nodes is definable by an expression in these algebras. Since each pair of nodes in such a relation represents a unique path in D, our results therefore capture the sets of paths in D definable in each of the fragments. We refer to this perspective on language semantics as the \"global view.\" In contrast with this global view, there is also a \"local view\" where one is interested in the nodes to which one can navigate starting from a particular node in the document. In this view, we characterize when a set of nodes in D can be defined as the result of applying an expression to a given node of D. All these definability results, both in the global and the local view, are obtained by using a robust two-step methodology, which consists of first characterizing when two nodes cannot be distinguished by an expression in the respective fragments of XPath, and then bootstrapping these characterizations to the desired results.", "subjects": "Databases (cs.DB)", "authors": "George H. L. Fletcher, Marc Gyssens, Jan Paredaens, Dirk Van Gucht, Yuqing Wu,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03248", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03248", "title": "\nOff-Policy Reward Shaping with Ensembles", "abstract": "Potential-based reward shaping (PBRS) is an effective and popular technique to speed up reinforcement learning by leveraging domain knowledge. While PBRS is proven to always preserve optimal policies, its effect on learning speed is determined by the quality of its potential function, which, in turn, depends on both the underlying heuristic and the scale. Knowing which heuristic will prove effective requires testing the options beforehand, and determining the appropriate scale requires tuning, both of which introduce additional sample complexity. We formulate a PBRS framework that reduces learning speed, but does not incur extra sample complexity. For this, we propose to simultaneously learn an ensemble of policies, shaped w.r.t. many heuristics and on a range of scales. The target policy is then obtained by voting. The ensemble needs to be able to efficiently and reliably learn off-policy: requirements fulfilled by the recent Horde architecture, which we take as our basis. We demonstrate empirically that (1) our ensemble policy outperforms both the base policy, and its single-heuristic components, and (2) an ensemble over a general range of scales performs at least as well as one with optimally tuned components.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Anna Harutyunyan, Tim Brys, Peter Vrancx, Ann Nowe,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03245", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03245", "title": "\nFEEBO: An Empirical Evaluation Framework for Malware Behavior  Obfuscation", "abstract": "Program obfuscation is increasingly popular among malware creators. Objectively comparing different malware detection approaches with respect to their resilience against obfuscation is challenging. To the best of our knowledge, there is no common empirical framework for evaluating the resilience of malware detection approaches w.r.t. behavior obfuscation. We propose and implement such a framework that obfuscates the observable behavior of malware binaries. To assess the framework's utility, we use it to obfuscate known malware binaries and then investigate the impact on detection effectiveness of different -gram based detection approaches. We find that the obfuscation transformations employed by our framework significantly affect the precision of such detection approaches. Several -gram-based approaches can hence be concluded not to be resilient against this simple kind of obfuscation.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Sebastian Banescu, Tobias W\u00fcchner, Marius Guggenmos, Mart\u00edn Ochoa, Alexander Pretschner,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.03241", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03241", "title": "\nDAG-width and circumference of digraphs", "abstract": "We prove that every digraph of circumference has DAG-width at most and this is best possible. As a consequence of our result we deduce that the -linkage problem is polynomially solvable for every fixed in the class of digraphs with bounded circumference. This answers a question posed in cite. We also prove that the weak -linkage problem (where we ask for arc-disjoint paths) is polynomially solvable for every fixed in the class of digraphs with circumference 2 as well as for digraphs with a bounded number of disjoint cycles each of length at least 3. The case of bounded circumference digraphs is open. Finally we prove that the minimum spanning strong subdigraph problem is NP-hard on digraphs of DAG-width at most 5.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "J\u00f8rgen Bang-Jensen, Tilde My Larsen,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03240", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03240", "title": "\nConditional Random Fields as Recurrent Neural Networks", "abstract": "Pixel-level labelling tasks, such as semantic segmentation and depth estimation from single RGB image, play a central role in image understanding. Recent approaches have attempted to harness the capabilities of deep learning techniques for image recognition to tackle pixel-level labelling tasks. To solve this problem, we introduce a new form of convolutional neural network, called CRF-RNN, which expresses a Conditional Random Field (CRF) as a Recurrent Neural Network (RNN). Our short network can be plugged in as a part of a deep Convolutional Neural Network (CNN) to obtain an end-to-end system that has desirable properties of both CNNs and CRFs. Importantly, our system fully integrates CRF modelling with CNNs, making it possible to train the whole system end-to-end with the usual back-propagation algorithm. We apply this framework to the problem of semantic image segmentation, obtaining competitive results with the state-of-the-art without the need of introducing any post-processing method for object delineation.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Shuai Zheng, Sadeep Jayasumana, Bernardino Romera-Paredes, Vibhav Vineet, Zhizhong Su, Dalong Du, Chang Huang, Philip Torr,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03234", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03234", "title": "\nA Scalable, Linear-Time Dynamic Cutoff Algorithm for Molecular  Simulations of Interfacial Systems", "abstract": "This master thesis introduces the idea of dynamic cutoffs in molecular dynamics simulations, based on the distance between particles and the interface, and presents a solution for detecting interfaces in real-time. Our dynamic cutoff method (DCM) exhibits a linear-time complexity as well as nearly ideal weak and strong scaling. The DCM is tailored for massively parallel architectures and for large interfacial systems with millions of particles. We implemented the DCM as part of the LAMMPS open-source molecular dynamics package and demonstrate the nearly ideal weak- and strong-scaling behavior of this method on an IBM BlueGene/Q supercomputer. Our results for a liquid/vapor system consisting of Lennard-Jones particles show that the accuracy of DCM is comparable to that of the traditional particle-particle particle- mesh (PPPM) algorithm. The performance comparison indicates that DCM is preferable for large systems due to the limited scaling of FFTs within the PPPM algorithm. Moreover, the DCM requires the interface to be identified every other MD timestep. As a consequence, this thesis also presents an interface detection method which is (1) applicable in real time; (2) parallelizable; and (3) scales linearly with respect to the number of particles.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Paul Springer,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03216", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03216", "title": "\nSimulation in the Call-by-Need Lambda-Calculus with Letrec, Case,  Constructors, and Seq", "abstract": "This paper shows equivalence of several versions of applicative similarity and contextual approximation, and hence also of applicative bisimilarity and contextual equivalence, in LR, the deterministic call-by-need lambda calculus with letrec extended by data constructors, case-expressions and Haskell's seq-operator. LR models an untyped version of the core language of Haskell. The use of bisimilarities simplifies equivalence proofs in calculi and opens a way for more convenient correctness proofs for program transformations. The proof is by a fully abstract and surjective transfer into a call-by-name calculus, which is an extension of Abramsky's lazy lambda calculus. In the latter calculus equivalence of our similarities and contextual approximation can be shown by Howe's method. Similarity is transferred back to LR on the basis of an inductively defined similarity. The translation from the call-by-need letrec calculus into the extended call-by-name lambda calculus is the composition of two translations. The first translation replaces the call-by-need strategy by a call-by-name strategy and its correctness is shown by exploiting infinite trees which emerge by unfolding the letrec expressions. The second translation encodes letrec-expressions by using multi-fixpoint combinators and its correctness is shown syntactically by comparing reductions of both calculi. A further result of this paper is an isomorphism between the mentioned calculi, which is also an identity on letrec-free expressions.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Manfred Schmidt-Schau\u00df, David Sabel, Elena Machkasova,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.03215", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03215", "title": "\nA Hybrid Approach for Improved Content-based Image Retrieval using  Segmentation", "abstract": "The objective of Content-Based Image Retrieval (CBIR) methods is essentially to extract, from large (image) databases, a specified number of images similar in visual and semantic content to a so-called query image. To bridge the semantic gap that exists between the representation of an image by low-level features (namely, colour, shape, texture) and its high-level semantic content as perceived by humans, CBIR systems typically make use of the relevance feedback (RF) mechanism. RF iteratively incorporates user-given inputs regarding the relevance of retrieved images, to improve retrieval efficiency. One approach is to vary the weights of the features dynamically via feature reweighting. In this work, an attempt has been made to improve retrieval accuracy by enhancing a CBIR system based on color features alone, through implicit incorporation of shape information obtained through prior segmentation of the images. Novel schemes for feature reweighting as well as for initialization of the relevant set for improved relevance feedback, have also been proposed for boosting performance of RF- based CBIR. At the same time, new measures for evaluation of retrieval accuracy have been suggested, to overcome the limitations of existing measures in the RF context. Results of extensive experiments have been presented to illustrate the effectiveness of the proposed approaches.", "subjects": "Information Retrieval (cs.IR)", "authors": "Smarajit Bose, Amita Pal, Jhimli Mallick, Sunil Kumar, Pratyaydipta Rudra,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03212", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03212", "title": "\nMathematical Modeling of Insurance Mechanisms for E-commerce Systems", "abstract": "Electronic commerce (a.k.a. E-commerce) systems such as eBay and Taobao of Alibaba are becoming increasingly popular. Having an effective reputation system is critical to this type of internet service because it can assist buyers to evaluate the trustworthiness of sellers, and it can also improve the revenue for reputable sellers and E-commerce operators. We formulate a stochastic model to analyze an eBay-like reputation system and propose four measures to quantify its effectiveness: (1) new seller ramp up time, (2) new seller drop out probability, (3) long term profit gains for sellers, and (4) average per seller transaction gains for the E-commerce operator. Through our analysis, we identify key factors which influence these four measures. We propose a new insurance mechanism which consists of an insurance protocol and a transaction mechanism to improve the above four measures. We show that our insurance mechanism can reduce the ramp up time by around 87.2%, and guarantee new sellers ramp up before the deadline with a high probability (close to 1.0). It also increases the long term profit gains and average per seller transaction gains by at least 95.3%.", "subjects": "Multiagent Systems (cs.MA)", "authors": "Hong Xie, John C.S. Lui,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.03204", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03204", "title": "\nA Proof of the Strong Converse Theorem for Gaussian Multiple Access  Channels", "abstract": "We prove that -user Gaussian multiple access channels (MACs) admit the strong converse. This means that every sequence of codes with asymptotic average error probabilities smaller than one has rate tuples that lie in the pentagonal region prescribed by Cover and Wyner. Our proof consists of four key ingredients: First, similar to Dueck's proof of the strong converse for the discrete memoryless MAC, we perform an expurgation step to convert the code defined in terms of the average probability of error to one defined in terms of the maximum error without too much loss in rate. Second, similar to Ahlswede's proof of the strong converse for the discrete memoryless MAC, we use a wringing technique to approximate the code distribution (induced by the code defined in terms of the maximum error) with a product distribution over users. Third, we use a scalar quantizer of increasing precision with the blocklength to discretize the input space so that Ahlswede's techniques can be applied to the resultant sequence of discrete problems. Finally, we upper bound achievable sum rates in terms of the fundamental limits of a binary hypothesis test and we use the preceding techniques to simplify the bound. Our proof carries over to the two sender-receiver (2-user) pair Gaussian interference channel in the strong interference regime.", "subjects": "Information Theory (cs.IT)", "authors": "Silas L. Fong, Vincent Y. F. Tan,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.03203", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03203", "title": "\nThe NUbots Team Description Paper 2015", "abstract": "The NUbots are an interdisciplinary RoboCup team from The University of Newcastle, Australia. The team has a history of strong contributions in the areas of machine learning and computer vision. The NUbots have participated in RoboCup leagues since 2002, placing first several times in the past. In 2014 the NUbots also partnered with the University of Newcastle Mechatronics Laboratory to participate in the RobotX Marine Robotics Challenge, which resulted in several new ideas and improvements to the NUbots vision system for RoboCup. This paper summarizes the history of the NUbots team, describes the roles and research of the team members, gives an overview of the NUbots' robots, their software system, and several associated research projects.", "subjects": "Robotics (cs.RO)", "authors": "Josiah Walker, Trent Houliston, Brendan Annable, Alex Biddulph, Jake Fountain, Mitchell Metcalfe, Anita Sugo, Monica Olejniczak, Stephan K. Chalup, Robert A.R. King, Alexandre Mendes, Peter Turner,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03191", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03191", "title": "\nCharacterization of Curved Creases and Rulings: Design and Analysis of  Lens Tessellations", "abstract": "We describe a general family of curved-crease folding tessellations consisting of a repeating \"lens\" motif formed by two convex curved arcs. The third author invented the first such design in 1992, when he made both a sketch of the crease pattern and a vinyl model (pictured below). Curve fitting suggests that this initial design used circular arcs. We show that in fact the curve can be chosen to be any smooth convex curve without inflection point. We identify the ruling configuration through qualitative properties that a curved folding satisfies, and prove that the folded form exists with no additional creases, through the use of differential geometry.", "subjects": "Computational Geometry (cs.CG)", "authors": "Erik D. Demaine, Martin L. Demaine, David A. Huffman, Duks Koschitz, Tomohiro Tachi,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03190", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03190", "title": "\nMAP: Microblogging Assisted Profiling of TV Shows", "abstract": "Online microblogging services that have been increasingly used by people to share and exchange information, have emerged as a promising way to profiling multimedia contents, in a sense to provide users a socialized abstraction and understanding of these contents. In this paper, we propose a microblogging profiling framework, to provide a social demonstration of TV shows. Challenges for this study lie in two folds: First, TV shows are generally offline, i.e., most of them are not originally from the Internet, and we need to create a connection between these TV shows with online microblogging services; Second, contents in a microblogging service are extremely noisy for video profiling, and we need to strategically retrieve the most related information for the TV show profiling.To address these challenges, we propose a MAP, a microblogging-assisted profiling framework, with contributions as follows: i) We propose a joint user and content retrieval scheme, which uses information about both actors and topics of a TV show to retrieve related microblogs; ii) We propose a social-aware profiling strategy, which profiles a video according to not only its content, but also the social relationship of its microblogging users and its propagation in the social network; iii) We present some interesting analysis, based on our framework to profile real-world TV shows.", "subjects": "Information Retrieval (cs.IR)", "authors": "Xiahong Lin, Zhi Wang, Lifeng Sun,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03182", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03182", "title": "\nPowerSpy: Location Tracking using Mobile Device Power Analysis", "abstract": "Modern mobile platforms like Android enable applications to read aggregate power usage on the phone. This information is considered harmless and reading it requires no user permission or notification. We show that by simply reading the phone's aggregate power consumption over a period of a few minutes an application can learn information about the user's location. Aggregate phone power consumption data is extremely noisy due to the multitude of components and applications that simultaneously consume power. Nevertheless, by using machine learning algorithms we are able to successfully infer the phone's location. We discuss several ways in which this privacy leak can be remedied.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Yan Michalevsky, Gabi Nakibly, Aaron Schulman, Dan Boneh,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.03181", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03181", "title": "\nMultiple Loop Self-Triggered Model Predictive Control for Network  Scheduling and Control", "abstract": "We present an algorithm for controlling and scheduling multiple linear time-invariant processes on a shared bandwidth limited communication network using adaptive sampling intervals. The controller is centralized and computes at every sampling instant not only the new control command for a process, but also decides the time interval to wait until taking the next sample. The approach relies on model predictive control ideas, where the cost function penalizes the state and control effort as well as the time interval until the next sample is taken. The latter is introduced in order to generate an adaptive sampling scheme for the overall system such that the sampling time increases as the norm of the system state goes to zero. The paper presents a method for synthesizing such a predictive controller and gives explicit sufficient conditions for when it is stabilizing. Further explicit conditions are given which guarantee conflict free transmissions on the network. It is shown that the optimization problem may be solved off-line and that the controller can be implemented as a lookup table of state feedback gains. Simulation studies which compare the proposed algorithm to periodic sampling illustrate potential performance gains.", "subjects": "Systems and Control (cs.SY)", "authors": "Erik Henriksson, Daniel E. Quevedo, Edwin G.W. Peters, Henrik Sandberg, Karl Henrik Johansson,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03167", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03167", "title": "\nBatch Normalization: Accelerating Deep Network Training by Reducing  Internal Covariate Shift", "abstract": "Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9% top-5 validation error (and 4.8% test error), exceeding the accuracy of human raters.", "subjects": "Learning (cs.LG)", "authors": "Sergey Ioffe, Christian Szegedy,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.03163", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03163", "title": "\nGaussian Process Models for HRTF based Sound-Source Localization and  Active-Learning", "abstract": "From a machine learning perspective, the human ability localize sounds can be modeled as a non-parametric and non-linear regression problem between binaural spectral features of sound received at the ears (input) and their sound-source directions (output). The input features can be summarized in terms of the individual's head-related transfer functions (HRTFs) which measure the spectral response between the listener's eardrum and an external point in D. Based on these viewpoints, two related problems are considered: how can one achieve an optimal sampling of measurements for training sound-source localization (SSL) models, and how can SSL models be used to infer the subject's HRTFs in listening tests. First, we develop a class of binaural SSL models based on Gaussian process regression and solve a emph problem that finds a subset of input-output samples that best generalize to all SSL directions. Second, we use an emph approach that updates an online SSL model for inferring the subject's SSL errors via headphones and a graphical user interface. Experiments show that only a small fraction of HRTFs are required for localization accuracy and that the learned HRTFs are localized closer to their intended directions than non-individualized HRTFs.", "subjects": "Sound (cs.SD)", "authors": "Yuancheng Luo, Dmitry N. Zotkin, Ramani Duraiswami,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03162", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03162", "title": "\nSparse Head-Related Impulse Response for Efficient Direct Convolution", "abstract": "Head-related impulse responses (HRIRs) are subject-dependent and direction-dependent filters used in spatial audio synthesis. They describe the scattering response of the head, torso, and pinnae of the subject. We propose a structural factorization of the HRIRs into a product of non-negative and Toeplitz matrices; the factorization is based on a novel extension of a non-negative matrix factorization algorithm. As a result, the HRIR becomes expressible as a convolution between a direction-independent emph filter and a direction-dependent emph filter. Further, the reflection filter can be made emph with minimal HRIR distortion. The described factorization is shown to be applicable to the arbitrary source signal case and allows one to employ time-domain convolution at a computational cost lower than using convolution in the frequency domain.", "subjects": "Sound (cs.SD)", "authors": "Yuancheng Luo, Dmitry N. Zotkin, Ramani Duraiswami,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03158", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03158", "title": "\nA Fast Distributed Solver for Symmetric Diagonally Dominant Linear  Equations", "abstract": "In this paper, we propose a fast distributed solver for linear equations given by symmetric diagonally dominant M-Matrices. Our approach is based on a distributed implementation of the parallel solver of Spielman and Peng by considering a specific approximated inverse chain which can be computed efficiently in a distributed fashion. Representing the system of equations by a graph , the proposed distributed algorithm is capable of attaining -close solutions (for arbitrary ) in time proportional to (number of nodes in ), (upper bound on the size of the R-Hop neighborhood), and (maximum and minimum weight of edges in ).", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Rasul Tutunov, Haitham Bou Ammar, Ali Jadbabaie,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03157", "category": "Computer Science ", "pdflink": "http://arxiv.org/html/1502.03157", "title": "\nProceedings 13th International Workshop on Foundations of Coordination  Languages and Self-Adaptive Systems", "abstract": "This volume contains the proceedings of FOCLASA 2014, the 13th International Workshop on the Foundations of Coordination Languages and Self-Adaptive Systems. FOCLASA 2014 was held in Rome, Italy, on September 9, 2014 as a satellite event of CONCUR 2014, the 25th International Conference on Concurrency Theory. Modern software systems are distributed, concurrent, mobile, and often involve composition of heterogeneous components and stand-alone services. Service coordination and self-adaptation constitute the core characteristics of distributed and service-oriented systems. Coordination languages and formal approaches to modelling and reasoning about self-adaptive behaviour help to simplify the development of complex distributed service-based systems, enable functional correctness proofs and improve reusability and maintainability of such systems. The goal of the FOCLASA workshop is to put together researchers and practitioners of the aforementioned fields, to share and identify common problems, and to devise general solutions in the context of coordination languages and self-adaptive systems.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Javier C\u00e1mara, Jos\u00e9 Proen\u00e7a,", "date": "2015-2-11"}, 
{"urllink": "http://arxiv.org/abs/1502.03147", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03147", "title": "\nTopological Interference Management with just Retransmission: What are  the \"Best\" Topologies?", "abstract": "We study the problem of interference management in fast fading wireless networks, in which the transmitters are only aware of network topology. We consider a class of retransmission-based schemes, where transmitters in the network are only allowed to resend their symbols in order to assist with the neutralization of interference at the receivers. We introduce a necessary and sufficient condition on the network topology, under which half symmetric degrees-of-freedom (DoF) is achievable through the considered retransmission-based schemes. This corresponds to the \"best\" topologies since half symmetric DoF is the highest possible value for the symmetric DoF in the presence of interference. We show that when the condition is satisfied, there always exists a set of carefully chosen transmitters in the network, such that by retransmission of their symbols at an appropriate time slot, we can neutralize all the interfering signals at the receivers. Quite surprisingly, we also show that for any given network topology, if we cannot achieve half symmetric DoF by retransmission-based schemes, then there does not exist any linear scheme that can do so. We also consider a practical network scenario that models cell edge users in a heterogeneous network, and show that the characterized condition on the network topology occurs frequently. Furthermore, we numerically evaluate the achievable rates of the DoF-optimal retransmission-based scheme in such network scenario, and show that its throughput gain is not restricted to the asymptotic DoF analysis.", "subjects": "Information Theory (cs.IT)", "authors": "Navid Naderializadeh, Aly El Gamal, A. Salman Avestimehr,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.03143", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03143", "title": "\nBenchmarking in Manipulation Research: The YCB Object and Model Set and  Benchmarking Protocols", "abstract": "In this paper we present the Yale-CMU-Berkeley (YCB) Object and Model set, intended to be used to facilitate benchmarking in robotic manipulation, prosthetic design and rehabilitation research. The objects in the set are designed to cover a wide range of aspects of the manipulation problem; it includes objects of daily life with different shapes, sizes, textures, weight and rigidity, as well as some widely used manipulation tests. The associated database provides high-resolution RGBD scans, physical properties, and geometric models of the objects for easy incorporation into manipulation and planning software platforms. In addition to describing the objects and models in the set along with how they were chosen and derived, we provide a framework and a number of example task protocols, laying out how the set can be used to quantitatively evaluate a range of manipulation approaches including planning, learning, mechanical design, control, and many others. A comprehensive literature survey on existing benchmarks and object datasets is also presented and their scope and limitations are discussed. The set will be freely distributed to research groups worldwide at a series of tutorials at robotics conferences, and will be otherwise available at a reasonable purchase cost. It is our hope that the ready availability of this set along with the ground laid in terms of protocol templates will enable the community of manipulation researchers to more easily compare approaches as well as continually evolve benchmarking tests as the field matures.", "subjects": "Robotics (cs.RO)", "authors": "Berk Calli, Aaron Walsman, Arjun Singh, Siddhartha Srinivasa, Pieter Abbeel, Aaron M. Dollar,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.03124", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03124", "title": "\nOrder-Optimal Rate of Caching and Coded Multicasting with Random Demands", "abstract": "We consider the canonical formed by a source node, hosting a library of information messages (files), connected via a noiseless common link to destination nodes (users), each with a cache of size M files. Users request files at random and independently, according to a given a-priori demand distribution . A coding scheme for this network consists of a caching placement (i.e., a mapping of the library files into the user caches) and delivery scheme (i.e., a mapping for the library files and user demands into a common multicast codeword) such that, after the codeword transmission, all users can retrieve their requested file. The rate of the scheme is defined as the codeword length normalized with respect to the length of one file, where expectation is taken over the random user demands. For the same shared link network, in the case of deterministic demands, the optimal min-max rate has been characterized within a uniform bound, independent of the network parameters. In particular, fractional caching (i.e., storing file segments) and using linear network coding has been shown to provide a min-max rate reduction proportional to 1/M with respect to standard schemes such as unicasting or \"naive\" uncoded multicasting. The case of random demands was previously considered by applying the same order-optimal min-max scheme separately within groups of files requested with similar probability. However, no order-optimal guarantee was provided for random demands under the average rate performance criterion. In this paper, we consider the random demand setting and provide general achievability and converse results. In particular, we consider a family of schemes that combine random fractional caching according to a probability distribution that depends on the demand distribution , with a linear coded delivery scheme based on ...", "subjects": "Information Theory (cs.IT)", "authors": "Mingyue Ji, Antonia M. Tulino, Jaime Llorca, Giuseppe Caire,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.03121", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03121", "title": "\nFast Fusion of Multi-Band Images Based on Solving a Sylvester Equation", "abstract": "This paper proposes a fast multi-band image fusion algorithm, which combines a high-spatial low-spectral resolution image and a low-spatial high-spectral resolution image. The well admitted forward model is explored to form the likelihoods of the observations. Maximizing the likelihoods leads to solving a Sylvester equation. By exploiting the properties of the circulant and downsampling matrices associated with the fusion problem, a closed-form solution for the corresponding Sylvester equation is obtained explicitly, getting rid of any iterative update step. Coupled with the alternating direction method of multipliers and the block coordinate descent method, the proposed algorithm can be easily generalized to incorporate prior information for the fusion problem, allowing a Bayesian estimator. Simulation results show that the proposed algorithm achieves the same performance as existing algorithms with the advantage of significantly decreasing the computational complexity of these algorithms.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Qi Wei, Nicolas Dobigeon, Jean-Yves Tourneret,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.03086", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03086", "title": "\nGender Gap Through Time and Space: A Journey Through Wikipedia  Biographies and the \"WIGI\" Index", "abstract": "In this study we investigate how quantification of Wikipedia biographies can shed light on worldwide longitudinal gender inequality trends. We present an academic index allowing comparative study of gender inequality through space and time, the Wikipedia Gender Index (WIGI), based on metadata available through the Wikidata database. Our research confirms that gender inequality is a phenomenon with a long history, but whose patterns can be analyzed and quantified on a larger scale than previously thought possible. Through the use of Inglehart- Welzel cultural clusters, we show that gender inequality can be analyzed with regards to world's cultures. In the dimension studied (coverage of females and other genders in reference works) we show a steadily improving trend, through one with aspects that deserve careful follow up analysis (such as the surprisingly high ranking of the Confucian and South Asian clusters). Keywords: data mining, Wikidata, Wikipedia, gender gap, demographics", "subjects": "Computers and Society (cs.CY)", "authors": "Maximilian Klein, Piotr Konieczny,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.03068", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03068", "title": "\nMulti-Sensor Scheduling for State Estimation with Event-Based,  Stochastic Triggers", "abstract": "In networked systems, state estimation is hampered by communication limits. Past approaches, which consider scheduling sensors through deterministic event-triggers, reduce communication and maintain estimation quality. However, these approaches destroy the Gaussian property of the state, making it computationally intractable to obtain an exact minimum mean squared error estimate. We propose a stochastic event-triggered sensor schedule for state estimation which preserves the Gaussianity of the system, extending previous results from the single-sensor to the multi-sensor case.", "subjects": "Information Theory (cs.IT)", "authors": "Sean Weerakkody, Yilin Mo, Bruno Sinopoli, Duo Han, Ling Shi,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.03038", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03038", "title": "\nLaneQuest: An Accurate and Energy-Efficient Lane Detection System", "abstract": "Current outdoor localization techniques fail to provide the required accuracy for estimating the car's lane. In this paper, we present LaneQuest: a system that leverages the ubiquitous and low-energy inertial sensors available in commodity smart-phones to provide an accurate estimate of the car's current lane. LaneQuest leverages hints from the phone sensors about the surrounding environment to detect the car's lane. For example, a car making a right turn most probably will be in the right-most lane, a car passing by a pothole will be in a specific lane, and the car's angular velocity when driving through a curve reflects its lane. Our investigation shows that there are amble opportunities in the environment, i.e. lane \"anchors\", that provide cues about the car's lane. To handle the ambiguous location, sensors noise, and fuzzy lane anchors; LaneQuest employs a novel probabilistic lane estimation algorithm. Furthermore, it uses an unsupervised crowd-sourcing approach to learn the position and lane-span distribution of the different lane-level anchors. Our evaluation results from implementation on different android devices and 260Km driving traces by 13 drivers in different cities shows that LaneQuest can detect the different lane-level anchors with an average precision and recall of more than 90%. This leads to an accurate detection of the exact car's lane position 80% of the time, increasing to 89% of the time to within one lane. This comes with a low-energy footprint, allowing LaneQuest to be implemented on the energy-constrained mobile devices.", "subjects": "Computers and Society (cs.CY)", "authors": "Heba Aly, Anas Basalamah, Moustafa Youssef,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.03032", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03032", "title": "\nImplementing Randomized Matrix Algorithms in Parallel and Distributed  Environments", "abstract": "In this era of large-scale data, distributed systems built on top of clusters of commodity hardware provide cheap and reliable storage and scalable processing of massive data. Here, we review recent work on developing and implementing randomized matrix algorithms in large-scale parallel and distributed environments. Randomized algorithms for matrix problems have received a great deal of attention in recent years, thus far typically either in theory or in machine learning applications or with implementations on a single machine. Our main focus is on the underlying theory and practical implementation of random projection and random sampling algorithms for very large very overdetermined (i.e., overconstrained) and regression problems. Randomization can be used in one of two related ways: either to construct sub-sampled problems that can be solved, exactly or approximately, with traditional numerical methods; or to construct preconditioned versions of the original full problem that are easier to solve with traditional iterative algorithms. Theoretical results demonstrate that in near input-sparsity time and with only a few passes through the data one can obtain very strong relative-error approximate solutions, with high probability. Empirical results highlight the importance of various trade-offs (e.g., between the time to construct an embedding and the conditioning quality of the embedding, between the relative importance of computation versus communication, etc.) and demonstrate that and regression problems can be solved to low, medium, or high precision in existing distributed systems on up to terabyte-sized data.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Jiyan Yang, Xiangrui Meng, Michael W. Mahoney,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.03005", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.03005", "title": "\nTowards Realizability Checking of Contracts using Theories", "abstract": "Virtual integration techniques focus on building architectural models of systems that can be analyzed early in the design cycle to try to lower cost, reduce risk, and improve quality of complex embedded systems. Given appropriate architectural descriptions and compositional reasoning rules, these techniques can be used to prove important safety properties about the architecture prior to system construction. Such proofs build from \"leaf-level\" assume/guarantee component contracts through architectural layers towards top-level safety properties. The proofs are built upon the premise that each leaf-level component contract is realizable; i.e., it is possible to construct a component such that for any input allowed by the contract assumptions, there is some output value that the component can produce that satisfies the contract guarantees. Without engineering support it is all too easy to write leaf-level components that can't be realized. Realizability checking for propositional contracts has been well-studied for many years, both for component synthesis and checking correctness of temporal logic requirements. However, checking realizability for contracts involving infinite theories is still an open problem. In this paper, we describe a new approach for checking realizability of contracts involving theories and demonstrate its usefulness on several examples.", "subjects": "Software Engineering (cs.SE)", "authors": "Andrew Gacek, Andreas Katis, Michael W. Whalen, John Backes, Darren Cofer,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02991", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02991", "title": "\nSimple Executions of Snapshot Implementations", "abstract": "The well known snapshot primitive in concurrent programming allows for n-asynchronous processes to write values to an array of single-writer registers and, for each process, to take a snapshot of these registers. In this paper we provide a formulation of the well known linearizability condition for snapshot algorithms in terms of the existence of certain mathematical functions. In addition, we identify a simplifying property of snapshot implementations we call \"schedule-based algorithms\". This property is natural to assume in the sense that as far as we know, every published snapshot algorithm is schedule-based. Based on this, we prove that when dealing with schedule-based algorithms, it suffices to consider only a small class of very simple executions to prove or disprove correctness in terms of linearizability. We believe that the ideas developed in this paper may help to design automatic verification of snapshot algorithms. Since verifying linearizability was recently proved to be EXPSPACE-complete, focusing on unique objects (snapshot in our case) can potentially lead to designing restricted, but feasible verification methods.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Gal Amram, Lior Mizrahi, Gera Weiss,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02973", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02973", "title": "\nA Distributed Tracking Algorithm for Reconstruction of Graph Signals", "abstract": "The rapid development of signal processing on graphs provides a new perspective for processing large-scale data associated with irregular domains. In many practical applications, it is necessary to handle massive data sets through complex networks, in which most nodes have limited computing power. Designing efficient distributed algorithms is critical for this task. This paper focuses on the distributed reconstruction of a time-varying bandlimited graph signal based on observations sampled at a subset of selected nodes. A distributed least square reconstruction (DLSR) algorithm is proposed to recover the unknown signal iteratively, by allowing neighboring nodes to communicate with one another and make fast updates. DLSR uses a decay scheme to annihilate the out-of-band energy occurring in the reconstruction process, which is inevitably caused by the transmission delay in distributed systems. Proof of convergence and error bounds for DLSR are provided in this paper, suggesting that the algorithm is able to track time-varying graph signals and perfectly reconstruct time-invariant signals. The DLSR algorithm is numerically experimented with synthetic data and real-world sensor network data, which verifies its ability in tracking slowly time-varying graph signals.", "subjects": "Information Theory (cs.IT)", "authors": "Xiaohan Wang, Mengdi Wang, Yuantao Gu,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02971", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02971", "title": "\nInformation complexity is computable", "abstract": "The information complexity of a function is the minimum amount of information Alice and Bob need to exchange to compute the function . In this paper we provide an algorithm for approximating the information complexity of an arbitrary function to within any additive error , thus resolving an open question as to whether information complexity is computable. In the process, we give the first explicit upper bound on the rate of convergence of the information complexity of when restricted to -bit protocols to the (unrestricted) information complexity of .", "subjects": "Information Theory (cs.IT)", "authors": "Mark Braverman, Jon Schneider,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02969", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02969", "title": "\nA DCT And SVD based Watermarking Technique To Identify Tag", "abstract": "With the rapid development of the multimedia,the secure of the multimedia is get more concerned. as far as we know , Digital watermarking is an effective way to protect copyright. The watermark must be generally hidden does not affect the quality of the original image. In this paper,a novel way based on discrete cosine transform(DCT) and singular value decomposition(SVD) .In the proposed way,we decomposition the image into 8*8 blocks, next we use the DCT to get the transformed block,then we choose the diagonal to embed the information, after we do this, we recover the image and then we decomposition the image to 8*8 blocks,we use the SVD way to get the diagonal matrix and embed the information in the matrix. next we extract the information use both inverse of DCT and SVD, as we all know,after we embed the information seconded time , the information we first information we embed must be changed, we choose a measure way called Peak Signal to Noise Ratio(PSNR) to estimate the similarity of the two image, and set a threshold to ensure whether the information is same or not.", "subjects": "Multimedia (cs.MM)", "authors": "Ke Ji, Jianbiao Lin, Hui Li, Ao Wang, Tianjing Tang,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02965", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02965", "title": "\nVideo Primal Sketch: A Unified Middle-Level Representation for Video", "abstract": "This paper presents a middle-level video representation named Video Primal Sketch (VPS), which integrates two regimes of models: i) sparse coding model using static or moving primitives to explicitly represent moving corners, lines, feature points, etc., ii) FRAME /MRF model reproducing feature statistics extracted from input video to implicitly represent textured motion, such as water and fire. The feature statistics include histograms of spatio-temporal filters and velocity distributions. This paper makes three contributions to the literature: i) Learning a dictionary of video primitives using parametric generative models; ii) Proposing the Spatio-Temporal FRAME (ST-FRAME) and Motion-Appearance FRAME (MA-FRAME) models for modeling and synthesizing textured motion; and iii) Developing a parsimonious hybrid model for generic video representation. Given an input video, VPS selects the proper models automatically for different motion patterns and is compatible with high-level action representations. In the experiments, we synthesize a number of textured motion; reconstruct real videos using the VPS; report a series of human perception experiments to verify the quality of reconstructed videos; demonstrate how the VPS changes over the scale transition in videos; and present the close connection between VPS and high-level action models.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Zhi Han, Zongben Xu, Song-Chun Zhu,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02961", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02961", "title": "\nAvatar-independent scripting for real-time gesture animation", "abstract": "When animation of a humanoid figure is to be generated at run-time, instead of by replaying pre-composed motion clips, some method is required of specifying the avatar's movements in a form from which the required motion data can be automatically generated. This form must be of a more abstract nature than raw motion data: ideally, it should be independent of the particular avatar's proportions, and both writable by hand and suitable for automatic generation from higher-level descriptions of the required actions. We describe here the development and implementation of such a scripting language for the particular area of sign languages of the deaf, called SiGML (Signing Gesture Markup Language), based on the existing HamNoSys notation for sign languages. We conclude by suggesting how this work may be extended to more general animation for interactive virtual reality applications.", "subjects": "Graphics (cs.GR)", "authors": "Richard Kennaway,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02960", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02960", "title": "\nAdaptive Fault Tolerant Execution of Multi-Robot Missions using Behavior  Trees", "abstract": "Multi-robot teams offer possibilities of improved performance and fault tolerance, compared to single robot solutions. In this paper, we show how to realize those possibilities when starting from a single robot system controlled by a Behavior Tree (BT). By extending the single robot BT to a multi-robot BT, we are able to combine the fault tolerant properties of the BT, in terms of built-in fallbacks, with the fault tolerance inherent in multi-robot approaches, in terms of a faulty robot being replaced by another one. Furthermore, we improve performance by identifying and taking advantage of the opportunities of parallel task execution, that are present in the single robot BT. Analyzing the proposed approach, we present results regarding how mission performance is affected by minor faults (a robot losing one capability) as well as major faults (a robot losing all its capabilities). Finally, a detailed example is provided to illustrate the approach.", "subjects": "Robotics (cs.RO)", "authors": "Michele Colledanchise, Alejandro Marzinotto, Dimos V. Dimarogonas, Petter \u00d6gren,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02943", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02943", "title": "\nA Control-Theoretic Approach to Adaptive Video Streaming in Dense  Wireless Networks", "abstract": "Recently, the way people consume video content has been undergoing a dramatic change. Plain TV sets, that have been the center of home entertainment for a long time, are losing grounds to Hybrid TV's, PC's, game consoles, and, more recently, mobile devices such as tablets and smartphones. The new predominant paradigm is: watch what I want, when I want, and where I want. The challenges of this shift are manifold. On the one hand, broadcast technologies such as DVB-T/C/S need to be extended or replaced by mechanisms supporting asynchronous viewing, such as IPTV and video streaming over best-effort networks, while remaining scalable to millions of users. On the other hand, the dramatic increase of wireless data traffic begins to stretch the capabilities of the existing wireless infrastructure to its limits. Finally, there is a challenge to video streaming technologies to cope with a high heterogeneity of end-user devices and dynamically changing network conditions, in particular in wireless and mobile networks. In the present work, our goal is to design an efficient system that supports a high number of unicast streaming sessions in a dense wireless access network. We address this goal by jointly considering the two problems of wireless transmission scheduling and video quality adaptation, using techniques inspired by the robustness and simplicity of Proportional-Integral-Derivative (PID) controllers. We show that the control-theoretic approach allows to efficiently utilize available wireless resources, providing high Quality of Experience (QoE) to a large number of users.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Konstantin Miller, Dilip Bethanabhotla, Giuseppe Caire, Adam Wolisz,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02942", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02942", "title": "\nSkipping Refinement", "abstract": "We introduce skipping refinement, a new notion of correctness for reasoning about optimized reactive systems. Reasoning about reactive systems using refinement involves defining an abstract, high-level specification system and a concrete, low-level implementation system. One then shows that every behavior allowed by the implementation is also allowed by the specification. Due to the difference in abstraction levels, it is often the case that the implementation requires many steps to match one step of the specification, hence, it is quite useful for refinement to directly account for stuttering. Some optimized implementations, however, can actually take multiple specification steps at once. For example, a memory controller can buffer the commands to the memory and at a later time simultaneously update multiple memory locations, thereby skipping several observable states of the abstract specification, which only updates one memory location at a time. We introduce skipping simulation refinement and provide a sound and complete characterization consisting of \"local\" proof rules that are amenable to mechanization and automated verification. We present case studies that highlight the applicability of skipping refinement: a JVM-inspired stack machine, a simple memory controller and a scalar to vector compiler transformation. Our experimental results demonstrate that current model-checking and automated theorem proving tools have difficultly automatically analyzing these systems using existing notions of correctness, but they can analyze the systems if we use skipping refinement.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Mitesh Jain, Panagiotis Manolios,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02940", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02940", "title": "\nThe Hilbert Space of Probability Mass Functions and Applications on  Probabilistic Inference", "abstract": "The Hilbert space of probability mass functions (pmf) is introduced in this thesis. A factorization method for multivariate pmfs is proposed by using the tools provided by the Hilbert space of pmfs. The resulting factorization is special for two reasons. First, it reveals the algebraic relations between the involved random variables. Second, it determines the conditional independence relations between the random variables. Due to the first property of the resulting factorization, it can be shown that channel decoders can be employed in the solution of probabilistic inference problems other than decoding. This approach might lead to new probabilistic inference algorithms and new hardware options for the implementation of these algorithms. An example of new inference algorithms inspired by the idea of using channel decoder for other inference tasks is a multiple-input multiple-output (MIMO) detection algorithm which has a complexity of the square-root of the optimum MIMO detection algorithm.", "subjects": "Information Theory (cs.IT)", "authors": "Muhammet Fatih Bayramoglu,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02927", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02927", "title": "\nOn the shape of the general error locator polynomial for cyclic codes", "abstract": "A general result on the explicit form of the general error locator polynomial for all cyclic codes is given, along with several specific results for classes of cyclic codes. From these, a theoretically justification of the sparsity of the general error locator polynomial is obtained for all cyclic codes with and , except for three cases.", "subjects": "Information Theory (cs.IT)", "authors": "Fabrizio Caruso, Emmanuela Orsini, Massimiliano Sala, Claudia Tinnirello,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02925", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02925", "title": "\nOn the Finite Length Scaling of Ternary Polar Codes", "abstract": "The polarization process of polar codes over a ternary alphabet is studied. Recently it has been shown that the scaling of the blocklength of polar codes with prime alphabet size scales polynomially with respect to the inverse of the gap between code rate and channel capacity. However, except for the binary case, the degree of the polynomial in the bound is extremely large. In this work, it is shown that a much lower degree polynomial can be computed numerically for the ternary case. Similar results are conjectured for the general case of prime alphabet size.", "subjects": "Information Theory (cs.IT)", "authors": "Dina Goldin, David Burshtein,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02921", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02921", "title": "\nOMP2MPI: Automatic MPI code generation from OpenMP programs", "abstract": "In this paper, we present OMP2MPI a tool that generates automatically MPI source code from OpenMP. With this transformation the original program can be adapted to be able to exploit a larger number of processors by surpassing the limits of the node level on large HPC clusters. The transformation can also be useful to adapt the source code to execute in distributed memory many-cores with message passing support. In addition, the resulting MPI code can be used as an starting point that still can be further optimized by software engineers. The transformation process is focused on detecting OpenMP parallel loops and distributing them in a master/worker pattern. A set of micro-benchmarks have been used to verify the correctness of the the transformation and to measure the resulting performance. Surprisingly not only the automatically generated code is correct by construction, but also it often performs faster even when executed with MPI.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Albert Saa-Garriga, David Castells-Rufas, Jordi Carrabina,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02910", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02910", "title": "\nCoalgebraic Tools for Bisimilarity and Decorated Trace Semantics", "abstract": "The modelling, specification and study of the semantics of concurrent reactive systems have been interesting research topics for many years now. The aim of this thesis is to exploit the strengths of the (co)algebraic framework in modelling reactive systems and reasoning on several types of associated semantics, in a uniform fashion. In particular, we are interested in handling notions of behavioural equivalence/preorder ranging from bisimilarity for systems that can be represented as non-deterministic coalgebras, to decorated trace semantics for labelled transition systems and probabilistic systems, and testing semantics for labelled transition systems with internal behaviour. Moreover, we aim at deriving a suite of corresponding verification algorithms suitable for implementation in automated tools.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Georgiana Caltais,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02905", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02905", "title": "\nReal Time Implementation of Spatial Filtering On FPGA", "abstract": "Field Programmable Gate Array (FPGA) technology has gained vital importance mainly because of its parallel processing hardware which makes it ideal for image and video processing. In this paper, a step by step approach to apply a linear spatial filter on real time video frame sent by Omnivision OV7670 camera using Zynq Evaluation and Development board based on Xilinx XC7Z020 has been discussed. Face detection application was chosen to explain above procedure. This procedure is applicable to most of the complex image processing algorithms which needs to be implemented using FPGA.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Chaitannya Supe,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02893", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02893", "title": "\nCoded Retransmission in Wireless Networks Via Abstract MDPs: Theory and  Algorithms", "abstract": "Consider a transmission scheme with a single transmitter and multiple receivers over a faulty broadcast channel. For each receiver, the transmitter has a unique infinite stream of packets, and its goal is to deliver them at the highest throughput possible. While such multiple-unicast models are unsolved in general, several network coding based schemes were suggested. In such schemes, the transmitter can either send an uncoded packet, or a coded packet which is a function of a few packets. Sent packets can be received by the designated receiver (with some probability) or heard and stored by other receivers. Two functional modes are considered; the first presumes that the storage time is unlimited, while in the second it is limited by a given Time To Live (TTL) parameter. We model the transmission process as an infinite-horizon Markov Decision Process (MDP). Since the large state space renders exact solutions computationally impractical, we introduce policy restricted and induced MDPs with significantly reduced state space, and prove that with proper reward function they have equal optimal value function (hence equal optimal throughput). We then derive a reinforcement learning algorithm, for the induced MDP, which approximates the optimal strategy and significantly improves over uncoded schemes. Next, we enhance the algorithm by means of analysis of the structural properties of the resulting reward functional. We demonstrate that our method scales well as the number of users grows. Moreover, this approach overcomes packet loss uncertainty.", "subjects": "Information Theory (cs.IT)", "authors": "Mark Shifrin, Asaf Cohen, Omer Gurewitz, Olga Weisman,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02874", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02874", "title": "\nInvariance of the spark, NSP order and RIP order under elementary  transformations of matrices", "abstract": "The theory of compressed sensing tells us that recovering all k-sparse signals requires a sensing matrix to satisfy that its spark is greater than 2k, or its order of the null space property (NSP) or the restricted isometry property (RIP) is 2k or above. If we perform elementary row or column operations on the sensing matrix, what are the changes of its spark, NSP order and RIP order? In this paper, we study this problem and discover that these three quantitative indexes of sensing matrices all possess invariance under all matrix elementary transformations except column-addition ones. Putting this result in form of matrix products, we get the types of matrices which multiply a sensing matrix and make the products still have the same properties of sparse recovery as the sensing matrix. According to these types of matrices, we made an interesting discovery that sensing matrices with deterministic constructions do not possess the property universality which belongs to sensing matrices with random constructions.", "subjects": "Information Theory (cs.IT)", "authors": "Jiawang Yi, Guanzheng Tan,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02868", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02868", "title": "\nMaximum Throughput Opportunistic Network Coding in Two-Way Relay  Networks", "abstract": "In this paper, we study Two-way relaying networks well-known for its throughput merits. In particular, we study the fundamental throughput delay trade-off in two-way relaying networks using opportunistic network coding. We characterize the optimal opportunistic network coding policy that maximizes the aggregate network throughput subject to an average packet delay constraint. Towards this objective, first, we consider a pair of nodes communicating through a common relay and develop a two dimensional Markov chain model capturing the buffers' length states at the two nodes. Second, we formulate an optimization problem for the delay constrained optimal throughput. Exploiting the structure of the problem, it can be cast as a linear programming problem. Third, we compare the optimal policy to two baseline schemes and show its merits with respect to throughput, average delay and power consumption. First, the optimal policy significantly outperforms the first baseline with respect to throughput, delay and power consumption. Moreover, it outperforms the second baseline with respect to the average delay and power consumption for asymmetrical traffic arrival rates.", "subjects": "Information Theory (cs.IT)", "authors": "Maha Zohdy, Tamer ElBatt, Mohamed Nafie,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02852", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02852", "title": "\nTransaction Level Analysis for a Clustered and Hardware-Enhanced Task  Manager on Homogeneous Many-Core Systems", "abstract": "The increasing parallelism of many-core systems demands for efficient strategies for the run-time system management. Due to the large number of cores the management overhead has a rising impact to the overall system performance. This work analyzes a clustered infrastructure of dedicated hardware nodes to manage a homogeneous many-core system. The hardware nodes implement a message passing protocol and perform the task mapping and synchronization at run-time. To make meaningful mapping decisions, the global management nodes employ a workload status communication mechanism. This paper discusses the design-space of the dedicated infrastructure by means of task mapping use-cases and a parallel benchmark including application-interference. We evaluate the architecture in terms of application speedup and analyze the mechanism for the status communication. A comparison versus centralized and fully-distributed configurations demonstrates the reduction of the computation and communication management overhead for our approach.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Daniel Gregorek, Robert Schmidt, Alberto Garcia-Ortiz,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02850", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02850", "title": "\nMassive M2M Access with Reliability Guarantees in LTE Systems", "abstract": "Machine-to-Machine (M2M) communications are one of the major drivers of the cellular network evolution towards 5G systems. One of the key challenges is on how to provide reliability guarantees to each accessing device in a situation in which there is a massive number of almost-simultaneous arrivals from a large set of M2M devices. The existing solutions take a reactive approach in dealing with massive arrivals, such as non-selective barring when a massive arrival event occurs, which implies that the devices cannot get individual reliability guarantees. In this paper we propose a proactive approach, based on a standard operation of the cellular access. The access procedure is divided into two phases, an estimation phase and a serving phase. In the estimation phase the number of arrivals is estimated and this information is used to tune the amount of resources allocated in the serving phase. Our results show that the proactive approach is instrumental in delivering high access reliability to the M2M devices.", "subjects": "Information Theory (cs.IT)", "authors": "German Corrales Madueno, Nuno K. Pratas, Cedomir Stefanovic, Petar Popovski,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02846", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02846", "title": "\nProbabilistic Line Searches for Stochastic Optimization", "abstract": "In deterministic optimization problems, line search routines are a standard tool ensuring stability and efficiency. In the stochastic setting, no direct equivalent has so far been formulated, because uncertain gradients do not allow for a strict sequence of decisions collapsing the search space. We construct a probabilistic version of the line search paradigm, by combining the structure of existing deterministic methods with notions from Bayesian optimization. Our algorithm retains a Gaussian process surrogate of the univariate optimization objective, and uses a probabilistic belief over the classic Wolfe conditions to monitor the descent. Care is taken to keep all steps at low computational cost, so that the resulting method stabilizes stochastic gradient descent at only minor computational overhead. The algorithm has no user-controlled parameters. Experiments show that it effectively removes the need to define a learning rate for stochastic gradient descent.", "subjects": "Learning (cs.LG)", "authors": "Maren Mahsereci, Philipp Hennig,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02844", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02844", "title": "\nAn overview on automatic design of robot controllers for complex tasks", "abstract": "In this paper we will explore different available methodologies to automatically design controllers for tasks that spans many level of abstraction, where the gap between primitive behaviours and the task definition is high. A good understanding of your evolutionary setup is needed to choose the correct strategy with which to tackle complex tasks thus we'll first review the most used types of each element composing an evolutionary setup (controllers, objective functions, ect.) then we'll move the focus on the bootstrapping problem and on the different strategies used to overcome it.", "subjects": "Robotics (cs.RO)", "authors": "Michele Matteini,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02840", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02840", "title": "\nAn Integrated Semantic Web Service Discovery and Composition Framework", "abstract": "In this paper we present a theoretical analysis of graph-based service composition in terms of its dependency with service discovery. Driven by this analysis we define a composition framework by means of integration with fine-grained I/O service discovery that enables the generation of a graph-based composition which contains the set of services that are semantically relevant for an input-output request. The proposed framework also includes an optimal composition search algorithm to extract the best composition from the graph minimising the length and the number of services, and different graph optimisations to improve the scalability of the system. A practical implementation used for the empirical analysis is also provided. This analysis proves the scalability and flexibility of our proposal and provides insights on how integrated composition systems can be designed in order to achieve good performance in real scenarios for the Web.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Pablo Rodriguez-Mier, Carlos Pedrinaci, Manuel Lama, Manuel Mucientes,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02839", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02839", "title": "\nLower bounds on the size of semi-quantum automata", "abstract": "In the literature, there exist several interesting hybrid models of finite automata which have both quantum and classical states. We call them semi-quantum automata. In this paper, we compare the descriptional power of these models with that of DFA. Specifically, we present a uniform method that gives a lower bound on the size of the three existing main models of semi-quantum automata, and this bound shows that semi-quantum automata can be at most exponentially more concise than DFA. Compared with a recent work (Bianchi, Mereghetti, Palano, Theoret. Comput. Sci., 551(2014), 102-115), our method shows the following two advantages: (i) our method is much more concise; and (ii) our method is universal, since it is applicable to the three existing main models of semi-quantum automata, instead of only a specific model.", "subjects": "Formal Languages and Automata Theory (cs.FL)", "authors": "Lvzhou Li, Daowen Qiu,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02834", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02834", "title": "\nCounterexample Explanation by Learning Small Strategies in Markov  Decision Processes", "abstract": "While for deterministic systems, a counterexample to a property can simply be an error trace, counterexamples in probabilistic systems are necessarily more complex. For instance, a set of erroneous traces with a sufficient cumulative probability mass can be used. Since these are too large objects to understand and manipulate, compact representations such as subchains have been considered. In the case of probabilistic systems with non-determinism, the situation is even more complex. While a subchain for a given strategy (or scheduler, resolving non-determinism) is a straightforward choice, we take a different approach. Instead, we focus on the strategy - which can be a counterexample to violation of or a witness of satisfaction of a property - itself, and extract the most important decisions it makes, and present its succinct representation. The key tools we employ to achieve this are (1) introducing a concept of importance of a state w.r.t. the strategy, and (2) learning using decision trees. There are three main consequent advantages of our approach. Firstly, it exploits the quantitative information on states, stressing the more important decisions. Secondly, it leads to a greater variability and degree of freedom in representing the strategies. Thirdly, the representation uses a self-explanatory data structure. In summary, our approach produces more succinct and more explainable strategies, as opposed to e.g. binary decision diagrams. Finally, our experimental results show that we can extract several rules describing the strategy even for very large systems that do not fit in memory, and based on the rules explain the erroneous behaviour.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Tom\u00e1\u0161 Br\u00e1zdil, Krishnendu Chatterjee, Martin Chmel\u00edk, Andreas Fellner, Jan K\u0159et\u00ednsk\u00fd,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02824", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02824", "title": "\nFuzzy finite element solution of uncertain neutron diffusion equation  for imprecisely defined homogeneous triangular bare reactor", "abstract": "Scattering of neutron collision inside a reactor depends upon geometry of the reactor, diffusion coefficient and absorption coefficient etc. In general these parameters are not crisp and hence we may get uncertain neutron diffusion equation. In this paper we have investigated the above problem for a bare triangular homogeneous reactor. Here the uncertain governing differential equation is modelled by a modified fuzzy finite element method using newly proposed interval arithmetic. Obtained eigenvalues by the proposed method are studied in detail. Further the eigenvalues are compared with the classical finite element method in special cases and various uncertain results have been discussed.", "subjects": "Computational Engineering, Finance, and Science (cs.CE)", "authors": "Sukanta Nayak, Snehashish Chakraverty,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02803", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02803", "title": "\nA TDOA technique with Super-Resolution based on the Volume  Cross-Correlation Function", "abstract": "TDOA (Time Difference of Arrival) is an important and widely used wireless localization technique. Among the enormous approaches of TDOA, high resolution TDOA algorithms have drawn much attention for its ability to resolve closely spaced signal delays in multipath environment. However, the state-of-art high resolution TDOA algorithms still have performance weakness on resolving time delays in a wireless channel with dense multipath effect, as well as difficulties of implementation for their high computation complexity. In this paper, we propose a novel TDOA algorithm with super resolution based on certain kind of multi-dimensional cross-correlation function: the volume cross-correlation function (VCC). The proposed TDOA algorithm has excellent time resolution performance in multipath environment, and it also has a much lower computational complexity. Our algorithm does not require priori knowledge about the waveform or power spectrum of transmitted signals, therefore has great potential of usage in various passive wireless localization systems. Numerical simulations is also provided to demonstrate the validity of our conclusion.", "subjects": "Information Theory (cs.IT)", "authors": "Hailong Shi, Hao Zhang, Xiqin Wang,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02800", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02800", "title": "\nFast arithmetic for faster integer multiplication", "abstract": "For almost 35 years, Sch \"onhage-Strassen's algorithm has been the fastest algorithm known for multiplying integers, with a time complexity O(n log n log log n) for multi-plying n-bit inputs. In 2007, F \"urer proved that there exists K textgreater 1 and an algorithm performing this operation in O(n log n K log * n). Recent work showed that this complexity estimate can be made more precise with K = 8, and conjecturally K = 4. We obtain here the same result K = 4 using simple modular arithmetic as a building block, and a careful complexity analysis. We rely on a conjecture about the existence of sufficiently many primes of a certain form.", "subjects": "Symbolic Computation (cs.SC)", "authors": "Svyatoslav Covanov, Emmanuel Thom\u00e9,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02799", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02799", "title": "\nOn Forgetting in Tractable Propositional Fragments", "abstract": "Distilling from a knowledge base only the part that is relevant to a subset of alphabet, which is recognized as forgetting, has attracted extensive interests in AI community. In standard propositional logic, a general algorithm of forgetting and its computation-oriented investigation in various fragments whose satisfiability are tractable are still lacking. The paper aims at filling the gap. After exploring some basic properties of forgetting in propositional logic, we present a resolution-based algorithm of forgetting for CNF fragment, and some complexity results about forgetting in Horn, renamable Horn, q-Horn, Krom, DNF and CNF fragments of propositional logic.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Yisong Wang,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02796", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02796", "title": "\nTransforming knowledge capture in healthcare: Opportunistic and  Context-aware affect Sensing on Smartphones", "abstract": "Recent advances in smartphone technology make it possible to gather affective information opportunistically during everyday activities including patient information. Better quality real time information is expected to assist in better decision making and better patient monitoring. This can lead to better outcomes and improved costs. Opportunistic affect sensing involves the capture of spontaneous affective behaviour, which contains rich latent information about a person's emotional and psychological states. As affect sensing has been performed in laboratory environments, information about scalability, accessibility and representativeness is limited. In this paper, attention is given to current advances of affective sensing on the smartphone platform. Emphasis is given to opportunistic sensing using audio and video modalities, as they offer the most powerful information yet the most difficult computational and privacy related challenges. As affective response is largely controlled by the ambient environment, this paper further discusses context aware affect sensing presenting the current landscape of context aware affective sensing on smartphone. The paper concludes by outlining the key barriers to successful implementation of opportunistic and context aware affect sensing on smartphones. The paper also offers potential solutions and suggests managerial and practical approaches for healthcare.", "subjects": "Human-Computer Interaction (cs.HC)", "authors": "Rajib Rana, Margee Hume, John Reilly, Raja Jurdak, Jeffrey Soar,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02793", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02793", "title": "\nThe Benefit of Sex in Noisy Evolutionary Search", "abstract": "The benefit of sexual recombination is one of the most fundamental questions both in population genetics and evolutionary computation. It is widely believed that recombination helps solving difficult optimization problems. We present the first result, which rigorously proves that it is beneficial to use sexual recombination in an uncertain environment with a noisy fitness function. For this, we model sexual recombination with a simple estimation of distribution algorithm called the Compact Genetic Algorithm (cGA), which we compare with the classical EA. For a simple noisy fitness function with additive Gaussian posterior noise , we prove that the mutation-only EA typically cannot handle noise in polynomial time for large enough while the cGA runs in polynomial time as long as the population size is not too small. This shows that in this uncertain environment sexual recombination is provably beneficial. We observe the same behavior in a small empirical study.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "Tobias Friedrich, Timo K\u00f6tzing, Martin Krejca, Andrew M. Sutton,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02791", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02791", "title": "\nLearning Transferable Features with Deep Adaptation Networks", "abstract": "Recent studies reveal that a deep neural network can learn transferable features which generalize well to novel tasks for domain adaptation. However, as deep features eventually transition from general to specific along the network, the feature transferability drops significantly in higher layers with increasing domain discrepancy. Hence, it is critical to formally reduce the domain bias and enhance the transferability in task-specific layers. In this paper, we propose a new Deep Adaptation Network (DAN) architecture, which generalizes deep convolutional neural network to the domain adaptation scenario. In DAN, hidden representations of all task-specific layers are embedded to a reproducing kernel Hilbert space where the mean embeddings of different domain distributions can be explicitly matched. The domain discrepancy is further reduced using an optimal multi-kernel selection method for mean embedding matching. DAN can learn invariant features with enhanced transferability, and can scale linearly by unbiased estimate of kernel embedding. Extensive empirical evidence demonstrates the proposed architecture significantly outperforms state-of-the-art results on standard domain adaptation benchmarks.", "subjects": "Learning (cs.LG)", "authors": "Mingsheng Long, Jianmin Wang,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02768", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02768", "title": "\nVirtual Network Embedding Algorithms Based on Best-Fit Subgraph  Detection", "abstract": "One of the main objectives of cloud computing providers is increasing the revenue of their cloud datacenters by accommodating virtual network requests as many as possible. However, arrival and departure of virtual network requests fragment physical network's resources and reduce the possibility of accepting more virtual network requests. To increase the number of virtual network requests accommodated by fragmented physical networks, we propose two virtual network embedding algorithms, which coarsen virtual networks using Heavy Edge Matching (HEM) technique and embed coarsened virtual networks on best-fit sub-substrate networks. The performance of the proposed algorithms are evaluated and compared with existing algorithms using extensive simulations, which show that the proposed algorithms increase the acceptance ratio and the revenue.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Ashraf A. Shahin,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02763", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02763", "title": "\nCascading Bandits", "abstract": "The cascade model is a well-established model of user interaction with content. In this work, we propose cascading bandits, a learning variant of the model where the objective is to learn most attractive items out of ground items. We cast the problem as a stochastic combinatorial bandit with a non-linear reward function and partially observed weights of items. Both of these are challenging in the context of combinatorial bandits. We propose two computationally-efficient algorithms for our problem, CascadeUCB1 and CascadeKL-UCB, and prove gap-dependent upper bounds on their regret. We also derive a lower bound for cascading bandits and show that it matches the upper bound of CascadeKL-UCB up to a logarithmic factor. Finally, we evaluate our algorithms on synthetic problems. Our experiments demonstrate that the algorithms perform well and robustly even when our modeling assumptions are violated.", "subjects": "Learning (cs.LG)", "authors": "Branislav Kveton, Csaba Szepesvari, Zheng Wen, Azin Ashkan,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02761", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02761", "title": "\nGenerative Moment Matching Networks", "abstract": "We consider the problem of learning deep generative models from data. We formulate a method that generates an independent sample via a single feedforward pass through a multilayer perceptron, as in the recently proposed generative adversarial networks (Goodfellow et al., 2014). Training a generative adversarial network, however, requires careful optimization of a difficult minimax program. Instead, we utilize a technique from statistical hypothesis testing known as maximum mean discrepancy (MMD), which leads to a simple objective that can be interpreted as matching all orders of statistics between a dataset and samples from the model, and can be trained by backpropagation. We further boost the performance of this approach by combining our generative network with an auto-encoder network, using MMD to learn to generate codes that can then be decoded to produce samples. We show that the combination of these techniques yields excellent generative models compared to baseline approaches as measured on MNIST and the Toronto Face Database.", "subjects": "Learning (cs.LG)", "authors": "Yujia Li, Kevin Swersky, Richard Zemel,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02741", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02741", "title": "\nA Generalized Prony Method for Filter Recovery in Evolutionary System  via Spatiotemporal Trade Off", "abstract": "We consider the problem of spatiotemporal sampling in an evolutionary process where an unknown linear operator driving an unknown initial state is to be recovered from a combined set of coarse spatial samples . In this paper, we will study the case of infinite dimensional spatially invariant evolutionary process, where the unknown initial signals are modeled as and is an unknown spatial convolution operator given by a filter so that . We show that contains enough information to recover the Fourier spectrum of a typical low pass filter , if the initial signal is from a dense subset of . The idea is based on a nonlinear, generalized Prony method similar to cite. We provide an algorithm for the case when both and are compactly supported around the center. Finally, we perform the accuracy analysis based on the spectral properties of the operator and the initial state , and verify them by several numerical experiments.", "subjects": "Information Theory (cs.IT)", "authors": "Sui Tang,", "date": "2015-2-10"}, 
{"urllink": "http://arxiv.org/abs/1502.02734", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02734", "title": "\nWeakly- and Semi-Supervised Learning of a DCNN for Semantic Image  Segmentation", "abstract": "Deep convolutional neural networks (DCNNs) trained on a large number of images with strong pixel-level annotations have recently significantly pushed the state-of-art in semantic image segmentation. We study the more challenging problem of learning DCNNs for semantic image segmentation from either (1) weakly annotated training data such as bounding boxes or image-level labels or (2) a combination of few strongly labeled and many weakly labeled images, sourced from one or multiple datasets. We develop methods for semantic image segmentation model training under these weakly supervised and semi-supervised settings. Extensive experimental evaluation shows that the proposed techniques can learn models delivering state-of-art results on the challenging PASCAL VOC 2012 image segmentation benchmark, while requiring significantly less annotation effort.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "George Papandreou, Liang-Chieh Chen, Kevin Murphy, Alan L. Yuille,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02733", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02733", "title": "\nBandwidth Efficient and Rate-Compatible Low-Density Parity-Check Coded  Modulation", "abstract": "A new coded modulation scheme is proposed. At the transmitter, the concatenation of a distribution matcher and a systematic binary encoder performs probabilistic signal shaping and channel coding. At the receiver, the output of a bitwise demapper is fed to a binary decoder. No iterative demapping is performed. Rate compatibility is achieved by adjusting the input distribution and the transmission power. The scheme is presented for bipolar amplitude shift keying (ASK) constellations with equidistant signal points and it is directly applicable to two-dimensional quadrature amplitude modulation (QAM). The scheme is implemented by using the DVB-S2 low-density parity-check (LDPC) codes. At a frame error rate of 1e-3, the new scheme operates within less than 1 dB of the AWGN capacity 0.5log(1+SNR) at any spectral efficiency between 1 and 5 bits/s/Hz by using only 5 modes, i.e., 4-ASK with code rate 2/3, 8-ASK with 3/4, 16-ASK and 32-ASK with 5/6 and 64-ASK with 9/10.", "subjects": "Information Theory (cs.IT)", "authors": "Georg B\u00f6cherer, Patrick Schulte, Fabian Steiner,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02727", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02727", "title": "\nNew Multiple Insertion-Deletion Correcting Codes for Non-Binary  Alphabets", "abstract": "We generalize Helberg's number-theoretic construction of multiple insertion-deletion correcting binary codes to non-binary alphabets. We prove that these codes are able to correct multiple deletion errors and also correct half as many substitution errors. We also present values for the size of the largest code for certain codeword lengths that were found through exhaustive computer search.", "subjects": "Information Theory (cs.IT)", "authors": "Tuan A. Le, Hieu D. Nguyen,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02725", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02725", "title": "\nWhy Transactional Memory Should Not Be Obstruction-Free", "abstract": "Transactional memory (TM) is an inherently optimistic abstraction: it allows concurrent processes to execute sequences of shared-data accesses (transactions) speculatively, with an option of aborting them in the future. Early TM designs avoided using locks and relied on non-blocking synchronization to ensure obstruction-freedom: a transaction that encounters no step contention is not allowed to abort. However, it was later observed that obstruction-free TMs perform poorly and, as a result, state-of-the-art TM implementations are nowadays blocking, allowing aborts because of data conflicts rather than step contention. In this paper, we explain this shift in the TM practice theoretically, via complexity bounds. We prove a few important lower bounds on obstruction-free TMs. Then we present a lock-based TM implementation that beats all of these lower bounds. In sum, our results exhibit a considerable complexity gap between non-blocking and blocking TM implementations.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Petr Kuznetsov, Srivatsan Ravi,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02711", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02711", "title": "\nAlgebraic structures of MRD Codes", "abstract": "Based on results in finite geometry we prove the existence of MRD codes in (F_q)_(n,n) with minimum distance which are essentially different from Gabidulin codes. The construction results from algebraic structures which are closely related to those of finite fields. Furthermore we show that an analogue of MacWilliams' extension theorem does not exist for linear rank metric codes.", "subjects": "Information Theory (cs.IT)", "authors": "Javier de la Cruz, Michael Kiermaier, Alfred Wassermann, Wolfgang Willems,", "date": "2015-1-16"}, 
{"urllink": "http://arxiv.org/abs/1502.02710", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02710", "title": "\nMultilabel Prediction via Calibration", "abstract": "We propose an efficient technique for multilabel classification based on calibration, a term we use to mean learning a link function that maps independent predictions to joint predictions. Though a naive implementation of our proposal would require training individual classifiers for each label, we show that for natural datasets and linear classifiers we can sidestep this by leveraging techniques from randomized linear algebra. Moreover, our algorithm applies equally well to multiclass classification. The end result is an algorithm that scales to very large multilabel and multiclass problems, and offers state of the art accuracy on many datasets.", "subjects": "Learning (cs.LG)", "authors": "Nikos Karampatziakis, Paul Mineiro,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02704", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02704", "title": "\nLearning Reductions that Really Work", "abstract": "We provide a summary of the mathematical and computational techniques that have enabled learning reductions to effectively address a wide class of problems, and show that this approach to solving machine learning problems can be broadly useful.", "subjects": "Learning (cs.LG)", "authors": "Alina Beygelzimer, Hal Daum\u00e9 III, John Langford, Paul Mineiro,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02655", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02655", "title": "\nAn investigation into language complexity of World-of-Warcraft  game-external texts", "abstract": "We present a language complexity analysis of World of Warcraft (WoW) community texts, which we compare to texts from a general corpus of web English. Results from several complexity types are presented, including lexical diversity, density, readability and syntactic complexity. The language of WoW texts is found to be comparable to the general corpus on some complexity measures, yet more specialized on other measures. Our findings can be used by educators willing to include game-related activities into school curricula.", "subjects": "Computation and Language (cs.CL)", "authors": "Simon \u0160uster,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02651", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02651", "title": "\nOptimal and Adaptive Algorithms for Online Boosting", "abstract": "We study online boosting, the task of converting any weak online learner into a strong online learner. Based on a novel and natural definition of weak online learnability, we develop two online boosting algorithms. The first algorithm is an online version of boost-by-majority. By proving a matching lower bound, we show that this algorithm is essentially optimal in terms of the number of weak learners and the sample complexity needed to achieve a specified accuracy. This optimal algorithm is not adaptive however. Using tools from online loss minimization, we derive an adaptive online boosting algorithm that is also parameter-free, but not optimal. Both algorithms work with base learners that can handle example importance weights directly, as well as by rejection sampling examples with probability defined by the booster. Results are complemented with an extensive experimental study.", "subjects": "Learning (cs.LG)", "authors": "Alina Beygelzimer, Satyen Kale, Haipeng Luo,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02647", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02647", "title": "\nSecure Degrees of Freedom Region of the Two-User MISO Broadcast Channel  with Alternating CSIT", "abstract": "The two user multiple-input single-output (MISO) broadcast channel with confidential messages (BCCM) is studied in which the nature of channel state information at the transmitter (CSIT) from each user can be of the form , where , and the forms , and correspond to perfect and instantaneous, completely delayed, and no CSIT, respectively. Thus, the overall CSIT can alternate between possible states corresponding to all possible values of , with each state occurring for fraction of the total duration. The main contribution of this paper is to establish the secure degrees of freedom (s.d.o.f.) region of the MISO BCCM with alternating CSIT with the symmetry assumption, where . The main technical contributions include developing a) novel achievable schemes for MISO BCCM with alternating CSIT with security constraints which also highlight the synergistic benefits of inter-state coding for secrecy, b) new converse proofs via local statistical equivalence and channel enhancement; and c) showing the interplay between various aspects of channel knowledge and their impact on s.d.o.f.", "subjects": "Information Theory (cs.IT)", "authors": "Pritam Mukherjee, Ravi Tandon, Sennur Ulukus,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02643", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02643", "title": "\nRandom Coordinate Descent Methods for Minimizing Decomposable Submodular  Functions", "abstract": "Submodular function minimization is a fundamental optimization problem that arises in several applications in machine learning and computer vision. The problem is known to be solvable in polynomial time, but general purpose algorithms have high running times and are unsuitable for large-scale problems. Recent work have used convex optimization techniques to obtain very practical algorithms for minimizing functions that are sums of ``simple\" functions. In this paper, we use random coordinate descent methods to obtain algorithms with faster linear convergence rates and cheaper iteration costs. Compared to alternating projection methods, our algorithms do not rely on full-dimensional vector operations and they converge in significantly fewer iterations.", "subjects": "Learning (cs.LG)", "authors": "Alina Ene, Huy L. Nguyen,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02642", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02642", "title": "\nS2WC2: a User Centric Web Usage Mining Framework", "abstract": "Unlike many works in Web Usage Mining, which took as object of study logs recorded by Web servers; we develop in this paper a different approach, qualified as usercentric, judged more accurate and effective. To do so, we develop first a client side tool, in order to collect the user navigation traces. Based on Browser Helper Object, this tool has several advantages as the lightness, the simple exploitation, and almost absence of changes in user environment. Secondly, we elaborate a pre-processing application to prepare the raw client logs. This application includes numerous algorithms and modules, which are originals and appropriates to the log defined format, in order to clean it, reconstruct user sessions and to do some final formatting tasks. The last stage in our work is devoted to the task of client web session clustering using Kohonen Self organizing Maps, with the use of a free knowledge discovery tool.", "subjects": "Databases (cs.DB)", "authors": "Slimane Oulad-Naoui, Mahieddine Djoudi,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02609", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02609", "title": "\nEfficient model-based reinforcement learning for approximate online  optimal", "abstract": "In this paper the infinite horizon optimal regulation problem is solved online for a deterministic control-affine nonlinear dynamical system using the state following (StaF) kernel method to approximate the value function. Unlike traditional methods that aim to approximate a function over a large compact set, the StaF kernel method aims to approximate a function in a small neighborhood of a state that travels within a compact set. Simulation results demonstrate that stability and approximate optimality of the control system can be achieved with significantly fewer basis functions than may be required for global approximation methods.", "subjects": "Systems and Control (cs.SY)", "authors": "Rushikesh Kamalapurkar, Joel A. Rosenfeld, Warren E. Dixon,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02606", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02606", "title": "\nThe Power of Randomization: Distributed Submodular Maximization on  Massive Datasets", "abstract": "A wide variety of problems in machine learning, including exemplar clustering, document summarization, and sensor placement, can be cast as constrained submodular maximization problems. Unfortunately, the resulting submodular optimization problems are often too large to be solved on a single machine. We develop a simple distributed algorithm that is embarrassingly parallel and it achieves provable, constant factor, worst-case approximation guarantees. In our experiments, we demonstrate its efficiency in large problems with different kinds of constraints with objective values always close to what is achievable in the centralized setting.", "subjects": "Learning (cs.LG)", "authors": "Rafael Barbosa, Alina Ene, Huy L. Nguyen, Justin Ward,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02605", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02605", "title": "\nVerifying the Safety of a Flight-Critical System", "abstract": "This paper describes our work on demonstrating verification technologies on a flight-critical system of realistic functionality, size, and complexity. Our work targeted a commercial aircraft control system named Transport Class Model (TCM), and involved several stages: formalizing and disambiguating requirements in collaboration with do- main experts; processing models for their use by formal verification tools; applying compositional techniques at the architectural and component level to scale verification. Performed in the context of a major NASA milestone, this study of formal verification in practice is one of the most challenging that our group has performed, and it took several person months to complete it. This paper describes the methodology that we followed and the lessons that we learned.", "subjects": "Software Engineering (cs.SE)", "authors": "Guillaume Brat, David Bushnell, Misty Davies, Dimitra Giannakopoulou, Falk Howar, Temesghen Kahsai,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02599", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02599", "title": "\nAdaptive Random SubSpace Learning (RSSL) Algorithm for Prediction", "abstract": "We present a novel adaptive random subspace learning algorithm (RSSL) for prediction purpose. This new framework is flexible where it can be adapted with any learning technique. In this paper, we tested the algorithm for regression and classification problems. In addition, we provide a variety of weighting schemes to increase the robustness of the developed algorithm. These different wighting flavors were evaluated on simulated as well as on real-world data sets considering the cases where the ratio between features (attributes) and instances (samples) is large and vice versa. The framework of the new algorithm consists of many stages: first, calculate the weights of all features on the data set using the correlation coefficient and F-statistic statistical measurements. Second, randomly draw n samples with replacement from the data set. Third, perform regular bootstrap sampling (bagging). Fourth, draw without replacement the indices of the chosen variables. The decision was taken based on the heuristic subspacing scheme. Fifth, call base learners and build the model. Sixth, use the model for prediction purpose on test set of the data. The results show the advancement of the adaptive RSSL algorithm in most of the cases compared with the synonym (conventional) machine learning algorithms.", "subjects": "Learning (cs.LG)", "authors": "Mohamed Elshrif, Ernest Fokoue,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02590", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02590", "title": "\nAnalysis of classifiers' robustness to adversarial perturbations", "abstract": "The robustness of a classifier to arbitrary small perturbations of the datapoints is a highly desirable property when the classifier is deployed in real and possibly hostile environments. In this paper, we propose a theoretical framework for analyzing the robustness of classifiers to adversarial perturbations, and study two common families of classifiers. In both cases, we show the existence of a fundamental limit on the robustness to adversarial perturbations, which is expressed in terms of a distinguishability measure between the classes. Our result implies that in tasks involving small distinguishability, no classifier will be robust to adversarial perturbations, even if a good accuracy is achieved. Furthermore, we show that robustness to random noise does not imply, in general, robustness to adversarial perturbations. In fact, in high dimensional problems, linear classifiers are shown to be much more robust to random noise than to adversarial perturbations. Our analysis is complemented by experimental results on controlled and real-world data. Up to our knowledge, this is the first theoretical work that addresses the surprising phenomenon of adversarial instability recently observed for deep networks (Szegedy et al., 2014). Our work shows that this phenomenon is not limited to deep networks, and gives a theoretical explanation of the causes underlying the adversarial instability of classifiers.", "subjects": "Learning (cs.LG)", "authors": "Alhussein Fawzi, Omar Fawzi, Pascal Frossard,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02589", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02589", "title": "\nSub-optimality of the Han--Kobayashi Achievable Region for Interference  Channels", "abstract": "Han-Kobayashi achievable region is the best known inner bound for a general discrete memoryless interference channel. We show that the capacity region can be strictly larger than the Han-Kobayashi region for some channel realizations, and hence the strict sub-optimality of Han-Kobayashi achievable region.", "subjects": "Information Theory (cs.IT)", "authors": "Chandra Nair, Lingxiao Xia, Mehdi Yazdanpanah,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02585", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02585", "title": "\nCore Higher-Order Session Processes: Tractable Equivalences and Relative  Expressiveness", "abstract": "This work proposes tractable bisimulations for the higher-order pi-calculus with session primitives (HOpi) and offers a complete study of the expressivity of its most significant subcalculi. First we develop three typed bisimulations, which are shown to coincide with contextual equivalence. These characterisations demonstrate that observing as inputs only a specific finite set of higher-order values (which inhabit session types) suffices to reason about HOp processes. Next, we identify HO, a minimal, second-order subcalculus of HOpi in which higher-order applications/abstractions, name-passing, and recursion are absent. We show that HO can encode HOpi extended with higher-order applications and abstractions and that a first-order session pi-calculus can encode HOpi. Both encodings are fully abstract. We also prove that the session pi-calculus with passing of shared names cannot be encoded into HOpi without shared names. We show that HOpi, HO, and pi are equally expressive; the expressivity of HO enables effective reasoning about typed equivalences for higher-order processes.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Dimitrios Kouzapas, Jorge A. P\u00e9rez, Nobuko Yoshida,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02557", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02557", "title": "\nList Colouring Big Graphs On-Line", "abstract": "In this paper, we investigate the problem of graph list colouring in the on-line setting. We provide several results on paintability of graphs in the model introduced by Schauz [13] and Zhu [20]. We prove that the on-line version of Ohba's conjecture is true in the class of planar graphs. We also consider several alternate on-line list colouring models.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Martin Derka, Alejandro L\u00f3pez-Ortiz, Daniela Maftuleac,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02551", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02551", "title": "\nDeep Learning with Limited Numerical Precision", "abstract": "Training of large-scale deep neural networks is often constrained by the available computational resources. We study the effect of limited precision data representation and computation on neural network training. Within the context of low-precision fixed-point computations, we observe the rounding scheme to play a crucial role in determining the network's behavior during training. Our results show that deep networks can be trained using only 16-bit wide fixed-point number representation when using stochastic rounding, and incur little to no degradation in the classification accuracy. We also demonstrate an energy-efficient hardware accelerator that implements low-precision fixed-point arithmetic with stochastic rounding.", "subjects": "Learning (cs.LG)", "authors": "Suyog Gupta, Ankur Agrawal, Kailash Gopalakrishnan, Pritish Narayanan,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02539", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02539", "title": "\nSampling with arbitrary precision", "abstract": "We study the problem of the generation of a continuous random variable when a source of independent fair coins is available. We first motivate the choice of a natural criterion for measuring accuracy, the Wasserstein metric, and then show a universal lower bound for the expected number of required fair coins as a function of the accuracy. In the case of an absolutely continuous random variable with finite differential entropy, several algorithms are presented that match the lower bound up to a constant, which can be eliminated by generating random variables in batches.", "subjects": "Information Theory (cs.IT)", "authors": "Luc Devroye, Claude Gravel,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02538", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02538", "title": "\nConsensus using Asynchronous Failure Detectors", "abstract": "The FLP result shows that crash-tolerant consensus is impossible to solve in asynchronous systems, and several solutions have been proposed for crash-tolerant consensus under alternative (stronger) models. One popular approach is to augment the asynchronous system with appropriate failure detectors, which provide (potentially unreliable) information about process crashes in the system, to circumvent the FLP impossibility. In this paper, we demonstrate the exact mechanism by which (sufficiently powerful) asynchronous failure detectors enable solving crash-tolerant consensus. Our approach, which borrows arguments from the FLP impossibility proof and the famous result from CHT, which shows that is a weakest failure detector to solve consensus, also yields a natural proof to as a weakest asynchronous failure detector to solve consensus. The use of I/O automata theory in our approach enables us to model execution in a more detailed fashion than CHT and also addresses the latent assumptions and assertions in the original result in CHT.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Nancy Lynch, Srikanth Sastry,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02535", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02535", "title": "\nOn First-Order Model-Based Reasoning", "abstract": "Reasoning semantically in first-order logic is notoriously a challenge. This paper surveys a selection of or methods that aim at meeting aspects of this challenge. For first-order logic we touch upon methods, methods, methods, and we give a preview of a new method called SGGS, for reasoning. For first-order theories we highlight and methods, concluding with the recent .", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Maria Paola Bonacina, Ulrich Furbach, Viorica Sofronie-Stokkermans,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02519", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02519", "title": "\nKickstarting Choreographic Programming", "abstract": "We present an overview of some recent efforts aimed at the development of Choreographic Programming, a programming paradigm for the production of concurrent software that is guaranteed to be correct by construction from global descriptions of communication behaviour.", "subjects": "Programming Languages (cs.PL)", "authors": "Fabrizio Montesi,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02511", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02511", "title": "\nMeasurement Scale Effect on Prediction of Soil Water Retention Curve and  Saturated Hydraulic Conductivity", "abstract": "Soil water retention curve (SWRC) and saturated hydraulic conductivity (SHC) are key hydraulic properties for unsaturated zone hydrology and groundwater. In particular, SWRC provides useful information on entry pore-size distribution, and SHC is required for flow and transport modeling in the hydrologic cycle. Not only the SWRC and SHC measurements are time-consuming, but also scale dependent. This means as soil column volume increases, variability of the SWRC and SHC decreases. Although prediction of the SWRC and SHC from available parameters, such as textural data, organic matter, and bulk density have been under investigation for decades, up to now no research has focused on the effect of measurement scale on the soil hydraulic properties pedotransfer functions development. In the literature, several data mining approaches have been applied, such as multiple linear regression, artificial neural networks, group method of data handling. However, in this study we develop pedotransfer functions using a novel approach called contrast pattern aided regression (CPXR) and compare it with the multiple linear regression method. For this purpose, two databases including 210 and 213 soil samples are collected to develop and evaluate pedotransfer functions for the SWRC and SHC, respectively, from the UNSODA database. The 10-fold cross-validation method is applied to evaluate the accuracy and reliability of the proposed regression-based models. Our results show that including measurement scale parameters, such as sample internal diameter and length could substantially improve the accuracy of the SWRC and SHC pedotransfer functions developed using the CPXR method, while this is not the case when MLR is used. Moreover, the CPXR method yields remarkably more accurate soil water retention curve and saturated hydraulic conductivity predictions than the MLR approach.", "subjects": "Computational Engineering, Finance, and Science (cs.CE)", "authors": "Behzad Ghanbarian, Vahid Taslimitehrani, Guozhu Dong, Yakov A. Pachepsky,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02506", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02506", "title": "\nPredicting Alzheimer's disease: a neuroimaging study with 3D  convolutional neural networks", "abstract": "Pattern recognition methods using neuroimaging data for the diagnosis of Alzheimer's disease have been the subject of extensive research in recent years. In this paper, we use deep learning methods, and in particular sparse autoencoders and 3D convolutional neural networks, to build an algorithm that can predict the disease status of a patient, based on an MRI scan of the brain. We report on experiments using the ADNI data set involving 2,265 historical scans. We demonstrate that 3D convolutional neural networks outperform several other classifiers reported in the literature and produce state-of-art results.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Adrien Payan, Giovanni Montana,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02493", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02493", "title": "\nImplicit Contextual Integrity in Online Social Networks", "abstract": "Many real incidents demonstrate that users of Online Social Networks need mechanisms that help them manage their interactions by increasing the awareness of the different contexts that coexist in Online Social Networks and preventing them from exchanging inappropriate information in those contexts or disseminating sensitive information from some contexts to others. Contextual integrity is a privacy theory that conceptualises the appropriateness of information sharing based on the contexts in which this information is to be shared. Computational models of Contextual Integrity assume the existence of well-defined contexts, in which individuals enact pre-defined roles and information sharing is governed by an explicit set of norms. However, contexts in Online Social Networks are known to be implicit, unknown a priori and ever changing; users relationships are constantly evolving; and the information sharing norms are implicit. This makes current Contextual Integrity models not suitable for Online Social Networks. In this paper, we propose the first computational model of Implicit Contextual Integrity, presenting an information model and an Information Assistant Agent that uses the information model to learn implicit contexts, relationships and the information sharing norms to help users avoid inappropriate information exchanges and undesired information disseminations. Through an experimental evaluation, we validate the properties of Information Assistant Agents, which are shown to: infer the information sharing norms even if a small proportion of the users follow the norms and in presence of malicious users; help reduce the exchange of inappropriate information and the dissemination of sensitive information with only a partial view of the system and the information received and sent by their users; and minimise the burden to the users in terms of raising unnecessary alerts.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Natalia Criado, Jose M. Such,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02489", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02489", "title": "\nFourier Codes and Hartley Codes", "abstract": "Real-valued block codes are introduced, which are derived from Discrete Fourier Transforms (DFT) and Discrete Hartley Transforms (DHT). These algebraic structures are built from the eigensequences of the transforms. Generator and parity check matrices were computed for codes up to block length N=24. They can be viewed as lattices codes so the main parameters (dimension, minimal norm, area of the Voronoi region, density, and centre density) are computed. Particularly, Hamming-Hartley and Golay-Hartley block codes are presented. These codes may possibly help an efficient computation of a DHT/DFT.", "subjects": "Information Theory (cs.IT)", "authors": "H.M. de Oliveira, C.M.F. Barros, R.M. Campello de Souza,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02484", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02484", "title": "\nDepQBF: An Incremental QBF Solver Based on Clause Groups", "abstract": "We present a novel API of our QBF solver DepQBF which allows for incremental QBF solving based on clause groups. A clause group is a set of clauses which is incrementally added to or removed from a previously solved QBF. Our implementation of this API is related to incremental SAT solvers which rely on selector variables and solving under assumptions. However, in contrast to SAT solvers the API entirely hides selector variables and assumptions from the user. This property facilitates the integration of DepQBF as a library in other tools. We provide implementation details and show that the API can be implemented in any DPLL-based SAT and QBF solver. As an application we consider the incremental computation of minimal unsatisfiable cores (MUCs) of QBFs and, for the first time, report on experiments.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Florian Lonsing, Uwe Egly,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02481", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02481", "title": "\nDynamic DFS Tree in Undirected Graphs: breaking the $O(m)$ barrier", "abstract": "Depth first search tree is a fundamental data structure for solving various problems in graphs. It is well known that it takes time to build a DFS tree for a given undirected graph on vertices and edges. We address the problem of maintaining a DFS tree when the graph is undergoing updates (insertion or deletion of vertices or edges). We present the following results for this problem. (a) Fault tolerant DFS tree: There exists a data structure of size such that given any vertex/edge updates, a DFS tree rooted at for the resulting graph can be reported in worst case time. When the updates are deletions only, this directly implies an time fault tolerant algorithm for DFS tree. (b) Fully dynamic DFS tree: There exists a fully dynamic algorithm for maintaining a DFS tree under arbitrary sequence of vertex insertions or deletions. This algorithm takes worst case time per update. Our results are the first worst case time results for the two problems mentioned above. Our dynamic algorithm for DFS provides, in a seamless manner, the first non-trivial algorithm with query time for the dynamic subgraph connectivity, bi-connectivity, 2edge-connectivity problems.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Surender Baswana, Shreejit Ray Chaudhury, Keerti Choudhary, Shahbaz Khan,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02478", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02478", "title": "\nEfficient batchwise dropout training using submatrices", "abstract": "Dropout is a popular technique for regularizing artificial neural networks. Dropout networks are generally trained by minibatch gradient descent with a dropout mask turning off some of the units---a different pattern of dropout is applied to every sample in the minibatch. We explore a very simple alternative to the dropout mask. Instead of masking dropped out units by setting them to zero, we perform matrix multiplication using a submatrix of the weight matrix---unneeded hidden units are never calculated. Performing dropout batchwise, so that one pattern of dropout is used for each sample in a minibatch, we can substantially reduce training times. Batchwise dropout can be used with fully-connected and convolutional neural networks.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "Ben Graham, Jeremy Reizenstein, Leigh Robinson,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02476", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02476", "title": "\nAn Infinite Restricted Boltzmann Machine", "abstract": "We present a mathematical construction for the restricted Boltzmann machine (RBM) in which the hidden layer size is adaptive and can grow during training. This is obtained by first extending the RBM to be sensitive to the ordering of its hidden units. Then, thanks to a carefully chosen definition of the energy function, we show that the limit of infinitely many hidden units is well defined. As in a regular RBM, approximate maximum likelihood training can be performed, resulting in an algorithm that naturally and adaptively adds trained hidden units during learning. We empirically study the behaviour of this infinite RBM, showing that its performance is competitive to that of the RBM.", "subjects": "Learning (cs.LG)", "authors": "Marc-Alexandre C\u00f4t\u00e9, Hugo Larochelle,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02474", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02474", "title": "\nPlanning for robotic exploration based on forward simulation", "abstract": "A robotic agent is tasked to explore an a priori unknown environment. The objective is to maximize the amount of information about the partially observable state. The problem is formulated as a partially observable Markov decision process (POMDP) with an information-theoretic objective function, further approximated to a form suitable for robotic exploration. An open-loop approximation is applied with receding horizon control to solve the problem. Algorithms based on evaluating the utilities of sequences of actions by forward simulation are presented for both finite and uncountable action spaces. The advantages of the receding horizon approach to myopic planning are demonstrated in simulated and real-world exploration experiments. The proposed method is applicable to a wide range of domains, both in dynamic and static environments, by modifying the underlying state transition and observation models.", "subjects": "Robotics (cs.RO)", "authors": "Mikko Lauri, Risto Ritala,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02473", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02473", "title": "\nReal root finding for rank defects in linear Hankel matrices", "abstract": "Let be matrices with entries in and Hankel structure, i.e. constant skew diagonals. We consider the linear Hankel matrix and the problem of computing sample points in each connected component of the real algebraic set defined by the rank constraint , for a given integer . Computing sample points in real algebraic sets defined by rank defects in linear matrices is a general problem that finds applications in many areas such as control theory, computational geometry, optimization, etc. Moreover, Hankel matrices appear in many areas of engineering sciences. Also, since Hankel matrices are symmetric, any algorithmic development for this problem can be seen as a first step towards a dedicated exact algorithm for solving semi-definite programming problems, i.e. linear matrix inequalities. Under some genericity assumptions on the input (such as smoothness of an incidence variety), we design a probabilistic algorithm for tackling this problem. It is an adaptation of the so-called critical point method that takes advantage of the special structure of the problem. Its complexity reflects this: it is essentially quadratic in specific degree bounds on an incidence variety. We report on practical experiments and analyze how the algorithm takes advantage of this special structure. A first implementation outperforms existing implementations for computing sample points in general real algebraic sets: it tackles examples that are out of reach of the state-of-the-art.", "subjects": "Symbolic Computation (cs.SC)", "authors": "Didier Henrion, Simone Naldi, Mohab Safey El Din,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02472", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02472", "title": "\nDerandomized Construction of Combinatorial Batch Codes", "abstract": "Combinatorial Batch Codes (CBCs), replication-based variant of Batch Codes introduced by Ishai et al. in STOC 2004, abstracts the following data distribution problem: data items are to be replicated among servers in such a way that any of the data items can be retrieved by reading at most one item from each server with the total amount of storage over servers restricted to . Given parameters and , where and are constants, one of the challenging problems is to construct -uniform CBCs (CBCs where each data item is replicated among exactly servers) which maximizes the value of . In this work, we present explicit construction of -uniform CBCs with data items. The construction has the property that the servers are almost regular, i.e., number of data items stored in each server is in the range . The construction is obtained through better analysis and derandomization of the randomized construction presented by Ishai et al. Analysis reveals almost regularity of the servers, an aspect that so far has not been addressed in the literature. The derandomization leads to explicit construction for a wide range of values of (for given and ) where no other explicit construction with similar parameters, i.e., with , is known. Finally, we discuss possibility of parallel derandomization of the construction.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Srimanta Bhattacharya,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02468", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02468", "title": "\nNonlinear Model Predictive Control for Constrained Output Path Following", "abstract": "We consider the tracking of geometric paths in output spaces of nonlinear systems subject to input and state constraints without pre-specified timing requirements. Such problems are commonly referred to as constrained output path-following problems. Specifically, we propose a predictive control approach to constrained path-following problems with and without velocity assignments and provide sufficient convergence conditions based on terminal regions and end penalties. Furthermore, we analyze the geometric nature of constrained output path-following problems and thereby provide insight into the computation of suitable terminal control laws and terminal regions. We draw upon an example from robotics to illustrate our findings.", "subjects": "Systems and Control (cs.SY)", "authors": "Timm Faulwasser, Rolf Findeisen,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02467", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02467", "title": "\nStructural Decompositions for Problems with Global Constraints", "abstract": "A wide range of problems can be modelled as constraint satisfaction problems (CSPs), that is, a set of constraints that must be satisfied simultaneously. Constraints can either be represented extensionally, by explicitly listing allowed combinations of values, or implicitly, by special-purpose algorithms provided by a solver. Such implicitly represented constraints, known as global constraints, are widely used; indeed, they are one of the key reasons for the success of constraint programming in solving real-world problems. In recent years, a variety of restrictions on the structure of CSP instances have been shown to yield tractable classes of CSPs. However, most such restrictions fail to guarantee tractability for CSPs with global constraints. We therefore study the applicability of structural restrictions to instances with such constraints. We show that when the number of solutions to a CSP instance is bounded in key parts of the problem, structural restrictions can be used to derive new tractable classes. Furthermore, we show that this result extends to combinations of instances drawn from known tractable classes, as well as to CSP instances where constraints assign costs to satisfying assignments.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Evgenij Thorstensen,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02465", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02465", "title": "\nA behavioural approach to obstacle avoidance for mobile manipulators  based on distributed sensing", "abstract": "A reactive obstacle avoidance method for mobile manipulators is presented. The objectives of the developed algorithm are twofold. The first one is to find a trajectory in the configuration space of a mobile manipulator so as to follow a given trajectory in the task space. The second objective consists in locally adjusting the trajectory in the configuration space in order to avoid collisions with potentially moving obstacles and self-collisions in unstructured and dynamic environments. The perception is exclusively based on a set of proximity sensors distributed on the robot mechanical structure and visual information are not required. Thanks to the adoption of this kind of proximity distributed perception, the approach does not require a 3D model of the robot and allows the real-time collision avoidance without the need of a sensorized environment. To achieve the features cited above, a behaviour-based technique known as Null-Space-Based (NSB) approach has been adopted with some modifications.On one hand, the concept of a total pseudo-energy based on the information from the distributed sensors has been introduced. On the other hand, a method to combine different tasks has been proposed to guarantee the smoothness of the realtime trajectory adjustments. Another significant feature of the method is the strict coordination between the base and the arm exploiting the redundant degrees of freedom, that is a relevant topic in mobile manipulation.", "subjects": "Robotics (cs.RO)", "authors": "Luigi Palmieri,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02454", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02454", "title": "\nA fast PC algorithm for high dimensional causal discovery with  multi-core PCs", "abstract": "Discovering causal relationships from observational data is a crucial problem and has applications in many research areas. PC algorithm is the state-of-the-art method in the constraint based approach. However, the PC algorithm is worst-case exponential to the number of nodes (variables), and thus it is inefficient when applying to high dimensional data, e.g. gene expression datasets where the causal relationships between thousands of nodes (genes) are explored. In this paper, we propose a fast and memory efficient PC algorithm using the parallel computing technique. We apply our method on a range of synthetic and real-world high dimensional datasets. Experimental results on a dataset from DREAM 5 challenge show that the PC algorithm could not produce any results after running more than 24 hours; meanwhile, our parallel-PC algorithm with a 4-core CPU computer managed to finish within around 12.5 hours, and less than 6 hours with a 8-core CPU computer.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Thuc Duy Le, Tao Hoang, Jiuyong Li, Lin Liu, Huawen Liu,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02448", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02448", "title": "\nDear CAV, We Need to Talk About Reproducibility", "abstract": "How many times have you tried to re-implement a past CAV tool paper, and failed? Reliably reproducing published scientific discoveries has been acknowledged as a barrier to scientific progress for some time but there remains only a small subset of software available to support the specific needs of the research community (i.e. beyond generic tools such as source code repositories). In this paper we propose an infrastructure for enabling reproducibility in our community, by automating the build, unit testing and benchmarking of research software.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Tom Crick, Benjamin A. Hall, Samin Ishtiaq,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02445", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02445", "title": "\nDeep Neural Networks for Anatomical Brain Segmentation", "abstract": "We present a novel approach to automatically segment magnetic resonance (MR) images of the human brain into anatomical regions. Our methodology is based on a deep artificial neural network that assigns each voxel in an MR image of the brain to its corresponding anatomical region. The inputs of the network capture information at different scales around the voxel of interest: 3D and orthogonal 2D intensity patches capture the local spatial context while large, compressed 2D orthogonal patches and distances to the regional centroids enforce global spatial consistency. Contrary to commonly used segmentation methods, our technique does not require any non-linear registration of the MR images. To benchmark our model, we used the dataset provided for the MICCAI 2012 challenge on multi-atlas labelling, which consists of 35 manually segmented MR images of the brain. We obtained competitive results (mean dice coefficient 0.725, error rate 0.163) showing the potential of our approach. To our knowledge, our technique is the first to tackle the anatomical segmentation of the whole brain using deep neural networks.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Alexandre de Brebisson, Giovanni Montana,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02444", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02444", "title": "\nOn the Dynamics of a Recurrent Hopfield Network", "abstract": "In this research paper novel real/complex valued recurrent Hopfield Neural Network (RHNN) is proposed. The method of synthesizing the energy landscape of such a network and the experimental investigation of dynamics of Recurrent Hopfield Network is discussed. Parallel modes of operation (other than fully parallel mode) in layered RHNN is proposed. Also, certain potential applications are proposed.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "Rama Garimella, Berkay Kicanaoglu, Moncef Gabbouj,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02441", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02441", "title": "\nNonparametric Simultaneous Sparse Recovery: an Application to Source  Localization", "abstract": "We consider multichannel sparse recovery problem where the objective is to find good recovery of jointly sparse unknown signal vectors from the given multiple measurement vectors which are different linear combinations of the same known elementary vectors. Many popular greedy or convex algorithms perform poorly under non-Gaussian heavy-tailed noise conditions or in the face of outliers. In this paper, we propose the usage of mixed norms on data fidelity (residual matrix) term and the conventional -norm constraint on the signal matrix to promote row-sparsity. We devise a greedy pursuit algorithm based on simultaneous normalized iterative hard thresholding (SNIHT) algorithm which is a simple, computationally efficient and scalable approach for solving the simultaneous sparse approximation problem. Simulation studies highlight the effectiveness of the proposed approaches to cope with different noise environments (i.i.d., row i.i.d, etc) and outliers. Usefulness of the methods are illustrated in source localization application with sensor arrays.", "subjects": "Information Theory (cs.IT)", "authors": "Esa Ollila,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02440", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02440", "title": "\nGeneralized switching signals for input-to-state stability of switched  systems", "abstract": "This article deals with input-to-state stability (ISS) of continuous-time switched nonlinear systems. Given a family of systems with exogenous inputs such that not all systems in the family are ISS, we characterize a new and general class of switching signals under which the resulting switched system is ISS. Our stabilizing switching signals allow the number of switches to grow faster than an affine function of the length of a time interval, unlike in the case of average dwell time switching. We also recast a subclass of average dwell time switching signals in our setting and establish analogs of two representative prior results.", "subjects": "Systems and Control (cs.SY)", "authors": "Atreyee Kundu, Debasish Chatterjee, Daniel Liberzon,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02436", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02436", "title": "\nExact solutions to Super Resolution on semi-algebraic domains in higher  dimensions", "abstract": "We investigate the multi-dimensional Super Resolution problem on closed semi-algebraic domains for various sampling schemes such as Fourier or moments. We present a new semidefinite programming (SDP) formulation of the 1 -minimization in the space of Radon measures in the multi-dimensional frame on semi-algebraic sets. While standard approaches have focused on SDP relaxations of the dual program (a popular approach is based on Gram matrix representations), this paper introduces an exact formulation of the primal 1 -minimization exact recovery problem of Super Resolution that unleashes standard techniques (such as moment-sum-of-squares hier-archies) to overcome intrinsic limitations of previous works in the literature. Notably, we show that one can exactly solve the Super Resolution problem in dimension greater than 2 and for a large family of domains described by semi-algebraic sets.", "subjects": "Information Theory (cs.IT)", "authors": "Y De Castro, F Gamboa, D Henrion, J.-B Lasserre,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02427", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02427", "title": "\nA Distributed Message-Optimal Assignment on Rings", "abstract": "Consider a set of items and a set of colors, where each item is associated to one color. Consider also computational agents connected by a ring. Each agent holds a subset of the items and items of the same color can be held by different agents. We analyze the problem of distributively assigning colors to agents in such a way that (a) each color is assigned to one agent only and (b) the number of different colors assigned to each agent is minimum. Since any color assignment requires the items be distributed according to it (e.g. all items of the same color are to be held by only one agent), we define the cost of a color assignment as the amount of items that need to be moved, given an initial allocation. We first show that any distributed algorithm for this problem requires a message complexity of and then we exhibit an optimal message complexity algorithm for synchronous rings that in polynomial time determines a color assignment with cost at most three times the optimal. We also discuss solutions for the asynchronous setting. Finally, we show how to get a better cost solution at the expenses of either the message or the time complexity.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Gianluca De Marco, Mauro Leoncini, Manuela Montangero,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02426", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02426", "title": "\nSimple Distributed Delta + 1 Coloring in the SINR Model", "abstract": "In wireless ad hoc or sensor networks, distributed node coloring is a fundamental problem closely related to establishing efficient communication through TDMA schedules. For networks with maximum degree Delta, a Delta + 1 coloring is the ultimate goal in the distributed setting as this is always possible. In this work we propose Delta + 1 coloring algorithms for the synchronous and asynchronous setting. All algorithms have a runtime of O(Delta log n) time slots. This improves on the previous algorithms for the SINR model either in terms of the number of required colors or the runtime and matches the runtime of local broadcasting in the SINR model (which can be seen as a lower bound).", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Fabian Fuchs, Roman Prutkin,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02422", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02422", "title": "\nAn improved lower bound for one-dimensional online unit clustering", "abstract": "The online unit clustering problem was proposed by Chan and Zarrabi-Zadeh (WAOA2007 and Theory of Computing Systems 45(3), 2009), which is defined as follows: \"Points\" are given online in the -dimensional Euclidean space one by one. An algorithm creates a \"cluster,\" which is a -dimensional rectangle. The initial length of each edge of a cluster is 0. An algorithm can extend an edge until it reaches unit length independently of other dimensions. The task of an algorithm is to cover a new given point either by creating a new cluster and assigning it to the point, or by extending edges of an existing cluster created in past times. The goal is to minimize the total number of created clusters. Chan and Zarrabi-Zadeh proposed some method to obtain a competitive algorithm for the -dimensional case using an algorithm for the one-dimensional case, and thus the one-dimensional case has been extensively studied including some variants of the unit clustering problem. In this paper, we show a lower bound of on the competitive ratio of any deterministic online algorithm for the one-dimensional unit clustering, improving the previous lower bound presented by Epstein and van Stee (WAOA2007 and ACM Transactions on Algorithms 7(1), 2010). Note that Ehmsen and Larsen (SWAT2010 and Theoretical Computer Science, 500, 2013) showed the current best upper bound of , and conjectured that the exact competitive ratio in the one-dimensional case may be .", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Jun Kawahara, Koji M. Kobayashi,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02417", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02417", "title": "\nSemantics-based services for a low carbon society: An application on  emissions trading system data and scenarios management", "abstract": "A low carbon society aims at fighting global warming by stimulating synergic efforts from governments, industry and scientific communities. Decision support systems should be adopted to provide policy makers with possible scenarios, options for prompt countermeasures in case of side effects on environment, economy and society due to low carbon society policies, and also options for information management. A necessary precondition to fulfill this agenda is to face the complexity of this multi-disciplinary domain and to reach a common understanding on it as a formal specification. Ontologies are widely accepted means to share knowledge. Together with semantic rules, they enable advanced semantic services to manage knowledge in a smarter way. Here we address the European Emissions Trading System (EU-ETS) and we present a knowledge base consisting of the EREON ontology and a catalogue of rules. Then we describe two innovative semantic services to manage ETS data and information on ETS scenarios.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Cecilia Camporeale, Antonio De Nicola, Maria Luisa Villani,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02414", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02414", "title": "\nTractability and Decompositions of Global Cost Functions", "abstract": "Enforcing local consistencies in cost function networks is performed by applying so-called Equivalent Preserving Transformations (EPTs) to the cost functions. As EPTs transform the cost functions, they may break the property that was making local consistency enforcement tractable on a global cost function. A global cost function is called tractable projection-safe when applying an EPT to it is tractable and does not break the tractability property. In this paper, we prove that depending on the size r of the smallest scopes used for performing EPTs, the tractability of global cost functions can be preserved (r = 0) or destroyed (r &gt; 1). When r = 1, the answer is indefinite. We show that on a large family of cost functions, EPTs can be computed via dynamic programming-based algorithms, leading to tractable projection-safety. We also show that when a global cost function can be decomposed into a Berge acyclic network of bounded arity cost functions, soft local consistencies such as soft Directed or Virtual Arc Consistency can directly emulate dynamic programming. These different approaches to decomposable cost functions are then embedded in a solver for extensive experiments that confirm the feasibility and efficiency of our proposal.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "David Allouche, Christian Bessiere, Patrice Boizumault, Simon de Givry, Patricia Gutierrez, Jimmy H.M. Lee, Kam Lun Leung, Samir Loudni, Jean-Philippe M\u00e9tivier, Thomas Schiex, Yi Wu,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02410", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02410", "title": "\nOut-of-sample generalizations for supervised manifold learning for  classification", "abstract": "Supervised manifold learning methods for data classification map data samples residing in a high-dimensional ambient space to a lower-dimensional domain in a structure-preserving way, while enhancing the separation between different classes in the learned embedding. Most nonlinear supervised manifold learning methods compute the embedding of the manifolds only at the initially available training points, while the generalization of the embedding to novel points, known as the out-of-sample extension problem in manifold learning, becomes especially important in classification applications. In this work, we propose a semi-supervised method for building an interpolation function that provides an out-of-sample extension for general supervised manifold learning algorithms studied in the context of classification. The proposed algorithm computes a radial basis function (RBF) interpolator that minimizes an objective function consisting of the total embedding error of unlabeled test samples, defined as their distance to the embeddings of the manifolds of their own class, as well as a regularization term that controls the smoothness of the interpolation function in a direction-dependent way. The class labels of test data and the interpolation function parameters are estimated jointly with a progressive procedure. Experimental results on face and object images demonstrate the potential of the proposed out-of-sample extension algorithm for the classification of manifold-modeled data sets.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Elif Vural, Christine Guillemot,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02407", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02407", "title": "\nA Social Spider Algorithm for Global Optimization", "abstract": "The growing complexity of real-world problems has motivated computer scientists to search for efficient problem-solving methods. Metaheuristics based on evolutionary computation and swarm intelligence are outstanding examples of nature-inspired solution techniques. Inspired by the social spiders, we propose a novel Social Spider Algorithm to solve global optimization problems. This algorithm is mainly based on the foraging strategy of social spiders, utilizing the vibrations on the spider web to determine the positions of preys. Different from the previously proposed swarm intelligence algorithms, we introduce a new social animal foraging strategy model to solve optimization problems. In addition, we perform preliminary parameter sensitivity analysis for our proposed algorithm, developing guidelines for choosing the parameter values. The Social Spider Algorithm is evaluated by a series of widely-used benchmark functions, and our proposed algorithm has superior performance compared with other state-of-the-art metaheuristics.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "James J.Q. Yu, Victor O.K. Li,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02404", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02404", "title": "\nThe relational model is injective for Multiplicative Exponential Linear  Logic", "abstract": "We show that the relational semantics is injective for Multiplicative Exponential Linear Logic proof-nets, i.e. the equality between MELL proof-nets in the relational model is exactly axiomatized by the cut-elimination.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Daniel de Carvalho,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02403", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02403", "title": "\nYesWorkflow: A User-Oriented, Language-Independent Tool for Recovering  Workflow Information from Scripts", "abstract": "Scientific workflow management systems offer features for composing complex computational pipelines from modular building blocks, for executing the resulting automated workflows, and for recording the provenance of data products resulting from workflow runs. Despite the advantages such features provide, many automated workflows continue to be implemented and executed outside of scientific workflow systems due to the convenience and familiarity of scripting languages (such as Perl, Python, R, and MATLAB), and to the high productivity many scientists experience when using these languages. YesWorkflow is a set of software tools that aim to provide such users of scripting languages with many of the benefits of scientific workflow systems. YesWorkflow requires neither the use of a workflow engine nor the overhead of adapting code to run effectively in such a system. Instead, YesWorkflow enables scientists to annotate existing scripts with special comments that reveal the computational modules and dataflows otherwise implicit in these scripts. YesWorkflow tools extract and analyze these comments, represent the scripts in terms of entities based on the typical scientific workflow model, and provide graphical renderings of this workflow-like view of the scripts. Future versions of YesWorkflow also will allow the prospective provenance of the data products of these scripts to be queried in ways similar to those available to users of scientific workflow systems.", "subjects": "Software Engineering (cs.SE)", "authors": "Timothy McPhillips, Tianhong Song, Tyler Kolisnik, Steve Aulenbach, Khalid Belhajjame, Kyle Bocinsky, Yang Cao, Fernando Chirigati, Saumen Dey, Juliana Freire, Deborah Huntzinger, Christopher Jones, David Koop, Paolo Missier, Mark Schildhauer, Christopher Schwalm, Yaxing Wei, James Cheney, Mark Bieda, Bertram Ludaescher,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02402", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02402", "title": "\nUser-space Multipath UDP in Mosh", "abstract": "In many network topologies, hosts have multiple IP addresses, and may choose among multiple network paths by selecting the source and destination addresses of the packets that they send. This can happen with multihomed hosts (hosts connected to multiple networks), or in multihomed networks using source-specific routing. A number of efforts have been made to dynamically choose between multiple addresses in order to improve the reliability or the performance of network applications, at the network layer, as in Shim6, or at the transport layer, as in MPTCP. In this paper, we describe our experience of implementing dynamic address selection at the application layer within the Mobile Shell. While our work is specific to Mosh, we hope that it is generic enough to serve as a basis for designing UDP-based multipath applications or even more general APIs.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Matthieu Boutier, Juliusz Chroboczek,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02401", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02401", "title": "\nRandom Preferential Attachment Hypergraphs", "abstract": "The random graph model has recently been extended to a random preferential attachment graph model, in order to enable the study of general asymptotic properties in network types that are better represented by the preferential attachment evolution model than by the ordinary (uniform) evolution lodel. Analogously, this paper extends the random model to a random model. We then analyze the degree distribution of random preferential attachment hypergraphs and show that they possess heavy tail degree distribution properties similar to those of random preferential attachment graphs. However, our results show that the exponent of the degree distribution is sensitive to whether one considers the structure as a hypergraph or as a graph.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Chen Avin, Zvi Lotker, David Peleg,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02389", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02389", "title": "\nPatterns and Rewrite Rules for Systematic Code Generation (From  High-Level Functional Patterns to High-Performance OpenCL Code)", "abstract": "Computing systems have become increasingly complex with the emergence of heterogeneous hardware combining multicore CPUs and GPUs. These parallel systems exhibit tremendous computational power at the cost of increased programming effort. This results in a tension between achieving performance and code portability. Code is either tuned using device-specific optimizations to achieve maximum performance or is written in a high-level language to achieve portability at the expense of performance. We propose a novel approach that offers high-level programming, code portability and high-performance. It is based on algorithmic pattern composition coupled with a powerful, yet simple, set of rewrite rules. This enables systematic transformation and optimization of a high-level program into a low-level hardware specific representation which leads to high performance code. We test our design in practice by describing a subset of the OpenCL programming model with low-level patterns and by implementing a compiler which generates high performance OpenCL code. Our experiments show that we can systematically derive high-performance device-specific implementations from simple high-level algorithmic expressions. The performance of the generated OpenCL code is on par with highly tuned implementations for multicore CPUs and GPUs written by experts", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Michel Steuwer, Christian Fensch, Christophe Dubach,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02388", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02388", "title": "\nThe extensional realizability model of continuous functionals and three  weakly non-constructive classical theorems", "abstract": "We investigate wether three statements in analysis, that can be proved classically, are realizable in the realizability model of extensional continuous functionals induced by Kleene's second model . We prove that a formulation of the Riemann Permutation Theorem as well as the statement that all partially Cauchy sequences are Cauchy cannot be realized in this model, while the statement that the product of two anti-Specker spaces is anti-Specker can be realized.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Dag Normann,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02385", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02385", "title": "\nMultiuser Charging Control in Wireless Power Transfer via Magnetic  Resonant Coupling", "abstract": "Magnetic resonant coupling (MRC) is a practically appealing method for realizing the near-field wireless power transfer (WPT). The MRC-WPT system with a single pair of transmitter and receiver has been extensively studied in the literature, while there is limited work on the general setup with multiple transmitters and/or receivers. In this paper, we consider a point-to-multipoint MRC-WPT system with one transmitter sending power wirelessly to a set of distributed receivers simultaneously. We derive the power delivered to the load of each receiver in closed-form expression, and reveal a \"near-far\" fairness issue in multiuser power transmission due to users' distance-dependent mutual inductances with the transmitter. We also show that by designing the receivers' load resistances, the near-far issue can be optimally solved. Specifically, we propose a centralized algorithm to jointly optimize the load resistances to minimize the power drawn from the energy source at the transmitter under given power requirements for the loads. We also devise a distributed algorithm for the receivers to adjust their load resistances iteratively, for ease of practical implementation.", "subjects": "Systems and Control (cs.SY)", "authors": "Mohammad R. Vedady Moghadam, Rui Zhang,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02377", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02377", "title": "\nSparse coding with earth mover's distance", "abstract": "Sparse coding (Sc) has been studied very well as a powerful data representation method. It attempts to represent the feature vector of a data sample by reconstructing it as the sparse linear combination of some basic elements, and a norm distance function is usually used as the loss function for the reconstruction error. In this paper, we investigate using Sc as the representation method within multi-instance learning framework, where a sample is given as a bag of instances, and further represented as a histogram of the quantized instances. We argue that for the data type of histogram, using norm distance is not suitable, and propose to use the earth mover's distance (EMD) instead of norm distance as a measure of the reconstruction error. By minimizing the EMD between the histogram of a sample and the its reconstruction from some basic histograms, a novel sparse coding method is developed, which is refereed as Sc-EMD. We evaluate its performances as a histogram representation method in tow multi-instance learning problems --- abnormal image detection in wireless capsule endoscopy videos, and protein binding site retrieval. The encouraging results demonstrate the advantages of the new method over the traditional method using norm distance.", "subjects": "Learning (cs.LG)", "authors": "Xuejie Liu, Jim Jing-Yan Wang,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02376", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02376", "title": "\nOptimal Relay Selection with Non-negligible Probing Time", "abstract": "In this paper an optimal relay selection algorithm with non-negligible probing time is proposed and analyzed for cooperative wireless networks. Relay selection has been introduced to solve the degraded bandwidth efficiency problem in cooperative communication. Yet complete information of relay channels often remain unavailable for complex networks which renders the optimal selection strategies impossible for transmission source without probing the relay channels. Particularly when the number of relay candidate is large, even though probing all relay channels guarantees the finding of the best relays at any time instant, the degradation of bandwidth efficiency due to non-negligible probing times, which was often neglected in past literature, is also significant. In this work, a stopping rule based relay selection strategy is determined for the source node to decide when to stop the probing process and choose one of the probed relays to cooperate with under wireless channels' stochastic uncertainties. This relay selection strategy is further shown to have a simple threshold structure. At the meantime, full diversity order and high bandwidth efficiency can be achieved simultaneously. Both analytical and simulation results are provided to verify the claims.", "subjects": "Information Theory (cs.IT)", "authors": "Yang Liu, Yi Ouyang, Mingyan Liu,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02370", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02370", "title": "\nTeachable Agent", "abstract": "Teachable Agent (TA) is a special type of pedagogical agent which instantiates the educational theory of Learning by Teaching. Soon after its emergence, research of TA becomes an active field, as it can solve the over scaffolded problem in traditional pedagogical systems, and encourage students to take the responsibility of learning. Apart from the benefits, existing TA design also has limitations. One is the lack of enough proactive interactions with students during the learning process, and the other is the lack of believability to arouse students empathy so as to offer students an immersive learning experience. To solve these two problems, we propose a new type of TA, Affective Teachable Agent, and use a goal oriented approach to design and implement the agent system allowing agents to proactively interact with students with affective expressions. The ATA model begins with the analysis of pedagogical requirements and teaching goals, using Learning by Teaching theory to design interventions which can authentically promote the learning behaviors of students. Two crucial capabilities of ATA are highlighted Teachability, to learn new knowledge and apply the knowledge to certain tasks, and Affectivability, to establish good relationship with students and encourage them to teach well. Through executing a hierarchy of goals, the proposed TA can interact with students by pursuing its own agenda. When a student teaches the agent, the agent is performed as a naive learning companion, and when an educator teaches the agent during the design and maintenance time, the agent can perform as an authoring tool. To facilitate the involvement of educators into the game design, we develop an authoring tool for proposed ATA system, which can encapsulate the technical details and provide educational experts a natural way to convey domain knowledge to agent knowledge base.", "subjects": "Computers and Society (cs.CY)", "authors": "Ailiya Borjigin,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02367", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02367", "title": "\nGated Feedback Recurrent Neural Networks", "abstract": "In this work, we propose a novel recurrent neural network (RNN) architecture. The proposed RNN, gated-feedback RNN (GF-RNN), extends the existing approach of stacking multiple recurrent layers by allowing and controlling signals flowing from upper recurrent layers to lower layers using a global gating unit for each pair of layers. The recurrent signals exchanged between layers are gated adaptively based on the previous hidden states and the current input. We evaluated the proposed GF-RNN with different types of recurrent units, such as tanh, long short-term memory and gated recurrent units, on the tasks of character-level language modeling and Python program evaluation. Our empirical evaluation of different RNN units, revealed that in both tasks, the GF-RNN outperforms the conventional approaches to build deep stacked RNNs. We suggest that the improvement arises because the GF-RNN can adaptively assign different layers to different timescales and layer-to-layer interactions (including the top-down ones which are not usually present in a stacked RNN) by learning to gate these interactions.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "Junyoung Chung, Caglar Gulcehre, Kyunghyun Cho, Yoshua Bengio,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02362", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02362", "title": "\nCounterfactual Risk Minimization: Learning from Logged Bandit Feedback", "abstract": "We develop a learning principle and an efficient algorithm for batch learning from logged bandit feedback. This learning setting is ubiquitous in online systems (e.g., ad placement, web search, recommendation), where an algorithm makes a prediction (e.g., ad ranking) for a given input (e.g., query) and observes bandit feedback (e.g., user clicks on presented ads). We first address the counterfactual nature of the learning problem through propensity scoring. Next, we prove generalization error bounds that account for the variance of the propensity-weighted empirical risk estimator. These constructive bounds give rise to the Counterfactual Risk Minimization (CRM) principle. We show how CRM can be used to derive a new learning method -- called Policy Optimizer for Exponential Models (POEM) -- for learning stochastic linear rules for structured output prediction. We present a decomposition of the POEM objective that enables efficient stochastic gradient optimization. POEM is evaluated on several multi-label classification problems showing substantially improved robustness and generalization performance compared to the state-of-the-art.", "subjects": "Learning (cs.LG)", "authors": "Adith Swaminathan, Thorsten Joachims,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02358", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02358", "title": "\nUsing Heavy Clique Base Coarsening to Enhance Virtual Network Embedding", "abstract": "Network virtualization allows cloud infrastructure providers to accommodate multiple virtual networks on a single physical network. However, mapping multiple virtual network resources to physical network components, called virtual network embedding (VNE), is known to be non-deterministic polynomial-time hard (NP-hard). Effective virtual network embedding increases the revenue by increasing the number of accepted virtual networks. In this paper, we propose virtual network embedding algorithm, which improves virtual network embedding by coarsening virtual networks. Heavy Clique matching technique is used to coarsen virtual networks. Then, the coarsened virtual networks are enhanced by using a refined Kernighan-Lin algorithm. The performance of the proposed algorithm is evaluated and compared with existing algorithms using extensive simulations, which show that the proposed algorithm improves virtual network embedding by increasing the acceptance ratio and the revenue.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Ashraf A. Shahin,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02348", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02348", "title": "\nMATLAB based language for generating randomized multiple choice  questions", "abstract": "In this work we describe a simple MATLAB based language which allows to create randomized multiple choice questions with minimal effort. This language has been successfully tested at Flinders University by the author in a number of mathematics topics including Numerical Analysis, Abstract Algebra and Partial Differential Equations.", "subjects": "Computers and Society (cs.CY)", "authors": "Nurulla Azamov,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02341", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02341", "title": "\nFirst Women, Second Sex: Gender Bias in Wikipedia", "abstract": "Contributing to history has never been as easy as it is today. Anyone with access to the Web is able to play a part on Wikipedia, an open and free encyclopedia. Wikipedia, available in many languages, is one of the most visited websites in the world and arguably one of the primary sources of knowledge on the Web. However, not everyone is contributing to Wikipedia from a diversity point of view; several groups are severely underrepresented. One of those groups is women, who make up approximately 16% of the current contributor community, meaning that most of the content is written by men. In addition, although there are specific guidelines of verifiability, notability, and neutral point of view that must be adhered by Wikipedia content, these guidelines are supervised and enforced by men. In this paper, we propose that gender bias is not about participation and representation only, but also about characterization of women. We approach the analysis of gender bias by defining a methodology for comparing the characterizations of men and women in biographies. In particular we refer to three dimensions of biographies: meta-data, language usage, and structure of the network built from links between articles. Our results show that, indeed, there are differences in characterization and structure. Some of these differences are reflected from the offline world documented by Wikipedia, but other differences can be attributed to gender bias in Wikipedia content. We contextualize these differences in feminist theory and discuss their implications for Wikipedia policy.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Eduardo Graells-Garrido, Mounia Lalmas, Filippo Menczer,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02328", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02328", "title": "\nContext-free Algorithms", "abstract": "Algorithms on grammars/transducers with context-free derivations: hypergraph reachability, shortest path, and inside-outside pruning of 'relatively useless' arcs that are unused by any near-shortest paths.", "subjects": "Formal Languages and Automata Theory (cs.FL)", "authors": "Jonathan Graehl,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02327", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02327", "title": "\nModel Checking C Programs with Loops via k-Induction and Invariants", "abstract": "We present a novel proof by induction algorithm, which combines k-induction with invariants to model check C programs with bounded and unbounded loops. The k-induction algorithm consists of three cases: in the base case, we aim to find a counterexample with up to k loop unwindings; in the forward condition, we check whether loops have been fully unrolled and that the safety property P holds in all states reachable within k unwindings; and in the inductive step, we check that whenever P holds for k unwindings, it also holds after the next unwinding of the system. For each step of the k-induction algorithm, we infer invariants using affine constraints (i.e., polyhedral) to specify pre- and post-conditions. The algorithm was implemented in two different ways, with and without invariants using polyhedral, and the results were compared. Experimental results show that both forms can handle a wide variety of safety properties; however, the k-induction algorithm adopting polyhedral solves more verification tasks, which demonstrate an improvement of the induction algorithm effectiveness.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Herbert Rocha, Hussama Ismail, Lucas Cordeiro, Raimundo Barreto,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02322", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02322", "title": "\nRademacher Observations, Private Data, and Boosting", "abstract": "The minimization of the logistic loss is a popular approach to batch supervised learning. Our paper starts from the surprising observation that, when fitting linear (or kernelized) classifiers, the minimization of the logistic loss is textit to the minimization of an exponential textit-loss computed (i) over transformed data that we call Rademacher observations (rados), and (ii) over the textit classifier as the one of the logistic loss. Thus, a classifier learnt from rados can be textit used to classify textit. We provide a learning algorithm over rados with boosting-compliant convergence rates on the textit (computed over examples). Experiments on domains with up to millions of examples, backed up by theoretical arguments, display that learning over a small set of random rados can challenge the state of the art that learns over the textit set of examples. We show that rados comply with various privacy requirements that make them good candidates for machine learning in a privacy framework. We give several algebraic, geometric and computational hardness results on reconstructing examples from rados. We also show how it is possible to craft, and efficiently learn from, rados in a differential privacy framework. Tests reveal that learning from differentially private rados can compete with learning from random rados, and hence with batch learning from examples, achieving non-trivial privacy vs accuracy tradeoffs.", "subjects": "Learning (cs.LG)", "authors": "Richard Nock, Giorgio Patrini, Arik Friedman,", "date": "2015-2-9"}, 
{"urllink": "http://arxiv.org/abs/1502.02304", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02304", "title": "\nOnline Algorithms for a Generalized Parallel Machine Scheduling Problem", "abstract": "We consider different online algorithms for a generalized scheduling problem for parallel machines, described in details in the first section. This problem is the generalization of the classical parallel machine scheduling problem, when the make-span is minimized; in that case each job contains only one task. On the other hand, the problem in consideration is still a special version of the workflow scheduling problem. We present several heuristic algorithms and compare them by computer tests.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Istvan Szalkai, Gyorgy Dosa,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1502.02298", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02298", "title": "\nBelief revision in Institutions : A relaxation based approach", "abstract": "Belief revision of knowledge bases represented by a set of sentences in a given logic has been extensively studied but for specific logics, mainly propositional, but also recently Horn and description logics. Here, we propose to generalize this operation from a model-theoretic point of view, by defining revision in a categorical abstract model theory known under the name of theory of institutions. In this framework, we generalize to any institution the characterization of the well known AGM postulates given by Katsuno and Mendelzon for propositional logic in terms of minimal change with respect to an ordering among interpretations. Moreover, we study how to define revision, satisfying the AGM postulates, from relaxation notions that have been first introduced in description logics to define dissimilarity measures between concepts, and the consequence of which is to relax the set of models of the old belief until it becomes consistent with the new pieces of knowledge. The proposed general framework can be instantiated in different logics such as propositional, description and Horn logics.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Marc Aiguier, Jamal Atif, Isabelle Bloch, C\u00e9line Hudelot,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1502.02290", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02290", "title": "\nHow Hard is Computing Parity with Noisy Communications?", "abstract": "We show a tight lower bound of on the number of transmissions required to compute the parity of input bits with constant error in a noisy communication network of randomly placed sensors, each having one input bit and communicating with others using local transmissions with power near the connectivity threshold. This result settles the lower bound question left open by Ying, Srikant and Dullerud (WiOpt 06), who showed how the sum of all the bits can be computed using transmissions. The same lower bound has been shown to hold for a host of other functions including majority by Dutta and Radhakrishnan (FOCS 2008). Most works on lower bounds for communication networks considered mostly the full broadcast model without using the fact that the communication in real networks is local, determined by the power of the transmitters. In fact, in full broadcast networks computing parity needs transmissions. To obtain our lower bound we employ techniques developed by Goyal, Kindler and Saks (FOCS 05), who showed lower bounds in the full broadcast model by reducing the problem to a model of noisy decision trees. However, in order to capture the limited range of transmissions in real sensor networks, we adapt their definition of noisy decision trees and allow each node of the tree access to only a limited part of the input. Our lower bound is obtained by exploiting special properties of parity computations in such noisy decision trees.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Chinmoy Dutta, Yashodhan Kanoria, D. Manjunath, Jaikumar Radhakrishnan,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1502.02287", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02287", "title": "\nProtecting Memory-Performance Critical Sections in Soft Real-Time  Applications", "abstract": "Soft real-time applications such as multimedia applications often show bursty memory access patterns---regularly requiring a high memory bandwidth for a short duration of time. Such a period is often critical for timely data processing. Hence, we call it a memory-performance critical section. Unfortunately, in multicore architecture, non-real-time applications on different cores may also demand high memory bandwidth at the same time, which can substantially increase the time spent on the memory performance critical sections. In this paper, we present BWLOCK, user-level APIs and a memory bandwidth control mechanism that can protect such memory performance critical sections of soft real-time applications. BWLOCK provides simple lock like APIs to declare memory-performance critical sections. If an application enters a memory-performance critical section, the memory bandwidth control system then dynamically limit other cores' memory access rates to protect memory performance of the application until the critical section finishes. From case studies with real-world soft real-time applications, we found (1) such memory-performance critical sections do exist and are often easy to identify; and (2) applying BWLOCK for memory critical sections significantly improve performance of the soft real-time applications at a small or no cost in throughput of non real-time applications.", "subjects": "Operating Systems (cs.OS)", "authors": "Heechul Yun, Santosh Gondi, Siddhartha Biswas,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1502.02280", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02280", "title": "\nA comparison of the Extrapolated Successive Overrelaxation and the  Preconditioned Simultaneous Displacement methods for augmented linear systems", "abstract": "In this paper we study the impact of two types of preconditioning on the numerical solution of large sparse augmented linear systems. The first preconditioning matrix is the lower triangular part whereas the second is the product of the lower triangular part with the upper triangular part of the augmented system's coefficient matrix. For the first preconditioning matrix we form the Generalized Modified Extrapolated Successive Overrelaxation (GMESOR) method, whereas the second preconditioning matrix yields the Generalized Modified Preconditioned Simultaneous Displacement (GMPSD) method, which is an extrapolated form of the Symmetric Successive Overrelaxation method. We find sufficient conditions for each aforementioned iterative method to converge. In addition, we develop a geometric approach, for determining the optimum values of their parameters and corresponding spectral radii. It is shown that both iterative methods studied (GMESOR and GMPSD) attain the same rate of convergence. Numerical results confirm our theoretical expectations.", "subjects": "Numerical Analysis (cs.NA)", "authors": "M. A. Louka, N. M. Missirlis,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1502.02277", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02277", "title": "\nImproving Term Frequency Normalization for Multi-topical Documents, and  Application to Language Modeling Approaches", "abstract": "Term frequency normalization is a serious issue since lengths of documents are various. Generally, documents become long due to two different reasons - verbosity and multi-topicality. First, verbosity means that the same topic is repeatedly mentioned by terms related to the topic, so that term frequency is more increased than the well-summarized one. Second, multi-topicality indicates that a document has a broad discussion of multi-topics, rather than single topic. Although these document characteristics should be differently handled, all previous methods of term frequency normalization have ignored these differences and have used a simplified length-driven approach which decreases the term frequency by only the length of a document, causing an unreasonable penalization. To attack this problem, we propose a novel TF normalization method which is a type of partially-axiomatic approach. We first formulate two formal constraints that the retrieval model should satisfy for documents having verbose and multi-topicality characteristic, respectively. Then, we modify language modeling approaches to better satisfy these two constraints, and derive novel smoothing methods. Experimental results show that the proposed method increases significantly the precision for keyword queries, and substantially improves MAP (Mean Average Precision) for verbose queries.", "subjects": "Information Retrieval (cs.IR)", "authors": "Seung-Hoon Na, In-Su Kang, Jong-Hyeok Lee,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1502.02272", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02272", "title": "\nRigorous Deductive Argumentation for Socially Relevant Issues", "abstract": "The most important problems for society are describable only in vague terms, dependent on subjective positions, and missing highly relevant data. This thesis is intended to revive and further develop the view that giving non-trivial, rigorous deductive arguments concerning such problems -without eliminating the complications of vagueness, subjectivity, and uncertainty- is, though very difficult, not problematic in principle, does not require the invention of new logics -classical first-order logic will do- and is something that more mathematically-inclined people should be pursuing. The framework of interpreted formal proofs is presented for formalizing and criticizing rigorous deductive arguments about vague, subjective, and uncertain issues, and its adequacy is supported largely by a number of major examples. This thesis also documents progress towards a web system for collaboratively authoring and criticizing such arguments, which is the ultimate goal of this project.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Dustin Wehr,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1502.02268", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02268", "title": "\nSDNA: Stochastic Dual Newton Ascent for Empirical Risk Minimization", "abstract": "We propose a new algorithm for minimizing regularized empirical loss: Stochastic Dual Newton Ascent (SDNA). Our method is dual in nature: in each iteration we update a random subset of the dual variables. However, unlike existing methods such as stochastic dual coordinate ascent, SDNA is capable of utilizing all curvature information contained in the examples, which leads to striking improvements in both theory and practice - sometimes by orders of magnitude. In the special case when an L2-regularizer is used in the primal, the dual problem is a concave quadratic maximization problem plus a separable term. In this regime, SDNA in each step solves a proximal subproblem involving a random principal submatrix of the Hessian of the quadratic function; whence the name of the method. If, in addition, the loss functions are quadratic, our method can be interpreted as a novel variant of the recently introduced Iterative Hessian Sketch.", "subjects": "Learning (cs.LG)", "authors": "Zheng Qu, Peter Richt\u00e1rik, Martin Tak\u00e1\u010d, Olivier Fercoq,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1502.02265", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02265", "title": "\nA geometric approach for the upper bound theorem for Minkowski sums of  convex polytopes", "abstract": "We derive tight expressions for the maximum number of -faces, , of the Minkowski sum, , of convex -polytopes in , where and , as a (recursively defined) function on the number of vertices of the polytopes. Our results coincide with those recently proved by Adiprasito and Sanyal [2]. In contrast to Adiprasito and Sanyal's approach, which uses tools from Combinatorial Commutative Algebra, our approach is purely geometric and uses basic notions such as - and -vector calculus and shellings, and generalizes the methodology used in [15] and [14] for proving upper bounds on the -vector of the Minkowski sum of two and three convex polytopes, respectively. The key idea behind our approach is to express the Minkowski sum as a section of the Cayley polytope of the summands; bounding the -faces of reduces to bounding the subset of the -faces of that contain vertices from each of the polytopes. We end our paper with a sketch of an explicit construction that establishes the tightness of the upper bounds.", "subjects": "Computational Geometry (cs.CG)", "authors": "Menelaos I. Karavelas, Eleni Tzanaki,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1502.02253", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02253", "title": "\nData Bits in Karnaugh Map and Increasing Map Capability in Error  Correcting", "abstract": "To provide reliable communication in data transmission, ability of correcting errors is of prime importance. This paper intends to suggest an easy algorithm to detect and correct errors in transmission codes using the well-known Karnaugh map. Referring to past research done and proving new theorems and also using a suggested simple technique taking advantage of the easy concept of Karnaugh map, we offer an algorithm to reduce the number of occupied squares in the map and therefore, reduce substantially the execution time for placing data bits in Karnaugh map. Based on earlier papers, we first propose an algorithm for correction of two simultaneous errors in a code. Then, defining specifications for empty squares of the map, we limit the choices for selection of new squares. In addition, burst errors in sending codes is discussed, and systematically code words for correcting them will be made.", "subjects": "Information Theory (cs.IT)", "authors": "Pouya Pezeshkpour, Mahmoud Tabandeh,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1502.02245", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02245", "title": "\nRestricted Isometry Property of Subspace Projection Matrix Under Random  Compression", "abstract": "Structures play a significant role in the field of signal processing. As a representative of structural data, low rank matrix along with its restricted isometry property (RIP) has been an important research topic in compressive signal processing. Subspace projection matrix is a kind of low rank matrix with additional structure, which allows for further reduction of its intrinsic dimension. This leaves room for improving its own RIP, which could work as the foundation of compressed subspace projection matrix recovery. In this work, we study the RIP of subspace projection matrix under random orthonormal compression. Considering the fact that subspace projection matrices of dimensional subspaces in form an dimensional submanifold in , our main concern is transformed to the stable embedding of such submanifold into . The result is that by number of random measurements the RIP of subspace projection matrix is guaranteed.", "subjects": "Information Theory (cs.IT)", "authors": "Xinyue Shen, Yuantao Gu,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1502.02242", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02242", "title": "\nPath Results for Context-free Grammar Queries on Graphs", "abstract": "Graph query languages often use regular expressions for navigation. Traditionally, these regular expressions evaluate to binary relations on nodes, where each node pair in the resulting relation is connected by a path whose labeling is accepted by the regular expression. Recent work generalized this usage of regular expressions to context-free grammars, while keeping efficient query evaluation algorithms under the traditional relational semantics. We believe that the relational semantics is limiting: node relations only indicate that nodes in the graph are connected in some way, this without telling how these connections can be established and, hence, only providing limited insight in the structure of the graph. To address the limits of the relational semantics, we propose two path-based semantics for evaluating context-free grammars on graphs: evaluating context-free grammars to the set of all paths whose labeling is accepted by the context-free grammar, and to a single path whose labeling is accepted by the context-free grammar. For both path-based semantics we introduce query evaluation algorithms. The algorithm we propose for the single path semantics guarantees that this path is the shortest possible path. As this shortest path algorithm places high demands on the hardware, we also propose a less demanding approximation algorithm that only guarantees that the length of the produced path is upper bounded. All proposed algorithms have polynomial complexity in terms of the size of the context-free grammar and the graph. We show practical viability of the algorithms via performance measurements on an implementation.", "subjects": "Databases (cs.DB)", "authors": "Jelle Hellings,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1502.02239", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02239", "title": "\nA High-Performance Solid-State Disk with Double-Data-Rate NAND Flash  Memory", "abstract": "We propose a novel solid-state disk (SSD) architecture that utilizes a double-data-rate synchronous NAND flash interface for improving read and write performance. Unlike the conventional design, the data transfer rate in the proposed design is doubled in harmony with synchronous signaling. The new architecture does not require any extra pins with respect to the conventional architecture, thereby guaranteeing backward compatibility. For performance evaluation, we simulated various SSD designs that adopt the proposed architecture and measured their performance in terms of read/write bandwidths and energy consumption. Both NAND flash cell types, namely single-level cells (SLCs) and multi-level cells (MLCs), were considered. In the experiments using SLC-type NAND flash chips, the read and write speeds of the proposed architecture were 1.65-2.76 times and 1.09-2.45 times faster than those of the conventional architecture, respectively. Similar improvements were observed for the MLC-based architectures tested. It was particularly effective to combine the proposed architecture with the way-interleaving technique that multiplexes the data channel between the controller and each flash chip. For a reasonably high degree of way interleaving, the read/write performance and the energy consumption of our approach were notably better than those of the conventional design.", "subjects": "Hardware Architecture (cs.AR)", "authors": "Eui-Young Chung, Chang-Il Son, Kwanhu Bang, Dong Kim, Soong-Mann Shin, Sungroh Yoon,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1502.02236", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02236", "title": "\nFRAME: Fast and Realistic Attacker Modeling and Evaluation for Temporal  Logical Correlation in Static Noise", "abstract": "We propose a method called Fast and Realistic Attacker Modeling and Evaluation (FRAME) that can reduce pessimism in static noise analysis by exploiting temporal logical correlation of attackers and using novel techniques termed envelopes and functions. Unlike conventional pruning-based approaches, FRAME efficiently considers all relevant attackers, thereby producing more realistic results. FRAME was tested with complex industrial design and successfully reduced the pessimism of conventional techniques by 30.4% on average, with little computational overhead.", "subjects": "Other Computer Science (cs.OH)", "authors": "Sungroh Yoon, Nahmsuk Oh, Peivand Tehrani, Eui-Young Chung, Giovanni De Micheli,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1502.02234", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02234", "title": "\nLineSwitch: Efficiently Managing Switch Flow in Software-Defined  Networking while Effectively Tackling DoS Attacks", "abstract": "Software Defined Networking (SDN) is a new networking architecture which aims to provide better decoupling between network control (control plane) and data forwarding functionalities (data plane). This separation introduces several benefits, such as a directly programmable and (virtually) centralized network control. However, researchers showed that the required communication channel between the control and data plane of SDN creates a potential bottleneck in the system, introducing new vulnerabilities. Indeed, this behavior could be exploited to mount powerful attacks, such as the control plane saturation attack, that can severely hinder the performance of the whole network. In this paper we present LineSwitch, an efficient and effective solution against control plane saturation attack. LineSwitch combines SYN proxy techniques and probabilistic blacklisting of network traffic. We implemented LineSwitch as an extension of OpenFlow, the current reference implementation of SDN, and evaluate our solution considering different traffic scenarios (with and without attack). The results of our preliminary experiments confirm that, compared to the state-of-the-art, LineSwitch reduces the time overhead up to 30%, while ensuring the same level of protection.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Moreno Ambrosin, Mauro Conti, Fabio De Gaspari, Radha Poovendran,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1502.02233", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02233", "title": "\nHierarchical Dirichlet process for tracking complex topical structure  evolution and its application to autism research literature", "abstract": "In this paper we describe a novel framework for the discovery of the topical content of a data corpus, and the tracking of its complex structural changes across the temporal dimension. In contrast to previous work our model does not impose a prior on the rate at which documents are added to the corpus nor does it adopt the Markovian assumption which overly restricts the type of changes that the model can capture. Our key technical contribution is a framework based on (i) discretization of time into epochs, (ii) epoch-wise topic discovery using a hierarchical Dirichlet process-based model, and (iii) a temporal similarity graph which allows for the modelling of complex topic changes: emergence and disappearance, evolution, and splitting and merging. The power of the proposed framework is demonstrated on the medical literature corpus concerned with the autism spectrum disorder (ASD) - an increasingly important research subject of significant social and healthcare importance. In addition to the collected ASD literature corpus which we will make freely available, our contributions also include two free online tools we built as aids to ASD researchers. These can be used for semantically meaningful navigation and searching, as well as knowledge discovery from this large and rapidly growing corpus of literature.", "subjects": "Information Retrieval (cs.IR)", "authors": "Adham Beykikhoshk, Ognjen Arandjelovic, Dinh Phung, Svetha Venkatesh,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1502.02226", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02226", "title": "\nDispersing Instant Social Video Service Across Multiple Clouds", "abstract": "Instant social video sharing which combines the online social network and user-generated short video streaming services, has become popular in today's Internet. Cloud-based hosting of such instant social video contents has become a norm to serve the increasing users with user-generated contents. A fundamental problem of cloud-based social video sharing service is that users are located globally, who cannot be served with good service quality with a single cloud provider. In this paper, we investigate the feasibility of dispersing instant social video contents to multiple cloud providers. The challenge is that inter-cloud social emph is indispensable with such multi-cloud social video hosting, yet such inter-cloud traffic incurs substantial operational cost. We analyze and formulate the multi-cloud hosting of an instant social video system as an optimization problem. We conduct large-scale measurement studies to show the characteristics of instant social video deployment, and demonstrate the trade-off between satisfying users with their ideal cloud providers, and reducing the inter-cloud data propagation. Our measurement insights of the social propagation allow us to propose a heuristic algorithm with acceptable complexity to solve the optimization problem, by partitioning a propagation-weighted social graph in two phases: a preference-aware initial cloud provider selection and a propagation-aware re-hosting. Our simulation experiments driven by real-world social network traces show the superiority of our design.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Zhi Wang, Baochun Li, Lifeng Sun, Wenwu Zhu, Shiqiang Yang,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1502.02218", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02218", "title": "\nUniversal channel coding for exponential family of channels", "abstract": "We propose a universal channel coding when each output distribution forms an exponential family even in a continuous output system. We propose two types of universal codes; One has the exponentially decreasing error with explicit a lower bound for the error exponent. The other attains the -capacity up to the second order. Our encoder is the same as the previous paper [CMP , 1087]. For our decoding process, we invent -R 'nyi divergence version of Clarke and Barron's formula for Bayesian average distribution, which are not required in the previous paper. Combing this formula and the information spectrum method, we propose our universal decoder. Our method enables us to treat a universal code of the continuous and discrete cases in a unified way with the second order coding rate as well as with the exponential decreasing rate.", "subjects": "Information Theory (cs.IT)", "authors": "Masahito Hayashi,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1502.02215", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02215", "title": "\nReal World Applications of Machine Learning Techniques over Large Mobile  Subscriber Datasets", "abstract": "Communication Service Providers (CSPs) are in a unique position to utilize their vast transactional data assets generated from interactions of subscribers with network elements as well as with other subscribers. CSPs could leverage its data assets for a gamut of applications such as service personalization, predictive offer management, loyalty management, revenue forecasting, network capacity planning, product bundle optimization and churn management to gain significant competitive advantage. However, due to the sheer data volume, variety, velocity and veracity of mobile subscriber datasets, sophisticated data analytics techniques and frameworks are necessary to derive actionable insights in a useable timeframe. In this paper, we describe our journey from a relational database management system (RDBMS) based campaign management solution which allowed data scientists and marketers to use hand-written rules for service personalization and targeted promotions to a distributed Big Data Analytics platform, capable of performing large scale machine learning and data mining to deliver real time service personalization, predictive modelling and product optimization. Our work involves a careful blend of technology, processes and best practices, which facilitate man-machine collaboration and continuous experimentation to derive measurable economic value from data. Our platform has a reach of more than 500 million mobile subscribers worldwide, delivering over 1 billion personalized recommendations annually, processing a total data volume of 64 Petabytes, corresponding to 8.5 trillion events.", "subjects": "Learning (cs.LG)", "authors": "Jobin Wilson, Chitharanj Kachappilly, Rakesh Mohan, Prateek Kapadia, Arun Soman, Santanu Chaudhury,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1502.02206", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02206", "title": "\nLearning to Search Better Than Your Teacher", "abstract": "Methods for learning to search for structured prediction typically imitate a reference policy, with existing theoretical guarantees demonstrating low regret compared to that reference. This is unsatisfactory in many applications where the reference policy is suboptimal and the goal of learning is to improve upon it. Can learning to search work even when the reference is poor? We provide a new learning to search algorithm, LOLS, which does well relative to the reference policy, but additionally guarantees low regret compared to deviations from the learned policy: a local-optimality guarantee. Consequently, LOLS can improve upon the reference policy, unlike previous algorithms. This enables us to develop structured contextual bandits, a partial information structured prediction setting with many potential applications.", "subjects": "Learning (cs.LG)", "authors": "Kai-Wei Chang, Akshay Krishnamurthy, Alekh Agarwal, Hal Daum\u00e9 III, John Langford,", "date": "2015-2-8"}, 
{"urllink": "http://arxiv.org/abs/1502.02193", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02193", "title": "\nThe Silver Lining Around Fearful Living", "abstract": "This paper discusses in layperson's terms human and computational studies of the impact of threat and fear on exploration and creativity. A first study showed that both killifish from a lake with predators and from a lake without predators explore a new environment to the same degree and plotting number of new spaces covered over time generates a hump-shaped curve. However, for the fish from the lake with predators the curve is shifted to the right; they take longer. This pattern was replicated by a computer model of exploratory behavior varying only one parameter, the fear parameter. A second study showed that stories inspired by threatening photographs were rated as more creative than stories inspired by non-threatening photographs. Various explanations for the findings are discussed.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Liane Gabora,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02191", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02191", "title": "\nCollective decision efficiency and optimal voting mechanisms: A  comprehensive overview for multi-classifier models", "abstract": "A new game-theoretic approach for combining multiple classifiers is proposed. A short introduction in Game Theory and coalitions illustrate the way any collective decision scheme can be viewed as a competitive game of coalitions that are formed naturally when players state their preferences. The winning conditions and the voting power of each player are studied under the scope of voting power indices, as well and the collective competence of the group. Coalitions and power indices are presented in relation to the Condorcet criterion of optimality in voting systems, and weighted Borda count models are asserted as a way to implement them in practice. A special case of coalition games, the weighted majority games (WMG) are presented as a restricted realization in dichotomy choice situations. As a result, the weighted majority rules (WMR), an extended version of the simple majority rules, are asserted as the theoretically optimal and complete solution to this type of coalition gaming. Subsequently, a generalized version of WMRs is suggested as the means to design a voting system that is optimal in the sense of both the correct classification criterion and the Condorcet efficiency criterion. In the scope of Pattern Recognition, a generalized risk-based approach is proposed as the framework upon which any classifier combination scheme can be applied. A new fully adaptive version of WMRs is proposed as a statistically invariant way of adjusting the design process of the optimal WMR to the arbitrary non-symmetrical properties of the underlying feature space. SVM theory is associated with properties and conclusions that emerge from the game-theoretic approach of the classification in general, while the theoretical and practical implications of employing SVM experts in WMR combination schemes are briefly discussed. Finally, a summary of the most important issues for further research is presented.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Harris V. Georgiou,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02188", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02188", "title": "\nEntropy-power inequality for weighted entropy", "abstract": "We analyse an analog of the entropy-power inequality for the weighted entropy.", "subjects": "Information Theory (cs.IT)", "authors": "Yuri Suhov, Salimeh Yasaei Sekeh, Mark Kelbert,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02182", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02182", "title": "\nComparison of Algorithms for Compressed Sensing of Magnetic Resonance  Images", "abstract": "Magnetic resonance imaging (MRI) is an essential medical tool with inherently slow data acquisition process. Slow acquisition process requires patient to be long time exposed to scanning apparatus. In recent years significant efforts are made towards the applying Compressive Sensing technique to the acquisition process of MRI and biomedical images. Compressive Sensing is an emerging theory in signal processing. It aims to reduce the amount of acquired data required for successful signal reconstruction. Reducing the amount of acquired image coefficients leads to lower acquisition time, i.e. time of exposition to the MRI apparatus. Using optimization algorithms, satisfactory image quality can be obtained from the small set of acquired samples. A number of optimization algorithms for the reconstruction of the biomedical images is proposed in the literature. In this paper, three commonly used optimization algorithms are compared and results are presented on the several MRI images.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Jelena Badnjar,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02179", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02179", "title": "\nOptimal Multiuser Scheduling Schemes for Simultaneous Wireless  Information and Power Transfer", "abstract": "In this paper, we study the downlink multiuser scheduling problem for systems with simultaneous wireless information and power transfer (SWIPT). We design optimal scheduling algorithms that maximize the long-term average system throughput under different fairness requirements, such as proportional fairness and equal throughput fairness. In particular, the algorithm designs are formulated as non-convex optimization problems which take into account the minimum required average sum harvested energy in the system. The problems are solved by using convex optimization techniques and the proposed optimization framework reveals the tradeoff between the long-term average system throughput and the sum harvested energy in multiuser systems with fairness constraints. Simulation results demonstrate that substantial performance gains can be achieved by the proposed optimization framework compared to existing suboptimal scheduling algorithms from the literature.", "subjects": "Information Theory (cs.IT)", "authors": "Maryna Chynonova, Rania Morsi, Derrick Wing Kwan Ng, Robert Schober,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02178", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02178", "title": "\nOn the Greedy Algorithm for Combinatorial Auctions with a Random Order", "abstract": "In this note we study the greedy algorithm for combinatorial auctions with submodular bidders. It is well known that this algorithm provides an approximation ratio of for every order of the items. We show that if the valuations are vertex cover functions and the order is random then the expected approximation ratio imrpoves to .", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Shahar Dobzinski, Ami Mor,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02171", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02171", "title": "\nPerson Re-identification Meets Image Search", "abstract": "For long time, person re-identification and image search are two separately studied tasks. However, for person re-identification, the effectiveness of local features and the \"query-search\" mode make it well posed for image search techniques. In the light of recent advances in image search, this paper proposes to treat person re-identification as an image search problem. Specifically, this paper claims two major contributions. 1) By designing an unsupervised Bag-of-Words representation, we are devoted to bridging the gap between the two tasks by integrating techniques from image search in person re-identification. We show that our system sets up an effective yet efficient baseline that is amenable to further supervised/unsupervised improvements. 2) We contribute a new high quality dataset which uses DPM detector and includes a number of distractor images. Our dataset reaches closer to realistic settings, and new perspectives are provided. Compared with approaches that rely on feature-feature match, our method is faster by over two orders of magnitude. Moreover, on three datasets, we report competitive results compared with the state-of-the-art methods.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Liang Zheng, Liyue Shen, Lu Tian, Shengjin Wang, Jiahao Bu, Qi Tian,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02168", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02168", "title": "\nMultilayer Hadamard Decomposition of Discrete Hartley Transforms", "abstract": "Discrete transforms such as the discrete Fourier transform (DFT) or the discrete Hartley transform (DHT) furnish an indispensable tool in signal processing. The successful application of transform techniques relies on the existence of the so-called fast transforms. In this paper some fast algorithms are derived which meet the lower bound on the multiplicative complexity of the DFT/DHT. The approach is based on a decomposition of the DHT into layers of Walsh-Hadamard transforms. In particular, fast algorithms for short block lengths such as are presented.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "H. M. de Oliveira, R. J. Cintra, R. M. Campello de Souza,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02160", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02160", "title": "\nA Survey on Hough Transform, Theory, Techniques and Applications", "abstract": "For more than half a century, the Hough transform is ever-expanding for new frontiers. Thousands of research papers and numerous applications have evolved over the decades. Carrying out an all-inclusive survey is hardly possible and enormously space-demanding. What we care about here is emphasizing some of the most crucial milestones of the transform. We describe its variations elaborating on the basic ones such as the line and circle Hough transforms. The high demand for storage and computation time is clarified with different solution approaches. Since most uses of the transform take place on binary images, we have been concerned with the work done directly on gray or color images. The myriad applications of the standard transform and its variations have been classified highlighting the up-to-date and the unconventional ones. Due to its merits such as noise-immunity and expandability, the transform has an excellent history, and a bright future as well.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Allam Shehata Hassanein, Sherien Mohammad, Mohamed Sameer, Mohammad Ehab Ragab,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02158", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02158", "title": "\nLearning Parametric-Output HMMs with Two Aliased States", "abstract": "In various applications involving hidden Markov models (HMMs), some of the hidden states are aliased, having identical output distributions. The minimality, identifiability and learnability of such aliased HMMs have been long standing problems, with only partial solutions provided thus far. In this paper we focus on parametric-output HMMs, whose output distributions come from a parametric family, and that have exactly two aliased states. For this class, we present a complete characterization of their minimality and identifiability. Furthermore, for a large family of parametric output distributions, we derive computationally efficient and statistically consistent algorithms to detect the presence of aliasing and learn the aliased HMM transition and emission parameters. We illustrate our theoretical analysis by several simulations.", "subjects": "Learning (cs.LG)", "authors": "Roi Weiss, Boaz Nadler,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02155", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02155", "title": "\nSecretary Problems with Non-Uniform Arrival Order", "abstract": "For many online problems, it is known that the uniform arrival order enables the design of algorithms with much better performance guarantees than under worst-case. The quintessential example is the secretary problem. If the sequence of elements is presented in uniformly random order there is an algorithm that picks the maximum value with probability 1/e, whereas no non-trivial performance guarantee is possible if the elements arrive in worst-case order. This work initiates an investigation into relaxations of the random-ordering hypothesis in online algorithms, by focusing on the secretary problems. We present two sets of properties of distributions over permutations as sufficient conditions, called the block-independence property and uniform-induced-ordering property. We show these two are asymptotically equivalent by borrowing some techniques from the approximation theory. Moreover, we show they both imply the existence of secretary algorithms with constant probability of correct selection, approaching the optimal constant 1/e in the limit. We substantiate our idea by providing several constructions of distributions that satisfy block-independence. We also show that (log log n) is the minimum entropy of any permutation distribution that permits constant probability of correct selection in the secretary problem with n elements. While our block-independence condition is sufficient for constant probability of correct selection, it is not necessary; however, we present complexity-theoretic evidence that no simple necessary and sufficient criterion exists. Finally, we explore the extent to which the performance guarantees of other algorithms are preserved when one relaxes the uniform random ordering assumption, obtaining a positive result for Kleinberg's multiple-choice secretary algorithm and a negative result for the weighted bipartite matching algorithm of Korula and Pal.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Thomas Kesselheim, Robert Kleinberg, Rad Niazadeh,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02139", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02139", "title": "\nMarching Surfaces: Isosurface Approximation using G$^1$ Multi-Sided  Surfaces", "abstract": "Marching surfaces is a method for isosurface extraction and approximation based on a multi-sided patch interpolation scheme. Given a 3D grid of scalar values, an underlying curve network is formed using second order information and cubic Hermite splines. Circular arc fitting defines the tangent vectors for the Hermite curves at specified isovalues. Once the boundary curve network is formed, a loop of curves is determined for each grid cell and then interpolated with multi-sided surface patches, which are continuous at the joins. The data economy of the method and its continuity preserving properties provide an effective compression scheme, ideal for indirect volume rendering on mobile devices, or collaborating on the Internet, while enhancing visual fidelity. The use of multi-sided patches enables a more natural way to approximate the isosurfaces than using a fixed number of sides or polygons as is proposed in the literature. This assertion is supported with comparisons to the traditional Marching Cubes algorithm and other methods.", "subjects": "Graphics (cs.GR)", "authors": "Gustavo Ch\u00e1vez, Alyn Rockwood,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02137", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02137", "title": "\nA class of cyclic codes whose dual have five zeros", "abstract": "In this paper, a family of cyclic codes over whose duals have five zeros is presented, where is an odd prime. Furthermore, the weight distributions of these cyclic codes are determined.", "subjects": "Information Theory (cs.IT)", "authors": "Yan Liu, Chunlei Liu,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02135", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02135", "title": "\nSimultaneous Time-Space Upper Bounds for Certain Problems in Planar  Graphs", "abstract": "In this paper, we show that given a weighted, directed planar graph , and any , there exists a polynomial time and space algorithm that computes the shortest path between two fixed vertices in . We also consider the problem, which states that given a graph whose edges are colored either red or blue and two fixed vertices and in , is there a path from to in that alternates between red and blue edges. The problem in planar DAGs is -complete. We exhibit a polynomial time and space algorithm (for any ) for the problem in planar DAG. In the last part of this paper, we consider the problem of deciding and constructing the perfect matching present in a planar bipartite graph and also a similar problem which is to find a Hall-obstacle in a planar bipartite graph. We show the time-space bound of these two problems are same as the bound of shortest path problem in a directed planar graph.", "subjects": "Computational Complexity (cs.CC)", "authors": "Diptarka Chakraborty, Raghunath Tewari,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02134", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02134", "title": "\nPower Efficient Resource Allocation for Full-Duplex Radio Distributed  Antenna Networks", "abstract": "In this paper, we study the resource allocation algorithm design for distributed antenna multiuser networks with full-duplex (FD) radio base stations (BSs) which enable simultaneous uplink and downlink communications. The considered resource allocation algorithm design is formulated as an optimization problem taking into account the antenna circuit power consumption of the BSs and the quality of service (QoS) requirements of both uplink and downlink users. We minimize the total network power consumption by jointly optimizing the downlink beamformer, the uplink transmit power, and the antenna selection. To overcome the intractability of the resulting problem, we reformulate it as an optimization problem with decoupled binary selection variables and non-convex constraints. The reformulated problem facilitates the design of an iterative resource allocation algorithm which obtains an optimal solution based on the generalized Bender's decomposition (GBD) and serves as a benchmark scheme. Furthermore, to strike a balance between computational complexity and system performance, a suboptimal algorithm with polynomial time complexity is proposed. Simulation results illustrate that the proposed GBD based iterative algorithm converges to the global optimal solution and the suboptimal algorithm achieves a close-to-optimal performance. Our results also demonstrate the trade-off between power efficiency and the number of active transmit antennas when the circuit power consumption is taken into account. In particular, activating an exceedingly large number of antennas may not be a power efficient solution for reducing the total system power consumption. In addition, our results reveal that FD systems facilitate significant power savings compared to traditional half-duplex systems, despite the non-negligible self-interference.", "subjects": "Information Theory (cs.IT)", "authors": "Derrick Wing Kwan Ng, Yongpeng Wu, Robert Schober,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02131", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02131", "title": "\nExtracting verified decision procedures: DPLL and Resolution", "abstract": "This article is concerned with the application of the program extraction technique to a new class of problems: the synthesis of decision procedures for the classical satisfiability problem that are correct by construction. To this end, we formalize a completeness proof for the DPLL proof system and extract a SAT solver from it. When applied to a propositional formula in conjunctive normal form the program produces either a satisfying assignment or a DPLL derivation showing its unsatisfiability. We use non-computational quantifiers to remove redundant computational content from the extracted program and translate it into Haskell to improve performance. We also prove the equivalence between the resolution proof system and the DPLL proof system with a bound on the size of the resulting resolution proof. This demonstrates that it is possible to capture quantitative information about the extracted program on the proof level. The formalization is carried out in the interactive proof assistant Minlog.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Ulrich Berger, Andrew Lawrence, Fredrik Nordvall Forsberg, Monika Seisenberger,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02127", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02127", "title": "\nHyperparameter Search in Machine Learning", "abstract": "We introduce the hyperparameter search problem in the field of machine learning and discuss its main challenges from an optimization perspective. Machine learning methods attempt to build models that capture some element of interest based on given data. Most common learning algorithms feature a set of hyperparameters that must be determined before training commences. The choice of hyperparameters can significantly affect the resulting model's performance, but determining good values can be complex; hence a disciplined, theoretically sound search strategy is essential.", "subjects": "Learning (cs.LG)", "authors": "Marc Claesen, Bart De Moor,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02126", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02126", "title": "\nEfficient Cache Availability Management in Information-Centric Networks", "abstract": "In-network caching is one of the fundamental operations of Information-centric networks (ICN). The default caching strategy taken by most of the current ICN proposals is caching along--default--path, which makes popular objects to be cached redundantly across the network, resulting in a low utilization of available cache space. On the other hand, efficient use of network-wide cache space requires possible cooperation among caching routers without the use of excessive signaling burden. While most of the cache optimization efforts strive to improve the latency and the overall traffic efficiency, we have taken a different path in this work and improved the storage efficiency of the cache space so that it is utilized to its most. In this work we discuss the ICN caching problem, and propose a novel distributed architecture to efficiently use the network-wide cache storage space based on distributed caching. The proposal achieves cache retention efficiency by means of controlled traffic redirection and selective caching. We utilize the ICN mechanisms and routing protocol messages for decision making, thus reducing the overall signaling need. Our proposal achieves almost 9-fold increase in cache storage efficiency, and around 20% increase in server load reduction when compared to the classic caching methods used in contemporary ICN proposals.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Sumanta Saha, Andrey Lukyanenko, Antti Yl\u00e4-J\u00e4\u00e4ski,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02125", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02125", "title": "\nContextual Online Learning for Multimedia Content Aggregation", "abstract": "The last decade has witnessed a tremendous growth in the volume as well as the diversity of multimedia content generated by a multitude of sources (news agencies, social media, etc.). Faced with a variety of content choices, consumers are exhibiting diverse preferences for content; their preferences often depend on the context in which they consume content as well as various exogenous events. To satisfy the consumers' demand for such diverse content, multimedia content aggregators (CAs) have emerged which gather content from numerous multimedia sources. A key challenge for such systems is to accurately predict what type of content each of its consumers prefers in a certain context, and adapt these predictions to the evolving consumers' preferences, contexts and content characteristics. We propose a novel, distributed, online multimedia content aggregation framework, which gathers content generated by multiple heterogeneous producers to fulfill its consumers' demand for content. Since both the multimedia content characteristics and the consumers' preferences and contexts are unknown, the optimal content aggregation strategy is unknown a priori. Our proposed content aggregation algorithm is able to learn online what content to gather and how to match content and users by exploiting similarities between consumer types. We prove bounds for our proposed learning algorithms that guarantee both the accuracy of the predictions as well as the learning speed. Importantly, our algorithms operate efficiently even when feedback from consumers is missing or content and preferences evolve over time. Illustrative results highlight the merits of the proposed content aggregation system in a variety of settings.", "subjects": "Multimedia (cs.MM)", "authors": "Cem Tekin, Mihaela van der Schaar,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02111", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02111", "title": "\nExploiting the power of multiplicity: a holistic survey of network-layer  multipath", "abstract": "The Internet is inherently a multipath network---for an underlying network with only a single path connecting various nodes would have been debilitatingly fragile. Unfortunately, traditional Internet technologies have been designed around the restrictive assumption of a single working path between a source and a destination. The lack of native multipath support constrains network performance even as the underlying network is richly connected and has redundant multiple paths. Computer networks can exploit the power of multiplicity to unlock the inherent redundancy of the Internet. This opens up a new vista of opportunities promising increased throughput (through concurrent usage of multiple paths) and increased reliability and fault-tolerance (through the use of multiple paths in backup/ redundant arrangements). There are many emerging trends in networking that signify that the Internet's future will be unmistakably multipath, including the use of multipath technology in datacenter computing; multi-interface, multi-channel, and multi-antenna trends in wireless; ubiquity of mobile devices that are multi-homed with heterogeneous access networks; and the development and standardization of multipath transport protocols such as MP-TCP. The aim of this paper is to provide a comprehensive survey of the literature on network-layer multipath solutions. We will present a detailed investigation of two important design issues, namely the control plane problem of how to compute and select the routes, and the data plane problem of how to split the flow on the computed paths. The main contribution of this paper is a systematic articulation of the main design issues in network-layer multipath routing along with a broad-ranging survey of the vast literature on network-layer multipathing. We also highlight open issues and identify directions for future work.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Junaid Qadir, Anwaar Ali, Kok-Lim Alvin Yau, Arjuna Sathiaseelan, Jon Crowcroft,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02106", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02106", "title": "\nBuilding Robust Crowdsourcing Systems with Reputation-aware Decision  Support Techniques", "abstract": "Crowdsourcing refers to the arrangement in which contributions are solicited from a large group of unrelated people. Due to this nature, crowdsourcers (or task requesters) often face uncertainty about the workers' capabilities which, in turn, affects the quality and timeliness of the results obtained. Trust is a mechanism used by people to facilitate interactions in human societies where risk and uncertain are common. The crucial challenge to building a robust crowdsourcing system is how to make trust-aware task delegation decisions to efficiently utilize the capacities of workers (or trustee agents) to achieve high social welfare? This book presents the research addressing this challenge. It goes beyond the existing trust management research framework by removing a widespread assumption implicitly adopted by existing research: that a trustee agent can process an unlimited number of interaction requests per discrete time unit without compromising its performance as perceived by the task requesters (or truster agents). Decision support in crowdsourcing is re-formalized as a multi-agent trust game based on the principles of the Congestion Game, which is solved by two trust-aware interaction decision-making approaches: 1) the Social Welfare Optimizing approach for Reputation-aware Decision-making (SWORD) approach, and 2) the Distributed Request Acceptance approach for Fair utilization of Trustee agents (DRAFT). SWORD is designed for centralized systems, while DRAFT is designed for fully distributed systems. Theoretical analyses have shown that the social welfare produced by these two approaches can be made closer to optimal by adjusting only one key parameter. With these two approaches, the framework of research for crowdsourcing systems can be enriched to handle more realistic scenarios where workers have varied and limited capabilities.", "subjects": "Multiagent Systems (cs.MA)", "authors": "Han Yu,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02103", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02103", "title": "\nSecondary Outage Analysis of Amplify-and-Forward Cognitive Relays with  Direct Link and Primary Interference", "abstract": "The use of cognitive relays is an emerging and promising solution to overcome the problem of spectrum underutilization while achieving the spatial diversity. In this paper, we perform an outage analysis of the secondary system with amplify-and-forward relays in a spectrum sharing scenario, where a secondary transmitter communicates with a secondary destination over a direct link as well as the best relay. Specifically, under the peak power constraint, we derive a closed-form expression of the secondary outage probability provided that the primary outage probability remains below a predefined value. We also take into account the effect of primary interference on the secondary outage performance. Finally, we validate the analysis by simulation results.", "subjects": "Information Theory (cs.IT)", "authors": "Subhajit Majhi, Sanket S. Kalamkar, Adrish Banerjee,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02092", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02092", "title": "\nReflectance Hashing for Material Recognition", "abstract": "We introduce a novel method for using reflectance to identify materials. Reflectance offers a unique signature of the material but is challenging to measure and use for recognizing materials due to its high-dimensionality. In this work, one-shot reflectance is captured using a unique optical camera measuring where the pixel coordinates correspond to surface viewing angles. The reflectance has class-specific stucture and angular gradients computed in this reflectance space reveal the material class. These reflectance disks encode discriminative information for efficient and accurate material recognition. We introduce a framework called reflectance hashing that models the reflectance disks with dictionary learning and binary hashing. We demonstrate the effectiveness of reflectance hashing for material recognition with a number of real-world materials.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Hang Zhang, Kristin Dana, Ko Nishino,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02084", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02084", "title": "\nIs a global virtual currency with universal acceptance feasible ?", "abstract": "As digital goods and services become an integral part of modern day society, the demand for a standardized and ubiquitous form of digital currency increases. And it is not just about digital goods; the adoption of electronic and mobile commerce has not reached its expected level at all parts of the globe as expected. One of the main reasons behind that is the lack of a universal digital as well as virtual currency. Many countries in the world have failed to realize the potential of e-commerce, let alone m-commerce, because of rigid financial regulations and apparent disorientation &amp; gap between monetary stakeholders across borders and continents. Digital currency which is internet-based, non-banks issued and circulated within a certain range of networks has brought a significant impact on the development of e-commerce. The research and analysis of this paper would focus on the feasibility of the operation of a digital currency and its economic implications.", "subjects": "Computers and Society (cs.CY)", "authors": "Sowmyan Jegatheesan, Sabbir Ahmed, Austin Chamney, Nour El-kadri,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02081", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02081", "title": "\nTaxing the Internet - is that feasible ?", "abstract": "Governments across the globe are facing challenging times to generate more revenue because of the economic slowdown and to balance their budgets. There is a growing need to find new ways of revenue generation as spending cuts and austerity measures dont go well with most sections of the society, especially during difficult economic times. Internet Today is seen more as a necessary commodity and nobody can deny the fact that the Internet has improved peoples life in an unprecedented way than any other technology in the past.The Internet as a commodity is taxed in many countries, but the Internet usage or the transactions carried out are something thats not taxed.", "subjects": "Computers and Society (cs.CY)", "authors": "Sowmyan Jegatheesan,", "date": "2015-2-7"}, 
{"urllink": "http://arxiv.org/abs/1502.02077", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02077", "title": "\nQuantum Energy Regression using Scattering Transforms", "abstract": "We present a novel approach to the regression of quantum mechanical energies based on a scattering transform of an intermediate electron density representation. A scattering transform is a deep convolution network computed with a cascade of multiscale wavelet transforms. It possesses appropriate invariant and stability properties for quantum energy regression. This new framework removes fundamental limitations of Coulomb matrix based energy regressions, and numerical experiments give state-of-the-art accuracy over planar molecules.", "subjects": "Learning (cs.LG)", "authors": "Matthew Hirn, Nicolas Poilvert, Stephane Mallat,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.02076", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02076", "title": "\nCan Other People Make You Less Creative?", "abstract": "This paper explains in layperson's terms how an agent-based model was used to investigate the hypothesis that culture evolves more effectively when novelty-generating creative processes are tempered by imitation processes that preserve proven successful ideas. Using EVOC, an agent-based model of cultural evolution we found that (1) the optimal ratio of inventing to imitating ranged from 1:1 to 2:1 depending on the fitness function, (2) there was a trade-off between the proportion of creators to conformers and how creative the creators were, and (3) when agents in increased or decreased their creativity depending on the success of their latest creative efforts, they segregated into creators and conformers, and the mean fitness of ideas across the society was higher. It is tentatively suggested that through the unconscious use of social cues, members of a society self-organizes to achieve a balanced mix of creators and conformers.", "subjects": "Multiagent Systems (cs.MA)", "authors": "Liane Gabora,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.02065", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02065", "title": "\nParticipatory Militias: An Analysis of an Armed Movement's Online  Audience", "abstract": "Armed groups of civilians known as \"self-defense forces\" have ousted the powerful Knights Templar drug cartel from several towns in Michoacan. This militia uprising has unfolded on social media, particularly in the \"VXM\" (\"Valor por Michoacan,\" Spanish for \"Courage for Michoacan\") Facebook page, gathering more than 170,000 fans. Previous work on the Drug War has documented the use of social media for real-time reports of violent clashes. However, VXM goes one step further by taking on a pro-militia propagandist role, engaging in two-way communication with its audience. This paper presents a descriptive analysis of VXM and its audience. We examined nine months of posts, from VXM's inception until May 2014, totaling 6,000 posts by VXM administrators and more than 108,000 comments from its audience. We describe the main conversation themes, post frequency and relationships with offline events and public figures. We also characterize the behavior of VXM's most active audience members. Our work illustrates VXM's online mobilization strategies, and how its audience takes part in defining the narrative of this armed conflict. We conclude by discussing possible applications of our findings for the design of future communication technologies.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Saiph Savage, Andr\u00e9s Monroy-Hern\u00e1ndez,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.02063", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02063", "title": "\nVisual Recognition by Counting Instances: A Multi-Instance Cardinality  Potential Kernel", "abstract": "Many visual recognition problems can be approached by counting instances. To determine whether an event is present in a long internet video, one could count how many frames seem to contain the activity. Classifying the activity of a group of people can be done by counting the actions of individual people. Encoding these cardinality relationships can reduce sensitivity to clutter, in the form of irrelevant frames or individuals not involved in a group activity. Learned parameters can encode how many instances tend to occur in a class of interest. To this end, this paper develops a powerful and flexible framework to infer any cardinality relation between latent labels in a multi-instance model. Hard or soft cardinality relations can be encoded to tackle diverse levels of ambiguity. Experiments on tasks such as human activity recognition, video event detection, and video summarization demonstrate the effectiveness of using cardinality relations for improving recognition results.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Hossein Hajimirsadeghi, Wang Yan, Arash Vahdat, Greg Mori,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.02051", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02051", "title": "\nApproximating ATSP by Relaxing Connectivity", "abstract": "The standard LP relaxation of the asymmetric traveling salesman problem has been conjectured to have a constant integrality gap in the metric case. We prove this conjecture when restricted to shortest path metrics of node-weighted digraphs. Our arguments are constructive and give a constant factor approximation algorithm for these metrics. We remark that the considered case is more general than the directed analog of the special case of the symmetric traveling salesman problem for which there were recent improvements on Christofides' algorithm. The main idea of our approach is to first consider an easier problem obtained by significantly relaxing the general connectivity requirements into local connectivity conditions. For this relaxed problem, it is quite easy to give an algorithm with a guarantee of 3 on node-weighted shortest path metrics. More surprisingly, we then show that any algorithm (irrespective of the metric) for the relaxed problem can be turned into an algorithm for the asymmetric traveling salesman problem by only losing a small constant factor in the performance guarantee. This leaves open the intriguing task of designing a \"good\" algorithm for the relaxed problem on general metrics.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Ola Svensson,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.02029", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02029", "title": "\nA Quantum Production Model", "abstract": "The production system is a theoretical model of computation relevant to the artificial intelligence field allowing for problem solving procedures such as hierarchical tree search. In this work we explore some of the connections between artificial intelligence and quantum computation by presenting a model for a quantum production system. Our approach focuses on initially developing a model for a reversible production system which is a simple mapping of Bennett's reversible Turing machine. We then expand on this result in order to accommodate for the requirements of quantum computation. We present the details of how our proposition can be used alongside Grover's algorithm in order to yield a speedup comparatively to its classical counterpart. We discuss the requirements associated with such a speedup and how it compares against a similar quantum hierarchical search approach.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Lu\u00eds Tarrataca, Andreas Wichert,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.02004", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.02004", "title": "\nCasper: Debugging Null Dereferences with Ghosts and Causality Traces", "abstract": "Fixing a software error requires understanding its root cause. In this paper, we introduce \"causality traces\", crafted execution traces augmented with the information needed to reconstruct the causal chain from the root cause of a bug to an execution error. We propose an approach and a tool, called Casper, for dynamically constructing causality traces for null dereference errors. The core idea of Casper is to inject special values, called \"ghosts\", into the execution stream to construct the causality trace at runtime. We evaluate our contribution by providing and assessing the causality traces of 14 real null dereference bugs collected over six large, popular open-source projects. Over this data set, Casper builds a causality trace in less than 5 seconds.", "subjects": "Software Engineering (cs.SE)", "authors": "Benoit Cornu, Earl Barr, Lionel Seinturier, Martin Monperrus,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01996", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01996", "title": "\nWavelet based Watermarking approach in the Compressive Sensing Scenario", "abstract": "Due to the wide distribution and usage of digital media, an important issue is protection of the digital content. There is a number of algorithms and techniques developed for the digital watermarking.In this paper, the invisible image watermark procedure is considered. Watermark is created as a pseudo random sequence, embedded in the certain region of the image, obtained using Haar wavelet decomposition. Generally, the watermarking procedure should be robust to the various attacks-filtering, noise etc. Here we assume the Compressive sensing scenario as a new signal processing technique that may influence the robustness. The focus of this paper was the possibility of the watermark detection under Compressive Sensing attack with different number of available image coefficients. The quality of the reconstructed images has been evaluated using Peak Signal to Noise Ratio (PSNR).The theory is supported with experimental results.", "subjects": "Multimedia (cs.MM)", "authors": "Jelena Music, Ivan Knezevic, Edis Franca,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01993", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01993", "title": "\nMALL proof equivalence is Logspace-complete, via binary decision  diagrams", "abstract": "Proof equivalence in a logic is the problem of deciding whether two proofs are equivalent modulo a set of permutation of rules that reflects the commutative conversions of its cut-elimination procedure. As such, it is related to the question of proofnets: finding canonical representatives of equivalence classes of proofs that have good computational properties. It can also be seen as the word problem for the notion of free category corresponding to the logic. It has been recently shown that proof equivalence in MLL (the multiplicative with units fragment of linear logic) is PSPACE-complete, which rules out any low-complexity notion of proofnet for this particular logic. Since it is another fragment of linear logic for which attempts to define a fully satisfactory low-complexity notion of proofnet have not been successful so far, we study proof equivalence in MALL- (multiplicative-additive without units fragment of linear logic) and discover a situation that is totally different from the MLL case. Indeed, we show that proof equivalence in MALL- corresponds (under AC0 reductions) to equivalence of binary decision diagrams, a data structure widely used to represent and analyze boolean functions efficiently. We show these two equivalent problems to be LOGSPACE-complete, which leaves open the possibility for a complete solution to the problem of proofnets for MALL-; although the relation to binary decision diagrams hints that this is a difficult problem.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Marc Bagnol,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01986", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01986", "title": "\nCensoring for Improved Sensing Performance in Infrastructure-less  Cognitive Radio Networks", "abstract": "Censoring has been proposed to be utilized in wireless distributed detection networks with a fusion center to enhance network performance in terms of error probability in addition to the well-established energy saving gains. In this paper, we further examine the employment of censoring in infrastructure-less cognitive radio networks, where nodes employ binary consensus algorithms to take global decisions regarding a binary hypothesis test without a fusion center to coordinate such a process. We show analytically - and verify by simulations - that censoring enhances the performance of such networks in terms of error probability and convergence times. Our protocol shows performance gains up to 46.6% in terms of average error probability over its conventional counterpart, in addition to performance gains of about 48.7% in terms of average energy expenditure and savings up to 50% in incurred transmission overhead.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Mohamed Seif, Mohammed Karmoose, Moustafa Youssef,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01980", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01980", "title": "\nLow Power Analog-to-Digital Conversion in Millimeter Wave Systems:  Impact of Resolution and Bandwidth on Performance", "abstract": "The wide bandwidth and large number of antennas used in millimeter wave systems put a heavy burden on the power consumption at the receiver. In this paper, using an additive quantization noise model, the effect of analog-digital conversion (ADC) resolution and bandwidth on the achievable rate is investigated for a multi-antenna system under a receiver power constraint. Two receiver architectures, analog and digital combining, are compared in terms of performance. Results demonstrate that: (i) For both analog and digital combining, there is a maximum bandwidth beyond which the achievable rate decreases; (ii) Depending on the operating regime of the system, analog combiner may have higher rate but digital combining uses less bandwidth when only ADC power consumption is considered, (iii) digital combining may have higher rate when power consumption of all the components in the receiver front-end are taken into account.", "subjects": "Information Theory (cs.IT)", "authors": "Oner Orhan, Elza Erkip, Sundeep Rangan,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01975", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01975", "title": "\nOptimal Haplotype Assembly from High-Throughput Mate-Pair Reads", "abstract": "Humans have pairs of homologous chromosomes. The homologous pairs are almost identical pairs of chromosomes. For the most part, differences in homologous chromosome occur at certain documented positions called single nucleotide polymorphisms (SNPs). A haplotype of an individual is the pair of sequences of SNPs on the two homologous chromosomes. In this paper, we study the problem of inferring haplotypes of individuals from mate-pair reads of their genome. We give a simple formula for the coverage needed for haplotype assembly, under a generative model. The analysis here leverages connections of this problem with decoding convolutional codes.", "subjects": "Information Theory (cs.IT)", "authors": "Govinda M. Kamath, Eren \u015ea\u015fo\u011flu, David Tse,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01972", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01972", "title": "\nA Multistage Stochastic Programming Approach to the Dynamic and  Stochastic VRPTW - Extended version", "abstract": "We consider a dynamic vehicle routing problem with time windows and stochastic customers (DS-VRPTW), such that customers may request for services as vehicles have already started their tours. To solve this problem, the goal is to provide a decision rule for choosing, at each time step, the next action to perform in light of known requests and probabilistic knowledge on requests likelihood. We introduce a new decision rule, called Global Stochastic Assessment (GSA) rule for the DS-VRPTW, and we compare it with existing decision rules, such as MSA. In particular, we show that GSA fully integrates nonanticipativity constraints so that it leads to better decisions in our stochastic context. We describe a new heuristic approach for efficiently approximating our GSA rule. We introduce a new waiting strategy. Experiments on dynamic and stochastic benchmarks, which include instances of different degrees of dynamism, show that not only our approach is competitive with state-of-the-art methods, but also enables to compute meaningful offline solutions to fully dynamic problems where absolutely no a priori customer request is provided.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Michael Saint-Guillain, Yves Deville, Christine Solnon,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01968", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01968", "title": "\nOld Wine in New Skins? Revisiting the Software Architecture for IP  Network Stacks on Constrained IoT Devices", "abstract": "In this paper, we argue that existing concepts for the design and implementation of network stacks for constrained devices do not comply with the requirements of current and upcoming Internet of Things (IoT) use cases. The IoT requires not only a lightweight but also a modular network stack, based on standards. We discuss functional and non-functional requirements for the software architecture of the network stack on constrained IoT devices. Then, revisiting concepts from the early Internet as well as current implementations, we propose a future-proof alternative to existing IoT network stack architectures, and provide an initial evaluation of this proposal based on its implementation running on top of state-of-the-art IoT operating system and hardware.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Hauke Petersen, Martine Lenders, Matthias W\u00e4hlisch, Oliver Hahm, Emmanuel Baccelli,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01965", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01965", "title": "\nHow can heat maps of indexing vocabularies be utilized for information  seeking purposes?", "abstract": "The ability to browse an information space in a structured way by exploiting similarities and dissimilarities between information objects is crucial for knowledge discovery. Knowledge maps use visualizations to gain insights into the structure of large-scale information spaces, but are still far away from being applicable for searching. The paper proposes a use case for enhancing search term recommendations by heat map visualizations of co-word relation-ships taken from indexing vocabulary. By contrasting areas of different \"heat\" the user is enabled to indicate mainstream areas of the field in question more easily.", "subjects": "Information Retrieval (cs.IR)", "authors": "Peter Mutschke, Karima Haddou ou Moussa,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01964", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01964", "title": "\nMaximum Likelihood based Multihop Localization in Wireless Sensor  Networks", "abstract": "For data sets retrieved from wireless sensors to be insightful, it is often of paramount importance that the data be accurate and also location stamped. This paper describes a maximum-likelihood based multihop localization algorithm called kHopLoc for use in wireless sensor networks that is strong in both isotropic and anisotropic network deployment regions. During an initial training phase, a Monte Carlo simulation is utilized to produce multihop connection density functions. Then, sensor node locations are estimated by maximizing local likelihood functions of the hop counts to anchor nodes. Compared to other multihop localization algorithms, the proposed kHopLoc algorithm achieves higher accuracy in varying network configurations and connection link-models.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "CamLy Nguyen, Orestis Georgiou, Yusuke Doi,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01963", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01963", "title": "\nEditorial for the Proceedings of the Workshop Knowledge Maps and  Information Retrieval (KMIR2014) at Digital Libraries 2014", "abstract": "Knowledge maps are promising tools for visualizing the structure of large-scale information spaces, but still far away from being applicable for searching. The first international workshop on \"Knowledge Maps and Information Retrieval (KMIR)\", held as part of the International Conference on Digital Libraries 2014 in London, aimed at bringing together experts in Information Retrieval (IR) and knowledge mapping in order to discuss the potential of interactive knowledge maps for information seeking purposes.", "subjects": "Information Retrieval (cs.IR)", "authors": "Peter Mutschke, Philipp Mayr, Andrea Scharnhorst,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01959", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01959", "title": "\nCan Quantum Entanglement Detection Schemes Improve Search?", "abstract": "Quantum computation, in particular Grover's algorithm, has aroused a great deal of interest since it allows for a quadratic speedup to be obtained in search procedures. Classical search procedures for an element database require at most time complexity. Grover's algorithm is able to find a solution with high probability in time through an amplitude amplification scheme. In this work we draw elements from both classical and quantum computation to develop an alternative search proposal based on quantum entanglement detection schemes. In 2002, Horodecki and Ekert proposed an efficient method for direct detection of quantum entanglement. Our proposition to quantum search combines quantum entanglement detection alongside entanglement inducing operators. Grover's quantum search relies on measuring a quantum superposition after having applied a unitary evolution. We deviate from the standard method by focusing on fine-tuning a unitary operator in order to infer the solution with certainty. Our proposal sacrifices space for speed and depends on the mathematical properties of linear positive maps which have not been operationally characterized. Whether such a can be easily determined remains an open question.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Lu\u00eds Tarrataca, Andreas Wichert,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01956", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01956", "title": "\nStochastic recursive inclusions with two timescales", "abstract": "A framework is presented to analyze the asymptotic behavior of two timescale stochastic approximation algorithms that include situations where the mean fields are set-valued. The framework is a natural generalization of the one developed by Borkar. Perkins and Leslie have developed a framework for asynchronous coupled stochastic approximation algorithms with set-valued mean fields. Our framework is however more general as compared to the synchronous version of the Perkins and Leslie framework.", "subjects": "Systems and Control (cs.SY)", "authors": "Arunselvan Ramaswamy, Shalabh Bhatnagar,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01954", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01954", "title": "\nInteractive 3D Face Stylization Using Sculptural Abstraction", "abstract": "Sculptors often deviate from geometric accuracy in order to enhance the appearance of their sculpture. These subtle stylizations may emphasize anatomy, draw the viewer's focus to characteristic features of the subject, or symbolize textures that might not be accurately reproduced in a particular sculptural medium, while still retaining fidelity to the unique proportions of an individual. In this work we demonstrate an interactive system for enhancing face geometry using a class of stylizations based on visual decomposition into abstract semantic regions, which we call sculptural abstraction. We propose an interactive two-scale optimization framework for stylization based on sculptural abstraction, allowing real-time adjustment of both global and local parameters. We demonstrate this system's effectiveness in enhancing physical 3D prints of scans from various sources.", "subjects": "Graphics (cs.GR)", "authors": "Jan Jachnik, Dan B Goldman, Linjie Luo, Andrew J. Davison,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01953", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01953", "title": "\nA Generalization of the Borkar-Meyn Theorem for Stochastic Recursive  Inclusions", "abstract": "In this paper the stability theorem of Borkar and Meyn is extended to include the case when the mean field is a differential inclusion. Two different sets of sufficient conditions are presented that guarantee the stability and convergence of stochastic recursive inclusions. Our work builds on the works of Benaim, Hofbauer and Sorin as well as Borkar and Meyn. As a corollary to one of the main theorems, a natural generalization of the Borkar and Meyn Theorem follows. In addition, the original theorem of Borkar and Meyn is shown to hold under slightly relaxed assumptions. Finally, as an application to one of the main theorems we discuss a solution to the approximate drift problem.", "subjects": "Systems and Control (cs.SY)", "authors": "Arunselvan Ramaswamy, Shalabh Bhatnagar,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01951", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01951", "title": "\nTree Search and Quantum Computation", "abstract": "Traditional tree search algorithms supply a blueprint for modeling problem solving behaviour. A diverse spectrum of problems can be formulated in terms of tree search. Quantum computation, in particular Grover's algorithm, has aroused a great deal of interest since it allows for a quadratic speedup to be obtained in search procedures. In this work we consider the impact of incorporating classical search concepts alongside Grover's algorithm into a hybrid quantum search system. Some of the crucial points examined include: (1) the reverberations of contemplating the use of non-constant branching factors; (2) determining the consequences of incorporating an heuristic perspective into a quantum tree search model.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Lu\u00eds Tarrataca, Andreas Wichert,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01924", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01924", "title": "\nLow-Complexity Widely-Linear Precoding for Downlink Large-Scale MU-MISO  Systems", "abstract": "In this letter, we present a widely-linear minimum mean square error (WL-MMSE) precoding scheme employing real-valued transmit symbols for downlink large-scale multi-user multiple-input single-output (MU-MISO) systems. In contrast to the existing WL-MMSE transceivers for single-user multiple-input multiple-output (SU-MIMO) systems, which use both WL precoders and WL detectors, the proposed scheme uses WL precoding only and simple conventional detection at the user terminals (UTs). Moreover, to avoid the computational complexity associated with inversion of large matrices, we modify the WL-MMSE precoder using polynomial expansion (PE). Our simulation results show that in overloaded systems, where the number of UTs is larger than the number of base station antennas, the proposed PE WL-MMSE precoder with only a few terms in the matrix polynomial achieves a substantially higher sum rate than systems employing conventional MMSE precoding. Hence, more UTs sharing the same time/frequency resources can be served in a cell. We validate our simulation results with an analytical expression for the asymptotic sum rate which is obtained by using results from random matrix theory.", "subjects": "Information Theory (cs.IT)", "authors": "Shahram Zarei, Wolfgang Gerstacker, Robert Schober,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01916", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01916", "title": "\nA General SIMD-based Approach to Accelerating Compression Algorithms", "abstract": "Compression algorithms are important for data oriented tasks, especially in the era of Big Data. Modern processors equipped with powerful SIMD instruction sets, provide us an opportunity for achieving better compression performance. Previous research has shown that SIMD-based optimizations can multiply decoding speeds. Following these pioneering studies, we propose a general approach to accelerate compression algorithms. By instantiating the approach, we have developed several novel integer compression algorithms, called Group-Simple, Group-Scheme, Group-AFOR, and Group-PFD, and implemented their corresponding vectorized versions. We evaluate the proposed algorithms on two public TREC datasets, a Wikipedia dataset and a Twitter dataset. With competitive compression ratios and encoding speeds, our SIMD-based algorithms outperform state-of-the-art non-vectorized algorithms with respect to decoding speeds.", "subjects": "Information Retrieval (cs.IR)", "authors": "Wayne Xin Zhao, Xudong Zhang, Daniel Lemire, Dongdong Shan, Jian-Yun Nie, Hongfei Yan, Ji-Rong Wen,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01911", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01911", "title": "\nStatistical Analysis of Multi-Antenna Relay Systems and Power Allocation  Algorithms in a Relay with Partial Channel State Information", "abstract": "The performance of a dual-hop MIMO relay network is studied in this paper. The relay is assumed to have access to the statistical channel state information of its preceding and following channels and it is assumed that fading at the antennas of the relay is correlated. The cumulative density function (cdf) of the received SNR at the destination is first studied and closed-form expressions are derived for the asymptotic cases of the fully-correlated and non-correlated scenarios; moreover, the statistical characteristics of the SNR are further studied and an approximate cdf of the SNR is derived for arbitrary correlation. The cdf is a multipartite function which does not easily lend itself to further mathematical calculations, e.g., rate optimization. However, we use it to propose a simple power allocation algorithm which we call \"proportional power allocation\". The algorithm is explained in detail for the case of two antennas and three antennas at the relay and the extension of the algorithm to a relay with an arbitrary number of the antennas is discussed. Although the proposed method is not claimed to be optimal, the result is indistinguishable from the benchmark obtained using exhaustive search. The simplicity of the algorithm combined with its precision is indeed attractive from the practical point of view.", "subjects": "Information Theory (cs.IT)", "authors": "Mehdi M. Molu, Alister Burr, Norbert Goertz,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01899", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01899", "title": "\nA framework for trustworthiness assessment based on fidelity in cyber  and physical domains", "abstract": "We introduce a method for the assessment of trust for n-open systems based on a measurement of fidelity and present a prototypic implementation of a complaint architecture. We construct a MAPE loop which monitors the compliance between corresponding figures of interest in cyber- and physical domains; derive measures of the system's trustworthiness; and use them to plan and execute actions aiming at guaranteeing system safety and resilience. We conclude with a view on our future work.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Vincenzo De Florio, Giuseppe Primiero,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01887", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01887", "title": "\nA Comparison Study of Coupled and Decoupled Uplink Heterogeneous  Cellular Networks", "abstract": "The evolution of mobile cellular networks has brought great changes of network architecture. For example, heterogeneous cellular network (HetNet) and Ultra dense network (UDN) have been proposed as promising techniques for 5G systems. Dense deployment of base stations (BSs) allows a mobile user to be able to access multiple BSs. Meanwhile the unbalance between UL and DL in HetNets, such as different received SINR threshold and traffic load, etc., becomes increasingly obvious. All these factors naturally inspire us to consider decoupling of uplink and downlink in radio access network. An interesting question is that whether the decoupled uplink (UL) /downlink (DL) access (DUDA) mode outperforms traditional coupled uplink (UL)/downlink (DL) access (CUDA) mode or not, and how big is the performance difference in terms of system rate, spectrum efficiency (SE) and energy efficiency (EE), etc. in HetNets. In this paper, we aim at thoroughly comparing the performance of the two modes based on stochastic geometry theory. In our analytical model, we take into account dynamic transmit power control in UL communication. Specifically, we employ fractional power control (FPC) to model a location-dependent channel state. Numerical results reveals that DUDA mode significantly outperforms CUDA mode in system rate, SE and EE in HetNets. In addition, DUDA mode improves load balance and potential fairness for both different type BSs and associated UEs.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Lan Zhang, Feng Gang, Qin Shuang,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01885", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01885", "title": "\nLinearized Reed-Solomon codes and linearized Wenger graphs", "abstract": "A codeword is associated to a linearized polynomial. The weight distribution of the codewords is determined as the linearized polynomial varies in a family of fixed degree. There is a corresponding result on Wenger graphs from linearized polynomials.", "subjects": "Information Theory (cs.IT)", "authors": "Haode Yan, Chunlei Liu,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01880", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01880", "title": "\nA Fingerprint-based Access Control using Principal Component Analysis  and Edge Detection", "abstract": "This paper presents a novel approach for deciding on the appropriateness or not of an acquired fingerprint image into a given database. The process begins with the assembly of a training base in an image space constructed by combining Principal Component Analysis (PCA) and edge detection. Then, the parameter H, a new feature that helps in the decision making about the relevance of a fingerprint image in databases, is derived from a relationship between Euclidean and Mahalanobian distances. This procedure ends with the lifting of the curve of the Receiver Operating Characteristic (ROC), where the thresholds defined on the parameter H are chosen according to the acceptable rates of false positives and false negatives.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "E.F. Melo, H.M. de Oliveira,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01877", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01877", "title": "\nOn Wavelet Decomposition over Finite Fields", "abstract": "This paper introduces some foundations of wavelets over Galois fields. Standard orthogonal finite-field wavelets (FF-Wavelets) including FF-Haar and FF-Daubechies are derived. Non-orthogonal FF-wavelets such as B-spline over GF(p) are also considered. A few examples of multiresolution analysis over Finite fields are presented showing how to perform Laplacian pyramid filtering of finite block lengths sequences. An application of FF-wavelets to design spread-spectrum sequences is presented.", "subjects": "Information Theory (cs.IT)", "authors": "H.M. de Oliveira, T.H. Falk,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01872", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01872", "title": "\nComprehensive Efficient Implementations of ECC on C54xx Family of  Low-cost Digital Signal Processors", "abstract": "Resource constraints in smart devices demand an efficient cryptosystem that allows for low power and memory consumption. This has led to popularity of comparatively efficient Elliptic curve cryptog-raphy (ECC). Prior to this paper, much of ECC is implemented on re-configurable hardware i.e. FPGAs, which are costly and unfavorable as low-cost solutions. We present comprehensive yet efficient implementations of ECC on fixed-point TMS54xx series of digital signal processors (DSP). 160-bit prime field GF(p) ECC is implemented over a wide range of coordinate choices. This paper also implements windowed recoding technique to provide better execution times. Stalls in the programming are mini-mized by utilization of loop unrolling and by avoiding data dependence. Complete scalar multiplication is achieved within 50 msec in coordinate implementations, which is further reduced till 25 msec for windowed-recoding method. These are the best known results for fixed-point low power digital signal processor to date.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Yasir Malik,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01871", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01871", "title": "\nShannon and Renyi Entropy of Wavelets", "abstract": "This paper reports a new reading for wavelets, which is based on the classical 'De Broglie' principle. The wave-particle duality principle is adapted to wavelets. Every continuous basic wavelet is associated with a proper probability density, allowing defining the Shannon entropy of a wavelet. Further entropy definitions are considered, such as Jumarie or Renyi entropy of wavelets. We proved that any wavelet of the same family has the same Shannon entropy of its mother wavelet. Finally, the Shannon entropy for a few standard wavelet families is determined.", "subjects": "Information Theory (cs.IT)", "authors": "H.M. de Oliveira,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01865", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01865", "title": "\nLower Bounds for Monotone Counting Circuits", "abstract": "A -circuit counts a given multivariate polynomial f, if its values on 0-1 inputs are the same as those of f; on other inputs the circuit may output arbitrary values. Such a circuit counts the number of monomials of f evaluated to 1 by a given 0-1 input vector (with multiplicities given by their coefficients). A circuit decides if it has the same 0-1 roots as f. We first show that some multilinear polynomials can be exponentially easier to count than to compute them, and can be exponentially easier to decide than to count them. Then we give general lower bounds on the size of counting circuits.", "subjects": "Computational Complexity (cs.CC)", "authors": "Stasys Jukna,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01861", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01861", "title": "\nIndexing arbitrary-length $k$-mers in sequencing reads", "abstract": "We propose a lightweight data structure for indexing and querying collections of NGS reads data in main memory. The data structure supports the interface proposed in the pioneering work by Philippe et al. for counting and locating -mers in sequencing reads. Our solution, PgSA (pseudogenome suffix array), based on finding overlapping reads, is competitive to the existing algorithms in the space use, query times, or both. The main applications of our index include variant calling, error correction and analysis of reads from RNA-seq experiments.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Tomasz Kowalski, Szymon Grabowski, Sebastian Deorowicz,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01853", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01853", "title": "\nGeneralized Inpainting Method for Hyperspectral Image Acquisition", "abstract": "A recently designed hyperspectral imaging device enables multiplexed acquisition of an entire data volume in a single snapshot thanks to monolithically-integrated spectral filters. Such an agile imaging technique comes at the cost of a reduced spatial resolution and the need for a demosaicing procedure on its interleaved data. In this work, we address both issues and propose an approach inspired by recent developments in compressed sensing and analysis sparse models. We formulate our superresolution and demosaicing task as a 3-D generalized inpainting problem. Interestingly, the target spatial resolution can be adjusted for mitigating the compression level of our sensing. The reconstruction procedure uses a fast greedy method called Pseudo-inverse IHT. We also show on simulations that a random arrangement of the spectral filters on the sensor is preferable to regular mosaic layout as it improves the quality of the reconstruction. The efficiency of our technique is demonstrated through numerical experiments on both synthetic and real data as acquired by the snapshot imager.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "K. Degraux, V. Cambareri, L. Jacques, B. Geelen, C. Blanch, G. Lafruit,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01852", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01852", "title": "\nDelving Deep into Rectifiers: Surpassing Human-Level Performance on  ImageNet Classification", "abstract": "Rectified activation units (rectifiers) are essential for state-of-the-art neural networks. In this work, we study rectifier neural networks for image classification from two aspects. First, we propose a Parametric Rectified Linear Unit (PReLU) that generalizes the traditional rectified unit. PReLU improves model fitting with nearly zero extra computational cost and little overfitting risk. Second, we derive a robust initialization method that particularly considers the rectifier nonlinearities. This method enables us to train extremely deep rectified models directly from scratch and to investigate deeper or wider network architectures. Based on our PReLU networks (PReLU-nets), we achieve 4.94% top-5 test error on the ImageNet 2012 classification dataset. This is a 26% relative improvement over the ILSVRC 2014 winner (GoogLeNet, 6.66%). To our knowledge, our result is the first to surpass human-level performance (5.1%, Russakovsky et al.) on this visual recognition challenge.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01838", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01838", "title": "\nDistributed Verification of Rare Properties with Lightweight Importance  Splitting Observers", "abstract": "Rare properties remain a challenge for statistical model checking due to the quadratic scaling of variance with rarity. Importance splitting can addresses this challenge, but makes demands on the encoding of the model-property product automaton. To maximise the performance of importance splitting, the user must be able to define arbitrary functions of the states of the product automaton. To distribute simulations efficiently, the product automaton must be compact and the length of its state must be small compared to the length of a simulation trace. In this work we describe an implementation of importance splitting for statistical model checking, using \"lightweight\" observers that meet the above demands. Specifically, we define an expressive bounded time logic and show how it may be compiled into compactly-described automata, whose memory requirement is only dependent on the length of the formula. We also present fixed and adaptive level importance splitting algorithms, optimised for distribution.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Cyrille Jegourel, Axel Legay, Sean Sedwards, Louis-Marie Traonouez,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01837", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01837", "title": "\nBipartite Synthesis Method applied to the Subset Sum Problem  demonstrates capability as decision and optimization tool", "abstract": "This paper introduces a deterministic algorithm for solving an instance of the Subset Sum Problem based on a new method entitled the Bipartite Synthesis Method. The algorithm is described and shown to have worst-case limiting performance over similar to the best deterministic algorithms achieving run time complexity on the order of O(2^0.5n). This algorithm is representative of a more expansive capability that might convey significant advantages over existing deterministic or probabilistic methods, and it is amenable to blending with existing methods. The method introduced can be applied to a variety of decision and optimization problems.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Scott Lilienthal,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01827", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01827", "title": "\nHierarchical Maximum-Margin Clustering", "abstract": "We present a hierarchical maximum-margin clustering method for unsupervised data analysis. Our method extends beyond flat maximum-margin clustering, and performs clustering recursively in a top-down manner. We propose an effective greedy splitting criteria for selecting which cluster to split next, and employ regularizers that enforce feature sharing/competition for capturing data semantics. Experimental results obtained on four standard datasets show that our method outperforms flat and hierarchical clustering baselines, while forming clean and semantically meaningful cluster hierarchies.", "subjects": "Learning (cs.LG)", "authors": "Guang-Tong Zhou, Sung Ju Hwang, Mark Schmidt, Leonid Sigal, Greg Mori,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01823", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01823", "title": "\nUnsupervised Fusion Weight Learning in Multiple Classifier Systems", "abstract": "In this paper we present an unsupervised method to learn the weights with which the scores of multiple classifiers must be combined in classifier fusion settings. We also introduce a novel metric for ranking instances based on an index which depends upon the rank of weighted scores of test points among the weighted scores of training points. We show that the optimized index can be used for computing measures such as average precision. Unlike most classifier fusion methods where a single weight is learned to weigh all examples our method learns instance-specific weights. The problem is formulated as learning the weight which maximizes a clarity index; subsequently the index itself and the learned weights both are used separately to rank all the test points. Our method gives an unsupervised method of optimizing performance on actual test data, unlike the well known stacking-based methods where optimization is done over a labeled training set. Moreover, we show that our method is tolerant to noisy classifiers and can be used for selecting N-best classifiers.", "subjects": "Learning (cs.LG)", "authors": "Anurag Kumar, Bhiksha Raj,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01818", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01818", "title": "\nEtude des d\u00e9terminants psychologiques de la persistance dans l'usage  d'un jeu s\u00e9rieux : \u00e9valuation de l'environnement optimal d'apprentissage  avec Mecagenius?", "abstract": "The aim of this paper is to show the relevance of motivational key concepts in evaluating the use of serious game. This research involves 115 students training with Mecagenius (serious game in mechanical engineering). The results of the exploratory study also confirm the relevance of the use of flow in Education scale (EduFlow) to evaluate the optimal learning experienc ewith a serious game. It also appears that EduFlow is related to specific actions within the school context such as self-efficacy, motivational climate and interest.", "subjects": "Other Computer Science (cs.OH)", "authors": "Jean Heutte, Michel Galaup, Catherine Lelardeux, Pierre Lagarrigue, Fabien Fenouillet,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01815", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01815", "title": "\nFog Computing: Focusing on Mobile Users at the Edge", "abstract": "With smartphones becoming our everyday companions, high-quality mobile applications have become an important integral of people's lives. The intensive and ubiquitous use of mobile applications have also led to the explosive growth of mobile data traffics. Therefore, to accommodate the surge mobile traffic yet providing the guaranteed service quality to mobile users represent a key issue of the next generation mobile networks. This motivates the emergence of Fog computing as a promising, practical and efficient solution tailored to serving mobile traffics. Fog computing deploys highly virtualized computing and communication facilities at the proximity of mobile users. Dedicated to serving the mobile users, Fog computing explores the predictable service demand patterns of mobile users and typically provides desirable localized services accordingly. Stitching above features, Fog computing can provide mobile users with the demanded services via low-latency and short-distance local connections. In this article, we outline the main features of Fog computing and describe its concept, architecture and design goals. Lastly, we discuss on the potential research issues from the networking's perspective.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Tom H. Luan, Longxiang Gao, Zhi Li, Yang Xiang, Limin Sun,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01812", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01812", "title": "\nCrowded Scene Analysis: A Survey", "abstract": "Automated scene analysis has been a topic of great interest in computer vision and cognitive science. Recently, with the growth of crowd phenomena in the real world, crowded scene analysis has attracted much attention. However, the visual occlusions and ambiguities in crowded scenes, as well as the complex behaviors and scene semantics, make the analysis a challenging task. In the past few years, an increasing number of works on crowded scene analysis have been reported, covering different aspects including crowd motion pattern learning, crowd behavior and activity analysis, and anomaly detection in crowds. This paper surveys the state-of-the-art techniques on this topic. We first provide the background knowledge and the available features related to crowded scenes. Then, existing models, popular algorithms, evaluation protocols, as well as system performance are provided corresponding to different aspects of crowded scene analysis. We also outline the available datasets for performance evaluation. Finally, some research problems and promising future directions are presented with discussions.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Teng Li, Huan Chang, Meng Wang, Bingbing Ni, Richang Hong, Shuicheng Yan,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01803", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01803", "title": "\nStrategic and Operational information support of decision making  processes and systems", "abstract": "This paper aims to present the different aspects and characteristics of strategic and operational information and propose a categorization pattern allowing to consider an information as strategic or operational. This categorization is to be used in the two decision making processes to assist its mining, and usage by the two related decision support systems. This is conducted trough the results of an investigative study of information used as basis for strategic decisions inside three different companies.", "subjects": "Computers and Society (cs.CY)", "authors": "Omar Abahmane, Mohamed Binkkour,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01802", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01802", "title": "\nOnline Convex Covering and Packing Problems", "abstract": "We study the online convex covering problem and online convex packing problem. The (offline) convex covering problem is modeled by the following convex program: , where is a monotone and convex cost function, and is an matrix with non-negative entries. Each row of the constraint matrix corresponds to a covering constraint. In the online problem, each row of comes online and the algorithm must maintain a feasible assignment and may only increase over time. The (offline) convex packing problem is modeled by the following convex program: , where is a monotone and convex cost function. It is the Fenchel dual program of convex covering when is the convex conjugate of . In the online problem, each variable arrives online and the algorithm must decide the value of on its arrival. We propose simple online algorithms for both problems using the online primal dual technique, and obtain nearly optimal competitive ratios for both problems for the important special case of polynomial cost functions. For any convex polynomial cost functions with non-negative coefficients and maximum degree , we introduce an -competitive online convex covering algorithm, and an -competitive online convex packing algorithm, matching the known and lower bounds respectively. There is a large family of online resource allocation problems that can be modeled under this online convex covering and packing framework, including online covering and packing problems (with linear objectives), online mixed covering and packing, and online combinatorial auction. Our framework allows us to study these problems using a unified approach.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "T-H. Hubert Chan, Zhiyi Huang, Ning Kang,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01801", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01801", "title": "\nBounded Verification with On-the-Fly Discrepancy Computation", "abstract": "Simulation-based verification algorithms can provide formal safety guarantees for nonlinear and hybrid systems. The previous algorithms rely on user provided model annotations called discrepancy function, which are crucial for computing reachtubes from simulations. In this paper, we eliminate this requirement by presenting an algorithm for computing piece-wise exponential discrepancy functions. The algorithm relies on computing local convergence or divergence rates of trajectories along a simulation using a coarse over-approximation of the reach set and bounding the maximal eigenvalue of the Jacobian over this over-approximation. The resulting discrepancy function preserves the soundness and the relative completeness of the verification algorithm. We also provide a coordinate transformation method to improve the local estimates for the convergence or divergence rates in practical examples. We extend the method to get the input-to-state discrepancy of nonlinear dynamical systems which can be used for compositional analysis. Our experiments show that the approach is effective in terms of running time for several benchmark problems, scales reasonably to larger dimensional systems, and compares favorably with respect to available tools for nonlinear models.", "subjects": "Systems and Control (cs.SY)", "authors": "Chuchu Fan, Sayan Mitra,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01783", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01783", "title": "\nLearning Efficient Anomaly Detectors from $K$-NN Graphs", "abstract": "We propose a non-parametric anomaly detection algorithm for high dimensional data. We score each datapoint by its average -NN distance, and rank them accordingly. We then train limited complexity models to imitate these scores based on the max-margin learning-to-rank framework. A test-point is declared as an anomaly at -false alarm level if the predicted score is in the -percentile. The resulting anomaly detector is shown to be asymptotically optimal in that for any false alarm rate , its decision region converges to the -percentile minimum volume level set of the unknown underlying density. In addition, we test both the statistical performance and computational efficiency of our algorithm on a number of synthetic and real-data experiments. Our results demonstrate the superiority of our algorithm over existing -NN based anomaly detection algorithms, with significant computational savings.", "subjects": "Learning (cs.LG)", "authors": "Jing Qian, Jonathan Root, Venkatesh Saligrama,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01782", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01782", "title": "\nMulti-Action Recognition via Stochastic Modelling of Optical Flow and  Gradients", "abstract": "In this paper we propose a novel approach to multi-action recognition that performs joint segmentation and classification. This approach models each action using a Gaussian mixture using robust low-dimensional action features. Segmentation is achieved by performing classification on overlapping temporal windows, which are then merged to produce the final result. This approach is considerably less complicated than previous methods which use dynamic programming or computationally expensive hidden Markov models (HMMs). Initial experiments on a stitched version of the KTH dataset show that the proposed approach achieves an accuracy of 78.3%, outperforming a recent HMM-based approach which obtained 71.2%.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Johanna Carvajal, Conrad Sanderson, Chris McCool, Brian C. Lovell,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01779", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01779", "title": "\nThe Number of Holes in the Union of Translates of a Convex Set in Three  Dimensions", "abstract": "We show that the union of translates of a convex body in can have holes in the worst case, where a hole in a set is a connected component of . This refutes a 20-year-old conjecture. As a consequence, we also obtain improved lower bounds on the complexity of motion planning problems and of Voronoi diagrams with convex distance functions.", "subjects": "Computational Geometry (cs.CG)", "authors": "Boris Aronov, Otfried Cheong, Michael Gene Dobbins, Xavier Goaoc,", "date": "2015-2-6"}, 
{"urllink": "http://arxiv.org/abs/1502.01763", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01763", "title": "\nRandomness of Spritz via DieHarder testing", "abstract": "RC4 is a stream cipher included in the TLS protocol, and widely used for encrypting network traffic during the last decades. Spritz is a possible candidate for replacing RC4. Spritz is based on a sponge construction and preserves the byte-oriented behaviour existing in RC4, but introduces an interface that provides encryption, hashing or MAC-generation functionalities. We present here the results obtained after applying several statistical tests on the keystreams generated by Spritz when used in the cipher mode. Our methodology makes use of 1024 keystreams of 2^25 bits. The algorithm was tested against the DieHarder test suite. None of the tests failed. Few tests produced weak results that were corrected when the number of samples increased.", "subjects": "Cryptography and Security (cs.CR)", "authors": "R\u0103zvan Ro\u015fie,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01761", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01761", "title": "\nA Framework for Symmetric Part Detection in Cluttered Scenes", "abstract": "The role of symmetry in computer vision has waxed and waned in importance during the evolution of the field from its earliest days. At first figuring prominently in support of bottom-up indexing, it fell out of favor as shape gave way to appearance and recognition gave way to detection. With a strong prior in the form of a target object, the role of the weaker priors offered by perceptual grouping was greatly diminished. However, as the field returns to the problem of recognition from a large database, the bottom-up recovery of the parts that make up the objects in a cluttered scene is critical for their recognition. The medial axis community has long exploited the ubiquitous regularity of symmetry as a basis for the decomposition of a closed contour into medial parts. However, today's recognition systems are faced with cluttered scenes, and the assumption that a closed contour exists, i.e. that figure-ground segmentation has been solved, renders much of the medial axis community's work inapplicable. In this article, we review a computational framework, previously reported in Lee et al. (2013), Levinshtein et al. (2009, 2013), that bridges the representation power of the medial axis and the need to recover and group an object's parts in a cluttered scene. Our framework is rooted in the idea that a maximally inscribed disc, the building block of a medial axis, can be modeled as a compact superpixel in the image. We evaluate the method on images of cluttered scenes.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Tom Lee, Sanja Fidler, Alex Levinshtein, Cristian Sminchisescu, Sven Dickinson,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01753", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01753", "title": "\nMonitoring Term Drift Based on Semantic Consistency in an Evolving  Vector Field", "abstract": "Based on the Aristotelian concept of potentiality vs. actuality allowing for the study of energy and dynamics in language, we propose a field approach to lexical analysis. Falling back on the distributional hypothesis to statistically model word meaning, we used evolving fields as a metaphor to express time-dependent changes in a vector space model by a combination of random indexing and evolving self-organizing maps (ESOM). To monitor semantic drifts within the observation period, an experiment was carried out on the term space of a collection of 12.8 million Amazon book reviews. For evaluation, the semantic consistency of ESOM term clusters was compared with their respective neighbourhoods in WordNet, and contrasted with distances among term vectors by random indexing. We found that at 0.05 level of significance, the terms in the clusters showed a high level of semantic consistency. Tracking the drift of distributional patterns in the term space across time periods, we found that consistency decreased, but not at a statistically significant level. Our method is highly scalable, with interpretations in philosophy.", "subjects": "Computation and Language (cs.CL)", "authors": "Peter Wittek, S\u00e1ndor Dar\u00e1nyi, Efstratios Kontopoulos, Theodoros Moysiadis, Ioannis Kompatsiaris,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01733", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01733", "title": "\nArrhythmia Detection using Mutual Information-Based Integration Method", "abstract": "The aim of this paper is to propose an application of mutual information-based ensemble methods to the analysis and classification of heart beats associated with different types of Arrhythmia. Models of multilayer perceptrons, support vector machines, and radial basis function neural networks were trained and tested using the MIT-BIH arrhythmia database. This research brings a focus to an ensemble method that, to our knowledge, is a novel application in the area of ECG Arrhythmia detection. The proposed classifier ensemble method showed improved performance, relative to either majority voting classifier integration or to individual classifier performance. The overall ensemble accuracy was 98.25%.", "subjects": "Computational Engineering, Finance, and Science (cs.CE)", "authors": "Othman Soufan, Samer Arafat,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01710", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01710", "title": "\nText Understanding from Scratch", "abstract": "This article demontrates that we can apply deep learning to text understanding from character-level inputs all the way up to abstract text concepts, using temporal convolutional networks (ConvNets). We apply ConvNets to various large-scale datasets, including ontology classification, sentiment analysis, and text categorization. We show that temporal ConvNets can achieve astonishing performance without the knowledge of words, phrases, sentences and any other syntactic or semantic structures with regards to a human language. Evidence shows that our models can work for both English and Chinese.", "subjects": "Learning (cs.LG)", "authors": "Xiang Zhang, Yann LeCun,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01708", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01708", "title": "\nAggregation and Trunking of M2M Traffic via D2D Connections", "abstract": "Machine-to-Machine (M2M) communications is one of the key enablers of the Internet of Things (IoT). Billions of devices are expected to be deployed in the next future for novel M2M applications demanding ubiquitous access and global connectivity. In order to cope with the massive number of machines, there is a need for new techniques to coordinate the access and allocate the resources. Although the majority of the proposed solutions are focused on the adaptation of the traditional cellular networks to the M2M traffic patterns, novel approaches based on the direct communication among nearby devices may represent an effective way to avoid access congestion and cell overload. In this paper, we propose a new strategy inspired by the classical Trunked Radio Systems (TRS), exploiting the Device-to-Device (D2D) connectivity between cellular users and Machine-Type Devices (MTDs). The aggregation of the locally generated packets is performed by a user device, which aggregates the machine-type data, supplements it with its own data and transmits all of them to the Base Station. We observe a fundamental trade-off between latency and the transmit power needed to deliver the aggregate traffic, in a sense that lower latency requires increase in the transmit power.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Giovanni Rigazzi, Nuno K. Pratas, Petar Popovski, Romano Fantacci,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01707", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01707", "title": "\nCS reconstruction of the speech and musical signals", "abstract": "The application of Compressive sensing approach to the speech and musical signals is considered in this paper. Compressive sensing (CS) is a new approach to the signal sampling that allows signal reconstruction from a small set of randomly acquired samples. This method is developed for the signals that exhibit the sparsity in a certain domain. Here we have observed two sparsity domains: discrete Fourier and discrete cosine transform domain. Furthermore, two different types of audio signals are analyzed in terms of sparsity and CS performance - musical and speech signals. Comparative analysis of the CS reconstruction using different number of signal samples is performed in the two domains of sparsity. It is shown that the CS can be successfully applied to both, musical and speech signals, but the speech signals are more demanding in terms of the number of observations. Also, our results show that discrete cosine transform domain allows better reconstruction using lower number of observations, compared to the Fourier transform domain, for both types of signals.", "subjects": "Sound (cs.SD)", "authors": "Trifun Savic, Radoje Albijanic,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01705", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01705", "title": "\nA Confident Information First Principle for Parametric Reduction and  Model Selection of Boltzmann Machines", "abstract": "Typical dimensionality reduction (DR) methods are often data-oriented, focusing on directly reducing the number of random variables (features) while retaining the maximal variations in the high-dimensional data. In unsupervised situations, one of the main limitations of these methods lies in their dependency on the scale of data features. This paper aims to address the problem from a new perspective and considers model-oriented dimensionality reduction in parameter spaces of binary multivariate distributions. Specifically, we propose a general parameter reduction criterion, called Confident-Information-First (CIF) principle, to maximally preserve confident parameters and rule out less confident parameters. Formally, the confidence of each parameter can be assessed by its contribution to the expected Fisher information distance within the geometric manifold over the neighbourhood of the underlying real distribution. We then revisit Boltzmann machines (BM) from a model selection perspective and theoretically show that both the fully visible BM (VBM) and the BM with hidden units can be derived from the general binary multivariate distribution using the CIF principle. This can help us uncover and formalize the essential parts of the target density that BM aims to capture and the non-essential parts that BM should discard. Guided by the theoretical analysis, we develop a sample-specific CIF for model selection of BM that is adaptive to the observed samples. The method is studied in a series of density estimation experiments and has been shown effective in terms of the estimate accuracy.", "subjects": "Learning (cs.LG)", "authors": "Xiaozhao Zhao, Yuexian Hou, Dawei Song, Wenjie Li,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01699", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01699", "title": "\nGraph invariants for unique localizability in cooperative localization  of wireless sensor networks: rigidity index and redundancy index", "abstract": "Rigidity theory enables us to specify the conditions of unique localizability in the cooperative localization problem of wireless sensor networks. This paper presents a combinatorial rigidity approach to measure (i) generic rigidity and (ii) generalized redundant rigidity properties of graph structures through graph invariants for the localization problem in wireless sensor networks. We define the rigidity index as a graph invariant based on independent set of edges in the rigidity matroid. It has a value between 0 and 1, and it indicates how close we are to rigidity. Redundant rigidity is required for global rigidity, which is associated with unique realization of graphs. Moreover, redundant rigidity also provides rigidity robustness in networked systems against structural changes, such as link losses. Here, we give a broader definition of redundant edge that we call the \"generalized redundant edge.\" This definition of redundancy is valid for both rigid and non-rigid graphs. Next, we define the redundancy index as a graph invariant based on generalized redundant edges in the rigidity matroid. It also has a value between 0 and 1, and it indicates the percentage of redundancy in a graph. These two indices allow us to explore the transition from non-rigidity to rigidity and the transition from rigidity to redundant rigidity. Examples on graphs are provided to demonstrate this approach. From a sensor network point of view, these two indices enable us to evaluate the effects of sensing radii of sensors on the rigidity properties of networks, which in turn, allow us to examine the localizability of sensor networks. We evaluate the required changes in sensing radii for localizability by means of the rigidity index and the redundancy index using random geometric graphs in simulations.", "subjects": "Systems and Control (cs.SY)", "authors": "Tolga Eren,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01694", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01694", "title": "\nMultidimensional Manhattan Sampling and Reconstruction", "abstract": "This paper introduces Manhattan sampling in two and higher dimensions, and proves sampling theorems. In two dimensions, Manhattan sampling, which takes samples densely along a Manhattan grid of lines, can be viewed as sampling on the union of two rectangular lattices, one dense horizontally, being a multiple of the fine spacing of the other. The sampling theorem shows that images bandlimited to the union of the Nyquist regions of the two rectangular lattices can be recovered from their Manhattan samples, and an efficient procedure for doing so is given. Such recovery is possible even though there is overlap among the spectral replicas induced by Manhattan sampling. In three and higher dimensions, there are many possible configurations for Manhattan sampling, each consisting of the union of special rectangular lattices called bi-step lattices. This paper identifies them, proves a sampling theorem showing that images bandlimited to the union of the Nyquist regions of the bi-step rectangular lattices are recoverable from Manhattan samples, and presents an efficient onion-peeling procedure for doing so. Furthermore, it develops a special representation for the bi-step lattices and an algebra with nice properties. It is also shown that the set of reconstructable images is maximal in the Landau sense. While most of the paper deals with continuous-space images, Manhattan sampling of discrete-space images is also considered, for infinite, as well as finite, support images.", "subjects": "Information Theory (cs.IT)", "authors": "Matthew A. Prelee, David L. Neuhoff,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01687", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01687", "title": "\nGraph Partitioning for Independent Sets", "abstract": "Computing maximum independent sets in graphs is an important problem in computer science. In this paper, we develop an evolutionary algorithm to tackle the problem. The core innovations of the algorithm are very natural combine operations based on graph partitioning and local search algorithms. More precisely, we employ a state-of-the-art graph partitioner to derive operations that enable us to quickly exchange whole blocks of given independent sets. To enhance newly computed offsprings we combine our operators with a local search algorithm. Our experimental evaluation indicates that we are able to outperform state-of-the-art algorithms on a variety of instances.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Sebastian Lamm, Peter Sanders, Christian Schulz,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01682", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01682", "title": "\nUse of Modality and Negation in Semantically-Informed Syntactic MT", "abstract": "This paper describes the resource- and system-building efforts of an eight-week Johns Hopkins University Human Language Technology Center of Excellence Summer Camp for Applied Language Exploration (SCALE-2009) on Semantically-Informed Machine Translation (SIMT). We describe a new modality/negation (MN) annotation scheme, the creation of a (publicly available) MN lexicon, and two automated MN taggers that we built using the annotation scheme and lexicon. Our annotation scheme isolates three components of modality and negation: a trigger (a word that conveys modality or negation), a target (an action associated with modality or negation) and a holder (an experiencer of modality). We describe how our MN lexicon was semi-automatically produced and we demonstrate that a structure-based MN tagger results in precision around 86% (depending on genre) for tagging of a standard LDC data set. We apply our MN annotation scheme to statistical machine translation using a syntactic framework that supports the inclusion of semantic annotations. Syntactic tags enriched with semantic annotations are assigned to parse trees in the target-language training texts through a process of tree grafting. While the focus of our work is modality and negation, the tree grafting procedure is general and supports other types of semantic information. We exploit this capability by including named entities, produced by a pre-existing tagger, in addition to the MN elements produced by the taggers described in this paper. The resulting system significantly outperformed a linguistically naive baseline model (Hiero), and reached the highest scores yet reported on the NIST 2009 Urdu-English test set. This finding supports the hypothesis that both syntactic and semantic information can improve translation quality.", "subjects": "Computation and Language (cs.CL)", "authors": "Kathryn Baker, Michael Bloodgood, Bonnie J. Dorr, Chris Callison-Burch, Nathaniel W. Filardo, Christine Piatko, Lori Levin, Scott Miller,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01659", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01659", "title": "\nLearning Articulated Motions From Visual Demonstration", "abstract": "Many functional elements of human homes and workplaces consist of rigid components which are connected through one or more sliding or rotating linkages. Examples include doors and drawers of cabinets and appliances; laptops; and swivel office chairs. A robotic mobile manipulator would benefit from the ability to acquire kinematic models of such objects from observation. This paper describes a method by which a robot can acquire an object model by capturing depth imagery of the object as a human moves it through its range of motion. We envision that in future, a machine newly introduced to an environment could be shown by its human user the articulated objects particular to that environment, inferring from these \"visual demonstrations\" enough information to actuate each object independently of the user. Our method employs sparse (markerless) feature tracking, motion segmentation, component pose estimation, and articulation learning; it does not require prior object models. Using the method, a robot can observe an object being exercised, infer a kinematic model incorporating rigid, prismatic and revolute joints, then use the model to predict the object's motion from a novel vantage point. We evaluate the method's performance, and compare it to that of a previously published technique, for a variety of household objects.", "subjects": "Robotics (cs.RO)", "authors": "Sudeep Pillai, Matthew R. Walter, Seth Teller,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01657", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01657", "title": "\nBitcoin Transaction Graph Analysis", "abstract": "Bitcoins have recently become an increasingly popular cryptocurrency through which users trade electronically and more anonymously than via traditional electronic transfers. Bitcoin's design keeps all transactions in a public ledger. The sender and receiver for each transaction are identified only by cryptographic public-key ids. This leads to a common misconception that it inherently provides anonymous use. While Bitcoin's presumed anonymity offers new avenues for commerce, several recent studies raise user-privacy concerns. We explore the level of anonymity in the Bitcoin system. Our approach is two-fold: (i) We annotate the public transaction graph by linking bitcoin public keys to \"real\" people - either definitively or statistically. (ii) We run the annotated graph through our graph-analysis framework to find and summarize activity of both known and unknown users.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Michael Fleder, Michael S. Kester, Sudeep Pillai,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01653", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01653", "title": "\nIn an Uncertain World: Distributed Optimization in MIMO Systems with  Imperfect Information", "abstract": "In this paper, we introduce a distributed algorithm that optimizes the Gaussian signal covariance matrices of multi-antenna users transmitting to a common multi-antenna receiver under imperfect and possibly delayed channel state information. The algorithm is based on an extension of exponential learning techniques to a semidefinite setting and it requires the same information as distributed water-filling methods. Unlike water-filling however, the proposed matrix exponential learning (MXL) algorithm converges to the system's optimum signal covariance profile under very mild conditions on the channel uncertainty statistics; moreover, the algorithm retains its convergence properties even in the presence of user update asynchronicities, random delays and/or ergodically changing channel conditions. In particular, by properly tuning the algorithm's learning rate (or step size), the algorithm converges within a few iterations, even for large numbers of users and/or antennas per user. Our theoretical analysis is complemented by numerical simulations which illustrate the algorithm's robustness and scalability in realistic network conditions.", "subjects": "Information Theory (cs.IT)", "authors": "Panayotis Mertikopoulos, Aris L. Moustakas,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01633", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01633", "title": "\nA Concurrency-Optimal List-Based Set", "abstract": "Designing a highly concurrent data structure is an important challenge that is not easy to meet. As we show in this paper, even for a data structure as simple as a linked list used to implement the set type, the most efficient algorithms known so far may reject correct concurrent schedules. We propose a new algorithm based on a versioned try-lock that we show to achieve optimal concurrency: it only rejects concurrent schedules that violate correctness of the implemented type. We show empirically that reaching optimality does not induce a significant overhead. In fact, our implementation of the optimal algorithm outperforms both the Lazy Linked List and the Harris-Michael state-of-the-art algorithms.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Vincent Gramoli, Petr Kuznetsov, Srivatsan Ravi, Di Shang,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01632", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01632", "title": "\nA Simple Expression for Mill's Ratio of the Student's $t$-Distribution", "abstract": "I show a simple expression of the Mill's ratio of the Student's t-Distribution. I use it to prove Conjecture 1 in P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit problem. Mach. Learn., 47(2-3):235--256, May 2002.", "subjects": "Learning (cs.LG)", "authors": "Francesco Orabona,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01625", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01625", "title": "\nA Self-Compiling Android Data Obfuscation Tool", "abstract": "Smartphones are becoming more significant in storing and transferring data. However, techniques ensuring this data is not compromised after a confiscation of the device are not readily available. DroidStealth is an open source Android application which combines data encryption and application obfuscation techniques to provide users with a way to securely hide content on their smartphones. This includes hiding the application's default launch methods and providing methods such as dial-to-launch or invisible launch buttons. A novel technique provided by DroidStealth is the ability to transform its appearance to be able to hide in plain sight on devices. To achieve this, it uses self-compilation, without requiring any special permissions. This Two-Layer protection aims to protect the user and its data from casual search in various situations.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Olivier Hokke, Alex Kolpa, Joris van den Oever, Alex Walterbos, Johan Pouwelse,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01621", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01621", "title": "\n3D Channel Model in 3GPP", "abstract": "Multi-antenna techniques capable of exploiting the elevation dimension are anticipated to be an important air-interface enhancement targeted to handle the expected growth in mobile traffic. In order to enable the development and evaluation of such multi-antenna techniques, the 3rd generation partnership project (3GPP) has recently developed a 3-dimensional (3D) channel model. The existing 2-dimensional (2D) channel models do not capture the elevation channel characteristics lending them insufficient for such studies. This article describes the main components of the newly developed 3D channel model and the motivations behind introducing them. One key aspect is the ability to model channels for users located on different floors of a building (at different heights). This is achieved by capturing a user height dependency in modelling some channel characteristics including pathloss, line-of-sight (LOS) probability, etc. In general this 3D channel model follows the framework of WINNERII/WINNER+ while also extending the applicability and the accuracy of the model by introducing some height and distance dependent elevation related parameters.", "subjects": "Information Theory (cs.IT)", "authors": "Bishwarup Mondal, Timothy A. Thomas, Eugene Visotsky, Frederick W. Vook, Amitava Ghosh, Young-Han Nam, Yang Li, Charlie Zhang, Min Zhang, Qinglin Luo, Yuichi Kakishima, Koshiro Kitao,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01609", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01609", "title": "\nRobust and Effective Malware Detection through Quantitative Data Flow  Graph Metrics", "abstract": "We present a novel malware detection approach based on metrics over quantitative data flow graphs. Quantitative data flow graphs (QDFGs) model process behavior by interpreting issued system calls as aggregations of quantifiable data flows.Due to the high abstraction level we consider QDFG metric based detection more robust against typical behavior obfuscation like bogus call injection or call reordering than other common behavioral models that base on raw system calls. We support this claim with experiments on obfuscated malware logs and demonstrate the superior obfuscation robustness in comparison to detection using n-grams. Our evaluations on a large and diverse data set consisting of about 7000 malware and 500 goodware samples show an average detection rate of 98.01% and a false positive rate of 0.48%. Moreover, we show that our approach is able to detect new malware (i.e. samples from malware families not included in the training set) and that the consideration of quantities in itself significantly improves detection precision.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Tobias W\u00fcchner, Mart\u00edn Ochoa, Alexander Pretschner,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01602", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01602", "title": "\nPhantom cascades: The effect of hidden nodes on information diffusion", "abstract": "Research on information diffusion generally assumes complete knowledge of the underlying network. However, in the presence of factors such as increasing privacy awareness, restrictions on application programming interfaces (APIs) and sampling strategies, this assumption rarely holds in the real world which in turn leads to an underestimation of the size of information cascades. In this work we study the effect of hidden network structure on information diffusion processes. We characterise information cascades through activation paths traversing visible and hidden parts of the network. We quantify diffusion estimation error while varying the amount of hidden structure in five empirical and synthetic network datasets and demonstrate the effect of topological properties on this error. Finally, we suggest practical recommendations for practitioners and propose a model to predict the cascade size with minimal information regarding the underlying network.", "subjects": "Social and Information Networks (cs.SI)", "authors": "V\u00e1clav Bel\u00e1k, Afra Mashhadi, Alessandra Sala, Donn Morrison,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01567", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01567", "title": "\nOn The Weight Distribution of Fixed-Rate Raptor Codes", "abstract": "In this paper Raptor code ensembles with linear random precodes in a fixed-rate setting are considered. An expression for the average distance spectrum is derived and this expression is used to obtain the asymptotic exponent of the weight distribution. The asymptotic growth rate analysis is then exploited to develop a necessary and sufficient condition under which the fixed-rate Raptor code ensemble exhibits a strictly positive typical minimum distance.", "subjects": "Information Theory (cs.IT)", "authors": "Francisco L\u00e1zaro Blasco, Enrico Paolini, Gianluigi Liva, Gerhard Bauch,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01566", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01566", "title": "\nA Matrix Laurent Series-based Fast Fourier Transform for Blocklengths  N=4 (mod 8)", "abstract": "General guidelines for a new fast computation of blocklength 8m+4 DFTs are presented, which is based on a Laurent series involving matrices. Results of non-trivial real multiplicative complexity are presented for blocklengths N=64, achieving lower multiplication counts than previously published FFTs. A detailed description for the cases m=1 and m=2 is presented.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "H.M. de Oliveira, R.M. Campello de Souza, R.C. de Oliveira,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01556", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01556", "title": "\nPosition Paper: Provenance Data Visualisation for Neuroimaging Analysis", "abstract": "Visualisation facilitates the understanding of scientific data both through exploration and explanation of visualised data. Provenance contributes to the understanding of data by containing the contributing factors behind a result. With the significant increase in data volumes and algorithm complexity, clinical researchers are struggling with information tracking, analysis reproducibility and the verification of scientific output. Data coming from various heterogeneous sources (multiple sources with varying level of trust) in a collaborative environment adds to the uncertainty of the scientific output. Systems are required that offer provenance data capture and visualisation support for analyses. We present an account for the need to visualise provenance information in order to aid the process of verification of scientific outputs, comparison of analyses,progression and evolution of results for neuroimaging analysis.", "subjects": "Databases (cs.DB)", "authors": "Bilal Arshad, Kamran Munir, Richard McClatchey, Saad Liaquat,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01545", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01545", "title": "\nDesigning Traceability into Big Data Systems", "abstract": "Providing an appropriate level of accessibility and traceability to data or process elements (so-called Items) in large volumes of data, often Cloud-resident, is an essential requirement in the Big Data era. Enterprise-wide data systems need to be designed from the outset to support usage of such Items across the spectrum of business use rather than from any specific application view. The design philosophy advocated in this paper is to drive the design process using a so-called description-driven approach which enriches models with meta-data and description and focuses the design process on Item re-use, thereby promoting traceability. Details are given of the description-driven design of big data systems at CERN, in health informatics and in business process management. Evidence is presented that the approach leads to design simplicity and consequent ease of management thanks to loose typing and the adoption of a unified approach to Item management and usage.", "subjects": "Databases (cs.DB)", "authors": "Richard McClatchey, Andrew Branson, Jetendr Shamdasani, Zsolt Kovacs, CRISTAL-ISE Consortium,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01540", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01540", "title": "\nSemantic Embedding Space for Zero-Shot Action Recognition", "abstract": "The number of categories for action recognition is growing rapidly. It is thus becoming increasingly hard to collect sufficient training data to learn conventional models for each category. This issue may be ameliorated by the increasingly popular 'zero-shot learning' (ZSL) paradigm. In this framework a mapping is constructed between visual features and a human interpretable semantic description of each category, allowing categories to be recognised in the absence of any training data. Existing ZSL studies focus primarily on image data, and attribute-based semantic representations. In this paper, we address zero-shot recognition in contemporary video action recognition tasks, using semantic word vector space as the common space to embed videos and category labels. This is more challenging because the mapping between the semantic space and space-time features of videos containing complex actions is more complex and harder to learn. We demonstrate that a simple self-training and data augmentation strategy can significantly improve the efficacy of this mapping. Experiments on human action datasets including HMDB51 and UCF101 demonstrate that our approach achieves the state-of-the-art zero-shot action recognition performance.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Xun Xu, Timothy Hospedales, Shaogang Gong,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01539", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01539", "title": "\nScientific Workflow Repeatability through Cloud-Aware Provenance", "abstract": "The transformations, analyses and interpretations of data in scientific workflows are vital for the repeatability and reliability of scientific workflows. This provenance of scientific workflows has been effectively carried out in Grid based scientific workflow systems. However, recent adoption of Cloud-based scientific workflows present an opportunity to investigate the suitability of existing approaches or propose new approaches to collect provenance information from the Cloud and to utilize it for workflow repeatability in the Cloud infrastructure. The dynamic nature of the Cloud in comparison to the Grid makes it difficult because resources are provisioned on-demand unlike the Grid. This paper presents a novel approach that can assist in mitigating this challenge. This approach can collect Cloud infrastructure information along with workflow provenance and can establish a mapping between them. This mapping is later used to re-provision resources on the Cloud. The repeatability of the workflow execution is performed by: (a) capturing the Cloud infrastructure information (virtual machine configuration) along with the workflow provenance, and (b) re-provisioning the similar resources on the Cloud and re-executing the workflow on them. The evaluation of an initial prototype suggests that the proposed approach is feasible and can be investigated further.", "subjects": "Databases (cs.DB)", "authors": "Khawar Hasham, Kamran Munir, Jetendr Shamdasani, Richard McClatchey,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01538", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01538", "title": "\nA Hybrid Systems Model for Simple Manipulation and Self-Manipulation  Systems", "abstract": "Rigid bodies, plastic impact, persistent contact, Coulomb friction, and massless limbs are ubiquitous simplifications introduced to reduce the complexity of mechanics models despite the obvious physical inaccuracies that each incurs individually. In concert, it is well known that the interaction of such idealized approximations can lead to conflicting and even paradoxical results. As robotics modeling moves from the consideration of isolated behaviors to the analysis of tasks requiring their composition, a mathematically tractable framework for building models that combine these simple approximations with reliable results is overdue. In this paper we present a formal hybrid dynamical system model that introduces suitably restricted compositions of these familiar abstractions with the guarantee of a certain kind of consistency analogous to global existence and uniqueness in classical dynamical systems. While a real system will have continuous (though possibly very stiff and fast) dynamics through impacts, the hybrid system developed here provides a discontinuous but self--consistent approximation to the dynamics. The modeling choices sacrifice exact quantitative accuracy for qualitatively correct and analytically tractable results with certain formal guarantees.", "subjects": "Robotics (cs.RO)", "authors": "Aaron M. Johnson, Samuel A. Burden, Daniel E. Koditschek,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01526", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01526", "title": "\nObject Proposal via Partial Re-ranking", "abstract": "Object proposals are an ensemble of bounding boxes with high potential to contain objects. Usually, the ranking models are utilized in order to provide a manageable number of candidate boxes. To obtain the rank for each candidate, prior ranking models generally compare each pair of candidates. However, one may be interested in only the top- candidates rather than all ones. Thus, in this paper, we propose a new ranking model for object proposals, which aims to produce a reliable estimation for only the top- candidates. To this end, we compute the IoU for each candidate and split the candidates into two subsets consisting of the top- candidates and the others respectively. Partial ranking constraints are imposed on the two subsets: any candidate from the first subset is better than that from the second one. In this way, the constraints are reduced dramatically compared to the full ranking model, which further facilitates an efficient learning procedure. Moreover, we show that our partial ranking model can be reduced into the large margin based framework. Extensive experiments demonstrate that after a re-ranking step of our model, the top- detection rate can be significantly improved.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Jing Wang, Jie Shen,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01523", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01523", "title": "\nEfficient and Perfect domination on circular-arc graphs", "abstract": "Given a graph , a emph is a subset of vertices such that each vertex is dominated by exactly one vertex . An emph is a perfect dominating set where is also an independent set. These problems are usually posed in terms of edges instead of vertices. Both problems, either for the vertex or edge variant, remains NP-Hard, even when restricted to certain graphs families. We study both variants of the problems for the circular-arc graphs, and show efficient algorithms for all of them.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Min Chih Lin, Michel J. Mizrahi, Jayme L. Szwarcfiter,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01514", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01514", "title": "\nFacilitating Evolution during Design and Implementation", "abstract": "The volumes and complexity of data that companies need to handle are increasing at an accelerating rate. In order to compete effectively and ensure their commercial sustainability, it is becoming crucial for them to achieve robust traceability in both their data and the evolving designs of their systems. This is addressed by the CRISTAL software which was originally developed at CERN by UWE, Bristol, for one of the particle detectors at the Large Hadron Collider, and has been subsequently transferred into the commercial world. Companies have been able to demonstrate increased agility, generate additional revenue, and improve the efficiency and cost-effectiveness with which they develop and implement systems in various areas, including business process management (BPM), healthcare and accounting applications. CRISTALs ability to manage data and its provenance at the terabyte scale, with full traceability over extended timescales, together with its description-driven approach, has provided the flexible adaptability required to future proof dynamically evolving software for these businesses.", "subjects": "Software Engineering (cs.SE)", "authors": "R. McClatchey,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01509", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01509", "title": "\nOS-level Failure Injection with SystemTap", "abstract": "Failure injection in distributed systems has been an important issue to experiment with robust, resilient distributed systems. In order to reproduce real-life conditions, parts of the application must be killed without letting the operating system close the existing network communications in a \"clean\" way. When a process is simply killed, the OS closes them. SystemTap is a an infrastructure that probes the Linux kernel's internal calls. If processes are killed at kernel-level, they can be destroyed without letting the OS do anything else. In this paper, we present a kernel-level failure injection system based on SystemTap. We present how it can be used to implement deterministic and probabilistic failure scenarios.", "subjects": "Operating Systems (cs.OS)", "authors": "Camille Coti, Nicolas Greneche,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01504", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01504", "title": "\nFeedback based Reputation on top of the Bitcoin Blockchain", "abstract": "The ability to assess the reputation of a member in a web community is a need addressed in many different ways according to the many different stages in which the nature of communities has evolved over time. In the case of reputation of goods/services suppliers, the solutions available to prevent the feedback abuse are generally reliable but centralized under the control of few big Internet companies. In this paper we show how a decentralized and distributed feedback management system can be built on top of the Bitcoin blockchain", "subjects": "Cryptography and Security (cs.CR)", "authors": "Davide Carboni,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01497", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01497", "title": "\nUsing temporal abduction for biosignal interpretation: A case study on  QRS detection", "abstract": "In this work, we propose an abductive framework for biosignal interpretation, based on the concept of Temporal Abstraction Patterns. A temporal abstraction pattern defines an abstraction relation between an observation hypothesis and a set of observations constituting its evidence support. New observations are generated abductively from any subset of the evidence of a pattern, building an abstraction hierarchy of observations in which higher levels contain those observations with greater interpretative value of the physiological processes underlying a given signal. Non-monotonic reasoning techniques have been applied to this model in order to find the best interpretation of a set of initial observations, permitting even to correct these observations by removing, adding or modifying them in order to make them consistent with the available domain knowledge. Some preliminary experiments have been conducted to apply this framework to a well known and bounded problem: the QRS detection on ECG signals. The objective is not to provide a new better QRS detector, but to test the validity of an abductive paradigm. These experiments show that a knowledge base comprising just a few very simple rhythm abstraction patterns can enhance the results of a state of the art algorithm by significantly improving its detection F1-score, besides proving the ability of the abductive framework to correct both sensitivity and specificity failures.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Tom\u00e1s Teijeiro, Paulo F\u00e9lix, Jes\u00fas Presedo,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01496", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01496", "title": "\nAssisting V2V failure recovery using Device-to-Device Communications", "abstract": "This paper aims to propose a new solution for failure recovery (dead-ends) in Vehicle to Vehicle (V2V) communications through LTE-assisted Device-to-Device communications (D2D). Based on the enhanced networking capabilities offered by Intelligent Transportation Systems (ITS) architecture, our solution can efficiently assist V2V communications in failure recovery situations. We also derive an analytical model to evaluate generic V2V routing recovery failures. Moreover, the proposed hybrid model is simulated and compared to the generic model under different constrains of worst and best cases of D2D discovery and communication. According to our comparison and simulation results, the hybrid model decreases the delay for alarm message propagation to the destination (typically the Traffic Control Center TCC) through the Road Side Unit (RSU)", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Emad Abd-Elrahman, Adel Mounir Said, Thouraya Toukabri, Hossam Afifi, Michel Marot,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01494", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01494", "title": "\nCode generator matrices as entropy extractors", "abstract": "We show the connection between the Walsh spectrum of the output of a binary random number generator (RNG) and the bias of individual bits, and use this to show how previously known bounds on the performance of linear binary codes as entropy extractors can be derived by considering generator matrices as a selector of a subset of that spectrum. We explicitly show the connection with the code's weight distribution, then extend this framework to the case of non-binary finite fields by the Fourier transform.", "subjects": "Information Theory (cs.IT)", "authors": "Alessandro Tomasi, Alessio Meneghetti, Massimiliano Sala,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01485", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01485", "title": "\nEffective Resource Allocation in 5G-Satellite Networks", "abstract": "This paper addresses the radio resource management of multicast transmissions in the emerging fifth generation satellite systems (5G-Satellite). A subgrouping approach is exploited to provide video streaming services to satellite users by splitting any multicast group into subgroups. This allows an effective exploitation of multi-user diversity according to the experienced channel conditions and the achievement of a high throughput level. The main drawback is the high computational cost usually related to the selection of the optimal subgroup configuration. In this paper we propose a low-complexity subgrouping algorithm that achieves performance close to optimum. Our solution is suitable for implementation in practical systems, such as Satellite-Long Term Evolution (S-LTE), since the computational cost does not depend on the multicast group size and the number of available resources. Through simulation campaigns conducted in different radio propagation and multicast group environments, the effectiveness of the proposed subgroup formation scheme is assessed.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Giuseppe Araniti, Massimo Condoluci, Antonino Orsino, Antonio Iera, Antonella Molinaro,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01482", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01482", "title": "\nEffective RAT Selection Approach for 5G Dense Wireless Networks", "abstract": "Dense Networks (DenseNet) and Multi-Radio Access Technologies (Multi-RATs) are considered as key features of the emerging fifth generation (5G) wireless systems. A Multi-RAT DenseNet is characterized by a very dense deployment of low-power base stations (BSs) and by a multi-tier architecture consisting of heterogeneous radio access technologies. Such a network aims to guarantee high data-rates, low latency and low energy consumption. Although the usage of a Multi RAT DenseNet solves problems such as coverage holes and low performance at the cell edge, frequent and unnecessary RAT handovers may occur with a consequent high signaling load. In this work, we propose an effective RAT selection algorithm that efficiently manages the RAT handover procedure by emph choosing the most suitable RAT that guarantees high system and user performance, and emph reducing unnecessary handover events. In particular, the decision to trigger a handover is based on a new system parameter named Reference Base Station Efficiency (RBSE). This parameter takes into account metrics related to both the system and the user: the BS transmitted power, the BS traffic load and the users' spectral efficiency. We compare, by simulation, the proposed scheme with the standardized 3GPP policies. Results show that the proposed RAT selection scheme significantly reduces the number of handovers and the end-to-end delay while maintaining high system throughput and user spectral efficiency.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Antonino Orsino, Giuseppe Araniti, Antonella Molinaro, Antonio Iera,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01475", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01475", "title": "\nFast Constraint Propagation for Image Segmentation", "abstract": "This paper presents a novel selective constraint propagation method for constrained image segmentation. In the literature, many pairwise constraint propagation methods have been developed to exploit pairwise constraints for cluster analysis. However, since most of these methods have a polynomial time complexity, they are not much suitable for segmentation of images even with a moderate size, which is actually equivalent to cluster analysis with a large data size. Considering the local homogeneousness of a natural image, we choose to perform pairwise constraint propagation only over a selected subset of pixels, but not over the whole image. Such a selective constraint propagation problem is then solved by an efficient graph-based learning algorithm. To further speed up our selective constraint propagation, we also discard those less important propagated constraints during graph-based learning. Finally, the selectively propagated constraints are exploited based on -minimization for normalized cuts over the whole image. The experimental results demonstrate the promising performance of the proposed method for segmentation with selectively propagated constraints.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Peng Han,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01462", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01462", "title": "\nUnary probabilistic and quantum automata on promise problems", "abstract": "We continue the systematic investigation of probabilistic and quantum finite automata (PFAs and QFAs) on promise problems by focusing on unary languages. We show that bounded-error QFAs are more powerful than PFAs. But, in contrary to the binary problems, the computational powers of Las-Vegas QFAs and bounded-error PFAs are equivalent to deterministic finite automata (DFAs). Lastly, we present a new family of unary promise problems with two parameters such that when fixing one parameter QFAs can be exponentially more succinct than PFAs and when fixing the other parameter PFAs can be exponentially more succinct than DFAs.", "subjects": "Computational Complexity (cs.CC)", "authors": "Aida Gainutdinova, Abuzer Yakaryilmaz,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01461", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01461", "title": "\nParameterized Complexity of Superstring Problems", "abstract": "In the Shortest Superstring problem we are given a set of strings and integer and the question is to decide whether there is a superstring of length at most containing all strings of as substrings. We obtain several parameterized algorithms and complexity results for this problem. In particular, we give an algorithm which in time finds a superstring of length at most containing at least strings of . We complement this by the lower bound showing that such a parameterization does not admit a polynomial kernel up to some complexity assumption. We also obtain several results about \"below guaranteed values\" parameterization of the problem. We show that parameterization by compression admits a polynomial kernel while parameterization \"below matching\" is hard.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Ivan Bliznets, Fedor V. Fomin, Petr A. Golovach, Nikolay Karpov, Alexander S. Kulikov, Saket Saurabh,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01454", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01454", "title": "\nThe Diversity and Scale Matter: Ubiquitous Transportation Mode Detection  using Single Cell Tower Information", "abstract": "Detecting the transportation mode of a user is important for a wide range of applications. While a number of recent systems addressed the transportation mode detection problem using the ubiquitous mobile phones, these studies either leverage GPS, the inertial sensors, and/or multiple cell towers information. However, these different phone sensors have high energy consumption, limited to a small subset of phones (e.g. high-end phones or phones that support neighbouring cell tower information), cannot work in certain areas (e.g. inside tunnels for GPS), and/or work only from the user side. In this paper, we present a transportation mode detection system, MonoSense, that leverages the phone serving cell information only. The basic idea is that the phone speed can be correlated with features extracted from both the serving cell tower ID and the received signal strength from it. To achieve high detection accuracy with this limited information, MonoSense leverages diversity along multiple axes to extract novel features. Specifically, MonoSense extracts features from both the time and frequency domain information available from the serving cell tower over different sliding widow sizes. More importantly, we show also that both the logarithmic and linear RSS scales can provide different information about the movement of a phone, further enriching the feature space and leading to higher accuracy. Evaluation of MonoSense using 135 hours of cellular traces covering 485 km and collected by four users using different Android phones shows that it can achieve an average precision and recall of 89.26% and 89.84% respectively in differentiating between the stationary, walking, and driving modes using only the serving cell tower information, highlighting MonoSense ability to enable a wide set of intelligent transportation applications.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Ali Mohamed AbdelAziz, Moustafa Youssef,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01446", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01446", "title": "\nBeyond Word-based Language Model in Statistical Machine Translation", "abstract": "Language model is one of the most important modules in statistical machine translation and currently the word-based language model dominants this community. However, many translation models (e.g. phrase-based models) generate the target language sentences by rendering and compositing the phrases rather than the words. Thus, it is much more reasonable to model dependency between phrases, but few research work succeed in solving this problem. In this paper, we tackle this problem by designing a novel phrase-based language model which attempts to solve three key sub-problems: 1, how to define a phrase in language model; 2, how to determine the phrase boundary in the large-scale monolingual data in order to enlarge the training set; 3, how to alleviate the data sparsity problem due to the huge vocabulary size of phrases. By carefully handling these issues, the extensive experiments on Chinese-to-English translation show that our phrase-based language model can significantly improve the translation quality by up to +1.47 absolute BLEU score.", "subjects": "Computation and Language (cs.CL)", "authors": "Jiajun Zhang, Shujie Liu, Mu Li, Ming Zhou, Chengqing Zong,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01435", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01435", "title": "\nOptimal component labeling algorithms for mesh-connected computers and  VLSI", "abstract": "Given an undirected graph of weighted edges, stored one edge per processor in a square mesh of processors, we show how to determine the connected components and a minimal spanning forest in time. More generally, we show how to solve these problems in time when the mesh is a -dimensional cube, where the implied constants depend upon .", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Quentin F. Stout,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01424", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01424", "title": "\nClose Approximations for Daublets and their Spectra", "abstract": "This paper offers a new regard on compactly supported wavelets derived from FIR filters. Although being continuous wavelets, analytical formulation are lacking for such wavelets. Close approximations for daublets (Daubechies wavelets) and their spectra are introduced here. The frequency detection properties of daublets are investigated through scalograms derived from these new analytical expressions. These near-daublets have been implemented on the Matlab wavelet toolbox and a few scalograms presented. This approach can be valuable for wavelet synthesis from hardware or for application involving continuous wavelet-based systems, such as wavelet OFDM.", "subjects": "Numerical Analysis (cs.NA)", "authors": "V.V. Vermehren, J.E. Wesen, H.M. de Oliveira,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01423", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01423", "title": "\nCollaborative Feature Learning from Social Media", "abstract": "Image feature representation plays an essential role in image recognition and related tasks. The current state-of-the-art feature learning paradigm is supervised learning from labeled data. However, this paradigm requires large-scale category labels, which limits its applicability to domains where labels are hard to obtain. In this paper, we propose a new data-driven feature learning paradigm which does not rely on category labels. Instead, we learn from user behavior data collected on social media. Concretely, we use the image relationship discovered in the latent space from the user behavior data to guide the image feature learning. In addition, we present a new large-scale image and user behavior dataset collected on Behance.net. The dataset consists of 1.9 million images and over 300 million view records from 1.9 million users. We validate our feature learning paradigm on this new dataset and find that the learned feature significantly outperforms the state-of-the-art image features in learning better image similarities. We also show that the learned feature performs competitively on various recognition benchmarks.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Chen Fang, Hailin Jin, Jianchao Yang, Zhe Lin,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01418", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01418", "title": "\nRELEAF: An Algorithm for Learning and Exploiting Relevance", "abstract": "Recommender systems, medical diagnosis, network security, etc., require on-going learning and decision-making in real time. These -- and many others -- represent perfect examples of the opportunities and difficulties presented by Big Data: the available information often arrives from a variety of sources and has diverse features so that learning from all the sources may be valuable but integrating what is learned is subject to the curse of dimensionality. This paper develops and analyzes algorithms that allow efficient learning and decision-making while avoiding the curse of dimensionality. We formalize the information available to the learner/decision-maker at a particular time as a context vector which the learner should consider when taking actions. In general the context vector is very high dimensional, but in many settings, the most relevant information is embedded into only a few relevant dimensions. If these relevant dimensions were known in advance, the problem would be simple -- but they are not. Moreover, the relevant dimensions may be different for different actions. Our algorithm learns the relevant dimensions for each action, and makes decisions based in what it has learned. Formally, we build on the structure of a contextual multi-armed bandit by adding and exploiting a relevance relation. We prove a general regret bound for our algorithm whose time order depends only on the maximum number of relevant dimensions among all the actions, which in the special case where the relevance relation is single-valued (a function), reduces to ; in the absence of a relevance relation, the best known contextual bandit algorithms achieve regret , where is the full dimension of the context vector.", "subjects": "Learning (cs.LG)", "authors": "Cem Tekin, Mihaela van der Schaar,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01414", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01414", "title": "\nCyclic LRC Codes and their Subfield Subcodes", "abstract": "We consider linear cyclic codes with the locality property, or locally recoverable codes (LRC codes). A family of LRC codes that generalizes the classical construction of Reed-Solomon codes was constructed in a recent paper by I. Tamo and A. Barg (IEEE Transactions on Information Theory, no. 8, 2014; arXiv:1311.3284). In this paper we focus on the optimal cyclic codes that arise from the general construction. We give a characterization of these codes in terms of their zeros, and observe that there are many equivalent ways of constructing optimal cyclic LRC codes over a given field. We also study subfield subcodes of cyclic LRC codes (BCH-like LRC codes) and establish several results about their locality and minimum distance.", "subjects": "Information Theory (cs.IT)", "authors": "Itzhak Tamo, Alexander Barg, Sreechakra Goparaju, Robert Calderbank,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01410", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01410", "title": "\nA Study of \"Wheat\" and \"Chaff\" in Source Code", "abstract": "Natural language is robust against noise. The meaning of many sentences survives the loss of words, sometimes many of them. Some words in a sentence, however, cannot be lost without changing the meaning of the sentence. We call these words \"wheat\" and the rest \"chaff.\" The word \"not\" in the sentence \"I do not like rain\" is wheat and \"do\" is chaff. For human understanding of the purpose and behavior of source code, we hypothesize that the same holds. To quantify the extent to which we can separate code into \"wheat\" and \"chaff\", we study a large (100M LOC), diverse corpus of real-world projects in Java. Since methods represent natural, likely distinct units of code, we use the, approximately, 9M Java methods in the corpus to approximate a universe of \"sentences.\" We \"thresh\", or lex, functions, then \"winnow\" them to extract their wheat by computing the minimal distinguishing subset (MINSET). Our results confirm that programs contain much chaff. On average, MINSETS have 1.56 words (none exceeds 6) and comprise 4% of their methods. Beyond its intrinsic scientific interest, our work offers the first quantitative evidence for recent promising work on keyword-based programming and insight into how to develop powerful, alternative programming systems.", "subjects": "Software Engineering (cs.SE)", "authors": "Martin Velez, Dong Qiu, You Zhou, Earl T. Barr, Zhendong Su,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01403", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01403", "title": "\nDistributed Estimation of Generalized Matrix Rank: Efficient Algorithms  and Lower Bounds", "abstract": "We study the following generalized matrix rank estimation problem: given an matrix and a constant , estimate the number of eigenvalues that are greater than . In the distributed setting, the matrix of interest is the sum of matrices held by separate machines. We show that any deterministic algorithm solving this problem must communicate bits, which is order-equivalent to transmitting the whole matrix. In contrast, we propose a randomized algorithm that communicates only bits. The upper bound is matched by an lower bound on the randomized communication complexity. We demonstrate the practical effectiveness of the proposed algorithm with some numerical experiments.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Yuchen Zhang, Martin J. Wainwright, Michael I. Jordan,", "date": "2015-2-5"}, 
{"urllink": "http://arxiv.org/abs/1502.01385", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01385", "title": "\nThe recoverability limit for superresolution via sparsity", "abstract": "We consider the problem of robustly recovering a -sparse coefficient vector from the Fourier series that it generates, restricted to the interval . The difficulty of this problem is linked to the superresolution factor SRF, equal to the ratio of the Rayleigh length (inverse of ) by the spacing of the grid supporting the sparse vector. In the presence of additive deterministic noise of norm , we show upper and lower bounds on the minimax error rate that both scale like , providing a partial answer to a question posed by Donoho in 1992. The scaling arises from comparing the noise level to a restricted isometry constant at sparsity , or equivalently from comparing to the so-called -spark of the Fourier system. The proof involves new bounds on the singular values of restricted Fourier matrices, obtained in part from old techniques in complex analysis.", "subjects": "Information Theory (cs.IT)", "authors": "Laurent Demanet, Nam Nguyen,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01380", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01380", "title": "\nDifferent approaches to calibration of nonlinear mechanical models using  artificial neural networks", "abstract": "Last decades witness rapid development in numerical modelling of structures as well as materials and the complexity of models increases quickly together with their computational demands. Despite the growing performance of modern computers and clusters, calibration of such models from noisy experimental data remains a nontrivial and often computational exhaustive task. The layered neural networks thus represent a robust and efficient technique to overcome the time-consuming simulations of a calibrated model. The potential of neural networks consists in simple implementation and high versatility in approximating nonlinear relationships. Therefore, there were several approaches proposed to accelerate the calibration of nonlinear models by neural networks. This contribution reviews and compares three possible strategies based on approximating (i) model response, (ii) inverse relationship between the model response and its parameters and (iii) error function quantifying how well the model fits the data. The advantages and drawbacks of particular strategies are demonstrated on calibration of four parameters of affinity hydration model from simulated data as well as from experimental measurements. This model is highly nonlinear, but computationally cheap thus allowing its calibration without any approximation and better quantification of results obtained by the examined calibration strategies.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "Tom\u00e1\u0161 Mare\u0161, Eli\u0161ka Janouchov\u00e1, Anna Ku\u010derov\u00e1,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01377", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01377", "title": "\nThe Arithmetic Cosine Transform: Exact and Approximate Algorithms", "abstract": "In this paper, we introduce a new class of transform method --- the arithmetic cosine transform (ACT). We provide the central mathematical properties of the ACT, necessary in designing efficient and accurate implementations of the new transform method. The key mathematical tools used in the paper come from analytic number theory, in particular the properties of the Riemann zeta function. Additionally, we demonstrate that an exact signal interpolation is achievable for any block-length. Approximate calculations were also considered. The numerical examples provided show the potential of the ACT for various digital signal processing applications.", "subjects": "Numerical Analysis (cs.NA)", "authors": "R. J. Cintra, V. S. Dimitrov,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01367", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01367", "title": "\nVisualizing Marden's theorem with Scilab", "abstract": "A theorem which is named after the American Mathematician Moris Marden states a very surprising and interesting fact concerning the relationship between the points of a triangle in the complex plane and the zeros of two complex polynomials related to this triangle: \"Suppose the zeroes z1, z2, and z3 of a third-degree polynomial p(z) are non-collinear. There is a unique ellipse inscribed in the triangle with vertices z1, z2, z3 and tangent to the sides at their midpoints: the Steiner in-ellipse. The foci of that ellipse are the zeroes of the derivative p'(z).\" (Wikipedia contributors, \"Marden's theorem\", this http URL). This document describes how Scilab, a popular and powerful open source alternative to MATLAB, can be used to visualize the above stated theorem for arbitrary complex numbers z1, z2, and z3 which are not collinear. It is further demonstrated how the equations of the Steiner ellipses of a triangle in the complex plane can be calculated and plotted by applying this theorem.", "subjects": "Mathematical Software (cs.MS)", "authors": "Klaus Rohe,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01359", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01359", "title": "\nThe Three-Terminal Interactive Lossy Source Coding Problem", "abstract": "The three-node multiterminal lossy source coding problem is investigated. We derive an inner bound to the general rate-distortion region of this problem which is a natural extension of the seminal work by Kaspi'85 on the interactive two-terminal source coding problem. It is shown that this (rather involved) inner bound contains several rate-distortion regions of some relevant source coding settings. In this way, besides the non-trivial extension of the interactive two terminal problem, our results can be seen as a generalization and hence unification of several previous works in the field. Specializing to particular cases we obtain novel rate-distortion regions for several lossy source coding problems. We finish by describing some of the open problems and challenges. However, the general three-node multiterminal lossy source coding problem seems to offer a formidable mathematical complexity.", "subjects": "Information Theory (cs.IT)", "authors": "Leonardo Rey Vega, Pablo Piantanida, Alfred Hero III,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01335", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01335", "title": "\nApproximately Counting H-Colourings is #BIS-Hard", "abstract": "We consider the problem of counting H-colourings from an input graph G to a target graph H. We show that if H is any fixed graph without trivial components, then the problem is as hard as the well-known problem #BIS, which is the problem of (approximately) counting independent sets in a bipartite graph. #BIS is a complete problem in an important complexity class for approximate counting, and is believed not to have an FPRAS. If this is so, then our result shows that for every graph H without trivial components, the H-colouring counting problem has no FPRAS. This problem was studied a decade ago by Goldberg, Kelk and Paterson. They were able to show that approximately sampling H-colourings is #BIS-hard, but it was not known how to get the result for approximate counting. Our solution builds on non-constructive ideas using the work of Lovasz.", "subjects": "Computational Complexity (cs.CC)", "authors": "Andreas Galanis, Leslie Ann Goldberg, Mark Jerrum,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01329", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01329", "title": "\nA proposal for regularly updated review/survey articles: \"Perpetual  Reviews\"", "abstract": "We advocate the publication of review/survey articles that will be updated regularly, both in traditional journals and novel venues. We call these \"perpetual reviews.\" This idea naturally builds on the dissemination and archival capabilities present in the modern internet, and indeed perpetual reviews exist already in some forms. Perpetual review articles allow authors to maintain over time the relevance of non-research scholarship that requires a significant investment of effort. Further, such reviews published in a purely electronic format without space constraints can also permit more pedagogical scholarship and clearer treatment of technical issues that remain obscure in a brief treatment.", "subjects": "Digital Libraries (cs.DL)", "authors": "David L. Mobley, Daniel M. Zuckerman,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.01322", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01322", "title": "\nSensor Control for Multi-Object Tracking Using Labeled Multi-Bernoulli  Filter", "abstract": "The recently developed labeled multi-Bernoulli (LMB) filter uses better approximations in its update step, compared to the unlabeled multi-Bernoulli filters, and more importantly, it provides us with not only the estimates for the number of targets and their states, but also with labels for existing tracks. This paper presents a novel sensor-control method to be used for optimal multi-target tracking within the LMB filter. The proposed method uses a task-driven cost function in which both the state estimation errors and cardinality estimation errors are taken into consideration. Simulation results demonstrate that the proposed method can successfully guide a mobile sensor in a challenging multi-target tracking scenario.", "subjects": "Systems and Control (cs.SY)", "authors": "Amirali K. Gostar, Reza Hoseinnezhad, Alireza Bab-Hadiashar,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.01321", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01321", "title": "\nNumerical Solution of Fuzzy Stochastic Differential Equation", "abstract": "In this paper an alternative approach to solve uncertain Stochastic Differential Equation (SDE) is proposed. This uncertainty occurs due to the involved parameters in system and these are considered as Triangular Fuzzy Numbers (TFN). Here the proposed fuzzy arithmetic in [2] is used as a tool to handle Fuzzy Stochastic Differential Equation (FSDE). In particular, a system of Ito stochastic differential equations is analysed with fuzzy parameters. Further exact and Euler Maruyama approximation methods with fuzzy values are demonstrated and solved some standard SDE.", "subjects": "Numerical Analysis (cs.NA)", "authors": "Sukanta Nayak, Snehashish Chakraverty,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.01312", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01312", "title": "\nVivace: A Collaborative Live Coding Language", "abstract": "This paper describes the principles and the design of Vivace, a live coding language and environment built with Web technologies to be executed, ideally, in any ordinary browser. It starts by reviewing what motivated and inspired the creation of the language, in the context of actual performances. That leads to specifications of the language and how it is parsed and then executed using the recently created real-time Web Audio API. A brief discussion is presented on why the Web is an environment of interest to collaborative live coding and how it affects the performances. This work concludes by describing how Vivace has motivated the creation of \"freak coding\", a live coding sub-genre.", "subjects": "Computers and Society (cs.CY)", "authors": "Vilson Vieira, Guilherme Lunhani, Geraldo Magela de Castro Rocha Junior, Caleb Mascarenhas Luporini, Daniel Penalva, Ricardo Fabbri, Renato Fabbri,", "date": "2015-1-13"}, 
{"urllink": "http://arxiv.org/abs/1502.01292", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01292", "title": "\nMachine-Checked Proofs For Realizability Checking Algorithms", "abstract": "We have recently proposed a contract-based realizability checking algorithm involving the use of theories, to provide an auxiliary procedure to consistency checking of \"leaf-level\" components in complex embedded systems. To prove the soundness of our approach on realizability, we formalized the necessary definitions and theorems of cite, in the Coq proof and specification language.", "subjects": "Software Engineering (cs.SE)", "authors": "Andreas Katis, Andrew Gacek, Michael W. Whalen,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01278", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01278", "title": "\nA Falsification View of Success Typing", "abstract": "Dynamic languages are praised for their flexibility and expressiveness, but static analysis often yields many false positives and verification is cumbersome for lack of structure. Hence, unit testing is the prevalent incomplete method for validating programs in such languages. Falsification is an alternative approach that uncovers definite errors in programs. A falsifier computes a set of inputs that definitely crash a program. Success typing is a type-based approach to document programs in dynamic languages. We demonstrate that success typing is, in fact, an instance of falsification by mapping success (input) types into suitable logic formulae. Output types are represented by recursive types. We prove the correctness of our mapping (which establishes that success typing is falsification) and we report some experiences with a prototype implementation.", "subjects": "Programming Languages (cs.PL)", "authors": "Robert Jakob, Peter Thiemann,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01271", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01271", "title": "\nINRIASAC: Simple Hypernym Extraction Methods", "abstract": "Given a set of terms from a given domain, how can we structure them into a taxonomy without manual intervention? This is the task 17 of SemEval 2015. Here we present our simple taxonomy structuring techniques which, despite their simplicity, ranked first in this 2015 benchmark. We use large quantities of text (English Wikipedia) and simple heuristics such as term overlap and document and sentence co-occurrence to produce hypernym lists. We describe these techniques and pre-sent an initial evaluation of results.", "subjects": "Computation and Language (cs.CL)", "authors": "Gregory Grefenstette,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01264", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01264", "title": "\nA Secure Electronic Prescription System Using Steganography with  Encryption Key Implementation", "abstract": "Over the years health care has seen major improvement due to the introduction information and communication technology with electronic medical prescription being one the areas benefiting from it. Within the overall context of protection of health care information, privacy of prescription data needs special treatment. This paper presents an e-prescription system that addresses some challenges pertaining to the prescription privacy protection in the process of drug prescription. The developed system uses spread spectrum image steganography algorithm with Advanced Encryption Standard (AES) key implementation to provide a secure means of delivering medical prescription to the parties involved. The architecture for encoding and decoding was implemented with an electronic health record. The software development tools used were PHP and MySQL database management system for front end and backend data management respectively. The designed system demonstration shows that the synergistic combination of steganography and cryptography technologies in medical prescription is capable of providing a secure transmission to properly provide security for patients medical prescription.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Adebayo Omotosho, Omotanwa Adegbola, Olaniyi Olayemi Mikail, Justice Emuoyibofarhe,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01257", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01257", "title": "\nTowards a Complexity-through-Realizability Theory", "abstract": "We explain how recent developments in the fields of realizability models for linear logic -- or geometry of interaction -- and implicit computational complexity can lead to a new approach of implicit computational complexity. This semantic-based approach should apply uniformly to various computational paradigms, and enable the use of new mathematical methods and tools to attack problem in computational complexity. This paper provides the background, motivations and perspectives of this complexity-through-realizability theory to be developed, and illustrates it with recent results.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Thomas Seiller,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01255", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01255", "title": "\nGraph Isomorphism, Color Refinement, and Compactness", "abstract": "Color refinement is a classical technique used to show that two given graphs and are non-isomorphic; it is very efficient, although it does not succeed on all graphs. We call a graph amenable to color refinement if the color-refinement procedure succeeds in distinguishing from any non-isomorphic graph . Babai, Erd Hs, and Selkow (1982) have shown that random graphs are amenable with high probability. Our main results are the following. We determine the exact range of applicability of color refinement by showing that the class of amenable graphs is recognizable in time , where and denote the number of vertices and the number of edges in the input graph. Furthermore, we prove that amenable graphs are compact in the sense of Tinhofer (1991). That is, their polytopes of fractional automorphisms are integral. The concept of compactness was introduced in order to identify the class of graphs for which isomorphism can be decided by computing an extreme point of the polytope of fractional isomorphisms from to and checking if this point is integral. Our result implies that the applicability range for this linear programming approach to isomorphism testing is at least as large as for the combinatorial approach based on color refinement.", "subjects": "Computational Complexity (cs.CC)", "authors": "V. Arvind, Johannes K\u00f6bler, Gaurav Rattan, Oleg Verbitsky,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01253", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01253", "title": "\nPrices Matter for the Parameterized Complexity of Shift Bribery", "abstract": "In the Shift Bribery problem, we are given an election (based on preference orders), a preferred candidate , and a budget. The goal is to ensure that wins by shifting higher in some voters' preference orders. However, each such shift request comes at a price (depending on the voter and on the extent of the shift) and we must not exceed the given budget. We study the parameterized computational complexity of Shift Bribery with respect to a number of parameters (pertaining to the nature of the solution sought and the size of the election) and several classes of price functions. When we parameterize Shift Bribery by the number of affected voters, then for each of our voting rules (Borda, Maximin, Copeland) the problem is W[2]-hard. If, instead, we parameterize by the number of positions by which is shifted in total,then the problem is fixed-parameter tractable for Borda and Maximin,and is W[1]-hard for Copeland. If we parameterize by the budget, then the results depend on the price function class. We also show that Shift Bribery tends to be tractable when parameterized by the number of voters, but that the results for the number of candidates are more enigmatic.", "subjects": "Multiagent Systems (cs.MA)", "authors": "Robert Bredereck, Jiehua Chen, Piotr Faliszewski, Andr\u00e9 Nichterlein, Rolf Niedermeier,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01245", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01245", "title": "\nAuthorship recognition via fluctuation analysis of network topology and  word intermittency", "abstract": "Statistical methods have been widely employed in many practical natural language processing applications. More specifically, complex networks concepts and methods from dynamical systems theory have been successfully applied to recognize stylistic patterns in written texts. Despite the large amount of studies devoted to represent texts with physical models, only a few studies have assessed the relevance of attributes derived from the analysis of stylistic fluctuations. Because fluctuations represent a pivotal factor for characterizing a myriad of real systems, this study focused on the analysis of the properties of stylistic fluctuations in texts via topological analysis of complex networks and intermittency measurements. The results showed that different authors display distinct fluctuation patterns. In particular, it was found that it is possible to identify the authorship of books using the intermittency of specific words. Taken together, the results described here suggest that the patterns found in stylistic fluctuations could be used to analyze other related complex systems. Furthermore, the discovery of novel patterns related to textual stylistic fluctuations indicates that these patterns could be useful to improve the state of the art of many stylistic-based natural language processing tasks.", "subjects": "Computation and Language (cs.CL)", "authors": "Diego R. Amancio,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01240", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01240", "title": "\nA Predictive Framework for Cyber Security Analytics using Attack Graphs", "abstract": "Security metrics serve as a powerful tool for organizations to understand the effectiveness of protecting computer networks. However majority of these measurement techniques don't adequately help corporations to make informed risk management decisions. In this paper we present a stochastic security framework for obtaining quantitative measures of security by taking into account the dynamic attributes associated with vulnerabilities that can change over time. Our model is novel as existing research in attack graph analysis do not consider the temporal aspects associated with the vulnerabilities, such as the availability of exploits and patches which can affect the overall network security based on how the vulnerabilities are interconnected and leveraged to compromise the system. In order to have a more realistic representation of how the security state of the network would vary over time, a nonhomogeneous model is developed which incorporates a time dependent covariate, namely the vulnerability age. The daily transition-probability matrices are estimated using Frei's Vulnerability Lifecycle model. We also leverage the trusted CVSS metric domain to analyze how the total exploitability and impact measures evolve over a time period for a given network.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Subil Abraham, Suku Nair,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01237", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01237", "title": "\nRunning Identical Threads in C-Slow Retiming based Designs for  Functional Failure Detection", "abstract": "This paper shows the usage of C-Slow Retiming (CSR) in safety critical and low power applications. CSR generates C copies of a design by reusing the given logic resources in a time sliced fashion. When all C design copies are stimulated with the same input values, then all C design copies should behave the same way and will therefore create a redundant system. The paper shows that this special method of using CSR offers great benefits when used in safety critical and low power applications. Additional optimization techniques towards reducing register count are shown and an on-the-fly recovery mechanism is discussed.", "subjects": "Hardware Architecture (cs.AR)", "authors": "Tobias Strauch,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01233", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01233", "title": "\nExploiting Multimodal Biometrics in E-Privacy Scheme for Electronic  Health Records", "abstract": "Existing approaches to protect the privacy of Electronic Health Records are either insufficient for existing medical laws or they are too restrictive in their usage. For example, smart card-based encryption systems require the patient to be always present to authorize access to medical records. Questionnaires were administered by 50 medical practitioners to identify and categorize different Electronic Health Records attributes. The system was implemented using multi biometrics of patients to access patient record in pre-hospital care.The software development tools employed were JAVA and MySQL database. The system provides applicable security when patients records are shared either with other practitioners, employers, organizations or research institutes. The result of the system evaluation shows that the average response time of 6 seconds and 11.1 seconds for fingerprint and iris respectively after ten different simulations. The system protects privacy and confidentiality by limiting the amount of data exposed to users.The system also enables emergency medical technicians to gain easy and reliable access to necessary attributes of patients Electronic Health Records while still maintaining the privacy and confidentiality of the data using the patients fingerprint and iris.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Adebayo Omotosho, Omotanwa Adegbola, Barakat Adelakin, Adeyemi Adelakun, Justice Emuoyibofarhe,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01228", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01228", "title": "\nAction Detection From Skeletal Data Using Effecient Linear Search", "abstract": "Sliding window is one direct way to extend a successful recognition system to handle the more challenging detection problem. While action recognition decides only whether or not an action is present in a pre-segmented video sequence, action detection identifies the time interval where the action occurred in an unsegmented video stream. Sliding window approaches for action detection can however be slow as they maximize a classifier score over all possible sub-intervals. Even though new schemes utilize dynamic programming to speed up the search for the optimal sub-interval, they require offline processing on the whole video sequence. In this paper, we propose a novel approach for online action detection based on 3D skeleton sequences extracted from depth data. It identifies the sub-interval with the maximum classifier score in linear time. Furthermore, it is invariant to temporal scale variations and is suitable for real-time applications with low latency.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Moustafa Meshry, Mohamed E. Hussein, Marwan Torki,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01227", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01227", "title": "\nModeling Curved Carbon Fiber Composite (CFC) Structures in the  Transmission-Line Modeling (TLM) Method", "abstract": "A new embedded model for curved thin panels is developed in the Transmission Line Modeling (TLM) method. In this model, curved panels are first linearized and then embedded between adjacent 2D TLM nodes allowing for arbitrary positioning between adjacent node centers. The embedded model eliminates the necessity for fine discretization thus reducing the run time and memory requirements for the calculation. The accuracy and convergence of the model are verified by comparing the resonant frequencies of an elliptical cylinder formed using carbon fiber composite (CFC) materials with those of the equivalent metal cylinder. Furthermore, the model is used to analyze the shielding performance of CFC airfoil NACA2415.", "subjects": "Computational Engineering, Finance, and Science (cs.CE)", "authors": "Xuesong Meng, Phillip Sewell, Sendy Phang, Ana Vukovic, Trevor M. Benson,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01222", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01222", "title": "\nIs There WiFi Yet? How Aggressive WiFi Probe Requests Deteriorate Energy  and Throughput", "abstract": "WiFi offloading has emerged as a key component of cellular operator strategy to meet the data needs of rich, mobile devices. As such, mobile devices tend to aggressively seek out WiFi in order to provide improved user Quality of Experience (QoE) and cellular capacity relief. For home and work environments, aggressive WiFi scans can significantly improve the speed on which mobile nodes join the WiFi network. Unfortunately, the same aggressive behavior that excels in the home environment incurs considerable side effects across crowded wireless environments. In this paper, we show through empirical studies at both large (stadium) and small (laboratory) scales how aggressive WiFi scans can have significant implications for energy and throughput, both for the mobile nodes scanning and other nearby mobile nodes. We close with several thoughts on the disjoint incentives for properly balancing WiFi discovery speed and ultra-dense network interactions.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Xueheng Hu, Lixing Song, Dirk Van Bruggen, Aaron Striegel,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01220", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01220", "title": "\nUnveiling The Tree: A Convex Framework for Sparse Problems", "abstract": "This paper presents a general framework for generating greedy algorithms for solving convex constraint satisfaction problems for sparse solutions by mapping the satisfaction problem into one of graph traversal on a rooted tree of unknown topology. For every pre-walk of the tree an initial set of generally dense feasible solutions is processed in such a way that the sparsity of each solution increases with each generation unveiled. The specific computation performed at any particular child node is shown to correspond to an embedding of a polytope into the polytope received from that nodes parent. Several issues related to pre-walk order selection, computational complexity and tractability, and the use of heuristic and/or side information is discussed. An example of a single-path, depth-first algorithm on a tree with randomized vertex reduction and a run-time path selection algorithm is presented in the context of sparse lowpass filter design.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Tarek A. Lahlou, Alan V. Oppenheim,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01199", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01199", "title": "\nA Multiple-Expert Binarization Framework for Multispectral Images", "abstract": "In this work, a multiple-expert binarization framework for multispectral images is proposed. The framework is based on a constrained subspace selection limited to the spectral bands combined with state-of-the-art gray-level binarization methods. The framework uses a binarization wrapper to enhance the performance of the gray-level binarization. Nonlinear preprocessing of the individual spectral bands is used to enhance the textual information. An evolutionary optimizer is considered that provides the optimal and some suboptimal 3-band subspaces from which an ensemble of experts is then formed. The framework is applied to a ground truth multispectral dataset with promising results. In addition, a generalization to the cross-validation approach is developed that not only evaluates generalizability of the framework, it also provides a practical instance of the selected experts that could be then applied to unseen inputs despite the small size of the given ground truth dataset.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Reza Farrahi Moghaddam, Mohamed Cheriet,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01188", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01188", "title": "\nWhat Can Wireless Cellular Technologies Do about the Upcoming Smart  Metering Traffic?", "abstract": "The introduction of smart electricity meters with cellular radio interface puts an additional load to the wireless cellular networks. Currently, these meters are designed for low duty cycle billing and occasional system check, which generates a low-rate sporadic traffic. As the number of distributed energy resources increases, the household power will become more variable and thus unpredictable from the viewpoint of the Distribution System Operator (DSO). It is therefore expected, in the near future, to have an increased number of Wide Area Measurement System (WAMS) devices with Phasor Measurement Unit (PMU)-like capabilities, thus allowing the utilities to monitor the low voltage grid quality while providing information required for tighter grid control. From a communication standpoint, the traffic profile will change drastically towards higher data volumes and higher rates per device. In this paper, we characterize the current traffic generated by smart electricity meters and supplement it with the potential traffic requirements brought by introducing enhanced Smart Meters, which have PMU capability. Our study shows how GSM/GPRS and LTE cellular system performance behaves with the current and next generation smart meters traffic, where it is clearly seen that the PMU data will seriously challenge these wireless systems. We conclude by highlighting the possible solutions for upgrading the cellular standards, in order to cope with the upcoming smart metering traffic.", "subjects": "Information Theory (cs.IT)", "authors": "Jimmy J. Nielsen, Germ\u00e1n C. Madue\u00f1o, Nuno K. Pratas, Ren\u00e9 B. S\u00f8rensen, \u010cedomir Stefanovi\u0107, Petar Popovski,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01187", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01187", "title": "\nReversibility of d-State Finite Cellular Automata", "abstract": "This paper investigates reversibility properties of 1-dimensional 3-neighborhood d-state finite cellular automata (CAs) under periodic boundary condition. A tool named reachability tree has been developed from de Bruijn graph which represents all possible reachable configurations of an n-cell CA. This tool has been used to test reversibility of CAs. We have identified a large set of reversible CAs using this tool by following some greedy strategies. Our conjecture is that the reversible CAs, defined over infinite lattice, are always reversible when the CAs are finite. However, the reverse may not be true.", "subjects": "Formal Languages and Automata Theory (cs.FL)", "authors": "Kamalika Bhattacharjee, Sukanta Das,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01181", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01181", "title": "\nA gap analysis of Internet-of-Things platforms", "abstract": "Nowadays, we experience an abundance of Internet-of-Things (IoT) middleware solutions that provide connectivity for sensors and actuators to the Internet. To gain a widespread adoption, these middleware solutions, referred to as platforms, have to meet the expectations of different players in the IoT ecosystem, including device providers, application developers, and end-users, among others. In this article, we evaluate a representative sample of these platforms, both proprietary and open-source, on the basis of their ability to meet the ecosystem expectations. The evaluation is completed by a gap analysis of the current IoT landscape with respect to (i) the support of heterogeneous hardware, (ii) the capabilities of the platform for data management, (iii) the support of application developers, (iv) the extensibility of the different platforms for the formation of ecosystems, as well as (v) the availability of dedicated marketplaces to the IoT. The gap analysis aims to highlight the deficiencies of today's solutions to improve their integration to tomorrow's ecosystem. Based on the result of the analysis, we conclude this article with a list of recommendations for extending these IoT platforms in order to fill in the gaps.", "subjects": "Computers and Society (cs.CY)", "authors": "Julien Mineraud, Oleksiy Mazhelis, Xiang Su, Sasu Tarkoma,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01176", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01176", "title": "\nLearning Local Invariant Mahalanobis Distances", "abstract": "For many tasks and data types, there are natural transformations to which the data should be invariant or insensitive. For instance, in visual recognition, natural images should be insensitive to rotation and translation. This requirement and its implications have been important in many machine learning applications, and tolerance for image transformations was primarily achieved by using robust feature vectors. In this paper we propose a novel and computationally efficient way to learn a local Mahalanobis metric per datum, and show how we can learn a local invariant metric to any transformation in order to improve performance.", "subjects": "Learning (cs.LG)", "authors": "Ethan Fetaya, Shimon Ullman,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01157", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01157", "title": "\nToward Fully Coordinated Multi-level Multi-carrier Energy Efficient  Networks", "abstract": "Enabling coordination between products from different vendors is a key characteristic of the design philosophy behind future wireless communication networks. As an example, different devices may have different implementations, leading to different user experiences. A similar story emerges when devices running different physical and link layer protocols share frequencies in the same spectrum in order to maximize the system-wide spectral efficiency. In such situations, coordinating multiple interfering devices presents a significant challenge not only from an interworking perspective (as a result of reduced infrastructure), but also from an implementation point of view. The following question may then naturally arise: How to accommodate integrating such heterogeneous wireless devices seamlessly? One approach is to coordinate the spectrum in a centralized manner. However, the desired autonomous feature of future wireless systems makes the use of a central authority for spectrum management less appealing. Alternately, intelligent spectrum coordination have spurred great interest and excitement in the recent years. This paper presents a multi-level (hierarchical) power control game where users jointly choose their channel control and power control selfishly in order to maximize their individual energy efficiency. By hierarchical, we mean that some users' decision priority is higher/lower than the others. We propose two simple and nearly-optimal algorithms that ensure complete spectrum coordination among users. Interestingly, it turns out that the complexity of the two proposed algorithms is, in the worst case, quadratic in the number of users, whereas the complexity of the optimal solution (obtained through exhaustive search) is N!.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Piotr Wiecek, Majed Haddad, Oussama Habachi, Yezekael Hayel,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01142", "category": "Computer Science ", "pdflink": "http://arxiv.org/html/1502.01142", "title": "\nProceedings of the 5th International Conference on Collaborative  Innovation Networks COINs15, Tokyo, Japan March 12-14, 2015", "abstract": "The 5th annual international conference on Collaborative Innovation Networks Conference (COINS) takes place at Keio University from March 12 to 14, 2015. COINS15 brings together practitioners, researchers and students of the emerging science of collaboration to share their work, learn from each other, and get inspired through creative new ideas. Where science, design, business and art meet, COINS15 looks at the emerging forces behind the phenomena of open-source, creative, entrepreneurial and social movements. Through interactive workshops, professional presentations, and fascinating keynotes, COINS15 combines a wide range of interdisciplinary fields such as social network analysis, group dynamics, design and visualization, information systems, collective action and the psychology and sociality of collaboration.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Keiichi Nemoto, Peter A. Gloor, Cristobal J. Garcia, Julia Gluesing, Takashi Iba, Casper Lassenius, Christine Miller, Maria Paasivaara, Ken Riopelle,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01134", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01134", "title": "\nEffect of Energy Harvesting on Stable Throughput in Cooperative Relay  Systems", "abstract": "In this paper, the impact of energy constraints on a two-hop network with a source, a relay and a destination under random medium access is studied. A collision channel with erasures is considered, and the source and the relay nodes have energy harvesting capabilities and an unlimited battery to store the harvested energy. Additionally, the source and the relay node have external traffic arrivals and the relay forwards a fraction of the source node's traffic to the destination; the cooperation is performed at the network level. An inner and an outer bound of the stability region for a given transmission probability vector are obtained. Then, the closure of the inner and the outer bound is obtained separately and they turn out to be identical. This work is not only a step in connecting information theory and networking, by studying the maximum stable throughput region metric but also it taps the relatively unexplored and important domain of energy harvesting and assesses the effect of that on this important measure.", "subjects": "Information Theory (cs.IT)", "authors": "Nikolaos Pappas, Marios Kountouris, Jeongho Jeon, Anthony Ephremides, Apostolos Traganitis,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01133", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01133", "title": "\nPractical and Legal Challenges of Cloud Investigations", "abstract": "An area presenting new opportunities for both legitimate business, as well as criminal organizations, is Cloud computing. This work gives a strong background in current digital forensic science, as well as a basic understanding of the goal of Law Enforcement when conducting digital forensic investigations. These concepts are then applied to digital forensic investigation of cloud environments in both theory and practice, and supplemented with current literature on the subject. Finally, legal challenges with digital forensic investigations in cloud environments are discussed.", "subjects": "Computers and Society (cs.CY)", "authors": "Joshua I. James, Yunsik Jang,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01122", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01122", "title": "\nHash Chain Links Resynchronization Methods in Video Streaming Security  Performance Comparison", "abstract": "Hash chains provide a secure and light way of security to data authentication including two aspects: Data Integrity and Data Origin Authentication. The real challenge of using the hash chains is how it could recover the synchronization state and continue keeping the hash link in case of packet loss? Based on the packet loss tolerance and some accepted delay of video delivery which are representing the permitted tolerance for heavy loaded applications, we propose different mechanisms for such synchronization recovery. Each mechanism is suitable to use according to the video use case and the low capabilities of end devices. This paper proposes comparative results between them based on the status of each one and its overhead. Then, we propose a hybrid technique based Redundancy Code (RC). This hybrid algorithm is simulated and compared analytically against the other techniques (SHHC, TSP, MLHC and TSS). Moreover, a global performance evaluation in terms of delay and overhead is conducted for all techniques.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Emad Abd-Elrahman, Mohamed Boutabia, Hossam Afifi,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01120", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01120", "title": "\nOptimization of Quality of Experience through File Duplication in Video  Sharing Servers", "abstract": "Consumers of short videos on Internet can have a bad Quality of Experience QoE due to the long distance between the consumers and the servers that hosting the videos. We propose an optimization of the file allocation in telecommunication operators content sharing servers to improve the QoE through files duplication, thus bringing the files closer to the consumers. This optimization allows the network operator to set the level of QoE and to have control over the users access cost by setting a number of parameters. Two optimization methods are given and are followed by a comparison of their efficiency. Also, the hosting costs versus the gain of optimization are analytically discussed.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Emad Abd-Elrahman, Tarek Rekik, Hossam Afifi,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01119", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01119", "title": "\nA discontinuous Galerkin method for cohesive zone modelling", "abstract": "We propose a discontinuous finite element method for small strain elasticity allowing for cohesive zone modeling. The method yields a seamless transition between the discontinuous Galerkin method and classical cohesive zone modeling. Some relevant numerical examples are presented.", "subjects": "Computational Engineering, Finance, and Science (cs.CE)", "authors": "Peter Hansbo, Kent Salomonsson,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01097", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01097", "title": "\nDense v.s. Sparse: A Comparative Study of Sampling Analysis in Scene  Classification of High-Resolution Remote Sensing Imagery", "abstract": "Scene classification is a key problem in the interpretation of high-resolution remote sensing imagery. Many state-of-the-art methods, e.g. bag-of-visual-words model and its variants, the topic models as well as deep learning-based approaches, share similar procedures: patch sampling, feature description/learning and classification. Patch sampling is the first and a key procedure which has a great influence on the results. In the literature, many different sampling strategies have been used,", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Jingwen Hu, Gui-Song Xia, Fan Hu, Liangpei Zhang,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01095", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01095", "title": "\nA Novel architecture for improving performance under virtualized  environments", "abstract": "Even though virtualization provides a lot of advantages in cloud computing, it does not provide effective performance isolation between the virtualization machines. In other words, the performance may get affected due the interferences caused by co-virtual machines. This can be achieved by the proper management of resource allocations between the Virtual Machines running simultaneously. This paper aims at providing a proposed novel architecture that is based on Fast Genetic K-means++ algorithm and test results show positive improvements in terms of performance improvements over a similar existing approach.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "A.P. Nirmala, Dr. R. Sridaran,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01075", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01075", "title": "\nClassificatory Sorites, Probabilistic Supervenience, and Rule-Making", "abstract": "We view sorites in terms of stimuli acting upon a system and evoking this system's responses. Supervenience of responses on stimuli implies that they either lack tolerance (i.e., they change in every vicinity of some of the stimuli), or stimuli are not always connectable by finite chains of stimuli in which successive members are `very similar'. If supervenience does not hold, the properties of tolerance and connectedness cannot be formulated and therefore soritical sequences cannot be constructed. We hypothesize that supervenience in empirical systems (such as people answering questions) is fundamentally probabilistic. The supervenience of probabilities of responses on stimuli is stable, in the sense that `higher-order' probability distributions can always be reduced to `ordinary' ones. In making rules about which stimuli ought to correspond to which responses, the main characterization of choices in soritical situations is their arbitrariness. We argue that arbitrariness poses no problems for classical logic.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Damir D. Dzhafarov, Ehtibar N. Dzhafarov,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01074", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01074", "title": "\nConsensus with objective map", "abstract": "In this paper, we will assume the standard consensus model whereby there is a rooted connected digraph specifying the underlying network topology, and each agent measures the relative positions of his outgoing neighbors and chooses nonnegative real numbers as the interaction weights. We will equip the consensus model a (linear) function, as we call the objective map, which sends a set of initial positions of agents to the position of rendezvous. We will address the question that given a digraph as the network topology, whether there is a set of nonnegative real numbers as interaction weights by which all agents converge to the position specified by the objective map? A complete answer to this question will be given in this paper. In particular, not only we will characterize the set of linear objective maps which are feasible by choices of interaction weights, but also we will characterize the set of interaction weights for a feasible linear objective map. In addition, a decentralized algorithm for implementing a choice of interaction weights will be given at the end of this paper.", "subjects": "Systems and Control (cs.SY)", "authors": "Xudong Chen, Ali Belabbas, Tamer Basar,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01066", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01066", "title": "\nInformation theoretic approach to robust multi-Bernoulli sensor control", "abstract": "A novel sensor control solution is presented, formulated within a Multi-Bernoulli-based multi-target tracking framework. The proposed method is especially designed for the general multi-target tracking case, where no prior knowledge of the clutter distribution or the probability of detection profile are available. In an information theoretic approach, our method makes use of R `nyi divergence as the reward function to be maximized for finding the optimal sensor control command at each step. We devise a Monte Carlo sampling method for computation of the reward. Simulation results demonstrate successful performance of the proposed method in a challenging scenario involving five targets maneuvering in a relatively uncertain space with unknown distance-dependent clutter rate and probability of detection.", "subjects": "Information Theory (cs.IT)", "authors": "Amirali K. Gostar, Reza Hoseinnezhad, Alireza Bab-Hadiashar,", "date": "2015-2-4"}, 
{"urllink": "http://arxiv.org/abs/1502.01065", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01065", "title": "\nDistributed Compressed Estimation for Wireless Sensor Networks Based on  Compressive Sensing", "abstract": "This letter proposes a novel distributed compressed estimation scheme for sparse signals and systems based on compressive sensing techniques. The proposed scheme consists of compression and decompression modules inspired by compressive sensing to perform distributed compressed estimation. A design procedure is also presented and an algorithm is developed to optimize measurement matrices, which can further improve the performance of the proposed distributed compressed estimation scheme. Simulations for a wireless sensor network illustrate the advantages of the proposed scheme and algorithm in terms of convergence rate and mean square error performance.", "subjects": "Information Theory (cs.IT)", "authors": "S. Xu, R. C. de Lamare, H. V. Poor,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.01063", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01063", "title": "\nQuadratic Conditional Lower Bounds for String Problems and Dynamic Time  Warping", "abstract": "We study the longest common subsequence of two given strings and the dynamic time warping distance of time-series. Both are classic similarity measures of sequences that have a wealth of applications and can be computed in time . We prove that both measures do not have strongly subquadratic time algorithms, i.e., no algorithms with running time for any , unless the Strong Exponential Time Hypothesis fails. This adds two important problems to a recent line of research showing conditional lower bounds for a growing number of quadratic time problems. As our main technical contribution, we introduce a framework for proving quadratic lower bounds for similarity measures. To apply the framework it suffices to construct a single gadget, which encapsulates all the expressive power necessary to emulate a reduction from satisfiability that is similar to a recent reduction for the edit distance. We prove a quadratic lower bound for any similarity measure admitting such a gadget, and then design such gadgets for the problems under consideration.", "subjects": "Computational Complexity (cs.CC)", "authors": "Karl Bringmann, Marvin K\u00fcnnemann,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.01057", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01057", "title": "\nPersonalized Web Search", "abstract": "Personalization is important for search engines to improve user experience. Most of the existing work do pure feature engineering and extract a lot of session-style features and then train a ranking model. Here we proposed a novel way to model both long term and short term user behavior using Multi-armed bandit algorithm. Our algorithm can generalize session information across users well, and as an Explore-Exploit style algorithm, it can generalize to new urls and new users well. Experiments show that our algorithm can improve performance over the default ranking and outperforms several popular Multi-armed bandit algorithms.", "subjects": "Information Retrieval (cs.IR)", "authors": "Li Zhou,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.01053", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01053", "title": "\nQuantized Consensus by the ADMM: Probabilistic versus Deterministic  Quantizers", "abstract": "This paper develops efficient algorithms for distributed average consensus with quantized communication using the alternating direction method of multipliers (ADMM). We first study the effects of probabilistic and deterministic quantizations on a distributed version of the ADMM. With probabilistic quantization, this approach yields linear convergence to the desired average in the mean sense with bounded variance. When deterministic quantization is employed, the distributed ADMM converges to a consensus within iterations where depends on the network topology and is a polynomial of quantization resolution, agents' data and the network topology. A tight upper bound on the consensus error is also obtained, which depends only on the quantization resolution and the average degree of the graph. This bound is much preferred in large scale networks over existing algorithms whose consensus errors are increasing in the range of agents' data, quantization resolution and the number of agents. We finally propose our algorithm which combines the probabilistic and deterministic quantizations. Simulations show that the consensus error of our algorithm is typically less than one quantization resolution for all connected networks with agents' data of arbitrary magnitudes. This is so far the best known result for quantized consensus.", "subjects": "Systems and Control (cs.SY)", "authors": "Shengyu Zhu, Biao Chen,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.01038", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01038", "title": "\nA Factorization Scheme for Some Discrete Hartley Transform Matrices", "abstract": "Discrete transforms such as the discrete Fourier transform (DFT) and the discrete Hartley transform (DHT) are important tools in numerical analysis. The successful application of transform techniques relies on the existence of efficient fast transforms. In this paper some fast algorithms are derived. The theoretical lower bound on the multiplicative complexity for the DFT/DHT are achieved. The approach is based on the factorization of DHT matrices. Algorithms for short blocklengths such as are presented.", "subjects": "Numerical Analysis (cs.NA)", "authors": "H. M. de Oliveira, R. J. Cintra, R. M. Campello de Souza,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.01032", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.01032", "title": "\nDFDL: Discriminative Feature-oriented Dictionary Learning for  Histopathological Image Classification", "abstract": "In histopathological image analysis, feature extraction for classification is a challenging task due to the diversity of histology features suitable for each problem as well as presence of rich geometrical structure. In this paper, we propose an automatic feature discovery framework for extracting discriminative class-specific features and present a low-complexity method for classification and disease grading in histopathology. Essentially, our Discriminative Feature-oriented Dictionary Learning (DFDL) method learns class-specific features which are suitable for representing samples from the same class while are poorly capable of representing samples from other classes. Experiments on three challenging real-world image databases: 1) histopathological images of intraductal breast lesions, 2) mammalian lung images provided by the Animal Diagnostics Lab (ADL) at Pennsylvania State University, and 3) brain tumor images from The Cancer Genome Atlas (TCGA) database, show the significance of DFDL model in a variety problems over state-of-the-art methods", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Tiep H. Vu, Hojjat S. Mousavi, Vishal Monga, UK Arvind Rao, Ganesh Rao,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00997", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00997", "title": "\nDriver-Based Adaptation of Vehicular Ad Hoc Networks for Design of  Active Safety Systems", "abstract": "This paper studies the need for individualizing vehicular communications in order to improve collision warning systems for an N-lane highway scenario. By relating the traffic-based and communications studies, we aim at reducing highway traffic accidents. To the best of our knowledge, this is the first paper that shows how to customize vehicular communications to driver's characteristics and traffic information. We propose to develop VANET protocols that selectively identify crash relevant information and customize the communications of that information based on each driver's assigned safety score. In this paper, first, we derive the packet success probability by accounting for multi-user interference, path loss, and fading. Then, by Monte carlo simulations, we demonstrate how appropriate channel access probabilities that satisfy the delay requirements of the safety application result in noticeable performance enhancement.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Ali Rakhshan, Hossein Pishro-Nik, Mohammad Nekoui,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00993", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00993", "title": "\nComputing maximal cliques in link streams", "abstract": "A link stream is a sequence of triplets (t, u, v) indicating that an interaction occurred between u and v at time t. We generalize the classical notion of cliques in graphs to such link streams: for a given , a -clique is a set of nodes and a time interval such that all pairs of nodes in this set interact at least every during this time interval. We propose an algorithm to enumerate all maximal cliques of a link stream, and illustrate its practical relevance on a real-world contact trace.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Jordan Viard, Matthieu Latapy, Cl\u00e9mence Magnien,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00979", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00979", "title": "\nFurther Properties of Wireless Channel Capacity", "abstract": "Future wireless communication calls for exploration of more efficient use of wireless channel capacity to meet the increasing demand on higher data rate and less latency. However, while ergodic capacity and instantaneous capacity are fundamental properties of a wireless channel, they are in many cases not sufficient for use in assessing if data transmission over the channel meets the quality of service (QoS) requirements. To address this limitation, we focus on the concept of \"cumulative capacity\", which is the cumulated capacity over a time period, and study its properties. Specifically, the moment generating function, the stochastic service curve, and the Mellin transform properties of cumulative capacity are investigated and related results are derived. It is appealing that with these properties, QoS assessment of data transmission over the channel can be further performed based on stochastic network calculus, a newly developed theory for (stochastic) QoS analysis. To demonstrate the derived properties, a Rayleigh fading channel is considered and numerical results are provided.", "subjects": "Information Theory (cs.IT)", "authors": "Fengyou Sun, Yuming Jiang, Luqun Li,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00963", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00963", "title": "\nThe Sample Complexity of Revenue Maximization", "abstract": "In the design and analysis of revenue-maximizing auctions, auction performance is typically measured with respect to a prior distribution over inputs. The most obvious source for such a distribution is past data. The goal is to understand how much data is necessary and sufficient to guarantee near-optimal expected revenue. Our basic model is a single-item auction in which bidders' valuations are drawn independently from unknown and non-identical distributions. The seller is given samples from each of these distributions \"for free\" and chooses an auction to run on a fresh sample. How large does m need to be, as a function of the number k of bidders and eps &gt; 0, so that a (1 - eps)-approximation of the optimal revenue is achievable? We prove that, under standard tail conditions on the underlying distributions, m = poly(k, 1/eps) samples are necessary and sufficient. Our lower bound stands in contrast to many recent results on simple and prior-independent auctions and fundamentally involves the interplay between bidder competition, non-identical distributions, and a very close (but still constant) approximation of the optimal revenue. It effectively shows that the only way to achieve a sufficiently good constant approximation of the optimal revenue is through a detailed understanding of bidders' valuation distributions. Our upper bound is constructive and applies in particular to a variant of the empirical Myerson auction, the natural auction that runs the revenue-maximizing auction with respect to the empirical distributions of the samples. Our sample complexity lower bound depends on the set of allowable distributions, and to capture this we introduce alpha-strongly regular distributions, which interpolate between the well-studied classes of regular (alpha = 0) and MHR (alpha = 1) distributions. We give evidence that this definition is of independent interest.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Richard Cole, Tim Roughgarden,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00956", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00956", "title": "\nORB-SLAM: a Versatile and Accurate Monocular SLAM System", "abstract": "The gold standard method for tridimensional reconstruction and camera localization from a set of images is well known to be Bundle Adjustment (BA). Although BA was regarded for years as a costly method restricted to the offline domain, several real time algorithms based on BA flourished in the last decade. However those algorithms were limited to perform SLAM in small scenes or only Visual Odometry. In this work we built on excellent algorithms of the last years to design from scratch a Monocular SLAM system that operates in real time, in small and large, indoor and outdoor environments, with the capability of wide baseline loop closing and relocalization, and including full automatic initialization. Our survival of the fittest approach to select the points and keyframes of the reconstruction generates a compact and trackable map that only grows if the scene content changes, enhancing lifelong operation. We present an exhaustive evaluation in 27 sequences from the most popular datasets achieving unprecedented performance with a typical localization accuracy from 0.2% to 1% of the trajectory dimension in scenes from a desk to several city blocks. We make public a ROS implementation.", "subjects": "Robotics (cs.RO)", "authors": "Raul Mur-Artal, J. M. M. Montiel, Juan D. Tardos,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00950", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00950", "title": "\nCompactly Supported Wavelets Derived From Legendre Polynomials:  Spherical Harmonic Wavelets", "abstract": "A new family of wavelets is introduced, which is associated with Legendre polynomials. These wavelets, termed spherical harmonic or Legendre wavelets, possess compact support. The method for the wavelet construction is derived from the association of ordinary second order differential equations with multiresolution filters. The low-pass filter associated with Legendre multiresolution analysis is a linear phase finite impulse response filter (FIR).", "subjects": "Numerical Analysis (cs.NA)", "authors": "M.M.S. Lira, H.M. de Oliveira, M.A. Carvalho Jr, R.M. Campello de Souza,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00946", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00946", "title": "\nClassification of Hyperspectral Imagery on Embedded Grassmannians", "abstract": "We propose an approach for capturing the signal variability in hyperspectral imagery using the framework of the Grassmann manifold. Labeled points from each class are sampled and used to form abstract points on the Grassmannian. The resulting points on the Grassmannian have representations as orthonormal matrices and as such do not reside in Euclidean space in the usual sense. There are a variety of metrics which allow us to determine a distance matrices that can be used to realize the Grassmannian as an embedding in Euclidean space. We illustrate that we can achieve an approximately isometric embedding of the Grassmann manifold using the chordal metric while this is not the case with geodesic distances. However, non-isometric embeddings generated by using a pseudometric on the Grassmannian lead to the best classification results. We observe that as the dimension of the Grassmannian grows, the accuracy of the classification grows to 100% on two illustrative examples. We also observe a decrease in classification rates if the dimension of the points on the Grassmannian is too large for the dimension of the Euclidean space. We use sparse support vector machines to perform additional model reduction. The resulting classifier selects a subset of dimensions of the embedding without loss in classification performance.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Sofya Chepushtanova, Michael Kirby,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00944", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00944", "title": "\nA Type System for proving Depth Boundedness in the pi-calculus", "abstract": "The depth-bounded fragment of the pi-calculus is an expressive class of systems enjoying decidability of some important verification problems. Unfortunately membership of the fragment is undecidable. We propose a novel type system, parameterised over a finite forest, that formalises name usage by pi-terms in a manner that respects the forest. Type checking is decidable and type inference is computable; furthermore typable pi-terms are guaranteed to be depth bounded. The second contribution of the paper is a proof of equivalence between the semantics of typable terms and nested data class memory automata, a class of automata over data words. We believe this connection can help to establish new links between the rich theory of infinite-alphabet automata and nominal calculi.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Emanuele D'Osualdo, Luke Ong,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00926", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00926", "title": "\nScaling Laws for Disturbance Propagation in Cyclic Dynamical Networks", "abstract": "Our goal is to analyze performance of stable linear dynamical networks subject to external stochastic disturbances. The square of the -norm of the network is used as a performance measure to quantify the expected steady-state dispersion of the outputs of the network. We show that this performance measure can be tightly bounded from below and above by some spectral functions of the state-space matrices of the network. This result is applied to a class of cyclic linear networks and shown that their performance measure scale quadratically with the network size.", "subjects": "Systems and Control (cs.SY)", "authors": "Milad Siami, Nader Motee,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00911", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00911", "title": "\nMulticuts in Planar and Bounded-Genus Graphs with Bounded Number of  Terminals", "abstract": "Given an undirected, edge-weighted graph G together with pairs of vertices, called pairs of terminals, the minimum multicut problem asks for a minimum-weight set of edges such that, after deleting these edges, the two terminals of each pair belong to different connected components of the graph. Relying on topological techniques, we provide a polynomial-time algorithm for this problem in the case where G is embedded on a fixed surface of genus g (e.g., when G is planar) and has a fixed number t of terminals. The running time is a polynomial of degree O(sqrt) in the input size. In the planar case, our result corrects an error in an extended abstract by Bentz [Int. Workshop on Parameterized and Exact Computation, 109-119, 2012]. The minimum multicut problem is also a generalization of the multiway cut problem, a.k.a. multiterminal cut problem; even for this special case, no dedicated algorithm was known for graphs embedded on surfaces.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "\u00c9ric Colin de Verdi\u00e8re,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00894", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00894", "title": "\nExtended Unary Coding", "abstract": "Extended variants of the recently introduced spread unary coding are described. These schemes, in which the length of the code word is fixed, allow representation of approximately n^2 numbers for n bits, rather than the n numbers of the standard unary coding. In the first of two proposed schemes the spread increases, whereas in the second scheme the spread remains constant.", "subjects": "Information Theory (cs.IT)", "authors": "Subhash Kak,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00873", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00873", "title": "\nDeepID3: Face Recognition with Very Deep Neural Networks", "abstract": "The state-of-the-art of face recognition has been significantly advanced by the emergence of deep learning. Very deep neural networks recently achieved great success on general object recognition because of their superb learning capacity. This motivates us to investigate their effectiveness on face recognition. This paper proposes two very deep neural network architectures, referred to as DeepID3, for face recognition. These two architectures are rebuilt from stacked convolution and inception layers proposed in VGG net and GoogLeNet to make them suitable to face recognition. Joint face identification-verification supervisory signals are added to both intermediate and final feature extraction layers during training. An ensemble of the proposed two architectures achieves 99.53% LFW face verification accuracy and 96.0% LFW rank-1 face identification accuracy, respectively. A further discussion of LFW face verification result is given in the end.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Yi Sun, Ding Liang, Xiaogang Wang, Xiaoou Tang,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00870", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00870", "title": "\nAuthentication Systems in Internet of Things", "abstract": "This paper analyses the various authentication systems implemented for enhanced security and private re-position of an individual's log-in credentials. The first part of the paper describes the multi-factor authentication (MFA) systems, which, though not applicable to the field of Internet of Things, provides great security to a user's credentials. MFA is followed by a brief description of the working mechanism of interaction of third party clients with private resources over the OAuth protocol framework and a study of the delegation based authentication system in IP-based IoT.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Tuhin Borgohain, Amardeep Borgohain, Uday Kumar, Sugata Sanyal,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00868", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00868", "title": "\nAnalysis of Human Awareness of Security and Privacy Threats in Smart  Environments", "abstract": "Smart environments integrate Information and Communication Technologies (ICT) into devices, vehicles, buildings and cities to offer an increased quality of life, energy efficiency and economical sustainability. In this perspective, the individual has a core role and so has networking, which enables such entities to cooperate. However, the huge amount of sensitive data, social aspects and the mixed set of protocols offer many opportunities to inject hazards, exfiltrate information, mass profiling of citizens, or produce a new wave of attacks. This work reviews the major risks arising from the usage of ICT-techniques for smart environments, with emphasis on networking. Its main contribution is to explain the role of different stakeholders for causing a lack of security and to envision future threats by considering human aspects.", "subjects": "Computers and Society (cs.CY)", "authors": "Luca Caviglione, Jean-Francois Lalande, Wojciech Mazurczyk, Steffen Wendzel,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00860", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00860", "title": "\nWavelet-based Estimator for the Hurst Parameters of Fractional Brownian  Sheet", "abstract": "It is proposed a class of statistical estimators for the Hurst parameters of fractional Brownian field via multi-dimensional wavelet analysis and least squares, which are asymptotically normal. These estimators can be used to detect self-similarity and long-range dependence in multi-dimensional signals, which is important in texture classification and improvement of diffusion tensor imaging (DTI) of nuclear magnetic resonance (NMR). Some fractional Brownian sheets will be simulated and the simulated data are used to validate these estimators. We find that when , the estimators are efficient, and when , there are some bias.", "subjects": "Information Theory (cs.IT)", "authors": "Liang Wu, Yiming Ding,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00859", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00859", "title": "\nAn on-line competitive algorithm for coloring bipartite graphs without  long induced paths", "abstract": "The existence of an on-line competitive algorithm for coloring bipartite graphs remains a tantalizing open problem. So far there are only partial positive results for bipartite graphs with certain small forbidden graphs as induced subgraphs. We propose a new on-line competitive coloring algorithm for -free bipartite graphs.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Piotr Micek, Veit Wiechert,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00852", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00852", "title": "\nFace frontalization for Alignment and Recognition", "abstract": "Recently, it was shown that excellent results can be achieved in both face landmark localization and pose-invariant face recognition. These breakthroughs are attributed to the efforts of the community to manually annotate facial images in many different poses and to collect 3D faces data. In this paper, we propose a novel method for joint face landmark localization and frontal face reconstruction (pose correction) using a small set of frontal images only. By observing that the frontal facial image is the one with the minimum rank from all different poses we formulate an appropriate model which is able to jointly recover the facial landmarks as well as the frontalized version of the face. To this end, a suitable optimization problem, involving the minimization of the nuclear norm and the matrix norm, is solved. The proposed method is assessed in frontal face reconstruction (pose correction), face landmark localization, and pose-invariant face recognition and verification by conducting experiments on facial images databases. The experimental results demonstrate the effectiveness of the proposed method.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Christos Sagonas, Yannis Panagakis, Stefanos Zafeiriou, Maja Pantic,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00842", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00842", "title": "\nErasure codes with symbol locality and group decodability for  distributed storage", "abstract": "We introduce a new family of erasure codes, called group decodable code (GDC), for distributed storage system. Given a set of design parameters , where k is the number of information symbols, each codeword of an ( alpha; beta; k; t)-group decodable code is a t-tuple of strings, called buckets, such that each bucket is a string of beta symbols that is a codeword of a [ beta; alpha] MDS code (which is encoded from alpha information symbols). Such codes have the following two properties: (P1) Locally Repairable: Each code symbol has locality ( alpha; beta- alpha + 1). (P2) Group decodable: From each bucket we can decode alpha information symbols. We establish an upper bound of the minimum distance of ( alpha; beta; k; t)-group decodable code for any given set of ; We also prove that the bound is achievable when the coding field F has size |F| &gt; n-1 choose k-1.", "subjects": "Information Theory (cs.IT)", "authors": "Wentu Song, Son Hoang Dau, Chau Yuen,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00839", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00839", "title": "\nA multiset model of multi-species evolution to solve big deceptive  problems", "abstract": "This chapter presents SMuGA, an integration of symbiogenesis with the Multiset Genetic Algorithm (MuGA). The symbiogenetic approach used here is based on the host-parasite model with the novelty of varying the length of parasites along the evolutionary process. Additionally, it models collaborations between multiple parasites and a single host. To improve efficiency, we introduced proxy evaluation of parasites, which saves fitness function calls and exponentially reduces the symbiotic collaborations produced. Another novel feature consists of breaking the evolutionary cycle into two phases: a symbiotic phase and a phase of independent evolution of both hosts and parasites. SMuGA was tested in optimization of a variety of deceptive functions, with results one order of magnitude better than state of the art symbiotic algorithms. This allowed to optimize deceptive problems with large sizes, and showed a linear scaling in the number of iterations to attain the optimum.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "Luis Correia, Antonio Manso,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00836", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00836", "title": "\nTask-Driven Dictionary Learning for Hyperspectral Image Classification  with Structured Sparsity Constraints", "abstract": "Sparse representation models a signal as a linear combination of a small number of dictionary atoms. As a generative model, it requires the dictionary to be highly redundant in order to ensure both a stable high sparsity level and a low reconstruction error for the signal. However, in practice, this requirement is usually impaired by the lack of labelled training samples. Fortunately, previous research has shown that the requirement for a redundant dictionary can be less rigorous if simultaneous sparse approximation is employed, which can be carried out by enforcing various structured sparsity constraints on the sparse codes of the neighboring pixels. In addition, numerous works have shown that applying a variety of dictionary learning methods for the sparse representation model can also improve the classification performance. In this paper, we highlight the task-driven dictionary learning algorithm, which is a general framework for the supervised dictionary learning method. We propose to enforce structured sparsity priors on the task-driven dictionary learning method in order to improve the performance of the hyperspectral classification. Our approach is able to benefit from both the advantages of the simultaneous sparse representation and those of the supervised dictionary learning. We enforce two different structured sparsity priors, the joint and Laplacian sparsity, on the task-driven dictionary learning method and provide the details of the corresponding optimization algorithms. Experiments on numerous popular hyperspectral images demonstrate that the classification performance of our approach is superior to sparse representation classifier with structured priors or the task-driven dictionary learning method.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Xiaoxia Sun, Nasser M. Nasrabadi, Trac D. Tran,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00831", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00831", "title": "\nOpen System Categorical Quantum Semantics in Natural Language Processing", "abstract": "Originally inspired by categorical quantum mechanics (Abramsky and Coecke, LiCS'04), the categorical compositional distributional model of natural language meaning of Coecke, Sadrzadeh and Clark provides a conceptually motivated procedure to compute the meaning of a sentence, given its grammatical structure within a Lambek pregroup and a vectorial representation of the meaning of its parts. The predictions of this first model have outperformed that of other models in mainstream empirical language processing tasks on large scale data. Moreover, just like CQM allows for varying the model in which we interpret quantum axioms, one can also vary the model in which we interpret word meaning. In this paper we show that further developments in categorical quantum mechanics are relevant to natural language processing too. Firstly, Selinger's CPM-construction allows for explicitly taking into account lexical ambiguity and distinguishing between the two inherently different notions of homonymy and polysemy. In terms of the model in which we interpret word meaning, this means a passage from the vector space model to density matrices. Despite this change of model, standard empirical methods for comparing meanings can be easily adopted, which we demonstrate by a small-scale experiment on real-world data. This experiment moreover provides preliminary evidence of the validity of our proposed new model for word meaning. Secondly, commutative classical structures as well as their non-commutative counterparts that arise in the image of the CPM-construction allow for encoding relative pronouns, verbs and adjectives, and finally, iteration of the CPM-construction, something that has no counterpart in the quantum realm, enables one to accommodate both entailment and ambiguity.", "subjects": "Computation and Language (cs.CL)", "authors": "Robin Piedeleu, Dimitri Kartsaklis, Bob Coecke, Mehrnoosh Sadrzadeh,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00827", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00827", "title": "\nOn the Duality of Additivity and Tensorization", "abstract": "A function is said to be additive if, similar to mutual information, expands by a factor of , when evaluated on i.i.d. repetitions of a source or channel. On the other hand, a function is said to satisfy the tensorization property if it remains unchanged when evaluated on i.i.d. repetitions. Additive rate regions are of fundamental importance in network information theory, serving as capacity regions or upper bounds thereof. Tensorizing measures of correlation have also found applications in distributed source and channel coding problems as well as the distribution simulation problem. Prior to our work only two measures of correlation, namely the hypercontractivity ribbon and maximal correlation (and their derivatives), were known to have the tensorization property. In this paper, we provide a general framework to obtain a region with the tensorization property from any additive rate region. We observe that hypercontractivity ribbon indeed comes from the dual of the rate region of the Gray-Wyner source coding problem, and generalize it to the multipartite case. Then we define other measures of correlation with similar properties from other source coding problems. We also present some applications of our results.", "subjects": "Information Theory (cs.IT)", "authors": "Salman Beigi, Amin Gohari,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00823", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00823", "title": "\nBig Data: Opportunities and Privacy Challenges", "abstract": "Recent advances in data collection and computational statistics coupled with increases in computer processing power, along with the plunging costs of storage are making technologies to effectively analyze large sets of heterogeneous data ubiquitous. Applying such technologies (often referred to as big data technologies) to an ever growing number and variety of internal and external data sources, businesses and institutions can discover hidden correlations between data items, and extract actionable insights needed for innovation and economic growth. While on one hand big data technologies yield great promises, on the other hand, they raise critical security, privacy, and ethical issues, which if left unaddressed may become significant barriers to the fulfillment of expected opportunities and long-term success of big data. In this paper, we discuss the benefits of big data to individuals and society at large, focusing on seven key use cases: Big data for business optimization and customer analytics, big data and science, big data and health care, big data and finance, big data and the emerging energy distribution systems, big/open data as enablers of openness and efficiency in government, and big data security. In addition to benefits and opportunities, we discuss the security, privacy, and ethical issues at stake.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Hervais Simo Fhom,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00821", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00821", "title": "\nSoftware that Learns from its Own Failures", "abstract": "All non-trivial software systems suffer from unanticipated production failures. However, those systems are passive with respect to failures and do not take advantage of them in order to improve their future behavior: they simply wait for them to happen and trigger hard-coded failure recovery strategies. Instead, I propose a new paradigm in which software systems learn from their own failures. By using an advanced monitoring system they have a constant awareness of their own state and health. They are designed in order to automatically explore alternative recovery strategies inferred from past successful and failed executions. Their recovery capabilities are assessed by self-injection of controlled failures; this process produces knowledge in prevision of future unanticipated failures.", "subjects": "Software Engineering (cs.SE)", "authors": "Martin Monperrus,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00814", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00814", "title": "\nGrafting Hypersequents onto Nested Sequents", "abstract": "We introduce a new Gentzen-style framework of grafted hypersequents that combines the formalism of nested sequents with that of hypersequents. To illustrate the potential of the framework, we present novel calculi for the modal logics and , as well as for extensions of the modal logics and with the axiom for shift reflexivity. The latter of these extensions is also known as in the context of deontic logic. All our calculi enjoy syntactic cut elimination and can be used in backwards proof search procedures of optimal complexity.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Roman Kuznets, Bj\u00f6rn Lellmann,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00804", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00804", "title": "\nA Polya Urn Document Language Model for Improved Information Retrieval", "abstract": "The multinomial language model has been one of the most effective models of retrieval for over a decade. However, the multinomial distribution does not model one important linguistic phenomenon relating to term-dependency, that is the tendency of a term to repeat itself within a document (i.e. word burstiness). In this article, we model document generation as a random process with reinforcement (a multivariate Polya process) and develop a Dirichlet compound multinomial language model that captures word burstiness directly. We show that the new reinforced language model can be computed as efficiently as current retrieval models, and with experiments on an extensive set of TREC collections, we show that it significantly outperforms the state-of-the-art language model for a number of standard effectiveness metrics. Experiments also show that the tuning parameter in the proposed model is more robust than in the multinomial language model. Furthermore, we develop a constraint for the verbosity hypothesis and show that the proposed model adheres to the constraint. Finally, we show that the new language model essentially introduces a measure closely related to idf which gives theoretical justification for combining the term and document event spaces in tf-idf type schemes.", "subjects": "Information Retrieval (cs.IR)", "authors": "Ronan Cummins, Jiaul Hoque Paik, Yuanhua Lv,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00802", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00802", "title": "\nAlgorithm for Achieving Consensus Over Conflicting Rumors: Convergence  Analysis and Applications", "abstract": "Motivated by the large expansion in the study of social networks, this paper deals with the problem of multiple messages spreading over the same network using gossip algorithms. Given two messages distributed over some nodes of the graph, we first investigate the final distribution of the messages given an initial state. Then, an algorithm is presented to achieve consensus over one of the messages. Finally, a game theoretical application and an analogy with word-of-mouth marketing are outlined.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Amine Semma, Ismail Elouafiq,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00797", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00797", "title": "\nTowards a Practical Architecture for the Next Generation Internet of  Things", "abstract": "The Internet of Things, or the IoT is a vision for a ubiquitous society wherein people and \"Things\" are connected in an immersively networked computing environment, with the connected \"Things\" providing utility to people/enterprises and their digital shadows, through intelligent social and commercial services. Translating this idea to a conceivable reality is a work in progress for more than a decade. Current IoT architectures are predicated on optimistic assumptions on the evolution and deployment of IoT technologies. We believe many of these assumptions will not be met, consequently impeding the practical and sustainable deployment of IoT. In this article, we explore use-cases across diff?erent applications domains that can potentially benefi?t from an IoT infrastructure, and analyze them in the context of an alternative world-view that is more grounded in reality. Despite this more conservative approach, we argue that adopting certain design paradigms when architecting an IoT ecosystem can achieve much of the promised benefi?ts in a practical and sustainable manner.", "subjects": "Computers and Society (cs.CY)", "authors": "Prasant Misra, Yogesh Simmhan, Jay Warrior,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00794", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00794", "title": "\nBest Signal Quality in Cellular Networks: Asymptotic Properties and  Applications to Mobility Management in Small Cell Networks", "abstract": "The quickly increasing data traffic and the user demand for a full coverage of mobile services anywhere and anytime are leading mobile networking into a future of small cell networks. However, due to the high-density and randomness of small cell networks, there are several technical challenges. In this paper, we investigate two critical issues: emph and emph. Under the assumptions that base stations are uniformly distributed in a ring shaped region and that shadowings are lognormal, independent and identically distributed, we prove that when the number of sites in the ring tends to infinity, then (i) the maximum signal strength received at the center of the ring tends in distribution to a Gumbel distribution when properly renormalized, and (ii) it is asymptotically independent of the interference. Using these properties, we derive the distribution of the best signal quality. Furthermore, an optimized random cell scanning scheme is proposed, based on the evaluation of the optimal number of sites to be scanned for maximizing the user data throughput.", "subjects": "Information Theory (cs.IT)", "authors": "Van Minh Nguyen, Fran\u00e7ois Baccelli, Laurent Thomas, Chung Shue Chen,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00781", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00781", "title": "\nCHAOS: Accurate and Realtime Detection of Aging-Oriented Failure Using  Entropy", "abstract": "Even well-designed software systems suffer from chronic performance degradation, also named \"software aging\", due to internal (e.g. software bugs) and external (e.g. resource exhaustion) impairments. These chronic problems often fly under the radar of software monitoring systems before causing severe impacts (e.g. system failure). Therefore it's a challenging issue how to timely detect these problems to prevent system crash. Although a large quantity of approaches have been proposed to solve this issue, the accuracy and effectiveness of these approaches are still far from satisfactory due to the insufficiency of aging indicators adopted by them. In this paper, we present a novel entropy-based aging indicator, Multidimensional Multi-scale Entropy (MMSE). MMSE employs the complexity embedded in runtime performance metrics to indicate software aging and leverages multi-scale and multi-dimension integration to tolerate system fluctuations. Via theoretical proof and experimental evaluation, we demonstrate that MMSE satisfies Stability, Monotonicity and Integration which we conjecture that an ideal aging indicator should have. Based upon MMSE, we develop three failure detection approaches encapsulated in a proof-of-concept named CHAOS. The experimental evaluations in a Video on Demand (VoD) system and in a real-world production system, AntVision, show that CHAOS can detect the failure-prone state in an extraordinarily high accuracy and a near 0 Ahead-Time-To-Failure (ATTF). Compared to previous approaches, CHAOS improves the detection accuracy by about 5 times and reduces the ATTF even by 3 orders of magnitude. In addition, CHAOS is light-weight enough to satisfy the realtime requirement.", "subjects": "Other Computer Science (cs.OH)", "authors": "Pengfei Chen, Yong Qi, Di Hou,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00780", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00780", "title": "\nMeasure the similarity of nodes in the complex networks", "abstract": "Measure the similarity of the nodes in the complex networks have interested many researchers to explore it. In this paper, a new method which is based on the degree centrality and the Relative-entropy is proposed to measure the similarity of the nodes in the complex networks. The results in this paper show that, the nodes which have a common structure property always have a high similarity to others nodes. The nodes which have a high influential to others always have a small value of similarity to other nodes and the marginal nodes also have a low similar to other nodes. The results in this paper show that the proposed method is useful and reasonable to measure the similarity of the nodes in the complex networks.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Qi Zhang, Meizhu Li, Yong Deng, Sankaran Mahadevan,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00762", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00762", "title": "\nOn the Solvability of 3s/nt Sum-Network---A Region Decomposition and  Weak Decentralized Code Method", "abstract": "We study the network coding problem of sum-networks with 3 sources and n terminals (3s/nt sum-network), for an arbitrary positive integer n, and derive a sufficient and necessary condition for the solvability of a family of so-called terminal-separable sum-network. Both the condition of terminal-separable and the solvability of a terminal-separable sum-network can be decided in polynomial time. Consequently, we give another necessary and sufficient condition, which yields a faster (O(|E|) time) algorithm than that of Shenvi and Dey ([18], (O(|E|^3) time), to determine the solvability of the 3s/3t sum-network. To obtain the results, we further develop the region decomposition method in [22], [23] and generalize the decentralized coding method in [21]. Our methods provide new efficient tools for multiple source multiple sink network coding problems.", "subjects": "Information Theory (cs.IT)", "authors": "Wentu Song, Kai Cai, Chau Yuen, Rongquan Feng,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00756", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00756", "title": "\nDesign of a Mobile Face Recognition System for Visually Impaired Persons", "abstract": "It is estimated that 285 million people globally are visually impaired. A majority of these people live in developing countries and are among the elderly population. One of the most difficult tasks faced by visually impaired persons is identification of people. While naturally, voice recognition is a common method of identification, it is an intuitive and difficult process. The rise of computation capability of mobile devices gives motivation to develop applications that can assist visually impaired persons. With the availability of mobile devices, these people can be assisted through an additional method of identification through intelligent software based on computer vision techniques. In this paper, we present the design and implementation of a face recognition system for the visually impaired through the use of mobile computing. We propose a mobile based face recognition system with cloud support for assisting visually impaired persons. The system was tested on a custom video database. Experiment results show high face detection accuracy and promising face recognition accuracy in suitable conditions. The challenges of the system lie in better recognition techniques for difficult situations in terms of lighting and weather.", "subjects": "Computers and Society (cs.CY)", "authors": "Shonal Chaudhry, Rohitash Chandra,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00750", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00750", "title": "\nRecognizing Focal Liver Lesions in Contrast-Enhanced Ultrasound with  Discriminatively Trained Spatio-Temporal Model", "abstract": "The aim of this study is to provide an automatic computational framework to assist clinicians in diagnosing Focal Liver Lesions (FLLs) in Contrast-Enhancement Ultrasound (CEUS). We represent FLLs in a CEUS video clip as an ensemble of Region-of-Interests (ROIs), whose locations are modeled as latent variables in a discriminative model. Different types of FLLs are characterized by both spatial and temporal enhancement patterns of the ROIs. The model is learned by iteratively inferring the optimal ROI locations and optimizing the model parameters. To efficiently search the optimal spatial and temporal locations of the ROIs, we propose a data-driven inference algorithm by combining effective spatial and temporal pruning. The experiments show that our method achieves promising results on the largest dataset in the literature (to the best of our knowledge), which we have made publicly available.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Xiaodan Liang, Qingxing Cao, Rui Huang, Liang Lin,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00749", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00749", "title": "\nData-Driven Scene Understanding with Adaptively Retrieved Exemplars", "abstract": "This article investigates a data-driven approach for semantically scene understanding, without pixelwise annotation and classifier training. Our framework parses a target image with two steps: (i) retrieving its exemplars (i.e. references) from an image database, where all images are unsegmented but annotated with tags; (ii) recovering its pixel labels by propagating semantics from the references. We present a novel framework making the two steps mutually conditional and bootstrapped under the probabilistic Expectation-Maximization (EM) formulation. In the first step, the references are selected by jointly matching their appearances with the target as well as the semantics (i.e. the assigned labels of the target and the references). We process the second step via a combinatorial graphical representation, in which the vertices are superpixels extracted from the target and its selected references. Then we derive the potentials of assigning labels to one vertex of the target, which depend upon the graph edges that connect the vertex to its spatial neighbors of the target and to its similar vertices of the references. Besides, the proposed framework can be naturally applied to perform image annotation on new test images. In the experiments, we validate our approach on two public databases, and demonstrate superior performances over the state-of-the-art methods in both semantic segmentation and image annotation tasks.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Xionghao Liu, Wei Yang, Liang Lin, Qing Wang, Zhaoquan Cai, Jianhuang Lai,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00744", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00744", "title": "\nIncorporating Structural Alternatives and Sharing into Hierarchy for  Multiclass Object Recognition and Detection", "abstract": "This paper proposes a reconfigurable model to recognize and detect multiclass (or multiview) objects with large variation in appearance. Compared with well acknowledged hierarchical models, we study two advanced capabilities in hierarchy for object modeling: (i) \"switch\" variables(i.e. or-nodes) for specifying alternative compositions, and (ii) making local classifiers (i.e. leaf-nodes) shared among different classes. These capabilities enable us to account well for structural variabilities while preserving the model compact. Our model, in the form of an And-Or Graph, comprises four layers: a batch of leaf-nodes with collaborative edges in bottom for localizing object parts; the or-nodes over bottom to activate their children leaf-nodes; the and-nodes to classify objects as a whole; one root-node on the top for switching multiclass classification, which is also an or-node. For model training, we present an EM-type algorithm, namely dynamical structural optimization (DSO), to iteratively determine the structural configuration, (e.g., leaf-node generation associated with their parent or-nodes and shared across other classes), along with optimizing multi-layer parameters. The proposed method is valid on challenging databases, e.g., PASCAL VOC 2007 and UIUC-People, and it achieves state-of-the-arts performance.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Xiaolong Wang, Liang Lin, Lichao Huang, Shuicheng Yan,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00743", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00743", "title": "\nDeep Joint Task Learning for Generic Object Extraction", "abstract": "This paper investigates how to extract objects-of-interest without relying on hand-craft features and sliding windows approaches, that aims to jointly solve two sub-tasks: (i) rapidly localizing salient objects from images, and (ii) accurately segmenting the objects based on the localizations. We present a general joint task learning framework, in which each task (either object localization or object segmentation) is tackled via a multi-layer convolutional neural network, and the two networks work collaboratively to boost performance. In particular, we propose to incorporate latent variables bridging the two networks in a joint optimization manner. The first network directly predicts the positions and scales of salient objects from raw images, and the latent variables adjust the object localizations to feed the second network that produces pixelwise object masks. An EM-type method is presented for the optimization, iterating with two steps: (i) by using the two networks, it estimates the latent variables by employing an MCMC-based sampling method; (ii) it optimizes the parameters of the two networks unitedly via back propagation, with the fixed latent variables. Extensive experiments suggest that our framework significantly outperforms other state-of-the-art approaches in both accuracy and efficiency (e.g. 1000 times faster than competing approaches).", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Xiaolong Wang, Liliang Zhang, Liang Lin, Zhujin Liang, Wangmeng Zuo,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00741", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00741", "title": "\nDynamical And-Or Graph Learning for Object Shape Modeling and Detection", "abstract": "This paper studies a novel discriminative part-based model to represent and recognize object shapes with an \"And-Or graph\". We define this model consisting of three layers: the leaf-nodes with collaborative edges for localizing local parts, the or-nodes specifying the switch of leaf-nodes, and the root-node encoding the global verification. A discriminative learning algorithm, extended from the CCCP [23], is proposed to train the model in a dynamical manner: the model structure (e.g., the configuration of the leaf-nodes associated with the or-nodes) is automatically determined with optimizing the multi-layer parameters during the iteration. The advantages of our method are two-fold. (i) The And-Or graph model enables us to handle well large intra-class variance and background clutters for object shape detection from images. (ii) The proposed learning algorithm is able to obtain the And-Or graph representation without requiring elaborate supervision and initialization. We validate the proposed method on several challenging databases (e.g., INRIA-Horse, ETHZ-Shape, and UIUC-People), and it outperforms the state-of-the-arts approaches.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Xiaolong Wang, Liang Lin,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00739", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00739", "title": "\nClothing Co-Parsing by Joint Image Segmentation and Labeling", "abstract": "This paper aims at developing an integrated system of clothing co-parsing, in order to jointly parse a set of clothing images (unsegmented but annotated with tags) into semantic configurations. We propose a data-driven framework consisting of two phases of inference. The first phase, referred as \"image co-segmentation\", iterates to extract consistent regions on images and jointly refines the regions over all images by employing the exemplar-SVM (E-SVM) technique [23]. In the second phase (i.e. \"region co-labeling\"), we construct a multi-image graphical model by taking the segmented regions as vertices, and incorporate several contexts of clothing configuration (e.g., item location and mutual interactions). The joint label assignment can be solved using the efficient Graph Cuts algorithm. In addition to evaluate our framework on the Fashionista dataset [30], we construct a dataset called CCP consisting of 2098 high-resolution street fashion photos to demonstrate the performance of our system. We achieve 90.29% / 88.23% segmentation accuracy and 65.52% / 63.89% recognition rate on the Fashionista and the CCP datasets, respectively, which are superior compared with state-of-the-art methods.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Wei Yang, Ping Luo, Liang Lin,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00734", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00734", "title": "\nA New Cell Association Scheme In Heterogeneous Networks", "abstract": "Cell association scheme determines which base station (BS) and mobile user (MU) should be associated with and also plays a significant role in determining the average data rate a MU can achieve in heterogeneous networks. However, the explosion of digital devices and the scarcity of spectra collectively force us to carefully re-design cell association scheme which was kind of taken for granted before. To address this, we develop a new cell association scheme in heterogeneous networks based on joint consideration of the signal-to-interference-plus-noise ratio (SINR) which a MU experiences and the traffic load of candidate BSs1. MUs and BSs in each tier are modeled as several independent Poisson point processes (PPPs) and all channels experience independently and identically distributed ( i.i.d.) Rayleigh fading. Data rate ratio and traffic load ratio distributions are derived to obtain the tier association probability and the average ergodic MU data rate. Through numerical results, We find that our proposed cell association scheme outperforms cell range expansion (CRE) association scheme. Moreover, results indicate that allocating small sized and high-density BSs will improve spectral efficiency if using our proposed cell association scheme in heterogeneous networks.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Bin Yang, Guoqiang Mao, Xiaohu Ge, Tao Han,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00731", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00731", "title": "\nIncremental Knowledge Base Construction Using DeepDive", "abstract": "Populating a database with unstructured information is a long-standing problem in industry and research that encompasses problems of extraction, cleaning, and integration. A recent name used to characterize this problem is knowledge base construction (KBC). In this work, we describe DeepDive, a system that combines database and machine learning ideas to help develop KBC systems, and we present techniques to make the KBC process more efficient. We observe that the KBC process is iterative, and we develop techniques to incrementally produce inference results for KBC systems. We propose two methods for incremental inference, based respectively on sampling and variational techniques. We also study the tradeoff space of these methods and develop a simple rule-based optimizer. DeepDive includes all of these contributions, and we evaluate DeepDive on five KBC systems, showing that it can speed up KBC inference tasks by up to two orders of magnitude with negligible impact on quality.", "subjects": "Databases (cs.DB)", "authors": "Sen Wu, Ce Zhang, Feiran Wang, Christopher R\u00e9,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00724", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00724", "title": "\nReview of Considerations for Mobile Device based Secure Access to  Financial Services and Risk Handling Strategy for CIOs, CISOs and CTOs", "abstract": "The information technology and security stakeholders like CIOs, CISOs and CTOs in financial services organization are often asked to identify the risks with mobile computing channel for financial services that they support. They are also asked to come up with approaches for handling risks, define risk acceptance level and mitigate them. This requires them to articulate strategy for supporting a huge variety of mobile devices from various vendors with different operating systems and hardware platforms and at the same time stay within the accepted risk level. These articulations should be captured in information security policy document or other suitable document of financial services organization like banks, payment service provider, etc. While risks and mitigation approaches are available from multiple sources, the senior stakeholders may find it challenging to articulate the issues in a comprehensive manner for sharing with business owners and other technology stakeholders. This paper reviews the current research that addresses the issues mentioned above and articulates a strategy that the senior stakeholders may use in their organization. It is assumed that this type of comprehensive strategy guide for senior stakeholders is not readily available and CIOs, CISOs and CTOs would find this paper to be very useful.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Amal Saha, Sugata Sanyal,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00723", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00723", "title": "\nLearning Contour-Fragment-based Shape Model with And-Or Tree  Representation", "abstract": "This paper proposes a simple yet effective method to learn the hierarchical object shape model consisting of local contour fragments, which represents a category of shapes in the form of an And-Or tree. This model extends the traditional hierarchical tree structures by introducing the \"switch\" variables (i.e. the or-nodes) that explicitly specify production rules to capture shape variations. We thus define the model with three layers: the leaf-nodes for detecting local contour fragments, the or-nodes specifying selection of leaf-nodes, and the root-node encoding the holistic distortion. In the training stage, for optimization of the And-Or tree learning, we extend the concave-convex procedure (CCCP) by embedding the structural clustering during the iterative learning steps. The inference of shape detection is consistent with the model optimization, which integrates the local testings via the leaf-nodes and or-nodes with the global verification via the root-node. The advantages of our approach are validated on the challenging shape databases (i.e., ETHZ and INRIA Horse) and summarized as follows. (1) The proposed method is able to accurately localize shape contours against unreliable edge detection and edge tracing. (2) The And-Or tree model enables us to well capture the intraclass variance.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Liang Lin, Xiaolong Wang, Wei Yang, Jianhuang Lai,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00718", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00718", "title": "\nProduct Echo State Networks: Time-Series Computation with Multiplicative  Neurons", "abstract": "Echo state networks (ESN) are efficient and accurate artificial neural systems for time series processing and learning. An ESN consists of a core of recurrent neural networks, called a reservoir, with a small number of tunable parameters to generate a high-dimensional representation of an input, and a readout layer which is easily trained using regression to produce a desired output from the reservoir states. Certain computational tasks involve real-time calculation of high-order time correlations, which requires nonlinear transformation either in the reservoir or the readout layer. Traditional ESN employs a reservoir with sigmoid function neurons. In contrast, some types of biological neurons obey response curves that can be described as a product unit rather than a sum and threshold. Inspired by this class of neurons, we introduce an ESN with a reservoir of product nodes for time series computation. We find that the capacity of a product ESN for learning nonlinear functions surpasses that of a standard ESN. In particular, product ESN resolves the limitation of standard ESN to learn symmetric (even) nonlinear functions of the input. On standard benchmarks for chaotic prediction tasks, a product ESN network maintains the performance of a standard nonlinear ESN while being more amenable to mathematical analysis. Our study provides evidence that such networks are powerful in highly nonlinear tasks owing to high-order statistics generated by the recurrent product node reservoir.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "Alireza Goudarzi, Alireza Shabani, Darko Stefanovic,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00717", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00717", "title": "\nBeyond Pixels: A Comprehensive Survey from Bottom-up to Semantic Image  Segmentation and Cosegmentation", "abstract": "Image segmentation refers to the process to divide an image into nonoverlapping meaningful regions according to human perception, which has become a classic topic since the early ages of computer vision. A lot of research has been conducted and has resulted in many applications. However, while many segmentation algorithms exist, yet there are only a few sparse and outdated summarizations available, an overview of the recent achievements and issues is lacking. We aim to provide a comprehensive review of the recent progress in this field. Covering 180 publications, we give an overview of broad areas of segmentation topics including not only the classic bottom-up approaches, but also the recent development in superpixel, interactive methods, object proposals, semantic image parsing and image cosegmentation. In addition, we also review the existing influential datasets and evaluation metrics. Finally, we suggest some design flavors and research directions for future research in image segmentation.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Hongyuan Zhu, Fanman Meng, Jianfei Cai, Shijian Lu,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00716", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00716", "title": "\nOptimal dynamic program for r-domination problems over tree  decompositions", "abstract": "There has been recent progress in showing that the exponential dependence on treewidth in dynamic programming algorithms for solving NP-hard problems are optimal under the Strong Exponential Time Hypothesis (SETH). We extend this work to -domination problems. In -dominating set, one wished to find a minimum subset of vertices such that every vertex of is within hops of some vertex in . In connected -dominating set, one additionally requires that the set induces a connected subgraph of . We give a time algorithm for -dominating set and a time algorithm for connected -dominating set in -vertex graphs of treewidth . We show that the running time dependence on and is the best possible under SETH. This adds to earlier observations that a \"+1\" in the denominator is required for connectivity constraints.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Glencora Borradaile, Hung Le,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00714", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00714", "title": "\nExploiting the Preferred Domain of FDD Massive MIMO Systems with Uniform  Planar Arrays", "abstract": "Massive multiple-input multiple-output (MIMO) systems hold the potential to be an enabling technology for 5G cellular. Uniform planar array (UPA) antenna structures are a focus of much commercial discussion because of their ability to enable a large number of antennas in a relatively small area. With UPA antenna structures, the base station can control the beam direction in both the horizontal and vertical domains simultaneously. However, channel conditions may dictate that one dimension requires higher channel state information (CSI) accuracy than the other. We propose the use of an additional one bit of feedback information sent from the user to the base station to indicate the preferred domain on top of the feedback overhead of CSI quantization in frequency division duplexing (FDD) massive MIMO systems. Combined with variable-rate CSI quantization schemes, the numerical studies show that the additional one bit of feedback can increase the quality of CSI significantly for UPA antenna structures.", "subjects": "Information Theory (cs.IT)", "authors": "Junil Choi, Taeyoung Kim, David J. Love, Ji-yun Seol,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00712", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00712", "title": "\nDeep Boosting: Layered Feature Mining for General Image Classification", "abstract": "Constructing effective representations is a critical but challenging problem in multimedia understanding. The traditional handcraft features often rely on domain knowledge, limiting the performances of exiting methods. This paper discusses a novel computational architecture for general image feature mining, which assembles the primitive filters (i.e. Gabor wavelets) into compositional features in a layer-wise manner. In each layer, we produce a number of base classifiers (i.e. regression stumps) associated with the generated features, and discover informative compositions by using the boosting algorithm. The output compositional features of each layer are treated as the base components to build up the next layer. Our framework is able to generate expressive image representations while inducing very discriminate functions for image classification. The experiments are conducted on several public datasets, and we demonstrate superior performances over state-of-the-art approaches.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Zhanglin Peng, Liang Lin, Ruimao Zhang, Jing Xu,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00705", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00705", "title": "\nRecovery of Piecewise Smooth Images from Few Fourier Samples", "abstract": "We introduce a Prony-like method to recover a continuous domain 2-D piecewise smooth image from few of its Fourier samples. Assuming the discontinuity set of the image is localized to the zero level-set of a trigonometric polynomial, we show the Fourier transform coefficients of partial derivatives of the signal satisfy an annihilation relation. We present necessary and sufficient conditions for unique recovery of piecewise constant images using the above annihilation relation. We pose the recovery of the Fourier coefficients of the signal from the measurements as a convex matrix completion algorithm, which relies on the lifting of the Fourier data to a structured low-rank matrix; this approach jointly estimates the signal and the annihilating filter. Finally, we demonstrate our algorithm on the recovery of MRI phantoms from few low-resolution Fourier samples.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Greg Ongie, Mathews Jacob,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00702", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00702", "title": "\nHybrid Orthogonal Projection and Estimation (HOPE): A New Framework to  Probe and Learn Neural Networks", "abstract": "In this paper, we propose a universal model for high-dimensional data, called the Hybrid Orthogonal Projection and Estimation (HOPE) model, which combines a linear orthogonal projection and a finite mixture model under a unified generative modelling framework. The HOPE model itself can be learned unsupervisedly from un-labelled data based on the maximum likelihood estimation as well as trained discriminatively from labelled data. More interestingly, we have shown the proposed HOPE models are closely related to neural networks (NNs) in a sense that each NN hidden layer can be reformulated as a HOPE model. As a result, the HOPE framework can be used as a novel tool to probe why and how NNs work, more importantly, it also provides several new learning algorithms to learn NNs either supervisedly or unsupervisedly. In this work, we have investigated the HOPE framework in learning NNs for several standard tasks, including image recognition on MNIST and speech recognition on TIMIT. Experimental results show that the HOPE framework yields significant performance gains over the current state-of-the-art methods in various types of NN learning problems, including unsupervised feature learning, supervised or semi-supervised learning.", "subjects": "Learning (cs.LG)", "authors": "Shiliang Zhang, Hui Jiang,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00695", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00695", "title": "\nAssessing the Fault Proneness Degree (DFP) by Estimating the Impact of  Change Request Artifacts Correlation", "abstract": "Exploring the impact of change requests applied to a software maintenance project helps to assess the fault-proneness of the change request to be handled further, which is perhaps a bug fix or even a new feature demand. In practice, the major development community stores change requests and related data using bug tracking systems such as Bugzilla. These data, together with the data stored in a versioning system, such as Concurrent Versioning Systems, are a valuable source of information to create descriptions and also can perform useful analyzes. In our earlier work, we proposed a novel statistical bipartite weighted graph-based approach to assessing the degree of fault-proneness of the change request and Change Request artifacts. With the motivation gained from this model, here we propose a novel strategy that estimates the degree of fault-proneness of a change request by assessing the impact of a change request artifact towards fault-proneness that considers the correlation between change requests artifact as another factor, which is in addition to our earlier strategy. The proposed model can be titled as Assessing the Fault Proneness Degree of Change Request Artifacts by estimating the impact of change requests correlation (DFP-CRC). As stated in our earlier model, the method DFP-CRC also makes use of information retrieval methods to identify the change request artifacts of the devised change request. And further evaluates the degree of fault-proneness of the Change Requests by estimating the correlation between change requests. The proposed method is evaluated by applying on concurrent versioning and Change request logs of the production level maintenance project.", "subjects": "Software Engineering (cs.SE)", "authors": "Rudra Kumar M, A Ananda Rao,", "date": "2015-2-3"}, 
{"urllink": "http://arxiv.org/abs/1502.00658", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00658", "title": "\nThrowing Out the Baby with the Bathwater: The Undesirable Effects of  National Research Assessment Exercises on Research", "abstract": "The evaluation of the quality of research at a national level has become increasingly common. The UK has been at the forefront of this trend having undertaken many assessments since 1986, the latest being the Research Excellence Framework in 2014. The argument of this paper is that, whatever the intended results in terms of evaluating and improving research, there have been many, presumably unintended, results that are highly undesirable for research and the university community more generally. We situate our analysis using Bourdieu's theory of cultural reproduction and then focus on the peculiarities of the 2008 RAE and the 2014 REF the rules of which allowed for, and indeed encouraged, significant game-playing on the part of striving universities. We conclude with practical recommendations to maintain the general intention of research assessment without the undesirable side-effects.", "subjects": "Digital Libraries (cs.DL)", "authors": "John Mingers, Leroy White,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00656", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00656", "title": "\nAlignment based Network Coding for Two-Unicast-Z Networks", "abstract": "In this paper, we study the wireline two-unicast-Z communication network over directed acyclic graphs. The two-unicast-Z network is a two-unicast network where the destination intending to decode the second message has apriori side information of the first message. We make three contributions in this paper: 1. We describe a new linear network coding algorithm for two-unicast-Z networks over directed acyclic graphs. Our approach includes the idea of interference alignment as one of its key ingredients. For graphs of a bounded degree, our algorithm has linear complexity in terms of the number of vertices, and polynomial complexity in terms of the number of edges. 2. We prove that our algorithm achieves the rate-pair (1, 1) whenever it is feasible in the network. Our proof serves as an alternative, albeit restricted to two-unicast-Z networks over directed acyclic graphs, to an earlier result of Wang et al. which studied necessary and sufficient conditions for feasibility of the rate pair (1, 1) in two-unicast networks. 3. We provide a new proof of the classical max-flow min-cut theorem for directed acyclic graphs.", "subjects": "Information Theory (cs.IT)", "authors": "Weifei Zeng, Viveck R. Cadambe, Muriel Medard,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00652", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00652", "title": "\nLearning the Matching Function", "abstract": "The matching function for the problem of stereo reconstruction or optical flow has been traditionally designed as a function of the distance between the features describing matched pixels. This approach works under assumption, that the appearance of pixels in two stereo cameras or in two consecutive video frames does not change dramatically. However, this might not be the case, if we try to match pixels over a large interval of time. In this paper we propose a method, which learns the matching function, that automatically finds the space of allowed changes in visual appearance, such as due to the motion blur, chromatic distortions, different colour calibration or seasonal changes. Furthermore, it automatically learns the importance of matching scores of contextual features at different relative locations and scales. Proposed classifier gives reliable estimations of pixel disparities already without any form of regularization. We evaluated our method on two standard problems - stereo matching on KITTI outdoor dataset, optical flow on Sintel data set, and on newly introduced TimeLapse change detection dataset. Our algorithm obtained very promising results comparable to the state-of-the-art.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "\u013dubor Ladick\u00fd, Christian H\u00e4ne, Marc Pollefeys,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00647", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00647", "title": "\nMinimax Robust Hypothesis Testing", "abstract": "The minimax robust hypothesis testing problem for the case where the nominal probability distributions are subject to both modeling errors and outliers is studied in twofold. First, a robust hypothesis testing scheme based on a relative entropy distance is designed. This approach provides robustness with respect to modeling errors and is a generalization of a previous work proposed by Levy. Then, it is shown that this scheme can be combined with Huber's robust test through a composite uncertainty class, for which the existence of a saddle value condition is also proven. The composite version of the robust hypothesis testing scheme as well as the individual robust tests are extended to fixed sample size and sequential probability ratio tests. The composite model is shown to extend to robust estimation problems as well. Simulation results are provided to validate the proposed assertions.", "subjects": "Information Theory (cs.IT)", "authors": "G\u00f6khan G\u00fcl, Abdelhak M. Zoubir,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00621", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00621", "title": "\nE-BLOW: E-Beam Lithography Overlapping aware Stencil Planning for MCC  System", "abstract": "Electron beam lithography (EBL) is a promising maskless solution for the technology beyond 14nm logic node. To overcome its throughput limitation, industry has proposed character projection (CP) technique, where some complex shapes (characters) can be printed in one shot. Recently the traditional EBL system is extended into multi-column cell (MCC) system to further improve the throughput. In MCC system, several independent CPs are used to further speed-up the writing process. Because of the area constraint of stencil, MCC system needs to be packed/planned carefully to take advantage of the characters. In this paper, we prove that the overlapping aware stencil planning (OSP) problem is NP-hard. To solve OSP problem in MCC system, we present a tool, E-BLOW, with several novel speedup techniques, such as successive relaxation, dynamic programming, and KD-Tree based clustering. Experimental results show that, compared with previous works, E-BLOW demonstrates better performance for both conventional EBL system and MCC system.", "subjects": "Other Computer Science (cs.OH)", "authors": "Bei Yu, Kun Yuan, Jhih-Rong Gao, David Z. Pan,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00611", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00611", "title": "\nUnifying Two Views on Multiple Mean-Payoff Objectives in Markov Decision  Processes", "abstract": "We consider Markov decision processes (MDPs) with multiple limit-average (or mean-payoff) objectives. There exist two different views: (i) the expectation semantics, where the goal is to optimize the expected mean-payoff objective, and (ii) the satisfaction semantics, where the goal is to maximize the probability of runs such that the mean-payoff value stays above a given vector. We consider optimization with respect to both objectives at once, thus unifying the existing semantics. Precisely, the goal is to optimize the expectation while ensuring the satisfaction constraint. Our problem captures the notion of optimization with respect to strategies that are risk-averse (i.e., ensure certain probabilistic guarantee). Our main results are as follows: First, we present algorithms for the decision problems which are always polynomial in the size of the MDP. We also show that an approximation of the Pareto-curve can be computed in time polynomial in the size of the MDP, and the approximation factor, but exponential in the number of dimensions. Second, we present a complete characterization of the strategy complexity (in terms of memory bounds and randomization) required to solve our problem.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Krishnendu Chatterjee, Zuzana Kom\u00e1rkov\u00e1, Jan K\u0159et\u00ednsk\u00fd,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00598", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00598", "title": "\nLock in Feedback in Sequential Experiment", "abstract": "We often encounter situations in which an experimenter wants to find, by sequential experimentation, , where is a (possibly unknown) function of a well controllable variable . Taking inspiration from physics and engineering, we have designed a new method to address this problem. In this paper, we first introduce the method in continuous time, and then present two algorithms for use in sequential experiments. Through a series of simulation studies, we show that the method is effective for finding maxima of unknown functions by experimentation, even when the maximum of the functions drifts or when the signal to noise ratio is low.", "subjects": "Learning (cs.LG)", "authors": "Maurits Kaptein, Davide Ianuzzi,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00588", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00588", "title": "\nCost-Efficient Throughput Maximization in Multi-Carrier Cognitive Radio  Systems", "abstract": "Cognitive radio (CR) systems allow opportunistic, secondary users (SUs) to access portions of the spectrum that are unused by the network's licensed primary users (PUs), provided that the induced interference does not compromise the primary users' performance guarantees. To account for interference constraints of this type, we consider a flexible spectrum access pricing scheme that charges secondary users based on the interference that they cause to the system's primary users (individually, globally, or both), and we examine how secondary users can maximize their achievable transmission rate in this setting. We show that the resulting non-cooperative game admits a unique Nash equilibrium under very mild assumptions on the pricing mechanism employed by the network operator, and under both static and ergodic (fast-fading) channel conditions. In addition, we derive a dynamic power allocation policy that converges to equilibrium within a few iterations (even for large numbers of users), and which relies only on local signal-to-interference-and-noise measurements; importantly, the proposed algorithm retains its convergence properties even in the ergodic channel regime, despite the inherent stochasticity thereof. Our theoretical analysis is complemented by extensive numerical simulations which illustrate the performance and scalability properties of the proposed pricing scheme under realistic network conditions.", "subjects": "Information Theory (cs.IT)", "authors": "Salvatore D'Oro, Panayotis Mertikopoulos, Aris L. Moustakas, Sergio Palazzo,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00582", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00582", "title": "\nVIP: Incorporating Human Cognitive Biases in a Probabilistic Model of  Retweeting", "abstract": "Information spread in social media depends on a number of factors, including how the site displays information, how users navigate it to find items of interest, users' tastes, and the `virality' of information, i.e., its propensity to be adopted, or retweeted, upon exposure. Probabilistic models can learn users' tastes from the history of their item adoptions and recommend new items to users. However, current models ignore cognitive biases that are known to affect behavior. Specifically, people pay more attention to items at the top of a list than those in lower positions. As a consequence, items near the top of a user's social media stream have higher visibility, and are more likely to be seen and adopted, than those appearing below. Another bias is due to the item's fitness: some items have a high propensity to spread upon exposure regardless of the interests of adopting users. We propose a probabilistic model that incorporates human cognitive biases and personal relevance in the generative model of information spread. We use the model to predict how messages containing URLs spread on Twitter. Our work shows that models of user behavior that account for cognitive factors can better describe and predict user behavior in social media.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Jeon-Hyung Kang, Kristina Lermam,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00561", "category": "Computer Science ", "pdflink": "http://arxiv.org/e-print/1502.00561", "title": "\nQuantum Pairwise Symmetry: Applications in 2D Shape Analysis", "abstract": "A pair of rooted tangents -- defining a quantum triangle -- with an associated quantum wave of spin 1/2 is proposed as the primitive to represent and compute symmetry. Measures of the spin characterize how \"isosceles\" or how \"degenerate\" these triangles are -- which corresponds to their mirror or parallel symmetry. We also introduce a complex-valued kernel to model probability errors in the parameter space, which is more robust to noise and clutter than the classical model.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Marcelo Cicconet, Davi Geiger, Michael Werman,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00558", "category": "Computer Science ", "pdflink": "http://arxiv.org/e-print/1502.00558", "title": "\nComplex-Valued Hough Transforms for Circles", "abstract": "This paper advocates the use of complex variables to represent votes in the Hough transform for circle detection. Replacing the positive numbers classically used in the parameter space of the Hough transforms by complex numbers allows cancellation effects when adding up the votes. Cancellation and the computation of shape likelihood via a complex number's magnitude square lead to more robust solutions than the \"classic\" algorithms, as shown by computational experiments on synthetic and real datasets.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Marcelo Cicconet, Davi Geiger, Michael Werman,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00530", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00530", "title": "\nOptimal Two-Tier Forecasting Power Generation Model in Smart Grids", "abstract": "There has been an increasing trend in the electric power system from a centralized generation-driven grid to a more reliable, environmental friendly, and customer-driven grid. One of the most important issues which the designers of smart grids need to deal with is to forecast the fluctuations of power demand and generation in order to make the power system facilities more flexible to the variable nature of renewable power resources and demand-side. This paper proposes a novel two-tier scheme for forecasting the power demand and generation in a general residential electrical gird which uses the distributed renewable resources as the primary energy resource. The proposed forecasting scheme has two tiers: long-term demand/generation forecaster which is based on Maximum-Likelihood Estimator (MLE) and real-time demand/generation forecaster which is based on Auto-Regressive Integrated Moving-Average (ARIMA) model. The paper also shows that how bulk generation improves the adequacy of proposed residential system by canceling-out the forecasters estimation errors which are in the form of Gaussian White noises.", "subjects": "Systems and Control (cs.SY)", "authors": "Kianoosh G. Boroojeni, Shekoufeh Mokhtari, M.H. Amini, S.S. Iyengar,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00527", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00527", "title": "\nContext Models For Web Search Personalization", "abstract": "We present our solution to the Yandex Personalized Web Search Challenge. The aim of this challenge was to use the historical search logs to personalize top-N document rankings for a set of test users. We used over 100 features extracted from user- and query-depended contexts to train neural net and tree-based learning-to-rank and regression models. Our final submission, which was a blend of several different models, achieved an NDCG@10 of 0.80476 and placed 4'th amongst the 194 teams winning 3'rd prize.", "subjects": "Information Retrieval (cs.IR)", "authors": "Maksims Volkovs,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00524", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00524", "title": "\nUnsupervised Incremental Learning and Prediction of Audio Signals", "abstract": "A system is presented that segments, clusters and predicts musical audio in an unsupervised manner, adjusting the number of (timbre) clusters instantaneously to the audio input. A sequence learning algorithm adapts its structure to a dynamically changing clustering tree. The flow of the system is as follows: 1) segmentation by onset detection, 2) timbre representation of each segment by Mel frequency cepstrum coefficients, 3) discretization by incremental clustering, yielding a tree of different sound classes (e.g. instruments) that can grow or shrink on the fly driven by the instantaneous sound events, resulting in a discrete symbol sequence, 4) extraction of statistical regularities of the symbol sequence, using hierarchical N-grams and the newly introduced conceptual Boltzmann machine, and 5) prediction of the next sound event in the sequence. The system's robustness is assessed with respect to complexity and noisiness of the signal. Clustering in isolation yields an adjusted Rand index (ARI) of 82.7% / 85.7% for data sets of singing voice and drums. Onset detection jointly with clustering achieve an ARI of 81.3% / 76.3% and the prediction of the entire system yields an ARI of 27.2% / 39.2%.", "subjects": "Sound (cs.SD)", "authors": "Ricard Marxer, Hendrik Purwins,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00523", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00523", "title": "\nModeling and Analysis of Scholar Mobility on Scientific Landscape", "abstract": "Scientific literature till date can be thought of as a partially revealed landscape, where scholars continue to unveil hidden knowledge by exploring novel research topics. How do scholars explore the scientific landscape , i.e., choose research topics to work on? We propose an agent-based model of topic mobility behavior where scholars migrate across research topics on the space of science following different strategies, seeking different utilities. We use this model to study whether strategies widely used in current scientific community can provide a balance between individual scientific success and the efficiency and diversity of the whole academic society. Through extensive simulations, we provide insights into the roles of different strategies, such as choosing topics according to research potential or the popularity. Our model provides a conceptual framework and a computational approach to analyze scholars' behavior and its impact on scientific production. We also discuss how such an agent-based modeling approach can be integrated with big real-world scholarly data.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Qiu Fang Ying, Srinivasan Venkatramanan, Dah Ming Chiu,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00521", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00521", "title": "\nA constructive proof of the phase-type characterization theorem", "abstract": "The paper presents a new proof of O'Cinneide's characterization theorem. It is much simpler than the original one and constructive in the sense that we not only show the existence of a phase type representation, but present a procedure which creates a phase type representation. We prove that the procedure succeeds when the conditions of the characterization theorem hold.", "subjects": "Systems and Control (cs.SY)", "authors": "I. Horvath, M. Telek,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00517", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00517", "title": "\nCodes for DNA Sequence Profiles", "abstract": "We consider the problem of storing and retrieving information from synthetic DNA media. The mathematical basis of the problem is the construction and design of sequences that may be discriminated based on their collection of substrings observed through a noisy channel. This problem of reconstructing sequences from traces was first investigated in the noiseless setting under the name of \"Markov type\" analysis. Here, we explain the connection between the reconstruction problem and the problem of DNA synthesis and sequencing, and introduce the notion of a DNA storage channel. We analyze the number of sequence equivalence classes under the channel mapping and propose new asymmetric coding techniques to combat the effects of synthesis and sequencing noise. In our analysis, we make use of restricted de Bruijn graphs and Ehrhart theory for rational polytopes.", "subjects": "Information Theory (cs.IT)", "authors": "Han Mao Kiah, Gregory J. Puleo, Olgica Milenkovic,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00512", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00512", "title": "\nScaling Recurrent Neural Network Language Models", "abstract": "This paper investigates the scaling properties of Recurrent Neural Network Language Models (RNNLMs). We discuss how to train very large RNNs on GPUs and address the questions of how RNNLMs scale with respect to model size, training-set size, computational costs and memory. Our analysis shows that despite being more costly to train, RNNLMs obtain much lower perplexities on standard benchmarks than n-gram models. We train the largest known RNNs and present relative word error rates gains of 18% on an ASR task. We also present the new lowest perplexities on the recently released billion word language modelling benchmark, 1 BLEU point gain on machine translation and a 17% relative hit rate gain in word prediction.", "subjects": "Computation and Language (cs.CL)", "authors": "Will Williams, Niranjani Prasad, David Mrva, Tom Ash, Tony Robinson,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00507", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00507", "title": "\n60 GHz MAC Standardization: Progress and Way Forward", "abstract": "Communication at mmWave frequencies has been the focus in the recent years. In this paper, we discuss standardization efforts in 60 GHz short range communication and the progress therein. We compare the available standards in terms of network architecture, medium access control mechanisms, physical layer techniques and several other features. Comparative analysis indicates that IEEE 802.11ad is likely to lead the short-range indoor communication at 60 GHz. We bring to the fore resolved and unresolved issues pertaining to robust WLAN connectivity at 60 GHz. Further, we discuss the role of mmWave bands in 5G communication scenarios and highlight the further efforts required in terms of research and standardization.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Kishor Chandra, Arjan Doff, Zizheng Cao, R. Venkatesha Prasad, Ignas Niemegeers,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00501", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00501", "title": "\nAn Expressive Deep Model for Human Action Parsing from A Single Image", "abstract": "This paper aims at one newly raising task in vision and multimedia research: recognizing human actions from still images. Its main challenges lie in the large variations in human poses and appearances, as well as the lack of temporal motion information. Addressing these problems, we propose to develop an expressive deep model to naturally integrate human layout and surrounding contexts for higher level action understanding from still images. In particular, a Deep Belief Net is trained to fuse information from different noisy sources such as body part detection and object detection. To bridge the semantic gap, we used manually labeled data to greatly improve the effectiveness and efficiency of the pre-training and fine-tuning stages of the DBN training. The resulting framework is shown to be robust to sometimes unreliable inputs (e.g., imprecise detections of human parts and objects), and outperforms the state-of-the-art approaches.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Zhujin Liang, Xiaolong Wang, Rui Huang, Liang Lin,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00500", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00500", "title": "\nFast and Robust Feature Matching for RGB-D Based Localization", "abstract": "In this paper we present a novel approach to global localization using an RGB-D camera in maps of visual features. For large maps, the performance of pure image matching techniques decays in terms of robustness and computational cost. Particularly, repeated occurrences of similar features due to repeating structure in the world (e.g., doorways, chairs, etc.) or missing associations between observations pose critical challenges to visual localization. We address these challenges using a two-step approach. We first estimate a candidate pose using few correspondences between features of the current camera frame and the feature map. The initial set of correspondences is established by proximity in feature space. The initial pose estimate is used in the second step to guide spatial matching of features in 3D, i.e., searching for associations where the image features are expected to be found in the map. A RANSAC algorithm is used to compute a fine estimation of the pose from the correspondences. Our approach clearly outperforms localization based on feature matching exclusively in feature space, both in terms of estimation accuracy and robustness to failure and allows for global localization in real time (30Hz).", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Miguel Heredia, Felix Endres, Wolfram Burgard, Rafael Sanz,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00495", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00495", "title": "\nA Study of the Matter of SPH Application to Saturated Soil Problems", "abstract": "We present an application of SPH to saturated soilproblems. Herein, the standard SPH formulation was improved to model saturated soil. It is shown that the proposed formulation could yield several advantages such as: it takes into account the pore-water pressure in an accurate manner, it automatically satisfies the dynamics boundary conditions between submerged soil and water, and it reduced the computational cost. Discussions on the use of the standard and the new SPH formulations are also given through some numerical tests. Furthermore, some techniques to obtained correct SPH solution are also proposed and discussed. To the end, this paper suggests that the proposed SPH formulation should be considered as the basic formulation for further developments of SPH for soil-water couple problems", "subjects": "Computational Engineering, Finance, and Science (cs.CE)", "authors": "H. Bui, R. Fukagawa, K. Sako,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1502.00478", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00478", "title": "\nStructured Occlusion Coding for Robust Face Recognition", "abstract": "Occlusion in face recognition is a common yet challenging problem. While sparse representation based classification (SRC) has been shown promising performance in laboratory conditions (i.e. noiseless or random pixel corrupted), it performs much worse in practical scenarios. In this paper, we consider the practical face recognition problem, where the occlusions are predictable and available for sampling. We propose the structured occlusion coding (SOC) to address occlusion problems. Specifically, SOC simultaneously separates the occlusion and classifies the image. In this way, the problem of recognizing an occluded image is turned into seeking a structured sparse solution on occlusion-appended dictionary. In order to construct a well-trained occlusion dictionary, we propose an occlusion mask estimating technique via locality constrained dictionary (LCD), showing striking improvement in occlusion sample. On a category-specific occlusion dictionary, we replace l1 norm sparsity with the structured sparsity which is shown more robust, further enhancing the robustness of our approach. Moreover, SOC achieves significant improvement in handling large occlusion in real world. Extensive experiments are conducted on public data sets to validate the superiority of the proposed algorithm.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Yandong Wen, Weiyang Liu, Meng Yang, Yuli Fu, Youjun Xiang, Rui Hu,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00451", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00451", "title": "\nOn Capacity of Active Relaying in Magnetic Induction based Wireless  Underground Sensor Networks", "abstract": "Wireless underground sensor networks (WUSNs) present a variety of new research challenges. Magnetic induction (MI) based transmission has been proposed to overcome the very harsh propagation conditions in underground communications in recent years. In this approach, induction coils are utilized as antennas in the sensor nodes. This solution achieves longer transmission ranges compared to the traditional electromagnetic (EM) waves based approach. Furthermore, a passive relaying technique has been proposed in the literature where additional resonant circuits are deployed between the nodes. However, this solution is shown to provide only a limited performance improvement under practical system design contraints. In this work, the potential of an active relay device is investigated which may improve the performance of the system by combining the benefits of the traditional wireless relaying and the MI based signal transmission.", "subjects": "Information Theory (cs.IT)", "authors": "S. Kisseleff, B. Sackenreuter, I.F. Akyildiz, W. Gerstacker,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00447", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00447", "title": "\nObtaining Quality-Proved Near Optimal Results for Traveling Salesman  Problem", "abstract": "The traveling salesman problem (TSP) is one of the most challenging NP-hard problems. It has widely applications in various disciplines such as physics, biology, computer science and so forth. The best known approximation algorithm for Symmetric TSP (STSP) whose cost matrix satisfies the triangle inequality (called STSP) is Christofides algorithm which was proposed in 1976 and is a -approximation. Since then no proved improvement is made and improving upon this bound is a fundamental open question in combinatorial optimization. In this paper, for the first time, we propose Truncated Generalized Beta distribution (TGB) for the probability distribution of optimal tour lengths in a TSP. We then introduce an iterative TGB approach to obtain quality-proved near optimal approximation, i.e., (1+)-approximation where is the number of iterations in TGB and is the shape parameters of TGB. The result can approach the true optimum as increases.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Wenhong Tian, Xinyang Wang, Qin Xiong, Yu Chen,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00433", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00433", "title": "\nMulti-sources Randomness Extraction over Finite Fields and Elliptic  Curve", "abstract": "This work is based on the proposal of a deterministic randomness extractor of a random Diffie-Hellman element defined over two prime order multiplicative subgroups of a finite fields , and . We show that the least significant bits of a random element in , are indistinguishable from a uniform bit-string of the same length. One of the main application of this extractor is to replace the use of hash functions in pairing by the use of a good deterministic randomness extractor.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Hortense Boudjou Tchapgnouo, Abdoul Aziz Ciss,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00416", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00416", "title": "\nTowards a solid solution of real-time fire and flame detection", "abstract": "Although the object detection and recognition has received growing attention for decades, a robust fire and flame detection method is rarely explored. This paper presents an empirical study, towards a general and solid approach to fast detect fire and flame in videos, with the applications in video surveillance and event retrieval. Our system consists of three cascaded steps: (1) candidate regions proposing by a background model, (2) fire region classifying with color-texture features and a dictionary of visual words, and (3) temporal verifying. The experimental evaluation and analysis are done for each step. We believe that it is a useful service to both academic research and real-world application. In addition, we release the software of the proposed system with the source code, as well as a public benchmark and data set, including 64 video clips covered both indoor and outdoor scenes under different conditions. We achieve an 82% Recall with 93% Precision on the data set, and greatly improve the performance by state-of-the-arts methods.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Bo Jiang, Yongyi Lu, Xiying Li, Liang Lin,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00407", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00407", "title": "\nA Unified Stochastic Model of Handover Measurement in Mobile Networks", "abstract": "Handover measurement is responsible for finding a handover target and directly decides the performance of mobility management. It is governed by a complex combination of parameters dealing with multi-cell scenarios and system dynamics. A network design has to offer an appropriate handover measurement procedure in such a multi-constraint problem. The present paper proposes a unified framework for the network analysis and optimization. The exposition focuses on the stochastic modeling and addresses its key probabilistic events namely (i) suitable handover target found, (ii) service failure, (iii) handover measurement triggering, and (iv) handover measurement withdrawal. We derive their closed-form expressions and provide a generalized setup for the analysis of handover measurement failure and target cell quality by the best signal quality and st textit. Finally, we show its application and effectiveness in today's 3GPP-LTE cellular networks.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Van Minh Nguyen, Chung Shue Chen, Laurent Thomas,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00389", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00389", "title": "\nPrivacy-preserving Network Functionality Outsourcing", "abstract": "Since the advent of software defined networks (), there have been many attempts to outsource the complex and costly local network functionality, i.e. the middlebox, to the cloud in the same way as outsourcing computation and storage. The privacy issues, however, may thwart the enterprises' willingness to adopt this innovation since the underlying configurations of these middleboxes may leak crucial and confidential information which can be utilized by attackers. To address this new problem, we use firewall as an sample functionality and propose the first privacy preserving outsourcing framework and schemes in SDN. The basic technique that we exploit is a ground-breaking tool in cryptography, the textit. In contrast to the infeasibility in efficiency if a naive approach is adopted, we devise practical schemes that can outsource the middlebox as a blackbox after textit it such that the cloud provider can efficiently perform the same functionality without knowing its underlying private configurations. Both theoretical analysis and experiments on real-world firewall rules demonstrate that our schemes are secure, accurate, and practical.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Junjie Shi, Yuan Zhang, Sheng Zhong,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00378", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00378", "title": "\nEnabling Minimal Dominating Set in Highly Dynamic Distributed Systems", "abstract": "We address the problem of computing a Minimal Dominating Set in highly dynamic distributed systems. We assume weak connectivity, i.e., the network may be disconnected at each time instant and topological changes are unpredictable. We make only weak assumptions on the communication: every process is infinitely often able to communicate with other processes (not necessarily directly). Our contribution is threefold. First, we propose a new definition of minimal dominating set suitable for the context of time-varying graphs that seems more relevant than existing ones. Next, we provide a necessary and sufficient topological condition for the existence of a deterministic algorithm for minimal dominating set construction in our settings. Finally, we propose a new measure of time complexity in time-varying graph in order to to allow fair comparison between algorithms. Indeed, this measure takes account of communication delays attributable to dynamicity of the graph and not to the algorithms.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Swan Dubois, Mohamed-Hamza Kaaouachi, Franck Petit,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00377", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00377", "title": "\nIntegrating Graph Partitioning and Matching for Trajectory Analysis in  Video Surveillance", "abstract": "In order to track the moving objects in long range against occlusion, interruption, and background clutter, this paper proposes a unified approach for global trajectory analysis. Instead of the traditional frame-by-frame tracking, our method recovers target trajectories based on a short sequence of video frames, e.g. frames. We initially calculate a foreground map at each frame, as obtained from a state-of-the-art background model. An attribute graph is then extracted from the foreground map, where the graph vertices are image primitives represented by the composite features. With this graph representation, we pose trajectory analysis as a joint task of spatial graph partitioning and temporal graph matching. The task can be formulated by maximizing a posteriori under the Bayesian framework, in which we integrate the spatio-temporal contexts and the appearance models. The probabilistic inference is achieved by a data-driven Markov Chain Monte Carlo (MCMC) algorithm. Given a peroid of observed frames, the algorithm simulates a ergodic and aperiodic Markov Chain, and it visits a sequence of solution states in the joint space of spatial graph partitioning and temporal graph matching. In the experiments, our method is tested on several challenging videos from the public datasets of visual surveillance, and it outperforms the state-of-the-art methods.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Liang Lin, Yongyi Lu, Yan Pan, Xiaowu Chen,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00374", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00374", "title": "\nAdaptive Scene Category Discovery with Generative Learning and  Compositional Sampling", "abstract": "This paper investigates a general framework to discover categories of unlabeled scene images according to their appearances (i.e., textures and structures). We jointly solve the two coupled tasks in an unsupervised manner: (i) classifying images without pre-determining the number of categories, and (ii) pursuing generative model for each category. In our method, each image is represented by two types of image descriptors that are effective to capture image appearances from different aspects. By treating each image as a graph vertex, we build up an graph, and pose the image categorization as a graph partition process. Specifically, a partitioned sub-graph can be regarded as a category of scenes, and we define the probabilistic model of graph partition by accumulating the generative models of all separated categories. For efficient inference with the graph, we employ a stochastic cluster sampling algorithm, which is designed based on the Metropolis-Hasting mechanism. During the iterations of inference, the model of each category is analytically updated by a generative learning algorithm. In the experiments, our approach is validated on several challenging databases, and it outperforms other popular state-of-the-art methods. The implementation details and empirical analysis are presented as well.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Liang Lin, Ruimao Zhang, Xiaohua Duan,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00367", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00367", "title": "\nA Solution to Yamakami's Problem on Advised Context-free Languages", "abstract": "Yamakami [2011, Theoret. Comput. Sci.] studies context-free languages with advice functions. Here, the length of an advice is assumed to be the same as that of an input. Let CFL and CFL/n denote the class of all context-free languages and that with advice functions, respectively. We let CFL(2) denote the class of intersections of two context-free languages. An interesting direction of a research is asking how complex CFL(2) is, relative to CFL. Yamakami raised a problem whether there is a CFL-immune set in CFL(2) - CFL/n. The best known so far is that LSPACE - CFL/n has a CFL-immune set, where LSPACE denotes the class of languages recognized in logarithmic-space. We present an affirmative solution to his problem. Two key concepts of our proof are the nested palindrome and Yamakami's swapping lemma. The swapping lemma is applicable to the setting where the pumping lemma (Bar-Hillel's lemma) does not work. Our proof is an example showing how useful the swapping lemma is.", "subjects": "Formal Languages and Automata Theory (cs.FL)", "authors": "Toshio Suzuki,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00365", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00365", "title": "\nOn the Performance of MIMO FSO Communications over Double Generalized  Gamma Fading Channels", "abstract": "A major performance degrading factor in free space optical communication (FSO) systems is atmospheric turbulence. Spatial diversity techniques provide a promising approach to mitigate turbulence-induced fading. In this paper, we study the error rate performance of FSO links with spatial diversity over atmospheric turbulence channels described by the Double Generalized Gamma distribution which is a new generic statistical model covering all turbulence conditions. We assume intensity modulation/direct detection with on-off keying and present the BER performance of single-input multiple-output (SIMO), multiple-input single-output (MISO) and multiple-input multiple-output (MIMO) FSO systems over this new channel model.", "subjects": "Information Theory (cs.IT)", "authors": "Mohmmadreza Aminikashani, Murat Uysal, Mohsen Kavehrad,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00364", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00364", "title": "\nOn the Performance of Single- and Multi-carrier Modulation Schemes for  Indoor Visible Light Communication Systems", "abstract": "In this paper, we investigate and compare the performance of single- and multi-carrier modulation schemes for indoor visible light communication (VLC). Particularly, the performances of single carrier frequency domain equalization (SCFDE), orthogonal frequency division multiplexing (OFDM) and on-off keying (OOK) with minimum mean square error equalization (MMSE) are analyzed in order to mitigate the effect of multipath distortion of the indoor optical channel where nonlinearity distortion of light emitting diode (LED) transfer function is taken into account. Our results indicate that SCFDE system, in contrast to OFDM system, does not suffer from high peak to average power ratio (PAPR) and can outperform OFDM and OOK systems. We further investigate the impact of LED bias point on the performance of OFDM systems and show that biasing LED with the optimum value can significantly enhance the performance of the system. Bit-interleaved coded modulation (BICM) is also considered for OFDM and SCFDE systems to further compensate signal degradation due to inter-symbol interference (ISI) and LED nonlinearity.", "subjects": "Information Theory (cs.IT)", "authors": "Mohammadreza Aminikashani, Mohsen Kavehrad,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00363", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00363", "title": "\nIterated Support Vector Machines for Distance Metric Learning", "abstract": "Distance metric learning aims to learn from the given training data a valid distance metric, with which the similarity between data samples can be more effectively evaluated for classification. Metric learning is often formulated as a convex or nonconvex optimization problem, while many existing metric learning algorithms become inefficient for large scale problems. In this paper, we formulate metric learning as a kernel classification problem, and solve it by iterated training of support vector machines (SVM). The new formulation is easy to implement, efficient in training, and tractable for large-scale problems. Two novel metric learning models, namely Positive-semidefinite Constrained Metric Learning (PCML) and Nonnegative-coefficient Constrained Metric Learning (NCML), are developed. Both PCML and NCML can guarantee the global optimality of their solutions. Experimental results on UCI dataset classification, handwritten digit recognition, face verification and person re-identification demonstrate that the proposed metric learning methods achieve higher classification accuracy than state-of-the-art methods and they are significantly more efficient in training.", "subjects": "Learning (cs.LG)", "authors": "Wangmeng Zuo, Faqiang Wang, David Zhang, Liang Lin, Yuchi Huang, Deyu Meng, Lei Zhang,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00357", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00357", "title": "\nOn Restricting No-Junta Boolean Function and Degree Lower Bounds by  Polynomial Method", "abstract": "Let be the set of Boolean functions depending on all variables. We prove that for any , or depends on the remaining variables, for some variable . This existent result suggests a possible way to deal with general Boolean functions via its subfunctions of some restrictions. As an application, we consider the degree lower bound of representing polynomials over finite rings. Let and denote the exact representing degree over the ring (with the integer ) as . Let , where 's are distinct primes, and and 's are positive integers. If is symmetric, then . If is non-symmetric, by the second moment method we prove almost always . In particular, as where and are arbitrary distinct primes, we have for symmetric and almost always for non-symmetric . Hence any -variate symmetric Boolean function can have exact representing degree in at most one finite field, and for non-symmetric functions, with -degree in at most one finite field.", "subjects": "Computational Complexity (cs.CC)", "authors": "Chia-Jung Lee, Satya V. Lokam, Shi-Chun Tsai, Ming-Chuan Yang,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00355", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00355", "title": "\nOn the Accelerating of Two-dimensional Smart Laplacian Smoothing on the  GPU", "abstract": "This paper presents a GPU-accelerated implementation of two-dimensional Smart Laplacian smoothing. This implementation is developed under the guideline of our paradigm for accelerating Laplacianbased mesh smoothing [13]. Two types of commonly used data layouts, Array-of-Structures (AoS) and Structure-of-Arrays (SoA) are used to represent triangular meshes in our implementation. Two iteration forms that have different choices of the swapping of intermediate data are also adopted. Furthermore, the feature CUDA Dynamic Parallelism (CDP) is employed to realize the nested parallelization in Smart Laplacian smoothing. Experimental results demonstrate that: (1) our implementation can achieve the speedups of up to 44x on the GPU GT640; (2) the data layout AoS can always obtain better efficiency than the SoA layout; (3) the form that needs to swap intermediate nodal coordinates is always slower than the one that does not swap data; (4) the version of our implementation with the use of the feature CDP is slightly faster than the version where the CDP is not adopted.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Kunyang Zhao, Gang Mei, Nengxiong Xu, Jiayin Zhang,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00354", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00354", "title": "\nA Web-based Interactive Visual Graph Analytics Platform", "abstract": "This paper proposes a web-based visual graph analytics platform for interactive graph mining, visualization, and real-time exploration of networks. GraphVis is fast, intuitive, and flexible, combining interactive visualizations with analytic techniques to reveal important patterns and insights for sense making, reasoning, and decision making. Networks can be visualized and explored within seconds by simply drag-and-dropping a graph file into the web browser. The structure, properties, and patterns of the network are computed automatically and can be instantly explored in real-time. At the heart of GraphVis lies a multi-level interactive network visualization and analytics engine that allows for real-time graph mining and exploration across multiple levels of granularity simultaneously. Both the graph analytic and visualization techniques (at each level of granularity) are dynamic and interactive, with immediate and continuous visual feedback upon every user interaction (e.g., change of a slider for filtering). Furthermore, nodes, edges, and subgraphs are easily inserted, deleted or exported via a number of novel techniques and tools that make it extremely easy and flexible for exploring, testing hypothesis, and understanding networks in real-time over the web. A number of interactive visual graph analytic techniques are also proposed including interactive role discovery methods, community detection, as well as a number of novel block models for generating graphs with community structure. Finally, we also highlight other key aspects including filtering, querying, ranking, manipulating, exporting, partitioning, as well as tools for dynamic network analysis and visualization, interactive graph generators, and a variety of multi-level network analysis, summarization, and statistical techniques.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Nesreen K. Ahmed, Ryan A. Rossi,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00344", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00344", "title": "\nComplex Background Subtraction by Pursuing Dynamic Spatio-Temporal  Models", "abstract": "Although it has been widely discussed in video surveillance, background subtraction is still an open problem in the context of complex scenarios, e.g., dynamic backgrounds, illumination variations, and indistinct foreground objects. To address these challenges, we propose an effective background subtraction method by learning and maintaining an array of dynamic texture models within the spatio-temporal representations. At any location of the scene, we extract a sequence of regular video bricks, i.e. video volumes spanning over both spatial and temporal domain. The background modeling is thus posed as pursuing subspaces within the video bricks while adapting the scene variations. For each sequence of video bricks, we pursue the subspace by employing the ARMA (Auto Regressive Moving Average) Model that jointly characterizes the appearance consistency and temporal coherence of the observations. During online processing, we incrementally update the subspaces to cope with disturbances from foreground objects and scene changes. In the experiments, we validate the proposed method in several complex scenarios, and show superior performances over other state-of-the-art approaches of background subtraction. The empirical studies of parameter setting and component analysis are presented as well.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Liang Lin, Yuanlu Xu, Xiaodan Liang, Jianhuang Lai,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00341", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00341", "title": "\nDiscriminatively Trained And-Or Graph Models for Object Shape Detection", "abstract": "In this paper, we investigate a novel reconfigurable part-based model, namely And-Or graph model, to recognize object shapes in images. Our proposed model consists of four layers: leaf-nodes at the bottom are local classifiers for detecting contour fragments; or-nodes above the leaf-nodes function as the switches to activate their child leaf-nodes, making the model reconfigurable during inference; and-nodes in a higher layer capture holistic shape deformations; one root-node on the top, which is also an or-node, activates one of its child and-nodes to deal with large global variations (e.g. different poses and views). We propose a novel structural optimization algorithm to discriminatively train the And-Or model from weakly annotated data. This algorithm iteratively determines the model structures (e.g. the nodes and their layouts) along with the parameter learning. On several challenging datasets, our model demonstrates the effectiveness to perform robust shape-based object detection against background clutter and outperforms the other state-of-the-art approaches. We also release a new shape database with annotations, which includes more than 1500 challenging shape instances, for recognition and detection.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Liang Lin, Xiaolong Wang, Wei Yang, Jian-Huang Lai,", "date": "2015-2-2"}, 
{"urllink": "http://arxiv.org/abs/1502.00327", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00327", "title": "\nDoes Dirichlet Prior Smoothing Solve the Shannon Entropy Estimation  Problem?", "abstract": "The Dirichlet prior is widely used in estimating discrete distributions and functionals of discrete distributions. In terms of Shannon entropy estimation, one approach is to plug-in the Dirichlet prior smoothed distribution into the entropy functional, while the other one is to calculate the Bayes estimator for entropy under the Dirichlet prior for squared error, which is the conditional expectation. We show that in general they do emph improve over the maximum likelihood estimator, which plugs-in the empirical distribution into the entropy functional. No matter how we tune the parameters in the Dirichlet prior, this approach cannot achieve the minimax rates in entropy estimation, as recently characterized by Jiao, Venkat, Han, and Weissman, and Wu and Yang. The performance of the minimax rate-optimal estimator with samples is essentially emph as good as that of the Dirichlet smoothed entropy estimators with samples. We harness the theory of approximation using positive linear operators for analyzing the bias of plug-in estimators for general functionals under arbitrary statistical models, thereby further consolidating the interplay between these two fields, which was thoroughly developed and exploited by Jiao, Venkat, Han, and Weissman. We establish new results in approximation theory, and apply them to analyze the bias of the Dirichlet prior smoothed plug-in entropy estimator. This interplay between bias analysis and approximation theory is of relevance and consequence far beyond the specific problem setting in this paper.", "subjects": "Information Theory (cs.IT)", "authors": "Yanjun Han, Jiantao Jiao, Tsachy Weissman,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00326", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00326", "title": "\nAdaptive Estimation of Shannon Entropy", "abstract": "We consider estimating the Shannon entropy of a discrete distribution from i.i.d. samples. Recently, Jiao, Venkat, Han, and Weissman, and Wu and Yang constructed approximation theoretic estimators that achieve the minimax rates in estimating entropy. Their estimators are consistent given samples, where is the alphabet size, and it is the best possible sample complexity. In contrast, the Maximum Likelihood Estimator (MLE), which is the empirical entropy, requires samples. In the present paper we significantly refine the minimax results of existing work. To alleviate the pessimism of minimaxity, we adopt the adaptive estimation framework, and show that the minimax rate-optimal estimator in Jiao, Venkat, Han, and Weissman achieves the minimax rates simultaneously over a nested sequence of subsets of distributions , without knowing the alphabet size or which subset lies in. In other words, their estimator is adaptive with respect to this nested sequence of the parameter space, which is characterized by the entropy of the distribution. We also characterize the maximum risk of the MLE over this nested sequence, and show, for every subset in the sequence, that the performance of the minimax rate-optimal estimator with samples is essentially that of the MLE with samples, thereby further substantiating the generality of the phenomenon discovered by Jiao, Venkat, Han, and Weissman.", "subjects": "Information Theory (cs.IT)", "authors": "Yanjun Han, Jiantao Jiao, Tsachy Weissman,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00324", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00324", "title": "\nModified Fast Fractal Image Compression Algorithm in spatial domain", "abstract": "In this paper a new fractal image compression algorithm is proposed in which the time of encoding process is considerably reduced. The algorithm exploits a domain pool reduction approach, along with using innovative predefined values for contrast scaling factor, S, instead of searching it across [0,1]. Only the domain blocks with entropy greater than a threshold are considered as domain pool. As a novel point, it is assumed that in each step of the encoding process, the domain block with small enough distance shall be found only for the range blocks with low activity (equivalently low entropy). This novel point is used to find reasonable estimations of S, and use them in the encoding process as predefined values, mentioned above, the remaining range blocks are split into four new smaller range blocks and the algorithm must be iterated for them, considered as the other step of encoding process. The algorithm has been examined for some of the well-known images and the results have been compared with the state-of-the-art algorithms. The experiments show that our proposed algorithm has considerably lower encoding time than the other where the encoded images are approximately the same in quality.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "M.Salarian, H. Miar Naimi,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00319", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00319", "title": "\nEfficient refinement of GPS-based localization in urban areas using  visual information and sensor parameter", "abstract": "An efficient method is proposed for refining GPS-acquired location coordinates in urban areas using camera images, Google Street View (GSV) and sensor parameters. The main goal is to compensate for GPS location imprecision in dense area of cities due to proximity to walls and buildings. Avail-able methods for better localization often use visual information by using query images acquired with camera-equipped mobile devices and applying image retrieval techniques to find the closest match in a GPS-referenced image data set. The search areas required for reliable search are about 1-2 sq. Km and the accuracy is typically 25-100 meters. Here we describe a method based on image retrieval where a reliable search can be confined to areas of 0.01 sq. Km and the accuracy in our experiments is less than 10 meters. To test our procedure we created a database by acquiring all Google Street View images close to what is seen by a pedestrian in a large region of downtown Chicago and saved all coordinates and orientation data to be used for confining our search region. Prior knowledge from approximate position of query image is leveraged to address complexity and accuracy issues of our search in a large scale geo-tagged data set. One key aspect that differentiates our work is that it utilizes the sensor information of GPS SOS and the camera orientation in improving localization. Finally we demonstrate retrieval-based technique are less accurate in sparse open areas compared with purely GPS measurement. The effectiveness of our approach is discussed in detail and experimental results show improved performance when compared with regular approaches.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Mahdi Salarian, Rashid Ansari,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00317", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00317", "title": "\nAn Exploration of Cursor tracking Data", "abstract": "Cursor tracking data contains information about website visitors which may provide new ways to understand visitors and their needs. This paper presents an Amazon Mechanical Turk study where participants were tracked as they used modified variants of the Wikipedia and BBC News websites. Participants were asked to complete reading and information-finding tasks. The results showed that it was possible to differentiate between users reading content and users looking for information based on cursor data. The effects of website aesthetics, user interest and cursor hardware were also analysed which showed it was possible to identify hardware from cursor data, but no relationship between cursor data and engagement was found. The implications of these results, from the impact on web analytics to the design of experiments to assess user engagement, are discussed.", "subjects": "Human-Computer Interaction (cs.HC)", "authors": "David Warnock, Mounia Lalmas,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00316", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00316", "title": "\nParallel clustering of high-dimensional social media data streams", "abstract": "We introduce Cloud DIKW as an analysis environment supporting scientific discovery through integrated parallel batch and streaming processing, and apply it to one representative domain application: social media data stream clustering. Recent work demonstrated that high-quality clusters can be generated by representing the data points using high-dimensional vectors that reflect textual content and social network information. Due to the high cost of similarity computation, sequential implementations of even single-pass algorithms cannot keep up with the speed of real-world streams. This paper presents our efforts to meet the constraints of real-time social stream clustering through parallelization. We focus on two system-level issues. Most stream processing engines like Apache Storm organize distributed workers in the form of a directed acyclic graph, making it difficult to dynamically synchronize the state of parallel workers. We tackle this challenge by creating a separate synchronization channel using a pub-sub messaging system. Due to the sparsity of the high-dimensional vectors, the size of centroids grows quickly as new data points are assigned to the clusters. Traditional synchronization that directly broadcasts cluster centroids becomes too expensive and limits the scalability of the parallel algorithm. We address this problem by communicating only dynamic changes of the clusters rather than the whole centroid vectors. Our algorithm under Cloud DIKW can process the Twitter 10% data stream in real-time with 96-way parallelism. By natural improvements to Cloud DIKW, including advanced collective communication techniques developed in our Harp project, we will be able to process the full Twitter stream in real-time with 1000-way parallelism. Our use of powerful general software subsystems will enable many other applications that need integration of streaming and batch data analytics.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Xiaoming Gao, Emilio Ferrara, Judy Qiu,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00303", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00303", "title": "\nDynamic texture and scene classification by transferring deep image  features", "abstract": "Dynamic texture and scene classification are two fundamental problems in understanding natural video content. Extracting robust and effective features is a crucial step towards solving these problems. However the existing approaches suffer from the sensitivity to either varying illumination, or viewpoint changing, or even camera motion, and/or the lack of spatial information. Inspired by the success of deep structures in image classification, we attempt to leverage a deep structure to extract feature for dynamic texture and scene classification. To tackle with the challenges in training a deep structure, we propose to transfer some prior knowledge from image domain to video domain. To be specific, we propose to apply a well-trained Convolutional Neural Network (ConvNet) as a mid-level feature extractor to extract features from each frame, and then form a representation of a video by concatenating the first and the second order statistics over the mid-level features. We term this two-level feature extraction scheme as a Transferred ConvNet Feature (TCoF). Moreover we explore two different implementations of the TCoF scheme, i.e., the textit TCoF and the textit TCoF, in which the mean-removed frames and the difference between two adjacent frames are used as the inputs of the ConvNet, respectively. We evaluate systematically the proposed spatial TCoF and the temporal TCoF schemes on three benchmark data sets, including DynTex, YUPENN, and Maryland, and demonstrate that the proposed approach yields superior performance.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Xianbiao Qi, Chun-Guang Li, Guoying Zhao, Xiaopeng Hong, Matti Pietik\u00e4inen,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00296", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00296", "title": "\nFragile Watermarking Using Finite Field Trigonometrical Transforms", "abstract": "Fragile digital watermarking has been applied for authentication and alteration detection in images. Utilizing the cosine and Hartley transforms over finite fields, a new transform domain fragile watermarking scheme is introduced. A watermark is embedded into a host image via a blockwise application of two-dimensional finite field cosine or Hartley transforms. Additionally, the considered finite field transforms are adjusted to be number theoretic transforms, appropriate for error-free calculation. The employed technique can provide invisible fragile watermarking for authentication systems with tamper location capability. It is shown that the choice of the finite field characteristic is pivotal to obtain perceptually invisible watermarked images. It is also shown that the generated watermarked images can be used as publicly available signature data for authentication purposes.", "subjects": "Multimedia (cs.MM)", "authors": "R. J. Cintra, V. S. Dimitrov, H. M. de Oliveira, R. M. Campello de Souza,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00290", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00290", "title": "\nSurvey on Awareness of Privacy Issues in Ubiquitous Environment", "abstract": "This study aims to determine privacy awareness among people in ubiquitous environment through a questionnaire based survey.", "subjects": "Computers and Society (cs.CY)", "authors": "Huma Tabassum, Sameena Javaid, Humera Farooq,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00281", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00281", "title": "\nHandling Mobility in Dense Networks", "abstract": "Network densification is one of key technologies in future networks to significantly increase network capacity. The gain obtained by network densification for fixed terminals have been studied and proved. However for mobility users, there are a number of issues, such as more frequent handover, packet loss due to high mobility, interference management and so on. The conventional solutions are to handover high speed mobiles to macro base stations or multicast traffic to multiple base stations. These solutions fail to exploit the capacity of dense networks and overuse the backhaul capacity. In this paper we propose a set of solutions to systematically solve the technical challenges of mobile dense networks. We introduce network architecture together with data transmission protocols to support mobile users. A software-defined protocol (SDP) concept is presented so that combinations of transport protocols and physical layer functions can be optimized and triggered on demand. Our solutions can significantly boost performance of dense networks and simplify the packet handling process. Importantly, the gain brought by network densification to fixed users can also be achieved for mobile users.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Ngoc-D\u0169ng \u0110\u00e0o, Hang Zhang, Hamid Farmanbar, Xu Li,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00277", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00277", "title": "\nFast Finite Field Hartley Transforms Based on Hadamard Decomposition", "abstract": "A new transform over finite fields, the finite field Hartley transform (FFHT), was recently introduced and a number of promising applications on the design of efficient multiple access systems and multilevel spread spectrum sequences were proposed. The FFHT exhibits interesting symmetries, which are exploited to derive tailored fast transform algorithms. The proposed fast algorithms are based on successive decompositions of the FFHT by means of Hadamard-Walsh transforms (HWT). The introduced decompositions meet the lower bound on the multiplicative complexity for all the cases investigated. The complexity of the new algorithms is compared with that of traditional algorithms.", "subjects": "Numerical Analysis (cs.NA)", "authors": "H. M. de Oliveira, R. G. F. T\u00e1vora, R. J. Cintra, R. M. Campello de Souza,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00258", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00258", "title": "\nLearning Latent Spatio-Temporal Compositional Model for Human Action  Recognition", "abstract": "Action recognition is an important problem in multimedia understanding. This paper addresses this problem by building an expressive compositional action model. We model one action instance in the video with an ensemble of spatio-temporal compositions: a number of discrete temporal anchor frames, each of which is further decomposed to a layout of deformable parts. In this way, our model can identify a Spatio-Temporal And-Or Graph (STAOG) to represent the latent structure of actions e.g. triple jumping, swinging and high jumping. The STAOG model comprises four layers: (i) a batch of leaf-nodes in bottom for detecting various action parts within video patches; (ii) the or-nodes over bottom, i.e. switch variables to activate their children leaf-nodes for structural variability; (iii) the and-nodes within an anchor frame for verifying spatial composition; and (iv) the root-node at top for aggregating scores over temporal anchor frames. Moreover, the contextual interactions are defined between leaf-nodes in both spatial and temporal domains. For model training, we develop a novel weakly supervised learning algorithm which iteratively determines the structural configuration (e.g. the production of leaf-nodes associated with the or-nodes) along with the optimization of multi-layer parameters. By fully exploiting spatio-temporal compositions and interactions, our approach handles well large intra-class action variance (e.g. different views, individual appearances, spatio-temporal structures). The experimental results on the challenging databases demonstrate superior performance of our approach over other competing methods.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Xiaodan Liang, Liang Lin, Liangliang Cao,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00256", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00256", "title": "\nHuman Re-identification by Matching Compositional Template with Cluster  Sampling", "abstract": "This paper aims at a newly raising task in visual surveillance: re-identifying people at a distance by matching body information, given several reference examples. Most of existing works solve this task by matching a reference template with the target individual, but often suffer from large human appearance variability (e.g. different poses/views, illumination) and high false positives in matching caused by conjunctions, occlusions or surrounding clutters. Addressing these problems, we construct a simple yet expressive template from a few reference images of a certain individual, which represents the body as an articulated assembly of compositional and alternative parts, and propose an effective matching algorithm with cluster sampling. This algorithm is designed within a candidacy graph whose vertices are matching candidates (i.e. a pair of source and target body parts), and iterates in two steps for convergence. (i) It generates possible partial matches based on compatible and competitive relations among body parts. (ii) It confirms the partial matches to generate a new matching solution, which is accepted by the Markov Chain Monte Carlo (MCMC) mechanism. In the experiments, we demonstrate the superior performance of our approach on three public databases compared to existing methods.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Yuanlu Xu, Liang Lin, Wei-Shi Zheng, Xiaobai Liu,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00254", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00254", "title": "\nFreehand Sketch Recognition Using Deep Features", "abstract": "Freehand sketches often contain sparse visual detail. In spite of the sparsity, they are easily and consistently recognized by humans across cultures, languages and age groups. Therefore, analyzing such sparse sketches can aid our understanding of the neuro-cognitive processes involved in visual representation and recognition. In the recent past, Convolutional Neural Networks (CNNs) have emerged as a powerful framework for feature representation and recognition for a variety of image domains. However, the domain of sketch images has not been explored. This paper introduces a freehand sketch recognition framework based on \"deep\" features extracted from CNNs. We use two popular CNNs for our experiments -- Imagenet CNN and a modified version of LeNet CNN. We evaluate our recognition framework on a publicly available benchmark database containing thousands of freehand sketches depicting everyday objects. Our results are an improvement over the existing state-of-the-art accuracies by 3% - 11%. The effectiveness and relative compactness of our deep features also make them an ideal candidate for related problems such as sketch-based image retrieval. In addition, we provide a preliminary glimpse of how such features can help identify crucial attributes (e.g. object-parts) of the sketched objects.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Ravi Kiran Sarvadevabhatla, R. Venkatesh Babu,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00250", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00250", "title": "\nDriver distraction detection and recognition using RGB-D sensor", "abstract": "Driver inattention assessment has become a very active field in intelligent transportation systems. Based on active sensor Kinect and computer vision tools, we have built an efficient module for detecting driver distraction and recognizing the type of distraction. Based on color and depth map data from the Kinect, our system is composed of four sub-modules. We call them eye behavior (detecting gaze and blinking), arm position (is the right arm up, down, right of forward), head orientation, and facial expressions. Each module produces relevant information for assessing driver inattention. They are merged together later on using two different classification strategies: AdaBoost classifier and Hidden Markov Model. Evaluation is done using a driving simulator and 8 drivers of different gender, age and nationality for a total of more than 8 hours of recording. Qualitative and quantitative results show strong and accurate detection and recognition capacity (85% accuracy for the type of distraction and 90% for distraction detection). Moreover, each module is obtained independently and could be used for other types of inference, such as fatigue detection, and could be implemented for real cars systems.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "C\u00e9line Craye, Fakhri Karray,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00245", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00245", "title": "\nInjury risk prediction for traffic accidents in Porto Alegre/RS, Brazil", "abstract": "This study describes the experimental application of Machine Learning techniques to build prediction models that can assess the injury risk associated with traffic accidents. This work uses an freely available data set of traffic accident records that took place in the city of Porto Alegre/RS (Brazil) during the year of 2013. This study also provides an analysis of the most important attributes of a traffic accident that could produce an outcome of injury to the people involved in the accident.", "subjects": "Learning (cs.LG)", "authors": "Christian S. Perone,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00238", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00238", "title": "\nOn instruction sets for Boolean registers in program algebra", "abstract": "In program algebra, different instruction sets for Boolean registers are conceivable. In previous work on instruction sequence size complexity, we chose instruction sets for Boolean registers that contain only a few of the possible instructions. In the current paper, we study instruction sequence size bounded functional completeness of instruction sets for Boolean registers. This work is among other things a requisite for making progress with proving lower bounds of non-asymptotic instruction sequence size complexity in cases where auxiliary Boolean registers may be used.", "subjects": "Programming Languages (cs.PL)", "authors": "J. A. Bergstra, C. A. Middelburg,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00237", "category": "Computer Science ", "pdflink": "http://arxiv.org/e-print/1502.00237", "title": "\nEnsuring a Secure and Resilient Smart Grid: Cyber-Attacks and  Countermeasures", "abstract": "This paper surveys the latest on Smart Grid security. It focuses on the deep understanding of the risk in terms of threats, vulnerabilities and consequences that arise from cyber-attacks.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Charalambos Konstantinou,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00231", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00231", "title": "\nFeature Selection with Redundancy-complementariness Dispersion", "abstract": "Feature selection has attracted significant attention in data mining and machine learning in the past decades. Many existing feature selection methods eliminate redundancy by measuring pairwise inter-correlation of features, whereas the complementariness of features and higher inter-correlation among more than two features are ignored. In this study, a modification item concerning the complementariness of features is introduced in the evaluation criterion of features. Additionally, in order to identify the interference effect of already-selected False Positives (FPs), the redundancy-complementariness dispersion is also taken into account to adjust the measurement of pairwise inter-correlation of features. To illustrate the effectiveness of proposed method, classification experiments are applied with four frequently used classifiers on ten datasets. Classification results verify the superiority of proposed method compared with five representative feature selection methods.", "subjects": "Learning (cs.LG)", "authors": "Zhijun Chen, Chaozhong Wu, Yishi Zhang, Zhen Huang, Bin Ran, Ming Zhong, Nengchao Lyu,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00229", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00229", "title": "\nCan \"Hot Spots\" in the Sciences Be Mapped Using the Dynamics of  Aggregated Journal-Journal Citation Relations?", "abstract": "Using three years of the Journal Citation Reports (2011, 2012, and 2013), indicators of change are developed involving only changes of more than one standard deviation above average. Two forms of change are distinguished: monotonic increases or decreases of citation intensity (cited or citing) and critical revisions of the a posteriori (2013) prediction in 2012 on the basis of 2011 data. Changes can be studied at the level of journals using the margin totals of entropy production along the row or column vectors, but also at the level of links among groups of journals by importing the transition matrices into network analysis and visualization programs (and using community-finding algorithms). The latter analysis improves on the former by being more fine-grained. Changes are found in the giant component representing the major disciplinary structures; and significant changes at the level of specialties are indicated in 52 components which are mostly on the applied side of the sciences and engineering.", "subjects": "Digital Libraries (cs.DL)", "authors": "Loet Leydesdorff,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00215", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00215", "title": "\nA Study on the Impact of Wind Generation on the Stability of  Electromechanical Oscillations", "abstract": "Wind is becoming an increasingly significant source of energy in modern power generation. Amongst existing technologies, Variable Speed Wind Turbines (VSWT) equipped with Double Fed Induction Generators (DFIG) is widely deployed. Consequently, power systems are now experiencing newer power flow patterns and operating conditions. This paper investigates the impact of a DFIG based Wind Farm (WF) on the stability of electromechanical oscillations. This is achieved by performing modal analysis to evaluate the stability of a two-area power network when subjected to different wind penetration levels and different geographical installed locations. The approach via eigenvalues analysis involves the design of voltage and Supplementary Damping Controllers (SDCs) that contribute to network damping. The effect of Power System Stabilizer (PSS) is also examined for several network conditions. Simulations demonstrate a damping improvement up to 933% when the control systems are activated and the system operates with 25% wind integration.", "subjects": "Systems and Control (cs.SY)", "authors": "Charalambos Konstantinou,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00212", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00212", "title": "\nMulti-User MIMO Receivers With Partial State Information", "abstract": "We consider a multi-user multiple-input multiple-output (MU-MIMO) system that uses orthogonal frequency division multiplexing (OFDM). Several receivers are developed for data detection of MU-MIMO transmissions where two users share the same OFDM time and frequency resources. The receivers have partial state information about the MU-MIMO transmission with each receiver having knowledge of the MU-MIMO channel, however the modulation constellation of the co-scheduled user is unknown. We propose a joint maximum likelihood (ML) modulation classification of the co-scheduled user and data detection receiver using the max-log-MAP approximation. It is shown that the decision metric for the modulation classification is an accumulation over a set of tones of Euclidean distance computations that are also used by the max-log-MAP detector for bit log-likelihood ratio (LLR) soft decision generation. An efficient hardware implementation emerges that exploits this commonality between the classification and detection steps and results in sharing of the hardware resources. Comparisons of the link performance of the proposed receiver to several linear receivers is demonstrated through computer simulations. It is shown that the proposed receiver offers unit[1.5] improvement in signal-to-noise ratio (SNR) over the nulling projection receiver at block error rate (BLER) for -QAM with turbo code rate of in the case of zero transmit and receiver antenna correlations. However, in the case of high antenna correlation, the linear receiver approaches suffer significant loss relative to the optimal receiver.", "subjects": "Information Theory (cs.IT)", "authors": "Ahmad Gomaa, Louay M.A. Jalloul, Krishna S. Gomadam, Djordje Tujkovic, Mohammad M. Mansour,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00210", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00210", "title": "\nA New Parameter Estimation Algorithm Based on Sub-band Dual Frequency  Conjugate LVT", "abstract": "A new parameter estimation algorithm, known as Sub-band Dual Frequency Conjugate LVT (SDFC-LVT), is proposed for the ground moving targets. This algorithm first constructs two sub-band signals with different central frequencies. After that, the two signals are shifted by different values in frequency domain and a new signal is constructed by multiplying one with the conjugate of the other. Finally, Keystone transform and LVT operation are performed on the constructed signal to attain the estimates. The cross-term and the performance of the proposed method are analyzed in detail. Since the equivalent carrier frequency is reduced greatly, the proposed method is capable of obtaining the accurate parameter estimates and resolving the problem of ambiguity which invalidates Keystone transform. It is search-free and can compensate the range walk of multiple targets simultaneously, thereby reducing the computational burden. The effectiveness of the proposed method is demonstrated by both simulated and real data.", "subjects": "Information Theory (cs.IT)", "authors": "Jing Tian, Wei Cui, Si-liang Wu,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00206", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00206", "title": "\nCross-Layer Multi-Cloud Real-Time Application QoS Monitoring and  Benchmarking As-a-Service Framework", "abstract": "Cloud computing provides on-demand access to affordable hardware (multi-core CPUs, GPUs, disks, and networking equipment) and software (databases, application servers and data processing frameworks) platforms with features such as elasticity, pay-per-use, low upfront investment and low time to market. This has led to the proliferation of business critical applications that leverage various cloud platforms. Such applications hosted on single or multiple cloud provider platforms have diverse characteristics requiring extensive monitoring and benchmarking mechanisms to ensure run-time Quality of Service (QoS) (e.g., latency and throughput). This paper proposes, develops and validates CLAMBS:Cross-Layer Multi-Cloud Application Monitoring and Benchmarking as-a-Service for efficient QoS monitoring and benchmarking of cloud applications hosted on multi-clouds environments. The major highlight of CLAMBS is its capability of monitoring and benchmarking individual application components such as databases and web servers, distributed across cloud layers, spread among multiple cloud providers. We validate CLAMBS using prototype implementation and extensive experimentation and show that CLAMBS efficiently monitors and benchmarks application components on multi-cloud platforms including Amazon EC2 and Microsoft Azure.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Khalid Alhamazani, Rajiv Ranjan, Prem Prakash Jayaraman, Karan Mitra, Chang Liu, Fethi Rabhi, Dimitrios Georgakopoulos, Lizhe Wang,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00202", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00202", "title": "\nFountain Uncorrectable Sets and Finite-Length Analysis", "abstract": "Decoding performance of Fountain codes for the binary erasure channel (BEC) depends on two aspects. One is the essential code structure, on which stopping set analysis operates. The other is the effect from the channel characteristic, which is difficult to give a precise estimation. To tackle these problems, in this paper, we propose a solution to analyzing the performance of Fountain codes based on the uncorrectable set. We give the condition for Fountain decoding failure over the BEC. Then, we conduct the analysis of uncorrectable set on Fountain codes. Finally, we combine the stopping set and the uncorrectable set to provide the integrated analysis on the performance of Fountain codes for BEC.", "subjects": "Information Theory (cs.IT)", "authors": "Wen Ji, Bo-Wei Chen, Yiqiang Chen,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00200", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00200", "title": "\nBase Station Switching Problem for Green Cellular Networks with Social  Spider Algorithm", "abstract": "With the recent explosion in mobile data, the energy consumption and carbon footprint of the mobile communications industry is rapidly increasing. It is critical to develop more energy-efficient systems in order to reduce the potential harmful effects to the environment. One potential strategy is to switch off some of the under-utilized base stations during off-peak hours. In this paper, we propose a binary Social Spider Algorithm to give guidelines for selecting base stations to switch off. In our implementation, we use a penalty function to formulate the problem and manage to bypass the large number of constraints in the original optimization problem. We adopt several randomly generated cellular networks for simulation and the results indicate that our algorithm can generate superior performance.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "James J.Q. Yu, Victor O.K. Li,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00199", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00199", "title": "\nChemical Reaction Optimization for the Set Covering Problem", "abstract": "The set covering problem (SCP) is one of the representative combinatorial optimization problems, having many practical applications. This paper investigates the development of an algorithm to solve SCP by employing chemical reaction optimization (CRO), a general-purpose metaheuristic. It is tested on a wide range of benchmark instances of SCP. The simulation results indicate that this algorithm gives outstanding performance compared with other heuristics and metaheuristics in solving SCP.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "James J.Q. Yu, Albert Y.S. Lam, Victor O.K. Li,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00197", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00197", "title": "\nAn Inter-molecular Adaptive Collision Scheme for Chemical Reaction  Optimization", "abstract": "Optimization techniques are frequently applied in science and engineering research and development. Evolutionary algorithms, as a kind of general-purpose metaheuristic, have been shown to be very effective in solving a wide range of optimization problems. A recently proposed chemical-reaction-inspired metaheuristic, Chemical Reaction Optimization (CRO), has been applied to solve many global optimization problems. However, the functionality of the inter-molecular ineffective collision operator in the canonical CRO design overlaps that of the on-wall ineffective collision operator, which can potential impair the overall performance. In this paper we propose a new inter-molecular ineffective collision operator for CRO for global optimization. To fully utilize our newly proposed operator, we also design a scheme to adapt the algorithm to optimization problems with different search space characteristics. We analyze the performance of our proposed algorithm with a number of widely used benchmark functions. The simulation results indicate that the new algorithm has superior performance over the canonical CRO.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "James J.Q. Yu, Victor O.K. Li, Albert Y.S. Lam,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00196", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00196", "title": "\nOptimal V2G Scheduling of Electric Vehicles and Unit Commitment using  Chemical Reaction Optimization", "abstract": "An electric vehicle (EV) may be used as energy storage which allows the bi-directional electricity flow between the vehicle's battery and the electric power grid. In order to flatten the load profile of the electricity system, EV scheduling has become a hot research topic in recent years. In this paper, we propose a new formulation of the joint scheduling of EV and Unit Commitment (UC), called EVUC. Our formulation considers the characteristics of EVs while optimizing the system total running cost. We employ Chemical Reaction Optimization (CRO), a general-purpose optimization algorithm to solve this problem and the simulation results on a widely used set of instances indicate that CRO can effectively optimize this problem.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "James J.Q. Yu, Victor O.K. Li, Albert Y.S. Lam,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00195", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00195", "title": "\nSensor Deployment for Air Pollution Monitoring Using Public  Transportation System", "abstract": "Air pollution monitoring is a very popular research topic and many monitoring systems have been developed. In this paper, we formulate the Bus Sensor Deployment Problem (BSDP) to select the bus routes on which sensors are deployed, and we use Chemical Reaction Optimization (CRO) to solve BSDP. CRO is a recently proposed metaheuristic designed to solve a wide range of optimization problems. Using the real world data, namely Hong Kong Island bus route data, we perform a series of simulations and the results show that CRO is capable of solving this optimization problem efficiently.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "James J.Q. Yu, Victor O.K. Li, Albert Y.S. Lam,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00194", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00194", "title": "\nReal-Coded Chemical Reaction Optimization with Different Perturbation  Functions", "abstract": "Chemical Reaction Optimization (CRO) is a powerful metaheuristic which mimics the interactions of molecules in chemical reactions to search for the global optimum. The perturbation function greatly influences the performance of CRO on solving different continuous problems. In this paper, we study four different probability distributions, namely, the Gaussian distribution, the Cauchy distribution, the exponential distribution, and a modified Rayleigh distribution, for the perturbation function of CRO. Different distributions have different impacts on the solutions. The distributions are tested by a set of well-known benchmark functions and simulation results show that problems with different characteristics have different preference on the distribution function. Our study gives guidelines to design CRO for different types of optimization problems.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "James J.Q. Yu, Albert Y.S. Lam, Victor O.K. Li,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00193", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00193", "title": "\nEvolutionary Artificial Neural Network Based on Chemical Reaction  Optimization", "abstract": "Evolutionary algorithms (EAs) are very popular tools to design and evolve artificial neural networks (ANNs), especially to train them. These methods have advantages over the conventional backpropagation (BP) method because of their low computational requirement when searching in a large solution space. In this paper, we employ Chemical Reaction Optimization (CRO), a newly developed global optimization method, to replace BP in training neural networks. CRO is a population-based metaheuristics mimicking the transition of molecules and their interactions in a chemical reaction. Simulation results show that CRO outperforms many EA strategies commonly used to train neural networks.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "James J.Q. Yu, Albert Y.S. Lam, Victor O.K. Li,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00192", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00192", "title": "\nPose and Shape Estimation with Discriminatively Learned Parts", "abstract": "We introduce a new approach for estimating the 3D pose and the 3D shape of an object from a single image. Given a training set of view exemplars, we learn and select appearance-based discriminative parts which are mapped onto the 3D model from the training set through a facil- ity location optimization. The training set of 3D models is summarized into a sparse set of shapes from which we can generalize by linear combination. Given a test picture, we detect hypotheses for each part. The main challenge is to select from these hypotheses and compute the 3D pose and shape coefficients at the same time. To achieve this, we optimize a function that minimizes simultaneously the geometric reprojection error as well as the appearance matching of the parts. We apply the alternating direction method of multipliers (ADMM) to minimize the resulting convex function. We evaluate our approach on the Fine Grained 3D Car dataset with superior performance in shape and pose errors. Our main and novel contribution is the simultaneous solution for part localization, 3D pose and shape by maximizing both geometric and appearance compatibility.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Menglong Zhu, Xiaowei Zhou, Kostas Daniilidis,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00189", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00189", "title": "\nRewriting Flash Memories by Message Passing", "abstract": "This paper constructs WOM codes that combine rewriting and error correction for mitigating the reliability and the endurance problems in flash memory. We consider a rewriting model that is of practical interest to flash applications where only the second write uses WOM codes. Our WOM code construction is based on binary erasure quantization with LDGM codes, where the rewriting uses message passing and has potential to share the efficient hardware implementations with LDPC codes in practice. We show that the coding scheme achieves the capacity of the rewriting model. Extensive simulations show that the rewriting performance of our scheme compares favorably with that of polar WOM code in the rate region where high rewriting success probability is desired. We further augment our coding schemes with error correction capability. By drawing a connection to the conjugate code pairs studied in the context of quantum error correction, we develop a general framework for constructing error-correction WOM codes. Under this framework, we give an explicit construction of WOM codes whose codewords are contained in BCH codes.", "subjects": "Information Theory (cs.IT)", "authors": "Eyal En Gad, Wentao Huang, Yue Li, Jehoshua Bruck,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00182", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00182", "title": "\nHigh Dimensional Low Rank plus Sparse Matrix Decomposition", "abstract": "This paper is concerned with the problem of low rank plus sparse matrix decomposition for big data applications. Most of the existing decomposition algorithms are not applicable in high dimensional settings for two main reasons. First, they need the whole data to extract the low-rank/sparse components; second, they are based on an optimization problem whose dimensionality is equal to the dimension of the given data. In this paper, we present a randomized decomposition algorithm which exploits the low dimensional geometry of the low rank matrix to reduce the complexity. The low rank plus sparse matrix decomposition problem is reformulated as a columns-rows subspace learning problem. It is shown that when the columns/rows subspace of the low rank matrix is incoherent with the standard basis, the columns/rows subspace can be learned from a small random subset of the columns/rows of the given data matrix. Thus, the high dimensional decomposition problem is converted to a subspace learning problem (which is a low dimensional optimization problem) and it uses a small random subset of the data rather than the whole big data matrix. We derive sufficient conditions, which are no more stringent than those for existing methods, to ensure exact decomposition with high probability.", "subjects": "Numerical Analysis (cs.NA)", "authors": "Mostafa Rahmani, George Atia,", "date": "2015-2-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00172", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00172", "title": "\nLeakage-resilient Cryptography with key derived from sensitive data", "abstract": "In this paper we address the problem of large space consumption for protocols in the Bounded Retrieval Model (BRM), which require users to store large secret keys subject to adversarial leakage. We propose a method to derive keys for such protocols on-the-fly from weakly random private data (like text documents or photos, users keep on their disks anyway for non-cryptographic purposes) in such a way that no extra storage is needed. We prove that any leakage-resilient protocol (belonging to a certain, arguably quite broad class) when run with a key obtained this way retains a similar level of security as the original protocol had. Additionally, we guarantee privacy of the data the actual keys are derived from. That is, an adversary can hardly gain any knowledge about the private data except that he could otherwise obtain via leakage. Our reduction works in the Random Oracle model.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Konrad Durnoga, Tomasz Kazana, Micha\u0142 Zaj\u0105c, Maciej Zdanowicz,", "date": "2015-1-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00166", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00166", "title": "\nModelling of trends in Twitter using retweet graph dynamics", "abstract": "In this paper we model user behaviour in Twitter to capture the emergence of trending topics. For this purpose, we first extensively analyse tweet datasets of several different events. In particular, for these datasets, we construct and investigate the retweet graphs. We find that the retweet graph for a trending topic has a relatively dense largest connected component (LCC). Next, based on the insights obtained from the analyses of the datasets, we design a mathematical model that describes the evolution of a retweet graph by three main parameters. We then quantify, analytically and by simulation, the influence of the model parameters on the basic characteristics of the retweet graph, such as the density of edges and the size and density of the LCC. Finally, we put the model in practice, estimate its parameters and compare the resulting behavior of the model to our datasets.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Marijn ten Thij, Tanneke Ouboter, Daniel Worm, Nelly Litvak, Hans van den Berg, Sandjai Bhulai,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00164", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00164", "title": "\nContext-aware Computing in the Internet of Things: A Survey on Internet  of Things From Industrial Market Perspective", "abstract": "The Internet of Things (IoT) is a dynamic global information network consisting of Internet-connected objects, such as RFIDs, sensors, and actuators, as well as other instruments and smart appliances that are becoming an integral component of the Internet. Over the last few years, we have seen a plethora of IoT solutions making their way into the industry marketplace. Context-aware communication and computing has played a critical role throughout the last few years of ubiquitous computing and is expected to play a significant role in the IoT paradigm as well. In this article, we examine a variety of popular and innovative IoT solutions in terms of context-aware technology perspectives. More importantly, we evaluate these IoT solutions using a framework that we built around well-known context-aware computing theories. This survey is intended to serve as a guideline and a conceptual framework for contextaware product development and research in the IoT paradigm. It also provides a systematic exploration of existing IoT products in the marketplace and highlights a number of potentially significant research directions and trends.", "subjects": "Computers and Society (cs.CY)", "authors": "Charith Perera, Chi Harold Liu Member, Srimal Jayawardena, Min Chen,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00163", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00163", "title": "\nSpectral Detection in the Censored Block Model", "abstract": "We consider the problem of partially recovering hidden binary variables from the observation of (few) censored edge weights, a problem with applications in community detection, correlation clustering and synchronization. We describe two spectral algorithms for this task based on the non-cktracking and the Bethe Hessian operators. These algorithms are shown to be asymptotically optimal for the partial recovery problem, in that they detect the hidden assignment as soon as it is information theoretically possible to do so.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Alaa Saade, Florent Krzakala, Marc Lelarge, Lenka Zdeborov\u00e1,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00152", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00152", "title": "\nMinimizing Regret in Dynamic Decision Problems", "abstract": "The menu-dependent nature of regret-minimization creates subtleties when it is applied to dynamic decision problems. Firstly, it is not clear whether emph should be included in the emph, with respect to which regrets are computed, at different points of the decision problem. If forgone opportunities are included, however, we can characterize when a form of dynamic consistency is guaranteed. Secondly, more subtleties arise when sophistication is used to deal with dynamic inconsistency. In the full version of this paper, we examine, axiomatically and by common examples, the implications of different menu definitions for sophisticated, regret-minimizing agents.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Joseph Y. Halpern, Samantha Leung,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00145", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00145", "title": "\nAn in-between \"implicit\" and \"explicit\" complexity: Automata", "abstract": "Implicit Computational Complexity makes two aspects implicit, by manipulating programming languages rather than models of com-putation, and by internalizing the bounds rather than using external measure. We survey how automata theory contributed to complexity with a machine-dependant with implicit bounds model.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Cl\u00e9ment Aubert,", "date": "2015-1-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00143", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00143", "title": "\nHybrid model for LTE Network-Assisted D2D communications", "abstract": "New Architecture to support D2D communications, where discovery is made directly between devices while communications occur with the help of the E-Node B", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Thouraya Toukabri Gunes, Hossam Afifi,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00138", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00138", "title": "\nCompositional Invariant Generation via Linear Recurrence Analysis", "abstract": "This paper presents a new method for automatically generating numerical invariants for imperative programs. Given a program, our procedure computes a binary input/output relation on program states which over-approximates the behaviour of the program. It is compositional in the sense that it operates by decomposing the program into parts, computing an abstract meaning of each part, and then composing the meanings. Our method for approximating loop behaviour is based on first approximating the meaning of the loop body, extracting recurrence relations from that approximation, and then using the closed forms to approximate the loop. Our experiments demonstrate that on verification tasks, our method is competitive with leading invariant generation and verification tools.", "subjects": "Programming Languages (cs.PL)", "authors": "Azadeh Farzan, Zachary Kincaid,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00137", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00137", "title": "\nHybrid Radio/Free-Space Optical Design for Next Generation Backhaul  Systems", "abstract": "The deluge of date rate in today's networks poses a cost burden on the backhaul network design. Designing cost efficient backhaul solutions becomes an interesting, yet challenging, problem. Traditional technologies for backhaul networks include either radio-frequency backhauls (RF) or optical fibers (OF). While RF is a cost-effective solution as compared to OF, it supports lower data rate requirements. Another promising backhaul solution that may combine both a high data rate and a relatively low cost is the free-space optics (FSO). FSO, however, is sensitive to nature conditions (e.g. rain, fog, line-of-sight, etc.). A more reliable alternative is therefore to combine RF and FSO solutions through a hybrid structure called hybrid RF/FSO. Consider a backhaul network, where the base-stations (BS) can be connected to each other either via OF or via hybrid RF/FSO backhaul links. The paper addresses the problem of minimizing the cost of backhaul planning under connectivity and data rates constraints, so as to choose the appropriate cost-effective backhaul type between BSs (i.e., either OF or hybrid RF/FSO). The paper solves the problem using graph theory techniques by introducing the corresponding planning graph. It shows that under a specified realistic assumption about the cost of OF and hybrid RF/FSO links, the problem is equivalent to a maximum weight clique problem, which can can be solved with moderate complexity. Simulation results show that our proposed solution shows a close-to-optimal performance, especially for practical prices of the hybrid RF/FSO.", "subjects": "Information Theory (cs.IT)", "authors": "Ahmed Douik, Hayssam Dahrouj, Tareq Y. Al-Naffouri, Mohamed-Slim Alouini,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00134", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00134", "title": "\nThe Emerging Internet of Things Marketplace From an Industrial  Perspective: A Survey", "abstract": "The Internet of Things (IoT) is a dynamic global information network consisting of internet-connected objects, such as Radio-frequency identification (RFIDs), sensors, actuators, as well as other instruments and smart appliances that are becoming an integral component of the future internet. Over the last decade, we have seen a large number of the IoT solutions developed by start-ups, small and medium enterprises, large corporations, academic research institutes (such as universities), and private and public research organisations making their way into the market. In this paper, we survey over one hundred IoT smart solutions in the marketplace and examine them closely in order to identify the technologies used, functionalities, and applications. More importantly, we identify the trends, opportunities and open challenges in the industry-based the IoT solutions. Based on the application domain, we classify and discuss these solutions under five different categories: smart wearable, smart home, smart, city, smart environment, and smart enterprise. This survey is intended to serve as a guideline and conceptual framework for future research in the IoT and to motivate and inspire further developments. It also provides a systematic exploration of existing research and suggests a number of potentially significant research directions.", "subjects": "Computers and Society (cs.CY)", "authors": "Charith Perera, Chi Harold Liu, Srimal Jayawardena,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00130", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00130", "title": "\nThe Search for Computational Intelligence", "abstract": "We define and explore in simulation several rules for the local evolution of generative rules for 1D and 2D cellular automata. Our implementation uses strategies from conceptual blending. We discuss potential applications to modelling social dynamics.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "Joseph Corneli, Ewen Maclean,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00121", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00121", "title": "\nTowards a Systems Engineering Essence", "abstract": "SEMAT/OMG Essence provides a powerful Language and a Kernel for describing software development processes. How can it be tweaked to apply it to systems engineering methods description? We must harmonize Essence and various systems engineering standards in order to provide a more formal system approach to obtaining a Systems Engineering Essence. In this paper, an approach of using Essence for systems engineering is presented. In this approach we partly modified a Kernel only within engineering solution area of concerns and completely preserved Language as an excellent situational method engineering foundation.", "subjects": "Software Engineering (cs.SE)", "authors": "Anatoly Levenchuk,", "date": "2015-1-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00120", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00120", "title": "\nElectricity markets regarding the operational flexibility of power  plants", "abstract": "Electricity market mechanisms designed to steer sustainable generation of electricity play an important role for the energy transition intended to mitigate climate change. One of the major problems is to complement volatile renewable energy sources by operationally flexible capacity reserves. In this paper a proposal is given to determine prices on electricity markets taking into account the operational flexibility of power plants, such that the costs of long-term capacity reserves can be paid by short-term electricity spot markets. For this purpose, a measure of operational flexibility is introduced enabling to compute an inflexibility fee charging each individual power plant on a wholesale electricity spot market. The total sum of inflexibility fees accumulated on the spot markets then can be used to finance a capacity market keeping the necessary reserves to warrant grid reliability. Here each reserve power plant then gets a reliability payment depending on its operational flexibility. The proposal is applied to a small exemplary grid, illustrating its main idea and also revealing the caveat that too high fees paradoxically could create incentives to employ highly flexible power plants on the spot market rather than to run them as backup capacity.", "subjects": "Computers and Society (cs.CY)", "authors": "Cem Kiyak, Andreas de Vries,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00116", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00116", "title": "\nIntercept Behavior Analysis of Industrial Wireless Sensor Networks in  the Presence of Eavesdropping Attack", "abstract": "This paper studies the intercept behavior of an industrial wireless sensor network (WSN) consisting of a sink node and multiple sensors in the presence of an eavesdropping attacker, where the sensors transmit their sensed information to the sink node through wireless links. Due to the broadcast nature of radio wave propagation, the wireless transmission from the sensors to the sink can be readily overheard by the eavesdropper for interception purposes. In an information-theoretic sense, the secrecy capacity of the wireless transmission is the difference between the channel capacity of the main link (from sensor to sink) and that of the wiretap link (from sensor to eavesdropper). If the secrecy capacity becomes non-positive due to the wireless fading effect, the sensor's data transmission could be successfully intercepted by the eavesdropper and an intercept event occurs in this case. However, in industrial environments, the presence of machinery obstacles, metallic frictions and engine vibrations makes the wireless fading fluctuate drastically, resulting in the degradation of the secrecy capacity. As a consequence, an optimal sensor scheduling scheme is proposed in this paper to protect the legitimate wireless transmission against the eavesdropping attack, where a sensor with the highest secrecy capacity is scheduled to transmit its sensed information to the sink. Closed-form expressions of the probability of occurrence of an intercept event (called intercept probability) are derived for the conventional round-robin scheduling and the proposed optimal scheduling schemes. Also, an asymptotic intercept probability analysis is conducted to provide an insight into the impact of the sensor scheduling on the wireless security. Numerical results demonstrate that the proposed sensor scheduling scheme outperforms the conventional round-robin scheduling in terms of the intercept probability.", "subjects": "Information Theory (cs.IT)", "authors": "Yulong Zou, Gongpu Wang,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00115", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00115", "title": "\nOptimized Projection for Sparse Representation Based Classification", "abstract": "Dimensionality reduction (DR) methods have been commonly used as a principled way to understand the high-dimensional data such as facial images. In this paper, we propose a new supervised DR method called Optimized Projection for Sparse Representation based Classification (OP-SRC), which is based on the recent face recognition method, Sparse Representation based Classification (SRC). SRC seeks a sparse linear combination on all the training data for a given query image, and make the decision by the minimal reconstruction residual. OP-SRC is designed on the decision rule of SRC, it aims to reduce the within-class reconstruction residual and simultaneously increase the between-class reconstruction residual on the training data. The projections are optimized and match well with the mechanism of SRC. Therefore, SRC performs well in the OP-SRC transformed space. The feasibility and effectiveness of the proposed method is verified on the Yale, ORL and UMIST databases with promising results.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Can-Yi Lu, De-Shuang Huang,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00112", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00112", "title": "\nBar recursion in classical realisability : dependent choice and well  ordering of R", "abstract": "T. Streicher has shown, by means of a bar recursion operator, that the realizability models of ZF, obtained from usual models of lambda-calculus (Scott domains, coherent spaces, etc.), satisfy the axiom of dependent choice. In this note, we give a proof of this result, in the framework of classical realizability. Moreover, we show that these realizability models satisfy the formula~: \"R is well ordered\". This formula is therefore realized by a closed lambda-c-term (i.e. with a control instruction). We also show that every true formula of analysis is realized by a closed lambda-c-term.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Jean-Louis Krivine,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00111", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00111", "title": "\nNonextensive analysis on the local structure entropy of complex networks", "abstract": "The local structure entropy is a new method which is proposed to identify the influential nodes in the complex networks. In this paper a new form of the local structure entropy of the complex networks is proposed based on the Tsallis entropy. The value of the entropic index will influence the property of the local structure entropy. When the value of is equal to 0, the nonextensive local structure entropy is degenerated to a new form of the degree centrality. When the value of is equal to 1, the nonextensive local structure entropy is degenerated to the existing form of the local structure entropy. We also have find a nonextensive threshold value in the nonextensive local structure entropy. When the value of is bigger than the nonextensive threshold value, change the value of will has no influence on the property of the local structure entropy, and different complex networks have different nonextensive threshold value. The results in this paper show that the new nonextensive local structure entropy is a generalised of the local structure entropy. It is more reasonable and useful than the existing one.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Qi Zhang, Meizhu Li, Yuxian Du, Yong Deng, Sankaran Mahadevan,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00101", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00101", "title": "\nHybrid Update/Invalidate Schemes for Cache Coherence Protocols", "abstract": "In general when considering cache coherence, write back schemes are the default. These schemes invalidate all other copies of a data block during a write. In this paper we propose several hybrid schemes that will switch between updating and invalidating on processor writes at runtime, depending on program conditions. We created our own cache simulator on which we could implement our schemes, and generated data sets from both commercial benchmarks and through artificial methods to run on the simulator. We analyze the results of running the benchmarks with various schemes, and suggest further research that can be done in this area.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Roman Dovgopol, Matthew Rosonke,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00096", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00096", "title": "\nCombining k-Induction with Continuously-Refined Invariants", "abstract": "Bounded model checking (BMC) is a well-known and successful technique for finding bugs in software. k-induction is an approach to extend BMC-based approaches from falsification to verification. Automatically generated auxiliary invariants can be used to strengthen the induction hypothesis. We improve this approach and further increase effectiveness and efficiency in the following way: we start with light-weight invariants and refine these invariants continuously during the analysis. We present and evaluate an implementation of our approach in the open-source verification-framework CPAchecker. Our experiments show that combining k-induction with continuously-refined invariants significantly increases effectiveness and efficiency, and outperforms all existing implementations of k-induction-based software verification in terms of successful verification results.", "subjects": "Software Engineering (cs.SE)", "authors": "Dirk Beyer, Matthias Dangl, Philipp Wendler,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00094", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00094", "title": "\nTwitter Hash Tag Recommendation", "abstract": "The rise in popularity of microblogging services like Twitter has led to increased use of content annotation strategies like the hashtag. Hashtags provide users with a tagging mechanism to help organize, group, and create visibility for their posts. This is a simple idea but can be challenging for the user in practice which leads to infrequent usage. In this paper, we will investigate various methods of recommending hashtags as new posts are created to encourage more widespread adoption and usage. Hashtag recommendation comes with numerous challenges including processing huge volumes of streaming data and content which is small and noisy. We will investigate preprocessing methods to reduce noise in the data and determine an effective method of hashtag recommendation based on the popular classification algorithms.", "subjects": "Information Retrieval (cs.IR)", "authors": "Roman Dovgopol, Matt Nohelty,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00089", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00089", "title": "\nEfficiently Testing T-Interval Connectivity in Dynamic Graphs", "abstract": "Many types of dynamic networks are made up of durable entities whose links evolve over time. When considered from a and standpoint, these networks are often modelled as evolving graphs, i.e. a sequence of static graphs such that represents the network topology at time step . Such a sequence is said to be -interval connected if for any all graphs in share a common connected spanning subgraph. In this paper, we consider the problem of deciding whether a given sequence is -interval connected for a given . We also consider the related problem of finding the largest for which a given is -interval connected. We assume that the changes between two consecutive graphs are arbitrary, and that two operations, and , are available to solve the problems. We show that such operations are required to solve both problems, and we present optimal online algorithms for both problems.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Arnaud Casteigts, Ralf Klasing, Yessin M. Neggaz, Joseph G. Peters,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00087", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00087", "title": "\nOn Optimization of Network-coded Scalable Multimedia Service  Multicasting", "abstract": "In the near future, the delivery of multimedia multicast services over next-generation networks is likely to become one of the main pillars of future cellular networks. In this extended abstract, we address the issue of efficiently multicasting layered video services by defining a novel optimization paradigm that is based on an Unequal Error Protection implementation of Random Linear Network Coding, and aims to ensure target service coverages by using a limited amount of radio resources.", "subjects": "Information Theory (cs.IT)", "authors": "Andrea Tassi, Ioannis Chatzigeorgiou, Dejan Vukobratovi\u0107,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00082", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00082", "title": "\nCategory-Epitomes : Discriminatively Minimalist Representations for  Object Categories", "abstract": "Freehand line sketches are an interesting and unique form of visual representation. Typically, such sketches are studied and utilized as an end product of the sketching process. However, we have found it instructive to study the sketches as sequentially accumulated composition of drawing strokes added over time. Studying sketches in this manner has enabled us to create novel sparse yet discriminative sketch-based representations for object categories which we term category-epitomes. Our procedure for obtaining these epitomes concurrently provides a natural measure for quantifying the sparseness underlying the original sketch, which we term epitome-score. We construct and analyze category-epitomes and epitome-scores for freehand sketches belonging to various object categories. Our analysis provides a novel viewpoint for studying the semantic nature of object categories.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Ravi Kiran Sarvadevabhatla, R. Venkatesh Babu,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00079", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00079", "title": "\nEXIT Chart Analysis of Block Markov Superposition Transmission of Short  Codes", "abstract": "In this paper, a modified extrinsic information transfer (EXIT) chart analysis that takes into account the relation between mutual information (MI) and bit-error-rate (BER) is presented to study the convergence behavior of block Markov superposition transmission (BMST) of short codes (referred to as basic codes). We show that the threshold curve of BMST codes using an iterative sliding window decoding algorithm with a fixed decoding delay achieves a lower bound in the high signal-to-noise ratio (SNR) region, while in the low SNR region, due to error propagation, the thresholds of BMST codes become slightly worse as the encoding memory increases. We also demonstrate that the threshold results are consistent with finite-length performance simulations.", "subjects": "Information Theory (cs.IT)", "authors": "Kechao Huang, Xiao Ma, Daniel J. Costello Jr,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00076", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00076", "title": "\nDesign of a Unified Transport Triggered Processor for LDPC/Turbo Decoder", "abstract": "This paper summarizes the design of a programmable processor with transport triggered architecture (TTA) for decoding LDPC and turbo codes. The processor architecture is designed in such a manner that it can be programmed for LDPC or turbo decoding for the purpose of internetworking and roaming between different networks. The standard trellis based maximum a posteriori (MAP) algorithm is used for turbo decoding. Unlike most other implementations, a supercode based sum-product algorithm is used for the check node message computation for LDPC decoding. This approach ensures the highest hardware utilization of the processor architecture for the two different algorithms. Up to our knowledge, this is the first attempt to design a TTA processor for the LDPC decoder. The processor is programmed with a high level language to meet the time-to-market requirement. The optimization techniques and the usage of the function units for both algorithms are explained in detail. The processor achieves 22.64 Mbps throughput for turbo decoding with a single iteration and 10.12 Mbps throughput for LDPC decoding with five iterations for a clock frequency of 200 MHz.", "subjects": "Information Theory (cs.IT)", "authors": "Shahriar Shahabuddin, Janne Janhunen, Muhammet Fatih Bayramoglu, Markku Juntti, Amanullah Ghazi, Olli Silven,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00075", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00075", "title": "\nByzantine Broadcast Under a Selective Broadcast Model for Single-hop  Wireless Networks", "abstract": "This paper explores an old problem, (BB), under a new model, . The new model \"interpolates\" between the two traditional models in the literature. In particular, it allows fault-free nodes to exploit the benefits of a broadcast channel (a feature from reliable broadcast model) and allows faulty nodes to send mismatching messages to different neighbors (a feature from point-to-point model) simultaneously. The model is motivated by the potential for transmissions on a wireless channel. We provide a collection of results for a single-hop wireless network under the new model. First, we present an algorithm for BB that is order-optimal in bit complexity. Then, we provide an algorithm that is designed to achieve BB efficiently in terms of message complexity. Third, we determine some lower bounds on both bit and message complexities of BB problems in the . Finally, we present a conjecture on an \"exact\" lower bound on the bit complexity of BB under the model.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Lewis Tseng, Nitin Vaidya,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00068", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00068", "title": "\nTuPAQ: An Efficient Planner for Large-scale Predictive Analytic Queries", "abstract": "The proliferation of massive datasets combined with the development of sophisticated analytical techniques have enabled a wide variety of novel applications such as improved product recommendations, automatic image tagging, and improved speech-driven interfaces. These and many other applications can be supported by Predictive Analytic Queries (PAQs). A major obstacle to supporting PAQs is the challenging and expensive process of identifying and training an appropriate predictive model. Recent efforts aiming to automate this process have focused on single node implementations and have assumed that model training itself is a black box, thus limiting the effectiveness of such approaches on large-scale problems. In this work, we build upon these recent efforts and propose an integrated PAQ planning architecture that combines advanced model search techniques, bandit resource allocation via runtime algorithm introspection, and physical optimization via batching. The result is TuPAQ, a component of the MLbase system, which solves the PAQ planning problem with comparable quality to exhaustive strategies but an order of magnitude more efficiently than the standard baseline approach, and can scale to models trained on terabytes of data across hundreds of machines.", "subjects": "Databases (cs.DB)", "authors": "Evan R. Sparks, Ameet Talwalkar, Michael J. Franklin, Michael I. Jordan, Tim Kraska,", "date": "2015-1-1"}, 
{"urllink": "http://arxiv.org/abs/1502.00065", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00065", "title": "\nSequential Defense Against Random and Intentional Attacks in Complex  Networks", "abstract": "Network robustness against attacks is one of the most fundamental researches in network science as it is closely associated with the reliability and functionality of various networking paradigms. However, despite the study on intrinsic topological vulnerabilities to node removals, little is known on the network robustness when network defense mechanisms are implemented, especially for networked engineering systems equipped with detection capabilities. In this paper, a sequential defense mechanism is firstly proposed in complex networks for attack inference and vulnerability assessment, where the data fusion center sequentially infers the presence of an attack based on the binary attack status reported from the nodes in the network. The network robustness is evaluated in terms of the ability to identify the attack prior to network disruption under two major attack schemes, i.e., random and intentional attacks. We provide a parametric plug-in model for performance evaluation on the proposed mechanism and validate its effectiveness and reliability via canonical complex network models and real-world large-scale network topology. The results show that the sequential defense mechanism greatly improves the network robustness and mitigates the possibility of network disruption by acquiring limited attack status information from a small subset of nodes in the network.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Pin-Yu Chen, Shin-Ming Cheng,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00064", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00064", "title": "\nA Batchwise Monotone Algorithm for Dictionary Learning", "abstract": "We propose a batchwise monotone algorithm for dictionary learning. Unlike the state-of-the-art dictionary learning algorithms which impose sparsity constraints on a sample-by-sample basis, we instead treat the samples as a batch, and impose the sparsity constraint on the whole. The benefit of batchwise optimization is that the non-zeros can be better allocated across the samples, leading to a better approximation of the whole. To accomplish this, we propose procedures to switch non-zeros in both rows and columns in the support of the coefficient matrix to reduce the reconstruction error. We prove in the proposed support switching procedure the objective of the algorithm, i.e., the reconstruction error, decreases monotonically and converges. Furthermore, we introduce a block orthogonal matching pursuit algorithm that also operates on sample batches to provide a warm start. Experiments on both natural image patches and UCI data sets show that the proposed algorithm produces a better approximation with the same sparsity levels compared to the state-of-the-art algorithms.", "subjects": "Learning (cs.LG)", "authors": "Huan Wang, John Wright, Daniel Spielman,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00054", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00054", "title": "\nECPR: Environment- and Context-aware Combined Power and Rate Distributed  Congestion Control for Vehicular Communications", "abstract": "Safety and efficiency applications in vehicular networks rely on the exchange of periodic messages between vehicles. These messages contain position, speed, heading, and other vital information that makes the vehicles aware of their surroundings. The drawback of exchanging periodic cooperative messages is that they generate significant channel load. Decentralized Congestion Control (DCC) algorithms have been proposed to control the channel load. However, while the rationale for periodic message exchange is to improve awareness, existing DCC algorithms do not use awareness as a metric for deciding when, at what power, and at what rate the periodic messages need to be sent in order to make sure that the hard-to-reach vehicles are informed. We propose ECPR, an environment and context-aware DCC algorithm, which combines power and rate control to improve cooperative awareness by adapting to both specific propagation environments (such as urban intersections, open highways, suburban roads) as well as application requirements (e.g., different target cooperative awareness range). Using the current context that the vehicle operates in (e.g., speed, direction, and application requirement), ECPR adjusts the transmit power of the messages to reach the desired awareness ratio at the target distance while at the same time controlling the channel load using an adaptive rate control algorithm. By performing extensive simulations, including realistic propagation and environment modeling and realistic vehicle contexts (varying demand on both awareness range and rate), we show that ECPR can increase awareness by 20% while keeping the channel load and interference at almost the same level. When the awareness requirements allow, ECPR can improve the average message rate by 18% compared to algorithms that perform rate adaptation only.", "subjects": "Other Computer Science (cs.OH)", "authors": "Bengi Aygun, Mate Boban, Alexander M. Wyglinski,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00052", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00052", "title": "\nJoint Tx/Rx Energy-Efficient Scheduling in Multi-Radio Networks: A  Divide-and-Conque Approach", "abstract": "Most of the existing works on energy-efficient wireless communication systems only consider the transmitter (Tx) or the receiver (Rx) side power consumption but not both. Moreover, they often assume the static circuit power consumption. To be more practical, this paper considers the joint Tx and Rx power consumption in multiple-access radio networks, where the power model takes both the transmission power and the dynamic circuit power into account. We formulate the joint Tx and Rx energy efficiency (EE) maximization problem which is a combinatorial-type one due to the indicator function for scheduling users and activating radio links. The link EE and the user EE are then introduced which have the similar structure as the system EE. Their hierarchical relationships are exploited to tackle the problem using a divide-and-conquer approach, which is only of linear complexity. We further reveal that the static receiving power plays a critical role in the user scheduling. Finally, comprehensive numerical results are provided to validate the theoretical findings and demonstrate the effectiveness of the proposed algorithm for improving the system EE.", "subjects": "Information Theory (cs.IT)", "authors": "Qingqing Wu, Meixia Tao, Wen Chen,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00050", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00050", "title": "\nTime-Free and Timer-Based Assumptions Can Be Combined to Solve  Authenticated Byzantine Consensus", "abstract": "To circumvent the FLP impossibility result in a deterministic way several protocols have been proposed on top of an asynchronous distributed system enriched with additional assumptions. In the context of Byzantine failures for systems where at most t processes may exhibit a Byzantine behavior, two approaches have been investigated to solve the consensus problem.The first, relies on the addition of synchrony, called Timer-Based, but the second is based on the pattern of the messages that are exchanged, called Time-Free. This paper shows that both types of assumptions are not antagonist and can be combined to solve authenticated Byzantine consensus. This combined assumption considers a correct process pi, called 2t-BW, and a set X of 2t processes such that, eventually, for each query broadcasted by a correct process pj of X, pj receives a response from pi 2 X among the (n- t) first responses to that query or both links connecting pi and pj are timely. Based on this combination, a simple hybrid authenticated Byzantine consensus protocol,benefiting from the best of both worlds, is proposed. Whereas many hybrid protocols have been designed for the consensus problem in the crash model, this is, to our knowledge, the first hybrid deterministic solution to the Byzantine consensus problem.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Hamouma Moumen,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00046", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00046", "title": "\nMax-Margin Object Detection", "abstract": "Most object detection methods operate by applying a binary classifier to sub-windows of an image, followed by a non-maximum suppression step where detections on overlapping sub-windows are removed. Since the number of possible sub-windows in even moderately sized image datasets is extremely large, the classifier is typically learned from only a subset of the windows. This avoids the computational difficulty of dealing with the entire set of sub-windows, however, as we will show in this paper, it leads to sub-optimal detector performance. In particular, the main contribution of this paper is the introduction of a new method, Max-Margin Object Detection (MMOD), for learning to detect objects in images. This method does not perform any sub-sampling, but instead optimizes over all sub-windows. MMOD can be used to improve any object detection method which is linear in the learned parameters, such as HOG or bag-of-visual-word models. Using this approach we show substantial performance gains on three publicly available datasets. Strikingly, we show that a single rigid HOG filter can outperform a state-of-the-art deformable part model on the Face Detection Data Set and Benchmark when the HOG filter is learned via MMOD.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Davis E. King,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00045", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00045", "title": "\nDomain-Type-Guided Refinement Selection Based on Sliced Path Prefixes", "abstract": "Abstraction is a successful technique in software verification, and interpolation on infeasible error paths is a successful approach to automatically detect the right level of abstraction in counterexample-guided abstraction refinement. Because the interpolants have a significant influence on the quality of the abstraction, and thus, the effectiveness of the verification, an algorithm for deriving the best possible interpolants is desirable. We present an analysis-independent technique that makes it possible to extract several alternative sequences of interpolants from one given infeasible error path, if there are several reasons for infeasibility in the error path. We take as input the given infeasible error path and apply a slicing technique to obtain a set of error paths that are more abstract than the original error path but still infeasible, each for a different reason. The (more abstract) constraints of the new paths can be passed to a standard interpolation engine, in order to obtain a set of interpolant sequences, one for each new path. The analysis can then choose from this set of interpolant sequences and select the most appropriate, instead of being bound to the single interpolant sequence that the interpolation engine would normally return. For example, we can select based on domain types of variables in the interpolants, prefer to avoid loop counters, or compare with templates for potential loop invariants, and thus control what kind of information occurs in the abstraction of the program. We implemented the new algorithm in the open-source verification framework CPAchecker and show that our proof-technique-independent approach yields a significant improvement of the effectiveness and efficiency of the verification process.", "subjects": "Software Engineering (cs.SE)", "authors": "Dirk Beyer, Stefan L\u00f6we, Philipp Wendler,", "date": "2015-1-31"}, 
{"urllink": "http://arxiv.org/abs/1502.00033", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00033", "title": "\nAnalyzing Interference from Static Cellular Cooperation using the  Nearest Neighbour Model", "abstract": "The problem of base station cooperation has recently been set within the framework of Stochastic Geometry. Existing works consider that a user dynamically chooses the set of stations that cooperate for his/her service. However, this assumption often does not hold. Cooperation groups could be predefined and static, with nodes connected by fixed infrastructure. To analyse such a potential network, in this work we propose a grouping method based on proximity. It is a variation of the so called Nearest Neighbour Model. We restrict ourselves to the simplest case where only singles and pairs of base stations are allowed to be formed. For this, two new point processes are defined from the dependent thinning of a Poisson Point Process, one for the singles and one for the pairs. Structural characteristics for the two are provided, including their density, Voronoi surface, nearest neighbour, empty space and J-function. We further make use of these results to analyse their interference fields and give explicit formulas to their expected value and their Laplace transform. The results constitute a novel toolbox towards the performance evaluation of networks with static cooperation.", "subjects": "Information Theory (cs.IT)", "authors": "Anastasios Giovanidis, Luis David Alvarez Corrales, Laurent Decreusefond,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1502.00030", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1502.00030", "title": "\nSHOE: Supervised Hashing with Output Embeddings", "abstract": "We present a supervised binary encoding scheme for image retrieval that learns projections by taking into account similarity between classes obtained from output embeddings. Our motivation is that binary hash codes learned in this way improve both the visual quality of retrieval results and existing supervised hashing schemes. We employ a sequential greedy optimization that learns relationship aware projections by minimizing the difference between inner products of binary codes and output embedding vectors. We develop a joint optimization framework to learn projections which improve the accuracy of supervised hashing over the current state of the art with respect to standard and sibling evaluation metrics. We further boost performance by applying the supervised dimensionality reduction technique on kernelized input CNN features. Experiments are performed on three datasets: CUB-2011, SUN-Attribute and ImageNet ILSVRC 2010. As a by-product of our method, we show that using a simple k-nn pooling classifier with our discriminative codes improves over the complex classification models on fine grained datasets like CUB and offer an impressive compression ratio of 1024 on CNN features.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Sravanthi Bondugula, Varun Manjunatha, Larry S. Davis, David Doermann,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.00375", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00375", "title": "\nPassing Expectation Propagation Messages with Kernel Methods", "abstract": "We propose to learn a kernel-based message operator which takes as input all expectation propagation (EP) incoming messages to a factor node and produces an outgoing message. In ordinary EP, computing an outgoing message involves estimating a multivariate integral which may not have an analytic expression. Learning such an operator allows one to bypass the expensive computation of the integral during inference by directly mapping all incoming messages into an outgoing message. The operator can be learned from training data (examples of input and output messages) which allows automated inference to be made on any kind of factor that can be sampled.", "subjects": "Machine Learning (stat.ML)", "authors": "Wittawat Jitkrittum, Arthur Gretton, Nicolas Heess,", "date": "2015-1-2"}, 
{"urllink": "http://arxiv.org/abs/1501.07430", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07430", "title": "\nBayesian Hierarchical Clustering with Exponential Family: Small-Variance  Asymptotics and Reducibility", "abstract": "Bayesian hierarchical clustering (BHC) is an agglomerative clustering method, where a probabilistic model is defined and its marginal likelihoods are evaluated to decide which clusters to merge. While BHC provides a few advantages over traditional distance-based agglomerative clustering algorithms, successive evaluation of marginal likelihoods and careful hyperparameter tuning are cumbersome and limit the scalability. In this paper we relax BHC into a non-probabilistic formulation, exploring small-variance asymptotics in conjugate-exponential models. We develop a novel clustering algorithm, referred to as relaxed BHC (RBHC), from the asymptotic limit of the BHC model that exhibits the scalability of distance-based agglomerative clustering algorithms as well as the flexibility of Bayesian nonparametric models. We also investigate the reducibility of the dissimilarity measure emerged from the asymptotic limit of the BHC model, allowing us to use scalable algorithms such as the nearest neighbor chain algorithm. Numerical experiments on both synthetic and real-world datasets demonstrate the validity and high performance of our method.", "subjects": "Machine Learning (stat.ML)", "authors": "Juho Lee, Seungjin Choi,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07788", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07788", "title": "\nHuman diffusion and city influence", "abstract": "Cities are characterized by concentrating population, economic activity and services. However, not all cities are equal and hierarchy in terms of influence at local, regional or global scales naturally emerges. Traditionally, there have been important efforts to describe this hierarchy by indirect measures such the sharing of company headquarters, traffic by air, train or boats or economical exchanges. In this work, we take a different approach and introduce a method that uses geolocated Twitter information to quantify the impact of cities on rural or other urban areas. Since geolocated tweets are becoming a global phenomenon, the method can be applied at a world-wide scale. We focus on cities and analyze the mobility patterns of people after visiting them for the first time. Cities such as Rome and Paris appear consistently as those with largest area covered by Twitter users after their visit and as those attracting visitors most diverse in origin. The study is also performed discerning users mobility by the contribution of locals and non-locals, which shows the relevance of the mixing ratio between them to have a global city. Finally, we focus on the mobility of users between cities and construct a network with the users flows between them. The network allows to analyze centrality defining it at a global and regional scale. The hierarchy of cities dramatically changes when referred only to urban users, with New York and London playing a predominant role.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Maxime Lenormand, Bruno Gon\u00e7alves, Ant\u00f2nia Tugores, Jos\u00e9 J. Ramasco,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07773", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07773", "title": "\nPolyhedral Omega: A New Algorithm for Solving Linear Diophantine Systems", "abstract": "Polyhedral Omega is a new algorithm for solving linear Diophantine systems (LDS), i.e., for computing a multivariate rational function representation of the set of all non-negative integer solutions to a system of linear equations and inequalities. Polyhedral Omega combines methods from partition analysis with methods from polyhedral geometry. In particular, we combine MacMahon's iterative approach based on the Omega operator and explicit formulas for its evaluation with geometric tools such as Brion decompositions and Barvinok's short rational function representations. In this way, we connect two recent branches of research that have so far remained separate, unified by the concept of symbolic cones which we introduce. The resulting LDS solver Polyhedral Omega is significantly faster than previous solvers based on partition analysis and it is competitive with state-of-the-art LDS solvers based on geometric methods. Most importantly, this synthesis of ideas makes Polyhedral Omega the simplest algorithm for solving linear Diophantine systems available to date. Moreover, we provide an illustrated geometric interpretation of partition analysis, with the aim of making ideas from both areas accessible to readers from a wide range of backgrounds.", "subjects": "Combinatorics (math.CO)", "authors": "Felix Breuer, Zafeirakis Zafeirakopoulos,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07758", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07758", "title": "\nGibbs-Ringing Artifact Removal Based on Local Subvoxel-shifts", "abstract": "Gibbs-ringing is a well known artifact which manifests itself as spurious oscillations in the vicinity of sharp image transients, e.g. at tissue boundaries. The origin can be seen in the truncation of k-space during MRI data-acquisition. Consequently, correction techniques like Gegenbauer reconstruction or extrapolation methods aim at recovering these missing data. Here, we present a simple and robust method which exploits a different view on the Gibbs-phenomena. The truncation in k-space can be interpreted as a convolution with a sinc-function in image space. Hence, the severity of the artifacts depends on how the sinc-function is sampled. We propose to re-interpolate the image based on local, subvoxel shifts to sample the ringing pattern at the zero-crossings of the oscillating sinc-function. With this, the artifact can effectively and robustly be removed with a minimal amount of smoothing.", "subjects": "Medical Physics (physics.med-ph)", "authors": "Elias Kellner, Bibek Dhital, Marco Reisert,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07756", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07756", "title": "\nA Resilient Quantum Secret Sharing Scheme", "abstract": "A resilient secret sharing scheme is supposed to generate the secret correctly even after some shares are damaged. In this paper, we show how quantum error correcting codes can be exploited to design a resilient quantum secret sharing scheme, where a quantum state is shared among more than one parties.", "subjects": "Quantum Physics (quant-ph)", "authors": "Arpita Maitra, Goutam Paul,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07721", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07721", "title": "\nAsymmetric polygons with maximum area", "abstract": "We say that a polygon inscribed in the circle is asymmetric if it contains no two antipodal points being the endpoints of a diameter. Given diameters of a circle and a positive integer , this paper addresses the problem of computing a maximum area asymmetric -gon having as vertices endpoints of the given diameters. The study of this type of polygons is motivated by ethnomusiciological applications.", "subjects": "Metric Geometry (math.MG)", "authors": "L. Barba, L.E. Caraballo, J. M. D\u00edaz-B\u00e1\u00f1ez, R. Fabila-Monroy, E. P\u00e9rez-Castillo,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07591", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07591", "title": "\nDirect algebraic solutions to constrained tropical optimization problems", "abstract": "We examine a new optimization problem formulated in the tropical mathematics setting as an extension of certain known problems. The problem is to minimize a nonlinear objective function, which is defined on vectors over an idempotent semifield by using multiplicative conjugate transposition, subject to inequality constraints. As compared to the known problems, the new one has a more general objective function and additional constraints. We provide a complete solution in an explicit form to the problem by using an approach that introduces an additional variable to represent the values of the objective function, and then reduces the initial problem to a parametrized vector inequality. The minimum of the objective function is evaluated by applying the existence conditions for the solution of this inequality. A complete solution to the problem is given by the solutions of the inequality, provided the parameter is set to the minimum value. As a consequence, we obtain solutions to new special cases of the general problem. To illustrate the application of the results, we solve a real-world problem drawn from project scheduling, and offer a representative numerical example.", "subjects": "Optimization and Control (math.OC)", "authors": "N. Krivulin,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07529", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07529", "title": "\nQuantum Information splitting using a pair of {\\it GHZ} states", "abstract": "We describe a protocol for quantum information splitting (QIS) of a restricted class of three-qubit states among three parties Alice, Bob and Charlie, using a pair of GHZ states as the quantum channel. There are two different forms of this three-qubit state that is used for QIS depending on the distribution of the particles among the three parties. There is also a special type of four-qubit state that can be used for QIS using the above channel. We explicitly construct the quantum channel, Alice's measurement basis and the analytic form of the unitary operations required by the receiver for such a purpose.", "subjects": "Quantum Physics (quant-ph)", "authors": "Kaushik Nandi, Goutam Paul,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07469", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07469", "title": "\nOn-line list colouring of random graphs", "abstract": "In this paper, the on-line list colouring of binomial random graphs G(n,p) is studied. We show that the on-line choice number of G(n,p) is asymptotically almost surely asymptotic to the chromatic number of G(n,p), provided that the average degree d=p(n-1) tends to infinity faster than (log log n)^1/3(log n)^2n^(2/3). For sparser graphs, we are slightly less successful; we show that if d&gt;(log n)^(2+epsilon) for some epsilon&gt;0, then the on-line choice number is larger than the chromatic number by at most a multiplicative factor of C, where C in [2,4], depending on the range of d. Also, for d=O(1), the on-line choice number is by at most a multiplicative constant factor larger than the chromatic number.", "subjects": "Combinatorics (math.CO)", "authors": "Alan Frieze, Dieter Mitsche, Xavier P\u00e9rez-Gim\u00e9nez, Pawe\u0142 Pra\u0142at,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07460", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07460", "title": "\nSimple greedy 2-approximation algorithm for the maximum genus of a graph", "abstract": "The maximum genus of a graph G is the largest genus of an orientable surface into which G has a cellular embedding. Combinatorially, it coincides with the maximum number of disjoint pairs of adjacent edges of G whose removal results in a connected spanning subgraph of G. In this paper we prove that removing pairs of adjacent edges from G arbitrarily while retaining connectedness leads to at least pairs of edges removed. This allows us to describe a greedy algorithm for the maximum genus of a graph; our algorithm returns an integer k such that , providing a simple method to efficiently approximate maximum genus. As a consequence of our approach we obtain a 2-approximate counterpart of Xuong's combinatorial characterisation of maximum genus.", "subjects": "Combinatorics (math.CO)", "authors": "Michal Kotrbcik, Martin Skoviera,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07417", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07417", "title": "\nAn improved rate region for the classical-quantum broadcast channel", "abstract": "We present a new achievable rate region for the two-user binary-input classical-quantum broadcast channel. The result is a generalization of the classical Marton-Gelfand-Pinsker region and is provably larger than the best previously known rate region for classical-quantum broadcast channels. The proof of achievability is based on the recently introduced polar coding scheme and its generalization to quantum network information theory.", "subjects": "Quantum Physics (quant-ph)", "authors": "Christoph Hirche, Ciara Morgan,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07396", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07396", "title": "\nA MILP model for single machine family scheduling with  sequence-dependent batch setup and controllable processing times", "abstract": "A mathematical programming model for a class of single machine family scheduling problem is described in this technical report, with the aim of comparing the performance in solving the scheduling problem by means of mathematical programming with the performance obtained when using optimal control strategies, that can be derived from the application of a dynamic programming-based methodology proposed by the Author. The scheduling problem is characterized by the presence of sequence-dependent batch setup and controllable processing times; moreover, the generalized due-date model is adopted in the problem. Three mixed-integer linear programming (MILP) models are proposed. The best one, from the performance point of view, is a model which makes use of two sets of binary variables: the former to define the relative position of jobs and the latter to define the exact sequence of jobs. In addition, one of the model exploits a stage-based state space representation which can be adopted to define the dynamics of the system.", "subjects": "Optimization and Control (math.OC)", "authors": "Davide Giglio,", "date": "2015-1-9"}, 
{"urllink": "http://arxiv.org/abs/1501.07349", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07349", "title": "\nStructure-Based Self-Triggered Consensus in Networks of Multiagents with  Switching Topologies", "abstract": "In this paper, we propose a new self-triggered consensus algorithm in networks of multi-agents. Different from existing works, which are based on the observation of states, here, each agent determines its next update time based on its coupling structure. Both centralized and distributed approaches of the algorithms have been discussed. By transforming the algorithm to a proper discrete-time systems without self delays, we established a new analysis framework to prove the convergence of the algorithm. Then we extended the algorithm to networks with switching topologies, especially stochastically switching topologies. Compared to existing works, our algorithm is easier to understand and implement. It explicitly provides positive lower and upper bounds for the update time interval of each agent based on its coupling structure, which can also be independently adjusted by each agent according to its own situation. Our work reveals that the event/self triggered algorithms are essentially discrete and more suitable to a discrete analysis framework. Numerical simulations are also provided to illustrate the theoretical results.", "subjects": "Optimization and Control (math.OC)", "authors": "Bo Liu, Wenlian Lu, Licheng Jiao, Tianping Chen,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07255", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07255", "title": "\nElliptic-cylindrical Wavelets: The Mathieu Wavelets", "abstract": "This note introduces a new family of wavelets and a multiresolution analysis, which exploits the relationship between analysing filters and Floquet's solution of Mathieu differential equations. The transfer function of both the detail and the smoothing filter is related to the solution of a Mathieu equation of odd characteristic exponent. The number of notches of these filters can be easily designed. Wavelets derived by this method have potential application in the fields of Optics and Electromagnetism.", "subjects": "Methodology (stat.ME)", "authors": "M. M. S. Lira, H. M. de Oliveira, R. J. Cintra,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07116", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07116", "title": "\nPeer-review Platform for Astronomy Education Activities", "abstract": "Hundreds of thousands of astronomy education activities exist, but their discoverability and quality is highly variable. The web platform for astronomy education activities, astroEDU, presented in this paper tries to solve these issues. Using the familiar peer-review workflow of scientific publications, astroEDU is improving standards of quality, visibility and accessibility, while providing credibility to these astronomy education activities. astroEDU targets activity guides, tutorials and other educational activities in the area of astronomy education, prepared by teachers, educators and other education specialists. Each of the astroEDU activities is peer-reviewed by an educator as well as an astronomer to ensure a high standard in terms of scientific content and educational value. All reviewed materials are then stored in a free open online database, enabling broad distribution in a range of different formats. In this way astroEDU is not another web repository for educational resources but a mechanism for peer-reviewing and publishing high-quality astronomy education activities in an open access way. This paper will provide an account on the implementation and first findings of the use of astroEDU.", "subjects": "Instrumentation and Methods for Astrophysics (astro-ph.IM)", "authors": "Pedro Russo, Edward Gomez, Thilina Heenatigala, Linda Strubbe,", "date": "2015-1-8"}, 
{"urllink": "http://arxiv.org/abs/1501.07019", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07019", "title": "\nKangaroo Methods for Solving the Interval Discrete Logarithm Problem", "abstract": "The interval discrete logarithm problem is defined as follows: Given some in a group , and some such that for some where , find . At the moment, kangaroo methods are the best low memory algorithm to solve the interval discrete logarithm problem. The fastest non parallelised kangaroo methods to solve this problem are the three kangaroo method, and the four kangaroo method. These respectively have expected average running times of , and group operations. It is currently an open question as to whether it is possible to improve kangaroo methods by using more than four kangaroos. Before this dissertation, the fastest kangaroo method that used more than four kangaroos required at least group operations to solve the interval discrete logarithm problem. In this thesis, I improve the running time of methods that use more than four kangaroos significantly, and almost beat the fastest kangaroo algorithm, by presenting a seven kangaroo method with an expected average running time of group operations. The question, 'Are five kangaroos worse than three?' is also answered in this thesis, as I propose a five kangaroo algorithm that requires on average group operations to solve the interval discrete logarithm problem.", "subjects": "Number Theory (math.NT)", "authors": "Alex Fowler, Steven Galbraith,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.06957", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06957", "title": "\nCongestion control in charging of electric vehicles", "abstract": "The increasing penetration of electric vehicles over the coming decades, taken together with the high cost to upgrade local distribution networks, and consumer demand for home charging, suggest that managing congestion on low voltage networks will be a crucial component of the electric vehicle revolution and the move away from fossil fuels in transportation. Here, we model the max-flow and proportional fairness protocols for the control of congestion caused by a fleet of vehicles charging on distribution networks. We analyse the inequality in the charging times as the vehicle arrival rate increases, and show that charging times are considerably more uneven in max-flow than in proportional fairness. We also analyse the onset of instability, and find that the critical arrival rate is indistinguishable between the two protocols.", "subjects": "Optimization and Control (math.OC)", "authors": "Rui Carvalho, Lubos Buzna, Richard Gibbens, Frank Kelly,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.06929", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06929", "title": "\nA Probabilistic Least-Mean-Squares Filter", "abstract": "We introduce a probabilistic approach to the LMS filter. By means of an efficient approximation, this approach provides an adaptable step-size LMS algorithm together with a measure of uncertainty about the estimation. In addition, the proposed approximation preserves the linear complexity of the standard LMS. Numerical results show the improved performance of the algorithm with respect to standard LMS and state-of-the-art algorithms with similar complexity. The goal of this work, therefore, is to open the door to bring some more Bayesian machine learning techniques to adaptive filtering.", "subjects": "Machine Learning (stat.ML)", "authors": "Jesus Fernandez-Bes, V\u00edctor Elvira, Steven Van Vaerenbergh,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06845", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06845", "title": "\nExact Solution for One Type of Lindley's Equation for Queueing Theory  and Network Calculus", "abstract": "Lindley's equation is an important relation in queueing theory and network calculus. In this paper, we develop a new method to solve one type of Lindley's equation, i.e., the equation V(s)T(-s)-1=0 only has finite negative real roots. V(s) and T(-s) are the Laplace transforms of service time's probability density function (PDF) and interarrival time's PDF (evaluated at -s). For queueing theory, we use this method to derive the exact M/M/1, M/H2/1 and M/E2/1 waiting-time distributions, and for the first time find the exact D/M/1 waiting-time distribution. For network calculus, we use two examples to compare our method with the effective bandwidth model and its dual, the effective capacity model, respectively. We observe that the distribution function of backlog size in the first example can be obtained exactly by our method and partially by the effective bandwidth model; however, such a distribution function in the second example cannot be obtained by our method but can be approximated by the effective capacity model.", "subjects": "Applications (stat.AP)", "authors": "Yu Chen,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06835", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06835", "title": "\nEmergence of Soft Communities from Geometric Preferential Attachment", "abstract": "All real networks are different, but many have some structural properties in common. There seems to be no consensus on what the most common properties are, but scale-free degree distributions, strong clustering, and community structure are frequently mentioned without question. Surprisingly, there exists no simple generative mechanism explaining all the three properties at once in growing networks. Here we show how latent network geometry coupled with preferential attachment of nodes to this geometry fills this gap. We call this mechanism geometric preferential attachment (GPA), and validate it against the Internet. GPA gives rise to soft communities that provide a different perspective on the community structure in networks. The connections between GPA and cosmological models, including inflation, are also discussed.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Konstantin Zuev, Marian Boguna, Ginestra Bianconi, Dmitri Krioukov,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06831", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06831", "title": "\nSome Notes about Subshifts on Groups", "abstract": "In this note we prove the following results: If a finitely presented group G admits a strongly aperiodic SFT, then G has decidable word problem. For a large class of group G, Z \u00d7 G admits a strongly aperiodic SFT. In particular, this is true for the free group with 2 generators, Thompson's groups T and V , PSL2(Z) and any f.g. group of rational matrices which is bounded.", "subjects": "Group Theory (math.GR)", "authors": "Emmanuel Jeandel,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06809", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06809", "title": "\nThe nested assembly of collective attention in online social systems", "abstract": "Online social networks have changed the way in which we communicate. These networks are characterized by a competitive information flow and a dynamic topology, where the success of a given topic or meme depends on many factors, most of which are unknown. Likely, given the many sources of information to which a typical individual is exposed, the economy of attention rules the system dynamics. Here we show, using microblogging data, that competition is minimized through consensus and that collective attention and successful topical assembly are characterized by a nested structure of the bipartite network made up by users and memes. Our results indicate that social phenomena could emerge as a result of a topological transition that minimizes modularity while maximizing the nestedness of the system, and that online social networks are comparable to an ecosystem, where generalists and specialists share resources.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Javier Borge-Holthoefer, Raquel A. Ba\u00f1os, Carlos Gracia-L\u00e1zaro, Yamir Moreno,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06794", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06794", "title": "\nComputing Functions of Random Variables via Reproducing Kernel Hilbert  Space Representations", "abstract": "We describe a method to perform functional operations on probability distributions of random variables. The method uses reproducing kernel Hilbert space representations of probability distributions, and it is applicable to all operations which can be applied to points drawn from the respective distributions. We refer to our approach as . We illustrate it on synthetic data, and show how it can be used for nonparametric structural equation models, with an application to causal inference.", "subjects": "Machine Learning (stat.ML)", "authors": "Bernhard Sch\u00f6lkopf, Krikamol Muandet, Kenji Fukumizu, Jonas Peters,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06789", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06789", "title": "\nCan Science and Technology Capacity be Measured?", "abstract": "The ability of a nation to participate in the global knowledge economy depends to some extent on its capacities in science and technology. In an effort to assess the capacity of different countries in science and technology, this article updates a classification scheme developed by RAND to measure science and technology capacity for 150 countries of the world.", "subjects": "Applications (stat.AP)", "authors": "Caroline S. Wagner, Edwin Horlings, Arindum Dutta,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06769", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06769", "title": "\nParticle Gibbs with Ancestor Sampling for Probabilistic Programs", "abstract": "Particle Markov chain Monte Carlo techniques rank among current state-of-the-art methods for probabilistic program inference. A drawback of these techniques is that they rely on importance resampling, which results in degenerate particle trajectories and a low effective sample size for variables sampled early in a program. We here develop a formalism to adapt ancestor resampling, a technique that mitigates particle degeneracy, to the probabilistic programming setting. We present empirical results that demonstrate nontrivial performance gains.", "subjects": "Machine Learning (stat.ML)", "authors": "Jan-Willem van de Meent, Hongseok Yang, Vikash Mansinghka, Frank Wood,", "date": "2015-1-7"}, 
{"urllink": "http://arxiv.org/abs/1501.06727", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06727", "title": "\nFactorization, Inference and Parameter Learning in Discrete AMP Chain  Graphs", "abstract": "We address some computational issues that may hinder the use of AMP chain graphs in practice. Specifically, we show how a discrete probability distribution that satisfies all the independencies represented by an AMP chain graph factorizes according to it. We show how this factorization makes it possible to perform inference and parameter learning efficiently, by adapting existing algorithms for Markov and Bayesian networks. Finally, we turn our attention to another issue that may hinder the use of AMP CGs, namely the lack of an intuitive interpretation of their edges. We provide one such interpretation.", "subjects": "Machine Learning (stat.ML)", "authors": "Jose M. Pe\u00f1a,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06661", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06661", "title": "\nDeterministic compressed sensing matrices: Construction via Euler  Squares and applications", "abstract": "In Compressed Sensing the matrices that satisfy the Restricted Isometry Property (RIP) play an important role. But to date, very few results for designing such matrices are available. For applications such as multiplier-less data compression, binary sensing matrices are of interest. The present work constructs deterministic and binary sensing matrices using Euler Squares. In particular, given a positive integer different from for a prime , we show that it is possible to construct a binary sensing matrix of size , where is the coherence parameter of the matrix and . The matrices that we construct have smaller density (that is, percentage of nonzero entries in the matrix is small) with no function evaluation in their construction, which support algorithms with low computational complexity. Through experimental work, we show that our binary sensing matrices can be used for such applications as content based image retrieval. Our simulation results demonstrate that the Euler Square based CS matrices give better performance than their Gaussian counterparts.", "subjects": "Optimization and Control (math.OC)", "authors": "R. Ramu Naidu, C. S. Sastry, Phanindra Jampana,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06598", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06598", "title": "\nOnline Nonparametric Regression with General Loss Functions", "abstract": "This paper establishes minimax rates for online regression with arbitrary classes of functions and general losses. We show that below a certain threshold for the complexity of the function class, the minimax rates depend on both the curvature of the loss function and the sequential complexities of the class. Above this threshold, the curvature of the loss does not affect the rates. Furthermore, for the case of square loss, our results point to the interesting phenomenon: whenever sequential and i.i.d. empirical entropies match, the rates for statistical and online learning are the same. In addition to the study of minimax regret, we derive a generic forecaster that enjoys the established optimal rates. We also provide a recipe for designing online prediction algorithms that can be computationally efficient for certain problems. We illustrate the techniques by deriving existing and new forecasters for the case of finite experts and for online linear regression.", "subjects": "Machine Learning (stat.ML)", "authors": "Alexander Rakhlin, Karthik Sridharan,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06558", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06558", "title": "\nDirectional learning and the provisioning of public goods", "abstract": "We consider an environment where players are involved in a public goods game and must decide repeatedly whether to make an individual contribution or not. However, players lack strategically relevant information about the game and about the other players in the population. The resulting behavior of players is completely uncoupled from such information, and the individual strategy adjustment dynamics are driven only by reinforcement feedbacks from each player's own past. We show that the resulting \"directional learning\" is sufficient to explain cooperative deviations away from the Nash equilibrium. We introduce the concept of k-strong equilibria, which nest both the Nash equilibrium and the Aumann-strong equilibrium as two special cases, and we show that, together with the parameters of the learning model, the maximal k-strength of equilibrium determines the stationary distribution. The provisioning of public goods can be secured even under adverse conditions, as long as players are sufficiently responsive to the changes in their own payoffs and adjust their actions accordingly. Substantial levels of public cooperation can thus be explained without arguments involving selflessness or social preferences, solely on the basis of uncoordinated directional (mis)learning.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Heinrich H. Nax, Matjaz Perc,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06518", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06518", "title": "\nFirst order convergence of matroids", "abstract": "The model theory based notion of the first order convergence unifies the notions of the left-convergence for dense structures and the Benjamini-Schramm convergence for sparse structures. It is known that every first order convergent sequence of graphs with bounded tree-depth has an analytic limit object called a limit modeling. We establish the matroid counterpart of this result: every first order convergent sequence of matroids with bounded branch-depth representable over a fixed finite field has a limit modeling, i.e., there exists an infinite matroid with the elements forming a probability space that has asymptotically the same first order properties. We show that neither of the bounded branch-depth assumption nor the representability assumption can be removed.", "subjects": "Combinatorics (math.CO)", "authors": "Frantisek Kardos, Daniel Kral, Anita Liebenau, Lukas Mach,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06450", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06450", "title": "\nIT-map: an Effective Nonlinear Dimensionality Reduction Method for  Interactive Clustering", "abstract": "Scientists in many fields have the common and basic need of dimensionality reduction: visualizing the underlying structure of the massive multivariate data in a low-dimensional space. However, many dimensionality reduction methods confront the so-called \"crowding problem\" that clusters tend to overlap with each other in the embedding. Previously, researchers expect to avoid that problem and seek to make clusters maximally separated in the embedding. However, the proposed in-tree (IT) based method, called IT-map, allows clusters in the embedding to be locally overlapped, while seeking to make them distinguishable by some small yet key parts. IT-map provides a simple, effective and novel solution to cluster-preserving mapping, which makes it possible to cluster the original data points interactively and thus should be of general meaning in science and engineering.", "subjects": "Machine Learning (stat.ML)", "authors": "Teng Qiu, Yongjie Li,", "date": "2015-1-6"}, 
{"urllink": "http://arxiv.org/abs/1501.06328", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06328", "title": "\nA weakly universal cellular automaton with 2 states on the tiling {11,3}", "abstract": "In this paper, we construct a weakly universal cellular automaton with two states only on the tiling . The cellular automaton is rotation invariant and it is a true planar one.", "subjects": "Cellular Automata and Lattice Gases (nlin.CG)", "authors": "Maurice Margenstern,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06301", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06301", "title": "\nLocal convergence of random graph colorings", "abstract": "Let be a random graph whose average degree is below the -colorability threshold. If we sample a -coloring of uniformly at random, what can we say about the correlations between the colors assigned to vertices that are far apart? According to a prediction from statistical physics, for average degrees below the so-called , the colors assigned to far away vertices are asymptotically independent [Krzakala et al.: Proc. National Academy of Sciences 2007]. We prove this conjecture for exceeding a certain constant . More generally, we investigate the joint distribution of the -colorings that induces locally on the bounded-depth neighborhoods of any fixed number of vertices. In addition, we point out an implication on the reconstruction problem.", "subjects": "Combinatorics (math.CO)", "authors": "Amin Coja-Oghlan, Charilaos Efthymiou, Nor Jaafari,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06243", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06243", "title": "\nPoisson Matrix Completion", "abstract": "We extend the theory of matrix completion to the case where we make Poisson observations for a subset of entries of a low-rank matrix of rank . We consider the (now) usual matrix recovery formulation through maximum likelihood with proper constraints on the matrix , and establish theoretical upper and lower bounds on the recovery error. Our bounds are nearly optimal up to a factor on the order of . These bounds are obtained by adapting the arguments used for one-bit matrix completion (although these two problems are different in nature) and the adaptation requires new techniques exploiting properties of the Poisson likelihood function and tackling the difficulties posed by the non sub-Gaussian (only locally sub-Gaussian) characteristic of the Poisson distribution. Our results highlight a few important distinctions of Poisson matrix completion compared to the prior work in matrix completion including having to impose a minimum signal-to-noise requirement on each observed entry. We also develop an efficient iterative algorithm and demonstrate its good performance in recovering solar flare images.", "subjects": "Machine Learning (stat.ML)", "authors": "Yang Cao, Yao Xie,", "date": "2015-1-6"}, 
{"urllink": "http://arxiv.org/abs/1501.06241", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06241", "title": "\nSequential Sensing with Model Mismatch", "abstract": "We characterize the performance of sequential information guided sensing, Info-Greedy Sensing, when there is a mismatch between the true signal model and the assumed model, which may be a sample estimate. In particular, we consider a setup where the signal is low-rank Gaussian and the measurements are taken in the directions of eigenvectors of the covariance matrix in a decreasing order of eigenvalues. We establish a set of performance bounds when a mismatched covariance matrix is used, in terms of the gap of signal posterior entropy, as well as the additional amount of power required to achieve the same signal recovery precision. Based on this, we further study how to choose an initialization for Info-Greedy Sensing using the sample covariance matrix, or using an efficient covariance sketching scheme.", "subjects": "Machine Learning (stat.ML)", "authors": "Ruiyang Song, Yao Xie, Sebastian Pokutta,", "date": "2015-1-6"}, 
{"urllink": "http://arxiv.org/abs/1501.06218", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06218", "title": "\nInfinite Edge Partition Models for Overlapping Community Detection and  Link Prediction", "abstract": "A hierarchical gamma process infinite edge partition model is proposed to factorize the binary adjacency matrix of an unweighted undirected relational network under a Bernoulli-Poisson link. The model describes both homophily and stochastic equivalence, and is scalable to big sparse networks by focusing its computation on pairs of linked nodes. It can not only discover overlapping communities and inter-community interactions, but also predict missing edges. A simplified version omitting inter-community interactions is also provided and we reveal its interesting connections to existing models. The number of communities is automatically inferred in a nonparametric Bayesian manner, and efficient inference via Gibbs sampling is derived using novel data augmentation techniques. Experimental results on four real networks demonstrate the models' scalability and state-of-the-art performance.", "subjects": "Machine Learning (stat.ML)", "authors": "Mingyuan Zhou,", "date": "2015-1-25"}, 
{"urllink": "http://arxiv.org/abs/1501.06195", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06195", "title": "\nRandomized sketches for kernels: Fast and optimal non-parametric  regression", "abstract": "Kernel ridge regression (KRR) is a standard method for performing non-parametric regression over reproducing kernel Hilbert spaces. Given samples, the time and space complexity of computing the KRR estimate scale as and respectively, and so is prohibitive in many cases. We propose approximations of KRR based on -dimensional randomized sketches of the kernel matrix, and study how small the projection dimension can be chosen while still preserving minimax optimality of the approximate KRR estimate. For various classes of randomized sketches, including those based on Gaussian and randomized Hadamard matrices, we prove that it suffices to choose the sketch dimension proportional to the statistical dimension (modulo logarithmic factors). Thus, we obtain fast and minimax optimal approximations to the KRR estimate for non-parametric regression.", "subjects": "Machine Learning (stat.ML)", "authors": "Yun Yang, Mert Pilanci, Martin J. Wainwright,", "date": "2015-1-25"}, 
{"urllink": "http://arxiv.org/abs/1501.06133", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06133", "title": "\nLocating the source of spreading in complex networks", "abstract": "Locating the sources that trigger a dynamical process is a fundamental but challenging problem in complex networks, ranging from epidemic spreading in society and on the Internet to cancer metastasis in the human body. An accurate localization of the source is inherently limited by our ability to simultaneously access the information of all nodes in a large-scale complex network, such as the time at which each individual is infected in a large population. This thus raises two critical questions: how do we locate the source from incomplete information and can we achieve full localization of sources at any possible location from a given set of observers. Here we develop an efficient algorithm to locate the source of a diffusion-like process and propose a general locatability condition. We test the algorithm by employing epidemic spreading and consensus dynamics as typical dynamical processes and apply it to the H1N1 pandemic in China. We find that the sources can be precisely located in arbitrary networks insofar as the locatability condition is assured. Our tools greatly improve our ability to locate the source of diffusion in complex networks based on limited accessibility of nodal information. Moreover they have implications for controlling a variety of dynamical processes taking place on complex networks, such as inhibiting epidemics, slowing the spread of rumors, and eliminating cancer seed cells in the human body.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Zhesi Shen, Shinan Cao, Ying Fan, Zengru Di, Wen-Xu Wang, H. Eugene Stanley,", "date": "2015-1-25"}, 
{"urllink": "http://arxiv.org/abs/1501.06087", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06087", "title": "\nNon-backtracking spectrum of random graphs: community detection and  non-regular Ramanujan graphs", "abstract": "A non-backtracking walk on a graph is a directed path such that no edge is the inverse of its preceding edge. The non-backtracking matrix of a graph is indexed by its directed edges and can be used to count non-backtracking walks of a given length. It has been used recently in the context of community detection and has appeared previously in connection with the Ihara zeta function and in some generalizations of Ramanujan graphs. In this work, we study the largest eigenvalues of the non-backtracking matrix of the Erdos-Renyi random graph and of the Stochastic Block Model in the regime where the number of edges is proportional to the number of vertices. Our results confirm the \"spectral redemption conjecture\" that community detection can be made on the basis of the leading eigenvectors above the feasibility threshold.", "subjects": "Probability (math.PR)", "authors": "Charles Bordenave, Marc Lelarge, Laurent Massouli\u00e9,", "date": "2015-1-24"}, 
{"urllink": "http://arxiv.org/abs/1501.06060", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06060", "title": "\nConsistency Analysis of Nearest Subspace Classifier", "abstract": "The Nearest subspace classifier (NSS) finds an estimation of the underlying subspace within each class and assigns data points to the class that corresponds to its nearest subspace. This paper mainly studies how well NSS can be generalized to new samples. It is proved that NSS is strongly consistent under certain assumptions. For completeness, NSS is evaluated through experiments on various simulated and real data sets, in comparison with some other linear model based classifiers. It is also shown that NSS can obtain effective classification results and is very efficient, especially for large scale data sets.", "subjects": "Machine Learning (stat.ML)", "authors": "Yi Wang,", "date": "2015-1-24"}, 
{"urllink": "http://arxiv.org/abs/1501.06035", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06035", "title": "\nBarker sequences of odd length", "abstract": "A Barker sequence is a binary sequence for which all nontrivial aperiodic autocorrelations are at most 1 in magnitude. An old conjecture due to Turyn asserts that there is no Barker sequence of length greater than 13. In 1961, Turyn and Storer gave an elementary, though somewhat complicated, proof that this conjecture holds for odd lengths. We give a new and simpler proof of this result.", "subjects": "Combinatorics (math.CO)", "authors": "Kai-Uwe Schmidt, J\u00fcrgen Willms,", "date": "2015-1-24"}, 
{"urllink": "http://arxiv.org/abs/1501.05992", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.05992", "title": "\nThe Murchison Widefield Array Correlator", "abstract": "The Murchison Widefield Array (MWA) is a Square Kilometre Array (SKA) Precursor. The telescope is located at the Murchison Radio--astronomy Observatory (MRO) in Western Australia (WA). The MWA consists of 4096 dipoles arranged into 128 dual polarisation aperture arrays forming a connected element interferometer that cross-correlates signals from all 256 inputs. A hybrid approach to the correlation task is employed, with some processing stages being performed by bespoke hardware, based on Field Programmable Gate Arrays (FPGAs), and others by Graphics Processing Units (GPUs) housed in general purpose rack mounted servers. The correlation capability required is approximately 8 TFLOPS (Tera FLoating point Operations Per Second). The MWA has commenced operations and the correlator is generating 8.3 TB/day of correlation products, that are subsequently transferred 700 km from the MRO to Perth (WA) in real-time for storage and offline processing. In this paper we outline the correlator design, signal path, and processing elements and present the data format for the internal and external interfaces.", "subjects": "Instrumentation and Methods for Astrophysics (astro-ph.IM)", "authors": "S. M. Ord, B. Crosse, D. Emrich, D. Pallot, R. B. Wayth, M. A. Clark, S. E. Tremblay, W. Arcus, D. Barnes, M. Bell, G. Bernardi, N. D. R. Bhat, J. D. Bowman, F. Briggs, J. D. Bunton, R. J. Cappallo, B. E. Corey, A. A. Deshpande, L. deSouza, A. Ewell-Wice, L. Feng, R. Goeke, L. J. Greenhill, B. J. Hazelton, D. Herne, J. N. Hewitt, L. Hindson, H. Hurley-Walker, D. Jacobs, M. Johnston-Hollitt, D. L. Kaplan, J. C. Kasper, B. B. Kincaid, R. Koenig, E. Kratzenberg, N. Kudryavtseva, E. Lenc, C. J. Lonsdale, M. J. Lynch, B. McKinley, S. R. McWhirter, D. A. Mitchell, M. F. Morales, E. Morgan, D. Oberoi, A. Offringa, J. Pathikulangara, B. Pindor, T. Prabu, P. Procopio, R. A. Remillard, J. Riding, A. E. E. Rogers, A. Roshi, J. E. Salah, R. J. Sault, N. Udaya Shankar, K. S. Srivani, J. Stevens, R. Subrahmanyan,  et al. (7 additional authors not shown),", "date": "2015-1-24"}, 
{"urllink": "http://arxiv.org/abs/1501.05976", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.05976", "title": "\nRobustness of Spatial Micronetworks", "abstract": "Power lines, roadways, pipelines and other physical infrastructure are critical to modern society. These structures may be viewed as spatial networks where geographic distances play a role in the functionality and construction cost of links. Traditionally, studies of network robustness have primarily considered the connectedness of large, random networks. Yet for spatial infrastructure physical distances must also play a role in network robustness. Understanding the robustness of small spatial networks is particularly important with the increasing interest in microgrids, small-area distributed power grids that are well suited to using renewable energy resources. We study the random failures of links in small networks where functionality depends on both spatial distance and topological connectedness. By introducing a percolation model where the failure of each link is proportional to its spatial length, we find that, when failures depend on spatial distances, networks are more fragile than expected. Accounting for spatial effects in both construction and robustness is important for designing efficient microgrids and other network infrastructure.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Thomas C. McAndrew, Christopher M. Danforth, James P. Bagrow,", "date": "2015-1-23"}, 
{"urllink": "http://arxiv.org/abs/1501.05973", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.05973", "title": "\nInferring and Learning from Neuronal Correspondences", "abstract": "We introduce and study methods for inferring and learning from correspondences among neurons. The approach enables alignment of data from distinct multiunit studies of nervous systems. We show that the methods for inferring correspondences combine data effectively from cross-animal studies to make joint inferences about behavioral decision making that are not possible with the data from a single animal. We focus on data collection, machine learning, and prediction in the representative and long-studied invertebrate nervous system of the European medicinal leech. Acknowledging the computational intractability of the general problem of identifying correspondences among neurons, we introduce efficient computational procedures for matching neurons across animals. The methods include techniques that adjust for missing cells or additional cells in the different data sets that may reflect biological or experimental variation. The methods highlight the value harnessing inference and learning in new kinds of computational microscopes for multiunit neurobiological studies.", "subjects": "Neurons and Cognition (q-bio.NC)", "authors": "Ashish Kapoor, E. Paxon Frady, Stefanie Jegelka, William B. Kristan, Eric Horvitz,", "date": "2015-1-3"}, 
{"urllink": "http://arxiv.org/abs/1501.05956", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.05956", "title": "\nDeterminants of Meme Popularity", "abstract": "Online social media have greatly affected the way in which we communicate with each other. However, little is known about what are the fundamental mechanisms driving dynamical information flow in online social systems. Here, we introduce a generative model for online sharing behavior and analytically show, using techniques from mathematical population genetics, that competition between memes for the limited resource of user attention leads to a type of self-organized criticality, with heavy-tailed distributions of meme popularity: a few memes \"go viral\" but the majority become only moderately popular. The time-dependent solutions of the model are shown to fit empirical micro-blogging data on hashtag usage, and to predict novel scaling features of the data. The presented framework, in contrast to purely empirical studies or simulation-based models, clearly distinguishes the roles of two distinct factors affecting meme popularity: the memory time of users and the connectivity structure of the social network.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "James P. Gleeson, Kevin P. O'Sullivan, Raquel A. Ba\u00f1os, Yamir Moreno,", "date": "2015-1-23"}, 
{"urllink": "http://arxiv.org/abs/1501.05943", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.05943", "title": "\nBit-oriented quantum public-key encryption", "abstract": "We propose a bit-oriented quantum public-key scheme which uses Boolean function as private-key and randomly changed pairs of quantum state and classical string as public-keys. Contrast to the typical classical public-key scheme, one private-key in our scheme corresponds to an exponential number of public-keys. The goal of our scheme is to achieve information-theoretic security, and the security analysis is also given.", "subjects": "Quantum Physics (quant-ph)", "authors": "Chenmiao Wu, Li Yang,", "date": "2015-1-5"}, 
{"urllink": "http://arxiv.org/abs/1501.05808", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.05808", "title": "\nA benchmark model to assess community structure in evolving networks", "abstract": "Detecting the time evolution of the community structure of networks is crucial to identify major changes in the internal organization of many complex systems, which may undergo important endogenous or exogenous events. This analysis can be done in two ways: considering each snapshot as an independent community detection problem or taking into account the whole evolution of the network. In the first case, one can apply static methods on the temporal snapshots, which correspond to configurations of the system in short time windows, and match afterwards the communities across layers. Alternatively, one can develop dedicated dynamic procedures, so that multiple snapshots are simultaneously taken into account while detecting communities, which allows to keep memory of the flow. To check how well a method of any kind could capture the evolution of communities, suitable benchmarks are needed. Here we propose a model for generating simple dynamic benchmark graphs, based on stochastic block models. In them, the time evolution consists of a periodic oscillation of the system's structure between configurations with built-in community structure. We also propose the extension of quality comparison indices to the dynamic scenario. Additionally, we perform several tests on various algorithms which show, unsurprisingly, that dynamic techniques are more suitable than static ones to describe community evolution.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Clara Granell, Richard K. Darst, Alex Arenas, Santo Fortunato, Sergio G\u00f3mez,", "date": "2015-1-23"}, 
{"urllink": "http://arxiv.org/abs/1501.05740", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.05740", "title": "\nBayesian Learning for Low-Rank matrix reconstruction", "abstract": "We develop latent variable models for Bayesian learning based low-rank matrix completion and reconstruction from linear measurements. For under-determined systems, the developed methods are shown to reconstruct low-rank matrices when neither the rank nor the noise power is known a-priori. We derive relations between the latent variable models and several low-rank promoting penalty functions. The relations justify the use of Kronecker structured covariance matrices in a Gaussian based prior. In the methods, we use evidence approximation and expectation-maximization to learn the model parameters. The performance of the methods is evaluated through extensive numerical simulations.", "subjects": "Machine Learning (stat.ML)", "authors": "Martin Sundin, Cristian R. Rojas, Magnus Jansson, Saikat Chatterjee,", "date": "2015-1-23"}, 
{"urllink": "http://arxiv.org/abs/1501.05691", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.05691", "title": "\nA Note on the Uniform Kan Condition in Nominal Cubical Sets", "abstract": "Bezem, Coquand, and Huber have recently given a constructively valid model of higher type theory in a category of nominal cubical sets satisfying a novel condition, called the uniform Kan condition (UKC), which generalizes the standard cubical Kan condition (as considered by, for example, Williamson in his survey of combinatorial homotopy theory) to admit phantom \"additional\" dimensions in open boxes. This note, which represents the authors' attempts to fill in the details of the UKC, is intended for newcomers to the field who may appreciate a more explicit formulation and development of the main ideas. The crux of the exposition is an analogue of the Yoneda Lemma for co-sieves that relates geometric open boxes bijectively to their algebraic counterparts, much as its progenitor for representables relates geometric cubes to their algebraic counterparts in a cubical set. This characterization is used to give a formulation of uniform Kan fibrations in which uniformity emerges as naturality in the additional dimensions.", "subjects": "Logic (math.LO)", "authors": "Robert Harper, Kuen-Bang Hou,", "date": "2015-1-23"}, 
{"urllink": "http://arxiv.org/abs/1501.05684", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.05684", "title": "\nBi-Objective Nonnegative Matrix Factorization: Linear Versus  Kernel-Based Models", "abstract": "Nonnegative matrix factorization (NMF) is a powerful class of feature extraction techniques that has been successfully applied in many fields, namely in signal and image processing. Current NMF techniques have been limited to a single-objective problem in either its linear or nonlinear kernel-based formulation. In this paper, we propose to revisit the NMF as a multi-objective problem, in particular a bi-objective one, where the objective functions defined in both input and feature spaces are taken into account. By taking the advantage of the sum-weighted method from the literature of multi-objective optimization, the proposed bi-objective NMF determines a set of nondominated, Pareto optimal, solutions instead of a single optimal decomposition. Moreover, the corresponding Pareto front is studied and approximated. Experimental results on unmixing real hyperspectral images confirm the efficiency of the proposed bi-objective NMF compared with the state-of-the-art methods.", "subjects": "Machine Learning (stat.ML)", "authors": "Paul Honeine, Fei Zhu,", "date": "2015-1-22"}, 
{"urllink": "http://arxiv.org/abs/1501.05636", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.05636", "title": "\nQuantum Markov chains, sufficiency of quantum channels, and Renyi  information measures", "abstract": "A short quantum Markov chain is a tripartite state such that system can be recovered perfectly by acting on system of the reduced state . Such states have conditional mutual information equal to zero and are the only states with this property. A quantum channel is sufficient for two states and if there exists a recovery channel using which one can perfectly recover from and from . The relative entropy difference is equal to zero if and only if is sufficient for and . In this paper, we show that these properties extend to Renyi generalizations of these information measures which were proposed in [Berta et al., J. Math. Phys. 56, 022205, (2015) and arXiv:1410.1443], thus providing an alternate characterization of short quantum Markov chains and sufficient quantum channels. These results give further support to these quantities as being legitimate Renyi generalizations of the conditional mutual information and the relative entropy difference. Along the way, we solve some open questions of Ruskai and Zhang, regarding the trace of particular matrices that arise in the study of monotonicity of relative entropy under quantum operations and strong subadditivity of the von Neumann entropy.", "subjects": "Quantum Physics (quant-ph)", "authors": "Nilanjana Datta, Mark M. Wilde,", "date": "2015-1-2"}, 
{"urllink": "http://arxiv.org/abs/1501.05624", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.05624", "title": "\nA Collaborative Kalman Filter for Time-Evolving Dyadic Processes", "abstract": "We present the collaborative Kalman filter (CKF), a dynamic model for collaborative filtering and related factorization models. Using the matrix factorization approach to collaborative filtering, the CKF accounts for time evolution by modeling each low-dimensional latent embedding as a multidimensional Brownian motion. Each observation is a random variable whose distribution is parameterized by the dot product of the relevant Brownian motions at that moment in time. This is naturally interpreted as a Kalman filter with multiple interacting state space vectors. We also present a method for learning a dynamically evolving drift parameter for each location by modeling it as a geometric Brownian motion. We handle posterior intractability via a mean-field variational approximation, which also preserves tractability for downstream calculations in a manner similar to the Kalman filter. We evaluate the model on several large datasets, providing quantitative evaluation on the 10 million Movielens and 100 million Netflix datasets and qualitative evaluation on a set of 39 million stock returns divided across roughly 6,500 companies from the years 1962-2014.", "subjects": "Machine Learning (stat.ML)", "authors": "San Gultekin, John Paisley,", "date": "2015-1-22"}, 
{"urllink": "http://arxiv.org/abs/1501.05590", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.05590", "title": "\nSketch and Validate for Big Data Clustering", "abstract": "In response to the need for learning tools tuned to big data analytics, the present paper introduces a framework for efficient clustering of huge sets of (possibly high-dimensional) data. Building on random sampling and consensus (RANSAC) ideas pursued earlier in a different (computer vision) context for robust regression, a suite of novel dimensionality and set-reduction algorithms is developed. The advocated sketch-and-validate (SkeVa) family includes two algorithms that rely on K-means clustering per iteration on reduced number of dimensions and/or feature vectors: The first operates in a batch fashion, while the second sequential one offers computational efficiency and suitability with streaming modes of operation. For clustering even nonlinearly separable vectors, the SkeVa family offers also a member based on user-selected kernel functions. Further trading off performance for reduced complexity, a fourth member of the SkeVa family is based on a divergence criterion for selecting proper minimal subsets of feature variables and vectors, thus bypassing the need for K-means clustering per iteration. Extensive numerical tests on synthetic and real data sets highlight the potential of the proposed algorithms, and demonstrate their competitive performance relative to state-of-the-art random projection alternatives.", "subjects": "Machine Learning (stat.ML)", "authors": "Panagiotis A. Traganitis, Konstantinos Slavakis, Georgios B. Giannakis,", "date": "2015-1-22"}, 
{"urllink": "http://arxiv.org/abs/1501.05582", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.05582", "title": "\nQuantum Secret Sharing with a Single d-level System", "abstract": "Secret sharing is a cryptographic primitive which plays a central role in various secure multiparty computation tasks and management of keys in cryptography. In secret sharing protocols, a message is divided into shares given to recipient parties in such a way that some number of parties need to collaborate in order to reconstruct the message. Quantum protocols for the task commonly rely on multipartite entanglement. We present a multiparty quantum secret sharing protocol which requires only sequential communication of a single -level system (for any prime ). It is scalable and can be realized with the state of the art technology.", "subjects": "Quantum Physics (quant-ph)", "authors": "Armin Tavakoli, Isabelle Herbauts, Marek Zukowski, Mohamed Bourennane,", "date": "2015-1-22"}, 
{"urllink": "http://arxiv.org/abs/1501.05579", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.05579", "title": "\nAmenability of Schreier graphs and strongly generic algorithms for the  conjugacy problem", "abstract": "In various occasions the conjugacy problem in finitely generated amalgamated products and HNN extensions can be decided efficiently for elements which cannot be conjugated into the base groups. This observation asks for a bound on how many such elements there are. Such bounds can be derived using the theory of amenable graphs: In this work we examine Schreier graphs of amalgamated products and HNN extensions. For an amalgamated product with , the Schreier graph with respect to or turns out to be non-amenable if and only if . Moreover, for an HNN extension of the form , we show that the Schreier graph of with respect to the subgroup is non-amenable if and only if . As application of these characterizations we show that under certain conditions the conjugacy problem in fundamental groups of finite graphs of groups with free abelian vertex groups can be solved in polynomial time on a strongly generic set. Furthermore, the conjugacy problem in groups with more than one end can be solved with a strongly generic algorithm which has essentially the same time complexity as the word problem. These are rather striking results as the word problem might be easy, but the conjugacy problem might be even undecidable. Finally, our results yield another proof that the set where the conjugacy problem of the Baumslag group is decidable in polynomial time is also strongly generic.", "subjects": "Group Theory (math.GR)", "authors": "Volker Diekert, Alexei G. Myasnikov, Armin Wei\u00df,", "date": "2015-1-22"}, 
{"urllink": "http://arxiv.org/abs/1501.05552", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.05552", "title": "\nEstimating the Intrinsic Dimension of Hyperspectral Images Using an  Eigen-Gap Approach", "abstract": "Linear mixture models are commonly used to represent hyperspectral datacube as a linear combinations of endmember spectra. However, determining of the number of endmembers for images embedded in noise is a crucial task. This paper proposes a fully automatic approach for estimating the number of endmembers in hyperspectral images. The estimation is based on recent results of random matrix theory related to the so-called spiked population model. More precisely, we study the gap between successive eigenvalues of the sample covariance matrix constructed from high dimensional noisy samples. The resulting estimation strategy is unsupervised and robust to correlated noise. This strategy is validated on both synthetic and real images. The experimental results are very promising and show the accuracy of this algorithm with respect to state-of-the-art algorithms.", "subjects": "Applications (stat.AP)", "authors": "A. Halimi, P. Honeine, M. Kharouf, C. Richard, J.-Y. Tourneret,", "date": "2015-1-22"}, 
{"urllink": "http://arxiv.org/abs/1501.05519", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.05519", "title": "\nA Note on the Cross Gramian for Non-Symmetric Systems", "abstract": "The cross gramian matrix is a tool for model reduction and system identification, but it is only computable for square control systems. For symmetric control systems the cross gramian possesses a useful relation to the associated system's Hankel singular values. Yet, many real-life models are neither square nor symmetric. In this work, concepts from decentralized control are used to generalize the cross gramian to be applicable for non-square and non-symmetric systems. To illustrate this new non-symmetric cross gramian, it is then applied in the context of model reduction.", "subjects": "Optimization and Control (math.OC)", "authors": "Christian Himpe, Mario Ohlberger,", "date": "2015-1-22"}, 
{"urllink": "http://arxiv.org/abs/1501.05508", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.05508", "title": "\nHigh performance computing aspects of a dimension independent  semi-Lagrangian discontinuous Galerkin code", "abstract": "The recently developed semi-Lagrangian discontinuous Galerkin approach is used to discretize hyperbolic partial differential equations (usually first order equations). Since these methods are conservative, local in space, and able to limit numerical diffusion, they are considered a promising alternative to more traditional semi-Lagrangian schemes (which are usually based on polynomial or spline interpolation). In this paper, we consider a parallel implementation of a semi-Lagrangian discontinuous Galerkin method for distributed memory systems (so-called clusters). Both strong and weak scaling studies are performed on the Vienna Scientific Cluster 2 (VSC-2). In the case of weak scaling, up to 8192 cores, we observe a parallel efficiency above 0.89 for both two and four dimensional problems. Strong scaling results show good scalability to at least 1024 cores (we consider problems that can be run on a single processor in reasonable time). In addition, we study the scaling of a two dimensional Vlasov--Poisson solver that is implemented using the framework provided. All of the simulation are conducted in the context of worst case communication overhead; i.e., in a setting where the CFL number increases linearly with the problem size. The framework introduced in this paper facilitates a dimension independent implementation (based on C++ templates) of scientific codes using both an MPI and a hybrid approach to parallelization. We describe the essential ingredients of our implementation.", "subjects": "Computational Physics (physics.comp-ph)", "authors": "Lukas Einkemmer,", "date": "2015-1-22"}, 
{"urllink": "http://arxiv.org/abs/1501.05367", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.05367", "title": "\nDelivering SKA Science", "abstract": "The SKA will be capable of producing a stream of science data products that are Exa-scale in terms of their storage and processing requirements. This Google-scale enterprise is attracting considerable international interest and excitement from within the industrial and academic communities. In this chapter we examine the data flow, storage and processing requirements of a number of key SKA survey science projects to be executed on the baseline SKA1 configuration. Based on a set of conservative assumptions about trends for HPC and storage costs, and the data flow process within the SKA Observatory, it is apparent that survey projects of the scale proposed will potentially drive construction and operations costs beyond the current anticipated SKA1 budget. This implies a sharing of the resources and costs to deliver SKA science between the community and what is contained within the SKA Observatory. A similar situation was apparent to the designers of the LHC more than 10 years ago. We propose that it is time for the SKA project and community to consider the effort and process needed to design and implement a distributed SKA science data system that leans on the lessons of other projects and looks to recent developments in Cloud technologies to ensure an affordable, effective and global achievement of SKA science goals.", "subjects": "Instrumentation and Methods for Astrophysics (astro-ph.IM)", "authors": "Peter Quinn, Tim Axelrod, Ian Bird, Richard Dodson, Alex Szalay, Andreas Wicenec,", "date": "2015-1-22"}, 
{"urllink": "http://arxiv.org/abs/1501.05269", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.05269", "title": "\nUncovering the spatial structure of mobility networks", "abstract": "The extraction of a clear and simple footprint of the structure of large, weighted and directed networks is a general problem that has many applications. An important example is given by origin-destination matrices which contain the complete information on commuting flows, but are difficult to analyze and compare. We propose here a versatile method which extracts a coarse-grained signature of mobility networks, under the form of a matrix that separates the flows into four categories. We apply this method to origin-destination matrices extracted from mobile phone data recorded in thirty-one Spanish cities. We show that these cities essentially differ by their proportion of two types of flows: integrated (between residential and employment hotspots) and random flows, whose importance increases with city size. Finally the method allows to determine categories of networks, and in the mobility case to classify cities according to their commuting structure.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Thomas Louail, Maxime Lenormand, Miguel Picornell, Oliva Garc\u00eda Cant\u00fa, Ricardo Herranz, Enrique Frias-Martinez, Jos\u00e9 J. Ramasco, Marc Barthelemy,", "date": "2015-1-21"}, 
{"urllink": "http://arxiv.org/abs/1501.05215", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.05215", "title": "\nA Separation Theorem for Chain Event Graphs", "abstract": "Bayesian Networks (BNs) are popular graphical models for the representation of statistical problems embodying dependence relationships between a number of variables. Much of this popularity is due to the d-separation theorem of Pearl and Lauritzen, which allows an analyst to identify the conditional independence statements that a model of the problem embodies using only the topology of the graph. However for many problems the complete model dependence structure cannot be depicted by a BN. The Chain Event Graph (CEG) was introduced for these types of problem. In this paper we introduce a separation theorem for CEGs, analogous to the d-separation theorem for BNs, which likewise allows an analyst to identify the conditional independence structure of their model from the topology of the graph.", "subjects": "Methodology (stat.ME)", "authors": "Peter A. Thwaites, Jim Q. Smith,", "date": "2015-1-21"}, 
{"urllink": "http://arxiv.org/abs/1501.05198", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.05198", "title": "\nMemory and burstiness in dynamic networks", "abstract": "We introduce a class of complex network models which evolve through the addition of edges between nodes selected randomly according to their intrinsic fitness, and the deletion of edges according to their age. We add to this a memory effect where the attractiveness of a node is increased by the number of edges it is currently attached to, and observe that this creates burst-like activity in the attachment events of each individual node which is characterised by a power-law distribution of inter-event times. The fitness of each node depends on the probability distribution from which it is drawn; we find exact solutions for the expectation of the degree distribution for a variety of possible fitness distributions, and for both cases where the memory effect either is, or is not present. This work can potentially lead to methods to uncover hidden fitness distributions from fast changing, temporal network data such as online social communications and fMRI scans.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Ewan R. Colman, Danica Vukadinovi\u0107 Greetham,", "date": "2015-1-1"}, 
{"urllink": "http://arxiv.org/abs/1501.05194", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.05194", "title": "\nA Bayesian alternative to mutual information for the hierarchical  clustering of dependent random variables", "abstract": "The use of mutual information as a similarity measure in agglomerative hierarchical clustering (AHC) raises an important issue: some correction needs to be applied for the dimensionality of variables. In this work, we formulate the decision of merging dependent multivariate normal variables in an AHC procedure as a Bayesian model comparison. We found that the Bayesian formulation naturally shrinks the empirical covariance matrix towards a matrix set a priori (e.g., the identity), provides an automated stopping rule, and corrects for dimensionality using a term that scales up the measure as a function of the dimensionality of the variables. Also, the resulting log Bayes factor is asymptotically proportional to the plug-in estimate of mutual information, with an additive correction for dimensionality in agreement with the Bayesian information criterion. We investigated the behavior of these Bayesian alternatives to mutual information (in exact and asymptotic forms) on simulated and real data. An encouraging result was first derived on simulations : the hierarchical clustering based on the log Bayes factor outperformed off-the-shelf clustering techniques as well as normalized mutual information in terms of classification accuracy. On a toy example, we found that the Bayesian approaches led to results that were similar to those of mutual information clustering techniques, with the advantage of an automated thresholding. On real functional magnetic resonance imaging (fMRI) datasets measuring brain activity, it identified clusters consistent with the established outcome of standard procedures. On this application, normalized mutual information had a highly atypical behavior, in the sense that it systematically favored very large clusters. These initial experiments suggest that the proposed Bayesian alternatives to mutual information are a useful new tool for hierarchical clustering.", "subjects": "Machine Learning (stat.ML)", "authors": "Guillaume Marrelec, Arnaud Mess\u00e9, Pierre Bellec,", "date": "2015-1-21"}, 
{"urllink": "http://arxiv.org/abs/1501.05145", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.05145", "title": "\nCooperation among rational agents in co-action equilibrium of Prisoner's  Dilemma and other single-stage symmetric games", "abstract": "The conventional solution concept used for solving non-cooperative games is that of the Nash equilibrium - a strategy choice by each player so that no player can do better by deviating unilaterally from it. In this paper, we propose an alternative framework referred to as the co-action equilibrium for solving such games. This equilibrium is guaranteed to exist for all games having a symmetric payoff structure. It also has the advantage of being unique for a given game. We analyze in detail three well-known two-person single-stage games, viz., Prisoner's Dilemma (PD), Chicken and Stag Hunt, to illustrate the differences between Nash and co-action solutions. The latter, in general, lead to \"nicer\" strategies being selected by the agents resulting in globally more efficient outcomes. For example, the co-action equilibrium in PD corresponds to full cooperation among agents at lower values of temptation to defect, while for higher temptation each agent employs a probabilistic (or mixed) strategy, thus essentially solving the dilemma. The key idea underlying the co-action solution is that agents make independent choices from the possible actions available, taking into account that other agents will behave the same way as them and they are also aware of this. It defines a new benchmark strategy for agents in non-cooperative games which is very different from the existing ones. The concept can be generalized to game situations where the symmetry assumption does not hold across all agents by clustering players into different symmetry groups that results in a novel class of games.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "V. Sasidevan, Sitabhra Sinha,", "date": "2015-1-21"}, 
{"urllink": "http://arxiv.org/abs/1501.05089", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.05089", "title": "\nWalk-powers and homomorphism bound of planar graphs", "abstract": "As an extension of the Four-Color Theorem it is conjectured that every planar graph of odd-girth at least admits a homomorphism to where 's are standard basis and is all 1 vector. Noting that itself is of odd-girth , in this work we show that if the conjecture is true, then is an optimal such a graph both with respect to number of vertices and number of edges. The result is obtained using the notion of walk-power of graphs and their clique numbers. An analogous result is proved for bipartite signed planar graphs of unbalanced-girth . The work is presented on a uniform frame work of planar consistent signed graphs.", "subjects": "Combinatorics (math.CO)", "authors": "Reza Naserasr, Sagnik Sen, Qiang Sun,", "date": "2015-1-21"}, 
{"urllink": "http://arxiv.org/abs/1501.04986", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.04986", "title": "\nApproximate statistical alignment by iterative sampling of substitution  matrices", "abstract": "We outline a procedure for jointly sampling substitution matrices and multiple sequence alignments, according to an approximate posterior distribution, using an MCMC-based algorithm. This procedure provides an efficient and simple method by which to generate alternative alignments according to their expected accuracy, and allows appropriate parameters for substitution matrices to be selected in an automated fashion. In the cases considered here, the sampled alignments with the highest likelihood have an accuracy consistently higher than alignments generated using the standard BLOSUM62 matrix.", "subjects": "Quantitative Methods (q-bio.QM)", "authors": "Joseph L. Herman, Adrienn Szab\u00f3, Instv\u00e1n Mikl\u00f3s, Jotun Hein,", "date": "2015-1-19"}, 
{"urllink": "http://arxiv.org/abs/1501.04896", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.04896", "title": "\nThe Classification of Quantum Symmetric-Key Encryption Protocols", "abstract": "The classification of quantum symmetric-key encryption protocol is presented. According to five elements of a quantum symmetric-key encryption protocol: plaintext, ciphertext, key, encryption algorithm and decryption algorithm, there are 32 different kinds of them. Among them, 5 kinds of protocols have already been constructed and studied, and 21 kinds of them are proved to be impossible to construct, the last 6 kinds of them are not yet presented effectively. That means the research on quantum symmetric-key encryption protocol only needs to consider with 5 kinds of them nowadays.", "subjects": "Quantum Physics (quant-ph)", "authors": "Chong Xiang, Li Yang, Yong Peng, Dongqing Chen,", "date": "2015-1-19"}, 
{"urllink": "http://arxiv.org/abs/1501.04895", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.04895", "title": "\nQuantum McEliece public-key encryption scheme", "abstract": "This paper investigates a quantum version of McEliece public-key encryption (PKE) scheme, and analyzes its security. As is well known, the security of classical McEliece PKE is not stronger than the onewayness of related classical one-way function. We prove the security of quantum McEliece PKE ranks between them. Moreover, we propose the double-encryption technique to improve its security, and the security of the improved scheme is proved to be between the original scheme and the quantum one-time pad.", "subjects": "Quantum Physics (quant-ph)", "authors": "Li Yang, Min Liang,", "date": "2015-1-19"}, 
{"urllink": "http://arxiv.org/abs/1501.04870", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.04870", "title": "\nScalable Multi-Output Label Prediction: From Classifier Chains to  Classifier Trellises", "abstract": "Multi-output inference tasks, such as multi-label classification, have become increasingly important in recent years. A popular method for multi-label classification is classifier chains, in which the predictions of individual classifiers are cascaded along a chain, thus taking into account inter-label dependencies and improving the overall performance. Several varieties of classifier chain methods have been introduced, and many of them perform very competitively across a wide range of benchmark datasets. However, scalability limitations become apparent on larger datasets when modeling a fully-cascaded chain. In particular, the methods' strategies for discovering and modeling a good chain structure constitutes a mayor computational bottleneck. In this paper, we present the classifier trellis (CT) method for scalable multi-label classification. We compare CT with several recently proposed classifier chain methods to show that it occupies an important niche: it is highly competitive on standard multi-label problems, yet it can also scale up to thousands or even tens of thousands of labels.", "subjects": "Machine Learning (stat.ML)", "authors": "J. Read, L. Martino, P. Olmos, D. Luengo,", "date": "2015-1-20"}, 
{"urllink": "http://arxiv.org/abs/1501.04731", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.04731", "title": "\nRobust Reconstruction of Complex Networks from Sparse Data", "abstract": "Reconstructing complex networks from measurable data is a fundamental problem for understanding and controlling collective dynamics of complex networked systems. However, a significant challenge arises when we attempt to decode structural information hidden in limited amounts of data accompanied by noise and in the presence of inaccessible nodes. Here, we develop a general framework for robust reconstruction of complex networks from sparse and noisy data. Specifically, we decompose the task of reconstructing the whole network into recovering local structures centered at each node. Thus, the natural sparsity of complex networks ensures a conversion from the local structure reconstruction into a sparse signal reconstruction problem that can be addressed by using the lasso, a convex optimization method. We apply our method to evolutionary games, transportation and communication processes taking place in a variety of model and real complex networks, finding that universal high reconstruction accuracy can be achieved from sparse data in spite of noise in time series and missing data of partial nodes. Our approach opens new routes to the network reconstruction problem and has potential applications in a wide range of fields.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Xiao Han, Zhesi Shen, Wen-Xu Wang, Zengru Di,", "date": "2015-1-20"}, 
{"urllink": "http://arxiv.org/abs/1501.04656", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.04656", "title": "\nMicroscopic Advances with Large-Scale Learning: Stochastic Optimization  for Cryo-EM", "abstract": "Determining the 3D structures of biological molecules is a key problem for both biology and medicine. Electron Cryomicroscopy (Cryo-EM) is a promising technique for structure estimation which relies heavily on computational methods to reconstruct 3D structures from 2D images. This paper introduces the challenging Cryo-EM density estimation problem as a novel application for stochastic optimization techniques. Structure discovery is formulated as MAP estimation in a probabilistic latent-variable model, resulting in an optimization problem to which an array of seven stochastic optimization methods are applied. The methods are tested on both real and synthetic data, with some methods recovering reasonable structures in less than one epoch from a random initialization. Complex quasi-Newton methods are found to converge more slowly than simple gradient-based methods, but all stochastic methods are found to converge to similar optima. This method represents a major improvement over existing methods as it is significantly faster and is able to converge from a random initialization.", "subjects": "Machine Learning (stat.ML)", "authors": "Ali Punjani, Marcus A. Brubaker,", "date": "2015-1-9"}, 
{"urllink": "http://arxiv.org/abs/1501.04621", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.04621", "title": "\nSparse Bayesian Learning for EEG Source Localization", "abstract": "Purpose: Localizing the sources of electrical activity from electroencephalographic (EEG) data has gained considerable attention over the last few years. In this paper, we propose an innovative source localization method for EEG, based on Sparse Bayesian Learning (SBL). Methods: To better specify the sparsity profile and to ensure efficient source localization, the proposed approach considers grouping of the electrical current dipoles inside human brain. SBL is used to solve the localization problem in addition with imposed constraint that the electric current dipoles associated with the brain activity are isotropic. Results: Numerical experiments are conducted on a realistic head model that is obtained by segmentation of MRI images of the head and includes four major components, namely the scalp, the skull, the cerebrospinal fluid (CSF) and the brain, with appropriate relative conductivity values. The results demonstrate that the isotropy constraint significantly improves the performance of SBL. In a noiseless environment, the proposed method was 1 found to accurately (with accuracy of &gt;75%) locate up to 6 simultaneously active sources, whereas for SBL without the isotropy constraint, the accuracy of finding just 3 simultaneously active sources was &lt;75%. Conclusions: Compared to the state-of-the-art algorithms, the proposed method is potentially more consistent in specifying the sparsity profile of human brain activity and is able to produce better source localization for EEG.", "subjects": "Quantitative Methods (q-bio.QM)", "authors": "Sajib Saha, Frank de Hoog, Ya.I. Nesterets, Rajib Rana, M. Tahtali, T.E. Gureyev,", "date": "2015-1-19"}, 
{"urllink": "http://arxiv.org/abs/1501.04543", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.04543", "title": "\nA test for monomial containment", "abstract": "We present an algorithm to decide whether a given ideal in the polynomial ring contains a monomial without using Gr \"obner bases, factorization or sub-resultant computations.", "subjects": "Commutative Algebra (math.AC)", "authors": "Simon Keicher, Thomas Kremer,", "date": "2015-1-19"}, 
{"urllink": "http://arxiv.org/abs/1501.04413", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.04413", "title": "\nStatistical-mechanical analysis of pre-training and fine tuning in deep  learning", "abstract": "In this paper, we present a statistical-mechanical analysis of deep learning. We elucidate some of the essential components of deep learning---pre-training by unsupervised learning and fine tuning by supervised learning. We formulate the extraction of features from the training data as a margin criterion in a high-dimensional feature-vector space. The self-organized classifier is then supplied with small amounts of labelled data, as in deep learning. Although we employ a simple single-layer perceptron model, rather than directly analyzing a multi-layer neural network, we find a nontrivial phase transition that is dependent on the number of unlabelled data in the generalization error of the resultant classifier. In this sense, we evaluate the efficacy of the unsupervised learning component of deep learning. The analysis is performed by the replica method, which is a sophisticated tool in statistical mechanics. We validate our result in the manner of deep learning, using a simple iterative algorithm to learn the weight vector on the basis of belief propagation.", "subjects": "Machine Learning (stat.ML)", "authors": "Masayuki Ohzeki,", "date": "2015-1-19"}, 
{"urllink": "http://arxiv.org/abs/1501.04366", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.04366", "title": "\nSource Compression with a Quantum Helper", "abstract": "We study classical source coding with quantum side-information where the quantum side-information is observed by a helper and sent to the decoder via a classical channel. We derive a single-letter characterization of the achievable rate region for this problem. The direct part of our result is proved via the measurement compression theory by Winter. Our result reveals that a helper's scheme that separately conducts a measurement and a compression is suboptimal, and the measurement compression is fundamentally needed to achieve the optimal rate region.", "subjects": "Quantum Physics (quant-ph)", "authors": "Min-Hsiu Hsieh, Shun Watanabe,", "date": "2015-1-18"}, 
{"urllink": "http://arxiv.org/abs/1501.04346", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.04346", "title": "\nMathematical Language Processing: Automatic Grading and Feedback for  Open Response Mathematical Questions", "abstract": "While computer and communication technologies have provided effective means to scale up many aspects of education, the submission and grading of assessments such as homework assignments and tests remains a weak link. In this paper, we study the problem of automatically grading the kinds of open response mathematical questions that figure prominently in STEM (science, technology, engineering, and mathematics) courses. Our data-driven framework for mathematical language processing (MLP) leverages solution data from a large number of learners to evaluate the correctness of their solutions, assign partial-credit scores, and provide feedback to each learner on the likely locations of any errors. MLP takes inspiration from the success of natural language processing for text data and comprises three main steps. First, we convert each solution to an open response mathematical question into a series of numerical features. Second, we cluster the features from several solutions to uncover the structures of correct, partially correct, and incorrect solutions. We develop two different clustering approaches, one that leverages generic clustering algorithms and one based on Bayesian nonparametrics. Third, we automatically grade the remaining (potentially large number of) solutions based on their assigned cluster and one instructor-provided grade per cluster. As a bonus, we can track the cluster assignment of each step of a multistep solution and determine when it departs from a cluster of correct solutions, which enables us to indicate the likely locations of errors to learners. We test and validate MLP on real-world MOOC data to demonstrate how it can substantially reduce the human effort required in large-scale educational platforms.", "subjects": "Machine Learning (stat.ML)", "authors": "Andrew S. Lan, Divyanshu Vats, Andrew E. Waters, Richard G. Baraniuk,", "date": "2015-1-18"}, 
{"urllink": "http://arxiv.org/abs/1501.04321", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.04321", "title": "\nErgodic Theorem for Stabilization of a Hyperbolic PDE Inspired by  Age-Structured Chemostat", "abstract": "We study a feedback stabilization problem for a first-order hyperbolic partial differential equation. The problem is inspired by the stabilization of equilibrium age profiles for an age-structured chemostat, using the dilution rate as the control. Two distinguishing features of the problem are that (a) the PDE has a multiplicative (instead of an additive) input and (b) the state is fed back to the inlet boundary. We provide a sampled-data feedback that ensures stabilization under arbitrarily sparse sampling and that satisfies input constraints. Our chemostat feedback does not require measurement of the age profile, nor does it require exact knowledge of the model.", "subjects": "Optimization and Control (math.OC)", "authors": "Iasson Karafyllis, Michael Malisoff, Miroslav Krstic,", "date": "2015-1-18"}, 
{"urllink": "http://arxiv.org/abs/1501.04313", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.04313", "title": "\nThompson's group F is 1-counter graph automatic", "abstract": "It is not known whether Thompson's group F is automatic. With the recent extensions of the notion of an automatic group to graph automatic by Kharlampovich, Khoussainov and Miasnikov and then to C-graph automatic by the authors, a compelling question is whether F is graph automatic or C-graph automatic for an appropriate language class C. The extended definitions allow the use of a symbol alphabet for the normal form language, replacing the dependence on generating set. In this paper we construct a 1-counter graph automatic structure for F based on the standard infinite normal form for group elements.", "subjects": "Group Theory (math.GR)", "authors": "Murray Elder, Jennifer Taback,", "date": "2015-1-18"}, 
{"urllink": "http://arxiv.org/abs/1501.04305", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.04305", "title": "\nA Novel Compressed Sensing Scheme for Photoacoustic Tomography", "abstract": "Speeding up the data acquisition is one of the central aims to advance tomographic imaging. On the one hand, this reduces motion artifacts due to undesired movements, and on the other hand this decreases the examination time for the patient. In this article, we propose a new scheme for speeding up the data collection process in photoacoustic tomography. Our proposal is based on compressed sensing and reduces acquisition time and system costs while maintaining image quality. As measurement data we use random combinations of pressure values that we use to recover a complete set of pressure data prior to the actual image reconstruction. We obtain theoretical recovery guarantees for our compressed sensing scheme and support the theory by reconstruction results on simulated data as well as on experimental data.", "subjects": "Numerical Analysis (math.NA)", "authors": "Michael Sandbichler, Felix Krahmer, Thomas Berer, Peter Burgholzer, Markus Haltmeier,", "date": "2015-1-18"}, 
{"urllink": "http://arxiv.org/abs/1501.04237", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.04237", "title": "\nQuantized linear systems on integer lattices: a frequency-based approach", "abstract": "The roundoff errors in computer simulations of continuous dynamical systems, caused by finiteness of machine arithmetic, can lead to qualitative discrepancies between phase portraits of the resulting spatially discretized systems and the original systems. These effects can be modelled on a multidimensional integer lattice by using a dynamical system obtained by composing the transition operator of the original system with a quantizer. Such models manifest pseudorandomness which can be studied using a rigorous probability theoretic approach. To this end, the lattice is endowed with a class of frequency measurable subsets and a spatial frequency functional as a finitely additive probability measure on them. Using a multivariate version of Weyl's equidistribution criterion, we introduce an algebra of frequency measurable quasiperiodic subsets of the lattice. This approach is applied to quantized linear systems with the transition operator , where is a nonsingular matrix of the original linear system in , and the map commutes with the additive group of translations of the lattice. For almost every , the events associated with the deviation of trajectories of the quantized and original systems are frequency measurable quasiperiodic subsets of the lattice whose frequencies involve geometric probabilities on finite-dimensional tori. Using the skew products of measure preserving toral automorphisms, we prove mutual independence and uniform distribution of the quantization errors and investigate statistical properties of invertibility loss for the quantized linear system, extending V.V.Voevodin's results. When is similar to an orthogonal matrix, we establish a functional central limit theorem for the deviations of trajectories of the quantized and original systems. These results are demonstrated for rounded-off planar rotations.", "subjects": "Probability (math.PR)", "authors": "Igor G. Vladimirov,", "date": "2015-1-17"}, 
{"urllink": "http://arxiv.org/abs/1501.04212", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.04212", "title": "\nA Proposal for Quantum Rational Secret Sharing", "abstract": "A rational secret sharing scheme is a game in which each party responsible for reconstructing a secret tries to maximize his utility by obtaining the secret alone. Quantum secret sharing schemes, either derived from quantum teleportation or from quantum error correcting code, do not succeed when we assume rational participants. This is because all existing quantum secret sharing schemes consider that the secret is reconstructed by a party chosen by the dealer. In this paper, for the first time, we propose a quantum secret sharing scheme which is resistant to rational parties. The proposed scheme is fair (everyone gets the secret), correct and achieves strict Nash equilibrium.", "subjects": "Quantum Physics (quant-ph)", "authors": "Arpita Maitra, Sourya Joyee De, Goutam Paul, Asim K. Pal,", "date": "2015-1-17"}, 
{"urllink": "http://arxiv.org/abs/1501.04131", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.04131", "title": "\nStructure Learning and Statistical Estimation in Distribution Networks -  Part I", "abstract": "Traditionally power distribution networks are either not observable or only partially observable. This complicates development and implementation of new smart grid technologies, such as those related to demand response, outage detection and management, and improved load-monitoring. In this two part paper, inspired by proliferation of metering technology, we discuss estimation problems in structurally loopy but operationally radial distribution grids from measurements, e.g. voltage data, which are either already available or can be made available with a relatively minor investment. In Part I, the objective is to learn the operational layout of the grid. Part II of this paper presents algorithms that estimate load statistics or line parameters in addition to learning the grid structure. Further, Part II discusses the problem of structure estimation for systems with incomplete measurement sets. Our newly suggested algorithms apply to a wide range of realistic scenarios. The algorithms are also computationally efficient -- polynomial in time -- which is proven theoretically and illustrated computationally on a number of test cases. The technique developed can be applied to detect line failures in real time as well as to understand the scope of possible adversarial attacks on the grid.", "subjects": "Optimization and Control (math.OC)", "authors": "Deepjyoti Deka, Scott Backhaus, Michael Chertkov,", "date": "2015-1-6"}, 
{"urllink": "http://arxiv.org/abs/1501.04091", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.04091", "title": "\nA Hierarchy of Linear Threshold Models for the Spread of Political  Revolutions on Social Networks", "abstract": "We study a linear threshold agent-based model (ABM) for the spread of political revolutions on social networks using empirical network data. We propose new techniques for building a hierarchy of simplified ordinary differential equation (ODE) based models that aim to capture essential features of the ABM, including effects of the actual networks, and give insight in the parameter regime transitions of the ABM. We relate the ABM and the hierarchy of models to a population-level compartmental ODE model that we proposed previously for the spread of political revolutions [1], which is shown to be mathematically consistent with the proposed ABM and provides a way to analyze the global behaviour of the ABM. This consistency with the linear threshold ABM also provides further justification a posteriori for the compartmental model of [1]. Extending concepts from epidemiological modelling, we define a basic reproduction number for the linear threshold ABM and apply it to predict ABM behaviour on empirical networks. In small-scale numerical tests we investigate experimentally the differences in spreading behaviour that occur under the linear threshold ABM model when applied to some empirical online and offline social networks, searching for quantitative evidence that political revolutions may be facilitated by the modern online social networks of social media.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "John C. Lang, Hans De Sterck,", "date": "2015-1-16"}, 
{"urllink": "http://arxiv.org/abs/1501.04067", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.04067", "title": "\nPartition and sum is fast", "abstract": "We consider the following \"partition and sum\" operation on a natural number: Treating the number as a long string of digits insert several plus signs in between some of the digits and carry out the indicated sum. This results in a smaller number and repeated application can always reduce the number to a single digit. We show that surprisingly few iterations of this operation are needed to get down to a single digit.", "subjects": "History and Overview (math.HO)", "authors": "Steve Butler, Ron Graham, Richard Stong,", "date": "2015-1-14"}, 
{"urllink": "http://arxiv.org/abs/1501.04060", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.04060", "title": "\nAnalysis of Quantum Particle Automata for Solving the Density  Classification Problem", "abstract": "To advance our understanding of Quantum Cellular Automata in problem solving through parallel and distributed computing, this research quantized the density classification problem and adopted the Quantum Particle Automata (QPA) to solve the quantized problem. In order to solve this problem, the QPA needed a unitary operator to carry out the QPA evolution and a boundary partition to make the classification decisions. We designed a Genetic Algorithm (GA) to search for the unitary operators and the boundary partitions to classify the density of binary inputs with length 5. The GA was able to find more than one unitary operator that can transform the QPA in ways such that when the particle was measured, it was more likely to collapse to the basis states that were on the correct side of the boundary partition for the QPA to decide if the binary input had majority density 0 or majority density 1. We analyzed these solutions and found that the QPA evolution dynamic was driven by a particular parameter of the unitary operator: a small gave the particle small mass hence fast evolution while large had the opposite effect. While these results are encouraging, scaling these solutions for binary inputs of arbitrary length of requires additional analysis, which we will investigate in our future work.", "subjects": "Quantum Physics (quant-ph)", "authors": "Tina Yu, Radel Ben-Av,", "date": "2015-1-16"}, 
{"urllink": "http://arxiv.org/abs/1501.03997", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.03997", "title": "\nHolistic random encoding for imaging through multimode fibers", "abstract": "The input numerical aperture (NA) of multimode fiber (MMF) can be effectively increased by placing turbid media at the input end of the MMF. This provides the potential for high-resolution imaging through the MMF. While the input NA is increased, the number of propagation modes in the MMF and hence the output NA remains the same. This makes the image reconstruction process underdetermined and may limit the quality of the image reconstruction. In this paper, we aim to improve the signal to noise ratio (SNR) of the image reconstruction in imaging through MMF. We notice that turbid media placed in the input of the MMF transforms the incoming waves into a better format for information transmission and information extraction. We call this transformation as holistic random (HR) encoding of turbid media. By exploiting the HR encoding, we make a considerable improvement on the SNR of the image reconstruction. For efficient utilization of the HR encoding, we employ sparse representation (SR), a relatively new signal reconstruction framework when it is provided with a HR encoded signal. This study shows for the first time to our knowledge the benefit of utilizing the HR encoding of turbid media for recovery in the optically underdetermined systems where the output NA of it is smaller than the input NA for imaging through MMF.", "subjects": "Optics (physics.optics)", "authors": "Hwanchol Jang, Changhyeong Yoon, Euiheon Chung, Wonshik Choi, Heung-No Lee,", "date": "2014-12-30"}, 
{"urllink": "http://arxiv.org/abs/1501.03915", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.03915", "title": "\nFeature Selection based on Machine Learning in MRIs for Hippocampal  Segmentation", "abstract": "Neurodegenerative diseases are frequently associated with structural changes in the brain. Magnetic Resonance Imaging (MRI) scans can show these variations and therefore be used as a supportive feature for a number of neurodegenerative diseases. The hippocampus has been known to be a biomarker for Alzheimer disease and other neurological and psychiatric diseases. However, it requires accurate, robust and reproducible delineation of hippocampal structures. Fully automatic methods are usually the voxel based approach, for each voxel a number of local features were calculated. In this paper we compared four different techniques for feature selection from a set of 315 features extracted for each voxel: (i) filter method based on the Kolmogorov-Smirnov test; two wrapper methods, respectively, (ii) Sequential Forward Selection and (iii) Sequential Backward Elimination; and (iv) embedded method based on the Random Forest Classifier on a set of 10 T1-weighted brain MRIs and tested on an independent set of 25 subjects. The resulting segmentations were compared with manual reference labelling. By using only 23 features for each voxel (sequential backward elimination) we obtained comparable state of-the-art performances with respect to the standard tool FreeSurfer.", "subjects": "Medical Physics (physics.med-ph)", "authors": "Sabina Tangaro, Nicola Amoroso, Massimo Brescia, Stefano Cavuoti, Andrea Chincarini, Rosangela Errico, Paolo Inglese, Giuseppe Longo, Rosalia Maglietta, Andrea Tateo, Giuseppe Riccio, Roberto Bellotti,", "date": "2015-1-16"}, 
{"urllink": "http://arxiv.org/abs/1501.03854", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.03854", "title": "\nUnderstanding Kernel Ridge Regression: Common behaviors from simple  functions to density functionals", "abstract": "Accurate approximations to density functionals have recently been obtained via machine learning (ML). By applying ML to a simple function of one variable without any random sampling, we extract the qualitative dependence of errors on hyperparameters. We find universal features of the behavior in extreme limits, including both very small and very large length scales, and the noise-free limit. We show how such features arise in ML models of density functionals.", "subjects": "Computational Physics (physics.comp-ph)", "authors": "Kevin Vu, John Snyder, Li Li, Matthias Rupp, Brandon F. Chen, Tarek Khelif, Klaus-Robert M\u00fcller, Kieron Burke,", "date": "2015-1-6"}, 
{"urllink": "http://arxiv.org/abs/1501.03844", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.03844", "title": "\nA revisit to evaluating accuracy of community detection using the  normalized mutual information", "abstract": "Normalized Mutual Information (NMI) has been widely used to evaluate accuracy of community detection algorithms. In this notes we show that NMI is seriously affected by systematic error due to finite size of networks, and may give wrong estimate of performance of algorithms in some cases. A simple expression for the estimate of this error is derived and tested numerically. We suggest to use a new measure to accuracy of community detection, namely relative Normalized Mutual Information (rNMI), which is NMI minus the expected NMI of random partitions. This measure is very close to zero for two random partitions even with a short length, so it can overcome the problem of NMI.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Pan Zhang,", "date": "2015-1-15"}, 
{"urllink": "http://arxiv.org/abs/1501.03783", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.03783", "title": "\nEffective zero-dimensionality for computable metric spaces", "abstract": "We begin to study classical dimension theory from the computable analysis (TTE) point of view. For computable metric spaces, several effectivisations of zero-dimensionality are shown to be equivalent. The part of this characterisation that concerns covering dimension extends to higher dimensions and to closed shrinkings of finite open covers. To deal with zero-dimensional subspaces uniformly, four operations (relative to the space and a class of subspaces) are defined; these correspond to definitions of inductive and covering dimensions and a countable basis condition. Finally, an effective retract characterisation of zero-dimensionality is proven under an effective compactness condition. In one direction this uses a version of the construction of bilocated sets.", "subjects": "Logic (math.LO)", "authors": "Robert Kenny,", "date": "2015-1-14"}, 
{"urllink": "http://arxiv.org/abs/1501.03737", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.03737", "title": "\nPolar codes in quantum information theory", "abstract": "Polar codes are the first capacity achieving and efficiently implementable codes for classical communication. Recently they have also been generalized to communication over classical-quantum and quantum channels. In this work we present our recent results for polar coding in quantum information theory, including applications to classical-quantum multiple access channels, interference channels and compound communication settings, including the first proof of channel coding achieving the Han-Kobayashi rate region of the interference channel without the need of a simultaneous decoder. Moreover we add to the existing framework by extending polar codes to achieve the asymmetric capacity and improving the block error probability for classical-quantum channels. In addition we use polar codes to prove a new achievable rate region for the classical-quantum broadcast channel. We also discuss polar codes for quantum communication over quantum channels and state results towards codes for compound quantum channels in this setting. We conclude by stating a list of interesting open questions to invite further research on the topic.", "subjects": "Quantum Physics (quant-ph)", "authors": "Christoph Hirche,", "date": "2015-1-15"}, 
{"urllink": "http://arxiv.org/abs/1501.03641", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.03641", "title": "\nOn Computability and Triviality of Well Groups", "abstract": "The concept of well group in a special but important case captures homological properties of the zero set of a continuous map on a compact space that are invariant with respect to perturbations of . The perturbations are arbitrary continuous maps within distance from for a given in the max-norm. The main drawback of the approach is that the computability of well groups has been shown only when or . Our contribution to the theory of well groups is twofold: on the one hand we improve on the computability issue, but on the other hand we present a range of examples where the well groups are incomplete, that is, fail to capture certain important robust properties of the zero set. As for the first part, we identify a computable subgroup of well group that is obtained by cap product with the pullback of the orientation of by . In other words, well groups can be algorithmically approximated from below. When is smooth and , our approximation of th well group is exact.", "subjects": "Algebraic Topology (math.AT)", "authors": "Peter Franek, Marek Krcal,", "date": "2015-1-15"}, 
{"urllink": "http://arxiv.org/abs/1501.03551", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.03551", "title": "\nDeforming Diamond", "abstract": "For materials science, diamond crystals are almost unrivaled for hardness and a range of other properties. Yet, when simply abstracting the carbon bonding structure as a geometric bar-and-joint periodic framework, it is far from rigid. We study the geometric deformations of this type of framework in arbitrary dimension d, with particular regard to the volume variation of a unit cell.", "subjects": "Metric Geometry (math.MG)", "authors": "Ciprian S. Borcea, Ileana Streinu,", "date": "2015-1-15"}, 
{"urllink": "http://arxiv.org/abs/1501.03550", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.03550", "title": "\nGeometric auxetics", "abstract": "We present a purely geometric notion of auxetic one-parameter deformation of a periodic framework. In materials science and elasticity theory, auxetic behaviour is an expression of negative Poisson's ratios. Simply phrased, auxetic behaviour means becoming laterally wider when streched and thinner when compressed. Our geometric approach relies on the evolution of the periodicity lattice. A deformation path will be auxetic when the Gram metrix for a basis of periods gives a curve with all tangents in the positive semidefinite cone. Thus, an auxetic trajectory is analogous to a causal line in special relativity, with all its tangents in the light cone.", "subjects": "Metric Geometry (math.MG)", "authors": "Ciprian S. Borcea, Ileana Streinu,", "date": "2015-1-15"}, 
{"urllink": "http://arxiv.org/abs/1501.03549", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.03549", "title": "\nLiftings and stresses for planar periodic frameworks", "abstract": "We formulate and prove a periodic analog of Maxwell's theorem relating stressed planar frameworks and their liftings to polyhedral surfaces with spherical topology. We use our lifting theorem to prove deformation and rigidity-theoretic properties for planar periodic pseudo-triangulations, generalizing features known for their finite counterparts. These properties are then applied to questions originating in mathematical crystallography and materials science, concerning planar periodic auxetic structures and ultrarigid periodic frameworks.", "subjects": "Metric Geometry (math.MG)", "authors": "Ciprian S. Borcea, Ileana Streinu,", "date": "2015-1-15"}, 
{"urllink": "http://arxiv.org/abs/1501.03529", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.03529", "title": "\nRanging without time stamps exchanging", "abstract": "We investigate the range estimate between two wireless nodes without time stamps exchanging. Considering practical aspects of oscillator clocks, we propose a new model for ranging in which the measurement errors include the sum of two distributions, namely, uniform and Gaussian. We then derive an approximate maximum likelihood estimator (AMLE), which poses a difficult global optimization problem. To avoid the difficulty in solving the complex AMLE, we propose a simple estimator based on the method of moments. Numerical results show a promising performance for the proposed technique.", "subjects": "Applications (stat.AP)", "authors": "Mohammad Reza Gholami, Satyam Dwivedi, Magnus Jansson, Peter H\u00e4ndel,", "date": "2015-1-14"}, 
{"urllink": "http://arxiv.org/abs/1501.03461", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.03461", "title": "\nAn Algorithmic Pipeline for Analyzing Multi-parametric Flow Cytometry  Data", "abstract": "Flow cytometry (FC) is a single-cell profiling platform for measuring the phenotypes of individual cells from millions of cells in biological samples. FC employs high-throughput technologies and generates high-dimensional data, and hence algorithms for analyzing the data represent a bottleneck. This dissertation addresses several computational challenges arising in modern cytometry while mining information from high-dimensional and high-content biological data. A collection of combinatorial and statistical algorithms for locating, matching, prototyping, and classifying cellular populations from multi-parametric FC data is developed. The algorithmic pipeline, flowMatch, developed in this dissertation consists of five well-defined algorithmic modules to (1) transform data to stabilize within-population variance, (2) identify cell populations by robust clustering algorithms, (3) register cell populations across samples, (4) encapsulate a class of samples with templates, and (5) classify samples based on their similarity with the templates. Components of flowMatch can work independently or collaborate with each other to perform the complete data analysis. flowMatch is made available as an open-source R package in Bioconductor. We have employed flowMatch for classifying leukemia samples, evaluating the phosphorylation effects on T cells, classifying healthy immune profiles, and classifying the vaccination status of HIV patients. In these analyses, the pipeline is able to reach biologically meaningful conclusions quickly and efficiently with the automated algorithms. The algorithms included in flowMatch can also be applied to problems outside of flow cytometry such as in microarray data analysis and image recognition. Therefore, this dissertation contributes to the solution of fundamental problems in computational cytometry and related domains.", "subjects": "Quantitative Methods (q-bio.QM)", "authors": "Ariful Azad,", "date": "2015-1-14"}, 
{"urllink": "http://arxiv.org/abs/1501.03444", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.03444", "title": "\nAverage case complexity of DNFs and Shannon semi-effect for narrow  subclasses of boolean functions", "abstract": "In this paper we establish some bounds on the complexity of disjunctive normal forms of boolean function from narrow subclasses (e.g. functions takes value 0 in a limited number of points). The bounds are obtained by reduction the initial problem to a simple set covering problem. The nature of the complexity bounds provided is tightly connected with Shannon effect and semi-effect for this classes.", "subjects": "Combinatorics (math.CO)", "authors": "Sergey Granin, Yura Maximov,", "date": "2015-1-14"}, 
{"urllink": "http://arxiv.org/abs/1501.03396", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.03396", "title": "\nSand transverse dune aerodynamics: 3D Coherent Flow Structures from a  computational study", "abstract": "The engineering interest about dune fields is dictated by the their interaction with a number of human infrastructures in arid environments. Sand dunes dynamics is dictated by wind and its ability to induce sand erosion, transport and deposition. A deep understanding of dune aerodynamics serves then to ground effective strategies for the protection of human infrastructures from sand, the so-called sand mitigation. Because of their simple geometry and their frequent occurrence in desert area, transverse sand dunes are usually adopted in literature as a benchmark to investigate dune aerodynamics by means of both computational or experimental approaches, usually in nominally 2D setups. The present study aims at evaluating 3D flow features in the wake of a idealised transverse dune, if any, under different nominally 2D setup conditions by means of computational simulations and to compare the obtained results with experimental measurements available in literature.", "subjects": "Fluid Dynamics (physics.flu-dyn)", "authors": "Luca Bruno, Davide Fransos,", "date": "2015-1-1"}, 
{"urllink": "http://arxiv.org/abs/1501.03371", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.03371", "title": "\nGoogle matrix analysis of the multiproduct world trade network", "abstract": "Using the United Nations COMTRADE database cite we construct the Google matrix of multiproduct world trade between the UN countries and analyze the properties of trade flows on this network for years 1962 - 2010. This construction, based on Markov chains, treats all countries on equal democratic grounds independently of their richness and at the same time it considers the contributions of trade products proportionally to their trade volume. We consider the trade with 61 products for up to 227 countries. The obtained results show that the trade contribution of products is asymmetric: some of them are export oriented while others are import oriented even if the ranking by their trade volume is symmetric in respect to export and import after averaging over all world countries. The construction of the Google matrix allows to investigate the sensitivity of trade balance in respect to price variations of products, e.g. petroleum and gas, taking into account the world connectivity of trade links. The trade balance based on PageRank and CheiRank probabilities highlights the leading role of China and other BRICS countries in the world trade in recent years. We also show that the eigenstates of with large eigenvalues select specific trade communities.", "subjects": "Statistical Finance (q-fin.ST)", "authors": "Leonardo Ermann, Dima L. Shepelyansky,", "date": "2015-1-14"}, 
{"urllink": "http://arxiv.org/abs/1501.03347", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.03347", "title": "\nDirichlet Process Parsimonious Mixtures for clustering", "abstract": "The parsimonious Gaussian mixture models, which exploit an eigenvalue decomposition of the group covariance matrices of the Gaussian mixture, have shown their success in particular in cluster analysis. Their estimation is in general performed by maximum likelihood estimation and has also been considered from a parametric Bayesian prospective. We propose new Dirichlet Process Parsimonious mixtures (DPPM) which represent a Bayesian nonparametric formulation of these parsimonious Gaussian mixture models. The proposed DPPM models are Bayesian nonparametric parsimonious mixture models that allow to simultaneously infer the model parameters, the optimal number of mixture components and the optimal parsimonious mixture structure from the data. We develop a Gibbs sampling technique for maximum a posteriori (MAP) estimation of the developed DPMM models and provide a Bayesian model selection framework by using Bayes factors. We apply them to cluster simulated data and real data sets, and compare them to the standard parsimonious mixture models. The obtained results highlight the effectiveness of the proposed nonparametric parsimonious mixture models as a good nonparametric alternative for the parametric parsimonious models.", "subjects": "Machine Learning (stat.ML)", "authors": "Faicel Chamroukhi, Marius Bartcus, Herv\u00e9 Glotin,", "date": "2015-1-14"}, 
{"urllink": "http://arxiv.org/abs/1501.03341", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.03341", "title": "\nSolving Polynomial Systems by Penetrating Gradient Algorithm Applying  Deepest Descent Strategy", "abstract": "An algorithm and associated strategy for solving polynomial systems within the optimization framework is presented. The algorithm and strategy are named, respectively, the penetrating gradient algorithm and the deepest descent strategy. The most prominent feature of penetrating gradient algorithm, after which it was named, is its ability to see and penetrate through the obstacles in error space along the line of search direction and to jump to the global minimizer in a single step. The ability to find the deepest point in an arbitrary direction, no matter how distant the point is and regardless of the relief of error space between the current and the best point, motivates movements in directions in which cost function can be maximally reduced, rather than in directions that seem to be the best locally (like, for instance, the steepest descent, i.e., negative gradient direction). Therefore, the strategy is named the deepest descent, in contrast but alluding to the steepest descent. Penetrating gradient algorithm is derived and its properties are proven mathematically, while features of the deepest descent strategy are shown by comparative simulations. Extensive benchmark tests confirm that the proposed algorithm and strategy jointly form an effective solver of polynomial systems. In addition, further theoretical considerations in Section 5 about solving linear systems by the proposed method reveal a surprising and interesting relation of proposed and Gauss-Seidel method.", "subjects": "Optimization and Control (math.OC)", "authors": "Nikica Hlupic, Ivo Beros,", "date": "2015-1-14"}, 
{"urllink": "http://arxiv.org/abs/1501.03326", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.03326", "title": "\nUnbiased Bayes for Big Data: Paths of Partial Posteriors", "abstract": "A key quantity of interest in Bayesian inference are expectations of functions with respect to a posterior distribution. Markov Chain Monte Carlo is a fundamental tool to consistently compute these expectations via averaging samples drawn from an approximate posterior. However, its feasibility is being challenged in the era of so called Big Data as all data needs to be processed in every iteration. Realising that such simulation is an unnecessarily hard problem if the goal is estimation, we construct a computationally scalable methodology that allows unbiased estimation of the required expectations -- without explicit simulation from the full posterior. The scheme's variance is finite by construction and straightforward to control, leading to algorithms that are provably unbiased and naturally arrive at a desired error tolerance. This is achieved at an average computational complexity that is sub-linear in the size of the dataset and its free parameters are easy to tune. We demonstrate the utility and generality of the methodology on a range of common statistical models applied to large-scale benchmark and real-world datasets.", "subjects": "Machine Learning (stat.ML)", "authors": "Heiko Strathmann, Dino Sejdinovic, Mark Girolami,", "date": "2015-1-4"}, 
{"urllink": "http://arxiv.org/abs/1501.03214", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.03214", "title": "\nQuantifying Prosodic Variability in Middle English Alliterative Poetry", "abstract": "Interest in the mathematical structure of poetry dates back to at least the 19th century: after retiring from his mathematics position, J. J. Sylvester wrote a book on prosody called . Today there is interest in the computer analysis of poems, and this paper discusses how a statistical approach can be applied to this task. Starting with the definition of what Middle English alliteration is, and William Langland's are used to illustrate the methodology. Theory first developed for analyzing data from a Riemannian manifold turns out to be applicable to strings allowing one to compute a generalized mean and variance for textual data, which is applied to the poems above. The ratio of these two variances produces the analogue of the F test, and resampling allows p-values to be estimated. Consequently, this methodology provides a way to compare prosodic variability between two texts.", "subjects": "Applications (stat.AP)", "authors": "Roger Bilisoly,", "date": "2015-1-14"}, 
{"urllink": "http://arxiv.org/abs/1501.03116", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.03116", "title": "\nGraphs with Eulerian unit spheres", "abstract": "d-spheres in graph theory are inductively defined as graphs for which all unit spheres S(x) are (d-1)-spheres and that the removal of one vertex renders the graph contractible. Eulerian d-spheres are geometric d-spheres which are d+1 colorable. We prove here that G is an Eulerian sphere if and only if the degrees of all the (d-2)-dimensional sub-simplices in G are even. This generalizes a Kempe-Heawood result for d=2 and is work related to the conjecture that all d-spheres have chromatic number d+1 or d+2 which is based on the geometric conjecture that every d-sphere can be embedded in an Eulerian (d+1)-sphere. For d=2, such an embedding into an Eulerian 3-sphere would lead to a geometric proof of the 4 color theorem, allowing to see \"why 4 colors suffice\". To achieve the goal of coloring a d-sphere G with d+2 colors, we hope to embed it into a (d+1)-sphere and refine or thin out the later using special homotopy deformations without touching the embedded sphere. Once rendered Eulerian and so (d+2)-colorable, it colors the embedded graph G. In order to define the degree of a simplex, we introduce a notion of dual graph H' of a subgraph H in a general finite simple graph G. This leads to a natural sphere bundle over the simplex graph. We look at geometric graphs which admit a unique geodesic flow: their unit spheres must be Eulerian. We define Platonic spheres graph theoretically as d-spheres for which all unit spheres S(x) are graph isomorphic Platonic (d-1)-spheres. Gauss-Bonnet allows a classification within graph theory: all spheres are Platonic for d=1, the octahedron and icosahedron are the Platonic 2-spheres, the sixteen and six-hundred cells are the Platonic 3-spheres. The cross polytop is the unique Platonic d-sphere for d&gt;3. It is Eulerian.", "subjects": "Combinatorics (math.CO)", "authors": "Oliver Knill,", "date": "2015-1-12"}, 
{"urllink": "http://arxiv.org/abs/1501.03056", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.03056", "title": "\nNon-Abelian Analogs of Lattice Rounding", "abstract": "Lattice rounding in Euclidean space can be viewed as finding the nearest point in the orbit of an action by a discrete group, relative to the norm inherited from the ambient space. Using this point of view, we initiate the study of non-abelian analogs of lattice rounding involving matrix groups. In one direction, we give an algorithm for solving a normed word problem when the inputs are random products over a basis set, and give theoretical justification for its success. In another direction, we prove a general inapproximability result which essentially rules out strong approximation algorithms (i.e., whose approximation factors depend only on dimension) analogous to LLL in the general case.", "subjects": "Group Theory (math.GR)", "authors": "Evgeni Begelfor, Stephen D. Miller, Ramarathnam Venkatesan,", "date": "2015-1-13"}, 
{"urllink": "http://arxiv.org/abs/1501.03049", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.03049", "title": "\nDynamical Properties of Interaction Data", "abstract": "Network dynamics are typically presented as a time series of network properties captured at each period. The current approach examines the dynamical properties of transmission via novel measures on an integrated, temporally extended network representation of interaction data across time. Because it encodes time and interactions as network connections, static network measures can be applied to this \"temporal web\" to reveal features of the dynamics themselves. Here we provide the technical details and apply it to agent-based implementations of the well-known SEIR and SEIS epidemiological models.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Aaron Bramson, Benjamin Vandermarliere,", "date": "2015-1-8"}, 
{"urllink": "http://arxiv.org/abs/1501.03044", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.03044", "title": "\nEffects of Data Resolution and Human Behavior on Large Scale Evacuation  Simulations", "abstract": "Traffic Analysis Zones (TAZ) based macroscopic simulation studies are mostly applied in evacuation planning and operation areas. The large size in TAZ and aggregated information of macroscopic simulation underestimate the real evacuation performance. To take advantage of the high resolution demographic data LandScan USA (the zone size is much smaller than TAZ) and agent-based microscopic traffic simulation models, many new problems appeared and novel solutions are needed. A series of studies are conducted using LandScan USA Population Cells (LPC) data for evacuation assignments with different network configurations, travel demand models, and travelers compliance behavior. First, a new Multiple Source Nearest Destination Shortest Path (MSNDSP) problem is defined for generating Origin Destination matrix in evacuation assignments when using LandScan dataset. Second, a new agent-based traffic assignment framework using LandScan and TRANSIMS modules is proposed for evacuation planning and operation study. Impact analysis on traffic analysis area resolutions (TAZ vs LPC), evacuation start times (daytime vs nighttime), and departure time choice models (normal S shape model vs location based model) are studied. Third, based on the proposed framework, multi-scale network configurations (two levels of road networks and two scales of zone sizes) and three routing schemes (shortest network distance, highway biased, and shortest straight-line distance routes) are implemented for the evacuation performance comparison studies. Fourth, to study the impact of human behavior under evacuation operations, travelers compliance behavior with compliance levels from total complied to total non-complied are analyzed.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Wei Lu,", "date": "2014-12-30"}, 
{"urllink": "http://arxiv.org/abs/1501.03043", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.03043", "title": "\nTypes and operations", "abstract": "A revision of the basic concepts of type, function (called here operation), and relation is proposed. A simple generic method is presented for constructing operations and types as concrete finite structures parameterized by natural numbers. The method gives rise to build inductively so called Universe intended to contain all what can be at least in the sense assumed in the paper. It is argued that the Universe is not yet another formal theory but may be considered as a grounding for some formal theories.", "subjects": "Logic (math.LO)", "authors": "Stanislaw Ambroszkiewicz,", "date": "2015-1-13"}, 
{"urllink": "http://arxiv.org/abs/1501.03024", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.03024", "title": "\nHigh performance photonic reservoir computer based on a coherently  driven passive cavity", "abstract": "Reservoir computing is a recent bio-inspired approach for processing time-dependent signals. It has enabled a breakthrough in analog information processing, with several experiments, both electronic and optical, demonstrating state-of-the-art performances for hard tasks such as speech recognition, time series prediction and nonlinear channel equalization. A proof-of-principle experiment using a linear optical circuit on a photonic chip to process digital signals was recently reported. Here we present a photonic implementation of a reservoir computer based on a coherently driven passive fiber cavity processing analog signals. Our experiment equals or surpasses all previous experiments on a wide variety of tasks, and also has lower power consumption. Furthermore, the analytical model describing our experiment is also of interest, as it constitutes a very simple high performance reservoir computer algorithm. The present experiment, given its good performances, low energy consumption and conceptual simplicity, confirms the great potential of photonic reservoir computing for information processing applications ranging from artificial intelligence to telecommunications.", "subjects": "Optics (physics.optics)", "authors": "Quentin Vinckier, Fran\u00e7ois Duport, Anteo Smerieri, Kristof Vandoorne, Peter Bienstman, Marc Haelterman, Serge Massar,", "date": "2015-1-3"}, 
{"urllink": "http://arxiv.org/abs/1501.03002", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.03002", "title": "\nAn Improvement to the Domain Adaptation Bound in a PAC-Bayesian context", "abstract": "This paper provides a theoretical analysis of domain adaptation based on the PAC-Bayesian theory. We propose an improvement of the previous domain adaptation bound obtained by Germain et al. in two ways. We first give another generalization bound tighter and easier to interpret. Moreover, we provide a new analysis of the constant term appearing in the bound that can be of high interest for developing new algorithmic solutions.", "subjects": "Machine Learning (stat.ML)", "authors": "Pascal Germain, Amaury Habrard, Francois Laviolette, Emilie Morvant,", "date": "2015-1-13"}, 
{"urllink": "http://arxiv.org/abs/1501.03001", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.03001", "title": "\nOn Generalizing the C-Bound to the Multiclass and Multi-label Settings", "abstract": "The C-bound, introduced in Lacasse et al., gives a tight upper bound on the risk of a binary majority vote classifier. In this work, we present a first step towards extending this work to more complex outputs, by providing generalizations of the C-bound to the multiclass and multi-label settings.", "subjects": "Machine Learning (stat.ML)", "authors": "Francois Laviolette, Emilie Morvant, Liva Ralaivola, Jean-Francis Roy,", "date": "2015-1-13"}, 
{"urllink": "http://arxiv.org/abs/1501.02990", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.02990", "title": "\nRandom Bits Regression: a Strong General Predictor for Big Data", "abstract": "To improve accuracy and speed of regressions and classifications, we present a data-based prediction method, Random Bits Regression (RBR). This method first generates a large number of random binary intermediate/derived features based on the original input matrix, and then performs regularized linear/logistic regression on those intermediate/derived features to predict the outcome. Benchmark analyses on a simulated dataset, UCI machine learning repository datasets and a GWAS dataset showed that RBR outperforms other popular methods in accuracy and robustness. RBR (available on this https URL) is very fast and requires reasonable memories, therefore, provides a strong, robust and fast predictor in the big data era.", "subjects": "Machine Learning (stat.ML)", "authors": "Yi Wang, Yi Li, Momiao Xiong, Li Jin,", "date": "2015-1-13"}, 
{"urllink": "http://arxiv.org/abs/1501.02859", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.02859", "title": "\n$\\ell_0$ Sparsifying Transform Learning with Efficient Optimal Updates  and Convergence Guarantees", "abstract": "Many applications in signal processing benefit from the sparsity of signals in a certain transform domain or dictionary. Synthesis sparsifying dictionaries that are directly adapted to data have been popular in applications such as image denoising, inpainting, and medical image reconstruction. In this work, we focus instead on the sparsifying transform model, and study the learning of well-conditioned square sparsifying transforms. The proposed algorithms alternate between a \"norm\"-based sparse coding step, and a non-convex transform update step. We derive the exact analytical solution for each of these steps. The proposed solution for the transform update step achieves the global minimum in that step, and also provides speedups over iterative solutions involving conjugate gradients. We establish that our alternating algorithms are globally convergent to the set of local minimizers of the non-convex transform learning problems. In practice, the algorithms are insensitive to initialization. We present results illustrating the promising performance and significant speed-ups of transform learning over synthesis K-SVD in image denoising.", "subjects": "Machine Learning (stat.ML)", "authors": "Saiprasad Ravishankar, Yoram Bresler,", "date": "2015-1-13"}, 
{"urllink": "http://arxiv.org/abs/1501.02758", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.02758", "title": "\nRevealing latent factors of temporal networks for mesoscale intervention  in epidemic spread", "abstract": "The customary perspective to reason about epidemic mitigation in temporal networks hinges on the identification of nodes with specific features or network roles. The ensuing individual-based control strategies, however, are difficult to carry out in practice and ignore important correlations between topological and temporal patterns. Here we adopt a mesoscopic perspective and present a principled framework to identify collective features at multiple scales and rank their importance for epidemic spread. We use tensor decomposition techniques to build an additive representation of a temporal network in terms of mesostructures, such as cohesive clusters and temporally-localized mixing patterns. This representation allows to determine the impact of individual mesostructures on epidemic spread and to assess the effect of targeted interventions that remove chosen structures. We illustrate this approach using high-resolution social network data on face-to-face interactions in a school and show that our method affords the design of effective mesoscale interventions.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Laetitia Gauvin, Andr\u00e9 Panisson, Alain Barrat, Ciro Cattuto,", "date": "2015-1-12"}, 
{"urllink": "http://arxiv.org/abs/1501.02755", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.02755", "title": "\nComputation of Differential Chow Forms for Prime Differential Ideals", "abstract": "In this paper, we propose algorithms to compute differential Chow forms for prime differential ideals which are given by their characteristic sets. The main algorithm is based on an optimal bound for the order of a prime differential ideal in terms of its characteristic set under an arbitrary ranking, which shows the Jacobi bound conjecture holds in this case. Apart from the order bound, we also give a degree bound for the differential Chow form. In addition, for prime differential ideals given by their characteristic sets under an orderly ranking, a much more simpler algorithm is given to compute its differential Chow form. The computational complexity of both is single exponential in terms of the Jacobi number, the maximal degree of the differential polynomials in the characteristic set and the number of variables.", "subjects": "Algebraic Geometry (math.AG)", "authors": "Wei Li, Yinghong Li,", "date": "2015-1-12"}, 
{"urllink": "http://arxiv.org/abs/1501.02728", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.02728", "title": "\nMinimal paths between communities induced by geographical networks", "abstract": "In this work we investigate the betweenness centrality in geographical networks and its relationship with network communities. We show that nodes with large betweenness define what we call characteristic betweenness paths in both modeled and real-world geographical networks. We define a geographical network model that possess a simple topology while still being able to present such betweenness paths. Using this model, we show that such paths represent pathways between entry and exit points of highly connected regions, or communities, of geographical networks. By defining a new network, containing information about community adjacencies in the original network, we describe a means to characterize the mesoscale connectivity provided by such characteristic betweenness paths.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Henrique Ferraz de Arruda, Cesar Henrique Comin, Luciano da Fontoura Costa,", "date": "2015-1-12"}, 
{"urllink": "http://arxiv.org/abs/1501.02680", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.02680", "title": "\nRecursive generation of IPR fullerenes", "abstract": "We describe a new construction algorithm for the recursive generation of all non-isomorphic IPR fullerenes. Unlike previous algorithms, the new algorithm stays entirely within the class of IPR fullerenes, that is: every IPR fullerene is constructed by expanding a smaller IPR fullerene unless it belongs to limited class of irreducible IPR fullerenes that can easily be made separately. The class of irreducible IPR fullerenes consists of 36 fullerenes with up to 112 vertices and 4 infinite families of nanotube fullerenes. Our implementation of this algorithm is faster than other generators for IPR fullerenes and we used it to compute all IPR fullerenes up to 400 vertices. We also determine a formula for the number of vertices of the smallest fullerenes with a given minimum face-distance between any two pentagons and determine the number of fullerenes where the minimum face-distance between any two pentagons is at least , for , up to 380 vertices.", "subjects": "Combinatorics (math.CO)", "authors": "Jan Goedgebeur, Brendan D. McKay,", "date": "2015-1-12"}, 
{"urllink": "http://arxiv.org/abs/1501.02629", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.02629", "title": "\nScaling-up Empirical Risk Minimization: Optimization of Incomplete  U-statistics", "abstract": "In a wide range of statistical learning problems such as ranking, clustering or metric learning among others, the risk is accurately estimated by -statistics of degree , i.e. functionals of the training data with low variance that take the form of averages over -tuples. From a computational perspective, the calculation of such statistics is highly expensive even for a moderate sample size , as it requires averaging terms. This makes learning procedures relying on the optimization of such data functionals hardly feasible in practice. It is the major goal of this paper to show that, strikingly, such empirical risks can be replaced by drastically computationally simpler Monte-Carlo estimates based on terms only, usually referred to as incomplete -statistics, without damaging the learning rate of Empirical Risk Minimization (ERM) procedures. For this purpose, we establish uniform deviation results describing the error made when approximating a -process by its incomplete version under appropriate complexity assumptions. Extensions to model selection, fast rate situations and various sampling techniques are also considered, as well as an application to stochastic gradient descent for ERM. Finally, numerical examples are displayed in order to provide strong empirical evidence that the approach we promote largely surpasses more naive subsampling techniques.", "subjects": "Machine Learning (stat.ML)", "authors": "St\u00e9phan Cl\u00e9men\u00e7on, Aur\u00e9lien Bellet, Igor Colin,", "date": "2015-1-12"}, 
{"urllink": "http://arxiv.org/abs/1501.02524", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.02524", "title": "\nDesign of a Universal Logic Block for Fault-Tolerant Realization of any  Logic Operation in Trapped-Ion Quantum Circuits", "abstract": "This paper presents a physical mapping tool for quantum circuits, which generates the optimal Universal Logic Block (ULB) that can perform any logical fault-tolerant (FT) quantum operations with the minimum latency. The operation scheduling, placement, and qubit routing problems tackled by the quantum physical mapper are highly dependent on one another. More precisely, the scheduling solution affects the quality of the achievable placement solution due to resource pressures that may be created as a result of operation scheduling whereas the operation placement and qubit routing solutions influence the scheduling solution due to resulting distances between predecessor and current operations, which in turn determines routing latencies. The proposed flow for the quantum physical mapper captures these dependencies by applying (i) a loose scheduling step, which transforms an initial quantum data flow graph into one that explicitly captures the no-cloning theorem of the quantum computing and then performs instruction scheduling based on a modified force-directed scheduling approach to minimize the resource contention and quantum circuit latency, (ii) a placement step, which uses timing-driven instruction placement to minimize the approximate routing latencies while making iterative calls to the aforesaid force-directed scheduler to correct scheduling levels of quantum operations as needed, and (iii) a routing step that finds dynamic values of routing latencies for the qubits. In addition to the quantum physical mapper, an approach is presented to determine the single best ULB size for a target quantum circuit by examining the latency of different FT quantum operations mapped onto different ULB sizes and using information about the occurrence frequency of operations on critical paths of the target quantum algorithm to weigh these latencies.", "subjects": "Quantum Physics (quant-ph)", "authors": "Hadi Goudarzi, Mohammad Javad Dousti, Alireza Shafaei, Massoud Pedram,", "date": "2015-1-12"}, 
{"urllink": "http://arxiv.org/abs/1501.02500", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.02500", "title": "\nLower bounds on the DNF exception problem for short exception lists and  related problems", "abstract": "In this paper we prowide lower bounds on the complexity of the DNF exception problem for short exception lists and hypercube covering problem. The method proposed is based on the relaxation of the initial problem to a certain linear programming problem. Some explicit bounds are provided for the case when exception list size is bounded above by a logarithm of dimension. The bound provided in this case is significantly stronger than the bounds known before.", "subjects": "Combinatorics (math.CO)", "authors": "Yura Maximov,", "date": "2015-1-11"}, 
{"urllink": "http://arxiv.org/abs/1501.02377", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.02377", "title": "\nFast Phase Retrieval for High-Dimensions", "abstract": "We develop a fast phase retrieval method which is near-linear time, making it computationally feasible for large dimensional signals. Both theoretical and experimental results demonstrate the method's speed, accuracy, and robustness. We then use this new phase retrieval method to help establish the first known sublinear-time compressive phase retrieval algorithm capable of recovering a given -sparse vector (up to an unknown phase factor) in just -time using only magnitude measurements.", "subjects": "Numerical Analysis (math.NA)", "authors": "Mark Iwen, Aditya Viswanathan, Yang Wang,", "date": "2015-1-10"}, 
{"urllink": "http://arxiv.org/abs/1501.02357", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.02357", "title": "\nVisibility in Proximal Delaunay Meshes", "abstract": "This paper introduces a visibility relation (and the strong visibility relation ) on proximal Delaunay meshes. A main result in this paper is that the visibility relation is equivalent to Wallman proximity. In addition, a Delaunay triangulation region endowed with the visibility relation has a local Leader uniform topology.", "subjects": "Metric Geometry (math.MG)", "authors": "James F. Peters,", "date": "2015-1-10"}, 
{"urllink": "http://arxiv.org/abs/1501.02315", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.02315", "title": "\nStatistical inference of long-term causal effects in multiagent systems  under the Neyman-Rubin model", "abstract": "Estimation of causal effects of interventions in dynamical systems of interacting agents is under-developed. In this paper, we explore the intricacies of this problem through standard approaches, and demonstrate the need for more appropriate methods. Working under the Neyman-Rubin causal model, we proceed to develop a causal inference method and we explicate the stability assumptions that are necessary for valid causal inference. Our method consists of a behavioral component that models the evolution of agent behaviors over time and informs on the long-term distribution of agent behaviors in the system, and a game-theoretic component that models the observed distribution of agent actions conditional on adopted behaviors. This allows the imputation of long-term estimates of quantities of interest, and thus the estimation of long-term causal effects of interventions. We demonstrate our method on a dataset from behavioral game theory, and discuss open problems to stimulate future research.", "subjects": "Methodology (stat.ME)", "authors": "Panos Toulis, David C. Parkes,", "date": "2015-1-10"}, 
{"urllink": "http://arxiv.org/abs/1501.02252", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.02252", "title": "\nOptimization Methods for Designing Sequences with Low Autocorrelation  Sidelobes", "abstract": "Unimodular sequences with low autocorrelations are desired in many applications, especially in the area of radar and code-division multiple access (CDMA). In this paper, we propose a new algorithm to design unimodular sequences with low integrated sidelobe level (ISL), which is a widely used measure of the goodness of a sequence's correlation property. The algorithm falls into the general framework of majorization-minimization (MM) algorithms and thus shares the monotonic property of such algorithms. In addition, the algorithm can be implemented via fast Fourier transform (FFT) operations and thus is computationally efficient. Furthermore, after some modifications the algorithm can be adapted to incorporate spectral constraints, which makes the design more flexible. Numerical experiments show that the proposed algorithms outperform existing algorithms in terms of both the quality of designed sequences and the computational complexity.", "subjects": "Optimization and Control (math.OC)", "authors": "Junxiao Song, Prabhu Babu, Daniel P. Palomar,", "date": "2014-12-26"}, 
{"urllink": "http://arxiv.org/abs/1501.02246", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.02246", "title": "\nThe Effect of Wedge Tip Angles on Stress Intensity Factors in the  Contact Problem between Tilted Wedge and a Half Plane with an Edge Crack  Using Digital Image Correlation", "abstract": "The first and second mode stress intensity factors (SIFs) of a contact problem between a half-plane with an edge crack and an asymmetric tilted wedge were obtained using experimental method of Digital Image Correlation (DIC). In this technique, displacement and strain fields can be measured using two digital images of the same sample at different stages of loading. However, several images were taken consequently in each stage of this experiment to avoid the noise effect. A pair of images of each stage was compared to each other. Then, the correlation coefficients between them were studied using a computer code. The pairs with the correlation coefficient higher than 0.8 were selected as the acceptable match for displacement measurements near the crack tip. Subsequently, the SIFs of specimens were calculated using displacement fields obtained from DIC method. The effect of wedge tips angle on their SIFs was also studied. Moreover, the results of DIC method were compared with the results of photoelasticity method and a close agreement between them was observed.", "subjects": "Materials Science (cond-mat.mtrl-sci)", "authors": "Seyedmeysam Khaleghian, Anahita Emami, Mohammad Yadegari, Nasser Soltani,", "date": "2015-1-6"}, 
{"urllink": "http://arxiv.org/abs/1501.02245", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.02245", "title": "\nImage Processing Code for Sharpening Photoelastic Fringe Patterns and  Its Usage in Determination of Stress Intensity Factors in a Sample Contact  Problem", "abstract": "This study presented a type of image processing code which is used for sharpening photoelastic fringe patterns of transparent materials in photoelastic experiences to determine the stress distribution. C-Sharp software was utilized for coding the algorithm of this image processing method. For evaluation of this code, the results of a photoelastic experience of a sample contact problem between a half-plane with an oblique edge crack and a tilted wedge using this image processing method was compared with the FEM results of the same problem in order to obtain the stress intensity factors (SIF) of the specimen. A good agreement between experimental results extracted from this method of image processing and computational results was observed.", "subjects": "Materials Science (cond-mat.mtrl-sci)", "authors": "Seyedmeysam Khaleghian, Anahita Emami, Nasser Soltani,", "date": "2015-1-6"}, 
{"urllink": "http://arxiv.org/abs/1501.02237", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.02237", "title": "\nParallel degree computation for solution space of binomial systems with  an application to the master space of $\\mathcal{N}=1$ gauge theories", "abstract": "The problem of solving a system of polynomial equations is one of the most fundamental problems in applied mathematics. Among them, the problem of solving a system of binomial equations form a important subclass for which specialized techniques exist. For both theoretic and applied purposes, the degree of the solution set of a system of binomial equations often plays an important role in understanding the geometric structure of the solution set. Its computation, however, is computationally intensive. This paper proposes a specialized parallel algorithm for computing the degree on GPUs that takes advantage of the massively parallel nature of GPU devices. The preliminary implementation shows remarkable efficiency and scalability when compared to the closest CPU-based counterpart. Applied to the \"master space problem of gauge theories\" the GPU-based implementation achieves nearly 30 fold speedup over its CPU-only counterpart enabling the discovery of previously unknown results. Equally important to note is the far superior scalability: with merely 3 GPU devices on a single workstation, the GPU-based implementation shows better performance, on certain problems, than a small cluster totaling 100 CPU cores.", "subjects": "Algebraic Geometry (math.AG)", "authors": "Tianran Chen, Dhagash Mehta,", "date": "2015-1-9"}, 
{"urllink": "http://arxiv.org/abs/1501.02185", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.02185", "title": "\nBinary and Polytomous Responses Modeling: Multiple-Campaign Ad-Targeting  Without Personal User Information", "abstract": "We present a vertical introduction to campaign optimization; that is, the ability to predict the user response to an ad campaign without any users' profiles on average and for each exposed ad. In practice, we present an approach to build a polytomous model, multi response, composed by several hundred binary models using generalized linear models. The theory has been introduced twenty years ago and it has been applied in different fields since then. Here, we show how we optimize hundreds campaigns and how this large number of campaigns may overcome a few characteristic caveats of single campaign optimization. We discuss the problem and solution of training and calibration at scale. We present statistical performance as , and used in classification. We present also a discussion about the potential performance as throughput: how many decisions can be done per second streaming the bid auctions also by using dedicated hardware.", "subjects": "Applications (stat.AP)", "authors": "Paolo D'Alberto,", "date": "2015-1-2"}, 
{"urllink": "http://arxiv.org/abs/1501.02155", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.02155", "title": "\nA formal proof of the Kepler conjecture", "abstract": "This article describes a formal proof of the Kepler conjecture on dense sphere packings in a combination of the HOL Light and Isabelle proof assistants. This paper constitutes the official published account of the now completed Flyspeck project.", "subjects": "Metric Geometry (math.MG)", "authors": "Thomas Hales, Mark Adams, Gertrud Bauer, Dat Tat Dang, John Harrison, Truong Le Hoang, Cezary Kaliszyk, Victor Magron, Sean McLaughlin, Thang Tat Nguyen, Truong Quang Nguyen, Tobias Nipkow, Steven Obua, Joseph Pleso, Jason Rute, Alexey Solovyev, An Hoai Thi Ta, Trung Nam Tran, Diep Thi Trieu, Josef Urban, Ky Khac Vu, Roland Zumkeller,", "date": "2015-1-9"}, 
{"urllink": "http://arxiv.org/abs/1501.02056", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.02056", "title": "\nSequential Kernel Herding: Frank-Wolfe Optimization for Particle  Filtering", "abstract": "Recently, the Frank-Wolfe optimization algorithm was suggested as a procedure to obtain adaptive quadrature rules for integrals of functions in a reproducing kernel Hilbert space (RKHS) with a potentially faster rate of convergence than Monte Carlo integration (and \"kernel herding\" was shown to be a special case of this procedure). In this paper, we propose to replace the random sampling step in a particle filter by Frank-Wolfe optimization. By optimizing the position of the particles, we can obtain better accuracy than random or quasi-Monte Carlo sampling. In applications where the evaluation of the emission probabilities is expensive (such as in robot localization), the additional computational cost to generate the particles through optimization can be justified. Experiments on standard synthetic examples as well as on a robot localization task indicate indeed an improvement of accuracy over random and quasi-Monte Carlo sampling.", "subjects": "Machine Learning (stat.ML)", "authors": "Simon Lacoste-Julien, Fredrik Lindsten, Francis Bach,", "date": "2015-1-9"}, 
{"urllink": "http://arxiv.org/abs/1501.01946", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.01946", "title": "\nMulti-Beam RF Aperture Using Multiplierless FFT Approximation", "abstract": "Multiple independent radio frequency (RF) beams find applications in communications, radio astronomy, radar, and microwave imaging. An -point FFT applied spatially across an array of receiver antennas provides -independent RF beams at multiplier complexity. Here, a low-complexity multiplierless approximation for the 8-point FFT is presented for RF beamforming, using only 26 additions. The algorithm provides eight beams that closely resemble the antenna array patterns of the traditional FFT-based beamformer albeit without using multipliers. The proposed FFT-like algorithm is useful for low-power RF multi-beam receivers; being synthesized in 45 nm CMOS technology at 1.1 V supply, and verified on-chip using a Xilinx Virtex-6 Lx240T FPGA device. The CMOS simulation and FPGA implementation indicate bandwidths of 588 MHz and 369 MHz, respectively, for each of the independent receive-mode RF beams.", "subjects": "Methodology (stat.ME)", "authors": "D. Suarez, R. J. Cintra, F. M. Bayer, A. Sengupta, S. Kulasekera, A. Madanayake,", "date": "2015-1-8"}, 
{"urllink": "http://arxiv.org/abs/1501.01944", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.01944", "title": "\nSeparating subadditive Euclidean functionals", "abstract": "If we are given random points in the hypercube , then the minimum length of a Traveling Salesperson Tour through the points, the minimum length of a spanning tree, and the minimum length of a matching, etc., are known to be asymptotically a.s., where is an absolute constant in each case. We prove separation results for these constants. In particular, concerning the constants , , , and from the asymptotic formulas for the minimum length TSP, spanning tree, matching, and 2-factor, respectively, we prove that , , and for all . Our results have some computational relevance, showing that a certain natural class of simple algorithms cannot solve the random Euclidean TSP efficiently.", "subjects": "Probability (math.PR)", "authors": "Alan Frieze, Wesley Pegden,", "date": "2015-1-8"}, 
{"urllink": "http://arxiv.org/abs/1501.01811", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.01811", "title": "\nIs \"Compressed Sensing\" compressive? Can it beat the Nyquist Sampling  Approach?", "abstract": "Data compression capability of \"Compressed sensing (sampling)\" in signal discretization is numerically evaluated and found to be far from the theoretical upper bound defined by signal sparsity. It is shown that, for the cases when ordinary sampling with subsequent data compression is prohibitive, there is at least one more efficient, in terms of data compression capability, and more simple and intuitive alternative to Compressed sensing: random sparse sampling and restoration of image band-limited approximations based on energy compaction capability of transforms. It is also shown that assertions that \"Compressed sensing\" can beat the Nyquist sampling approach are rooted in misinterpretation of the sampling theory.", "subjects": "Optics (physics.optics)", "authors": "L. Yaroslavsky,", "date": "2015-1-8"}, 
{"urllink": "http://arxiv.org/abs/1501.01745", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.01745", "title": "\nTransferable measurements of Heredity in models of the Origins of Life", "abstract": "We propose a metric which can be used to compute the amount of heritable variation enabled by a given dynamical system. A distribution of selection pressures is used such that each pressure selects a particular fixed point via competitive exclusion in order to determine the corresponding distribution of potential fixed points in the population dynamics. This metric accurately detects the number of species present in artificially prepared test systems, and furthermore can correctly determine the number of heritable sets in clustered transition matrix models in which there are no clearly defined genomes. Finally, we apply our metric to the GARD model and show that it accurately reproduces prior measurements of the model's heritability.", "subjects": "Populations and Evolution (q-bio.PE)", "authors": "Nicholas Guttenberg, Matthieu Laneuville, Melissa Ilardo, Nathanael Aubert-Kato,", "date": "2015-1-8"}, 
{"urllink": "http://arxiv.org/abs/1501.01741", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.01741", "title": "\nA linear k-fold Cheeger inequality", "abstract": "Given an undirected graph , the classical Cheeger constant, , measures the optimal partition of the vertices into 2 parts with relatively few edges between them based upon the sizes of the parts. The well-known Cheeger's inequality states that where is the minimum nontrivial eigenvalue of the normalized Laplacian matrix. Recent work has generalized the concept of the Cheeger constant when partitioning the vertices of a graph into parts. While there are several approaches, recent results have shown these higher-order Cheeger constants to be tightly controlled by , the -th nontrivial eigenvalue, to within a quadratic factor. We present a new higher-order Cheeger inequality with several new perspectives. First, we use an alternative higher-order Cheeger constant which considers an \"average case\" approach. We show this measure is related to the average of the first nontrivial eigenvalues of the normalized Laplacian matrix. Further, using recent techniques, our results provide linear inequalities using the -norms of the corresponding eigenvectors. Consequently, unlike previous results, this result is relevant even when .", "subjects": "Combinatorics (math.CO)", "authors": "Franklin Kenter, Mary Radcliffe,", "date": "2015-1-8"}, 
{"urllink": "http://arxiv.org/abs/1501.01692", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.01692", "title": "\nDirect products in projective Segre codes", "abstract": "Let K=Fq be a finite field. We introduce a family of projective Reed-Muller-type codes called projective Segre codes. Using commutative algebra and linear algebra methods, we study their basic parameters and show that they are direct products of projective Reed-Muller-type codes. As a consequence we recover some results on projective Reed-Muller-type codes over the Segre variety and over projective tori.", "subjects": "Commutative Algebra (math.AC)", "authors": "Azucena Tochimani, Maria Vaz Pinto, Rafael H. Villarreal,", "date": "2015-1-8"}, 
{"urllink": "http://arxiv.org/abs/1501.01571", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.01571", "title": "\nAn Introduction to Matrix Concentration Inequalities", "abstract": "In recent years, random matrices have come to play a major role in computational mathematics, but most of the classical areas of random matrix theory remain the province of experts. Over the last decade, with the advent of matrix concentration inequalities, research has advanced to the point where we can conquer many (formerly) challenging problems with a page or two of arithmetic. The aim of this monograph is to describe the most successful methods from this area along with some interesting examples that these techniques can illuminate.", "subjects": "Probability (math.PR)", "authors": "Joel A. Tropp,", "date": "2015-1-7"}, 
{"urllink": "http://arxiv.org/abs/1501.01549", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.01549", "title": "\nQuantifying the Leakage of Quantum Protocols for Classical Two-Party  Cryptography", "abstract": "We study quantum protocols among two distrustful parties. By adopting a rather strict definition of correctness - guaranteeing that honest players obtain their correct outcomes only - we can show that every strictly correct quantum protocol implementing a non-trivial classical primitive necessarily leaks information to a dishonest player. This extends known impossibility results to all non-trivial primitives. We provide a framework for quantifying this leakage and argue that leakage is a good measure for the privacy provided to the players by a given protocol. Our framework also covers the case where the two players are helped by a trusted third party. We show that despite the help of a trusted third party, the players cannot amplify the cryptographic power of any primitive. All our results hold even against quantum honest-but-curious adversaries who honestly follow the protocol but purify their actions and apply a different measurement at the end of the protocol. As concrete examples, we establish lower bounds on the leakage of standard universal two-party primitives such as oblivious transfer.", "subjects": "Quantum Physics (quant-ph)", "authors": "Louis Salvail, Christian Schaffner, Miroslava Sotakova,", "date": "2015-1-7"}, 
{"urllink": "http://arxiv.org/abs/1501.01331", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.01331", "title": "\nDNF complexity of complete boolean functions", "abstract": "In this paper we analyse the complexity of boolean functions takes value 0 on a sufficiently small number of points. For many functions this leads to the analysis of a single function attains 0 only on unsigned representation of numbers from 1 to d for various d. Here we obtain a tight bounds on the DNF complexity of complete functions in terms of the number of literals and conjunctions. The method is based on a certain efficient approximation of the hypercube covering problem related to DNF complexity of a given boolean function.", "subjects": "Combinatorics (math.CO)", "authors": "Yura Maximov,", "date": "2015-1-6"}, 
{"urllink": "http://arxiv.org/abs/1501.01144", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.01144", "title": "\nAirborne Ultrasonic Tactile Display BCI", "abstract": "We report on a contactless and airborne ultrasonic tactile display (AUTD) stimulus-based BCI paradigm. Six palm positions are used to evoke somatosensory brain responses, in order to define a novel contactless tactile BCI. A comparison is made with classical attached vibrotactile transducers. Experiment results of subjects performing online experiments validate the novel BCI paradigm. The rationale behind the use of the AUTD is that, due to its contactless nature, it allows for a more hygienic application, avoiding the occurrence of skin ulcers (bedsores) in patients in a locked-in state (LIS).", "subjects": "Neurons and Cognition (q-bio.NC)", "authors": "Katsuhiko Hamada, Hiromu Mori, Hiroyuki Shinoda, Tomasz M. Rutkowski,", "date": "2015-1-6"}, 
{"urllink": "http://arxiv.org/abs/1501.01139", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.01139", "title": "\nSAMP, the Simple Application Messaging Protocol: Letting applications  talk to each other", "abstract": "SAMP, the Simple Application Messaging Protocol, is a hub-based communication standard for the exchange of data and control between participating client applications. It has been developed within the context of the Virtual Observatory with the aim of enabling specialised data analysis tools to cooperate as a loosely integrated suite, and is now in use by many and varied desktop and web-based applications dealing with astronomical data. This paper reviews the requirements and design principles that led to SAMP's specification, provides a high-level description of the protocol, and discusses some of its common and possible future usage patterns, with particular attention to those factors that have aided its success in practice.", "subjects": "Instrumentation and Methods for Astrophysics (astro-ph.IM)", "authors": "M. B. Taylor, T. Boch, J. Taylor,", "date": "2015-1-6"}, 
{"urllink": "http://arxiv.org/abs/1501.01019", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.01019", "title": "\nProtocol for making a $2$-qutrit entangling gate in the Kauffman-Jones  version of $SU(2)_4$", "abstract": "The following paper provides a protocol to physically generate a -qutrit entangling gate in the Kauffman-Jones version of Chern-Simons theory at level . The protocol uses elementary operations on anyons consisting of braids, interferometric measurements, fusions and unfusions and ancilla pair creation.", "subjects": "Quantum Physics (quant-ph)", "authors": "Claire Levaillant,", "date": "2014-12-28"}, 
{"urllink": "http://arxiv.org/abs/1501.01013", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.01013", "title": "\nMaking a circulant 2-qubit entangling gate", "abstract": "We present a way to physically realize a circulant 2-qubit entangling gate in the Kauffman-Jones version of SU(2) Chern-Simons theory at level 4. Our approach uses qubit and qutrit ancillas, braids, fusions and interferometric measurements. Our qubit is formed by four anyons of topological charges 1221. Among other 2-qubit entangling gates we generate in the present paper, we produce in particular the circulant gate CEG = 1/4 I + I sqrt(3)/4 J - 3/4 J^2 + I sqrt(3)/4 J^3, where J denotes the permutation matrix associated with the cycle (1432) and I denotes the identity matrix.", "subjects": "Quantum Physics (quant-ph)", "authors": "Claire I. Levaillant,", "date": "2014-12-31"}, 
{"urllink": "http://arxiv.org/abs/1501.00960", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00960", "title": "\nCharacterizing the Google Books corpus: Strong limits to inferences of  socio-cultural and linguistic evolution", "abstract": "It is tempting to treat frequency trends from Google Books data sets as indicators for the true popularity of various words and phrases. Doing so allows us to draw novel conclusions about the evolution of public perception of a given topic, such as time and gender. However, sampling published works by availability and ease of digitization leads to several important effects. One of these is the surprising ability of a single prolific author to noticeably insert new phrases into a language. A greater effect arises from scientific texts, which have become increasingly prolific in the last several decades and are heavily sampled in the corpus. The result is a surge of phrases typical to academic articles but less common in general, such as references to time in the form of citations. Here, we highlight these dynamics by examining and comparing major contributions to the statistical divergence of English data sets between decades in the period 1800--2000. We find that only the English Fiction data set from the second version of the corpus is not heavily affected by professional texts, in clear contrast to the first version of the fiction data set and both unfiltered English data sets. Our findings emphasize the need to fully characterize the dynamics of the Google Books corpus before using these data sets to draw broad conclusions about cultural and linguistic evolution.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Eitan Adam Pechenick, Christopher M. Danforth, Peter Sheridan Dodds,", "date": "2015-1-5"}, 
{"urllink": "http://arxiv.org/abs/1501.00943", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00943", "title": "\nComparative Studies of Clustering Techniques for Real-Time Dynamic Model  Reduction", "abstract": "Dynamic model reduction in power systems is necessary for improving computational efficiency. Traditional model reduction using linearized models or offline analysis would not be adequate to capture power system dynamic behaviors, especially the new mix of intermittent generation and intelligent consumption makes the power system more dynamic and non-linear. Real-time dynamic model reduction emerges as an important need. This paper explores the use of clustering techniques to analyze real-time phasor measurements to determine generator groups and representative generators for dynamic model reduction. Two clustering techniques -- graph clustering and evolutionary clustering -- are studied in this paper. Various implementations of these techniques are compared and also compared with a previously developed Singular Value Decomposition (SVD)-based dynamic model reduction approach. Various methods exhibit different levels of accuracy when comparing the reduced model simulation against the original model. But some of them are consistently accurate. From this comparative perspective, this paper provides a good reference point for practical implementations.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Emilie Hogan, Eduardo Cotilla-Sanchez, Mahantesh Halappanavar, Zhenyu Huang, Guang Lin, Shuai Lu, Shaobu Wang,", "date": "2015-1-5"}, 
{"urllink": "http://arxiv.org/abs/1501.00882", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00882", "title": "\nObserving Each Other's Observations in the Electronic Mail Game", "abstract": "We study a Bayesian coordination game where agents receive private information on the game's payoff structure. In addition, agents receive private signals on each other's private information. We show that once agents possess these different types of information, there exists a coordination game in the evaluation of this information. And even though the precisions of both signal types is exogenous, the precision with which agents predict each other's actions at equilibrium turns out to be endogenous. As a consequence, we find that there exist multiple equilibria if the private signals' precision is high. These equilibria differ with regard to the way that agents weight their private information to reason about each other's actions.", "subjects": "Economics (q-fin.EC)", "authors": "Dominik Grafenhofer, Wolgang Kuhle,", "date": "2014-12-19"}, 
{"urllink": "http://arxiv.org/abs/1501.00850", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00850", "title": "\nTight bound on trace distance between a realistic device with partially  indistinguishable bosons and the ideal Boson-Sampling computer", "abstract": "We study the closeness of an experimental unitary bosonic network with only partially indistinguishable bosons in an arbitrary mixed input state, in particular an experimental realization of the Boson-Sampling computer, to the ideal bosonic network, where the measure of closeness of two networks is the trace distance between the output probability distributions. An upper bound on the trace distance to the ideal bosonic network is proven and also a bound on the difference between probabilities of an output configuration. Moreover, the upper bound on the trace distance is tight, provided that a physically transparent distinguishability conjecture is true. For a small distinguishability error it is shown that a realistic device with bosons is at a constant trace distance to the ideal Boson-Sampling computer under the -scaling of the mismatch of internal states of bosons.", "subjects": "Quantum Physics (quant-ph)", "authors": "V. S. Shchesnovich,", "date": "2015-1-5"}, 
{"urllink": "http://arxiv.org/abs/1501.00758", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00758", "title": "\nMathematical model for hit phenomena and its application to analyze  popularity of weekly tv drama", "abstract": "Mathematical model for hit phenomena presented by A Ishii et al in 2012 has been extended to analyze and predict a lot of hit subject using social network system. The equation for each individual consumers is assumed and the equation of social response to each hit subject is derived as stochastic process of statistical physics. The advertisement effect is included as external force and the communication effects are included as two-body and three-body interaction. The applications of this model are demonstrated for analyzing population of weekly TV drama. Including both the realtime view data and the playback view data, we found that the indirect communication correlate strongly to the TV viewing rate data for recent Japanese 20 TV drama.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Akira Ishii, Akiko Kitao, Tsukasa Usui, Koki Uchiyama,", "date": "2015-1-5"}, 
{"urllink": "http://arxiv.org/abs/1501.00742", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00742", "title": "\nLEQA: Latency Estimation for a Quantum Algorithm Mapped to a Quantum  Circuit Fabric", "abstract": "This paper presents LEQA, a fast latency estimation tool for evaluating the performance of a quantum algorithm mapped to a quantum fabric. The actual quantum algorithm latency can be computed by performing detailed scheduling, placement and routing of the quantum instructions and qubits in a quantum operation dependency graph on a quantum circuit fabric. This is, however, a very expensive proposition that requires large amounts of processing time. Instead, LEQA, which is based on computing the neighborhood population counts of qubits, can produce estimates of the circuit latency with good accuracy (i.e., an average of less than 3% error) with up to two orders of magnitude speedup for mid-size benchmarks. This speedup is expected to increase superlinearly as a function of circuit size (operation count).", "subjects": "Quantum Physics (quant-ph)", "authors": "Mohammad Javad Dousti, Massoud Pedram,", "date": "2015-1-5"}, 
{"urllink": "http://arxiv.org/abs/1501.00738", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00738", "title": "\nA Unifying Theory for Scaling Laws of Human Populations", "abstract": "The spatial distribution of people exhibits clustering across a wide range of scales, from household (~ km) to continental (~ km) scales. Empirical data indicates simple power-law scalings for the size distribution of cities (known as Zipf's law), the geographic distribution of friends, and the population density fluctuations as a function of scale. We derive a simple statistical model that explains all of these scaling laws based on a single unifying principle involving the random spatial growth of clusters of people on all scales. The model makes important new predictions for the spread of diseases and other social phenomena.", "subjects": "Physics and Society (physics.soc-ph)", "authors": "Henry W. Lin, Abraham Loeb,", "date": "2015-1-5"}, 
{"urllink": "http://arxiv.org/abs/1501.00729", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00729", "title": "\nTwo Globally Convergent Adaptive Speed Observers for Mechanical Systems", "abstract": "A globally exponentially stable speed observer for mechanical systems was recently reported in the literature, under the assumptions of known (or no) Coulomb friction and no disturbances. In this note we propose and adaptive version of this observer, which is robust vis--a--vis constant disturbances. Moreover, we propose a new globally convergent speed observer that, besides rejecting the disturbances, estimates some unknown friction coefficients for a class of mechanical systems that contains several practical examples.", "subjects": "Dynamical Systems (math.DS)", "authors": "Jose Guadalupe Romero, Romeo Ortega,", "date": "2015-1-4"}, 
{"urllink": "http://arxiv.org/abs/1501.00676", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00676", "title": "\nA variational formula for risk-sensitive reward", "abstract": "We derive a variational formula for the optimal growth rate of reward in the infinite horizon risk-sensitive control problem for discrete time Markov decision processes with compact metric state and action spaces, extending a formula of Donsker and Varadhan for the Perron-Frobenius eigenvalue of a positive operator. This leads to a concave maximization formulation of the problem of determining this optimal growth rate.", "subjects": "Optimization and Control (math.OC)", "authors": "Venkatachalam Anantharam, Vivek Shripad Borkar,", "date": "2015-1-4"}, 
{"urllink": "http://arxiv.org/abs/1501.00665", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00665", "title": "\nHuge Unimodular N-Fold Programs", "abstract": "Optimization over integer -way tables with given line-sums is NP-hard already for fixed , but is polynomial time solvable with both fixed. In the version of the problem, the variable dimension is encoded in , with . It was recently shown that the huge problem can be solved in polynomial time for fixed , and the complexity of the problem for variable was raised as an open problem. Here we solve this problem and show that the huge table problem can be solved in polynomial time even when the number of types is . The complexity of the problem over -way tables with variable remains open. Our treatment goes through the more general class of . We show that huge integer programs over -fold products of totally unimodular matrices can be solved in polynomial time even when the number of brick types is variable.", "subjects": "Optimization and Control (math.OC)", "authors": "Shmuel Onn, Pauline Sarrabezolles,", "date": "2015-1-4"}, 
{"urllink": "http://arxiv.org/abs/1501.00656", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00656", "title": "\nAlgebraic Analysis Applied to the Theory of Linear Dynamical Systems", "abstract": "The expression \"Algebraic Analysis\" was coined by Mikio Sato. It consists of using algebraic notions to solve analytic problem. The origin of Algebraic Analysis is Algebraic Geometry as was developed by Alexander Grothendieck and his school. Mimicking the introduction of Grothendieck's EGA (changing only a few words) one obtains a good definition of the modern theory of linear dynamical systems, as developed by Michel Fliess, Ian Willems, Ulrich Oberst and others.", "subjects": "Optimization and Control (math.OC)", "authors": "Henri Bourl\u00e8s,", "date": "2015-1-4"}, 
{"urllink": "http://arxiv.org/abs/1501.00622", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00622", "title": "\nStrong NP-Hardness Result for Regularized $L_q$-Minimization Problems  with Concave Penalty Functions", "abstract": "In this note, we consider the regularize -minimization problem () with a general penalty function. We show that if the penalty function is concave but not linear in a neighborhood of zero, then the optimization problem is strongly NP-hard. This result answers the complexity of many regularized optimization problems studied in the literature. It implies that it is impossible to have a fully polynomial-time approximation scheme (FPTAS) for a large class of regularization problems unless P = NP.", "subjects": "Optimization and Control (math.OC)", "authors": "Dongdong Ge, Zizhuo Wang, Yinyu Ye, Hao Yin,", "date": "2015-1-4"}, 
{"urllink": "http://arxiv.org/abs/1501.00602", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00602", "title": "\nAn analogue of Vosper's Theorem for Extension Fields", "abstract": "We are interested in characterising pairs of -linear subspaces in a field extension such that the linear span of the set of products of elements of and of elements of has small dimension. Our central result is a linear analogue of Vosper's Theorem, which gives the structure of vector spaces in a prime extension of a finite field for which , when and .", "subjects": "Number Theory (math.NT)", "authors": "Christine Bachoc, Oriol Serra, Gilles Zemor,", "date": "2015-1-3"}, 
{"urllink": "http://arxiv.org/abs/1501.00559", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00559", "title": "\nThe Learnability of Unknown Quantum Measurements", "abstract": "Quantum machine learning has received significant attention in recent years, and promising progress has been made in the development of quantum algorithms to speed up traditional machine learning tasks. In this work, however, we focus on investigating the information-theoretic upper bounds of sample complexity - how many training samples are sufficient to predict the future behaviour of an unknown target function. This kind of problem is, arguably, one of the most fundamental problems in statistical learning theory and the bounds for practical settings can be completely characterised by a simple measure of complexity. Our main result in the paper is that, for learning an unknown quantum measurement, the upper bound, given by the fat-shattering dimension, is linearly proportional to the dimension of the underlying Hilbert space. Learning an unknown quantum state becomes a dual problem to ours, and as a byproduct, we can recover Aaronson's famous result [Proc. R. Soc. A 463:3089-3144 (2007)] solely using a classical machine learning technique. In addition, other famous complexity measures like covering numbers and Rademacher complexities are derived explicitly. We are able to connect measures of sample complexity with various areas in quantum information science, e.g. quantum state/measurement tomography, quantum state discrimination and quantum random access codes, which may be of independent interest. Lastly, with the assistance of general Bloch-sphere representation, we show that learning quantum measurements/states can be mathematically formulated as a neural network. Consequently, classical ML algorithms can be applied to efficiently accomplish the two quantum learning tasks.", "subjects": "Quantum Physics (quant-ph)", "authors": "Hao-Chung Cheng, Min-Hsiu Hsieh, Ping-Cheng Yeh,", "date": "2015-1-3"}, 
{"urllink": "http://arxiv.org/abs/1501.00433", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00433", "title": "\nOn the Uniform Computational Content of Computability Theory", "abstract": "We demonstrate that the Weihrauch lattice can be used to study the uniform computational content of computability theoretic properties and theorems in one common setting. The properties that we study include diagonal non-computability, hyperimmunity, complete extensions of Peano arithmetic, 1-genericity, Martin-L \"of randomness and cohesiveness. The theorems that we include in our case study are the Low Basis Theorem of Jockusch and Soare, the Kleene-Post Theorem and Friedman's Jump Inversion Theorem. It turns out that all the aforementioned properties and many theorems in computability theory, including all theorems that claim the existence of some Turing degree, have very little uniform computational content. They are all located outside of the upper cone of binary choice (also known as LLPO) and we call problems with this property indiscriminative. Since practically all theorems from classical analysis whose computational content has been classified are discriminative, our observation could yield an explanation for why theorems and results in computability theory typically have very little direct consequences in other disciplines such as analysis. A notable exception in our case study is the Low Basis Theorem which is discriminative, this is perhaps why it is considered to be one of the most applicable theorems in computability theory. In some cases a bridge between the indiscriminative world and the discriminative world of classical mathematics can be established via a suitable residual operation and we demonstrate this in case of the cohesiveness problem, which turns out to be the quotient of two discriminative problems, namely the limit operation and the jump of Weak K Hnig's Lemma.", "subjects": "Logic (math.LO)", "authors": "Vasco Brattka, Matthew Hendtlass, Alexander P. Kreuzer,", "date": "2015-1-2"}, 
{"urllink": "http://arxiv.org/abs/1501.00379", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00379", "title": "\nThe number of unit-area triangles in the plane: Theme and variations", "abstract": "We show that the number of unit-area triangles determined by a set of points in the plane is , improving the earlier bound of Apfelbaum and Sharir [Discrete Comput. Geom., 2010]. We also consider two special cases of this problem: (i) We show, using a somewhat subtle construction, that if consists of points on three lines, the number of unit-area triangles that spans, with one vertex on each of the lines, can be , for any triple of lines (this number is always in this case). (ii) We show that if is a of the form , where , are sets of real numbers each (i.e., the sequences of differences of consecutive elements of and of are both strictly increasing), then determines unit-area triangles.", "subjects": "Combinatorics (math.CO)", "authors": "Orit E. Raz, Micha Sharir,", "date": "2015-1-2"}, 
{"urllink": "http://arxiv.org/abs/1501.00316", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00316", "title": "\nPhenomenological modelling for Time-Resolved Electron Paramagnetic  Resonance in radical-triplet system", "abstract": "The spin dynamics of radical-triplet system (RTS) has been calculated by using the Lindblad formalism within the theory of open quantum system. The single-radical-triplet system (SRTS) is considered here for single-qubit quantum gate operations while double-radical-triplet system (DRTS) for two-qubit operations. The environment effects taken into account include the spin-lattice relaxation of the triplet exciton and radical spin-, the inter-system crossing process that induces the transition from singlet excited state to the triplet ground state, and the rather slow relaxation process from the triplet ground state back down to the singlet ground state. These calculations shown that the line shape broadening is strongly related to the exchange interaction between triplet and exciton, which can be understood as a spontaneous magnetic field created by the triplet renormalises the original spin- electron spin resonance spectra. This work will provide key information about the spin dynamics for building optically-controlled molecular quantum gate out of radical-bearing molecules. Moreover, this has generated the further theoretical question on how the mixture of fermion and boson behaves.", "subjects": "Quantum Physics (quant-ph)", "authors": "Wei Wu,", "date": "2015-1-1"}, 
{"urllink": "http://arxiv.org/abs/1501.00312", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00312", "title": "\nStatistical consistency and asymptotic normality for high-dimensional  robust M-estimators", "abstract": "We study theoretical properties of regularized robust M-estimators, applicable when data are drawn from a sparse high-dimensional linear model and contaminated by heavy-tailed distributions and/or outliers in the additive errors and covariates. We first establish a form of local statistical consistency for the penalized regression estimators under fairly mild conditions on the error distribution: When the derivative of the loss function is bounded and satisfies a local restricted curvature condition, all stationary points within a constant radius of the true regression vector converge at the minimax rate enjoyed by the Lasso with sub-Gaussian errors. When an appropriate nonconvex regularizer is used in place of an l_1-penalty, we show that such stationary points are in fact unique and equal to the local oracle solution with the correct support---hence, results on asymptotic normality in the low-dimensional case carry over immediately to the high-dimensional setting. This has important implications for the efficiency of regularized nonconvex M-estimators when the errors are heavy-tailed. Our analysis of the local curvature of the loss function also has useful consequences for optimization when the robust regression function and/or regularizer is nonconvex and the objective function possesses stationary points outside the local region. We show that as long as a composite gradient descent algorithm is initialized within a constant radius of the true regression vector, successive iterates will converge at a linear rate to a stationary point within the local region. Furthermore, the global optimum of a convex regularized robust regression function may be used to obtain a suitable initialization. The result is a novel two-step procedure that uses a convex M-estimator to achieve consistency and a nonconvex M-estimator to increase efficiency.", "subjects": "Statistics Theory (math.ST)", "authors": "Po-Ling Loh,", "date": "2015-1-1"}, 
{"urllink": "http://arxiv.org/abs/1501.00288", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00288", "title": "\nLP approximations to mixed-integer polynomial optimization problems", "abstract": "We present a class of linear programming approximations for constrained optimization problems. In the case of mixed-integer polynomial optimization problems, if the intersection graph of the constraints has bounded tree-width our construction yields a class of linear size formulations that attain any desired tolerance. As a result, we obtain an approximation scheme for the \"AC-OPF\" problem on graphs with bounded tree-width. We also describe a more general construction for pure binary optimization problems where individual constraints are available through a membership oracle; if the intersection graph for the constraints has bounded tree-width our construction is of linear size and exact. This improves on a number of results in the literature, both from the perspective of formulation size and generality.", "subjects": "Optimization and Control (math.OC)", "authors": "Daniel Bienstock, Gonzalo Munoz,", "date": "2015-1-1"}, 
{"urllink": "http://arxiv.org/abs/1501.00263", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00263", "title": "\nCommunication-Efficient Distributed Optimization of Self-Concordant  Empirical Loss", "abstract": "We consider distributed convex optimization problems originated from sample average approximation of stochastic optimization, or empirical risk minimization in machine learning. We assume that each machine in the distributed computing system has access to a local empirical loss function, constructed with i.i.d. data sampled from a common distribution. We propose a communication-efficient distributed algorithm to minimize the overall empirical loss, which is the average of the local empirical losses. The algorithm is based on an inexact damped Newton method, where the inexact Newton steps are computed by a distributed preconditioned conjugate gradient method. We analyze its iteration complexity and communication efficiency for minimizing self-concordant empirical loss functions, and discuss the results for distributed ridge regression, logistic regression and binary classification with a smoothed hinge loss. In a standard setting for supervised learning, the required number of communication rounds of the algorithm does not increase with the sample size, and only grows slowly with the number of machines.", "subjects": "Optimization and Control (math.OC)", "authors": "Yuchen Zhang, Lin Xiao,", "date": "2015-1-1"}, 
{"urllink": "http://arxiv.org/abs/1501.00076", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00076", "title": "\nOn The Number of Similar Instances of a Pattern in a Finite Set", "abstract": "New bounds on the number of similar or directly similar copies of a pattern within a finite subset of the line or the plane are proved. The number of equilateral triangles whose vertices all lie within an -point subset of the plane is shown to be no more than . The number of -term arithmetic progressions that lie within an -point subset of the line is shown to be at most , where is the remainder when is divided by . This upper bound is achieved when the points themselves form an arithmetic progression, but for some values of and , it can also be achieved for other configurations of the points, and a full classification of such optimal configurations is given. These results are achieved using a new general method based on ordering relations.", "subjects": "Combinatorics (math.CO)", "authors": "Bernardo Abrego, Silvia Fernandez-Merchant, Daniel J. Katz, Levon Kolesnikov,", "date": "2014-12-31"}, 
{"urllink": "http://arxiv.org/abs/1501.00052", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00052", "title": "\nDetailed Derivations of Small-Variance Asymptotics for some Hierarchical  Bayesian Nonparametric Models", "abstract": "In this note we provide detailed derivations of two versions of small-variance asymptotics for hierarchical Dirichlet process (HDP) mixture models and the HDP hidden Markov model (HDP-HMM, a.k.a. the infinite HMM). We include derivations for the probabilities of certain CRP and CRF partitions, which are of more general interest.", "subjects": "Machine Learning (stat.ML)", "authors": "Jonathan H. Huggins, Ardavan Saeedi, Matthew J. Johnson,", "date": "2014-12-31"}, 
{"urllink": "http://arxiv.org/abs/1501.00033", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00033", "title": "\nParallel repetition for entangled k-player games via fast quantum search", "abstract": "We present two parallel repetition theorems for the entangled value of multi-player, one-round free games (games where the inputs come from a product distribution). Our first theorem shows that for a -player free game with entangled value , the -fold repetition of has entangled value at most , where is the answer length of any player. In contrast, the best known parallel repetition theorem for the classical value of two-player free games is , due to Barak, et al. (RANDOM 2009). This suggests the possibility of a separation between the behavior of entangled and classical free games under parallel repetition. Our second theorem handles the broader class of free games where the players can output (possibly entangled) quantum states. For such games, the repeated entangled value is upper bounded by . We also show that the dependence of the exponent on is necessary: we exhibit a -player free game and such that . Our analysis exploits the novel connection between communication protocols and quantum parallel repetition, first explored by Chailloux and Scarpa (ICALP 2014). We demonstrate that better communication protocols yield better parallel repetition theorems: our first theorem crucially uses a quantum search protocol by Aaronson and Ambainis, which gives a quadratic speed-up for distributed search problems. Finally, our results apply to a broader class of games than were previously considered before; in particular, we obtain the first parallel repetition theorem for entangled games involving more than two players, and for games involving quantum outputs.", "subjects": "Quantum Physics (quant-ph)", "authors": "Xiaodi Wu, Kai-Min Chung, Henry S. Yuen,", "date": "2014-12-26"}, 
{"urllink": "http://arxiv.org/abs/1501.00011", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00011", "title": "\nWhy now is the right time to study quantum computing", "abstract": "Quantum computing is a good way to justify difficult physics experiments. But until quantum computers are built, do computer scientists need to know anything about quantum information? In fact, quantum computing is not merely a recipe for new computing devices, but a new way of looking at the world that has been astonishingly intellectually productive. In this article, I'll talk about where quantum computing came from, what it is, and what we can learn from it.", "subjects": "Quantum Physics (quant-ph)", "authors": "Aram W. Harrow,", "date": "2014-12-30"}, 
{"urllink": "http://arxiv.org/abs/1501.00008", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.00008", "title": "\nReview of Quantum Algorithms for Systems of Linear Equations", "abstract": "This article reviews the 2008 quantum algorithm for linear systems of equations due to Harrow, Hassidim and Lloyd, as well as some of the followup and related work. It was submitted to the Springer Encyclopedia of Algorithms.", "subjects": "Quantum Physics (quant-ph)", "authors": "Aram W. Harrow,", "date": "2014-12-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07887", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07887", "title": "\nOptimal offline virtual network embedding with rent-at-bulk aspects", "abstract": "Network virtualization techniques allow for the coexistence of many virtual networks (VNs) jointly sharing the resources of an underlying substrate network. The Virtual Network Embedding problem (VNE) arises when looking for the most profitable set of VNs to embed onto the substrate. In this paper, we address the offline version of the problem. We propose a Mixed-Integer Linear Programming formulation to solve it to optimality which accounts for acceptance and rejection of virtual network requests, allowing for both splittable and unsplittable (single path) routing schemes. Our formulation also considers a Rent-at-Bulk (RaB) model for the rental of substrate capacities where economies of scale apply. To better emphasize the importance of RaB, we also compare our method to a baseline one which only takes RaB into account a posteriori, once a solution to VNE, oblivious to RaB, has been found. Computational experiments show the viability of our approach, stressing the relevance of addressing RaB directly with an exact formulation", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Stefano Coniglio, Boris Grimm, Arie M.C.A. Koster, Martin Tieves, Axel Werner,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07873", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07873", "title": "\nDeep Neural Networks for Sketch Recognition", "abstract": "Deep Neural Networks (DNNs) have recently outperformed traditional object recognition algorithms on multiple large-scale datasets, such as ImageNet. However, the model trained on ImageNet fails on recognising the sketches, because the data source is dominated by photos and all kinds of sketches are roughly labelled as 'cartoon' rather than their own categorises (e.g., 'cat'). Most of sketch recognition methods still heavily rely on the hand-craft feature extraction techniques, thus it is interesting to know whether DNNs can eliminate the needs of specific feature engineering in this area, and how the architecture is designed for sketch recognition purpose. To the best of our knowledge, it is the first deep neural network model for sketch classification, and it has outperformed state-of-the-art results in the TU-Berlin sketch benchmark. Based on that, we outline a sketch image retrieval system in a unified neural network framework.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Yongxin Yang, Timothy M. Hospedales,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07870", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07870", "title": "\nFractional Coloring (Orthogonal Access) achieves All-unicast Capacity  (DoF) Region of Index Coding (TIM) if and only if Network Topology is Chordal", "abstract": "The main result of this work is that fractional coloring (orthogonal access) achieves the all-unicast capacity (degrees of freedom (DoF)) region of the index coding (topological interference management (TIM)) problem if and only if the bipartite network topology graph (with sources on one side and destinations on the other, and edges identifying presence of nontrivial channels whose communication capacity is not zero or infinity) is chordal, i.e., every cycle that can contain a chord, does contain a chord. The all-unicast capacity (DoF) region includes the capacity (DoF) region for any arbitrary choice of a unicast message set, so e.g., the results of Maleki and Jafar on the optimality of orthogonal access for the sum-capacity (DoF) of one-dimensional convex networks are recovered as a special case.", "subjects": "Information Theory (cs.IT)", "authors": "Xinping Yi, Hua Sun, Syed A. Jafar, David Gesbert,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07867", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07867", "title": "\nMulti-task Image Classification via Collaborative, Hierarchical  Spike-and-Slab Priors", "abstract": "Promising results have been achieved in image classification problems by exploiting the discriminative power of sparse representations for classification (SRC). Recently, it has been shown that the use of emph spike-and-slab priors in conjunction with the class-specific dictionaries from SRC is particularly effective in low training scenarios. As a logical extension, we build on this framework for multitask scenarios, wherein multiple representations of the same physical phenomena are available. We experimentally demonstrate the benefits of mining joint information from different camera views for multi-view face recognition.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Hojjat Seyed Mousavi, Umamahesh Srinivas, Vishal Monga, Yuanming Suo, Minh Dao, Trac. D. Tran,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07866", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07866", "title": "\nA Comparison of Classifiers in Performing Speaker Accent Recognition  Using MFCCs", "abstract": "An algorithm involving Mel-Frequency Cepstral Coefficients (MFCCs) is provided to perform signal feature extraction for the task of speaker accent recognition. Then different classifiers are compared based on the MFCC feature. For each signal, the mean vector of MFCC matrix is used as an input vector for pattern recognition. A sample of 330 signals, containing 165 US voice and 165 non-US voice, is analyzed. By comparison, k-nearest neighbors yield the highest average test accuracy, after using a cross-validation of size 500, and least time being used in the computation", "subjects": "Sound (cs.SD)", "authors": "Zichen Ma, Ernest Fokoue,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07865", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07865", "title": "\nA Criticism of the Current Security, Privacy and Accountability Issues  in Electronic Health Records", "abstract": "Cryptography has been widely accepted for security and partly for privacy control as discovered from past works. However, many of these works did not provide a way to manage cryptographic keys effectively especially in EHR applications, as this is the Achilles heel of cryptographic techniques currently proposed. The issue of accountability for legitimate users also has not been so popular and only a few considered it in EHR. Unless a different approach is used, the reliant on cryptography and password or escrow based system for key management will impede trust of the system and hence its acceptability. Also users with right access should also be monitored without affecting the clinician workflow. This paper presents a detailed review of some selected recent approaches to ensuring security, privacy and accountability in EHR and gaps for future research were also identified.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Adebayo Omotosho, Justice Emuoyibofarhe,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07864", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07864", "title": "\nA Trichotomy in the Data Complexity of Certain Query Answering for  Conjunctive Queries", "abstract": "A relational database is said to be uncertain if primary key constraints can possibly be violated. A repair (or possible world) of an uncertain database is obtained by selecting a maximal number of tuples without ever selecting two distinct tuples with the same primary key value. For any Boolean query q, CERTAINTY(q) is the problem that takes an uncertain database db on input, and asks whether q is true in every repair of db. The complexity of this problem has been particularly studied for q ranging over the class of self-join-free Boolean conjunctive queries. A research challenge is to determine, given q, whether CERTAINTY(q) belongs to complexity classes FO, P, or coNP-complete. In this paper, we combine existing techniques for studying the above complexity classification task. We show that for any self-join-free Boolean conjunctive query q, it can be decided whether or not CERTAINTY(q) is in FO. Further, for any self-join-free Boolean conjunctive query q, CERTAINTY(q) is either in P or coNP-complete, and the complexity dichotomy is effective. This settles a research question that has been open for ten years, since [9].", "subjects": "Databases (cs.DB)", "authors": "Paraschos Koutris, Jef Wijsen,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07862", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07862", "title": "\nAn Analytical Study of different Document Image Binarization Methods", "abstract": "Document image has been the area of research for a couple of decades because of its potential application in the area of text recognition, line recognition or any other shape recognition from the image. For most of these purposes binarization of image becomes mandatory as far as recognition is concerned. Throughout couple decades standard algorithms have already been developed for this purpose. Some of these algorithms are applicable to degraded image also. Our objective behind this work is to study the existing techniques, compare them in view of advantages and disadvantages and modify some of these algorithms to optimize time or performance.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Mahua Nandy, Satadal Saha,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07860", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07860", "title": "\nPopularity and Quality in Social News Aggregators: A Study of Reddit and  Hacker News", "abstract": "In this paper we seek to understand the relationship between the online popularity of an article and its intrinsic quality. Prior experimental work suggests that the relationship between quality and popularity can be very distorted due to factors like social influence bias and inequality in visibility. We conduct a study of popularity on two different social news aggregators, Reddit and Hacker News. We define quality as the relative number of votes an article would have received if each article was shown, in a bias-free way, to an equal number of users. We propose a simple poisson regression method to estimate this quality metric from time-series voting data. We validate our methods on data from Reddit and Hacker News, as well the experimental data from prior work. This method works well even though the collected data is subject to common social media biases. Using these estimates, we find that popularity on Reddit and Hacker News is a stronger reflection of intrinsic quality than expected.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Greg Stoddard,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07857", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07857", "title": "\nPredicting Results of the Research Excellence Framework using  Departmental h-Index -- Revisited", "abstract": "We revisit our recent study [Predicting results of the Research Excellence Framework using departmental h-index, Scientometrics, 2014, 1-16; arXiv:1411.1996] in which we attempted to predict outcomes of the UK's Research Excellence Framework (REF~2014) using the so-called departmental -index. Here we report that our predictions failed to anticipate with any accuracy either overall REF outcomes or movements of individual institutions in the rankings relative to their positions in the previous Research Assessment Exercise (RAE~2008).", "subjects": "Digital Libraries (cs.DL)", "authors": "O. Mryglod, R. Kenna, Yu. Holovatch, B. Berche,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07847", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07847", "title": "\nElectronic Medication Prescribing Support System for Diagnosing Tropical  Diseases", "abstract": "This paper presents the development of an e-prescription system for diagnosing tropical diseases.Results after testing the developed system by medical experts indicated that the e-prescription systems is more efficient and less susceptible to common errors associated with the conventional handwritten medical prescription and can also go a long way to help to improve patients health outcome in the health industry especially in the tropics.", "subjects": "Computers and Society (cs.CY)", "authors": "Adebayo Omotosho, Mikhail Olaniyi, Justice Emuoyibofarhe, Funbi Osobu,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07844", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07844", "title": "\nA Proximal Bregman Projection Approach to Continuous Max-Flow Problems  Using Entropic Distances", "abstract": "One issue limiting the adaption of large-scale multi-region segmentation is the sometimes prohibitive memory requirements. This is especially troubling considering advances in massively parallel computing and commercial graphics processing units because of their already limited memory compared to the current random access memory used in more traditional computation. To address this issue in the field of continuous max-flow segmentation, we have developed a textit framework using the theory of Bregman proximal projections and entropic distances which implicitly represents flow variables between labels and designated source and sink nodes. This reduces the memory requirements for max-flow segmentation by approximately 20 % for Potts models and approximately 30 % for hierarchical max-flow (HMF) and directed acyclic graph max-flow (DAGMF) models. This represents a great improvement in the state-of-the-art in max-flow segmentation, allowing for much larger problems to be addressed and accelerated using commercially available graphics processing hardware.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "John S.H. Baxter, Martin Rajchl, Jing Yuan, Terry M. Peters,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07814", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07814", "title": "\nValued Workflow Satisfiability Problem", "abstract": "A workflow is a collection of steps that must be executed in some specific order to achieve an objective. A computerised workflow management system may enforce authorisation policies and constraints, thereby restricting which users can perform particular steps in a workflow. The existence of policies and constraints may mean that a workflow is unsatisfiable, in the sense that it is impossible to find an authorised user for each step in the workflow and satisfy all constraints. In this paper, we consider the problem of finding the \"least bad\" assignment of users to workflow steps by assigning a weight to each policy and constraint violation. To this end, we introduce a framework for associating costs with the violation of workflow policies and constraints and define the emph (Valued WSP), whose solution is an assignment of steps to users of minimum cost. We establish the computational complexity of Valued WSP with user-independent constraints and show that it is fixed-parameter tractable. We then describe an algorithm for solving Valued WSP with user-independent constraints and evaluate its performance, comparing it to that of an off-the-shelf mixed integer programming package.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Jason Crampton, Gregory Z. Gutin, Daniel Karapetyan,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07774", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07774", "title": "\nNear Optimal Subdivision Algorithms for Real Root Isolation", "abstract": "We describe a subroutine that improves the running time of any subdivision algorithm for real root isolation. The subroutine first detects clusters of roots using a result of Ostrowski, and then uses Newton iteration to converge to them. Near a cluster, we switch to subdivision, and proceed recursively. The subroutine has the advantage that it is independent of the predicates used to terminate the subdivision. This gives us an alternative and simpler approach to recent developments of Sagraloff (2012) and Sagraloff-Mehlhorn (2013), assuming exact arithmetic. The subdivision tree size of our algorithm using predicates based on Descartes's rule of signs is bounded by , which is better by compared to known results. Our analysis differs in two key aspects. First, we use the general technique of continuous amortization from Burr-Krahmer-Yap (2009), and second, we use the geometry of clusters of roots instead of the Davenport-Mahler bound. The analysis naturally extends to other predicates.", "subjects": "Numerical Analysis (cs.NA)", "authors": "Vikram Sharma, Prashant Batra,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07740", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07740", "title": "\nAdaptive Compute-and-Forward with Lattice Codes Over Algebraic Integers", "abstract": "We consider the compute-and-forward relay network with limited feedback. A novel scheme called adaptive compute-and-forward is proposed to exploit the channel knowledge by working with the best ring of imaginary quadratic integers. This is enabled by generalizing Construction A lattices to other rings of imaginary quadratic integers which may not form principal ideal domains and by showing such construction can produce good lattices for coding in the sense of Poltyrev and for MSE quantization. Since there are channel coefficients (complex numbers) which are closer to elements of rings of imaginary quadratic integers other than Gaussian and Eisenstein integers, by always working with the best ring among them, one expects to obtain a better performance than that provided by working over Gaussian or Eisenstein integers.", "subjects": "Information Theory (cs.IT)", "authors": "Yu-Chih Huang, Krishna R. Narayanan, Ping-Chung Wang,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07738", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07738", "title": "\nCo-Regularized Deep Representations for Video Summarization", "abstract": "Compact keyframe-based video summaries are a popular way of generating viewership on video sharing platforms. Yet, creating relevant and compelling summaries for arbitrarily long videos with a small number of keyframes is a challenging task. We propose a comprehensive keyframe-based summarization framework combining deep convolutional neural networks and restricted Boltzmann machines. An original co-regularization scheme is used to discover meaningful subject-scene associations. The resulting multimodal representations are then used to select highly-relevant keyframes. A comprehensive user study is conducted comparing our proposed method to a variety of schemes, including the summarization currently in use by one of the most popular video sharing websites. The results show that our method consistently outperforms the baseline schemes for any given amount of keyframes both in terms of attractiveness and informativeness. The lead is even more significant for smaller summaries.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Olivier Mor\u00e8re, Hanlin Goh, Antoine Veillard, Vijay Chandrasekhar, Jie Lin,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07725", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07725", "title": "\nOn the switch Markov chain for perfect matchings", "abstract": "We study a simple Markov chain, the switch chain, on the set of all perfect matchings in a bipartite graph. This Markov chain was proposed by Diaconis, Graham and Holmes as a possible approach to a sampling problem arising in Statistics. We ask: for which classes of graphs is the Markov chain ergodic and for which is it rapidly mixing? We provide a precise answer to the ergodicity question and close bounds on the mixing question. We show for the first time that the mixing time of the switch chain is polynomial in the case of monotone graphs, a class that includes examples of interest in the statistical setting.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Martin Dyer, Mark Jerrum, Haiko M\u00fcller,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07723", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07723", "title": "\nA hybrid TIM-NOMA scheme for the SISO Broadcast Channel", "abstract": "Future mobile communication networks will require enhanced network efficiency and reduced system overhead due to their user density and high data rate demanding applications of the mobile devices. Research on Blind Interference Alignment (BIA) and Topological Interference Management (TIM) has shown that optimal Degrees of Freedom (DoF) can be achieved, in the absence of Channel State Information (CSI) at the transmitters, reducing the network's overhead. Moreover, the recently emerged Non-Orthogonal Multiple Access (NOMA) scheme suggests a different multiple access approach, compared to the current orthogonal methods employed in 4G networks, resulting in high capacity gains. Our contribution is a hybrid TIM-NOMA scheme in Single-Input-Single-Output (SISO) K-user cells, in which users are divided into T groups, and 1/T DoF is achieved for each user. By superimposing users in the power domain, we introduce a two-stage decoding process, managing 'inter-group' interference based on the TIM principles, and 'intra-group' interference based on Successful Interference Cancellation (SIC), as proposed by NOMA. We show that for high SNR values the hybrid scheme can improve the sum rate by at least 100% when compared to Time Division Multiple Access (TDMA).", "subjects": "Information Theory (cs.IT)", "authors": "Vaia Kalokidou, Oliver Johnson, Robert Piechocki,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07716", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07716", "title": "\nAttention Please! A Hybrid Resource Recommender Mimicking  Attention-Interpretation Dynamics", "abstract": "Classic resource recommenders like Collaborative Filtering (CF) treat users as being just another entity, neglecting non-linear user-resource dynamics shaping attention and interpretation. In this paper, we propose a novel hybrid recommendation strategy that refines CF by capturing these dynamics. The evaluation results reveal that our approach substantially improves CF and, depending on the dataset, successfully competes with a computationally much more expensive Matrix Factorization variant.", "subjects": "Information Retrieval (cs.IR)", "authors": "Paul Seitlinger, Dominik Kowald, Simone Kopeinik, Ilire Hasani-Mavriqi, Tobias Ley, Elisabeth Lex,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07704", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07704", "title": "\nComplete Decentralized Method for On-Line Multi-Robot Trajectory  Planning in Valid Infrastructures", "abstract": "We consider a system consisting of multiple mobile robots in which the user can at any time issue relocation tasks ordering one of the robots to move from its current location to a given destination location. In this paper, we deal with the problem of finding a trajectory for each such relocation task that avoids collisions with other robots. The chosen robot plans its trajectory so as to avoid collision with other robots executing tasks that were issued earlier. We prove that if all possible destinations of the relocation tasks satisfy so-called valid infrastructure property, then this mechanism is guaranteed to always succeed and provide a trajectory for the robot that reaches the destination without colliding with any other robot. The time-complexity of the approach on a fixed space-time discretization is only quadratic in the number of robots. We demonstrate the applicability of the presented method on several real-world maps and compare its performance against a popular reactive approach that attempts to solve the collisions locally. Besides being dead-lock free, the presented approach generates trajectories that are significantly faster (up to 48% improvement) than the trajectories resulting from local collision avoidance.", "subjects": "Robotics (cs.RO)", "authors": "Michal \u010c\u00e1p, Ji\u0159\u00ed Vok\u0159\u00ednek, Alexander Kleiner,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07701", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07701", "title": "\nReliable Initialization of GPU-enabled Parallel Stochastic Simulations  Using Mersenne Twister for Graphics Processors", "abstract": "Parallel stochastic simulations tend to exploit more and more computing power and they are now also developed for General Purpose Graphics Process Units (GP-GPUs). Conse-quently, they need reliable random sources to feed their applications. We propose a survey of the current Pseudo Random Numbers Generators (PRNG) available on GPU. We give a particular focus to the recent Mersenne Twister for Graphics Processors (MTGP) that has just been released. Our work provides empirically checked statuses designed to initialize a particular configuration of this generator, in order to prevent any potential bias introduced by the parallelization of the PRNG.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Jonathan Passerat-Palmbach, Claude Mazel, Antoine Mahul, David Hill,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07695", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07695", "title": "\nLive Group Detection for Mobile Wireless Sensor Networks", "abstract": "This paper deals with distributed algorithms for monitoring the topology of a dynamic group of mobile wireless sensor networks. We propose two major extensions of a distributed static group consensus algorithm and an experimental implementation. Group consensus algorithms are exploited to let each node obtain the knowledge of its connected com-ponents. The proposed extensions provide a more accurate information about the proximity of nodes and allow to deal with dynamic networks using a periodical reevaluation of the group detection. We validate these algorithms by implementing them in an original and challenging application scenario, in the context of a real bicycle race. The real traces thus obtained and analyzed show the effectiveness of our live group detection implementation.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Matthieu Lauzier, Tanguy Risset, Antoine Fraboulet, Jean-Marie Gorce,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07692", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07692", "title": "\nBlob indentation identification via curvature measurement", "abstract": "This paper presents a novel method for identifying indentations on the boundary of solid 2D shape. It uses the signed curvature at a set of points along the boundary to identify indentations and provides one parameter for tuning the selection mechanism for discriminating indentations from other boundary irregularities. An efficient implementation is described based on the Fourier transform for calculating curvature from a sequence of points obtained from the boundary of a binary blob.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Matthew Sottile,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07687", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07687", "title": "\nOptimistic-Conservative Bidding in Sequential Auctions", "abstract": "In this work we consider selling items using a sequential first price auction mechanism. We generalize the assumption of conservative bidding to extensive form games (henceforth optimistic conservative bidding), and show that for both linear and unit demand valuations, the only pure subgame perfect equilibrium where buyers are bidding in an optimistic conservative manner is the minimal Walrasian equilibrium. In addition, we show examples where without the requirement of conservative bidding, subgame perfect equilibria can admit a variety of unlikely predictions, including high price of anarchy and low revenue in markets composed of additive bidders, equilibria which elicit all the surplus as revenue, and more. We also show that the order in which the items are sold can influence the outcome.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Avinatan Hassidim, Yishay Mansour,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07686", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07686", "title": "\nConstruction of rational expression from tree automata using a  generalization of Arden's Lemma", "abstract": "Arden's Lemma is a classical result in language theory allowing the computation of a rational expression denoting the language recognized by a finite string automaton. In this paper we generalize this important lemma to the rational tree languages. Moreover, we propose also a construction of a rational tree expression which denotes the accepted tree language of a finite tree automaton.", "subjects": "Formal Languages and Automata Theory (cs.FL)", "authors": "Younes Guellouma, Ludovic Mignot, Hadda Cherroun, Djelloul Ziadi,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07683", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07683", "title": "\nDownscaling Microwave Brightness Temperatures Using Self Regularized  Regressive Models", "abstract": "A novel algorithm is proposed to downscale microwave brightness temperatures (), at scales of 10-40 km such as those from the Soil Moisture Active Passive mission to a resolution meaningful for hydrological and agricultural applications. This algorithm, called Self-Regularized Regressive Models (SRRM), uses auxiliary variables correlated to along-with a limited set of textit SM observations, which are converted to high resolution observations using biophysical models. It includes an information-theoretic clustering step based on all auxiliary variables to identify areas of similarity, followed by a kernel regression step that produces downscaled . This was implemented on a multi-scale synthetic data-set over NC-Florida for one year. An RMSE of 5.76~K with standard deviation of 2.8~k was achieved during the vegetated season and an RMSE of 1.2~K with a standard deviation of 0.9~K during periods of no vegetation.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Subit Chakrabarti, Jasmeet Judge, Anand Rangarajan, Sanjay Ranka,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07681", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07681", "title": "\nVector Quantization by Minimizing Kullback-Leibler Divergence", "abstract": "This paper proposes a new method for vector quantization by minimizing the Kullback-Leibler Divergence between the class label distributions over the quantization inputs, which are original vectors, and the output, which is the quantization subsets of the vector set. In this way, the vector quantization output can keep as much information of the class label as possible. An objective function is constructed and we also developed an iterative algorithm to minimize it. The new method is evaluated on bag-of-features based image classification problem.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Lan Yang, Jingbin Wang, Yujin Tu, Prarthana Mahapatra, Nelson Cardoso,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07680", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07680", "title": "\nDisaggregation of Remotely Sensed Soil Moisture in Heterogeneous  Landscapes using Holistic Structure based Models", "abstract": "In this study, a novel machine learning algorithm is proposed to disaggregate coarse-scale remotely sensed observations to finer scales, using correlated auxiliary data at the fine scale. It includes a regularized Cauchy-Schwarz distance based clustering step that assigns soft memberships to each pixel at the fine-scale followed by a kernel regression that computes the value of the desired variable at all the pixels. This algorithm, based on self-regularized regressive models (SRRM), is implemented to disaggregate soil moisture (SM) from 10km to 1km using land cover, precipitation, land surface temperature, leaf area index and some point observations of SM. This was tested using multi-scale synthetic observations in NC Florida for heterogeneous agricultural land covers, with two growing seasons of sweet corn and one of cotton, annually. It was found that the root mean square error (RMSE) for 96 % of the pixels was less than 0.02 . The Kullback Leibler divergence (KLD) between the true SM and the disaggregated estimates was close to 0, for both vegetated and baresoil land covers. The disaggregated estimates are compared to those generated by the Principle of Relevant Information (PRI) method. The RMSE for the PRI disaggregated estimates are higher than the RMSE for the SRRM methods on each day of the season. The KLD of the disaggregated estimates generated by the SRRM method estimates is at least 3 orders of magnitude lesser than for the PRI disaggregated estimates.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Subit Chakrabarti, Jasmeet Judge, Anand Rangarajan, Sanjay Ranka,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07676", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07676", "title": "\nTowards Resolving Software Quality-in-Use Measurement Challenges", "abstract": "Software quality-in-use comprehends the quality from user's perspectives. It has gained its importance in e-learning applications, mobile service based applications and project management tools. User's decisions on software acquisitions are often ad hoc or based on preference due to difficulty in quantitatively measure software quality-in-use. However, why quality-in-use measurement is difficult? Although there are many software quality models to our knowledge, no works surveys the challenges related to software quality-in-use measurement. This paper has two main contributions; 1) presents major issues and challenges in measuring software quality-in-use in the context of the ISO SQuaRE series and related software quality models, 2) Presents a novel framework that can be used to predict software quality-in-use, and 3) presents preliminary results of quality-in-use topic prediction. Concisely, the issues are related to the complexity of the current standard models and the limitations and incompleteness of the customized software quality models. The proposed framework employs sentiment analysis techniques to predict software quality-in-use.", "subjects": "Software Engineering (cs.SE)", "authors": "Issa Atoum, Chih How Bong, Narayanan Kulathuramaiyer,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07671", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07671", "title": "\nPrioritizing the Components of Vulnerability in a Genetic Algorithms  Minimization of Flood Risk", "abstract": "We compare two prioritization schemes for the components of flooding vulnerability: urbanized area ration, literacy rate, mortality rate, poverty, radio/tv penetration, non-structural measures and structural measure. We prioritize the components, giving each a weight. We then express the vulnerability function as a weighted sum of its components. This weighted sum serves as the fitness function in a genetic algorithm, which comes up with the optimal design for a flood-resistant city.", "subjects": "Computational Engineering, Finance, and Science (cs.CE)", "authors": "Vena Pearl Bo\u00f1golan, Karessa Alexandra O. Baritua, Marie Junne Santos,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07662", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07662", "title": "\nSuper-Resolution in Phase Space", "abstract": "This work considers the problem of super-resolution. The goal is to resolve a Dirac distribution from knowledge of its discrete, low-pass, Fourier measurements. Classically, such problems have been dealt with parameter estimation methods. Recently, it has been shown that convex-optimization based formulations facilitate a continuous time solution to the super-resolution problem. Here we treat super-resolution from low-pass measurements in Phase Space. The Phase Space transformation parametrically generalizes a number of well known unitary mappings such as the Fractional Fourier, Fresnel, Laplace and Fourier transforms. Consequently, our work provides a general super- resolution strategy which is backward compatible with the usual Fourier domain result. We consider low-pass measurements of Dirac distributions in Phase Space and show that the super-resolution problem can be cast as Total Variation minimization. Remarkably, even though are setting is quite general, the bounds on the minimum separation distance of Dirac distributions is comparable to existing methods.", "subjects": "Information Theory (cs.IT)", "authors": "Ayush Bhandari, Yonina Eldar, Ramesh Raskar,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07658", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07658", "title": "\nRobust Transceiver Design for MISO Interference Channel with Energy  Harvesting", "abstract": "In this study, we consider the power splitting technique for multiuser multiple-input single-output (MISO) channel where the received signal is divided into two parts for information decoding and energy harvesting (EH) respectively. The transmit beamforming and receive power splitting ratios are jointly designed in order to minimize the total transmission power subject to both signal-to-interference-plus-noise ratio (SINR) and EH constraints. Most joint beamforming and power splitting (JBPS) designs assume that perfect channel state information (CSI) is available; however CSI errors are inevitable in practice. Assuming norm-bounded CSI errors (NBE), this paper studies the robust JBPS design problem. We first propose an efficient approximation method for solving the highly non-convex problem based on semidefinite relaxation (SDR), where the JBPS problem can be formulated as a semidefinite programming (SDP) problem. A rank-one recovery method is provided to recover a robust feasible solution to the original problem. Then, a novel method for the purpose of complexity reduction is proposed, where we formulate the robust JBPS problem as a second-order cone programming (SOCP) problem with SCOP relaxation and Cauchy-Schwarz inequality. Since the solution to the relaxed problem is not necessarily robust, a closed-form robust solution recovery method is provided. Moreover, a new iterative method is provided which can achieve near-bound performance when SDR-based algorithm results in an higher-rank solution. Finally, simulation results are presented to validate the robustness and efficiency of the proposed algorithms.", "subjects": "Information Theory (cs.IT)", "authors": "Ming-Min Zhao, Yunlong Cai, Qingjiang Shi, Benoit Champagne, Min-Jian Zhao,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07648", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07648", "title": "\nImproved Adaptive Sparse Channel Estimation Using Re-Weighted L1-norm  Normalized Least Mean Fourth Algorithm", "abstract": "In next-generation wireless communications systems, accurate sparse channel estimation (SCE) is required for coherent detection. This paper studies SCE in terms of adaptive filtering theory, which is often termed as adaptive channel estimation (ACE). Theoretically, estimation accuracy could be improved by either exploiting sparsity or adopting suitable error criterion. It motivates us to develop effective adaptive sparse channel estimation (ASCE) methods to improve estimation performance. In our previous research, two ASCE methods have been proposed by combining forth-order error criterion based normalized least mean fourth (NLMF) and L1-norm penalized functions, i.e., zero-attracting NLMF (ZA-NLMF) algorithm and reweighted ZA-NLMF (RZA-NLMF) algorithm. Motivated by compressive sensing theory, an improved ASCE method is proposed by using reweighted L1-norm NLMF (RL1-NLMF) algorithm where RL1 can exploit more sparsity information than ZA and RZA. Specifically, we construct the cost function of RL1-NLMF and hereafter derive its update equation. In addition, intuitive figure is also given to verify that RL1 is more efficient than conventional two sparsity constraints. Finally, simulation results are provided to confirm this study.", "subjects": "Information Theory (cs.IT)", "authors": "Chen Ye, Guan Gui, Li Xu, Nobuhiro Shimoi,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07645", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07645", "title": "\nHyper-parameter optimization of Deep Convolutional Networks for object  recognition", "abstract": "Recently sequential model based optimization (SMBO) has emerged as a promising hyper-parameter optimization strategy in machine learning. In this work, we investigate SMBO to identify architecture hyper-parameters of deep convolution networks (DCNs) object recognition. We propose a simple SMBO strategy that starts from a set of random initial DCN architectures to generate new architectures, which on training perform well on a given dataset. Using the proposed SMBO strategy we are able to identify a number of DCN architectures that produce results that are comparable to state-of-the-art results on object recognition benchmarks. Specifically, we report three DCN networks generated by our proposed algorithm that produce &lt;9% test error rate, with the best network exhibiting a test error rate of 7.81% on the CIFAR-10 benchmark. Our results compare favorably to the current state-of-the-art of 7.97 % test error rate for CIFAR-10 that are obtained by hand tuning.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Sachin S. Talathi,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07640", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07640", "title": "\nJoint source-channel coding with feedback (extended)", "abstract": "This paper quantifies the fundamental limits of variable-length transmission of a general (possibly analog) source over a memoryless channel with noiseless feedback, under a distortion constraint. We consider excess distortion, average distortion and guaranteed distortion (d-semifaithful codes). In contrast to the asymptotic fundamental limit, a general conclusion is that allowing variable-length codes and feedback leads to a sizable improvement in the fundamental delay-distortion tradeoff. In addition, we investigate the minimum energy required to reproduce k source samples with a given fidelity after transmission over a memoryless Gaussian channel, and we show that the required minimum energy is reduced with feedback and an average (rather than maximal) power constraint.", "subjects": "Information Theory (cs.IT)", "authors": "Victoria Kostina, Yury Polyanskiy, Sergio Verd\u00fa,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07637", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07637", "title": "\nSimple Mechanisms for a Combinatorial Buyer and Applications to Revenue  Monotonicity", "abstract": "We study the revenue maximization problem of a seller with n heterogeneous items for sale to a single buyer whose valuation function for sets of items is unknown and drawn from some distribution D. We show that if D is a distribution over subadditive valuations with independent items, then the better of pricing each item separately or pricing only the grand bundle achieves a constant-factor approximation to the revenue of the optimal mechanism. This includes buyers who are k-demand, additive up to a matroid constraint, or additive up to constraints of any downwards-closed set system (and whose values for the individual items are sampled independently), as well as buyers who are fractionally subadditive with item multipliers drawn independently. Our proof makes use of the core-tail decomposition framework developed in prior work showing similar results for the significantly simpler class of additive buyers [LY13, BILW14]. In the second part of the paper, we develop a connection between approximately optimal simple mechanisms and approximate revenue monotonicity with respect to buyers' valuations. Revenue non-monotonicity is the phenomenon that sometimes strictly increasing buyers' values for every set can strictly decrease the revenue of the optimal mechanism [HR12]. Using our main result, we derive a bound on how bad this degradation can be (and dub such a bound a proof of approximate revenue monotonicity); we further show that better bounds on approximate monotonicity imply a better analysis of our simple mechanisms.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Aviad Rubinstein, S. Matthew Weinberg,", "date": "2015-1-30"}, 
{"urllink": "http://arxiv.org/abs/1501.07627", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07627", "title": "\nRepresenting Objects, Relations, and Sequences", "abstract": "Vector Symbolic Architectures (VSAs) are high-dimensional vector representations of objects (eg., words, image parts), relations (eg., sentence structures), and sequences for use with machine learning algorithms. They consist of a vector addition operator for representing a collection of unordered objects, a Binding operator for associating groups of objects, and a methodology for encoding complex structures. We first develop Constraints that machine learning imposes upon VSAs: for example, similar structures must be represented by similar vectors. The constraints suggest that current VSAs should represent phrases (\"The smart Brazilian girl\") by binding sums of terms, in addition to simply binding the terms directly. We show that matrix multiplication can be used as the binding operator for a VSA, and that matrix elements can be chosen at random. A consequence for living systems is that binding is mathematically possible without the need to specify, in advance, precise neuron-to-neuron connection properties for large numbers of synapses. A VSA that incorporates these ideas, MBAT (Matrix Binding of Additive Terms), is described that satisfies all Constraints. With respect to machine learning, for some types of problems appropriate VSA representations permit us to prove learnability, rather than relying on simulations. We also propose dividing machine (and neural) learning and representation into three Stages, with differing roles for learning in each stage. For neural modeling, we give \"representational reasons\" for nervous systems to have many recurrent connections, as well as for the importance of phrases in language processing. Sizing simulations and analyses suggest that VSAs in general, and MBAT in particular, are ready for real-world applications.", "subjects": "Learning (cs.LG)", "authors": "Stephen I. Gallant, T. Wendy Okaywe,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07621", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07621", "title": "\nEcological metrics of diversity in understanding social media", "abstract": "Topical discussion networks (TDNs) are networks centered around a discourse concerning a particular concept, whether in real life or online. This paper analogises the population of such networks to populations encountered in mathematical ecology, and seeks to evaluate whether three metrics of diversity used in ecology - Shannon's , Simpson's and proposed by Smith and Wilson - give valuable information about the composition and diversity of TDNs. It concludes that each metric has its particular use, and the choice of metric is best understood in the context of the particular research question.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Chris von Csefalvay,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07594", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07594", "title": "\nAnalytical Model for IEEE 802.15.4 Multi-Hop Networks with Improved  Handling of Acknowledgements and Retransmissions", "abstract": "The IEEE 802.15.4 standard allows for the deployment of cost-effective and energy-efficient multi-hop networks. This document features an in-depth presentation of an analytical model for assessing the performance of such networks. It considers a generic, static topology with Poisson distributed data-collection as well as data-dissemination traffic. The unslotted CSMA/CA MAC layer of IEEE 802.15.4 is closely modeled as well as an enhanced model of the neighborhood allows for consideration of collisions of packets including interferences with acknowledgements. The hidden node problem is taken into account as well as a formerly disregarded effect of repeated collisions of retransmissions. The model has been shown to be suitable to estimate the capacity of large-scale multi-hop networks.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Florian Meier, Volker Turau,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07586", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07586", "title": "\nFAIR: Forwarding Accountability for Internet Reputability", "abstract": "This paper presents FAIR, a forwarding accountability mechanism that incentivizes ISPs to apply stricter security policies to their customers. The Autonomous System (AS) of the receiver specifies a traffic profile that the sender AS must adhere to. Intermediate ASes on the path mark packets. In case of traffic profile violations, the marked packets are used as proof of misbehavior. FAIR introduces minimal bandwidth overhead and requires no per-packet and no per-flow state for forwarding. We describe integration with IPv4/IPv6 and demonstrate a software switch running on commodity hardware that can switch packets at a line rate of 120 Gbps, and can forward 140M minimum-sized packets per second, limited by the hardware I/O subsystem. Furthermore, FAIR is incrementally deployable and provides incentives for adoption to edge ASes and ISPs. Moreover, this paper proposes a \"suspicious bit\" for packet headers - an application that builds on top of FAIR's proofs of misbehavior and flags packets to warn other entities in the network.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Christos Pappas, Raphael M. Reischuk, Adrian Perrig,", "date": "2015-1-9"}, 
{"urllink": "http://arxiv.org/abs/1501.07584", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07584", "title": "\nEfficient Divide-And-Conquer Classification Based on Feature-Space  Decomposition", "abstract": "This study presents a divide-and-conquer (DC) approach based on feature space decomposition for classification. When large-scale datasets are present, typical approaches usually employed truncated kernel methods on the feature space or DC approaches on the sample space. However, this did not guarantee separability between classes, owing to overfitting. To overcome such problems, this work proposes a novel DC approach on feature spaces consisting of three steps. Firstly, we divide the feature space into several subspaces using the decomposition method proposed in this paper. Subsequently, these feature subspaces are sent into individual local classifiers for training. Finally, the outcomes of local classifiers are fused together to generate the final classification results. Experiments on large-scale datasets are carried out for performance evaluation. The results show that the error rates of the proposed DC method decreased comparing with the state-of-the-art fast SVM solvers, e.g., reducing error rates by 10.53% and 7.53% on RCV1 and covtype datasets respectively.", "subjects": "Learning (cs.LG)", "authors": "Qi Guo, Bo-Wei Chen, Feng Jiang, Xiangyang Ji, Sun-Yuan Kung,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07556", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07556", "title": "\nCoding with Constraints: Minimum Distance Bounds and Systematic  Constructions", "abstract": "We examine an error-correcting coding framework in which each coded symbol is constrained to be a function of a fixed subset of the message symbols. With an eye toward distributed storage applications, we seek to design systematic codes with good minimum distance that can be decoded efficiently. On this note, we provide theoretical bounds on the minimum distance of such a code based on the coded symbol constraints. We refine these bounds in the case where we demand a systematic linear code. Finally, we provide conditions under which each of these bounds can be achieved by choosing our code to be a subcode of a Reed-Solomon code, allowing for efficient decoding. This problem has been considered in multisource multicast network error correction. The problem setup is also reminiscent of locally repairable codes.", "subjects": "Information Theory (cs.IT)", "authors": "Wael Halbawi, Matthew Thill, Babak Hassibi,", "date": "2015-1-9"}, 
{"urllink": "http://arxiv.org/abs/1501.07547", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07547", "title": "\nIndividual secrecy for broadcast channels with receiver side information", "abstract": "This paper studies the problem of secure communication over the broadcast channel with receiver side information under the lens of individual secrecy constraints. That is, the transmitter wants to send two independent messages to two receivers which have, respectively, the desired message of the other receiver as side information, while keeping the eavesdropper ignorant of each message (i.e., the information leakage from each message to the eavesdropper is made vanishing). Building upon one-time pad, secrecy coding, and broadcasting schemes, achievable rate regions are investigated, and the capacity region for special cases of either a weak or strong eavesdropper (compared to both legitimate receivers) are characterized. Interestingly, the capacity region for the former corresponds to a line and the latter corresponds to a square with missing corners; a phenomenon occurring due to the coupling between user's rates. Moreover, the individual secrecy capacity region is also fully characterized for the case where the eavesdropper's channel is deterministic. In addition to discrete memoryless setup, Gaussian scenarios are studied. For the Gaussian model, in addition to the strong and weak eavesdropper cases, the capacity region is characterized for the low and high SNR regimes when the eavesdropper's channel is stronger than one receiver but weaker than the other. Remarkably, positive secure transmission rates are always guaranteed under the individual secrecy constraint, unlike the case of the joint secrecy constraint (i.e., the information leakage from both messages to the eavesdropper is made vanishing). Thus, this notion of secrecy serves as an appropriate candidate for trading off secrecy level and transmission rate; making secrecy more affordable but still acceptable to the end user.", "subjects": "Information Theory (cs.IT)", "authors": "Yanling Chen, O. Ozan Koyluoglu, Aydin Sezgin,", "date": "2015-1-9"}, 
{"urllink": "http://arxiv.org/abs/1501.07544", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07544", "title": "\nWhen Does an Ensemble of Matrices with Randomly Scaled Rows Lose Rank?", "abstract": "We consider the problem of determining rank loss conditions for a concatenation of full-rank matrices, such that each row of the composing matrices is scaled by a random coefficient. This problem has applications in wireless interference management and recommendation systems. We determine necessary and sufficient conditions for the design of each matrix, such that the random ensemble will almost surely lose rank by a certain amount. The result is proved by converting the problem to determining rank loss conditions for the union of some specific matroids, and then using tools from matroid and graph theories to derive the necessary and sufficient conditions. As an application, we discuss how this result can be applied to the problem of topological interference management, and characterize the linear symmetric degrees of freedom for a class of network topologies.", "subjects": "Information Theory (cs.IT)", "authors": "Aly El Gamal, Navid Naderializadeh, A. Salman Avestimehr,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07539", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07539", "title": "\nCounting Homomorphisms to Square-Free Graphs, Modulo 2", "abstract": "We study the problem HomsTo of counting, modulo 2, the homomorphisms from an input graph to a fixed undirected graph . A characteristic feature of modular counting is that cancellations make wider classes of instances tractable than is the case for exact (non-modular) counting, so subtle dichotomy theorems can arise. We show the following dichotomy: for any that contains no 4-cycles, HomsTo is either in polynomial time or is -complete. This confirms a conjecture of Faben and Jerrum that was previously only known to hold for trees and for a restricted class of treewidth-2 graphs called cactus graphs. We confirm the conjecture for a rich class of graphs including graphs of unbounded treewidth. In particular, we focus on square-free graphs, which are graphs without 4-cycles. These graphs arise frequently in combinatorics, for example in connection with the strong perfect graph theorem and in certain graph algorithms. Previous dichotomy theorems required the graph to be tree-like so that tree-like decompositions could be exploited in the proof. We prove the conjecture for a much richer class of graphs by adopting a much more general approach.", "subjects": "Computational Complexity (cs.CC)", "authors": "Andreas G\u00f6bel, Leslie Ann Goldberg, David Richerby,", "date": "2015-1-9"}, 
{"urllink": "http://arxiv.org/abs/1501.07510", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07510", "title": "\nThroughput of a Cognitive Radio Network under Congestion Constraints: A  Network-Level Study", "abstract": "In this paper we analyze a cognitive radio network with one primary and one secondary transmitter, in which the primary transmitter has bursty arrivals while the secondary node is assumed to be saturated (i.e. always has a packet waiting to be transmitted). The secondary node transmits in a cognitive way such that it does not impede the performance of the primary node. We assume that the receivers have multipacket reception (MPR) capabilities and that the secondary node can take advantage of the MPR capability by transmitting simultaneously with the primary under certain conditions. We obtain analytical expressions for the stationary distribution of the primary node queue and we also provide conditions for its stability. Finally, we provide expressions for the aggregate throughput of the network as well as for the throughput at the secondary node.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Nikolaos Pappas, Marios Kountouris,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07496", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07496", "title": "\nImplementation of an Automatic Syllabic Division Algorithm from Speech  Files in Portuguese Language", "abstract": "A new algorithm for voice automatic syllabic splitting in the Portuguese language is proposed, which is based on the envelope of the speech signal of the input audio file. A computational implementation in MatlabTM is presented and made available at the URL this http URL Due to its straightforwardness, the proposed method is very attractive for embedded systems (e.g. i-phones). It can also be used as a screen to assist more sophisticated methods. Voice excerpts containing more than one syllable and identified by the same envelope are named as super-syllables and they are subsequently separated. The results indicate which samples corresponds to the beginning and end of each detected syllable. Preliminary tests were performed to fifty words at an identification rate circa 70% (further improvements may be incorporated to treat particular phonemes). This algorithm is also useful in voice command systems, as a tool in the teaching of Portuguese language or even for patients with speech pathology.", "subjects": "Sound (cs.SD)", "authors": "E.L.F. Da Silva, H.M. de Oliveira,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07492", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07492", "title": "\nWeakly Supervised Learning for Salient Object Detection using Background  Images", "abstract": "Recent advances of supervised salient object detection models demonstrate significant performance on benchmark datasets. Training such models, however, requires expensive pixel-wise annotations of salient objects. Moreover, many existing salient object detection models assume that at least a salient object exists in the input image. Such an impractical assumption leads to less appealing saliency maps on the background images, which contain no salient objects at all. To avoid expensive strong saliency annotations, in this paper, we study weakly supervised learning approaches for salient object detection. In specific, given a set of background images and/or salient object images, where we only have annotations of salient object existence, we propose two approaches to train salient object detection models. In the first approach, we train a one-class SVM based on background superpixels. The further a superpixel is from the decision boundary of the one-class SVM, the more salient it is. The most interesting property of this approach is that we can effortlessly synthesize a set of background images to train the model. In the second approach, we present a solution toward jointly addressing salient object existence and detection tasks. We formulate salient object detection as an image labeling problem, where saliency labels of superpixels are modeled as hidden variables in the latent structural SVM framework. Experimental results on benchmark datasets validate the effectiveness of our proposed approaches.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Huaizu Jiang,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07467", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07467", "title": "\nRegression and Learning to Rank Aggregation for User Engagement  Evaluation", "abstract": "User engagement refers to the amount of interaction an instance (e.g., tweet, news, and forum post) achieves. Ranking the items in social media websites based on the amount of user participation in them, can be used in different applications, such as recommender systems. In this paper, we consider a tweet containing a rating for a movie as an instance and focus on ranking the instances of each user based on their engagement, i.e., the total number of retweets and favorites it will gain. For this task, we define several features which can be extracted from the meta-data of each tweet. The features are partitioned into three categories: user-based, movie-based, and tweet-based. We show that in order to obtain good results, features from all categories should be considered. We exploit regression and learning to rank methods to rank the tweets and propose to aggregate the results of regression and learning to rank methods to achieve better performance. We have run our experiments on an extended version of MovieTweeting dataset provided by ACM RecSys Challenge 2014. The results show that learning to rank approach outperforms most of the regression models and the combination can improve the performance significantly.", "subjects": "Information Retrieval (cs.IR)", "authors": "Hamed Zamani, Azadeh Shakery, Pooya Moradi,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07464", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07464", "title": "\nAbelian bordered factors and periodicity", "abstract": "A finite word u is said to be bordered if u has a proper prefix which is also a suffix of u, and unbordered otherwise. Ehrenfeucht and Silberger proved that an infinite word is purely periodic if and only if it contains only finitely many unbordered factors. We are interested in abelian and weak abelian analogues of this result; namely, we investigate the following question(s): Let w be an infinite word such that all sufficiently long factors are (weakly) abelian bordered; is w (weakly) abelian periodic? In the process we answer a question of Avgustinovich et al. concerning the abelian critical factorization theorem.", "subjects": "Formal Languages and Automata Theory (cs.FL)", "authors": "Emilie Charlier, Tero Harju, Svetlana Puzynina, Luca Zamboni,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07440", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07440", "title": "\nLimits on Support Recovery with Probabilistic Models: An  Information-Theoretic Framework", "abstract": "The support recovery problem consists of determining a sparse subset of a set of variables that is relevant in generating a set of observations, and arises in a diverse range of settings such as group testing, compressive sensing, and subset selection in regression. In this paper, we take a unified approach to support recovery problems, considering general probabilistic observation models relating a sparse data vector to an observation vector. We study the information-theoretic limits of both exact and partial support recovery, taking a novel approach motivated by thresholding techniques in channel coding. We provide general achievability and converse bounds characterizing the trade-off between the error probability and number of measurements, and we specialize these bounds to variants of models from group testing, linear regression, and 1-bit compressive sensing. In several cases, our bounds not only provide matching scaling laws in the necessary and sufficient number of measurements, but also sharp thresholds with matching constant factors. Our approach has several advantages over previous approaches: For the achievability part, we obtain sharp thresholds under broader scalings of the sparsity level and other parameters (e.g. signal-to-noise ratio) compared to several previous works, and for the converse part, we not only provide conditions under which the error probability fails to vanish, but also conditions under which it tends to one.", "subjects": "Information Theory (cs.IT)", "authors": "Jonathan Scarlett, Volkan Cevher,", "date": "2015-1-9"}, 
{"urllink": "http://arxiv.org/abs/1501.07439", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07439", "title": "\nThe Arbitrarily Varying Wiretap Channel - Secret Randomness, Stability  and Super-Activation", "abstract": "We define the common randomness assisted capacity of an arbitrarily varying channel (AVWC) when the Eavesdropper is kept ignorant about the common randomness. We prove a multi-letter capacity formula for this model. We prove that, if enough common randomness is used, the capacity formula can be given a single-shot form again. We then consider the opposite extremal case, where no common randomness is available. It is known that the capacity of the system can be discontinuous under these circumstances. We prove here that it is still stable in the sense that it is continuous around its positivity points. We further prove that discontinuities can only arise if the legal link is symmetrizable and characterize the points where it is positive. These results shed new light on the design principles of communication systems with embedded security features. At last we investigate the effect of super-activation of the message transmission capacity of AVWCs under the average error criterion. We give a complete characterization of those AVWCs that may be super-activated. The effect is thereby also related to the (conjectured) super-activation of the common randomness assisted capacity of AVWCs with an eavesdropper that gets to know the common randomness.", "subjects": "Information Theory (cs.IT)", "authors": "Janis Noetzel, Moritz Wiese, Holger Boche,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07438", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07438", "title": "\nContemporary Internet of Things platforms", "abstract": "This document regroups a representative, but non-exhaustive, list of contemporary IoT platforms. The platforms are ordered alphabetically. The aim of this document is to provide the a quick review of current IoT platforms, as well as relevant information.", "subjects": "Other Computer Science (cs.OH)", "authors": "Julien Mineraud, Oleksiy Mazhelis, Xiang Su, Sasu Tarkoma,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07431", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07431", "title": "\nNegacyclic codes of odd length over the ring $\\mathbb{F}_p[u,v]/\\langle  u^2,v^2,uv-vu\\rangle$", "abstract": "We discuss the structure of negacyclic codes of odd length over the ring . We find the unique generating set, the rank and the minimum distance for these negacyclic codes.", "subjects": "Information Theory (cs.IT)", "authors": "Bappaditya Ghosh,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07429", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07429", "title": "\nConvergence law for hyper-graphs with prescribed degree sequences", "abstract": "We view hyper-graphs as incidence graphs, i.e. bipartite graphs with a set of nodes representing vertices and a set of nodes representing hyper-edges, with two nodes being adjacent if the corresponding vertex belongs to the corresponding hyper-edge. It defines a random hyper-multigraph specified by two distributions, one for the degrees of the vertices, and one for the sizes of the hyper-edges. We develop the logical analysis of this framework and first prove a convergence law for first-order logic, then characterise the limit first-order theories defined by a wide class of degree distributions. Convergence laws of other models follow, and in particular for the classical Erd Hs-R 'enyi graphs and -uniform hyper-graphs.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Nans Lefebvre,", "date": "2015-1-9"}, 
{"urllink": "http://arxiv.org/abs/1501.07423", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07423", "title": "\nA Flexible Coupling Approach to Multi-Agent Planning under Incomplete  Information", "abstract": "Multi-agent planning (MAP) approaches are typically oriented at solving loosely-coupled problems, being ineffective to deal with more complex, strongly-related problems. In most cases, agents work under complete information, building complete knowledge bases. The present article introduces a general-purpose MAP framework designed to tackle problems of any coupling levels under incomplete information. Agents in our MAP model are partially unaware of the information managed by the rest of agents and share only the critical information that affects other agents, thus maintaining a distributed vision of the task.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Alejandro Torre\u00f1o, Eva Onaindia, \u00d3scar Sapena,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07422", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07422", "title": "\nPairwise Rotation Hashing for High-dimensional Features", "abstract": "Binary Hashing is widely used for effective approximate nearest neighbors search. Even though various binary hashing methods have been proposed, very few methods are feasible for extremely high-dimensional features often used in visual tasks today. We propose a novel highly sparse linear hashing method based on pairwise rotations. The encoding cost of the proposed algorithm is for n-dimensional features, whereas that of the existing state-of-the-art method is typically . The proposed method is also remarkably faster in the learning phase. Along with the efficiency, the retrieval accuracy is comparable to or slightly outperforming the state-of-the-art. Pairwise rotations used in our method are formulated from an analytical study of the trade-off relationship between quantization error and entropy of binary codes. Although these hashing criteria are widely used in previous researches, its analytical behavior is rarely studied. All building blocks of our algorithm are based on the analytical solution, and it thus provides a fairly simple and efficient procedure.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Kohta Ishikawa, Ikuro Sato, Mitsuru Ambai,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07420", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07420", "title": "\nTejas Simulator : Validation against Hardware", "abstract": "In this report we show results that validate the Tejas architectural simulator against native hardware. We report mean error rates of 11.45% and 18.77% for the SPEC2006 and Splash2 benchmark suites respectively. These error rates are competitive and in most cases better than the numbers reported by other contemporary simulators.", "subjects": "Hardware Architecture (cs.AR)", "authors": "Smruti R. Sarangi, Rajshekar Kalayappan, Prathmesh Kallurkar, Seep Goel,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07418", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07418", "title": "\nDistributionally Robust Counterpart in Markov Decision Processes", "abstract": "This paper studies Markov Decision Processes under parameter uncertainty. We adapt the distributionally robust optimization framework, and assume that the uncertain parameters are random variables following an unknown distribution, and seeks the strategy which maximizes the expected performance under the most adversarial distribution. In particular, we generalize previous study cite which concentrates on distribution sets with very special structure to much more generic class of distribution sets, and show that the optimal strategy can be obtained efficiently under mild technical condition. This significantly extends the applicability of distributionally robust MDP to incorporate probabilistic information of uncertainty in a more flexible way.", "subjects": "Systems and Control (cs.SY)", "authors": "Pengqian Yu, Huan Xu,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07400", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07400", "title": "\nResilience for Exascale Enabled Multigrid Methods", "abstract": "With the increasing number of components and further miniaturization the mean time between faults in supercomputers will decrease. System level fault tolerance techniques are expensive and cost energy, since they are often based on redundancy. Also classical check-point-restart techniques reach their limits when the time for storing the system state to backup memory becomes excessive. Therefore, algorithm-based fault tolerance mechanisms can become an attractive alternative. This article investigates the solution process for elliptic partial differential equations that are discretized by finite elements. Faults that occur in the parallel geometric multigrid solver are studied in various model scenarios. In a standard domain partitioning approach, the impact of a failure of a core or a node will affect one or several subdomains. Different strategies are developed to compensate the effect of such a failure algorithmically. The recovery is achieved by solving a local subproblem with Dirichlet boundary conditions using local multigrid cycling algorithms. Additionally, we propose a superman strategy where extra compute power is employed to minimize the time of the recovery process.", "subjects": "Computational Engineering, Finance, and Science (cs.CE)", "authors": "Markus Huber, Bj\u00f6rn Gmeiner, Ulrich R\u00fcde, Barbara Wohlmuth,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07399", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07399", "title": "\nParticle swarm optimization for time series motif discovery", "abstract": "Efficiently finding similar segments or motifs in time series data is a fundamental task that, due to the ubiquity of these data, is present in a wide range of domains and situations. Because of this, countless solutions have been devised but, to date, none of them seems to be fully satisfactory and flexible. In this article, we propose an innovative standpoint and present a solution coming from it: an anytime multimodal optimization algorithm for time series motif discovery based on particle swarms. By considering data from a variety of domains, we show that this solution is extremely competitive when compared to the state-of-the-art, obtaining comparable motifs in considerably less time using minimal memory. In addition, we show that it is robust to different implementation choices and see that it offers an unprecedented degree of flexibility with regard to the task. All these qualities make the presented solution stand out as one of the most prominent candidates for motif discovery in long time series streams. Besides, we believe the proposed standpoint can be exploited in further time series analysis and mining tasks, widening the scope of research and potentially yielding novel effective solutions.", "subjects": "Learning (cs.LG)", "authors": "Joan Serr\u00e0, Josep Lluis Arcos,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07388", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07388", "title": "\nCoordination Games on Graphs", "abstract": "We introduce natural strategic games on graphs, which capture the idea of coordination in a local setting. We show that these games have an exact potential and have strong equilibria when the graph is a pseudoforest. We also exhibit some other classes of graphs for which a strong equilibrium exists. However, in general strong equilibria do not need to exist. Further, we study the (strong) price of stability and anarchy. Finally, we consider the problems of computing strong equilibria and of determining whether a joint strategy is a strong equilibrium.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Krzysztof R. Apt, Mona Rahn, Guido Schaefer, Sunil Simon,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07379", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07379", "title": "\nHardness of Virtual Network Embedding with Replica Selection", "abstract": "Efficient embedding virtual clusters in physical network is a challenging problem. In this paper we consider a scenario where physical network has a structure of a balanced tree. This assumption is justified by many real- world implementations of datacenters. We consider an extension to virtual cluster embedding by introducing replication among data chunks. In many real-world applications, data is stored in distributed and redundant way. This assumption introduces additional hardness in deciding what replica to process. By reduction from classical NP-complete problem of Boolean Satisfia- bility, we show limits of optimality of embedding. Our result holds even in trees of edge height bounded by three. Also, we show that limiting repli- cation factor to two replicas per chunk type does not make the problem simpler.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Carlo Fuerst, Maciej Pacut, Stefan Schmid,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07365", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07365", "title": "\n7R Darboux Linkages by Factorization of Motion Polynomials", "abstract": "In this paper, we construct two types of 7R closed single loop linkages by combining different factorizations of a general (non-vertical) Darboux motion. These factorizations are obtained by extensions of a factorization algorithm for a generic rational motion. The first type of 7R linkages has several one-dimensional configuration components and one of them corresponds to the Darboux motion. The other type is a 7R linkage with two degrees of freedom and without one-dimensional component. The Darboux motion is a curve in an irreducible two dimensional configuration component.", "subjects": "Robotics (cs.RO)", "authors": "Zijia Li, Josef Schicho, Hans-Peter Schr\u00f6cker,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07362", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07362", "title": "\nA Cross-Layer Approach for Video Delivery over Wireless Video Sensor  Networks", "abstract": "In this paper, we propose a novel cross-layer ap-proach for video delivery over Wireless Video Sensor Networks (WVSN)s. We adopt an energy efficient and adaptive video compression scheme dedicated to the WVSNs, based on the H.264/AVC video compression standard. The encoder operates using two modes. In the first mode, the nodes capture the scene following a low frame rate. When an event is detected, the encoder switches to the second mode with a higher frame rate and outputs two different types of macroblocks, referring to the region of interest and the background respectively. Furthermore, we propose an Energy and Queue Buffer Size Aware MMSPEED-based protocol for reliably and energy efficiently routing both regions towards the destination. Simulations results prove that the proposed approach is energy efficient and delivers good quality video streams. In addition, the proposed routing protocol EQBSA-MMSPEED outperforms its predecessors, the QBSA-MMSPEED and the MMSPEED, providing 33% of lifetime extension and 3 dBs of video quality enhancement.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Othmane Alaoui-Fdili, Patrick CORLAY, Youssef Fakhri, Fran\u00e7ois-Xavier Coudoux, Driss Aboutajdine,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07359", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07359", "title": "\nLearning And-Or Models to Represent Context and Occlusion for Car  Detection and Viewpoint Estimation", "abstract": "This paper presents a method for learning And-Or models to represent context and occlusion for car detection and viewpoint estimation. The learned And-Or model represents car-to-car context and occlusion configurations at three levels: (i) spatially-aligned cars, (ii) single car under different occlusion configurations, and (iii) a small number of parts. The And-Or model embeds a grammar for representing large structural and appearance variations in a reconfigurable hierarchy. The learning process consists of two stages in a weakly supervised way (i.e., only bounding boxes of single cars are annotated). Firstly, the structure of the And-Or model is learned with three components: (a) mining multi-car contextual patterns based on layouts of annotated single car bounding boxes, (b) mining occlusion configurations between single cars, and (c) learning different combinations of part visibility based on car 3D CAD simulation. The And-Or model is organized in a directed and acyclic graph which can be inferred by Dynamic Programming. Secondly, the model parameters (for appearance, deformation and bias) are jointly trained using Weak-Label Structural SVM. In experiments, we test our model on four car detection datasets --- the KITTI dataset cite, the PASCAL VOC2007 car dataset~ cite, and two self-collected car datasets, namely the Street-Parking car dataset and the Parking-Lot car dataset, and three datasets for car viewpoint estimation --- the PASCAL VOC2006 car dataset~ cite, the 3D car dataset~ cite, and the PASCAL3D+ car dataset~ cite. Compared with state-of-the-art variants of deformable part-based models and other methods, our model achieves significant improvement consistently on the four detection datasets, and comparable performance on car viewpoint estimation.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Tianfu Wu, Bo Li, Song-Chun Zhu,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07350", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07350", "title": "\nPerformance Tuning of an Open-Source Parallel 3-D FFT Package OpenFFT", "abstract": "The fast Fourier transform (FFT) is a primitive kernel in numerous fields of science and engineering. OpenFFT is an open-source parallel package for 3-D FFTs, built on a communication-optimal domain decomposition method for achieving minimal volume of communication. In this paper, we analyze, model, and tune the performance of OpenFFT, paying a particular attention to tuning of communication that dominates the run time of large-scale calculations. We first analyze its performance on different machines for a thorough understanding of the behaviors of the package and machines. We then build a performance model of OpenFFT on the machines, dividing it into computation and communication with a modeling of network overhead. Based on the performance analysis, we develop six communication methods for performing communication with the aim of covering varied calculation scales on a wide variety of computational platforms. OpenFFT is therefore augmented with an auto-tuning of communication to select the best method in run time depending on their performance. Numerical results demonstrate that the optimized OpenFFT is able to deliver good performance in comparison with other state-of-the-art packages at different computational scales on a number of parallel machines. The performance model is also useful for performance predictions and understanding.", "subjects": "Mathematical Software (cs.MS)", "authors": "Truong Vinh Truong Duy, Taisuke Ozaki,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07348", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07348", "title": "\nFinding Connected Dense $k$-Subgraphs", "abstract": "Given a connected graph on vertices and a positive integer , a subgraph of on vertices is called a -subgraph in . We design combinatorial approximation algorithms for finding a connected -subgraph in such that its density is at least a factor of the density of the densest -subgraph in (which is not necessarily connected). These particularly provide the first non-trivial approximations for the densest connected -subgraph problem on general graphs.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Xujin Chen, Xiaodong Hu, Changjun Wang,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07340", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07340", "title": "\nSequential Probability Assignment with Binary Alphabets and Large  Classes of Experts", "abstract": "We analyze the problem of sequential probability assignment for binary outcomes with side information and logarithmic loss, where regret---or, redundancy---is measured with respect to a (possibly infinite) class of experts. We provide upper and lower bounds for minimax regret in terms of sequential complexities of the class. These complexities were recently shown to give matching (up to logarithmic factors) upper and lower bounds for sequential prediction with general convex Lipschitz loss functions (Rakhlin and Sridharan, 2015). To deal with unbounded gradients of the logarithmic loss, we present a new analysis that employs a sequential chaining technique with a Bernstein-type bound. The introduced complexities are intrinsic to the problem of sequential probability assignment, as illustrated by our lower bound. We also consider an example of a large class of experts parametrized by vectors in a high-dimensional Euclidean ball (or a Hilbert ball). The typical discretization approach fails, while our techniques give a non-trivial bound. For this problem we also present an algorithm based on regularization with a self-concordant barrier. This algorithm is of an independent interest, as it requires a bound on the function values rather than gradients.", "subjects": "Information Theory (cs.IT)", "authors": "Alexander Rakhlin, Karthik Sridharan,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07338", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07338", "title": "\nOn Vectorization of Deep Convolutional Neural Networks for Vision Tasks", "abstract": "We recently have witnessed many ground-breaking results in machine learning and computer vision, generated by using deep convolutional neural networks (CNN). While the success mainly stems from the large volume of training data and the deep network architectures, the vector processing hardware (e.g. GPU) undisputedly plays a vital role in modern CNN implementations to support massive computation. Though much attention was paid in the extent literature to understand the algorithmic side of deep CNN, little research was dedicated to the vectorization for scaling up CNNs. In this paper, we studied the vectorization process of key building blocks in deep CNNs, in order to better understand and facilitate parallel implementation. Key steps in training and testing deep CNNs are abstracted as matrix and vector operators, upon which parallelism can be easily achieved. We developed and compared six implementations with various degrees of vectorization with which we illustrated the impact of vectorization on the speed of model training and testing. Besides, a unified CNN framework for both high-level and low-level vision tasks is provided, along with a vectorized Matlab implementation with state-of-the-art speed performance.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Jimmy SJ. Ren, Li Xu,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07336", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07336", "title": "\nGeneralized Simplified Variable-Scaled Min Sum LDPC decoder for  irregular LDPC Codes", "abstract": "In this paper, we propose a novel low complexity scaling strategy of min-sum decoding algorithm for irregular LDPC codes. In the proposed method, we generalize our previously proposed simplified Variable Scaled Min-Sum (SVS-min-sum) by replacing the sub-optimal starting value and heuristic update for the scaling factor sequence by optimized values. Density evolution and Nelder-Mead optimization are used offline, prior to the decoding, to obtain the optimal starting point and per iteration updating step size for the scaling factor sequence of the proposed scaling strategy. The optimization of these parameters proves to be of noticeable positive impact on the decoding performance. We used different DVB-T2 LDPC codes in our simulation. Simulation results show the superior performance (in both WER and latency) of the proposed algorithm to other Min-Sum based algorithms. In addition to that, generalized SVS-min-sum algorithm has very close performance to LLR-SPA with much lower complexity.", "subjects": "Information Theory (cs.IT)", "authors": "Ahmed A. Emran, Maha Elsabrouty,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07328", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07328", "title": "\nOn the Convergence of Massive MIMO Systems", "abstract": "In this paper we examine convergence properties of massive MIMO systems with the aim of determining the number of antennas required for massive MIMO gains. We consider three characteristics of a channel matrix and study their asymptotic behaviour. Furthermore, we derive ZF SNR and MF SINR for a scenario of unequal receive powers. In our results we include the effects of spatial correlation. We show that the rate of convergence of channel metrics is much slower than that of the ZF/MF precoder properties.", "subjects": "Information Theory (cs.IT)", "authors": "Peter J. Smith, Callum T. Neil, Mansoor Shafi, Pawel A. Dmochowski,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07323", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07323", "title": "\nPerformance Analysis of Raptor Codes under Maximum-Likelihood (ML)  Decoding", "abstract": "Raptor codes have been widely used in many multimedia broadcast/multicast applications. However, our understanding of Raptor codes is still incomplete due to the insufficient amount of theoretical work on the performance analysis of Raptor codes, particularly under maximum-likelihood (ML) decoding, which provides an optimal benchmark on the system performance for the other decoding schemes to compare against. For the first time, this paper provides an upper bound and a lower bound, on the packet error performance of Raptor codes under ML decoding, which is measured by the probability that all source packets can be successfully decoded by a receiver with a given number of successfully received coded packets. Simulations are conducted to validate the accuracy of the analysis. More specifically, Raptor codes with different degree distribution and pre-coders, are evaluated using the derived bounds with high accuracy.", "subjects": "Information Theory (cs.IT)", "authors": "Peng Wang, Guoqiang Mao, Zihuai Lin, Ming Ding, Weifa Liang, Xiaohu Ge, Zhiyun Lin,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07320", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07320", "title": "\nTensor Factorization via Matrix Factorization", "abstract": "Tensor factorization arises in many machine learning applications, such knowledge base modeling and parameter estimation in latent variable models. However, numerical methods for tensor factorization have not reached the level of maturity of matrix factorization methods. In this paper, we propose a new method for CP tensor factorization that uses random projections to reduce the problem to simultaneous matrix diagonalization. Our method is conceptually simple and also applies to non-orthogonal and asymmetric tensors of arbitrary order. We prove that a small number random projections essentially preserves the spectral information in the tensor, allowing us to remove the dependence on the eigengap that plagued earlier tensor-to-matrix reductions. Experimentally, our method outperforms existing tensor factorization methods on both simulated data and two real datasets.", "subjects": "Learning (cs.LG)", "authors": "Volodymyr Kuleshov, Arun Tejasvi Chaganty, Percy Liang,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07319", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07319", "title": "\nVirtual Full-Duplex Buffer-Aided Relaying in the Presence of Inter-Relay  Interference", "abstract": "In this paper, we study virtual full-duplex (FD) buffer-aided relaying to recover the loss of multiplexing gain caused by half-duplex (HD) relaying in a multiple relay network, where each relay is equipped with a buffer and multiple antennas, through joint opportunistic relay selection (RS) and beamforming (BF) design. The main idea of virtual FD buffer-aided relaying is that the source and one of the relays simultaneously transmit their own information to another relay and the destination, respectively. In such networks, inter-relay interference (IRI) is a crucial problem which has to be resolved like self-interference in the FD relaying. In contrast to previous work that neglected IRI, we propose joint RS and BF schemes taking IRI into consideration by using multiple antennas at the relays. In order to maximize average end-to-end rate, we propose a weighted sum-rate maximization strategy assuming that adaptive rate transmission is employed in both the source to relay and relay to destination links. Then, we propose several BF schemes cancelling or suppressing IRI in order to maximize the weighted sum-rate. Numerical results show that our proposed optimal, zero forcing, and minimum mean square error BF-based RS schemes asymptotically approach the ideal FD relaying upper bound when increasing the number of antennas and/or the number of relays.", "subjects": "Information Theory (cs.IT)", "authors": "Su Min Kim, Mats Bengtsson,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07315", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07315", "title": "\nPer-Block-Convex Data Modeling by Accelerated Stochastic Approximation", "abstract": "Applications involving dictionary learning, non-negative matrix factorization, subspace clustering, and parallel factor tensor decomposition tasks motivate well algorithms for per-block-convex and non-smooth optimization problems. By leveraging the stochastic approximation paradigm and first-order acceleration schemes, this paper develops an online and modular learning algorithm for a large class of non-convex data models, where convexity is manifested only per-block of variables whenever the rest of them are held fixed. The advocated algorithm incurs computational complexity that scales linearly with the number of unknowns. Under minimal assumptions on the cost functions of the composite optimization task, without bounding constraints on the optimization variables, or any explicit information on bounds of Lipschitz coefficients, the expected cost evaluated online at the resultant iterates is provably convergent with quadratic rate to an accumulation point of the (per-block) minima, while subgradients of the expected cost asymptotically vanish in the mean-squared sense. The merits of the general approach are demonstrated in two online learning setups: (i) Robust linear regression using a sparsity-cognizant total least-squares criterion; and (ii) semi-supervised dictionary learning for network-wide link load tracking and imputation with missing entries. Numerical tests on synthetic and real data highlight the potential of the proposed framework for streaming data analytics by demonstrating superior performance over block coordinate descent, and reduced complexity relative to the popular alternating-direction method of multipliers.", "subjects": "Learning (cs.LG)", "authors": "Konstantinos Slavakis, Georgios B. Giannakis,", "date": "2015-1-29"}, 
{"urllink": "http://arxiv.org/abs/1501.07304", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07304", "title": "\nThe Beauty of Capturing Faces: Rating the Quality of Digital Portraits", "abstract": "Digital portrait photographs are everywhere, and while the number of face pictures keeps growing, not much work has been done to on automatic portrait beauty assessment. In this paper, we design a specific framework to automatically evaluate the beauty of digital portraits. To this end, we procure a large dataset of face images annotated not only with aesthetic scores but also with information about the traits of the subject portrayed. We design a set of visual features based on portrait photography literature, and extensively analyze their relation with portrait beauty, exposing interesting findings about what makes a portrait beautiful. We find that the beauty of a portrait is linked to its artistic value, and independent from age, race and gender of the subject. We also show that a classifier trained with our features to separate beautiful portraits from non-beautiful portraits outperforms generic aesthetic classifiers.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Miriam Redi, Nikhil Rasiwasia, Gaurav Aggarwal, Alejandro Jaimes,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07293", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07293", "title": "\nAccelerate micromagnetic simulations with GPU programming in MATLAB", "abstract": "A finite-difference Micromagnetic simulation code written in MATLAB is presented with Graphics Processing Unit (GPU) acceleration. The high performance of Graphics Processing Unit (GPU) is demonstrated compared to a typical Central Processing Unit (CPU) based code. The speed-up of GPU to CPU is shown to be greater than 30 for problems with larger sizes on a mid-end GPU in single precision. The code is less than 200 lines and suitable for new algorithm developing.", "subjects": "Computational Engineering, Finance, and Science (cs.CE)", "authors": "Ru Zhu,", "date": "2015-1-25"}, 
{"urllink": "http://arxiv.org/abs/1501.07256", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07256", "title": "\nAn approach to multi-agent planning with incomplete information", "abstract": "Multi-agent planning (MAP) approaches have been typically conceived for independent or loosely-coupled problems to enhance the benefits of distributed planning between autonomous agents as solving this type of problems require less coordination between the agents' sub-plans. However, when it comes to tightly-coupled agents' tasks, MAP has been relegated in favour of centralized approaches and little work has been done in this direction. In this paper, we present a general-purpose MAP capable to efficiently handle planning problems with any level of coupling between agents. We propose a cooperative refinement planning approach, built upon the partial-order planning paradigm, that allows agents to work with incomplete information and to have incomplete views of the world, i.e. being ignorant of other agents' information, as well as maintaining their own private information. We show various experiments to compare the performance of our system with a distributed CSP-based MAP approach over a suite of problems.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Alejandro Torre\u00f1o, Eva Onaindia, \u00d3scar Sapena,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07250", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07250", "title": "\nFMAP: Distributed Cooperative Multi-Agent Planning", "abstract": "This paper proposes FMAP (Forward Multi-Agent Planning), a fully-distributed multi-agent planning method that integrates planning and coordination. Although FMAP is specifically aimed at solving problems that require cooperation among agents, the flexibility of the domain-independent planning model allows FMAP to tackle multi-agent planning tasks of any type. In FMAP, agents jointly explore the plan space by building up refinement plans through a complete and flexible forward-chaining partial-order planner. The search is guided by , a novel heuristic function that is based on the concepts of Domain Transition Graph and frontier state and is optimized to evaluate plans in distributed environments. Agents in FMAP apply an advanced privacy model that allows them to adequately keep private information while communicating only the data of the refinement plans that is relevant to each of the participating agents. Experimental results show that FMAP is a general-purpose approach that efficiently solves tightly-coupled domains that have specialized agents and cooperative goals as well as loosely-coupled problems. Specifically, the empirical evaluation shows that FMAP outperforms current MAP systems at solving complex planning tasks that are adapted from the International Planning Competition benchmarks.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Alejandro Torre\u00f1o, Eva Onaindia, \u00d3scar Sapena,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07242", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07242", "title": "\nEscaping the Local Minima via Simulated Annealing: Optimization of  Approximately Convex Functions", "abstract": "We consider the problem of optimizing an approximately convex function over a bounded convex set in using only function evaluations. The problem is reduced to sampling from an emph log-concave distribution using the Hit-and-Run method, with query complexity of . In the context of zeroth order stochastic convex optimization, the proposed method produces an -minimizer after noisy function evaluations by inducing a -approximately log concave distribution. We also consider the case when the \"amount of non-convexity\" decays towards the optimum of the function. Other applications of the random walk method include private computation of empirical risk minimizers, two-stage stochastic programming, and approximate dynamic programming for online learning.", "subjects": "Numerical Analysis (cs.NA)", "authors": "Alexandre Belloni, Tengyuan Liang, Hariharan Narayanan, Alexander Rakhlin,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07227", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07227", "title": "\nA Neural Network Anomaly Detector Using the Random Cluster Model", "abstract": "The random cluster model is used to define an upper bound on a distance measure as a function of the number of data points to be classified and the expected value of the number of classes to form in a hybrid K-means and regression classification methodology, with the intent of detecting anomalies. Conditions are given for the identification of classes which contain anomalies and individual anomalies within identified classes. A neural network model describes the decision region-separating surface for offline storage and recall in any new anomaly detection.", "subjects": "Learning (cs.LG)", "authors": "Robert A. Murphy,", "date": "2015-1-8"}, 
{"urllink": "http://arxiv.org/abs/1501.07215", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07215", "title": "\nMonadic Second-Order Logic and Bisimulation Invariance for Coalgebras", "abstract": "Generalizing standard monadic second-order logic for Kripke models, we introduce monadic second-order logic interpreted over coalgebras for an arbitrary set functor. Similar to well-known results for monadic second-order logic over trees, we provide a translation of this logic into a class of automata, relative to the class of coalgebras that admit a tree-like supporting Kripke frame. We then consider invariance under behavioral equivalence of formulas; more in particular, we investigate whether the coalgebraic mu-calculus is the bisimulation-invariant fragment of monadic second-order logic. Building on recent results by the third author we show that in order to provide such a coalgebraic generalization of the Janin-Walukiewicz Theorem, it suffices to find what we call an adequate uniform construction for the functor. As applications of this result we obtain a partly new proof of the Janin-Walukiewicz Theorem, and bisimulation invariance results for the bag functor (graded modal logic) and all exponential polynomial functors. Finally, we consider in some detail the monotone neighborhood functor, which provides coalgebraic semantics for monotone modal logic. It turns out that there is no adequate uniform construction for this functor, whence the automata-theoretic approach towards bisimulation invariance does not apply directly. This problem can be overcome if we consider global bisimulations between neighborhood models: one of our main technical results provides a characterization of the monotone modal mu-calculus extended with the global modalities, as the fragment of monadic second-order logic for the monotone neighborhood functor that is invariant for global bisimulations.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Sebastian Enqvist, Fatemeh Seifan, Yde Venema,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07209", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07209", "title": "\nBernays-Sch\u00f6nfinkel-Ramsey with Simple Bounds is NEXPTIME-complete", "abstract": "Linear arithmetic extended with free predicate symbols is undecidable, in general. We show that the restriction of linear arithmetic inequations to simple bounds extended with the Bernays-Sch \"onfinkel-Ramsey free first-order fragment is decidable and NEXPTIME-complete. The result is almost tight because the Bernays-Sch \"onfinkel-Ramsey fragment is undecidable in combination with linear difference inequations, simple additive inequations, quotient inequations and multiplicative inequations.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Marco Voigt, Christoph Weidenbach,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07203", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07203", "title": "\nStructural Patterns of the Occupy Movement on Facebook", "abstract": "In this work we study a peculiar example of social organization on Facebook: the Occupy Movement -- i.e., an international protest movement against social and economic inequality organized online at a city level. We consider 179 US Facebook public pages during the time period between September 2011 and February 2013. The dataset includes 618K active users and 753K posts that received about 5.2M likes and 1.1M comments. By labeling user according to their interaction patterns on pages -- e.g., a user is considered to be polarized if she has at least the 95% of her likes on a specific page -- we find that activities are not locally coordinated by geographically close pages, but are driven by pages linked to major US cities that act as hubs within the various groups. Such a pattern is verified even by extracting the backbone structure -- i.e., filtering statistically relevant weight heterogeneities -- for both the pages-reshares and the pages-common users networks.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Michela Del Vicario, Qian Zhang, Alessandro Bessi, Fabiana Zollo, Antonio Scala, Guido Caldarelli, Walter Quattrociocchi,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07201", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07201", "title": "\nEveryday the Same Picture: Popularity and Content Diversity", "abstract": "Facebook is flooded by diverse and heterogeneous content, from kittens up to music and news, passing through satirical and funny stories. Each piece of that corpus reflects the heterogeneity of the underlying social background. In the Italian Facebook we have found an interesting case: a page having more than followers that every day posts the same picture of a popular Italian singer. In this work, we use such a page as a control to study and model the relationship between content heterogeneity on popularity. In particular, we use that page for a comparative analysis of information consumption patterns with respect to pages posting science and conspiracy news. In total, we analyze about likes and comments, made by approximately and users, respectively. We conclude the paper by introducing a model mimicking users selection preferences accounting for the heterogeneity of contents.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Alessandro Bessi, Fabiana Zollo, Michela Del Vicario, Antonio Scala, Fabio Petroni, Bruno Gon\u00e7alves, Walter Quattrociocchi,", "date": "2015-1-8"}, 
{"urllink": "http://arxiv.org/abs/1501.07195", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07195", "title": "\nThe Logic of Counting Query Answers: A Study via Existential Positive  Queries", "abstract": "We consider the computational complexity of counting the number of answers to a logical formula on a finite structure. In the setting of parameterized complexity, we present a trichotomy theorem on classes of existential positive queries. We then proceed to study an extension of first-order logic in which algorithms for the counting problem at hand can be naturally and conveniently expressed.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Hubie Chen, Stefan Mengel,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07188", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07188", "title": "\nLabel Placement in Road Maps", "abstract": "A road map can be interpreted as a graph embedded in the plane, in which each vertex corresponds to a road junction and each edge to a particular road section. We consider the cartographic problem to place non-overlapping road labels along the edges so that as many road sections as possible are identified by their name, i.e., covered by a label. We show that this is NP-hard in general, but the problem can be solved in polynomial time if the road map is an embedded tree.", "subjects": "Computational Geometry (cs.CG)", "authors": "Andreas Gemsa, Benjamin Niedermann, Martin N\u00f6llenburg,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07184", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07184", "title": "\nOne Size Does not Fit All: When to Use Signature-based Pruning to  Improve Template Matching for RDF graphs", "abstract": "Signature-based pruning is broadly accepted as an effective way to improve query performance of graph template matching on general labeled graphs. Most existing techniques which utilize signature-based pruning claim its benefits on all datasets and queries. However, the effectiveness of signature-based pruning varies greatly among different RDF datasets and highly related with their dataset characteristics. We observe that the performance benefits from signature-based pruning depend not only on the size of the RDF graphs, but also the underlying graph structure and the complexity of queries. This motivates us to propose a flexible RDF querying framework, called RDF-h, which selectively utilizes signature-based pruning by evaluating the characteristics of RDF datasets and query templates. Scalability and efficiency of RDF-h is demonstrated in experimental results using both real and synthetic datasets. Keywords: RDF, Graph Template Matching, Signature-based Pruning", "subjects": "Databases (cs.DB)", "authors": "Shi Qiao, Z. Meral Ozsoyoglu,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07180", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07180", "title": "\nEnd-to-End Photo-Sketch Generation via Fully Convolutional  Representation Learning", "abstract": "Sketch-based face recognition is an interesting task in vision and multimedia research, yet it is quite challenging due to the great difference between face photos and sketches. In this paper, we propose a novel approach for photo-sketch generation, aiming to automatically transform face photos into detail-preserving personal sketches. Unlike the traditional models synthesizing sketches based on a dictionary of exemplars, we develop a fully convolutional network to learn the end-to-end photo-sketch mapping. Our approach takes whole face photos as inputs and directly generates the corresponding sketch images with efficient inference and learning, in which the architecture are stacked by only convolutional kernels of very small sizes. To well capture the person identity during the photo-sketch transformation, we define our optimization objective in the form of joint generative-discriminative minimization. In particular, a discriminative regularization term is incorporated into the photo-sketch generation, enhancing the discriminability of the generated person sketches against other individuals. Extensive experiments on several standard benchmarks suggest that our approach outperforms other state-of-the-art methods in both photo-sketch generation and face sketch verification.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Liliang Zhang, Liang Lin, Xian Wu, Shengyong Ding, Lei Zhang,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07174", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07174", "title": "\nEnhancing Reuse of Constraint Solutions to Improve Symbolic Execution", "abstract": "Constraint solution reuse is an effective approach to save the time of constraint solving in symbolic execution. Most of the existing reuse approaches are based on syntactic or semantic equivalence of constraints; e.g. the Green framework is able to reuse constraints which have different representations but are semantically equivalent, through canonizing constraints into syntactically equivalent normal forms. However, syntactic/semantic equivalence is not a necessary condition for reuse--some constraints are not syntactically or semantically equivalent, but their solutions still have potential for reuse. Existing approaches are unable to recognize and reuse such constraints. In this paper, we present GreenTrie, an extension to the Green framework, which supports constraint reuse based on the logical implication relations among constraints. GreenTrie provides a component, called L-Trie, which stores constraints and solutions into tries, indexed by an implication partial order graph of constraints. L-Trie is able to carry out logical reduction and logical subset and superset querying for given constraints, to check for reuse of previously solved constraints. We report the results of an experimental assessment of GreenTrie against the original Green framework, which shows that our extension achieves better reuse of constraint solving result and saves significant symbolic execution time.", "subjects": "Software Engineering (cs.SE)", "authors": "Xiangyang Jia, Carlo Ghezzi, Shi Ying,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07139", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07139", "title": "\nA Data Annotation Architecture for Semantic Applications in Virtualized  Wireless Sensor Networks", "abstract": "Wireless Sensor Networks (WSNs) have become very popular and are being used in many application domains (e.g. smart cities, security, gaming and agriculture). Virtualized WSNs allow the same WSN to be shared by multiple applications. Semantic applications are situation-aware and can potentially play a critical role in virtualized WSNs. However, provisioning them in such settings remains a challenge. The key reason is that semantic applications provisioning mandates data annotation. Unfortunately it is no easy task to annotate data collected in virtualized WSNs. This paper proposes a data annotation architecture for semantic applications in virtualized heterogeneous WSNs. The architecture uses overlays as the cornerstone, and we have built a prototype in the cloud environment using Google App Engine. The early performance measurements are also presented.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Imran Khan, Rifat Jafrin, Fatima Zahra Errounda, Roch Glitho, Noel Crespi, Monique Morrow, Paul Polako,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07135", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07135", "title": "\nWireless Sensor Network Virtualization: Early Architecture and Research  Perspectives", "abstract": "Wireless sensor networks (WSNs) have become pervasive and are used in many applications and services. Usually the deployments of WSNs are task oriented and domain specific; thereby precluding re-use when other applications and services are contemplated. This inevitably leads to the proliferation of redundant WSN deployments. Virtualization is a technology that can aid in tackling this issue, as it enables the sharing of resources/infrastructure by multiple independent entities. In this paper we critically review the state of the art and propose a novel architecture for WSN virtualization. The proposed architecture has four layers (physical layer, virtual sensor layer, virtual sensor access layer and overlay layer) and relies on the constrained application protocol (CoAP). We illustrate its potential by using it in a scenario where a single WSN is shared by multiple applications; one of which is a fire monitoring application. We present the proof-of-concept prototype we have built along with the performance measurements, and discuss future research directions.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Imran Khan, Fatna Belqasmi, Roch Glitho, Noel Crespi, Monique Morrow, Paul Polakos,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07133", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07133", "title": "\nOn Optimal Family of Codes for DNA Storage", "abstract": "Advancement in the technology has generated immense data which has become a burning issue for data storage experts. To accommodate the data and cope up with demand, computer scientist are striving to produce the improved, dense and reliable data storage medium. The main challenge for the development of optimum data storage medium is enhancement in storage capacity, reliability and security. Various applications of DNA in computing technologies and its dense, stable, reliable nature enticed the researcher to use DNA as storage medium. The idea of using DNA as storage medium has many success stories but the main challenges to deal with are error correction and cost associated with the DNA sequencing and synthesis. In this work, we have developed an efficient technique to encode the data into DNA by using non-linear family of ternary codes. This gives us significant reduction in file size for storing data on DNA from previous developed methods. Using our method one can store 1.15 ExaBytes (EB) of information in one gram of DNA.", "subjects": "Information Theory (cs.IT)", "authors": "Vijay Dhameliya, Dixita Limbachiya, Madhav Khakhar, Manish K Gupta,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07132", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07132", "title": "\nOn Kalman-Like Finite Impulse Response Filters", "abstract": "This note reveals an explicit relationship between two representative finite impulse response (FIR) filters, i.e. the newly derived and popularized Kalman-Like unbiased FIR filter (UFIR) and the receding horizon Kalman FIR filter (RHKF). It is pointed out that the only difference of the two algorithms lies in the noise statistics ignorance and appropriate initial condition construction strategy in UFIR. The revelation can benefit the performance improvement of one by drawing lessons from the other. Some interesting conclusions have also been drawn and discussed from this revelation.", "subjects": "Systems and Control (cs.SY)", "authors": "Lubin Chang,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.07131", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07131", "title": "\nA Characterisation of Context-Sensitive Languages by Consensus Games", "abstract": "We propose a game for recognising formal languages, in which two players with imperfect information need to coordinate on a common decision, given private input information. The players have a joint objective to avoid an inadmissible decision, in spite of the uncertainty induced by the input. We show that this model of consensus acceptor games characterises context-sensitive languages, and conversely, that winning strategies in such games can be described by context-sensitive languages. This implies that it is undecidable whether a consensus game admits a winning strategy, and, even if so, it is PSPACE-hard to execute one. On the positive side, we prove that whenever a winning strategy exists, there exists one that can be implemented by a linear bounded automaton.", "subjects": "Formal Languages and Automata Theory (cs.FL)", "authors": "Dietmar Berwanger, Marie van den Bogaard,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07130", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07130", "title": "\nOn Partial Maximally-Recoverable and Maximally-Recoverable Codes", "abstract": "An [n, k] linear code C that is subject to locality constraints imposed by a parity check matrix H0 is said to be a maximally recoverable (MR) code if it can recover from any erasure pattern that some k-dimensional subcode of the null space of H0 can recover from. The focus in this paper is on MR codes constrained to have all-symbol locality r. Given that it is challenging to construct MR codes having small field size, we present results in two directions. In the first, we relax the MR constraint and require only that apart from the requirement of being an optimum all-symbol locality code, the code must yield an MDS code when punctured in a single, specific pattern which ensures that each local code is punctured in precisely one coordinate and that no two local codes share the same punctured coordinate. We term these codes as partially maximally recoverable (PMR) codes. We provide a simple construction for high-rate PMR codes and then provide a general, promising approach that needs further investigation. In the second direction, we present three constructions of MR codes with improved parameters, primarily the size of the finite field employed in the construction", "subjects": "Information Theory (cs.IT)", "authors": "S. B. Balaji, P. Vijay Kumar,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07114", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07114", "title": "\nOptimal Binary Locally Repairable Codes via Anticodes", "abstract": "This paper presents a construction for several families of optimal binary locally repairable codes (LRCs) with small locality (2 and 3). This construction is based on various anticodes. It provides binary LRCs which attain the Cadambe-Mazumdar bound. Moreover, most of these codes are optimal with respect to the Griesmer bound.", "subjects": "Information Theory (cs.IT)", "authors": "Natalia Silberstein, Alexander Zeh,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07107", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07107", "title": "\nIterative-Promoting Variable Step Size Least Mean Square Algorithm for  Accelerating Adaptive Channel Estimation", "abstract": "Invariable step size based least-mean-square error (ISS-LMS) was considered as a very simple adaptive filtering algorithm and hence it has been widely utilized in many applications, such as adaptive channel estimation. It is well known that the convergence speed of ISS-LMS is fixed by the initial step-size. In the channel estimation scenarios, it is very hard to make tradeoff between convergence speed and estimation performance. In this paper, we propose an iterative-promoting variable step size based least-mean-square error (VSS-LMS) algorithm to control the convergence speed as well as to improve the estimation performance. Simulation results show that the proposed algorithm can achieve better estimation performance than previous ISS-LMS while without sacrificing convergence speed.", "subjects": "Information Theory (cs.IT)", "authors": "Beiyi Liu, Guan Gui, Li Xu, Nobuhiro Shimoi,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07106", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07106", "title": "\nPlanarity of Streamed Graphs", "abstract": "In this paper we introduce a notion of planarity for graphs that are presented in a streaming fashion. A is a stream of edges on a vertex set . A streamed graph is - with respect to a positive integer window size if there exists a sequence of planar topological drawings of the graphs such that the common graph is drawn the same in and in , for . The Problem with window size asks whether a given streamed graph is -stream planar. We also consider a generalization, where there is an additional whose edges have to be present during each time step. These problems are related to several well-studied planarity problems. We show that the Problem is NP-complete even when the window size is a constant and that the variant with a backbone graph is NP-complete for all . On the positive side, we provide -time algorithms for (i) the case and (ii) all values of provided the backbone graph consists of one -connected component plus isolated vertices and no stream edge connects two isolated vertices. Our results improve on the Hanani-Tutte-style -time algorithm proposed by Schaefer [GD'14] for .", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Giordano Da Lozzo, Ignaz Rutter,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07093", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07093", "title": "\nNovel Approaches for Predicting Risk Factors of Atherosclerosis", "abstract": "Coronary heart disease (CHD) caused by hardening of artery walls due to cholesterol known as atherosclerosis is responsible for large number of deaths world-wide. The disease progression is slow, asymptomatic and may lead to sudden cardiac arrest, stroke or myocardial infraction. Presently, imaging techniques are being employed to understand the molecular and metabolic activity of atherosclerotic plaques to estimate the risk. Though imaging methods are able to provide some information on plaque metabolism they lack the required resolution and sensitivity for detection. In this paper we consider the clinical observations and habits of individuals for predicting the risk factors of CHD. The identification of risk factors helps in stratifying patients for further intensive tests such as nuclear imaging or coronary angiography. We present a novel approach for predicting the risk factors of atherosclerosis with an in-built imputation algorithm and particle swarm optimization (PSO). We compare the performance of our methodology with other machine learning techniques on STULONG dataset which is based on longitudinal study of middle aged individuals lasting for twenty years. Our methodology powered by PSO search has identified physical inactivity as one of the risk factor for the onset of atherosclerosis in addition to other already known factors. The decision rules extracted by our methodology are able to predict the risk factors with an accuracy of which is higher than the accuracies obtained by application of the state-of-the-art machine learning techniques presently being employed in the identification of atherosclerosis risk studies.", "subjects": "Learning (cs.LG)", "authors": "V. Sree Hari Rao, M. Naresh Kumar,", "date": "2015-1-8"}, 
{"urllink": "http://arxiv.org/abs/1501.07084", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07084", "title": "\nk2U: A General Framework from k-Point Effective Schedulability Analysis  to Utilization-Based Tests", "abstract": "To deal with a large variety of workloads in different application domains in real-time embedded systems, a number of expressive task models have been developed. For each individual task model, researchers tend to develop different types of techniques for schedulability tests with different computation complexity and performance. In this paper, we present a general schedulability analysis framework, namely the k2U framework, that can be potentially applied to analyze a large set of real- time task models under any fixed-priority scheduling algorithm, on both uniprocessors and multiprocessors. The key to k2U is a k-point effective schedulability test, which can be viewed as a blackbox interface to apply the k2U framework. For any task model, if a corresponding k-point effective schedulability test can be constructed, then a sufficient utilization-based test can be automatically derived. We show the generality of k2U by applying it to different task models, which results in new and better tests compared to the state-of-the-art.", "subjects": "Operating Systems (cs.OS)", "authors": "Jian-Jia Chen, Wen-Hung Huang, Cong Liu,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07082", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07082", "title": "\nA Diagrammatic Axiomatisation for Qubit Entanglement", "abstract": "Diagrammatic techniques for reasoning about monoidal categories provide an intuitive understanding of the symmetries and connections of interacting computational processes. In the context of categorical quantum mechanics, Coecke and Kissinger suggested that two 3-qubit states, GHZ and W, may be used as the building blocks of a new graphical calculus, aimed at a diagrammatic classification of multipartite qubit entanglement that would highlight the communicational properties of quantum states, and their potential uses in cryptographic schemes. In this paper, we present a full graphical axiomatisation of the relations between GHZ and W: the ZW calculus. This refines a version of the preexisting ZX calculus, while keeping its most desirable characteristics: undirectedness, a large degree of symmetry, and an algebraic underpinning. We prove that the ZW calculus is complete for the category of free abelian groups on a power of two generators - \"qubits with integer coefficients\" - and provide an explicit normalisation procedure.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Amar Hadzihasanovic,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07080", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07080", "title": "\nOn the genetic optimization of APSK constellations for satellite  broadcasting", "abstract": "Both satellite transmissions and DVB applications over satellite present peculiar characteristics that could be taken into consideration in order to further exploit the optimality of the transmission. In this paper, starting from the state-of-the-art, the optimization of the APSK constellation through asymmetric symbols arrangement is investigated for its use in satellite communications. In particular, the optimization problem is tackled by means of Genetic Algorithms that have already been demonstrated to work nicely with complex non-linear optimization problems like the one presented hereinafter. This work aims at studying the various parameters involved in the optimization routine in order to establish those that best fit this case, thus further enhancing the constellation.", "subjects": "Information Theory (cs.IT)", "authors": "Alessio Meloni, Maurizio Murroni,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07079", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07079", "title": "\nThe Affinity Effects of Parallelized Libraries in Concurrent  Environments", "abstract": "The use of cloud computing grows as it appears to be an additional resource for High-Performance Parallel and Distributed Computing (HPDC), especially with respect to its use in support of scientific applications. Many studies have been devoted to determining the effect of the virtualization layer on the performance, but most of the studies conducted so far lack insight into the joint effects between application type, virtualization layer and parallelized libraries in applications. This work introduces the concept of affinity with regard to the combined effects of the virtualization layer, class of application and parallelized libraries used in these applications. Affinity is here defined as the degree of influence that one application has on other applications when running concurrently in virtual environments hosted on the same real server. The results presented here show how parallel libraries used in application implementation have a significant influence and how the combinations between these types of libraries and classes of applications could significantly influence the performance of the environment. In this context, the concept of affinity is then used to evaluate these impacts to contribute to better stability and performance in the computational environment.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Fabio Licht, Bruno Schulze, Luis E. Bona, Antonio R. Mury,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07072", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07072", "title": "\nOn the stability of asynchronous Random Access Schemes", "abstract": "Slotted Aloha-based Random Access (RA) techniques have recently regained attention in light of the use of Interference Cancellation (IC) as a mean to exploit diversity created through the transmission of multiple burst copies per packet content (CRDSA). Subsequently, the same concept has been extended to pure ALOHA-based techniques in order to boost the performance also in case of asynchronous RA schemes. In this paper, throughput as well as packet delay and related stability for asynchronous ALOHA techniques under geometrically distributed retransmissions are analyzed both in case of finite and infinite population size. Moreover, a comparison between pure ALOHA, its evolution (known as CRA) and CRDSA techniques is presented, in order to give a measure of the achievable gain that can be reached in a closed-loop scenario with respect to the previous state of the art.", "subjects": "Information Theory (cs.IT)", "authors": "Alessio Meloni, Maurizio Murroni,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07056", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07056", "title": "\nAn Effective Framework for Managing University Data using a Cloud based  Environment", "abstract": "Management of data in education sector particularly management of data for big universities with several employees, departments and students is a very challenging task. There are also problems such as lack of proper funds and manpower for management of such data in universities. Education sector can easily and effectively take advantage of cloud computing skills for management of data. It can enhance the learning experience as a whole and can add entirely new dimensions to the way in which education is imbibed. Several benefits of Cloud computing such as monetary benefits, environmental benefits and remote data access for management of data such as university database can be used in education sector. Therefore, in this paper we have proposed an effective framework for managing university data using a cloud based environment. We have also proposed cloud data management simulator: a new simulation framework which demonstrates the applicability of cloud in the current education sector. The framework consists of a cloud developed for processing a universities database which consists of staff and students. It has the following features (i) support for modeling cloud computing infrastructure, which includes data centers containing university database; (ii) a user friendly interface; (iii) flexibility to switch between the different types of users; and (iv) virtualized access to cloud data.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Kashish Ara Shakil, Shuchi Sethi, Mansaf Alam,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07053", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07053", "title": "\nQuadratic-Time Hardness of LCS and other Sequence Similarity Measures", "abstract": "Two important similarity measures between sequences are the longest common subsequence (LCS) and the dynamic time warping distance (DTWD). The computations of these measures for two given sequences are central tasks in a variety of applications. Simple dynamic programming algorithms solve these tasks in time, and despite an extensive amount of research, no algorithms with significantly better worst case upper bounds are known. In this paper, we show that an time algorithm, for some , for computing the LCS or the DTWD of two sequences of length over a constant size alphabet, refutes the popular Strong Exponential Time Hypothesis (SETH). Moreover, we show that computing the LCS of strings over an alphabet of size cannot be done in time, for any , under SETH. Finally, we also address the time complexity of approximating the DTWD of two strings in truly subquadratic time.", "subjects": "Computational Complexity (cs.CC)", "authors": "Amir Abboud, Arturs Backurs, Virginia Vassilevska Williams,", "date": "2015-1-8"}, 
{"urllink": "http://arxiv.org/abs/1501.07034", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07034", "title": "\nEmbedding of binary image in the Gray planes", "abstract": "For watermarking of the digital grayscale image its Gray planes have been used. With the help of the introduced representation over Gray planes the LSB embedding method and detection have been discussed. It found that data, a binary image, hidden in the Gray planes is more robust to JPEG lossy compression than in the bit planes.", "subjects": "Multimedia (cs.MM)", "authors": "V.N. Gorbachev, L.A. Denisov, E.M. Kainarova,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07033", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07033", "title": "\nError Correction for Differential Linear Network Coding in  Slowly-Varying Networks", "abstract": "Differential linear network coding (DLNC) is a precoding scheme for information transmission over random linear networks. By using differential encoding and decoding, the conventional approach of lifting, required for inherent channel sounding, can be omitted and in turn higher transmission rates are supported. However, the scheme is sensitive to variations in the network topology. In this paper, we derive an extended DLNC channel model which includes slow network changes. Based on this, we propose and analyze a suitable channel coding scheme matched to the situation at hand using rank-metric convolutional codes.", "subjects": "Information Theory (cs.IT)", "authors": "Sven Puchinger, Michael Cyran, Robert F. H. Fischer, Martin Bossert, Johannes B. Huber,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07020", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07020", "title": "\nResource Usage Estimation of Data Stream Processing Workloads in  Datacenter Clouds", "abstract": "Real-time computation of data streams over affordable virtualized infrastructure resources is an important form of data in motion processing architecture. However, processing such data streams while ensuring strict guarantees on quality of services is problematic due to: (i) uncertain stream arrival pattern; (ii) need of processing different types of continuous queries; and (iii) variable resource consumption behavior of continuous queries. Recent work has explored the use of statistical techniques for resource estimation of SQL queries and OLTP workloads. All these techniques approximate resource usage for each query as a single point value. However, in data stream processing workloads in which data flows through the graph of operators endlessly and poses performance and resource demand fluctuations, the single point resource estimation is inadequate. Because it is neither expressive enough nor does it capture the multi-modal nature of the target data. To this end, we present a novel technique which uses mixture density networks, a combined structure of neural networks and mixture models, to estimate the whole spectrum of resource usage as probability density functions. The proposed approach is a flexible and convenient means of modeling unknown distribution models. We have validated the models using both the linear road benchmark and the TPC-H, observing high accuracy under a number of error metrics: mean-square error, continuous ranked probability score, and negative log predictive density.", "subjects": "Databases (cs.DB)", "authors": "Alireza Khoshkbarforoushha, Rajiv Ranjan, Raj Gaire, Prem P. Jayaraman, John Hosking, Ehsan Abbasnejad,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07008", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07008", "title": "\nA Distance-Based Decision in the Credal Level", "abstract": "Belief function theory provides a flexible way to combine information provided by different sources. This combination is usually followed by a decision making which can be handled by a range of decision rules. Some rules help to choose the most likely hypothesis. Others allow that a decision is made on a set of hypotheses. In [6], we proposed a decision rule based on a distance measure. First, in this paper, we aim to demonstrate that our proposed decision rule is a particular case of the rule proposed in [4]. Second, we give experiments showing that our rule is able to decide on a set of hypotheses. Some experiments are handled on a set of mass functions generated randomly, others on real databases.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Amira Essaid, Arnaud Martin, Gr\u00e9gory Smits, Boutheina Ben Yaghlane,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.07005", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.07005", "title": "\nSurvey:Natural Language Parsing For Indian Languages", "abstract": "Syntactic parsing is a necessary task which is required for NLP applications including machine translation. It is a challenging task to develop a qualitative parser for morphological rich and agglutinative languages. Syntactic analysis is used to understand the grammatical structure of a natural language sentence. It outputs all the grammatical information of each word and its constituent. Also issues related to it help us to understand the language in a more detailed way. This literature survey is groundwork to understand the different parser development for Indian languages and various approaches that are used to develop such tools and techniques. This paper provides a survey of research papers from well known journals and conferences.", "subjects": "Computation and Language (cs.CL)", "authors": "Monika T. Makwana, Deepak C. Vegda,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.06993", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06993", "title": "\nFeature Sampling Strategies for Action Recognition", "abstract": "Although dense local spatial-temporal features with bag-of-features representation achieve state-of-the-art performance for action recognition, the huge feature number and feature size prevent current methods from scaling up to real size problems. In this work, we investigate different types of feature sampling strategies for action recognition, namely dense sampling, uniformly random sampling and selective sampling. We propose two effective selective sampling methods using object proposal techniques. Experiments conducted on a large video dataset show that we are able to achieve better average recognition accuracy using 25% less features, through one of proposed selective sampling methods, and even remain comparable accuracy while discarding 70% features.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Youjie Zhou, Hongkai Yu, Song Wang,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.06988", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06988", "title": "\nHeterogeneous Cellular Networks Using Wireless Backhaul: Fast Admission  Control and Large System Analysis", "abstract": "We consider a heterogeneous cellular network with densely underlaid small cell access points (SAPs). Wireless backhaul provides the data connection from the core network to SAPs. To serve as many SAPs as possible with guaranteed data rates, admission control of SAPs needs to be performed in wireless backhaul. Such a problem involves joint design of transmit beamformers, power control, and selection of SAPs. In order to tackle such a difficult problem, we apply -relaxation and propose an iterative algorithm for the -relaxed problem. The selection of SAPs is made based on the outputs of the iterative algorithm. This algorithm is fast and enjoys low complexity for small-to-medium sized systems. However, its solution depends on the actual channel state information, and resuming the algorithm for each new channel realization may be unrealistic for large systems. Therefore, we make use of random matrix theory and also propose an iterative algorithm for large systems. Such a large system iterative algorithm produces asymptotically optimum solution for the -relaxed problem, which only requires large-scale channel coefficients irrespective of the actual channel realization. Near optimum results are achieved by our proposed algorithms in simulations.", "subjects": "Information Theory (cs.IT)", "authors": "Jian Zhao, Tony Q. S. Quek, Zhongding Lei,", "date": "2015-1-28"}, 
{"urllink": "http://arxiv.org/abs/1501.06964", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06964", "title": "\nLearning Analytics: A Survey", "abstract": "Learning analytics is a research topic that is gaining increasing popularity in recent time. It analyzes the learning data available in order to make aware or improvise the process itself and/or the outcome such as student performance. In this survey paper, we look at the recent research work that has been conducted around learning analytics, framework and integrated models, and application of various models and data mining techniques to identify students at risk and to predict student performance.", "subjects": "Databases (cs.DB)", "authors": "Usha Keshavamurthy, H. S. Guruprasad,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06954", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06954", "title": "\nStability Analysis of Slotted Aloha with Opportunistic RF Energy  Harvesting", "abstract": "Energy harvesting (EH) is a promising technology for realizing energy efficient wireless networks. In this paper, we utilize the ambient RF energy, particularly interference from neighboring transmissions, to replenish the batteries of the EH enabled nodes. However, RF energy harvesting imposes new challenges into the design of wireless networks. In this work, we investigate the performance of a slotted Aloha random access wireless network consisting of two types of nodes, namely type I which has unlimited energy supply and type II which is solely powered by an RF energy harvesting circuit. The transmissions of a type I node are recycled by a type II node to replenish its battery. Our contribution in this paper is multi-fold. First, we generalize the stochastic dominance technique for analyzing RF EH-networks. Second, we characterize an outer bound on the stable throughput region of RF EH-networks under the half-duplex and full-duplex energy harvesting paradigms. Third, we investigate the impact of finite capacity batteries on the stable throughput region. Finally, we derive the closure of the outer bound over all transmission probability vectors.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Abdelrahman M.Ibrahim, Ozgur Ercetin, Tamer ElBatt,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06946", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06946", "title": "\nNew Bounds on Optimal Sorting Networks", "abstract": "We present new parallel sorting networks for to inputs. For and inputs these new networks are faster (i.e., they require less computation steps) than the previously known best networks. Therefore, we improve upon the known upper bounds for minimal depth sorting networks on and channels. Furthermore, we show that our sorting network for inputs is optimal in the sense that no sorting network using less layers exists. This solves the main open problem of [D. Bundala &amp; J. Za 'vodn 'y. Optimal sorting networks, Proc. LATA 2014].", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Thorsten Ehlers, Mike M\u00fcller,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06941", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06941", "title": "\nThe Economy of Internet-Based Hospitality Exchange", "abstract": "In this paper, we analyze and compare general development and individual behavior on two non-profit internet-based hospitality exchange services -- bewelcome.org and warmshowers.org. We measure the effort needed to achieve a real-life interaction, whereby the advantages of mutual altruism arise. The effort needed is the communication quantified in units of time. Since the amount of effort is not obvious to individual users, the development of the effort investing strategy is investigated. The impact of individual behavior on general development is discussed.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Rustam Tagiew,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06907", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06907", "title": "\nJMS: A workflow management system and web-based cluster front-end for  the Torque resource manager", "abstract": "Motivation: Complex computational pipelines are becoming a staple of modern scientific research. Often these pipelines are resource intensive and require days of computing time. In such cases, it makes sense to run them over distributed computer clusters where they can take advantage of the aggregated resources of many powerful computers. In addition to this, researchers often want to integrate their workflows into their own web servers. In these cases, software is needed to manage the submission of jobs from the web interface to the cluster and then return the results once the job has finished executing. Results: We have developed the Job Management System (JMS), a workflow management system and interface for the Torque resource manager. The JMS provides users with a user-friendly interface for creating complex workflows with multiple stages. It integrates this workflow functionality with Torque, a tool that is used to control and manage batch jobs on distributed computing clusters. The JMS can be used by researchers to build and run complex computational pipelines and provides functionality to include these pipelines in external interfaces. The JMS is currently being used to house a number of structural bioinformatics pipelines at the Research Unit in Bioinformatics (RUBi) at Rhodes University. Availability: The JMS is an open-source project and is freely available at this https URL", "subjects": "Software Engineering (cs.SE)", "authors": "David K. Brown, Thommas M. Musyoka, David L. Penkler, \u00d6zlem Tastan Bishop,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06873", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06873", "title": "\nTruss Analysis Discussion and Interpretation Using Linear Systems of  Equalities and Inequalities", "abstract": "This paper shows the complementary roles of mathematical and engineering points of view when dealing with truss analysis problems involving systems of linear equations and inequalities. After the compatibility condition and the mathematical structure of the general solution of a system of linear equations is discussed, the truss analysis problem is used to illustrate its mathematical and engineering multiple aspects, including an analysis of the compatibility conditions and a physical interpretation of the general solution, and the generators of the resulting affine space. Next, the compatibility and the mathematical structure of the general solution of linear systems of inequalities are analyzed and the truss analysis problem revisited adding some inequality constraints, and discussing how they affect the resulting general solution and many other aspects of it. Finally, some conclusions are drawn.", "subjects": "Computational Engineering, Finance, and Science (cs.CE)", "authors": "R. M\u00ednguez, E. Castillo, R. Pruneda, C. Solares,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06864", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06864", "title": "\nSelf-Calibration and Biconvex Compressive Sensing", "abstract": "The design of high-precision sensing devises becomes ever more difficult and expensive. At the same time, the need for precise calibration of these devices (ranging from tiny sensors to space telescopes) manifests itself as a major roadblock in many scientific and technological endeavors. To achieve optimal performance of advanced high-performance sensors one must carefully calibrate them, which is often difficult or even impossible to do in practice. In this work we bring together three seemingly unrelated concepts, namely Self-Calibration, Compressive Sensing, and Biconvex Optimization. The idea behind self-calibration is to equip a hardware device with a smart algorithm that can compensate automatically for the lack of calibration. We show how several self-calibration problems can be treated efficiently within the framework of biconvex compressive sensing via a new method called SparseLift. More specifically, we consider a linear system of equations y = DAx, where both x and the diagonal matrix D (which models the calibration error) are unknown. By \"lifting\" this biconvex inverse problem we arrive at a convex optimization problem. By exploiting sparsity in the signal model, we derive explicit theoretical guarantees under which both x and D can be recovered exactly, robustly, and numerically efficiently via linear programming. Applications in array calibration and wireless communications are discussed and numerical simulations are presented, confirming and complementing our theoretical analysis.", "subjects": "Information Theory (cs.IT)", "authors": "Shuyang Ling, Thomas Strohmer,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06862", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06862", "title": "\nFactorization of Rational Motions: A Survey with Examples and  Applications", "abstract": "Since its introduction in 2012, the factorization theory for rational motions quickly evolved and found applications in theoretical and applied mechanism science. We provide an accessible introduction to motion factorization with many examples, summarize recent developments and hint at some new applications. In particular, we provide pseudo-code for the generic factorization algorithm, demonstrate how to find a replacement linkage for a special case in the synthesis of Bennett mechanisms and, as an example of non-generic factorization, synthesize open chains for circular and elliptic translations.", "subjects": "Robotics (cs.RO)", "authors": "Zijia Li, Tudor-Dan Rad, Josef Schicho, Hans-Peter Schr\u00f6cker,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06857", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06857", "title": "\nMeasuring the local GitHub developer community", "abstract": "Creating rankings might seem like a vain exercise in belly-button gazing, even more so for people so unlike that kind of things as programmers. However, in this paper we will try to prove how creating city (or province) based rankings in Spain has led to all kind of interesting effects, including increased productivity and community building. We describe the methodology we have used to search for programmers residing in a particular province focusing on those where most population is concentrated and apply different measures to show how these communities differ in structure, number and productivity.", "subjects": "Social and Information Networks (cs.SI)", "authors": "J.J. Merelo, Nuria Rico, Israel Blancas, M. G. Arenas, Fernando Tricas, Jos\u00e9 Antonio Vacas,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06851", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06851", "title": "\nDistributed Power Allocations in Heterogeneous Networks with Dual  Connectivity using Backhaul State Information", "abstract": "LTE release 12 proposes the use of dual connectivity in heterogeneous cellular networks, where a user equipment (UE) maintains parallel connections to a macro-cell node (base station) and to a low-tier node (pico base station or relay). In this paper, we propose a distributed multi-objective power control scheme where each UE independently adapts its transmit power on its dual connections, possibly of unequal bandwidth, with non-ideal backhaul links. In the proposed scheme, the UEs can dynamically switch their objectives between data rate maximization and transmit power minimization as the backhaul load varies. Given the coupling between interference and the backhaul load, we propose a low-overhead convergence mechanism which does not require explicit coordination between autonomous nodes and also derive a closed-form expression of the transmit power levels at equilibrium. We illustrate a higher aggregate end-to-end data rate and significant power saving for our scheme over when the optimization is implemented through a greedy algorithm or when UEs only perform waterfilling.", "subjects": "Information Theory (cs.IT)", "authors": "Syed Amaar Ahmad, Dinesh Datla,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06841", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06841", "title": "\nA Canonical Form for Weighted Automata and Applications to Approximate  Minimization", "abstract": "We study the problem of constructing approximations to a weighted automaton. Weighted finite automata (WFA) are closely related to the theory of rational series. A rational series is a function from strings to real numbers that can be computed by a finite WFA. Among others, this includes probability distributions generated by hidden Markov models and probabilistic automata. The relationship between rational series and WFA is analogous to the relationship between regular languages and ordinary automata. Associated with such rational series are infinite matrices called Hankel matrices which play a fundamental role in the theory of minimal WFA. Our contributions are: (1) an effective procedure for computing the singular value decomposition (SVD) of such infinite Hankel matrices based on their representation in terms of finite WFA; (2) a new canonical form for finite WFA based on this SVD decomposition; and, (3) an algorithm to construct approximate minimizations of a given WFA. The goal of our approximate minimization algorithm is to start from a minimal WFA and produce a smaller WFA that is close to the given one in a certain sense. The desired size of the approximating automaton is given as input. We give bounds describing how well the approximation emulates the behavior of the original WFA.", "subjects": "Formal Languages and Automata Theory (cs.FL)", "authors": "Borja Balle, Prakash Panangaden, Doina Precup,", "date": "2015-1-7"}, 
{"urllink": "http://arxiv.org/abs/1501.06814", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06814", "title": "\nSpatio-Temporal Techniques for User Identification by means of GPS  Mobility Data", "abstract": "One of the greatest concerns related to the popularity of GPS-enabled devices and applications is the increasing availability of the personal location information generated by them and shared with application and service providers. Moreover, people tend to have regular routines and be characterized by a set of \"significant places\", thus making it possible to identify a user from his/her mobility data. In this paper we present a series of techniques for identifying individuals from their GPS movements. More specifically, we study the uniqueness of GPS information for three popular datasets, and we provide a detailed analysis of the discriminatory power of speed, direction and distance of travel. Most importantly, we present a simple yet effective technique for the identification of users from location information that are not included in the original dataset used for training, thus raising important privacy concerns for the management of location datasets.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Luca Rossi, James Walker, Mirco Musolesi,", "date": "2015-1-7"}, 
{"urllink": "http://arxiv.org/abs/1501.06813", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06813", "title": "\nMixed Map Labeling", "abstract": "Point feature map labeling is a geometric problem, in which a set of input points must be labeled with a set of disjoint rectangles (the bounding boxes of the label texts). Typically, labeling models either use internal labels, which must touch their feature point, or external (boundary) labels, which are placed on one of the four sides of the input points' bounding box and which are connected to their feature points by crossing-free leader lines. In this paper we study polynomial-time algorithms for maximizing the number of internal labels in a mixed labeling model that combines internal and external labels. The model requires that all leaders are parallel to a given orientation , whose value influences the geometric properties and hence the running times of our algorithms.", "subjects": "Computational Geometry (cs.CG)", "authors": "Maarten L\u00f6ffler, Martin N\u00f6llenburg, Frank Staals,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06802", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06802", "title": "\nA Simulation Modeling Approach for Optimization of Storage Space  Allocation in Container Terminal", "abstract": "Container handling problems at container terminals are NP-hard problems. This paper presents an approach using discrete-event simulation modeling to optimize solution for storage space allocation problem, taking into account all various interrelated container terminal handling activities. The proposed approach is applied on a real case study data of container terminal at Alexandria port. The computational results show the effectiveness of the proposed model for optimization of storage space allocation in container terminal where 54% reduction in containers handling time in port is achieved.", "subjects": "Other Computer Science (cs.OH)", "authors": "Gamal Abd El-Nasser A. Said, El-Sayed M. El-Horbaty,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06783", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06783", "title": "\nBig Data on the Rise: Testing monotonicity of distributions", "abstract": "The field of property testing of probability distributions, or distribution testing, aims to provide fast and (most likely) correct answers to questions pertaining to specific aspects of very large datasets. In this work, we consider a property of particular interest, monotonicity of distributions. We focus on the complexity of monotonicity testing across different models of access to the distributions; and obtain results in these new settings that differ significantly from the known bounds in the standard sampling model.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Cl\u00e9ment L. Canonne,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06781", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06781", "title": "\nError and Erasure Exponents for the Broadcast Channel with Degraded  Message Sets", "abstract": "Error and erasure exponents for the broadcast channel with degraded message sets are analyzed. The focus of our error probability analysis is on the main receiver where, nominally, both messages are to be decoded. A two-step decoding algorithm is proposed and analyzed. This receiver first attempts to decode both messages, failing which, it attempts to decode only the message representing the coarser information, i.e., the cloud center. This algorithm reflects the intuition that we should decode both messages only if we have confidence in the estimates; otherwise one should only decode the coarser information. The resulting error and erasure exponents, derived using the method of types, are expressed in terms of a penalized form of the modified random coding error exponent.", "subjects": "Information Theory (cs.IT)", "authors": "Vincent Y. F. Tan,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06774", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06774", "title": "\nMaximum Common Subelement Metrics and its Applications to Graphs", "abstract": "In this paper we characterize a mathematical model called Maximum Common Subelement (MCS) Model and prove the existence of four different metrics on such model. We generalize metrics on graphs previously proposed in the literature and identify new ones by showing three different examples of MCS Models on graphs based on (1) subgraphs, (2) induced subgraphs and (3) an extended notion of subgraphs. This latter example can be used to model graphs with complex labels (e.g., graphs whose labels are other graphs), and hence to derive metrics on them. Furthermore, we also use (3) to show that graph edit distance, when a metric, is related to a maximum common subelement in a corresponding MCS Model.", "subjects": "Discrete Mathematics (cs.DM)", "authors": "Lauro Lins, Nivan Ferreira, Juliana Freire, Claudio Silva,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06758", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06758", "title": "\nAssignment of Different-Sized Inputs in MapReduce", "abstract": "A MapReduce algorithm can be described by a mapping schema, which assigns inputs to a set of reducers, such that for each required output there exists a reducer that receives all the inputs that participate in the computation of this output. Reducers have a capacity, which limits the sets of inputs that they can be assigned. However, individual inputs may vary in terms of size. We consider, for the first time, mapping schemas where input sizes are part of the considerations and restrictions. One of the significant parameters to optimize in any MapReduce job is communication cost between the map and reduce phases. The communication cost can be optimized by minimizing the number of copies of inputs sent to the reducers. The communication cost is closely related to the number of reducers of constrained capacity that are used to accommodate appropriately the inputs, so that the requirement of how the inputs must meet in a reducer is satisfied. In this work, we consider a family of problems where it is required that each input meets with each other input in at least one reducer. We also consider a slightly different family of problems in which, each input of a set, X, is required to meet each input of another set, Y, in at least one reducer. We prove that finding an optimal mapping schema for these families of problem is NP-hard, and present several approximation algorithms for finding a near optimal mapping schema.", "subjects": "Databases (cs.DB)", "authors": "Foto Afrati, Shlomi Dolev, Ephraim Korach, Shantanu Sharma, Jeffrey D. Ullman,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06751", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06751", "title": "\nA Cheap System for Vehicle Speed Detection", "abstract": "The reliable detection of speed of moving vehicles is considered key to traffic law enforcement in most countries, and is seen by many as an important tool to reduce the number of traffic accidents and fatalities. Many automatic systems and different methods are employed in different countries, but as a rule they tend to be expensive and/or labor intensive, often employing outdated technology due to the long development time. Here we describe a speed detection system that relies on simple everyday equipment - a laptop and a consumer web camera. Our method is based on tracking the license plates of cars, which gives the relative movement of the cars in the image. This image displacement is translated to actual motion by using the method of projection to a reference plane, where the reference plane is the road itself. However, since license plates do not touch the road, we must compensate for the entailed distortion in speed measurement. We show how to compute the compensation factor using knowledge of the license plate standard dimensions. Consequently our system computes the true speed of moving vehicles fast and accurately. We show promising results on videos obtained in a number of scenes and with different car models.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Chaim Ginzburg, Amit Raphael, Daphna Weinshall,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06743", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06743", "title": "\nEnhancing the performance of Decoupled Software Pipeline through  Backward Slicing", "abstract": "The rapidly increasing number of cores available in multicore processors does not necessarily lead directly to a commensurate increase in performance: programs written in conventional languages, such as C, need careful restructuring, preferably automatically, before the benefits can be observed in improved run-times. Even then, much depends upon the intrinsic capacity of the original program for concurrent execution. The subject of this paper is the performance gains from the combined effect of the complementary techniques of the Decoupled Software Pipeline (DSWP) and (backward) slicing. DSWP extracts threadlevel parallelism from the body of a loop by breaking it into stages which are then executed pipeline style: in effect cutting across the control chain. Slicing, on the other hand, cuts the program along the control chain, teasing out finer threads that depend on different variables (or locations). parts that depend on different variables. The main contribution of this paper is to demonstrate that the application of DSWP, followed by slicing offers notable improvements over DSWP alone, especially when there is a loop-carried dependence that prevents the application of the simpler DOALL optimization. Experimental results show an improvement of a factor of ?1.6 for DSWP + slicing over DSWP alone and a factor of ?2.4 for DSWP + slicing over the original sequential code.", "subjects": "Programming Languages (cs.PL)", "authors": "Esraa Alwan, John Fitch, Julian Padget,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06741", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06741", "title": "\nA simple approach to the numerical simulation with trimmed CAD surfaces", "abstract": "In this work a novel method for the analysis with trimmed CAD surfaces is presented. The method involves an additional mapping step and the attraction stems from its sim- plicity and ease of implementation into existing Finite Element (FEM) or Boundary Element (BEM) software. The method is first verified with classical test examples in structural mechanics. Then two practical applications are presented one using the FEM, the other the BEM, that show the applicability of the method.", "subjects": "Numerical Analysis (cs.NA)", "authors": "Gernot Beer, Benjamin Marussig, J\u00fcrgen Zechner,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06736", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06736", "title": "\nSpatially-Coupled MacKay-Neal Codes Universally Achieve the Symmetric  Information Rate of Arbitrary Generalized Erasure Channels with Memory", "abstract": "This paper investigates the belief propagation decoding of spatially-coupled MacKay-Neal (SC-MN) codes over erasure channels with memory. We show that SC-MN codes with bounded degree universally achieve the symmetric information rate (SIR) of arbitrary erasure channels with memory. We mean by universality the following sense: the sender does not need to know the whole channel statistics but needs to know only the SIR, while the receiver estimates the transmitted codewords from channel statistics and received words. The proof is based on potential function.", "subjects": "Information Theory (cs.IT)", "authors": "Masaru Fukushima, Takuya Okazaki, Kenta Kasai,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06729", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06729", "title": "\nThe Complexity of the Kth Largest Subset Problem and Related Problems", "abstract": "We show that the Kth largest subset problem and the Kth largest m-tuple problem are in PP and hard for PP under polynomial-time Turing reductions. Several problems from the literature were previously shown NP-hard via reductions from those two problems, and by our main result they become PP-hard as well. We also provide complementary PP-upper bounds for some of them.", "subjects": "Computational Complexity (cs.CC)", "authors": "Christoph Haase, Stefan Kiefer,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06722", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06722", "title": "\nParametric Image Segmentation of Humans with Structural Shape Priors", "abstract": "The figure-ground segmentation of humans in images captured in natural environments is an outstanding open problem due to the presence of complex backgrounds, articulation, varying body proportions, partial views and viewpoint changes. In this work we propose class-specific segmentation models that leverage parametric max-flow image segmentation and a large dataset of human shapes. Our contributions are as follows: (1) formulation of a sub-modular energy model that combines class-specific structural constraints and data-driven shape priors, within a parametric max-flow optimization methodology that systematically computes all breakpoints of the model in polynomial time; (2) design of a data-driven class-specific fusion methodology, based on matching against a large training set of exemplar human shapes (100,000 in our experiments), that allows the shape prior to be constructed on-the-fly, for arbitrary viewpoints and partial views. (3) demonstration of state of the art results, in two challenging datasets, H3D and MPII (where figure-ground segmentation annotations have been added by us), where we substantially improve on the first ranked hypothesis estimates of mid-level segmentation methods, by 20%, with hypothesis set sizes that are up to one order of magnitude smaller.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Alin-Ionut Popa, Cristian Sminchisescu,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06721", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06721", "title": "\nMassively-concurrent Agent-based Evolutionary Computing", "abstract": "The fusion of the multi-agent paradigm with evolutionary computation yielded promising results in many optimization problems. Evolutionary multi-agent system (EMAS) are more similar to biological evolution than classical evolutionary algorithms. However, technological limitations prevented the use of fully asynchronous agents in previous EMAS implementations. In this paper we present a new algorithm for agent-based evolutionary computations. The individuals are represented as fully autonomous and asynchronous agents. An efficient implementation of this algorithm was possible through the use of modern technologies based on functional languages (namely Erlang and Scala), which natively support lightweight processes and asynchronous communication. Our experiments show that such an asynchronous approach is both faster and more efficient in solving common optimization problems.", "subjects": "Multiagent Systems (cs.MA)", "authors": "D. Krzywicki, W. Turek, A. Byrski, M. Kisiel-Dorohinicki,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06716", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06716", "title": "\nA General Preprocessing Method for Improved Performance of Epipolar  Geometry Estimation Algorithms", "abstract": "In this paper a deterministic preprocessing algorithm is presented, whose output can be given as input to most state-of-the-art epipolar geometry estimation algorithms, improving their results considerably. They are now able to succeed on hard cases for which they failed before. The algorithm consists of three steps, whose scope changes from local to global. In the local step it extracts from a pair of images local features (e.g. SIFT). Similar features from each image are clustered and the clusters are matched yielding a large number of putative matches. In the second step pairs of spatially close features (called 2keypoints) are matched and ranked by a classifier. The 2keypoint matches with the highest ranks are selected. In the global step, from each two 2keypoint matches a fundamental matrix is computed. As quite a few of the matrices are generated from correct matches they are used to rank the putative matches found in the first step. For each match the number of fundamental matrices, for which it approximately satisfies the epipolar constraint, is calculated. This set of matches is combined with the putative matches generated by standard methods and their probabilities to be correct are estimated by a classifier. These are then given as input to state-of-the-art epipolar geometry estimation algorithms such as BEEM, BLOGS and USAC yielding much better results than the original algorithms. This was shown in extensive testing performed on almost 900 image pairs from six publicly available data-sets.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "authors": "Maria Kushnir, Ilan Shimshoni,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06715", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06715", "title": "\nTime Aware Knowledge Extraction for Microblog Summarization on Twitter", "abstract": "Microblogging services like Twitter and Facebook collect millions of user generated content every moment about trending news, occurring events, and so on. Nevertheless, it is really a nightmare to find information of interest through the huge amount of available posts that are often noise and redundant. In general, social media analytics services have caught increasing attention from both side research and industry. Specifically, the dynamic context of microblogging requires to manage not only meaning of information but also the evolution of knowledge over the timeline. This work defines Time Aware Knowledge Extraction (briefly TAKE) methodology that relies on temporal extension of Fuzzy Formal Concept Analysis. In particular, a microblog summarization algorithm has been defined filtering the concepts organized by TAKE in a time-dependent hierarchy. The algorithm addresses topic-based summarization on Twitter. Besides considering the timing of the concepts, another distinguish feature of the proposed microblog summarization framework is the possibility to have more or less detailed summary, according to the user's needs, with good levels of quality and completeness as highlighted in the experimental results.", "subjects": "Information Retrieval (cs.IR)", "authors": "Carmen De Maio, Giuseppe Fenza, Vincenzo Loia, Mimmo Parente,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06705", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06705", "title": "\nInclusion within Continuous Belief Functions", "abstract": "Defining and modeling the relation of inclusion between continuous belief function may be considered as an important operation in order to study their behaviors. Within this paper we will propose and present two forms of inclusion: The strict and the partial one. In order to develop this relation, we will study the case of consonant belief function. To do so, we will simulate normal distributions allowing us to model and analyze these relations. Based on that, we will determine the parameters influencing and characterizing the two forms of inclusion.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Dorra Attiaoui, Pierre-Emmanuel Dor\u00e9, Arnaud Martin, Boutheina Ben Yaghlane,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06698", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06698", "title": "\nOn Error Correction for Physical Unclonable Functions", "abstract": "Physical Unclonable Functions evaluate manufacturing variations to generate secure cryptographic keys for embedded systems without secure key storage. It is explained how methods from coding theory are applied in order to ensure reliable key reproduction. We show how better results can be obtained using code classes and decoding principles not used for this scenario before. These methods are exemplified by specific code constructions which improve existing codes with respect to error probability, decoding complexity and codeword length.", "subjects": "Information Theory (cs.IT)", "authors": "Sven Puchinger, Sven M\u00fcelich, Martin Bossert, Matthias Hiller, Georg Sigl,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06689", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06689", "title": "\nGeneral-Purpose Join Algorithms for Listing Triangles in Large Graphs", "abstract": "We investigate applying general-purpose join algorithms to the triangle listing problem in an out-of-core context. In particular, we focus on Leapfrog Triejoin (LFTJ) by Veldhuizen 2014, a recently proposed, worst-case optimal algorithm. We present \"boxing\": a novel, yet conceptually simple, approach for feeding input data to LFTJ. Our extensive analysis shows that this approach is I/O efficient, being worst-case optimal (in a certain sense). Furthermore, if input data is only a constant factor larger than the available memory, then a boxed LFTJ essentially maintains the CPU data-complexity of the vanilla LFTJ. Next, focusing on LFTJ applied to the triangle query, we show that for many graphs boxed LFTJ matches the I/O complexity of the recently by Hu, Tao and Yufei proposed specialized algorithm MGT for listing tiangles in an out-of-core setting. We also strengthen the analysis of LFTJ's computational complexity for the triangle query by considering families of input graphs that are characterized not only by the number of edges but also by a measure of their density. E.g., we show that LFTJ achieves a CPU complexity of O(|E|log|E|) for planar graphs, while on general graphs, no algorithm can be faster than O(|E|^). Finally, we perform an experimental evaluation for the triangle listing problem confirming our theoretical results and showing the overall effectiveness of our approach. On all our real-world and synthetic data sets (some of which containing more than 1.2 billion edges) LFTJ in single-threaded mode is within a factor of 3 of the specialized MGT; a penalty that---as we demonstrate---can be alleviated by parallelization.", "subjects": "Databases (cs.DB)", "authors": "Daniel Zinn,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06686", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06686", "title": "\nReduced Complexity Decoding of n x n Algebraic Space-Time Codes", "abstract": "Algebraic space-time coding allows for reliable data exchange across fading multiple-input multiple-output channels. A powerful technique for decoding space-time codes in Maximum-Likelihood (ML) decoding, but well-performing and widely-used codes such as the Golden code often suffer from high ML-decoding complexity. In this article, a recursive algorithm for decoding general algebraic space-time codes of arbitrary dimension is proposed, which reduces the worst-case decoding complexity from to .", "subjects": "Information Theory (cs.IT)", "authors": "Amaro Barreal, Camilla Hollanti, David Karpuk,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06683", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06683", "title": "\nCodes With Hierarchical Locality", "abstract": "In this paper, we study the notion of that is identified as another approach to local recovery from multiple erasures. The well-known class of is said to possess hierarchical locality with a single level. In a , every symbol is protected by an inner-most local code, and another middle-level code of larger dimension containing the local code. We first consider codes with two levels of hierarchical locality, derive an upper bound on the minimum distance, and provide optimal code constructions of low field-size under certain parameter sets. Subsequently, we generalize both the bound and the constructions to hierarchical locality of arbitrary levels.", "subjects": "Information Theory (cs.IT)", "authors": "Birenjith Sasidharan, Gaurav Kumar Agarwal, P. Vijay Kumar,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06678", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06678", "title": "\nEdge Agreement of Multi-agent System with Quantized Measurements via  Directed Edge Laplacian", "abstract": "This work explores the edge agreement problem of the second-order nonlinear multi-agent system under quantized measurements. To begin with, the general concepts of weighted edge Laplacian of directed graph are proposed and its algebraic properties are further explored. Based on the essential edge Laplacian, we derive a model reduction representation of the closed-loop multi-agent system based on the spanning tree subgraph. Meanwhile, the edge agreement problem of second-order nonlinear multi-agent system under quantized effects is studied, in which both uniform and logarithmic quantizers are considered. Particularly, for the uniform quantizers, we provide the upper bound of the radius of the agreement neighborhood, which indicates that the radius increases with the quantization interval. While for the logarithmic quantizers, the agents converge exponentially to the desired agreement equilibrium. Additionally, we also provide the estimates of the convergence rate as well as indicate that the coarser the quantizer is, the slower the convergence speed. Finally, simulation results are given to verify the theoretical analysis.", "subjects": "Systems and Control (cs.SY)", "authors": "Zhiwen Zeng, Xiangke Wang, Zhiqiang Zheng,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06671", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06671", "title": "\nThe Gaussian Channel with Noisy Feedback: Improving Reliability via  Interaction", "abstract": "Consider a pair of terminals connected by two independent (feedforward and feedback) Additive White Gaussian Noise (AWGN) channels, and limited by individual power constraints. The first terminal would like to reliably send information to the second terminal at a given rate. While the reliability in the cases of no feedback and of noiseless feedback is well studied, not much is known about the case of noisy feedback. In this work, we present an interactive scheme that significantly improves the reliability relative to the no-feedback setting, whenever the feedback Signal to Noise Ratio (SNR) is sufficiently larger than the feedforward SNR. The scheme combines Schalkwijk-Kailath (S-K) coding and modulo--lattice analog transmission.", "subjects": "Information Theory (cs.IT)", "authors": "Assaf Ben-Yishai, Ofer Shayevitz,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06663", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06663", "title": "\nOn Longest Repeat Queries Using GPU", "abstract": "Repeat finding in strings has important applications in subfields such as computational biology. The challenge of finding the longest repeats covering particular string positions was recently proposed and solved by .leri et al., using a total of the optimal time and space, where is the string size. However, their solution can only find the emph longest repeat for each of the string position. It is also not known how to parallelize their solution. In this paper, we propose a new solution for longest repeat finding, which although is theoretically suboptimal in time but is conceptually simpler and works faster and uses less memory space in practice than the optimal solution. Further, our solution can find emph longest repeats of every string position, while still maintaining a faster processing speed and less memory space usage. Moreover, our solution is emph in the shared memory architecture (SMA), enabling it to take advantage of the modern multi-processor computing platforms such as the general-purpose graphics processing units (GPU). We have implemented both the sequential and parallel versions of our solution. Experiments with both biological and non-biological data show that our sequential and parallel solutions are faster than the optimal solution by a factor of 2--3.5 and 6--14, respectively, and use less memory space.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Yun Tian, Bojian Xu,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06662", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06662", "title": "\nA High-Rate MSR Code With Polynomial Sub-Packetization Level", "abstract": "We present a high-rate -MSR code with a sub-packetization level that is polynomial in the dimension of the code. While polynomial sub-packetization level was achieved earlier for vector MDS codes that repair systematic nodes optimally, no such MSR code construction is known. In the low-rate regime (i. e., rates less than one-half), MSR code constructions with a linear sub-packetization level are available. But in the high-rate regime (i. e., rates greater than one-half), the known MSR code constructions required a sub-packetization level that is exponential in . In the present paper, we construct an MSR code for with a fixed rate achieveing a sub-packetization level . The code allows help-by-transfer repair, i. e., no computations are needed at the helper nodes during repair of a failed node.", "subjects": "Information Theory (cs.IT)", "authors": "Birenjith Sasidharan, Gaurav Kumar Agarwal, P. Vijay Kumar,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06654", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06654", "title": "\nCompressive Sampling of Ensembles of Correlated Signals", "abstract": "We propose several sampling architectures for the efficient acquisition of an ensemble of correlated signals. We show that without prior knowledge of the correlation structure, each of our architectures (under different sets of assumptions) can acquire the ensemble at a sub-Nyquist rate. Prior to sampling, the analog signals are diversified using simple, implementable components. The diversification is achieved by injecting types of \"structured randomness\" into the ensemble, the result of which is subsampled. For reconstruction, the ensemble is modeled as a low-rank matrix that we have observed through an (undetermined) set of linear equations. Our main results show that this matrix can be recovered using standard convex programming techniques when the total number of samples is on the order of the intrinsic degree of freedom of the ensemble --- the more heavily correlated the ensemble, the fewer samples are needed. To motivate this study, we discuss how such ensembles arise in the context of array processing.", "subjects": "Information Theory (cs.IT)", "authors": "Ali Ahmed, Justin Romberg,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06647", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06647", "title": "\nEnergy Efficient Broadcast in Mobile Networks Subject to Channel  Randomness", "abstract": "Wireless communication in a network of mobile devices is a challenging and resource demanding task, due to the highly dynamic network topology and the wireless channel randomness. This paper investigates information broadcast schemes in 2D mobile ad-hoc networks where nodes are initially randomly distributed and then move following a random direction mobility model. Based on an in-depth analysis of the popular Susceptible-Infectious-Recovered epidemic broadcast scheme, this paper proposes a novel energy and bandwidth efficient broadcast scheme, named the energy-efficient broadcast scheme, which is able to adapt to fast-changing network topology and channel randomness. Analytical results are provided to characterize the performance of the proposed scheme, including the fraction of nodes that can receive the information and the delay of the information dissemination process. The accuracy of analytical results is verified using simulations driven by both the random direction mobility model and a real world trace.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Zijie Zhang, Guoqiang Mao, Brian Anderson,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06633", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06633", "title": "\nmaxDNN: An Efficient Convolution Kernel for Deep Learning with Maxwell  GPUs", "abstract": "This paper describes maxDNN, a computationally efficient convolution kernel for deep learning with the NVIDIA Maxwell GPU. maxDNN reaches 96.3% computational efficiency on typical deep learning network architectures. The design combines ideas from cuda-convnet2 with the Maxas SGEMM assembly code. We only address forward propagation (FPROP) operation of the network, but we believe that the same techniques used here will be effective for backward propagation (BPROP) as well.", "subjects": "Neural and Evolutionary Computing (cs.NE)", "authors": "Andrew Lavin,", "date": "2015-1-7"}, 
{"urllink": "http://arxiv.org/abs/1501.06627", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06627", "title": "\nCompetitive Equilibrium with Equal Incomes for Allocation of Indivisible  Objects", "abstract": "In AAMAS 2014, Bouveret and Lemaitre (2014) presented a hierarchy of fairness concepts for allocation of indivisible objects. Among them CEEI (Competitive Equilibrium with Equal Incomes) was the strongest. In this note, we settle the complexity of computing a discrete CEEI assignment by showing it is strongly NP-hard. We then highlight a fairness notion (CEEI-FRAC) that is even stronger than CEEI for discrete assignments, is always Pareto optimal, and can be verified in polynomial time. We also show that computing a CEEI-FRAC discrete assignment is strongly NP-hard in general but polynomial-time computable if the utilities are zero or one.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Haris Aziz,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06626", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06626", "title": "\nManipulating the Probabilistic Serial Rule", "abstract": "The probabilistic serial (PS) rule is one of the most prominent randomized rules for the assignment problem. It is well-known for its superior fairness and welfare properties. However, PS is not immune to manipulative behaviour by the agents. We initiate the study of the computational complexity of an agent manipulating the PS rule. We show that computing an expected utility better response is NP- hard. On the other hand, we present a polynomial-time algorithm to compute a lexicographic best response. For the case of two agents, we show that even an expected utility best response can be computed in polynomial time. Our result for the case of two agents relies on an interesting connection with sequential allocation of discrete objects.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Haris Aziz, Serge Gaspers, Simon Mackenzie, Nicholas Mattei, Nina Narodytska, Toby Walsh,", "date": "2015-1-27"}, 
{"urllink": "http://arxiv.org/abs/1501.06625", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06625", "title": "\nAccelerating Polynomial Homotopy Continuation on a Graphics Processing  Unit with Double Double and Quad Double Arithmetic", "abstract": "Numerical continuation methods apply predictor-corrector algorithms to track a solution path defined by a family of systems, the so-called homotopy. The systems we consider are defined by polynomials in several variables with complex coefficients. For larger dimensions and degrees, the numerical conditioning worsens and hardware double precision becomes often insufficient to reach the end of the solution path. With double double and quad double arithmetic, we can solve larger problems that we could not solve with hardware double arithmetic, but at a higher computational cost. This cost overhead can be compensated by acceleration on a Graphics Processing Unit (GPU). We describe our implementation and report on computational results on two benchmark polynomial systems. In case the linear algebra dominates the total computational cost of a path tracker, the dimension needs to be of the order of at least several hundreds to offset the computational overhead caused by double double arithmetic. For general polynomials of higher degrees, when evaluating and differentiating the polynomials is computationally expensive, already in smaller dimensions, acceleration may offset the cost of higher precision arithmetic.", "subjects": "Mathematical Software (cs.MS)", "authors": "Jan Verschelde, Xiangcheng Yu,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06619", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06619", "title": "\nConstructing LZ78 Tries and Position Heaps in Linear Time for Large  Alphabets", "abstract": "We present the first worst-case linear-time algorithm to compute the Lempel-Ziv 78 factorization of a given string over an integer alphabet. Our algorithm is based on nearest marked ancestor queries on the suffix tree of the given string. We also show that the same technique can be used to construct the position heap of a set of strings in worst-case linear time, when the set of strings is given as a trie.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Yuto Nakashima, Tomohiro I, Shunsuke Inenaga, Hideo Bannai, Masayuki Takeda,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06618", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06618", "title": "\nA Simple Observer for Gyro and Accelerometer Biases in Land Navigation  Systems", "abstract": "In various applications of land vehicle navigation and automatic guidance systems, Global Navigation Satellite System/Inertial Measurement Unit (GNSS/IMU) positioning performance crucially depends on the attitude determination accuracy affected by gyro and accelerometer bias instabilities. Traditional bias estimation approaches based on the Kalman filter suffer from implementation complexity and require non-intuitive tuning procedures. In this paper we propose, as an alternative, a simple observer that estimates inertial sensor biases exclusively in terms of quantities with obvious geometrical meaning. By this, any multidimensional vector-matrix operations are avoided and observer tuning is substantially simplified. The observer has been successfully tested in a farming vehicle navigation system.", "subjects": "Systems and Control (cs.SY)", "authors": "Vasiliy M. Tereshkov,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06614", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06614", "title": "\nApproximation Algorithms for Reducing the Spectral Radius to Control  Epidemic Spread", "abstract": "The largest eigenvalue of the adjacency matrix of a network (referred to as the spectral radius) is an important metric in its own right. Further, for several models of epidemic spread on networks (e.g., the `flu-like' SIS model), it has been shown that an epidemic dies out quickly if the spectral radius of the graph is below a certain threshold that depends on the model parameters. This motivates a strategy to control epidemic spread by reducing the spectral radius of the underlying network. In this paper, we develop a suite of provable approximation algorithms for reducing the spectral radius by removing the minimum cost set of edges (modeling quarantining) or nodes (modeling vaccinations), with different time and quality tradeoffs. Our main algorithm, textsc, is based on the idea of hitting closed walks of a given length, and gives an -approximation, where denotes the number of nodes; it also performs much better in practice compared to all prior heuristics proposed for this problem. We further present a novel sparsification method to improve its running time. In addition, we give a new primal-dual based algorithm with an even better approximation guarantee (), albeit with slower running time. We also give lower bounds on the worst-case performance of some of the popular heuristics. Finally we demonstrate the applicability of our algorithms and the properties of our solutions via extensive experiments on multiple synthetic and real networks.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Sudip Saha, Abhijin Adiga, B. Aditya Prakash, Anil Kumar S. Vullikanti,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06613", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06613", "title": "\nAdaptive Robust Transmission Network Expansion Planning using Structural  Reliability and Decomposition Techniques", "abstract": "Structural reliability and decomposition techniques have recently proved to be appropriate tools for solving robust uncertain mixed-integer linear programs using ellipsoidal uncertainty sets. In fact, its computational performance makes this type of problem to be an alternative method in terms of tractability with respect to robust problems based on cardinality constrained uncertainty sets. This paper extends the use of these techniques for solving an adaptive robust optimization (ARO) problem, i.e. the adaptive robust solution of the transmission network expansion planning for energy systems. The formulation of this type of problem materializes on a three-level mixed-integer optimization formulation, which based on structural reliability methods, can be solved using an ad-hoc decomposition technique. The method allows the use of the correlation structure of the uncertain variables involved by means of their variance-covariance matrix, and besides, it provides a new interpretation of the robust problem based on quantile optimization. We also compare results with respect to robust optimization methods that consider cardinality constrained uncertainty sets. Numerical results on an illustrative example, the IEEE-24 and IEEE 118-bus test systems demonstrate that the algorithm is comparable in terms of computational performance with respect to existing robust methods with the additional advantage that the correlation structure of the uncertain variables involved can be incorporated straightforwardly.", "subjects": "Computational Engineering, Finance, and Science (cs.CE)", "authors": "Roberto M\u00ednguez, Raquel Garc\u00eda-Bertrand, Jos\u00e9 Manuel Arroyo,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06595", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06595", "title": "\nUser Clustering in Online Advertising via Topic Models", "abstract": "In the domain of online advertising, our aim is to serve the best ad to a user who visits a certain webpage, to maximize the chance of a desired action to be performed by this user after seeing the ad. While it is possible to generate a different prediction model for each user to tell if he/she will act on a given ad, the prediction result typically will be quite unreliable with huge variance, since the desired actions are extremely sparse, and the set of users is huge (hundreds of millions) and extremely volatile, i.e., a lot of new users are introduced everyday, or are no longer valid. In this paper we aim to improve the accuracy in finding users who will perform the desired action, by assigning each user to a cluster, where the number of clusters is much smaller than the number of users (in the order of hundreds). Each user will fall into the same cluster with another user if their event history are similar. For this purpose, we modify the probabilistic latent semantic analysis (pLSA) model by assuming the independence of the user and the cluster id, given the history of events. This assumption helps us to identify a cluster of a new user without re-clustering all the users. We present the details of the algorithm we employed as well as the distributed implementation on Hadoop, and some initial results on the clusters that were generated by the algorithm.", "subjects": "Artificial Intelligence (cs.AI)", "authors": "Sahin Cem Geyik, Ali Dasdan, Kuang-Chih Lee,", "date": "2015-1-6"}, 
{"urllink": "http://arxiv.org/abs/1501.06587", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06587", "title": "\nMeasuring academic influence: Not all citations are equal", "abstract": "The importance of a research article is routinely measured by counting how many times it has been cited. However, treating all citations with equal weight ignores the wide variety of functions that citations perform. We want to automatically identify the subset of references in a bibliography that have a central academic influence on the citing paper. For this purpose, we examine the effectiveness of a variety of features for determining the academic influence of a citation. By asking authors to identify the key references in their own work, we created a data set in which citations were labeled according to their academic influence. Using automatic feature selection with supervised machine learning, we found a model for predicting academic influence that achieves good performance on this data set using only four features. The best features, among those we evaluated, were those based on the number of times a reference is mentioned in the body of a citing paper. The performance of these features inspired us to design an influence-primed h-index (the hip-index). Unlike the conventional h-index, it weights citations by how many times a reference is mentioned. According to our experiments, the hip-index is a better indicator of researcher performance than the conventional h-index.", "subjects": "Digital Libraries (cs.DL)", "authors": "Xiaodan Zhu, Peter Turney, Daniel Lemire, Andr\u00e9 Vellino,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06582", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06582", "title": "\nBack to the Past: Source Identification in Diffusion Networks from  Partially Observed Cascades", "abstract": "When a piece of malicious information becomes rampant in an information diffusion network, can we identify the source node that originally introduced the piece into the network and infer the time when it initiated this? Being able to do so is critical for curtailing the spread of malicious information, and reducing the potential losses incurred. This is a very challenging problem since typically only incomplete traces are observed and we need to unroll the incomplete traces into the past in order to pinpoint the source. In this paper, we tackle this problem by developing a two-stage framework, which first learns a continuous-time diffusion network model based on historical diffusion traces and then identifies the source of an incomplete diffusion trace by maximizing the likelihood of the trace under the learned model. Experiments on both large synthetic and real-world data show that our framework can effectively go back to the past, and pinpoint the source node and its initiation time significantly more accurately than previous state-of-the-arts.", "subjects": "Social and Information Networks (cs.SI)", "authors": "Mehrdad Farajtabar, Manuel Gomez-Rodriguez, Nan Du, Mohammad Zamani, Hongyuan Zha, Le Song,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06561", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06561", "title": "\nImproved Practical Matrix Sketching with Guarantees", "abstract": "Matrices have become essential data representations for many large-scale problems in data analytics, and hence matrix sketching is a critical task. Although much research has focused on improving the error/size tradeoff under various sketching paradigms, the many forms of error bounds make these approaches hard to compare in theory and in practice. This paper attempts to categorize and compare most known methods under row-wise streaming updates with provable guarantees, and then to tweak some of these methods to gain practical improvements while retaining guarantees. For instance, we observe that a simple heuristic iSVD, with no guarantees, tends to outperform all known approaches in terms of size/error trade-off. We modify the best performing method with guarantees FrequentDirections under the size/error trade-off to match the performance of iSVD and retain its guarantees. We also demonstrate some adversarial datasets where iSVD performs quite poorly. In comparing techniques in the time/error trade-off, techniques based on hashing or sampling tend to perform better. In this setting we modify the most studied sampling regime to retain error guarantee but obtain dramatic improvements in the time/error trade-off. Finally, we provide easy replication of our studies on APT, a new testbed which makes available not only code and datasets, but also a computing platform with fixed environmental settings.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Amey Desai, Mina Ghashami, Jeff M. Phillips,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06543", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06543", "title": "\nConstruction of Quasi-Cyclic Product Codes", "abstract": "Linear quasi-cyclic product codes over finite fields are investigated. Given the generating set in the form of a reduced Grbner basis of a quasi-cyclic component code and the generator polynomial of a second cyclic component code, an explicit expression of the basis of the generating set of the quasi-cyclic product code is given. Furthermore, the reduced Grbner basis of a one-level quasi-cyclic product code is derived.", "subjects": "Information Theory (cs.IT)", "authors": "Alexander Zeh, San Ling,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06528", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06528", "title": "\nHigh-Girth Matrices and Polarization", "abstract": "The girth of a matrix is the least number of linearly dependent columns, in contrast to the rank which is the largest number of linearly independent columns. This paper considers the construction of matrices, whose probabilistic girth is close to its rank. Random matrices can be used to show the existence of high-girth matrices with constant relative rank, but the construction is non-explicit. This paper uses a polar-like construction to obtain a deterministic and efficient construction of high-girth matrices for arbitrary fields and relative ranks. Applications to coding and sparse recovery are discussed.", "subjects": "Information Theory (cs.IT)", "authors": "Emmanuel Abbe, Yuval Wigderson,", "date": "2015-1-6"}, 
{"urllink": "http://arxiv.org/abs/1501.06523", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06523", "title": "\nDeduction modulo theory", "abstract": "This paper is a survey on Deduction modulo theory", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Gilles Dowek,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06522", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06522", "title": "\nModels and termination of proof-reduction in the $\u03bb$$\u03a0$-calculus  modulo theory", "abstract": "We define a notion of model for the -calculus modulo theory, a notion of super-consistent theory, and prove that proof-reduction terminates in the -calculus modulo a super-consistent theory. We prove this way the termination of proof-reduction in two theories in the -calculus modulo theory, and their consistency: an embedding of Simple type theory and an embedding of the Calculus of constructions.", "subjects": "Logic in Computer Science (cs.LO)", "authors": "Gilles Dowek,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06521", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06521", "title": "\nTensor Prediction, Rademacher Complexity and Random 3-XOR", "abstract": "Here we study the tensor prediction problem, where the goal is to accurately predict the entries of a low rank, third-order tensor (with noise) given as few observations as possible. We give algorithms based on the sixth level of the sum-of-squares hierarchy that work with observations, and we complement our result by showing that any attempt to solve tensor prediction with observations through the sum-of-squares hierarchy needs rounds and consequently would run in moderately exponential time. In contrast, information theoretically observations suffice. Our approach is to characterize the Rademacher complexity of the sequence of norms that arise from the sum-of-squares hierarchy, and both our upper and lower bounds are based on establishing connections between tensor prediction and the task of strongly refuting random -XOR formulas, and the resolution proof system.", "subjects": "Learning (cs.LG)", "authors": "Boaz Barak, Ankur Moitra,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06515", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06515", "title": "\nApproximation Algorithms for P2P Orienteering and Stochastic Vehicle  Routing Problem", "abstract": "We consider the P2P orienteering problem on general metrics and present a (2+) approximation algorithm. In the stochastic P2P orienteering problem we are given a metric and each node has a fixed reward and random size. The goal is to devise a strategy for visiting the nodes so as to maximize the expected value of the reward without violating the budget constraints. We present an approximation algorithm for the non-adaptive variant of the P2P Stochastic orienteering. As an implication of the approximation to the stochastic P2P orienteering problem, we define a stochastic vehicle routing problem with time-windows and present a constant factor approximation solution.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Shalabh Vidyarthi, Kaushal K Shukla,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06508", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06508", "title": "\nPractical Foundations of History Independence", "abstract": "The way data structures organize data is often a function of the sequence of past operations. The organization of data is referred to as the data structure's state, and the sequence of past operations constitutes the data structure's history. A data structure state can therefore be used as an oracle to derive information about its history. As a result, for history-sensitive applications, such as privacy in e-voting, incremental signature schemes, and regulatory compliant data retention; it is imperative to conceal historical information contained within data structure states. Data structure history can be hidden by making data structures history independent. In this paper, we explore how to achieve history independence. We observe that current history independence notions are significantly limited in number and scope. There are two existing notions of history independence -- weak history independence (WHI) and strong history independence (SHI). WHI does not protect against insider adversaries and SHI mandates canonical representations, resulting in inefficiency. We postulate the need for a broad, encompassing notion of history independence, which can capture WHI, SHI, and a broad spectrum of new history independence notions. To this end, we introduce history independence (HI), a generic game-based framework that is malleable enough to accommodate existing and new history independence notions. As an essential step towards formalizing HI, we explore the concepts of abstract data types, data structures, machine models, memory representations and history independence. Finally, to bridge the gap between theory and practice, we outline a general recipe for building end-to-end, history independent systems and demonstrate the use of the recipe in designing two history independent file systems.", "subjects": "Cryptography and Security (cs.CR)", "authors": "Sumeet Bajaj, Anrin Chakraborti, Radu Sion,", "date": "2015-1-6"}, 
{"urllink": "http://arxiv.org/abs/1501.06493", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06493", "title": "\nCoordination in State-Dependent Distributed Networks: The Two-Agent Case", "abstract": "This paper addresses a coordination problem between two agents (Agents and ) in the presence of a noisy communication channel which depends on an external system state . The channel takes as inputs both agents' actions, and and produces outputs that are observed strictly causally at Agent but not at Agent . The system state is available either causally or non-causally at Agent but unknown at Agent . Necessary and sufficient conditions on a joint distribution to be implementable asymptotically (i.e, when the number of taken actions grows large) are provided for both causal and non-causal state information at Agent . Since the coordination degree between the agents' actions, and , and the system state is measured in terms of an average payoff function, feasible payoffs are fully characterized by implementable joint distributions. In this sense, our results allow us to derive the performance of optimal power control policies on an interference channel and to assess the gain provided by non-causal knowledge of the system state at Agent . The derived proofs readily yield new results also for the problem of state-amplification under a causality constraint at the decoder.", "subjects": "Information Theory (cs.IT)", "authors": "Benjamin Larrousse, Samson Lasaulce, Mich\u00e8le Wigger,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06487", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06487", "title": "\nAverage probability of a dangerous failure on demand: Different  modelling methods, similar results", "abstract": "According to the IEC 61508 functional safety standard, it is required to estimate the achieved safety integrity of the system due to random hardware failures. For a safety function operating in a low demand mode, this measure is the average probability of a dangerous failure on demand (PFDavg). In the present paper, four techniques have been applied to various configurations of a case study: fault tree analyses supported by GRIF/Tree, multi-phase Markov models supported by GRIF/Markov, stochastic Petri nets with predicates supported by GRIF/Petri, and approximate equations (developed by DNV and different from those given in IEC 61508) supported by OrbitSIL. It is shown that all these methods yield very similar results for PFDavg, taking the characteristics required by the standard into account. The choice of a method should therefore not be determined by dogmatic assumptions, but should result of a balance between modelling effort and objectives, given the system properties. For this task, a discussion about pros and cons of each method is proposed.", "subjects": "Software Engineering (cs.SE)", "authors": "Florent Brissaud, Fernando Luiz,", "date": "2015-1-20"}, 
{"urllink": "http://arxiv.org/abs/1501.06484", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06484", "title": "\nSymmetric Strategy Improvement", "abstract": "Symmetry is inherent in the definition of most of the two-player zero-sum games, including parity, mean-payoff, and discounted-payoff games. It is therefore quite surprising that no symmetric analysis techniques for these games exist. We develop a novel symmetric strategy improvement algorithm where, in each iteration, the strategies of both players are improved simultaneously. We show that symmetric strategy improvement defies Friedmann's traps, which shook the belief in the potential of classic strategy improvement to be polynomial.", "subjects": "Computer Science and Game Theory (cs.GT)", "authors": "Sven Schewe, Ashutosh Trivedi, Thomas Varghese,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06479", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06479", "title": "\nCheepSync: A Time Synchronization Service for Resource Constrained  Bluetooth Low Energy Advertisers", "abstract": "Clock synchronization is highly desirable in distributed systems, including many applications in the Internet of Things and Humans (IoTH). It improves the efficiency, modularity and scalability of the system; and optimizes use of event triggers. For IoTH, Bluetooth Low Energy (BLE) - a subset of the recent Bluetooth v4:0 stack - provides a low-power and loosely coupled mechanism for sensor data collection with ubiquitous units (e.g., smartphones and tablets) carried by humans. This fundamental design paradigm of BLE is enabled by a range of broadcast advertising modes. While its operational benefits are numerous, the lack of a common time reference in the broadcast mode of BLE has been a fundamental limitation. This paper presents and describes CheepSync: a time synchronization service for BLE advertisers, especially tailored for applications requiring high time precision on resource constrained BLE platforms. Designed on top of the existing Bluetooth v4:0 standard, the CheepSync framework utilizes low-level timestamping and comprehensive error compensation mechanisms for overcoming uncertainties in message transmission, clock drift and other system specific constraints. CheepSync was implemented on custom designed nRF24Cheep beacon platforms (as broadcasters) and commercial off-the-shelf Android ported smartphones (as passive listeners). We demonstrate the efficacy of CheepSync by numerous empirical evaluations in a variety of experimental setups; and show that its average (single-hop) time synchronization accuracy is in the 10u?s range.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Sabarish Sridhar, Prasant Misra, Jay Warrior,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06478", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06478", "title": "\nCompressed Support Vector Machines", "abstract": "Support vector machines (SVM) can classify data sets along highly non-linear decision boundaries because of the kernel-trick. This expressiveness comes at a price: During test-time, the SVM classifier needs to compute the kernel inner-product between a test sample and all support vectors. With large training data sets, the time required for this computation can be substantial. In this paper, we introduce a post-processing algorithm, which compresses the learned SVM model by reducing and optimizing support vectors. We evaluate our algorithm on several medium-scaled real-world data sets, demonstrating that it maintains high test accuracy while reducing the test-time evaluation cost by several orders of magnitude---in some cases from hours to seconds. It is fair to say that most of the work in this paper was previously been invented by Burges and Sch \"olkopf almost 20 years ago. For most of the time during which we conducted this research, we were unaware of this prior work. However, in the past two decades, computing power has increased drastically, and we can therefore provide empirical insights that were not possible in their original paper.", "subjects": "Learning (cs.LG)", "authors": "Zhixiang Xu, Jacob R. Gardner, Stephen Tyree, Kilian Q. Weinberger,", "date": "2015-1-6"}, 
{"urllink": "http://arxiv.org/abs/1501.06470", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06470", "title": "\nInterference Calculation in Asynchronous Random Access Protocols using  Diversity", "abstract": "The use of Aloha-based Random Access protocols is interesting when channel sensing is either not possible or not convenient and the traffic from terminals is unpredictable and sporadic. In this paper an analytic model for packet interference calculation in asynchronous Random Access protocols using diversity is presented. The aim is to provide a tool that avoids time-consuming simulations to evaluate packet loss and throughput in case decodability is still possible when a certain interference threshold is not exceeded. Moreover the same model represents the groundbase for further studies in which iterative Interference Cancellation is applied to received frames.", "subjects": "Information Theory (cs.IT)", "authors": "Alessio Meloni, Maurizio Murroni,", "date": "2015-1-6"}, 
{"urllink": "http://arxiv.org/abs/1501.06469", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06469", "title": "\nOptimal Base Station Deployment for Small Cell Networks with  Energy-Efficient Power Control", "abstract": "In this paper, how to optimally deploy base station density in a small cell network with energy-efficient power control was investigated. Base stations (BSs) and users form two independent Poisson point processes (PPPs) in the network. Since user-centric cell association may lead to void cells that do not have any users, the power of each BS is controlled in either all-on or on-off mode depending on whether its cell is void or not. The average cell rates for each power control mode are first found and their corresponding energy efficiency is also characterized. The optimal BS density that maximizes the energy efficiency under a given user density is theoretically proved to exist and its value can be found numerically. Both analytical and simulated results indicate that on-off power control is significantly superior to all-on power control in terms of energy efficiency if BSs are deployed based on their optimal energy-efficient density.", "subjects": "Information Theory (cs.IT)", "authors": "Ching-Ting Peng, Li-Chun Wang, Chun-Hung Liu,", "date": "2015-1-6"}, 
{"urllink": "http://arxiv.org/abs/1501.06461", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06461", "title": "\nOn The Average-Case Complexity of Shellsort", "abstract": "We prove a lower bound expressed in the increment sequence on the average-case complexity (number of inversions which is proportional to the running time) of Shellsort. This lower bound is sharp in every case where it could be checked. We obtain new results e.g. determining the average-case complexity precisely in the Yao-Janson-Knuth 3-pass case.", "subjects": "Data Structures and Algorithms (cs.DS)", "authors": "Paul M.B. Vitanyi,", "date": "2015-1-6"}, 
{"urllink": "http://arxiv.org/abs/1501.06456", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06456", "title": "\nWeather forecasting using Convex hull & K-Means Techniques An Approach", "abstract": "Data mining is a popular concept of mined necessary data from a large set of data. Data mining using clustering is a powerful way to analyze data and gives prediction. In this paper non structural time series data is used to forecast daily average temperature, humidity and overall weather conditions of Kolkata city. The air pollution data have been taken from West Bengal Pollution Control Board to build the original dataset on which the prediction approach of this paper is studied and applied. This paper describes a new technique to predict the weather conditions using convex hull which gives structural data and then apply incremental K-means to define the appropriate clusters. It splits the total database into four separate databases with respect to different weather conditions. In the final step, the result will be calculated on the basis of priority based protocol which is defined based on some mathematical deduction.", "subjects": "Databases (cs.DB)", "authors": "Ratul Dey Sanjay Chakraborty Lopamudra Dey,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06451", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06451", "title": "\nDesign of a Novel Network Architecture for Distributed Event-Based  Systems Using Directional Random Walks in an Ubiquitous Sensing Scenario", "abstract": "Ubiquitous sensing devices frequently disseminate data among them. The use of a distributed event-based system that decouples publishers from subscribers arises as an ideal candidate to implement the dissemination process. In this paper, we present a network architecture that merges the network and overlay layers of typical structured event-based systems. Directional random walks are used for the construction of this merged layer. Our strategy avoids using a specific network protocol that provides point-to-point communication. This implies that the topology of the network is not maintained, so that nodes not involved in the system are able to save energy and computing resources. We evaluate the performance of the overlay layer using directional random walks and pure random walks for its construction. Our results show that directional random walks are more efficient because: (1) they use less nodes of the network for the establishment of the active path of the overlay layer and (2) they have a more reliable performance. Furthermore, as the number of nodes in the network increases, so do the number of nodes in the active path of the overlay layer for the same number of publishers and subscribers. Finally, we discard any correlation between the number of nodes that form the overlay layer and the maximum Euclidean distance traversed by the walkers.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "authors": "Cristina Mu\u00f1oz, Pierre Leone,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06446", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06446", "title": "\nIndex Policies for Optimal Mean-Variance Trade-Off of Inter-delivery  Times in Real-Time Sensor Networks", "abstract": "A problem of much current practical interest is the replacement of the wiring infrastructure connecting approximately 200 sensor and actuator nodes in automobiles by an access point. This is motivated by the considerable savings in automobile weight, simplification of manufacturability, and future upgradability. A key issue is how to schedule the nodes on the shared access point so as to provide regular packet delivery. In this and other similar applications, the mean of the inter-delivery times of packets, i.e., throughput, is not sufficient to guarantee service-regularity. The time-averaged variance of the inter-delivery times of packets is also an important metric. So motivated, we consider a wireless network where an Access Point schedules real-time generated packets to nodes over a fading wireless channel. We are interested in designing simple policies which achieve optimal mean-variance tradeoff in interdelivery times of packets by minimizing the sum of time-averaged means and variances over all clients. Our goal is to explore the full range of the Pareto frontier of all weighted linear combinations of mean and variance so that one can fully exploit the design possibilities. We transform this problem into a Markov decision process and show that the problem of choosing which node's packet to transmit in each slot can be formulated as a bandit problem. We establish that this problem is indexable and explicitly derive the Whittle indices. The resulting Index policy is optimal in certain cases. We also provide upper and lower bounds on the cost for any policy. Extensive simulations show that Index policies perform better than previously proposed policies.", "subjects": "Networking and Internet Architecture (cs.NI)", "authors": "Rahul Singh, Xueying Guo, P.R. Kumar,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06440", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06440", "title": "\nOn the Achievable Rates of Multihop Virtual Full-Duplex Relay Channels", "abstract": "We study a multihop \"virtual\" full-duplex relay channel as a special case of a general multiple multicast relay network. For such channel, quantize-map-and-forward (QMF) (or noisy network coding (NNC)) achieves the cut-set upper bound within a constant gap where the gap grows with the number of relay stages . However, this gap may not be negligible for the systems with multihop transmissions (i.e., a wireless backhaul operating at higher frequencies). We have recently attained an improved result to the capacity scaling where the gap grows as , by using an optimal quantization at relays and by exploiting relays' messages (decoded in the previous time slot) as side-information. In this paper, we further improve the performance of this network by presenting a mixed scheme where each relay can perform either decode-and-forward (DF) or QMF with possibly rate-splitting. We derive the achievable rate and show that the proposed scheme outperforms the QMF-optimized scheme. Furthermore, we demonstrate that this performance improvement increases with .", "subjects": "Information Theory (cs.IT)", "authors": "Song-Nam Hong, Ivana Maric, Dennis Hui, Giuseppe Caire,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06419", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06419", "title": "\nCritical pairs for the Product Singleton Bound", "abstract": "We characterize Product-MDS pairs of linear codes, i.e. pairs of codes whose product under coordinatewise multiplication has maximum possible minimum distance as a function of the code length and the dimensions . We prove in particular, for , that if the square of the code has minimum distance at least , and is a Product-MDS pair, then either is a generalized Reed-Solomon code, or is a direct sum of self-dual codes. In passing we establish coding-theory analogues of classical theorems of additive combinatorics.", "subjects": "Information Theory (cs.IT)", "authors": "Diego Mirandola, Gilles Z\u00e9mor,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06412", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06412", "title": "\nThe Anatomy of Relevance: Topical, Snippet and Perceived Relevance in  Search Result Evaluation", "abstract": "Currently, the quality of a search engine is often determined using so-called topical relevance, i.e., the match between the user intent (expressed as a query) and the content of the document. In this work we want to draw attention to two aspects of retrieval system performance affected by the presentation of results: result attractiveness (\"perceived relevance\") and immediate usefulness of the snippets (\"snippet relevance\"). Perceived relevance may influence discoverability of good topical documents and seemingly better rankings may in fact be less useful to the user if good-looking snippets lead to irrelevant documents or vice-versa. And result items on a search engine result page (SERP) with high snippet relevance may add towards the total utility gained by the user even without the need to click those items. We start by motivating the need to collect different aspects of relevance (topical, perceived and snippet relevances) and how these aspects can improve evaluation measures. We then discuss possible ways to collect these relevance aspects using crowdsourcing and the challenges arising from that.", "subjects": "Information Retrieval (cs.IR)", "authors": "Aleksandr Chuklin, Maarten de Rijke,", "date": "2015-1-26"}, 
{"urllink": "http://arxiv.org/abs/1501.06407", "category": "Computer Science ", "pdflink": "http://arxiv.org/pdf/1501.06407", "title": "\nOn Secrecy Performance of Antenna Selection Aided MIMO Systems Against  Eavesdropping", "abstract": "In this paper, we consider a multiple-input multiple-output (MIMO) system consisting of one source, one destination and one eavesdropper, where each node is equipped with an arbitrary number of antennas. To improve the security of source-destination transmissions, we investigate the antenna selection at the source and propose the optimal antenna selection (OAS) and suboptimal antenna selection (SAS) schemes, depending on whether the source node has the global channel state information (CSI) of both the main link (from source to destination) and wiretap link (from source to eavesdropper). Also, the traditional space-time transmission (STT) is studied as a benchmark. We evaluate the secrecy performance of STT, SAS, and OAS schemes in terms of the probability of zero secrecy capacity. Furthermore, we examine the generalized secrecy diversity of STT, SAS, and OAS schemes through an asymptotic analysis of the probability of zero secrecy capacity, as the ratio between the average gains of the main a