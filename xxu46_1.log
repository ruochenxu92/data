nohup: ignoring input
2015-03-23 21:40:38+0000 [scrapy] INFO: Scrapy 0.24.5 started (bot: superqq_spider)
2015-03-23 21:40:38+0000 [scrapy] INFO: Optional features available: ssl, http11, boto
2015-03-23 21:40:38+0000 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'superqq_spider.spiders', 'SPIDER_MODULES': ['superqq_spider.spiders'], 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 72, 'BOT_NAME': 'superqq_spider'}
2015-03-23 21:40:39+0000 [scrapy] INFO: Enabled extensions: LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, SpiderState
2015-03-23 21:40:39+0000 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentPoolMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-03-23 21:40:39+0000 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-03-23 21:40:39+0000 [scrapy] INFO: Enabled item pipelines: JsonWriterPipeline
2015-03-23 21:40:39+0000 [xxu46_1] INFO: Spider opened
2015-03-23 21:40:39+0000 [xxu46_1] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-03-23 21:40:39+0000 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2015-03-23 21:40:39+0000 [scrapy] DEBUG: Web service listening on 127.0.0.1:6080
2015-03-23 21:41:04+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/list/cs/10?skip=5000&show=1000> (referer: None)
2015-03-23 21:41:14+0000 [xxu46_1] DEBUG: Filtered duplicate request: <GET http://arxiv.org/abs/1009.4798> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2015-03-23 21:41:39+0000 [xxu46_1] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2015-03-23 21:42:39+0000 [xxu46_1] INFO: Crawled 1 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-03-23 21:42:51+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/list/cs/10?skip=4000&show=1000> (referer: None)
2015-03-23 21:43:39+0000 [xxu46_1] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2015-03-23 21:44:08+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/list/cs/10?skip=3000&show=1000> (referer: None)
2015-03-23 21:44:39+0000 [xxu46_1] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2015-03-23 21:45:01+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/list/cs/10?skip=2000&show=1000> (referer: None)
2015-03-23 21:45:39+0000 [xxu46_1] INFO: Crawled 4 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2015-03-23 21:46:06+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/list/cs/10?skip=1000&show=1000> (referer: None)
2015-03-23 21:46:39+0000 [xxu46_1] INFO: Crawled 5 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2015-03-23 21:48:21+0000 [xxu46_1] INFO: Crawled 5 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-03-23 21:48:22+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/list/cs/10?skip=0&show=1000> (referer: None)
2015-03-23 21:48:39+0000 [xxu46_1] INFO: Crawled 6 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2015-03-23 21:48:41+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1009.0077> (referer: http://arxiv.org/list/cs/10?skip=5000&show=1000)
2015-03-23 21:48:42+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1009.0077>
	{'abstract': u'Machine Consciousness and Machine Intelligence are not simply new buzzwords that occupy our imagination. Over the last decades, we witness an unprecedented rise in attempts to create machines with human-like features and capabilities. However, despite widespread sympathy and abundant funding, progress in these enterprises is far from being satisfactory. The reasons for this are twofold: First, the notions of cognition and intelligence (usually borrowed from human behavior studies) are notoriously blurred and ill-defined, and second, the basic concepts underpinning the whole discourse are by themselves either undefined or defined very vaguely. That leads to improper and inadequate research goals determination, which I will illustrate with some examples drawn from recent documents issued by DARPA and the European Commission. On the other hand, I would like to propose some remedies that, I hope, would improve the current state-of-the-art disgrace.',
	 'authors': u'Emanuel Diamant,',
	 'category': u'Computer Science ',
	 'date': '2010-9-1',
	 'pdflink': u'http://arxiv.org/pdf/1009.0077',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nNot only a lack of right definitions: Arguments for a shift in  information-processing paradigm',
	 'urllink': u'http://arxiv.org/abs/1009.0077'}
2015-03-23 21:53:57+0000 [xxu46_1] INFO: Crawled 7 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2015-03-23 21:54:53+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1009.0078> (referer: http://arxiv.org/list/cs/10?skip=5000&show=1000)
2015-03-23 21:54:54+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1009.0078>
	{'abstract': u'Energy-efficient communication is an important requirement for mobile relay networks due to the limited battery power of user terminals. This paper considers energy-efficient relaying schemes through selection of mobile relays in cooperative cellular systems with asymmetric traffic. The total energy consumption per information bit of the battery-powered terminals, i.e., the mobile station (MS) and the relay, is derived in theory. In the Joint Uplink and Downlink Relay Selection (JUDRS) scheme we proposed, the relay which minimizes the total energy consumption is selected. Additionally, the energy-efficient cooperation regions are investigated, and the optimal relay location is found for cooperative cellular systems with asymmetric traffic. The results reveal that the MS-relay and the relay-base station (BS) channels have different influence over relay selection decisions for optimal energy-efficiency. Information theoretic analysis of the diversity-multiplexing tradeoff (DMT) demonstrates that the proposed scheme achieves full spatial diversity in the quantity of cooperating terminals in this network. Finally, numerical results further confirm a significant energy efficiency gain of the proposed algorithm comparing to the previous best worse channel selection and best harmonic mean selection algorithms.',
	 'authors': u'Wei Yang, Lihua Li, Wanlu Sun,',
	 'category': u'Computer Science ',
	 'date': '2010-9-1',
	 'pdflink': u'http://arxiv.org/pdf/1009.0078',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nEnergy-Efficient Relay Selection and Optimal Relay Location in  Cooperative Cellular Networks with Asymmetric Traffic',
	 'urllink': u'http://arxiv.org/abs/1009.0078'}
2015-03-23 21:55:39+0000 [xxu46_1] INFO: Crawled 8 pages (at 1 pages/min), scraped 2 items (at 1 items/min)
2015-03-23 21:56:21+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1009.0088> (referer: http://arxiv.org/list/cs/10?skip=5000&show=1000)
2015-03-23 21:56:22+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1009.0088>
	{'abstract': u"We study the classic graph drawing problem of drawing a planar graph using straight-line edges with a prescribed convex polygon as the outer face. Unlike previous algorithms for this problem, which may produce drawings with exponential area, our method produces drawings with polynomial area. In addition, we allow for collinear points on the boundary, provided such vertices do not create overlapping edges. Thus, we solve an open problem of Duncan et al., which, when combined with their work, implies that we can produce a planar straight-line drawing of a combinatorially-embedded genus-g graph with the graph's canonical polygonal schema drawn as a convex polygonal external face.",
	 'authors': u'Erin W. Chambers, David Eppstein, Michael T. Goodrich, Maarten L\xf6ffler,',
	 'category': u'Computer Science ',
	 'date': '2010-9-1',
	 'pdflink': u'http://arxiv.org/pdf/1009.0088',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nDrawing Graphs in the Plane with a Prescribed Outer Face and Polynomial  Area',
	 'urllink': u'http://arxiv.org/abs/1009.0088'}
2015-03-23 21:56:39+0000 [xxu46_1] INFO: Crawled 9 pages (at 1 pages/min), scraped 3 items (at 1 items/min)
2015-03-23 21:57:39+0000 [xxu46_1] INFO: Crawled 9 pages (at 0 pages/min), scraped 3 items (at 0 items/min)
2015-03-23 21:58:05+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1009.0108> (referer: http://arxiv.org/list/cs/10?skip=5000&show=1000)
2015-03-23 21:58:05+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1009.0108>
	{'abstract': u'This paper presents our investigations on emotional state categorization from speech signals with a psychologically inspired computational model against human performance under the same experimental setup. Based on psychological studies, we propose a multistage categorization strategy which allows establishing an automatic categorization model flexibly for a given emotional speech categorization task. We apply the strategy to the Serbian Emotional Speech Corpus (GEES) and the Danish Emotional Speech Corpus (DES), where human performance was reported in previous psychological studies. Our work is the first attempt to apply machine learning to the GEES corpus where the human recognition rates were only available prior to our study. Unlike the previous work on the DES corpus, our work focuses on a comparison to human performance under the same experimental settings. Our studies suggest that psychology-inspired systems yield behaviours that, to a great extent, resemble what humans perceived and their performance is close to that of humans under the same experimental setup. Furthermore, our work also uncovers some differences between machine and humans in terms of emotional state recognition from speech.',
	 'authors': u'Arslan Shaukat, Ke Chen,',
	 'category': u'Computer Science ',
	 'date': '2010-9-1',
	 'pdflink': u'http://arxiv.org/pdf/1009.0108',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nEmotional State Categorization from Speech: Machine vs. Human',
	 'urllink': u'http://arxiv.org/abs/1009.0108'}
2015-03-23 21:58:39+0000 [xxu46_1] INFO: Crawled 10 pages (at 1 pages/min), scraped 4 items (at 1 items/min)
2015-03-23 21:59:25+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1009.0117> (referer: http://arxiv.org/list/cs/10?skip=5000&show=1000)
2015-03-23 21:59:25+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1009.0117>
	{'abstract': u'We propose a novel feature selection strategy to discover language-independent acoustic features that tend to be responsible for emotions regardless of languages, linguistics and other factors. Experimental results suggest that the language-independent feature subset discovered yields the performance comparable to the full feature set on various emotional speech corpora.',
	 'authors': u'Arslan Shaukat, Ke Chen,',
	 'category': u'Computer Science ',
	 'date': '2010-9-1',
	 'pdflink': u'http://arxiv.org/pdf/1009.0117',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nExploring Language-Independent Emotional Acoustic Features via Feature  Selection',
	 'urllink': u'http://arxiv.org/abs/1009.0117'}
2015-03-23 21:59:39+0000 [xxu46_1] INFO: Crawled 11 pages (at 1 pages/min), scraped 5 items (at 1 items/min)
2015-03-23 22:00:39+0000 [xxu46_1] INFO: Crawled 11 pages (at 0 pages/min), scraped 5 items (at 0 items/min)
2015-03-23 22:01:12+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1009.0119> (referer: http://arxiv.org/list/cs/10?skip=5000&show=1000)
2015-03-23 22:01:12+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1009.0119>
	{'abstract': u'We explore the hypothesis that it is possible to obtain information about the dynamics of a blog network by analysing the temporal relationships between blogs at a semantic level, and that this type of analysis adds to the knowledge that can be extracted by studying the network only at the structural level of URL links. We present an algorithm to automatically detect fine-grained discussion topics, characterized by n-grams and time intervals. We then propose a probabilistic model to estimate the temporal relationships that blogs have with one another. We define the precursor score of blog A in relation to blog B as the probability that A enters a new topic before B, discounting the effect created by asymmetric posting rates. Network-level metrics of precursor and laggard behavior are derived from these dyadic precursor score estimations. This model is used to analyze a network of French political blogs. The scores are compared to traditional link degree metrics. We obtain insights into the dynamics of topic participation on this network, as well as the relationship between precursor/laggard and linking behaviors. We validate and analyze results with the help of an expert on the French blogosphere. Finally, we propose possible applications to the improvement of search engine ranking algorithms.',
	 'authors': u'Telmo Menezes, Camille Roth, Jean-Philippe Cointet,',
	 'category': u'Computer Science ',
	 'date': '2010-9-1',
	 'pdflink': u'http://arxiv.org/pdf/1009.0119',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nPrecursors and Laggards: An Analysis of Semantic Temporal Relationships  on a Blog Network',
	 'urllink': u'http://arxiv.org/abs/1009.0119'}
2015-03-23 22:01:39+0000 [xxu46_1] INFO: Crawled 12 pages (at 1 pages/min), scraped 6 items (at 1 items/min)
2015-03-23 22:02:30+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1009.0143> (referer: http://arxiv.org/list/cs/10?skip=5000&show=1000)
2015-03-23 22:02:30+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1009.0143>
	{'abstract': u'We exhibit a Probabilistic Cellular Automaton (PCA) on the integers with an alphabet and a neighborhood of size 2 which is non-ergodic although it has a unique invariant measure. This answers by the negative an old open question on whether uniqueness of the invariant measure implies ergodicity for a PCA.',
	 'authors': u'Philippe Chassaing, Jean Mairesse,',
	 'category': u'Computer Science ',
	 'date': '2010-9-1',
	 'pdflink': u'http://arxiv.org/pdf/1009.0143',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nA non-ergodic probabilistic cellular automaton with a unique invariant  measure',
	 'urllink': u'http://arxiv.org/abs/1009.0143'}
2015-03-23 22:02:39+0000 [xxu46_1] INFO: Crawled 13 pages (at 1 pages/min), scraped 7 items (at 1 items/min)
2015-03-23 22:03:39+0000 [xxu46_1] INFO: Crawled 13 pages (at 0 pages/min), scraped 7 items (at 0 items/min)
2015-03-23 22:03:40+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1009.0152> (referer: http://arxiv.org/list/cs/10?skip=5000&show=1000)
2015-03-23 22:03:40+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1009.0152>
	{'abstract': u'Three controlled experiments testing the benefits that Java programmers gain from using the Two-Tier Programming Toolkit have recently been concluded. The first experiment offers statistically significant evidence (p-value: 0.02) that programmers who undertook only minimal (1-hour) training in using the current prototype exhibit 76% productivity gains in key tasks in software development and maintenance. The second experiment shows that the use of the TTP Toolkit is likely (p-value: 0.10) to almost triple the accuracy of programmers performing tasks associated with software quality. The third experiment shows that the TTP Toolkit does not offer significant productivity gains in performing very short (under 10 min.) tasks.',
	 'authors': u'Amnon H. Eden, Epameinondas Gasparis,',
	 'category': u'Computer Science ',
	 'date': '2010-9-1',
	 'pdflink': u'http://arxiv.org/pdf/1009.0152',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nThree Controlled Experiments in Software Engineering with the Two-Tier  Programming Toolkit: Final Report',
	 'urllink': u'http://arxiv.org/abs/1009.0152'}
2015-03-23 22:04:39+0000 [xxu46_1] INFO: Crawled 14 pages (at 1 pages/min), scraped 8 items (at 1 items/min)
2015-03-23 22:05:03+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1009.0216> (referer: http://arxiv.org/list/cs/10?skip=5000&show=1000)
2015-03-23 22:05:03+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1009.0216>
	{'abstract': u'Boolean-width is a recently introduced graph parameter. Many problems are fixed parameter tractable when parametrized by boolean-width, for instance "Minimum Weighted Dominating Set" (MWDS) problem can be solved in time given a boolean-decomposition of width , hence for all graph classes where a boolean-decomposition of width can be found in polynomial time, MWDS can be solved in polynomial time. We study graph classes having boolean-width and problems solvable in , combining these two results to design polynomial algorithms. We show that for trapezoid graphs, circular permutation graphs, convex graphs, Dilworth- graphs, circular arc graphs and complements of -degenerate graphs, boolean-decompositions of width can be found in polynomial time. We also show that circular -trapezoid graphs have boolean-width , and find such a decomposition if a circular -trapezoid intersection model is given. For many of the graph classes we also prove that they contain graphs of boolean-width . Further we apply the results from cite to give a new polynomial time algorithm solving all vertex partitioning problems introduced by Proskurowski and Telle cite. This extends previous results by Kratochv \'il, Manuel and Miller cite showing that a large subset of the vertex partitioning problems are polynomial solvable on interval graphs.',
	 'authors': u'R\xe9my Belmonte, Martin Vatshelle,',
	 'category': u'Computer Science ',
	 'date': '2010-9-1',
	 'pdflink': u'http://arxiv.org/pdf/1009.0216',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nOn graph classes with logarithmic boolean-width',
	 'urllink': u'http://arxiv.org/abs/1009.0216'}
2015-03-23 22:05:39+0000 [xxu46_1] INFO: Crawled 15 pages (at 1 pages/min), scraped 9 items (at 1 items/min)
2015-03-23 22:06:39+0000 [xxu46_1] INFO: Crawled 15 pages (at 0 pages/min), scraped 9 items (at 0 items/min)
2015-03-23 22:06:50+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1009.0240> (referer: http://arxiv.org/list/cs/10?skip=5000&show=1000)
2015-03-23 22:06:50+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1009.0240>
	{'abstract': u'How can we model influence between individuals in a social system, even when the network of interactions is unknown? In this article, we review the literature on the "influence model," which utilizes independent time series to estimate how much the state of one actor affects the state of another actor in the system. We extend this model to incorporate dynamical parameters that allow us to infer how influence changes over time, and we provide three examples of how this model can be applied to simulated and real data. The results show that the model can recover known estimates of influence, it generates results that are consistent with other measures of social networks, and it allows us to uncover important shifts in the way states may be transmitted between actors at different points in time.',
	 'authors': u'Wei Pan, Manuel Cebrian, Wen Dong, Taemie Kim, James Fowler, Alex Pentland,',
	 'category': u'Computer Science ',
	 'date': '2010-9-1',
	 'pdflink': u'http://arxiv.org/pdf/1009.0240',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nModeling Dynamical Influence in Human Interaction Patterns',
	 'urllink': u'http://arxiv.org/abs/1009.0240'}
2015-03-23 22:07:39+0000 [xxu46_1] INFO: Crawled 16 pages (at 1 pages/min), scraped 10 items (at 1 items/min)
2015-03-23 22:08:36+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1009.0246> (referer: http://arxiv.org/list/cs/10?skip=5000&show=1000)
2015-03-23 22:08:36+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1009.0246>
	{'abstract': u'This article describes a formal strategy of geometric complexity theory (GCT) to resolve the in the vs. and related problems. The strategy, called the , is to go for of these problems. By an explicit proof we mean a proof that constructs proof certificates of hardness that are easy to verify, construct and decode. The main result in this paper says that (1) any proof of the arithmetic implication of the vs. conjecture is close to an explicit proof in the sense that it can be transformed into an explicit proof by proving in addition that arithmetic circuit identity testing can be derandomized in a blackbox fashion, and (2) stronger forms of these arithmetic hardness and derandomization conjectures together imply a polynomial time algorithm for a formidable explicit construction problem in algebraic geometry. This may explain why these conjectures, which look so elementary at the surface, have turned out to be so hard.',
	 'authors': u'Ketan Mulmuley,',
	 'category': u'Computer Science ',
	 'date': '2010-9-1',
	 'pdflink': u'http://arxiv.org/pdf/1009.0246',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nExplicit Proofs and The Flip',
	 'urllink': u'http://arxiv.org/abs/1009.0246'}
2015-03-23 22:08:39+0000 [xxu46_1] INFO: Crawled 17 pages (at 1 pages/min), scraped 11 items (at 1 items/min)
2015-03-23 22:09:39+0000 [xxu46_1] INFO: Crawled 17 pages (at 0 pages/min), scraped 11 items (at 0 items/min)
2015-03-23 22:10:14+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1010.4850> (referer: http://arxiv.org/list/cs/10?skip=5000&show=1000)
2015-03-23 22:10:14+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1010.4850>
	{'abstract': u'The skyline concept has been introduced in order to exhibit the best objects according to all the criterion combinations and makes it possible to analyse the relationships between skyline objects. Like the data cube, the skycube is so voluminous that reduction approaches are really necessary. In this paper, we define an approach which partially materializes the skycube. The underlying idea is to discard from the representation the skycuboids which can be computed again the most easily. To meet this reduction objective, we characterize a formal framework: the agree concept lattice. From this structure, we derive the skyline concept lattice which is one of its constrained instances. The strong points of our approach are: (i) it is attribute oriented; (ii) it provides a boundary for the number of lattice nodes; (iii) it facilitates the navigation within the Skycuboids.',
	 'authors': u'S\xe9bastien Nedjar, Fabien Pesci, Lotfi Lakhal, Rosine Cicchetti,',
	 'category': u'Computer Science ',
	 'date': '2010-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1010.4850',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nTreillis des concepts skylines : Analyse multidimensionnelle des  skylines fond\xe9e sur les ensembles en accord',
	 'urllink': u'http://arxiv.org/abs/1010.4850'}
2015-03-23 22:10:39+0000 [xxu46_1] INFO: Crawled 18 pages (at 1 pages/min), scraped 12 items (at 1 items/min)
2015-03-23 22:11:39+0000 [xxu46_1] INFO: Crawled 18 pages (at 0 pages/min), scraped 12 items (at 0 items/min)
2015-03-23 22:12:00+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1008.1663> (referer: http://arxiv.org/list/cs/10?skip=4000&show=1000)
2015-03-23 22:12:00+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1008.1663>
	{'abstract': u'We define a two-step learner for RFSAs based on an observation table by using an algorithm for minimal DFAs to build a table for the reversal of the language in question and showing that we can derive the minimal RFSA from it after some simple modifications. We compare the algorithm to two other table-based ones of which one (by Bollig et al. 2009) infers a RFSA directly, and the other is another two-step learner proposed by the author. We focus on the criterion of query complexity.',
	 'authors': u'Anna Kasprzik,',
	 'category': u'Computer Science ',
	 'date': '2010-8-10',
	 'pdflink': u'http://arxiv.org/pdf/1008.1663',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nLearning Residual Finite-State Automata Using Observation Tables',
	 'urllink': u'http://arxiv.org/abs/1008.1663'}
2015-03-23 22:12:39+0000 [xxu46_1] INFO: Crawled 19 pages (at 1 pages/min), scraped 13 items (at 1 items/min)
2015-03-23 22:13:39+0000 [xxu46_1] INFO: Crawled 19 pages (at 0 pages/min), scraped 13 items (at 0 items/min)
2015-03-23 22:13:47+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1006.0403> (referer: http://arxiv.org/list/cs/10?skip=3000&show=1000)
2015-03-23 22:13:47+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1006.0403>
	{'abstract': u'In this paper we investigate the existence of model-equivalence reduction between NP-logic systems which are logic systems with model existence problem in NP. It is shown that among all NP-systems with model checking problem in NP, the existentially quantified propositional logic ( exists PF) is maximal with respect to poly-time model-equivalent reduction. However, exists PF seems not a maximal NP-system in general because there exits a NP-system with model checking problem D^P-complete.',
	 'authors': u'Yuping Shen, Xishun Zhao,',
	 'category': u'Computer Science ',
	 'date': '2010-6-2',
	 'pdflink': u'http://arxiv.org/pdf/1006.0403',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nNP-Logic Systems and Model-Equivalence Reductions',
	 'urllink': u'http://arxiv.org/abs/1006.0403'}
2015-03-23 22:14:39+0000 [xxu46_1] INFO: Crawled 20 pages (at 1 pages/min), scraped 14 items (at 1 items/min)
2015-03-23 22:15:04+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.3109> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-23 22:15:04+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.3109>
	{'abstract': u'Stochastic network calculus provides an elegant way to characterize traffic and service processes. However, little effort has been made on applying it to multi-access communication systems such as 802.11. In this paper, we take the first step to apply it to the backlog and delay analysis of an 802.11 wireless local network. In particular, we address the following questions: In applying stochastic network calculus, under what situations can we derive stable backlog and delay bounds? How to derive the backlog and delay bounds of an 802.11 wireless node? And how tight are these bounds when compared with simulations? To answer these questions, we first derive the general stability condition of a wireless node (not restricted to 802.11). From this, we give the specific stability condition of an 802.11 wireless node. Then we derive the backlog and delay bounds of an 802.11 node based on an existing model of 802.11. We observe that the derived bounds are loose when compared with ns-2 simulations, indicating that improvements are needed in the current version of stochastic network calculus.',
	 'authors': u'Yue Wang,',
	 'category': u'Computer Science ',
	 'date': '2010-4-19',
	 'pdflink': u'http://arxiv.org/pdf/1004.3109',
	 'subjects': u'Performance (cs.PF)',
	 'title': u'\nApplying Stochastic Network Calculus to 802.11 Backlog and Delay  Analysis',
	 'urllink': u'http://arxiv.org/abs/1004.3109'}
2015-03-23 22:15:39+0000 [xxu46_1] INFO: Crawled 21 pages (at 1 pages/min), scraped 15 items (at 1 items/min)
2015-03-23 22:15:55+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1001.0282> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:15:55+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1001.0282>
	{'abstract': u'In this paper a new approach to image watermarking in wavelet domain is presented. The idea is to hide the watermark data in blocks of the block segmented image. Two schemes are presented based on this idea by embedding the watermark data in the low pass wavelet coefficients of each block. Due to low computational complexity of the proposed approach, this algorithm can be implemented in real time. Experimental results demonstrate the impercepti-bility of the proposed method and its high robustness against various attacks such as filtering, JPEG compres-sion, cropping, noise addition and geometric distortions.',
	 'authors': u'Hamed Dehghan, S. Ebrahim Safavi,',
	 'category': u'Computer Science ',
	 'date': '2010-1-4',
	 'pdflink': u'http://arxiv.org/pdf/1001.0282',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nRobust Image Watermarking in the Wavelet Domain for Copyright Protection',
	 'urllink': u'http://arxiv.org/abs/1001.0282'}
2015-03-23 22:16:39+0000 [xxu46_1] INFO: Crawled 22 pages (at 1 pages/min), scraped 16 items (at 1 items/min)
2015-03-23 22:17:36+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1001.0436> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:17:36+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1001.0436>
	{'abstract': u"We study the design of truthful mechanisms that do not use payments for the generalized assignment problem (GAP) and its variants. An instance of the GAP consists of a bipartite graph with jobs on one side and machines on the other. Machines have capacities and edges have values and sizes; the goal is to construct a welfare maximizing feasible assignment. In our model of private valuations, motivated by impossibility results, the value and sizes on all job-machine pairs are public information; however, whether an edge exists or not in the bipartite graph is a job's private information. We study several variants of the GAP starting with matching. For the unweighted version, we give an optimal strategyproof mechanism; for maximum weight bipartite matching, however, we show give a 2-approximate strategyproof mechanism and show by a matching lowerbound that this is optimal. Next we study knapsack-like problems, which are APX-hard. For these problems, we develop a general LP-based technique that extends the ideas of Lavi and Swamy to reduce designing a truthful mechanism without money to designing such a mechanism for the fractional version of the problem, at a loss of a factor equal to the integrality gap in the approximation ratio. We use this technique to obtain strategyproof mechanisms with constant approximation ratios for these problems. We then design an O(log n)-approximate strategyproof mechanism for the GAP by reducing, with logarithmic loss in the approximation, to our solution for the value-invariant GAP. Our technique may be of independent interest for designing truthful mechanisms without money for other LP-based problems.",
	 'authors': u'Shaddin Dughmi, Arpita Ghosh,',
	 'category': u'Computer Science ',
	 'date': '2010-1-4',
	 'pdflink': u'http://arxiv.org/pdf/1001.0436',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nTruthful Assignment without Money',
	 'urllink': u'http://arxiv.org/abs/1001.0436'}
2015-03-23 22:17:39+0000 [xxu46_1] INFO: Crawled 23 pages (at 1 pages/min), scraped 17 items (at 1 items/min)
2015-03-23 22:18:39+0000 [xxu46_1] INFO: Crawled 23 pages (at 0 pages/min), scraped 17 items (at 0 items/min)
2015-03-23 22:19:19+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1001.1122> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:19:19+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1001.1122>
	{'abstract': u"We present several applications of non-linear data modeling, using principal manifolds and principal graphs constructed using the metaphor of elasticity (elastic principal graph approach). These approaches are generalizations of the Kohonen's self-organizing maps, a class of artificial neural networks. On several examples we show advantages of using non-linear objects for data approximation in comparison to the linear ones. We propose four numerical criteria for comparing linear and non-linear mappings of datasets into the spaces of lower dimension. The examples are taken from comparative political science, from analysis of high-throughput data in molecular biology, from analysis of dynamical systems.",
	 'authors': u'A. N. Gorban, A. Zinovyev,',
	 'category': u'Computer Science ',
	 'date': '2010-1-7',
	 'pdflink': u'http://arxiv.org/pdf/1001.1122',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nPrincipal manifolds and graphs in practice: from molecular biology to  dynamical systems',
	 'urllink': u'http://arxiv.org/abs/1001.1122'}
2015-03-23 22:19:39+0000 [xxu46_1] INFO: Crawled 24 pages (at 1 pages/min), scraped 18 items (at 1 items/min)
2015-03-23 22:20:39+0000 [xxu46_1] INFO: Crawled 24 pages (at 0 pages/min), scraped 18 items (at 0 items/min)
2015-03-23 22:20:44+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1001.3017> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:20:44+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1001.3017>
	{'abstract': u"We revisit the 3-pass code-based identification scheme proposed by Stern at Crypto'93, and give a new 5-pass protocol for which the probability of the cheater is 1/2 (instead of 2/3 in the original Stern's proposal). Furthermore, we propose to use quasi-cyclic construction in order to dramatically reduce the size of the public key. The proposed scheme is zero-knowledge and relies on an NP-complete problem coming from coding theory (namely the q-ary Syndrome Decoding problem). Taking into account a recent study of a generalization of Stern's information-set-decoding algorithm for decoding linear codes over arbitrary finite fields Fq we suggest parameters so that the public key be 34Kbits while those of Stern's scheme is about 66Kbits. This provides a very practical identification (and possibly signature) scheme which is mostly attractive for light-weight cryptography",
	 'authors': u'Pierre-Louis Cayrel, Pascal Veron,',
	 'category': u'Computer Science ',
	 'date': '2010-1-18',
	 'pdflink': u'http://arxiv.org/pdf/1001.3017',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nImproved code-based identification scheme',
	 'urllink': u'http://arxiv.org/abs/1001.3017'}
2015-03-23 22:21:39+0000 [xxu46_1] INFO: Crawled 25 pages (at 1 pages/min), scraped 19 items (at 1 items/min)
2015-03-23 22:22:13+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1001.5364> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:22:13+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1001.5364>
	{'abstract': u'This paper proposes a new detection algorithm for MIMO communication systems employing high order QAM constellations. The factor graph that corresponds to this problem is very loopy; in fact, it is a complete graph. Hence, a straightforward application of the Belief Propagation (BP) algorithm yields very poor results. Our algorithm is based on an optimal tree approximation of the Gaussian density of the unconstrained linear system. The finite-set constraint is then applied to obtain a loop-free discrete distribution. It is shown that even though the approximation is not directly applied to the exact discrete distribution, applying the BP algorithm to the loop-free factor graph outperforms current methods in terms of both performance and complexity. The improved performance of the proposed algorithm is demonstrated on the problem of MIMO detection.',
	 'authors': u'Jacobb Goldberger, Amir Leshem,',
	 'category': u'Computer Science ',
	 'date': '2010-1-29',
	 'pdflink': u'http://arxiv.org/pdf/1001.5364',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nMIMO Detection for High-Order QAM Based on a Gaussian Tree Approximation',
	 'urllink': u'http://arxiv.org/abs/1001.5364'}
2015-03-23 22:22:39+0000 [xxu46_1] INFO: Crawled 26 pages (at 1 pages/min), scraped 20 items (at 1 items/min)
2015-03-23 22:23:22+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3337> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:23:22+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3337>
	{'abstract': u'Selection of the most suitable substrate for a Microstrip antenna is a matter of prime importance. This is because many limitations of the microstrip antenna such as high return loss, low gain and low efficiency can be overcome by selecting an appropriate substrate for fabrication of the antenna, without shifting the resonant frequency significantly. The substate properties such as its dielectric constant, loss tangent have a pronounced effect on the antenna characteristics. Some of the critical properties that are to be taken care of while selecting a dielectric are homogeneity, moisture absorption and adhesion of metal- foil cladding. In this paper a comprehensive study of the effect of variation of substrate material on the antenna properties has been presented.',
	 'authors': u'Asok De, N. S. Raghava, Sagar Malhotra, Pushkar Arora, Rishik Bazaz,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3337',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nEffect of different substrates on Compact stacked square Microstrip  Antenna',
	 'urllink': u'http://arxiv.org/abs/1002.3337'}
2015-03-23 22:23:39+0000 [xxu46_1] INFO: Crawled 27 pages (at 1 pages/min), scraped 21 items (at 1 items/min)
2015-03-23 22:24:32+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3339> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:24:32+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3339>
	{'abstract': u'This paper is concerned with distributed limited memory prediction for continuous-time linear stochastic systems with multiple sensors. A distributed fusion with the weighted sum structure is applied to the optimal local limited memory predictors. The distributed prediction algorithm represents the optimal linear fusion by weighting matrices under the minimum mean square criterion. The algorithm has the parallel structure and allows parallel processing of observations making it reliable since the rest faultless sensors can continue to the fusion estimation if some sensors occur faulty. The derivation of equations for error cross-covariances between the local predictors is the key of this paper. Example demonstrates effectiveness of the distributed limited memory predictor.',
	 'authors': u'Ha-ryong Song, Vladimir Shin,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3339',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nLimited Memory Prediction for Linear Systems with Different types of  Observation',
	 'urllink': u'http://arxiv.org/abs/1002.3339'}
2015-03-23 22:24:39+0000 [xxu46_1] INFO: Crawled 28 pages (at 1 pages/min), scraped 22 items (at 1 items/min)
2015-03-23 22:25:39+0000 [xxu46_1] INFO: Crawled 28 pages (at 0 pages/min), scraped 22 items (at 0 items/min)
2015-03-23 22:25:59+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3333> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:25:59+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3333>
	{'abstract': u'In this paper, we describe an effective framework for adapting electronic commerce or e-commerce services in developing countries like Bangladesh. The internet has opened up a new horizon for commerce, namely electronic commerce (e-commerce). It entails the use of the internet in the marketing, identification, payment and delivery of goods and services. At present internet facilities are available in Bangladesh. Slowly, but steadily these facilities are holding a strong position in every aspects of our life. E-commerce is one of those sectors which need more attention if we want to be a part of global business. Bangladesh is far-far away to adapt the main stream of e-commerce application. Though government is shouting to take the challenges of e-commerce, but they do not take the right step, that is why e-commerce dose not make any real contribution in our socio-economic life. Here we propose a model which may develop the e-commerce infrastructure of Bangladesh.',
	 'authors': u'Ijaj Md. Laisuzzaman, Nahid Imran, Abdullah Al Nahid, Md. Ziaul, Md. Abdul Alim,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3333',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nThe Framework for Implementing ECommerce: The Role of Bank and Telecom  in Bangladesh',
	 'urllink': u'http://arxiv.org/abs/1002.3333'}
2015-03-23 22:26:39+0000 [xxu46_1] INFO: Crawled 29 pages (at 1 pages/min), scraped 23 items (at 1 items/min)
2015-03-23 22:27:39+0000 [xxu46_1] INFO: Crawled 29 pages (at 0 pages/min), scraped 23 items (at 0 items/min)
2015-03-23 22:27:46+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3332> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:27:46+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3332>
	{'abstract': u"Commercial cellular networks, like the systems based on DS-CDMA, face many types of interferences such as multi-user interference inside each sector in a cell to interoperate interference. Independent Component Analysis (ICA) has been used as an advanced preprocessing tool for blind suppression of interfering signals in DS-CDMA communication systems. The role of ICA is to provide an interference-mitigated signal to the conventional detection. This paper evaluates the performance of some major ICA algorithms like Cardoso's joint approximate diagonalization of eigen matrices (JADE), Hyvarinen's fixed point algorithm and Comon's algorithm to solve the symbol estimation problem of the multi users in a DSCDMA communication system. The main focus is on blind separation of convolved CDMA mixture and the improvement of the downlink symbol estimation. The results of numerical experiment are compared with those obtained by the Single User Detection (SUD) receiver, ICA detector and combined SUD-ICA detector.",
	 'authors': u'Sargam Parmar, Bhuvan Unhelkar,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3332',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nPerformance Comparisions of ICA Algorithms to DS-CDMA Detection',
	 'urllink': u'http://arxiv.org/abs/1002.3332'}
2015-03-23 22:28:39+0000 [xxu46_1] INFO: Crawled 30 pages (at 1 pages/min), scraped 24 items (at 1 items/min)
2015-03-23 22:29:22+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3330> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:29:22+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3330>
	{'abstract': u'Formal semantics offers a complete and rigorous definition of a language. It is important to define different semantic models for a language and different models serve different purposes. Building equivalence between different semantic models of a language strengthen its formal foundation. This paper shows the derivation of denotational semantics from operational semantics of the language cCSP. The aim is to show the correspondence between operational and trace semantics. We extract traces from operational rules and use induction over traces to show the correspondence between the two semantics of cCSP.',
	 'authors': u'Shamim H. Ripon, Michael Butler,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3330',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nDeriving Relationship Between Semantic Models - An Approach for cCSP',
	 'urllink': u'http://arxiv.org/abs/1002.3330'}
2015-03-23 22:29:39+0000 [xxu46_1] INFO: Crawled 31 pages (at 1 pages/min), scraped 25 items (at 1 items/min)
2015-03-23 22:30:39+0000 [xxu46_1] INFO: Crawled 31 pages (at 0 pages/min), scraped 25 items (at 0 items/min)
2015-03-23 22:30:57+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3329> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:30:57+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3329>
	{'abstract': u'In this paper, we show that performance of the virtualized cluster servers could be improved through intelligent decision over migration time of Virtual Machines across heterogeneous physical nodes of a cluster server. The cluster serves a variety range of services from Web Service to File Service. Some of them are CPU-Intensive while others are RAM-Intensive and so on. Virtualization has many advantages such as less hardware cost, cooling cost, more manageability. One of the key benefits is better load balancing by using of VM migration between hosts. To migrate, we must know which virtual machine needs to be migrated and when this relocation has to be done and, moreover, which host must be destined. To relocate VMs from overloaded servers to underloaded ones, we need to sort nodes from the highest volume to the lowest. There are some models to finding the most overloaded node, but they have some shortcomings. The focus of this paper is to present a new method to migrate VMs between cluster nodes using TOPSIS algorithm - one of the most efficient Multi Criteria Decision Making techniques- to make more effective decision over whole active servers of the Cluster and find the most loaded serversTo evaluate the performance improvement resulted from this model, we used cluster Response time and Unbalanced Factor.',
	 'authors': u'M.Tarighi, S.A.Motamedi, S.Sharifian,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3329',
	 'subjects': u'Operating Systems (cs.OS)',
	 'title': u'\nA new model for virtual machine migration in virtualized cluster server  based on Fuzzy Decision Making',
	 'urllink': u'http://arxiv.org/abs/1002.3329'}
2015-03-23 22:31:39+0000 [xxu46_1] INFO: Crawled 32 pages (at 1 pages/min), scraped 26 items (at 1 items/min)
2015-03-23 22:32:24+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3328> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:32:24+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3328>
	{'abstract': u'One of the biggest drawbacks of the wireless environment is the limited bandwidth. However, the users sharing this limited bandwidth have been increasing considerably.Space Division Multiple Access (SDMA) is a new technology by which the capacity of existing mobile communication systems can economically be increased. This paper has been presented how the capacity can be enhanced by using SDMA with smart antennas in mobile communications system. Based on Adaptive Antenna Array (AAA) technology the spatial dimension of the existing system is exploited by means of forming independent radio beams in each of the original channels. This paper analyses the comparison of average Bit Error Rate (BER) of SDMA and CDMA technique and the different ways in which SDMA can be introduced to increase the capacity of a cellular system. The probability of error is found for a standard omni directional base station antenna, and another set of curves is found for flat top beam having a directivity of 5.1dB. It is assumed that k separate flat top beams can be formed by base station and pointed each of the k users within the cell of interest. Noticing that for an average probability of error greater than 0.1 in a propagation path loss environment of n=4, the flat top beam will support 200 users, whereas the omni-directional antenna will support only 50 users. This increase the number of user is roughly equal to the directivity offered by the flat top beam system, and illustrates the promise SDMA offers for improving capacity in wireless system. Here multipath fading is not considered.',
	 'authors': u'Md. M. Hossain, J.Hossain,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3328',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nError Performance Analysis to Increase Capacity of A Cellular System  Using SDMA',
	 'urllink': u'http://arxiv.org/abs/1002.3328'}
2015-03-23 22:32:39+0000 [xxu46_1] INFO: Crawled 33 pages (at 1 pages/min), scraped 27 items (at 1 items/min)
2015-03-23 22:33:39+0000 [xxu46_1] INFO: Crawled 33 pages (at 0 pages/min), scraped 27 items (at 0 items/min)
2015-03-23 22:34:01+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3326> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:34:01+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3326>
	{'abstract': u'Topological design of terrestrial networks for communication via satellites is studied in the paper. Quantitative model of the network cost-analysis minimizing the total transmission and switching cost is described. Several algorithms solving combinatorial problem of the optimal topology design based on binary partitioning, a minimax parametric search and dynamic programming are developed by the author and demonstrated with a numeric example. Analysis of average complexity of the minimax parametric search algorithm is also provided.',
	 'authors': u'Boris S. Verkhovsky,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3326',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nDesign of Optimal Topology of Satellite-Based Terrestrial Communication  Networks',
	 'urllink': u'http://arxiv.org/abs/1002.3326'}
2015-03-23 22:34:39+0000 [xxu46_1] INFO: Crawled 34 pages (at 1 pages/min), scraped 28 items (at 1 items/min)
2015-03-23 22:35:39+0000 [xxu46_1] INFO: Crawled 34 pages (at 0 pages/min), scraped 28 items (at 0 items/min)
2015-03-23 22:35:48+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3322> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:35:48+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3322>
	{'abstract': u'Denial of service attacks (DoS) can cause significant financial damages. Flooding and Malicious packets are two kinds of DoS attacks. This paper presents a new security approach which stops malicious packets and prevents flooding in the critical systems. New concepts of packet stamp a dynamic-multi-communication-point mechanism has been identified for this proposed approach to make the prevention of flooding attacks easier and the performing of malicious packet attacks harder. In addition, dynamic key encryption technique has been adapted as a part of the proposed approach to enhance its functionality.',
	 'authors': u'M.A. Alhabeeb, A.M Almuhaideb, P.D Le,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3322',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nHolistic Approach for Critical System Security: Flooding Prevention and  Malicious Packet Stopping',
	 'urllink': u'http://arxiv.org/abs/1002.3322'}
2015-03-23 22:36:39+0000 [xxu46_1] INFO: Crawled 35 pages (at 1 pages/min), scraped 29 items (at 1 items/min)
2015-03-23 22:37:16+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3320> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:37:16+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3320>
	{'abstract': u'Combined with space-time coding, the orthogonal frequency division multiplexing (OFDM) system explores space diversity. It is a potential scheme to offer spectral efficiency and robust high data rate transmissions over frequency-selective fading channel. However, space-time coding impairs the system ability to suppress interferences as the signals transmitted from two transmit antennas are superposed and interfered at the receiver antennas. In this paper, we developed an adaptive beamforming based on least mean squared error algorithm and null deepening to combat co-channel interference (CCI) for the space-time coded OFDM (STC-OFDM) system. To illustrate the performance of the presented approach, it is compared to the null steering beamformer which requires a prior knowledge of directions of arrival (DOAs). The structure of space-time decoders are preserved although there is the use of beamformers before decoding. By incorporating the proposed beamformer as a CCI canceller in the STC-OFDM systems, the performance improvement is achieved as shown in the simulation results.',
	 'authors': u'Raungrong Suleesathira,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3320',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nCo-channel Interference Cancellation for Space-Time Coded OFDM Systems  Using Adaptive Beamforming and Null Deepening',
	 'urllink': u'http://arxiv.org/abs/1002.3320'}
2015-03-23 22:37:39+0000 [xxu46_1] INFO: Crawled 36 pages (at 1 pages/min), scraped 30 items (at 1 items/min)
2015-03-23 22:38:39+0000 [xxu46_1] INFO: Crawled 36 pages (at 0 pages/min), scraped 30 items (at 0 items/min)
2015-03-23 22:38:59+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3317> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:38:59+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3317>
	{'abstract': u'Multiple Input Multiple Output (MIMO) systems have recently emerged as a key technology in wireless communication systems for increasing both data rates and system performance. There are many schemes that can be applied to MIMO systems such as space time block codes, space time trellis codes, and the Vertical Bell Labs Space-Time Architecture (V-BLAST). This paper proposes a novel signal detector scheme called MIMO detectors to enhance the performance in MIMO channels. We study the general MIMO system, the general V-BLAST architecture with Maximum Likelihood (ML), Zero- Forcing (ZF), Minimum Mean- Square Error (MMSE), and Ordered Successive Interference Cancellation (SIC) detectors and simulate this structure in Rayleigh fading channel. Also compares the performances of MIMO system with different modulation techniques in Fading and AWGN channels. Base on frame error rates and bit error rates, we compare the performance and the computational complexity of these schemes with other existence model.Simulations shown that V-BLAST implements a detection technique, i.e. SIC receiver, based on ZF or MMSE combined with symbol cancellation and optimal ordering to improve the performance with lower complexity, although ML receiver appears to have the best SER performance-BLAST achieves symbol error rates close to the ML scheme while retaining the lowcomplexity nature of the V-BLAST.',
	 'authors': u'Nirmalendu Bikas Sinha, S.Chakraborty, P. K. Sutradhar, R. Bera, M.Mitra,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3317',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nOptimization of MIMO detectors: Unleashing the multiplexing gain',
	 'urllink': u'http://arxiv.org/abs/1002.3317'}
2015-03-23 22:39:39+0000 [xxu46_1] INFO: Crawled 37 pages (at 1 pages/min), scraped 31 items (at 1 items/min)
2015-03-23 22:40:34+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3316> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:40:34+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3316>
	{'abstract': u'A directly public verifiable signcryption scheme is introduced in this paper that provides the security attributes of message confidentiality, authentication, integrity, non-repudiation, unforgeability, and forward secrecy of message confidentiality. It provides the attribute of direct public verifiability so anyone can verify the signcryption without any need for any secret information from the corresponding participants. The proposed scheme is based on elliptic curve cryptography and is so suitable for environments with resource constraints.',
	 'authors': u'M. Toorani, A. A. Beheshti,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3316',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nA Directly Public Verifiable Signcryption Scheme based on Elliptic  Curves',
	 'urllink': u'http://arxiv.org/abs/1002.3316'}
2015-03-23 22:40:39+0000 [xxu46_1] INFO: Crawled 38 pages (at 1 pages/min), scraped 32 items (at 1 items/min)
2015-03-23 22:41:39+0000 [xxu46_1] INFO: Crawled 38 pages (at 0 pages/min), scraped 32 items (at 0 items/min)
2015-03-23 22:41:51+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3312> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:41:51+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3312>
	{'abstract': u'We focus on the downlink of a cellular system, which corresponds to the bulk of the data transfer in such wireless systems. We address the problem of opportunistic multiuser scheduling under imperfect channel state information, by exploiting the memory inherent in the channel. In our setting, the channel between the base station and each user is modeled by a two-state Markov chain and the scheduled user sends back an ARQ feedback signal that arrives at the scheduler with a random delay that is i.i.d across users and time. The scheduler indirectly estimates the channel via accumulated delayed-ARQ feedback and uses this information to make scheduling decisions. We formulate a throughput maximization problem as a partially observable Markov decision process (POMDP). For the case of two users in the system, we show that a greedy policy is sum throughput optimal for any distribution on the ARQ feedback delay. For the case of more than two users, we prove that the greedy policy is suboptimal and demonstrate, via numerical studies, that it has near optimal performance. We show that the greedy policy can be implemented by a simple algorithm that does not require the statistics of the underlying Markov channel or the ARQ feedback delay, thus making it robust against errors in system parameter estimation. Establishing an equivalence between the two-user system and a genie-aided system, we obtain a simple closed form expression for the sum capacity of the Markov-modeled downlink. We further derive inner and outer bounds on the capacity region of the Markov-modeled downlink and tighten these bounds for special cases of the system parameters.',
	 'authors': u'Sugumar Murugesan, Philip Schniter, Ness B. Shroff,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3312',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nMultiuser Scheduling in a Markov-modeled Downlink using Randomly Delayed  ARQ Feedback',
	 'urllink': u'http://arxiv.org/abs/1002.3312'}
2015-03-23 22:42:39+0000 [xxu46_1] INFO: Crawled 39 pages (at 1 pages/min), scraped 33 items (at 1 items/min)
2015-03-23 22:43:32+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3307> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:43:32+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3307>
	{'abstract': u'We propose a new approach to the analysis of Loopy Belief Propagation (LBP) by establishing a formula that connects the Hessian of the Bethe free energy with the edge zeta function. The formula has a number of theoretical implications on LBP. It is applied to give a sufficient condition that the Hessian of the Bethe free energy is positive definite, which shows non-convexity for graphs with multiple cycles. The formula clarifies the relation between the local stability of a fixed point of LBP and local minima of the Bethe free energy. We also propose a new approach to the uniqueness of LBP fixed point, and show various conditions of uniqueness.',
	 'authors': u'Yusuke Watanabe, Kenji Fukumizu,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3307',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nGraph Zeta Function in the Bethe Free Energy and Loopy Belief  Propagation',
	 'urllink': u'http://arxiv.org/abs/1002.3307'}
2015-03-23 22:43:39+0000 [xxu46_1] INFO: Crawled 40 pages (at 1 pages/min), scraped 34 items (at 1 items/min)
2015-03-23 22:44:22+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3303> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:44:22+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3303>
	{'abstract': u"The signcryption is a relatively new cryptographic technique that is supposed to fulfill the functionalities of encryption and digital signature in a single logical step. Several signcryption schemes are proposed throughout the years, each of them having its own problems and limitations. In this paper, the security of a recent signcryption scheme, i.e. Hwang et al.'s scheme is analyzed, and it is proved that it involves several security flaws and shortcomings. Several devastating attacks are also introduced to the mentioned scheme whereby it fails all the desired and essential security attributes of a signcryption scheme.",
	 'authors': u'M. Toorani, A. A. Beheshti,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3303',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nCryptanalysis of an Efficient Signcryption Scheme with Forward Secrecy  Based on Elliptic Curve',
	 'urllink': u'http://arxiv.org/abs/1002.3303'}
2015-03-23 22:44:39+0000 [xxu46_1] INFO: Crawled 41 pages (at 1 pages/min), scraped 35 items (at 1 items/min)
2015-03-23 22:45:39+0000 [xxu46_1] INFO: Crawled 41 pages (at 0 pages/min), scraped 35 items (at 0 items/min)
2015-03-23 22:45:50+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3299> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:45:50+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3299>
	{'abstract': u'The non-repudiation as an essential requirement of many applications can be provided by the asymmetric key model. With the evolution of new applications such as mobile commerce, it is essential to provide secure and efficient solutions for the mobile environments. The traditional public key cryptography involves huge computational costs and is not so suitable for the resource-constrained platforms. The elliptic curve-based approaches as the newer solutions require certain considerations that are not taken into account in the traditional public key infrastructures. The main contribution of this paper is to introduce a Lightweight Public Key Infrastructure (LPKI) for the constrained platforms such as mobile phones. It takes advantages of elliptic curve cryptography and signcryption to decrease the computational costs and communication overheads, and adapting to the constraints. All the computational costs of required validations can be eliminated from end-entities by introduction of a validation authority to the introduced infrastructure and delegating validations to such a component. LPKI is so suitable for mobile environments and for applications such as mobile commerce where the security is the great concern.',
	 'authors': u'M. Toorani, A. A. Beheshti,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3299',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nLPKI - A Lightweight Public Key Infrastructure for the Mobile  Environments',
	 'urllink': u'http://arxiv.org/abs/1002.3299'}
2015-03-23 22:46:39+0000 [xxu46_1] INFO: Crawled 42 pages (at 1 pages/min), scraped 36 items (at 1 items/min)
2015-03-23 22:47:09+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3258> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:47:09+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3258>
	{'abstract': u"This paper presents three feedback controllers that achieve an asymptotically stable, periodic, and fast walking gait for a 3D (spatial) bipedal robot consisting of a torso, two legs, and passive (unactuated) point feet. The contact between the robot and the walking surface is assumed to inhibit yaw rotation. The studied robot has 8 DOF in the single support phase and 6 actuators. The interest of studying robots with point feet is that the robot's natural dynamics must be explicitly taken into account to achieve balance while walking. We use an extension of the method of virtual constraints and hybrid zero dynamics, in order to simultaneously compute a periodic orbit and an autonomous feedback controller that realizes the orbit. This method allows the computations to be carried out on a 2-DOF subsystem of the 8-DOF robot model. The stability of the walking gait under closed-loop control is evaluated with the linearization of the restricted Poincar 'e map of the hybrid zero dynamics. Three strategies are explored. The first strategy consists of imposing a stability condition during the search of a periodic gait by optimization. The second strategy uses an event-based controller. In the third approach, the effect of output selection is discussed and a pertinent choice of outputs is proposed, leading to stabilization without the use of a supplemental event-based controller.",
	 'authors': u'Christine Chevallereau, Jessy W. Grizzle, Ching-Long Shih,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3258',
	 'subjects': u'Robotics (cs.RO)',
	 'title': u'\nAsymptotically Stable Walking of a Five-Link Underactuated 3D Bipedal  Robot',
	 'urllink': u'http://arxiv.org/abs/1002.3258'}
2015-03-23 22:47:39+0000 [xxu46_1] INFO: Crawled 43 pages (at 1 pages/min), scraped 37 items (at 1 items/min)
2015-03-23 22:48:39+0000 [xxu46_1] INFO: Crawled 43 pages (at 0 pages/min), scraped 37 items (at 0 items/min)
2015-03-23 22:48:54+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3239> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:48:55+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3239>
	{'abstract': u'The max-product algorithm, a local message-passing scheme that attempts to compute the most probable assignment (MAP) of a given probability distribution, has been successfully employed as a method of approximate inference for applications arising in coding theory, computer vision, and machine learning. However, the max-product algorithm is not guaranteed to converge to the MAP assignment, and if it does, is not guaranteed to recover the MAP assignment. Alternative convergent message-passing schemes have been proposed to overcome these difficulties. This work provides a systematic study of such message-passing algorithms that extends the known results by exhibiting new sufficient conditions for convergence to local and/or global optima, providing a combinatorial characterization of these optima based on graph covers, and describing a new convergent and correct message-passing algorithm whose derivation unifies many of the known convergent message-passing algorithms. While convergent and correct message-passing algorithms represent a step forward in the analysis of max-product style message-passing algorithms, the conditions needed to guarantee convergence to a global optimum can be too restrictive in both theory and practice. This limitation of convergent and correct message-passing schemes is characterized by graph covers and illustrated by example.',
	 'authors': u'Nicholas Ruozzi, Sekhar Tatikonda,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3239',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nMessage-Passing Algorithms: Reparameterizations and Splittings',
	 'urllink': u'http://arxiv.org/abs/1002.3239'}
2015-03-23 22:49:39+0000 [xxu46_1] INFO: Crawled 44 pages (at 1 pages/min), scraped 38 items (at 1 items/min)
2015-03-23 22:50:39+0000 [xxu46_1] INFO: Crawled 44 pages (at 0 pages/min), scraped 38 items (at 0 items/min)
2015-03-23 22:50:39+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3238> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:50:39+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3238>
	{'abstract': u'In Information Retrieval (IR), whether implicitly or explicitly, queries and documents are often represented as vectors. However, it may be more beneficial to consider documents and/or queries as multidimensional objects. Our belief is this would allow building "truly" interactive IR systems, i.e., where interaction is fully incorporated in the IR framework. The probabilistic formalism of quantum physics represents events and densities as multidimensional objects. This paper presents our first step towards building an interactive IR framework upon this formalism, by stating how the first interaction of the retrieval process, when the user types a query, can be formalised. Our framework depends on a number of parameters affecting the final document ranking. In this paper we experimentally investigate the effect of these parameters, showing that the proposed representation of documents and queries as multidimensional objects can compete with standard approaches, with the additional prospect to be applied to interactive retrieval.',
	 'authors': u'Benjamin Piwowarski, Ingo Frommholz, Mounia Lalmas, Keith van Rijsbergen,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3238',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nExploring a Multidimensional Representation of Documents and Queries  (extended version)',
	 'urllink': u'http://arxiv.org/abs/1002.3238'}
2015-03-23 22:51:39+0000 [xxu46_1] INFO: Crawled 45 pages (at 1 pages/min), scraped 39 items (at 1 items/min)
2015-03-23 22:52:12+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3234> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:52:12+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3234>
	{'abstract': u'We consider the problem of subspace estimation in situations where the number of available snapshots and the observation dimension are comparable in magnitude. In this context, traditional subspace methods tend to fail because the eigenvectors of the sample correlation matrix are heavily biased with respect to the true ones. It has recently been suggested that this situation (where the sample size is small compared to the observation dimension) can be very accurately modeled by considering the asymptotic regime where the observation dimension and the number of snapshots converge to at the same rate. Using large random matrix theory results, it can be shown that traditional subspace estimates are not consistent in this asymptotic regime. Furthermore, new consistent subspace estimate can be proposed, which outperform the standard subspace methods for realistic values of and . The work carried out so far in this area has always been based on the assumption that the observations are random, independent and identically distributed in the time domain. The goal of this paper is to propose new consistent subspace estimators for the case where the source signals are modelled as unknown deterministic signals. In practice, this allows to use the proposed approach regardless of the statistical properties of the source signals. In order to construct the proposed estimators, new technical results concerning the almost sure location of the eigenvalues of sample covariance matrices of Information plus Noise complex Gaussian models are established. These results are believed to be of independent interest.',
	 'authors': u'Pascal Vallet, Philippe Loubaton, Xavier Mestre,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3234',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nImproved subspace estimation for multivariate observations of high  dimension: the deterministic signals case',
	 'urllink': u'http://arxiv.org/abs/1002.3234'}
2015-03-23 22:52:39+0000 [xxu46_1] INFO: Crawled 46 pages (at 1 pages/min), scraped 40 items (at 1 items/min)
2015-03-23 22:53:39+0000 [xxu46_1] INFO: Crawled 46 pages (at 0 pages/min), scraped 40 items (at 0 items/min)
2015-03-23 22:53:55+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3229> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:53:55+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3229>
	{'abstract': u'Information theoretic Broadcast Channels (BC) and Multiple Access Channels (MAC) enable a single node to transmit data simultaneously to multiple nodes, and multiple nodes to transmit data simultaneously to a single node respectively. In this paper, we address the problem of link scheduling in multihop wireless networks containing nodes with BC and MAC capabilities. We first propose an interference model that extends protocol interference models, originally designed for point to point channels, to include the possibility of BC and MAC. Due to the high complexity of optimal link schedulers, we introduce the Multiuser Greedy Maximum Weight algorithm for link scheduling in multihop wireless networks containing BCs and MACs. Given a network graph, we develop new local pooling conditions and show that the performance of our algorithm can be fully characterized using the associated parameter, the multiuser local pooling factor. We provide examples of some network graphs, on which we apply local pooling conditions and derive the multiuser local pooling factor. We prove optimality of our algorithm in tree networks and show that the exploitation of BCs and MACs improve the throughput performance considerably in multihop wireless networks.',
	 'authors': u'Arun Sridharan, C. Emre Koksal, Elif Uysal-Biyikoglu,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3229',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nA Greedy link scheduler for Wireless Networks having Gaussian Broadcast  and Multiple Access Channels',
	 'urllink': u'http://arxiv.org/abs/1002.3229'}
2015-03-23 22:54:39+0000 [xxu46_1] INFO: Crawled 47 pages (at 1 pages/min), scraped 41 items (at 1 items/min)
2015-03-23 22:55:39+0000 [xxu46_1] INFO: Crawled 47 pages (at 0 pages/min), scraped 41 items (at 0 items/min)
2015-03-23 22:55:42+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3222> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:55:42+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3222>
	{'abstract': u'We analyse the problem of solving Boolean equation systems through the use of structure graphs. The latter are obtained through an elegant set of Plotkin-style deduction rules. Our main contribution is that we show that equation systems with bisimilar structure graphs have the same solution. We show that our work conservatively extends earlier work, conducted by Keiren and Willemse, in which dependency graphs were used to analyse a subclass of Boolean equation systems, viz., equation systems in standard recursive form. We illustrate our approach by a small example, demonstrating the effect of simplifying an equation system through minimisation of its structure graph.',
	 'authors': u'Jeroen Keiren, Michel A. Reniers, Tim A.C. Willemse,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3222',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nStructural Analysis of Boolean Equation Systems',
	 'urllink': u'http://arxiv.org/abs/1002.3222'}
2015-03-23 22:56:39+0000 [xxu46_1] INFO: Crawled 48 pages (at 1 pages/min), scraped 42 items (at 1 items/min)
2015-03-23 22:57:17+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3195> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:57:17+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3195>
	{'abstract': u"Similarity networks are important abstractions in many information management applications such as recommender systems, corpora analysis, and medical informatics. For instance, by inducing similarity networks between movies rated similarly by users, or between documents containing common terms, and or between clinical trials involving the same themes, we can aim to find the global structure of connectivities underlying the data, and use the network as a basis to make connections between seemingly disparate entities. In the above applications, composing similarities between objects of interest finds uses in serendipitous recommendation, in storytelling, and in clinical diagnosis, respectively. We present an algorithmic framework for traversing similarity paths using the notion of `hammock' paths which are generalization of traditional paths. Our framework is exploratory in nature so that, given starting and ending objects of interest, it explores candidate objects for path following, and heuristics to admissibly estimate the potential for paths to lead to a desired destination. We present three diverse applications: exploring movie similarities in the Netflix dataset, exploring abstract similarities across the PubMed corpus, and exploring description similarities in a database of clinical trials. Experimental results demonstrate the potential of our approach for unstructured knowledge discovery in similarity networks.",
	 'authors': u'M. Shahriar Hossain, Michael Narayan, Naren Ramakrishnan,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3195',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nEfficiently Discovering Hammock Paths from Induced Similarity Networks',
	 'urllink': u'http://arxiv.org/abs/1002.3195'}
2015-03-23 22:57:39+0000 [xxu46_1] INFO: Crawled 49 pages (at 1 pages/min), scraped 43 items (at 1 items/min)
2015-03-23 22:58:31+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3192> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 22:58:31+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3192>
	{'abstract': u'In this paper, we consider full-duplex and half-duplex Gaussian relay channels where the noises at the relay and destination are arbitrarily correlated. We first derive the capacity upper bound and the achievable rates with three existing schemes: Decode-and-Forward (DF), Compress-and-Forward (CF), and Amplify-and-Forward (AF). We present two capacity results under specific noise correlation coefficients, one being achieved by DF and the other being achieved by direct link transmission (or a special case of CF). The channel for the former capacity result is equivalent to the traditional Gaussian degraded relay channel and the latter corresponds to the Gaussian reversely-degraded relay channel. For CF and AF schemes, we show that their achievable rates are strictly decreasing functions over the negative correlation coefficient. Through numerical comparisons under different channel settings, we observe that although DF completely disregards the noise correlation while the other two can potentially exploit such extra information, none of the three relay schemes always outperforms the others over different correlation coefficients. Moreover, the exploitation of noise correlation by CF and AF accrues more benefit when the source-relay link is weak. This paper also considers the optimal power allocation problem under the correlated-noise channel setting. With individual power constraints at the relay and the source, it is shown that the relay should use all its available power to maximize the achievable rates under any correlation coefficient. With a total power constraint across the source and the relay, the achievable rates are proved to be concave functions over the power allocation factor for AF and CF under full-duplex mode, where the closed-form power allocation strategy is derived.',
	 'authors': u'Lili Zhang, Jinhua Jiang, Andrea J. Goldsmith, Shuguang Cui,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3192',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nStudy of Gaussian Relay Channels with Correlated Noises',
	 'urllink': u'http://arxiv.org/abs/1002.3192'}
2015-03-23 22:58:39+0000 [xxu46_1] INFO: Crawled 50 pages (at 1 pages/min), scraped 44 items (at 1 items/min)
2015-03-23 22:59:39+0000 [xxu46_1] INFO: Crawled 50 pages (at 0 pages/min), scraped 44 items (at 0 items/min)
2015-03-23 23:00:01+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3190> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:00:01+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3190>
	{'abstract': u'Collaborative intrusion detection networks are often used to gain better detection accuracy and cost efficiency as compared to a single host-based intrusion detection system (IDS). Through cooperation, it is possible for a local IDS to detect new attacks that may be known to other experienced acquaintances. In this paper, we present a sequential hypothesis testing method for feedback aggregation for each individual IDS in the net- work. Our simulation results corroborate our theoretical results and demonstrate the properties of cost efficiency and accuracy compared to other heuristic methods. The analytical result on the lower-bound of the average number of acquaintances for consultation is essential for the design and configuration of IDSs in a collaborative environment.',
	 'authors': u'Quanyan Zhu, Carol J. Fung, Raouf Boutaba, Tamer Basar,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3190',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nA Distributed Sequential Algorithm for Collaborative Intrusion Detection  Networks',
	 'urllink': u'http://arxiv.org/abs/1002.3190'}
2015-03-23 23:00:39+0000 [xxu46_1] INFO: Crawled 51 pages (at 1 pages/min), scraped 45 items (at 1 items/min)
2015-03-23 23:01:24+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3188> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:01:24+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3188>
	{'abstract': u'A noisy network coding scheme for sending multiple sources over a general noisy network is presented. For multi-source multicast networks, the scheme naturally extends both network coding over noiseless networks by Ahlswede, Cai, Li, and Yeung, and compress-forward coding for the relay channel by Cover and El Gamal to general discrete memoryless and Gaussian networks. The scheme also recovers as special cases the results on coding for wireless relay networks and deterministic networks by Avestimehr, Diggavi, and Tse, and coding for wireless erasure networks by Dana, Gowaikar, Palanki, Hassibi, and Effros. The scheme involves message repetition coding, relay signal compression, and simultaneous decoding. Unlike previous compress--forward schemes, where independent messages are sent over multiple blocks, the same message is sent multiple times using independent codebooks as in the network coding scheme for cyclic networks. Furthermore, the relays do not use Wyner--Ziv binning as in previous compress-forward schemes, and each decoder performs simultaneous joint typicality decoding on the received signals from all the blocks without explicitly decoding the compression indices. A consequence of this new scheme is that achievability is proved simply and more generally without resorting to time expansion to extend results for acyclic networks to networks with cycles. The noisy network coding scheme is then extended to general multi-source networks by combining it with decoding techniques for interference channels. For the Gaussian multicast network, noisy network coding improves the previously established gap to the cutset bound. We also demonstrate through two popular AWGN network examples that noisy network coding can outperform conventional compress-forward, amplify-forward, and hash-forward schemes.',
	 'authors': u'Sung Hoon Lim, Young-Han Kim, Abbas El Gamal, Sae-Young Chung,',
	 'category': u'Computer Science ',
	 'date': '2010-2-16',
	 'pdflink': u'http://arxiv.org/pdf/1002.3188',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nNoisy Network Coding',
	 'urllink': u'http://arxiv.org/abs/1002.3188'}
2015-03-23 23:01:39+0000 [xxu46_1] INFO: Crawled 52 pages (at 1 pages/min), scraped 46 items (at 1 items/min)
2015-03-23 23:02:39+0000 [xxu46_1] INFO: Crawled 52 pages (at 0 pages/min), scraped 46 items (at 0 items/min)
2015-03-23 23:02:50+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3187> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:02:50+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3187>
	{'abstract': u'We provide upper and lower bounds on the escape rate of the Bhattacharyya process corresponding to polar codes and transmission over the the binary erasure channel. More precisely, we bound the exponent of the number of sub-channels whose Bhattacharyya constant falls in a fixed interval . Mathematically this can be stated as bounding the limit , where is the Bhattacharyya process. The quantity represents the fraction of sub-channels that are still un-polarized at time .',
	 'authors': u'S. Hamed Hassani, Kasra Alishahi, Rudiger Urbanke,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3187',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOn the scaling of Polar Codes: II. The behavior of un-polarized channels',
	 'urllink': u'http://arxiv.org/abs/1002.3187'}
2015-03-23 23:03:39+0000 [xxu46_1] INFO: Crawled 53 pages (at 1 pages/min), scraped 47 items (at 1 items/min)
2015-03-23 23:04:20+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3183> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:04:20+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3183>
	{'abstract': u"Statistical query (SQ) learning model of Kearns (1993) is a natural restriction of the PAC learning model in which a learning algorithm is allowed to obtain estimates of statistical properties of the examples but cannot see the examples themselves. We describe a new and simple characterization of the query complexity of learning in the SQ learning model. Unlike the previously known bounds on SQ learning our characterization preserves the accuracy and the efficiency of learning. The preservation of accuracy implies that that our characterization gives the first characterization of SQ learning in the agnostic learning framework. The preservation of efficiency is achieved using a new boosting technique and allows us to derive a new approach to the design of evolutionary algorithms in Valiant's (2006) model of evolvability. We use this approach to demonstrate the existence of a large class of monotone evolutionary learning algorithms based on square loss performance estimation. These results differ significantly from the few known evolutionary algorithms and give evidence that evolvability in Valiant's model is a more versatile phenomenon than there had been previous reason to suspect.",
	 'authors': u'Vitaly Feldman,',
	 'category': u'Computer Science ',
	 'date': '2010-2-16',
	 'pdflink': u'http://arxiv.org/pdf/1002.3183',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nA Complete Characterization of Statistical Query Learning with  Applications to Evolvability',
	 'urllink': u'http://arxiv.org/abs/1002.3183'}
2015-03-23 23:04:39+0000 [xxu46_1] INFO: Crawled 54 pages (at 1 pages/min), scraped 48 items (at 1 items/min)
2015-03-23 23:05:22+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3180> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:05:22+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3180>
	{'abstract': u'We describe an algorithm for the factorization of non-commutative polynomials over a field. The first sketch of this algorithm appeared in an unpublished manuscript (literally hand written notes) by James H. Davenport more than 20 years ago. This version of the algorithm contains some improvements with respect to the original sketch. An improved version of the algorithm has been fully implemented in the Axiom computer algebra system.',
	 'authors': u'Fabrizio Caruso,',
	 'category': u'Computer Science ',
	 'date': '2010-2-16',
	 'pdflink': u'http://arxiv.org/pdf/1002.3180',
	 'subjects': u'Mathematical Software (cs.MS)',
	 'title': u'\nFactorization of Non-Commutative Polynomials',
	 'urllink': u'http://arxiv.org/abs/1002.3180'}
2015-03-23 23:05:39+0000 [xxu46_1] INFO: Crawled 55 pages (at 1 pages/min), scraped 49 items (at 1 items/min)
2015-03-23 23:06:39+0000 [xxu46_1] INFO: Crawled 55 pages (at 0 pages/min), scraped 49 items (at 0 items/min)
2015-03-23 23:06:58+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3176> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:06:58+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3176>
	{'abstract': u'The electronic mail plays an unavoidable role in the humankind communications. With the great interest for the connection via mobile platforms, and the growing number of vulnerabilities and attacks, it is essential to provide suitable security solutions regarding the limitations of resource restricted platforms. Although some solutions such as PGP and S/MIME are currently available for the secure e-mail over the Internet, they are based on traditional public key cryptography that involves huge computational costs. In this paper, a new secure application-layer protocol, called SMEmail, is introduced that provides several security attributes such as confidentiality, integrity, authentication, non-repudiation, and forward secrecy of message confidentiality for the electronic mails. SMEmail offers an elliptic curve-based public key solution that uses public keys for the secure key establishment of a symmetric encryption, and is so suitable for the resource restricted platforms such as mobile phones.',
	 'authors': u'M. Toorani,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3176',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nSMEmail - A New Protocol for the Secure E-mail in Mobile Environments',
	 'urllink': u'http://arxiv.org/abs/1002.3176'}
2015-03-23 23:07:39+0000 [xxu46_1] INFO: Crawled 56 pages (at 1 pages/min), scraped 50 items (at 1 items/min)
2015-03-23 23:08:30+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3175> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:08:30+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3175>
	{'abstract': u'Recently, the mobile industry has experienced an extreme increment in number of its users. The GSM network with the greatest worldwide number of users succumbs to several security vulnerabilities. Although some of its security problems are addressed in its upper generations, there are still many operators using 2G systems. This paper briefly presents the most important security flaws of the GSM network and its transport channels. It also provides some practical solutions to improve the security of currently available 2G systems.',
	 'authors': u'M. Toorani, A. A. Beheshti,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3175',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nSolutions to the GSM Security Weaknesses',
	 'urllink': u'http://arxiv.org/abs/1002.3175'}
2015-03-23 23:08:39+0000 [xxu46_1] INFO: Crawled 57 pages (at 1 pages/min), scraped 51 items (at 1 items/min)
2015-03-23 23:09:39+0000 [xxu46_1] INFO: Crawled 57 pages (at 0 pages/min), scraped 51 items (at 0 items/min)
2015-03-23 23:10:04+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3174> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:10:04+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3174>
	{'abstract': u'File type identification and file type clustering may be difficult tasks that have an increasingly importance in the field of computer and network security. Classical methods of file type detection including considering file extensions and magic bytes can be easily spoofed. Content-based file type detection is a newer way that is taken into account recently. In this paper, a new content-based method for the purpose of file type detection and file type clustering is proposed that is based on the PCA and neural networks. The proposed method has a good accuracy and is fast enough.',
	 'authors': u'M. C. Amirani, M. Toorani, A. A. Beheshti,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3174',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nA new approach to content-based file type detection',
	 'urllink': u'http://arxiv.org/abs/1002.3174'}
2015-03-23 23:10:39+0000 [xxu46_1] INFO: Crawled 58 pages (at 1 pages/min), scraped 52 items (at 1 items/min)
2015-03-23 23:11:29+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3171> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:11:29+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3171>
	{'abstract': u'The GSM network with the greatest worldwide number of users, succumbs to several security vulnerabilities. The short message service (SMS) is one of its superior and well-tried services with a global availability in the GSM networks. The main contribution of this paper is to introduce a new secure application layer protocol, called SSMS, to efficiently embed the desired security attributes in the SMS messages to be used as a secure bearer in the m-payment systems. SSMS efficiently embeds the confidentiality, integrity, authentication, and non-repudiation in the SMS messages. It provides an elliptic curve-based public key solution that uses public keys for the secret key establishment of a symmetric encryption. It also provides the attributes of public verification and forward secrecy. It efficiently makes the SMS messaging suitable for the m-payment applications where the security is the great concern.',
	 'authors': u'M. Toorani, A. A. Beheshti,',
	 'category': u'Computer Science ',
	 'date': '2010-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1002.3171',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nSSMS - A Secure SMS Messaging Protocol for the M-payment Systems',
	 'urllink': u'http://arxiv.org/abs/1002.3171'}
2015-03-23 23:11:39+0000 [xxu46_1] INFO: Crawled 59 pages (at 1 pages/min), scraped 53 items (at 1 items/min)
2015-03-23 23:12:36+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3131> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:12:36+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3131>
	{'abstract': u'We show that for Multiplicative Exponential Linear Logic (without weakenings) the syntactical equivalence relation on proofs induced by cut-elimination coincides with the semantic equivalence relation on proofs induced by the multiset based relational model: one says that the interpretation in the model (or the semantics) is injective. We actually prove a stronger result: two cut-free proofs of the full multiplicative and exponential fragment of linear logic whose interpretations coincide in the multiset based relational model are the same "up to the connections between the doors of exponential boxes".',
	 'authors': u'Daniel de Carvalho, Lorenzo Tortora de Falco,',
	 'category': u'Computer Science ',
	 'date': '2010-2-16',
	 'pdflink': u'http://arxiv.org/pdf/1002.3131',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nThe relational model is injective for Multiplicative Exponential Linear  Logic (without weakenings)',
	 'urllink': u'http://arxiv.org/abs/1002.3131'}
2015-03-23 23:12:39+0000 [xxu46_1] INFO: Crawled 60 pages (at 1 pages/min), scraped 54 items (at 1 items/min)
2015-03-23 23:13:39+0000 [xxu46_1] INFO: Crawled 60 pages (at 0 pages/min), scraped 54 items (at 0 items/min)
2015-03-23 23:14:21+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3117> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:14:21+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3117>
	{'abstract': u'We study error bounds for linear programming decoding of regular LDPC codes. For memoryless binary-input output-symmetric channels, we prove bounds on the word error probability that are inverse doubly-exponential in the girth of the factor graph. For memoryless binary-input AWGN channel, we prove lower bounds on the threshold for regular LDPC codes whose factor graphs have logarithmic girth under LP-decoding. Specifically, we prove a lower bound of (upper bound of dB) on the threshold of -regular LDPC codes whose factor graphs have logarithmic girth. Our proof is an extension of a recent paper of Arora, Daskalakis, and Steurer [STOC 2009] who presented a novel probabilistic analysis of LP decoding over a binary symmetric channel. Their analysis is based on the primal LP representation and has an explicit connection to message passing algorithms. We extend this analysis to any MBIOS channel.',
	 'authors': u'Nissim Halabi, Guy Even,',
	 'category': u'Computer Science ',
	 'date': '2010-2-16',
	 'pdflink': u'http://arxiv.org/pdf/1002.3117',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nLP Decoding of Regular LDPC Codes in Memoryless Channels',
	 'urllink': u'http://arxiv.org/abs/1002.3117'}
2015-03-23 23:14:39+0000 [xxu46_1] INFO: Crawled 61 pages (at 1 pages/min), scraped 55 items (at 1 items/min)
2015-03-23 23:15:39+0000 [xxu46_1] INFO: Crawled 61 pages (at 0 pages/min), scraped 55 items (at 0 items/min)
2015-03-23 23:15:57+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3102> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:15:57+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3102>
	{'abstract': u"Ads on the Internet are increasingly sold via ad exchanges such as RightMedia, AdECN and Doubleclick Ad Exchange. These exchanges allow real-time bidding, that is, each time the publisher contacts the exchange, the exchange ``calls out'' to solicit bids from ad networks. This aspect of soliciting bids introduces a novel aspect, in contrast to existing literature. This suggests developing a joint optimization framework which optimizes over the allocation and well as solicitation. We model this selective call out as an online recurrent Bayesian decision framework with bandwidth type constraints. We obtain natural algorithms with bounded performance guarantees for several natural optimization criteria. We show that these results hold under different call out constraint models, and different arrival processes. Interestingly, the paper shows that under MHR assumptions, the expected revenue of generalized second price auction with reserve is constant factor of the expected welfare. Also the analysis herein allow us prove adaptivity gap type results for the adwords problem.",
	 'authors': u'Tanmoy Chakraborty, Eyal Even-Dar, Sudipto Guha, Yishay Mansour, S. Muthukrishnan,',
	 'category': u'Computer Science ',
	 'date': '2010-2-16',
	 'pdflink': u'http://arxiv.org/pdf/1002.3102',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nSelective Call Out and Real Time Bidding',
	 'urllink': u'http://arxiv.org/abs/1002.3102'}
2015-03-23 23:16:39+0000 [xxu46_1] INFO: Crawled 62 pages (at 1 pages/min), scraped 56 items (at 1 items/min)
2015-03-23 23:17:39+0000 [xxu46_1] INFO: Crawled 62 pages (at 0 pages/min), scraped 56 items (at 0 items/min)
2015-03-23 23:17:45+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3086> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:17:45+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3086>
	{'abstract': u'Recently, new approaches to adaptive control have sought to reformulate the problem as a minimization of a relative entropy criterion to obtain tractable solutions. In particular, it has been shown that minimizing the expected deviation from the causal input-output dependencies of the true plant leads to a new promising stochastic control rule called the Bayesian control rule. This work proves the convergence of the Bayesian control rule under two sufficient assumptions: boundedness, which is an ergodicity condition; and consistency, which is an instantiation of the sure-thing principle.',
	 'authors': u'Pedro A. Ortega, Daniel A. Braun,',
	 'category': u'Computer Science ',
	 'date': '2010-2-16',
	 'pdflink': u'http://arxiv.org/pdf/1002.3086',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nConvergence of Bayesian Control Rule',
	 'urllink': u'http://arxiv.org/abs/1002.3086'}
2015-03-23 23:18:39+0000 [xxu46_1] INFO: Crawled 63 pages (at 1 pages/min), scraped 57 items (at 1 items/min)
2015-03-23 23:19:10+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3084> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:19:10+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3084>
	{'abstract': u"Dynamic Spectrum Access systems exploit temporarily available spectrum (`white spaces') and can spread transmissions over a number of non-contiguous sub-channels. Such methods are highly beneficial in terms of spectrum utilization. However, excessive fragmentation degrades performance and hence off-sets the benefits. Thus, there is a need to study these processes so as to determine how to ensure acceptable levels of fragmentation. Hence, we present experimental and analytical results derived from a mathematical model. We model a system operating at capacity serving requests for bandwidth by assigning a collection of gaps (sub-channels) with no limitations on the fragment size. Our main theoretical result shows that even if fragments can be arbitrarily small, the system does not degrade with time. Namely, the average total number of fragments remains bounded. Within the very difficult class of dynamic fragmentation models (including models of storage fragmentation), this result appears to be the first of its kind. Extensive experimental results describe behavior, at times unexpected, of fragmentation under different algorithms. Our model also applies to dynamic linked-list storage allocation, and provides a novel analysis in that domain. We prove that, interestingly, the 50% rule of the classical (non-fragmented) allocation model carries over to our model. Overall, the paper provides insights into the potential behavior of practical fragmentation algorithms.",
	 'authors': u'Ed Coffman, Philippe Robert, Florian Simatos, Shuzo Tarumi, Gil Zussman,',
	 'category': u'Computer Science ',
	 'date': '2010-2-16',
	 'pdflink': u'http://arxiv.org/pdf/1002.3084',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nChannel Fragmentation in Dynamic Spectrum Access Systems - a Theoretical  Study',
	 'urllink': u'http://arxiv.org/abs/1002.3084'}
2015-03-23 23:19:39+0000 [xxu46_1] INFO: Crawled 64 pages (at 1 pages/min), scraped 58 items (at 1 items/min)
2015-03-23 23:20:39+0000 [xxu46_1] INFO: Crawled 64 pages (at 0 pages/min), scraped 58 items (at 0 items/min)
2015-03-23 23:20:57+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3083> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:20:57+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3083>
	{'abstract': u'Live sequence charts (LSCs) have been proposed as an inter-object scenario-based specification and visual programming language for reactive systems. In this paper, we introduce a logic-based framework to check the consistency of an LSC specification. An LSC simulator has been implemented in logic programming, utilizing a memoized depth-first search strategy, to show how a reactive system in LSCs would response to a set of external event sequences. A formal notation is defined to specify external event sequences, extending the regular expression with a parallel operator and a testing control. The parallel operator allows interleaved parallel external events to be tested in LSCs simultaneously; while the testing control provides users to a new approach to specify and test certain temporal properties (e.g., CTL formula) in a form of LSC. Our framework further provides either a state transition graph or a failure trace to justify the consistency checking results.',
	 'authors': u'Hai-Feng Guo, Wen Zheng, Mahadevan Subramaniam,',
	 'category': u'Computer Science ',
	 'date': '2010-2-16',
	 'pdflink': u'http://arxiv.org/pdf/1002.3083',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nL2C2: Logic-based LSC Consistency Checking',
	 'urllink': u'http://arxiv.org/abs/1002.3083'}
2015-03-23 23:21:39+0000 [xxu46_1] INFO: Crawled 65 pages (at 1 pages/min), scraped 59 items (at 1 items/min)
2015-03-23 23:22:34+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3078> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:22:34+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3078>
	{'abstract': u'Transforming constraint models is an important task in re- cent constraint programming systems. User-understandable models are defined during the modeling phase but rewriting or tuning them is manda- tory to get solving-efficient models. We propose a new architecture al- lowing to define bridges between any (modeling or solver) languages and to implement model optimizations. This architecture follows a model- driven approach where the constraint modeling process is seen as a set of model transformations. Among others, an interesting feature is the def- inition of transformations as concept-oriented rules, i.e. based on types of model elements where the types are organized into a hierarchy called a metamodel.',
	 'authors': u'Raphael Chenouard, Laurent Granvilliers, Ricardo Soto,',
	 'category': u'Computer Science ',
	 'date': '2010-2-16',
	 'pdflink': u'http://arxiv.org/pdf/1002.3078',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nUsing ATL to define advanced and flexible constraint model  transformations',
	 'urllink': u'http://arxiv.org/abs/1002.3078'}
2015-03-23 23:22:39+0000 [xxu46_1] INFO: Crawled 66 pages (at 1 pages/min), scraped 60 items (at 1 items/min)
2015-03-23 23:23:39+0000 [xxu46_1] INFO: Crawled 66 pages (at 0 pages/min), scraped 60 items (at 0 items/min)
2015-03-23 23:24:17+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3077> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:24:17+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3077>
	{'abstract': u'This article describes the implementation in the software package NumGfun of classical algorithms that operate on solutions of linear differential equations or recurrence relations with polynomial coefficients, including what seems to be the first general implementation of the fast high-precision numerical evaluation algorithms of Chudnovsky &amp; Chudnovsky. In some cases, our descriptions contain improvements over existing algorithms. We also provide references to relevant ideas not currently used in NumGfun.',
	 'authors': u'Marc Mezzarobba,',
	 'category': u'Computer Science ',
	 'date': '2010-2-16',
	 'pdflink': u'http://arxiv.org/pdf/1002.3077',
	 'subjects': u'Symbolic Computation (cs.SC)',
	 'title': u'\nNumGfun: a Package for Numerical and Analytic Computation with D-finite  Functions',
	 'urllink': u'http://arxiv.org/abs/1002.3077'}
2015-03-23 23:24:39+0000 [xxu46_1] INFO: Crawled 67 pages (at 1 pages/min), scraped 61 items (at 1 items/min)
2015-03-23 23:25:39+0000 [xxu46_1] INFO: Crawled 67 pages (at 0 pages/min), scraped 61 items (at 0 items/min)
2015-03-23 23:25:43+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3074> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:25:43+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3074>
	{'abstract': u'We describe the "Fair Dealing Button," a feature designed for authors who have deposited their papers in an Open Access Institutional Repository but have deposited them as "Closed Access" (meaning only the metadata are visible and retrievable, not the full eprint) rather than Open Access. The Button allows individual users to request and authors to provide a single eprint via semi-automated email. The purpose of the Button is to tide over research usage needs during any publisher embargo on Open Access and, more importantly, to make it possible for institutions to adopt the "Immediate-Deposit/Optional-Access" Mandate, without exceptions or opt-outs, instead of a mandate that allows delayed deposit or deposit waivers, depending on publisher permissions or embargoes (or no mandate at all). This is only "Almost-Open Access," but in facilitating exception-free immediate-deposit mandates it will accelerate the advent of universal Open Access.',
	 'authors': u'Arthur Sale, Marc Couture, Eloy Rodrigues, Leslie Carr, Stevan Harnad,',
	 'category': u'Computer Science ',
	 'date': '2010-2-16',
	 'pdflink': u'http://arxiv.org/pdf/1002.3074',
	 'subjects': u'Digital Libraries (cs.DL)',
	 'title': u'\nOpen Access Mandates and the "Fair Dealing" Button',
	 'urllink': u'http://arxiv.org/abs/1002.3074'}
2015-03-23 23:26:39+0000 [xxu46_1] INFO: Crawled 68 pages (at 1 pages/min), scraped 62 items (at 1 items/min)
2015-03-23 23:27:26+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3065> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:27:26+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3065>
	{'abstract': u'We investigate the role of cooperation in wireless networks subject to a spatial degrees of freedom limitation. To address the worst case scenario, we consider a free-space line-of-sight type environment with no scattering and no fading. We identify three qualitatively different operating regimes that are determined by how the area of the network A, normalized with respect to the wavelength lambda, compares to the number of users n. In networks with sqrt/lambda &lt; sqrt, the limitation in spatial degrees of freedom does not allow to achieve a capacity scaling better than sqrt and this performance can be readily achieved by multi-hopping. This result has been recently shown by Franceschetti et al. However, for networks with sqrt/lambda &gt; sqrt, the number of available degrees of freedom is min(n, sqrt/lambda), larger that what can be achieved by multi-hopping. We show that the optimal capacity scaling in this regime is achieved by hierarchical cooperation. In particular, in networks with sqrt/lambda&gt; n, hierarchical cooperation can achieve linear scaling.',
	 'authors': u'Ayfer Ozgur, Olivier Leveque, David Tse,',
	 'category': u'Computer Science ',
	 'date': '2010-2-16',
	 'pdflink': u'http://arxiv.org/pdf/1002.3065',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nLinear Capacity Scaling in Wireless Networks: Beyond Physical Limits?',
	 'urllink': u'http://arxiv.org/abs/1002.3065'}
2015-03-23 23:27:39+0000 [xxu46_1] INFO: Crawled 69 pages (at 1 pages/min), scraped 63 items (at 1 items/min)
2015-03-23 23:28:39+0000 [xxu46_1] INFO: Crawled 69 pages (at 0 pages/min), scraped 63 items (at 0 items/min)
2015-03-23 23:29:04+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3047> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:29:04+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3047>
	{'abstract': u'We investigate the multipath fading relay channel in the limit of a large bandwidth, and in the non-coherent setting, where the channel state is unknown to all terminals, including the relay and the destination. We propose a hypergraph model of the wideband multipath fading relay channel, and show that its min-cut is achieved by a non-coherent peaky frequency binning scheme. The so-obtained lower bound on the capacity of the wideband multipath fading relay channel turns out to coincide with the block-Markov lower bound on the capacity of the wideband frequency-division Gaussian (FD-AWGN) relay channel. In certain cases, this achievable rate also meets the cut-set upper-bound, and thus reaches the capacity of the non-coherent wideband multipath fading relay channel.',
	 'authors': u'Nadia Fawaz, Muriel Medard,',
	 'category': u'Computer Science ',
	 'date': '2010-2-16',
	 'pdflink': u'http://arxiv.org/pdf/1002.3047',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOn the Non-Coherent Wideband Multipath Fading Relay Channel',
	 'urllink': u'http://arxiv.org/abs/1002.3047'}
2015-03-23 23:29:39+0000 [xxu46_1] INFO: Crawled 70 pages (at 1 pages/min), scraped 64 items (at 1 items/min)
2015-03-23 23:30:39+0000 [xxu46_1] INFO: Crawled 70 pages (at 0 pages/min), scraped 64 items (at 0 items/min)
2015-03-23 23:30:48+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3031> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:30:48+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3031>
	{'abstract': u'The design structure of OO software has decisive impact on its quality. The design must be strongly correlated with quality characteristics like analyzability, changeability, stability and testability, which are important for maintaining the system. But due to the diversity and complexity of the design properties of OO system e.g. Polymorphism, encapsulation, coupling it becomes cumbersome.',
	 'authors': u'R. Selvarani, Wahida Banu, Kamakshi Prasad,',
	 'category': u'Computer Science ',
	 'date': '2010-2-16',
	 'pdflink': u'http://arxiv.org/pdf/1002.3031',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nQuantifying the Deign Quality of Object Oriented System The metric based  rules and heuristic',
	 'urllink': u'http://arxiv.org/abs/1002.3031'}
2015-03-23 23:31:39+0000 [xxu46_1] INFO: Crawled 71 pages (at 1 pages/min), scraped 65 items (at 1 items/min)
2015-03-23 23:32:19+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3024> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:32:19+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3024>
	{'abstract': u"We apply Schrijver's semidefinite programming method to obtain improved upper bounds on generalized distances and list decoding radii of binary codes.",
	 'authors': u'Christine Bachoc, Gilles Zemor,',
	 'category': u'Computer Science ',
	 'date': '2010-2-16',
	 'pdflink': u'http://arxiv.org/pdf/1002.3024',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nBounds for binary codes relative to pseudo-distances of k points',
	 'urllink': u'http://arxiv.org/abs/1002.3024'}
2015-03-23 23:32:39+0000 [xxu46_1] INFO: Crawled 72 pages (at 1 pages/min), scraped 66 items (at 1 items/min)
2015-03-23 23:33:39+0000 [xxu46_1] INFO: Crawled 72 pages (at 0 pages/min), scraped 66 items (at 0 items/min)
2015-03-23 23:33:58+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3023> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:33:58+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3023>
	{'abstract': u'An important challenge in constraint programming is to rewrite constraint models into executable programs calculat- ing the solutions. This phase of constraint processing may require translations between constraint programming lan- guages, transformations of constraint representations, model optimizations, and tuning of solving strategies. In this paper, we introduce a pivot metamodel describing the common fea- tures of constraint models including different kinds of con- straints, statements like conditionals and loops, and other first-class elements like object classes and predicates. This metamodel is general enough to cope with the constructions of many languages, from object-oriented modeling languages to logic languages, but it is independent from them. The rewriting operations manipulate metamodel instances apart from languages. As a consequence, the rewriting operations apply whatever languages are selected and they are able to manage model semantic information. A bridge is created between the metamodel space and languages using parsing techniques. Tools from the software engineering world can be useful to implement this framework.',
	 'authors': u'Raphael Chenouard, Laurent Granvilliers, Ricardo Soto,',
	 'category': u'Computer Science ',
	 'date': '2010-2-16',
	 'pdflink': u'http://arxiv.org/pdf/1002.3023',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nRewriting Constraint Models with Metamodels',
	 'urllink': u'http://arxiv.org/abs/1002.3023'}
2015-03-23 23:34:39+0000 [xxu46_1] INFO: Crawled 73 pages (at 1 pages/min), scraped 67 items (at 1 items/min)
2015-03-23 23:34:55+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3015> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:34:55+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3015>
	{'abstract': u'In a world of increasing mobility, there is a growing need for people to communicate with each other and have timely access to information regardless of the location of the individuals or the information. With the advent of moblle technology, the way of communication has changed. The gira system is basically a mobile phone technology service. In this paper we discuss about a novel local area network control system called gprs based Intranet Remote Administration gira. This system finds application in a mobile handset. With this system, a network administrator will have an effective remote control over the network. gira system is developed using gprs, gcf Generic Connection Framework of j2me, sockets and rmi technologies',
	 'authors': u'Shashi Kumar N.R., R. Selvarani, Pushpavathi T.P,',
	 'category': u'Computer Science ',
	 'date': '2010-2-16',
	 'pdflink': u'http://arxiv.org/pdf/1002.3015',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nGPRS Based Intranet Remote Administration GIRA',
	 'urllink': u'http://arxiv.org/abs/1002.3015'}
2015-03-23 23:35:39+0000 [xxu46_1] INFO: Crawled 74 pages (at 1 pages/min), scraped 68 items (at 1 items/min)
2015-03-23 23:36:37+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3011> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:36:37+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3011>
	{'abstract': u'Future security measures will create comfortable living environments that are embedded with a wide range of intelligent functionalities including home computing, entertainment, health care and security. These place stringent requirements on the home networking architecture which integrates various existing technologies for monitoring and control for future high security needs. This paper discusses the design and implementation of a gvss gprs Video Streaming Surveillance System system, which integrates various existing technologies for providing security for smart home environments. This system provides security for office, home and other buildings where high security is required.This allows the mobile user to track the activities from a particular location. The system will send snapshots of the video and stores them in different formats. It is also possible to display the time with the image when it was captured in the gprs enabled mobiles. This system is implemented using J2me Technology',
	 'authors': u'T.P. Pushpavathi, R Selvarani, N.R. Shashi Kumar,',
	 'category': u'Computer Science ',
	 'date': '2010-2-16',
	 'pdflink': u'http://arxiv.org/pdf/1002.3011',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nGPRS Video Streaming Surveillance System GVSS',
	 'urllink': u'http://arxiv.org/abs/1002.3011'}
2015-03-23 23:36:39+0000 [xxu46_1] INFO: Crawled 75 pages (at 1 pages/min), scraped 69 items (at 1 items/min)
2015-03-23 23:37:39+0000 [xxu46_1] INFO: Crawled 75 pages (at 0 pages/min), scraped 69 items (at 0 items/min)
2015-03-23 23:38:15+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.3008> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:38:15+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.3008>
	{'abstract': u'Requirement Analysis is an important phase in software development which deals with understanding the customers requirements. It includes the collection of information from the customer, which is regarding the customers requirements and what he expects from the software which is to be developed. By doing so, you can have a better understanding of what the customer actually needs and hence can deliver the output as per the customers requirements. Studies are being carried out to bring about improvements in the process of requirement analysis so that errors in software development could be minimized and hence improved and reliable products could be delivered.',
	 'authors': u'Abhishek Kotnala, R. Selvarani,',
	 'category': u'Computer Science ',
	 'date': '2010-2-16',
	 'pdflink': u'http://arxiv.org/pdf/1002.3008',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nCognitive Process of Comprehension in Requirement Analysis in IT  Applications',
	 'urllink': u'http://arxiv.org/abs/1002.3008'}
2015-03-23 23:38:39+0000 [xxu46_1] INFO: Crawled 76 pages (at 1 pages/min), scraped 70 items (at 1 items/min)
2015-03-23 23:39:34+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2978> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:39:34+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2978>
	{'abstract': u'This volume contains the proceedings of SOS 2009, the Sixth Workshop on Structural Operational Semantics held on the 31st of August 2009 in Bologna, Italy as a affiliated workshop of CONCUR 2009, the 20th International Conference on Concurrency Theory. Structural operational semantics (SOS) is a technique for defining operational semantics for programming and specification languages. The workshop is forum for researchers, students and practitioners interested in new developments and directions for future investigations in the area of SOS. One of the specific goals of the workshop is to provide a meeting point for the concurrency and programming language communities. Another goal is the dissemination of the theory and practice of SOS amongst postgraduate students and young researchers worldwide.',
	 'authors': u'Bartek Klin, Pawe\u0142 Soboci\u0144ski,',
	 'category': u'Computer Science ',
	 'date': '2010-2-15',
	 'pdflink': u'http://arxiv.org/html/1002.2978',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nProceedings Sixth Workshop on Structural Operational Semantics',
	 'urllink': u'http://arxiv.org/abs/1002.2978'}
2015-03-23 23:39:39+0000 [xxu46_1] INFO: Crawled 77 pages (at 1 pages/min), scraped 71 items (at 1 items/min)
2015-03-23 23:40:29+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2971> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:40:29+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2971>
	{'abstract': u'We consider a binary erasure version of the n-channel multiple descriptions problem with symmetric descriptions, i.e., the rates of the n descriptions are the same and the distortion constraint depends only on the number of messages received. We consider the case where there is no excess rate for every k out of n descriptions. Our goal is to characterize the achievable distortions D_1, D_2,...,D_n. We measure the fidelity of reconstruction using two distortion criteria: an average-case distortion criterion, under which distortion is measured by taking the average of the per-letter distortion over all source sequences, and a worst-case distortion criterion, under which distortion is measured by taking the maximum of the per-letter distortion over all source sequences. We present achievability schemes, based on random binning for average-case distortion and systematic MDS (maximum distance separable) codes for worst-case distortion, and prove optimality results for the corresponding achievable distortion regions. We then use the binary erasure multiple descriptions setup to propose a layered coding framework for multiple descriptions, which we then apply to vector Gaussian multiple descriptions and prove its optimality for symmetric scalar Gaussian multiple descriptions with two levels of receivers and no excess rate for the central receiver. We also prove a new outer bound for the general multi-terminal source coding problem and use it to prove an optimality result for the robust binary erasure CEO problem. For the latter, we provide a tight lower bound on the distortion for ell messages for any coding scheme that achieves the minimum achievable distortion for k messages where k is less than or equal to ell.',
	 'authors': u'Ebad Ahmed, Aaron B. Wagner,',
	 'category': u'Computer Science ',
	 'date': '2010-2-15',
	 'pdflink': u'http://arxiv.org/pdf/1002.2971',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nErasure Multiple Descriptions',
	 'urllink': u'http://arxiv.org/abs/1002.2971'}
2015-03-23 23:40:39+0000 [xxu46_1] INFO: Crawled 78 pages (at 1 pages/min), scraped 72 items (at 1 items/min)
2015-03-23 23:41:30+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2966> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:41:30+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2966>
	{'abstract': u'Quantum computers theoretically are able to solve certain problems more quickly than any deterministic or probabilistic computers. A quantum computer exploits the rules of quantum mechanics to speed up computations. However, one has to mitigate the resulting noise and decoherence effects to avoid computational errors in order to successfully build quantum computers. In this paper, we construct asymmetric quantum codes to protect quantum information over asymmetric quantum channels, . Two generic methods are presented to derive asymmetric quantum cyclic codes using the generator polynomials and defining sets of classical cyclic codes. Consequently, the methods allow us to construct several families of quantum BCH, RS, and RM codes over asymmetric quantum channels. Finally, the methods are used to construct families of asymmetric subsystem codes.',
	 'authors': u'Salah A. Aly, Alexei Ashikhmin,',
	 'category': u'Computer Science ',
	 'date': '2010-2-15',
	 'pdflink': u'http://arxiv.org/pdf/1002.2966',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nNonbinary Quantum Cyclic and Subsystem Codes Over  Asymmetrically-decohered Quantum Channels',
	 'urllink': u'http://arxiv.org/abs/1002.2966'}
2015-03-23 23:41:39+0000 [xxu46_1] INFO: Crawled 79 pages (at 1 pages/min), scraped 73 items (at 1 items/min)
2015-03-23 23:42:39+0000 [xxu46_1] INFO: Crawled 79 pages (at 0 pages/min), scraped 73 items (at 0 items/min)
2015-03-23 23:43:04+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2964> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:43:04+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2964>
	{'abstract': u"Femtocells are assuming an increasingly important role in the coverage and capacity of cellular networks. In contrast to existing cellular systems, femtocells are end-user deployed and controlled, randomly located, and rely on third party backhaul (e.g. DSL or cable modem). Femtocells can be configured to be either open access or closed access. Open access allows an arbitrary nearby cellular user to use the femtocell, whereas closed access restricts the use of the femtocell to users explicitly approved by the owner. Seemingly, the network operator would prefer an open access deployment since this provides an inexpensive way to expand their network capabilities, whereas the femtocell owner would prefer closed access, in order to keep the femtocell's capacity and backhaul to himself. We show mathematically and through simulations that the reality is more complicated for both parties, and that the best approach depends heavily on whether the multiple access scheme is orthogonal (TDMA or OFDMA, per subband) or non-orthogonal (CDMA). In a TDMA/OFDMA network, closed-access is typically preferable at high user densities, whereas in CDMA, open access can provide gains of more than 200% for the home user by reducing the near-far problem experienced by the femtocell. The results of this paper suggest that the interests of the femtocell owner and the network operator are more compatible than typically believed, and that CDMA femtocells should be configured for open access whereas OFDMA or TDMA femtocells should adapt to the cellular user density.",
	 'authors': u'Ping Xia, Vikram Chandrasekhar, Jeffrey G. Andrews,',
	 'category': u'Computer Science ',
	 'date': '2010-2-15',
	 'pdflink': u'http://arxiv.org/pdf/1002.2964',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOpen vs Closed Access Femtocells in the Uplink',
	 'urllink': u'http://arxiv.org/abs/1002.2964'}
2015-03-23 23:43:39+0000 [xxu46_1] INFO: Crawled 80 pages (at 1 pages/min), scraped 74 items (at 1 items/min)
2015-03-23 23:43:50+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2959> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:43:50+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2959>
	{'abstract': u"Relationships that exist between the classical, Shannon-type, and geometric-based approaches to sampling are investigated. Some aspects of coding and communication through a Gaussian channel are considered. In particular, a constructive method to determine the quantizing dimension in Zador's theorem is provided. A geometric version of Shannon's Second Theorem is introduced. Applications to Pulse Code Modulation and Vector Quantization of Images are addressed.",
	 'authors': u'Emil Saucan, Eli Appleboim, Yehoshua Y. Zeevi,',
	 'category': u'Computer Science ',
	 'date': '2010-2-15',
	 'pdflink': u'http://arxiv.org/pdf/1002.2959',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nGeometric approach to sampling and communication',
	 'urllink': u'http://arxiv.org/abs/1002.2959'}
2015-03-23 23:44:39+0000 [xxu46_1] INFO: Crawled 81 pages (at 1 pages/min), scraped 75 items (at 1 items/min)
2015-03-23 23:45:19+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2954> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:45:19+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2954>
	{'abstract': u'The Jordan Curve Theorem (JCT) states that a simple closed curve divides the plane into exactly two connected regions. We formalize and prove the theorem in the context of grid graphs, under different input settings, in theories of bounded arithmetic that correspond to small complexity classes. The theory (corresponding to ) proves that any set of edges that form disjoint cycles divides the grid into at least two regions. The theory (corresponding to ) proves that any sequence of edges that form a simple closed curve divides the grid into exactly two regions. As a consequence, the Hex tautologies and the st-connectivity tautologies have polynomial size -Frege-proofs, which improves results of Buss which only apply to the stronger proof system -Frege.',
	 'authors': u'Phuong Nguyen, Stephen Cook,',
	 'category': u'Computer Science ',
	 'date': '2010-2-15',
	 'pdflink': u'http://arxiv.org/pdf/1002.2954',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nThe Complexity of Proving the Discrete Jordan Curve Theorem',
	 'urllink': u'http://arxiv.org/abs/1002.2954'}
2015-03-23 23:45:39+0000 [xxu46_1] INFO: Crawled 82 pages (at 1 pages/min), scraped 76 items (at 1 items/min)
2015-03-23 23:46:39+0000 [xxu46_1] INFO: Crawled 82 pages (at 0 pages/min), scraped 76 items (at 0 items/min)
2015-03-23 23:46:56+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2897> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:46:56+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2897>
	{'abstract': u'Constraint programming can definitely be seen as a model-driven paradigm. The users write programs for modeling problems. These programs are mapped to executable models to calculate the solutions. This paper focuses on efficient model management (definition and transformation). From this point of view, we propose to revisit the design of constraint-programming systems. A model-driven architecture is introduced to map solving-independent constraint models to solving-dependent decision models. Several important questions are examined, such as the need for a visual highlevel modeling language, and the quality of metamodeling techniques to implement the transformations. A main result is the s-COMMA platform that efficiently implements the chain from modeling to solving constraint problems',
	 'authors': u'Raphael Chenouard, Laurent Granvilliers, Ricardo Soto,',
	 'category': u'Computer Science ',
	 'date': '2010-2-15',
	 'pdflink': u'http://arxiv.org/pdf/1002.2897',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nModel-Driven Constraint Programming',
	 'urllink': u'http://arxiv.org/abs/1002.2897'}
2015-03-23 23:47:39+0000 [xxu46_1] INFO: Crawled 83 pages (at 1 pages/min), scraped 77 items (at 1 items/min)
2015-03-23 23:47:55+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2873> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:47:55+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2873>
	{'abstract': u'We analyse the problem of solving Boolean equation systems through the use of structure graphs. The latter are obtained through an elegant set of Plotkin-style deduction rules. Our main contribution is that we show that equation systems with bisimilar structure graphs have the same solution. We show that our work conservatively extends earlier work, conducted by Keiren and Willemse, in which dependency graphs were used to analyse a subclass of Boolean equation systems, viz., equation systems in standard recursive form. We illustrate our approach by a small example, demonstrating the effect of simplifying an equation system through minimisation of its structure graph.',
	 'authors': u'Michel A. Reniers, Tim A.C. Willemse,',
	 'category': u'Computer Science ',
	 'date': '2010-2-15',
	 'pdflink': u'http://arxiv.org/pdf/1002.2873',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nAnalysis of Boolean Equation Systems through Structure Graphs',
	 'urllink': u'http://arxiv.org/abs/1002.2873'}
2015-03-23 23:48:39+0000 [xxu46_1] INFO: Crawled 84 pages (at 1 pages/min), scraped 78 items (at 1 items/min)
2015-03-23 23:49:19+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2872> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:49:19+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2872>
	{'abstract': u'The Plan Execution Interchange Language (PLEXIL) is a synchronous language developed by NASA to support autonomous spacecraft operations. In this paper, we propose a rewriting logic semantics of PLEXIL in Maude, a high-performance logical engine. The rewriting logic semantics is by itself a formal interpreter of the language and can be used as a semantic benchmark for the implementation of PLEXIL executives. The implementation in Maude has the additional benefit of making available to PLEXIL designers and developers all the formal analysis and verification tools provided by Maude. The formalization of the PLEXIL semantics in rewriting logic poses an interesting challenge due to the synchronous nature of the language and the prioritized rules defining its semantics. To overcome this difficulty, we propose a general procedure for simulating synchronous set relations in rewriting logic that is sound and, for deterministic relations, complete. We also report on two issues at the design level of the original PLEXIL semantics that were identified with the help of the executable specification in Maude.',
	 'authors': u'Gilles Dowek, C\xe9sar Mu\xf1oz, Camilo Rocha,',
	 'category': u'Computer Science ',
	 'date': '2010-2-15',
	 'pdflink': u'http://arxiv.org/pdf/1002.2872',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nRewriting Logic Semantics of a Plan Execution Language',
	 'urllink': u'http://arxiv.org/abs/1002.2872'}
2015-03-23 23:49:39+0000 [xxu46_1] INFO: Crawled 85 pages (at 1 pages/min), scraped 79 items (at 1 items/min)
2015-03-23 23:50:39+0000 [xxu46_1] INFO: Crawled 85 pages (at 0 pages/min), scraped 79 items (at 0 items/min)
2015-03-23 23:50:39+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2871> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:50:39+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2871>
	{'abstract': u"The relationships between various equivalences on configuration structures, including interleaving bisimulation (IB), step bisimulation (SB) and hereditary history-preserving (HH) bisimulation, have been investigated by van Glabbeek and Goltz (and later Fecher). Since HH bisimulation may be characterised by the use of reverse as well as forward transitions, it is of interest to investigate forms of IB and SB where both forward and reverse transitions are allowed. We give various characterisations of reverse SB, showing that forward steps do not add extra power. We strengthen Bednarczyk's result that, in the absence of auto-concurrency, reverse IB is as strong as HH bisimulation, by showing that we need only exclude auto-concurrent events at the same depth in the configuration.",
	 'authors': u'Iain Phillips, Irek Ulidowski,',
	 'category': u'Computer Science ',
	 'date': '2010-2-15',
	 'pdflink': u'http://arxiv.org/pdf/1002.2871',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nReverse Bisimulations on Stable Configuration Structures',
	 'urllink': u'http://arxiv.org/abs/1002.2871'}
2015-03-23 23:51:39+0000 [xxu46_1] INFO: Crawled 86 pages (at 1 pages/min), scraped 80 items (at 1 items/min)
2015-03-23 23:52:01+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2869> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:52:01+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2869>
	{'abstract': u'Reactive systems (RSs) represent a meta-framework aimed at deriving behavioral congruences for those computational formalisms whose operational semantics is provided by reduction rules. RSs proved a flexible specification device, yet so far most of the efforts dealing with their behavioural semantics focused on idem pushouts (IPOs) and saturated (also known as dynamic) bisimulations. In this paper we introduce a novel, intermediate behavioural equivalence: L-bisimilarity, which is able to recast both its IPO and saturated counterparts. The equivalence is parametric with respect to a set L of RSs labels, and it is shown that under mild conditions on L it is indeed a congruence. Furthermore, L-bisimilarity can also recast the notion of barbed semantics for RSs, proposed by the same authors in a previous paper. In order to provide a suitable test-bed, we instantiate our proposal by addressing the semantics of (asynchronous) CCS and of the calculus of mobile ambients.',
	 'authors': u'Filippo Bonchi, Fabio Gadducci, Giacoma Valentina Monreale,',
	 'category': u'Computer Science ',
	 'date': '2010-2-15',
	 'pdflink': u'http://arxiv.org/pdf/1002.2869',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nOn Barbs and Labels in Reactive Systems',
	 'urllink': u'http://arxiv.org/abs/1002.2869'}
2015-03-23 23:52:39+0000 [xxu46_1] INFO: Crawled 87 pages (at 1 pages/min), scraped 81 items (at 1 items/min)
2015-03-23 23:53:27+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2868> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:53:27+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2868>
	{'abstract': u'We re-examine the challenges concerning causality in the semantics of Esterel and show that they pertain to the known issues in the semantics of Structured Operational Semantics with negative premises. We show that the solutions offered for the semantics of SOS also provide answers to the semantic challenges of Esterel and that they satisfy the intuitive requirements set by the language designers.',
	 'authors': u'MohammadReza Mousavi,',
	 'category': u'Computer Science ',
	 'date': '2010-2-15',
	 'pdflink': u'http://arxiv.org/pdf/1002.2868',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nCausality in the Semantics of Esterel: Revisited',
	 'urllink': u'http://arxiv.org/abs/1002.2868'}
2015-03-23 23:53:39+0000 [xxu46_1] INFO: Crawled 88 pages (at 1 pages/min), scraped 82 items (at 1 items/min)
2015-03-23 23:54:39+0000 [xxu46_1] INFO: Crawled 88 pages (at 0 pages/min), scraped 82 items (at 0 items/min)
2015-03-23 23:55:09+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2867> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:55:09+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2867>
	{'abstract': u'We present a symbolic transition system and bisimulation equivalence for psi-calculi, and show that it is fully abstract with respect to bisimulation congruence in the non-symbolic semantics. A psi-calculus is an extension of the pi-calculus with nominal data types for data structures and for logical assertions representing facts about data. These can be transmitted between processes and their names can be statically scoped using the standard pi-calculus mechanism to allow for scope migrations. Psi-calculi can be more general than other proposed extensions of the pi-calculus such as the applied pi-calculus, the spi-calculus, the fusion calculus, or the concurrent constraint pi-calculus. Symbolic semantics are necessary for an efficient implementation of the calculus in automated tools exploring state spaces, and the full abstraction property means the semantics of a process does not change from the original.',
	 'authors': u'Magnus Johansson, Bj\xf6rn Victor, Joachim Parrow,',
	 'category': u'Computer Science ',
	 'date': '2010-2-15',
	 'pdflink': u'http://arxiv.org/pdf/1002.2867',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nA Fully Abstract Symbolic Semantics for Psi-Calculi',
	 'urllink': u'http://arxiv.org/abs/1002.2867'}
2015-03-23 23:55:39+0000 [xxu46_1] INFO: Crawled 89 pages (at 1 pages/min), scraped 83 items (at 1 items/min)
2015-03-23 23:56:22+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2864> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:56:22+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2864>
	{'abstract': u"This paper presents a bisimulation-based method for establishing the soundness of equations between terms constructed using operations whose semantics is specified by rules in the GSOS format of Bloom, Istrail and Meyer. The method is inspired by de Simone's FH-bisimilarity and uses transition rules as schematic transitions in a bisimulation-like relation between open terms. The soundness of the method is proven and examples showing its applicability are provided. The proposed bisimulation-based proof method is incomplete, but the article offers some completeness results for restricted classes of GSOS specifications.",
	 'authors': u'Luca Aceto, Matteo Cimini, Anna Ingolfsdottir,',
	 'category': u'Computer Science ',
	 'date': '2010-2-15',
	 'pdflink': u'http://arxiv.org/pdf/1002.2864',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nA Bisimulation-based Method for Proving the Validity of Equations in  GSOS Languages',
	 'urllink': u'http://arxiv.org/abs/1002.2864'}
2015-03-23 23:56:39+0000 [xxu46_1] INFO: Crawled 90 pages (at 1 pages/min), scraped 84 items (at 1 items/min)
2015-03-23 23:57:39+0000 [xxu46_1] INFO: Crawled 90 pages (at 0 pages/min), scraped 84 items (at 0 items/min)
2015-03-23 23:58:06+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2858> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:58:06+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2858>
	{'abstract': u'PageRank is a Web page ranking technique that has been a fundamental ingredient in the development and success of the Google search engine. The method is still one of the many signals that Google uses to determine which pages are most important. The main idea behind PageRank is to determine the importance of a Web page in terms of the importance assigned to the pages hyperlinking to it. In fact, this thesis is not new, and has been previously successfully exploited in different contexts. We review the PageRank method and link it to some renowned previous techniques that we have found in the fields of Web information retrieval, bibliometrics, sociometry, and econometrics.',
	 'authors': u'Massimo Franceschet,',
	 'category': u'Computer Science ',
	 'date': '2010-2-15',
	 'pdflink': u'http://arxiv.org/pdf/1002.2858',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nPageRank: Standing on the shoulders of giants',
	 'urllink': u'http://arxiv.org/abs/1002.2858'}
2015-03-23 23:58:39+0000 [xxu46_1] INFO: Crawled 91 pages (at 1 pages/min), scraped 85 items (at 1 items/min)
2015-03-23 23:59:39+0000 [xxu46_1] INFO: Crawled 91 pages (at 0 pages/min), scraped 85 items (at 0 items/min)
2015-03-23 23:59:43+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2829> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-23 23:59:43+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2829>
	{'abstract': u'Software design in Software Engineering is a critical and dynamic cognitive process. Accurate and flawless system design will lead to fast coding and early completion of a software project. Blooms taxonomy classifies cognitive domain into six dynamic levels such as Knowledge at base level to Comprehension, Application, Analysis, Synthesis and Evaluation at the highest level in the order of increasing complexity. A case study indicated in this paper is a gira system, which is a gprs based Intranet Remote Administration which monitors and controls the intranet from a mobile device. This paper investigates from this case study that the System Design stage in Software Engineering uses all the six levels of Blooms Taxonomy. The application of the highest levels of Blooms Taxonomy such as Synthesis and Evaluation in the design of gira indicates that Software Design in Software Development Life Cycle is a complex and critical cognitive process.',
	 'authors': u'NR Shashi Kumar, TP Pushpavathi, R Selvarani,',
	 'category': u'Computer Science ',
	 'date': '2010-2-15',
	 'pdflink': u'http://arxiv.org/pdf/1002.2829',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nDynamic Cognitive Process Application of Blooms Taxonomy for Complex  Software Design in the Cognitive Domain',
	 'urllink': u'http://arxiv.org/abs/1002.2829'}
2015-03-24 00:00:39+0000 [xxu46_1] INFO: Crawled 92 pages (at 1 pages/min), scraped 86 items (at 1 items/min)
2015-03-24 00:01:10+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2827> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:01:10+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2827>
	{'abstract': u'The design and development of a complex system requires an adequate methodology and efficient instrumental support in order to early detect and correct anomalies in the functional and non-functional properties of the tested protocols. Among the various tools used to provide experimental support for such developments, network emulation relies on real-time production of impairments on real traffic according to a communication model, either realistically or not. This paper aims at simply presenting to newcomers in network emulation (students, engineers, ...) basic principles and practices illustrated with a few commonly used tools. The motivation behind is to fill a gap in terms of introductory and pragmatic papers in this domain. The study particularly considers centralized approaches, allowing cheap and easy implementation in the context of research labs or industrial developments. In addition, an architectural model for emulation systems is proposed, defining three complementary levels, namely hardware, impairment and model levels. With the help of this architectural framework, various existing tools are situated and described. Various approaches for modeling the emulation actions are studied, such as impairment-based scenarios and virtual architectures, real-time discrete simulation and trace-based systems. Those modeling approaches are described and compared in terms of services and we study their ability to respond to various designer needs to assess when emulation is needed.',
	 'authors': u'Emmanuel Lochin, Tanguy Perennou, Laurent Dairaine,',
	 'category': u'Computer Science ',
	 'date': '2010-2-15',
	 'pdflink': u'http://arxiv.org/pdf/1002.2827',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nWhen Should I Use Network Emulation?',
	 'urllink': u'http://arxiv.org/abs/1002.2827'}
2015-03-24 00:01:39+0000 [xxu46_1] INFO: Crawled 93 pages (at 1 pages/min), scraped 87 items (at 1 items/min)
2015-03-24 00:02:34+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2813> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:02:34+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2813>
	{'abstract': u"This paper develops a distributed algorithm for rate allocation in wireless networks that achieves the same throughput region as optimal centralized algorithms. This cross-layer algorithm jointly performs medium access control (MAC) and physical-layer rate adaptation. The paper establishes that this algorithm is throughput-optimal for general rate regions. In contrast to on-off scheduling, rate allocation enables optimal utilization of physical-layer schemes by scheduling multiple rate levels. The algorithm is based on local queue-length information, and thus the algorithm is of significant practical value. The algorithm requires that each link can determine the global feasibility of increasing its current data-rate. In many classes of networks, any one link's data-rate primarily impacts its neighbors and this impact decays with distance. Hence, local exchanges can provide the information needed to determine feasibility. Along these lines, the paper discusses the potential use of existing physical-layer control messages to determine feasibility. This can be considered as a technique analogous to carrier sensing in CSMA (Carrier Sense Multiple Access) networks. An important application of this algorithm is in multiple-band multiple-radio throughput-optimal distributed scheduling for white-space networks.",
	 'authors': u'Jubin Jose, Sriram Vishwanath,',
	 'category': u'Computer Science ',
	 'date': '2010-2-15',
	 'pdflink': u'http://arxiv.org/pdf/1002.2813',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nDistributed Rate Allocation for Wireless Networks',
	 'urllink': u'http://arxiv.org/abs/1002.2813'}
2015-03-24 00:02:39+0000 [xxu46_1] INFO: Crawled 94 pages (at 1 pages/min), scraped 88 items (at 1 items/min)
2015-03-24 00:03:39+0000 [xxu46_1] INFO: Crawled 94 pages (at 0 pages/min), scraped 88 items (at 0 items/min)
2015-03-24 00:04:07+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2798> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:04:07+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2798>
	{'abstract': u'This note compares the performance of two multidimensional search and optimization algorithms: Group Search Optimizer and Central Force Optimization. GSO is a new state-of-the-art algorithm that has gained some notoriety, consequently providing an excellent yardstick for measuring the performance of other algorithms. CFO is a novel deterministic metaheuristic that has performed well against GSO in previous tests. The CFO implementation reported here includes architectural improvements in errant probe retrieval and decision space adaptation that result in even better performance. Detailed results are provided for the twenty-three function benchmark suite used to evaluate GSO. CFO performs better than or essentially as well as GSO on twenty functions and nearly as well on one of the remaining three. Includes update 24 February 2010.',
	 'authors': u'Richard A. Formato,',
	 'category': u'Computer Science ',
	 'date': '2010-2-14',
	 'pdflink': u'http://arxiv.org/pdf/1002.2798',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nComparative Results: Group Search Optimizer and Central Force  Optimization',
	 'urllink': u'http://arxiv.org/abs/1002.2798'}
2015-03-24 00:04:39+0000 [xxu46_1] INFO: Crawled 95 pages (at 1 pages/min), scraped 89 items (at 1 items/min)
2015-03-24 00:05:39+0000 [xxu46_1] INFO: Crawled 95 pages (at 0 pages/min), scraped 89 items (at 0 items/min)
2015-03-24 00:05:42+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2780> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:05:42+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2780>
	{'abstract': u'We show that matrix completion with trace-norm regularization can be significantly hurt when entries of the matrix are sampled non-uniformly. We introduce a weighted version of the trace-norm regularizer that works well also with non-uniform sampling. Our experimental results demonstrate that the weighted trace-norm regularization indeed yields significant gains on the (highly non-uniformly sampled) Netflix dataset.',
	 'authors': u'Ruslan Salakhutdinov, Nathan Srebro,',
	 'category': u'Computer Science ',
	 'date': '2010-2-14',
	 'pdflink': u'http://arxiv.org/pdf/1002.2780',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nCollaborative Filtering in a Non-Uniform World: Learning with the  Weighted Trace Norm',
	 'urllink': u'http://arxiv.org/abs/1002.2780'}
2015-03-24 00:06:39+0000 [xxu46_1] INFO: Crawled 96 pages (at 1 pages/min), scraped 90 items (at 1 items/min)
2015-03-24 00:07:03+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2755> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:07:03+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2755>
	{'abstract': u'This paper proposes a multimodal biometric system through Gaussian Mixture Model (GMM) for face and ear biometrics with belief fusion of the estimated scores characterized by Gabor responses and the proposed fusion is accomplished by Dempster-Shafer (DS) decision theory. Face and ear images are convolved with Gabor wavelet filters to extracts spatially enhanced Gabor facial features and Gabor ear features. Further, GMM is applied to the high-dimensional Gabor face and Gabor ear responses separately for quantitive measurements. Expectation Maximization (EM) algorithm is used to estimate density parameters in GMM. This produces two sets of feature vectors which are then fused using Dempster-Shafer theory. Experiments are conducted on multimodal database containing face and ear images of 400 individuals. It is found that use of Gabor wavelet filters along with GMM and DS theory can provide robust and efficient multimodal fusion strategy.',
	 'authors': u'Dakshina Ranjan Kisku, Jamuna Kanta Sing, Phalguni Gupta,',
	 'category': u'Computer Science ',
	 'date': '2010-2-14',
	 'pdflink': u'http://arxiv.org/pdf/1002.2755',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nMultibiometrics Belief Fusion',
	 'urllink': u'http://arxiv.org/abs/1002.2755'}
2015-03-24 00:07:39+0000 [xxu46_1] INFO: Crawled 97 pages (at 1 pages/min), scraped 91 items (at 1 items/min)
2015-03-24 00:08:39+0000 [xxu46_1] INFO: Crawled 97 pages (at 0 pages/min), scraped 91 items (at 0 items/min)
2015-03-24 00:08:48+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2746> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:08:48+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2746>
	{'abstract': u'This paper explores the use of negative (i.e., repulsive) interaction the abstract Tile Assembly Model defined by Winfree. Winfree postulated negative interactions to be physically plausible in his Ph.D. thesis, and Reif, Sahu, and Yin explored their power in the context of reversible attachment operations. We explore the power of negative interactions with irreversible attachments, and we achieve two main results. Our first result is an impossibility theorem: after t steps of assembly, Omega(t) tiles will be forever bound to an assembly, unable to detach. Thus negative glue strengths do not afford unlimited power to reuse tiles. Our second result is a positive one: we construct a set of tiles that can simulate a Turing machine with space bound s and time bound t, while ensuring that no intermediate assembly grows larger than O(s), rather than O(s * t) as required by the standard Turing machine simulation with tiles.',
	 'authors': u'David Doty, Lila Kari, Benoit Masson,',
	 'category': u'Computer Science ',
	 'date': '2010-2-14',
	 'pdflink': u'http://arxiv.org/pdf/1002.2746',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nNegative Interactions in Irreversible Self-Assembly',
	 'urllink': u'http://arxiv.org/abs/1002.2746'}
2015-03-24 00:09:39+0000 [xxu46_1] INFO: Crawled 98 pages (at 1 pages/min), scraped 92 items (at 1 items/min)
2015-03-24 00:10:29+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2724> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:10:29+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2724>
	{'abstract': u'The subword complexity of a finite word of length is a function which associates to each the number of all distinct subwords of having the length . We define the emph C(w) as the maximum of the subword complexity for , and the emph K(N) as the maximum of C(w) for all words of a fixed length over a finite alphabet. By R(N) we will denote the set of the values for which there exits a word of length having K(N) subwords of length . M(N) represents the number of words of length whose maximal complexity is equal to the global maximal complexity.',
	 'authors': u'M-C. Anisiu, Z. Blazsik, Z. Kasa,',
	 'category': u'Computer Science ',
	 'date': '2010-2-13',
	 'pdflink': u'http://arxiv.org/pdf/1002.2724',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nMaximal Complexity of Finite Words',
	 'urllink': u'http://arxiv.org/abs/1002.2724'}
2015-03-24 00:10:39+0000 [xxu46_1] INFO: Crawled 99 pages (at 1 pages/min), scraped 93 items (at 1 items/min)
2015-03-24 00:11:39+0000 [xxu46_1] INFO: Crawled 99 pages (at 0 pages/min), scraped 93 items (at 0 items/min)
2015-03-24 00:12:01+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2723> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:12:01+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2723>
	{'abstract': u'We present a method which displays all palindromes of a given length from De Bruijn words of a certain order, and also a recursive one which constructs all palindromes of length from the set of palindromes of length . We show that the palindrome complexity function, which counts the number of palindromes of each length contained in a given word, has a different shape compared with the usual (subword) complexity function. We give upper bounds for the average number of palindromes contained in all words of length , and obtain exact formulae for the number of palindromes of length 1 and 2 contained in all words of length .',
	 'authors': u'M-C. Anisiu, V. Anisiu, Z. Kasa,',
	 'category': u'Computer Science ',
	 'date': '2010-2-13',
	 'pdflink': u'http://arxiv.org/pdf/1002.2723',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nProperties of palindromes in finite words',
	 'urllink': u'http://arxiv.org/abs/1002.2723'}
2015-03-24 00:12:39+0000 [xxu46_1] INFO: Crawled 100 pages (at 1 pages/min), scraped 94 items (at 1 items/min)
2015-03-24 00:13:25+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2722> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:13:25+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2722>
	{'abstract': u'Autonomic management can improve the QoS provided by parallel/ distributed applications. Within the CoreGRID Component Model, the autonomic management is tailored to the automatic - monitoring-driven - alteration of the component assembly and, therefore, is defined as the effect of (distributed) management code. This work yields a semantics based on hypergraph rewriting suitable to model the dynamic evolution and non-functional aspects of Service Oriented Architectures and component-based autonomic applications. In this regard, our main goal is to provide a formal description of adaptation operations that are typically only informally specified. We contend that our approach makes easier to raise the level of abstraction of management code in autonomic and adaptive applications.',
	 'authors': u'Marco Aldinucci, Emilio Tuosto,',
	 'category': u'Computer Science ',
	 'date': '2010-2-13',
	 'pdflink': u'http://arxiv.org/pdf/1002.2722',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nToward a Formal Semantics for Autonomic Components',
	 'urllink': u'http://arxiv.org/abs/1002.2722'}
2015-03-24 00:13:39+0000 [xxu46_1] INFO: Crawled 101 pages (at 1 pages/min), scraped 95 items (at 1 items/min)
2015-03-24 00:14:39+0000 [xxu46_1] INFO: Crawled 101 pages (at 0 pages/min), scraped 95 items (at 0 items/min)
2015-03-24 00:15:12+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2721> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:15:12+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2721>
	{'abstract': u'This paper deals with the complexity of strings, which play an important role in biology (nucleotid sequences), information theory and computer science. The d-complexity of a string is defined as the number of its distinct d-substrings given in Definition 1. The case d=1 is studied in detail.',
	 'authors': u'Zoltan Kasa,',
	 'category': u'Computer Science ',
	 'date': '2010-2-13',
	 'pdflink': u'http://arxiv.org/pdf/1002.2721',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nOn the d-complexity of strings',
	 'urllink': u'http://arxiv.org/abs/1002.2721'}
2015-03-24 00:15:39+0000 [xxu46_1] INFO: Crawled 102 pages (at 1 pages/min), scraped 96 items (at 1 items/min)
2015-03-24 00:16:27+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2720> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:16:27+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2720>
	{'abstract': u'We propose a blind interference alignment scheme for the vector broadcast channel where the transmitter is equipped with M antennas and there are K receivers, each equipped with a reconfigurable antenna capable of switching among M preset modes. Without any knowledge of the channel coefficient values at the transmitters and with only mild assumptions on the channel coherence structure we show that MK/M+K-1 degrees of freedom are achievable. The key to the blind interference alignment scheme is the ability of the receivers to switch between reconfigurable antenna modes to create short term channel fluctuation patterns that are exploited by the transmitter. The achievable scheme does not require cooperation between transmit antennas and is therefore applicable to the MxK X network as well. Only finite symbol extensions are used, and no channel knowledge at the receivers is required to null the interference.',
	 'authors': u'Chenwei Wang, Tiangao Gou, Syed A. Jafar,',
	 'category': u'Computer Science ',
	 'date': '2010-2-15',
	 'pdflink': u'http://arxiv.org/pdf/1002.2720',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nAiming Perfectly in the Dark - Blind Interference Alignment through  Staggered Antenna Switching',
	 'urllink': u'http://arxiv.org/abs/1002.2720'}
2015-03-24 00:16:39+0000 [xxu46_1] INFO: Crawled 103 pages (at 1 pages/min), scraped 97 items (at 1 items/min)
2015-03-24 00:17:39+0000 [xxu46_1] INFO: Crawled 103 pages (at 0 pages/min), scraped 97 items (at 0 items/min)
2015-03-24 00:17:54+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2687> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:17:54+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2687>
	{'abstract': u'In this paper we investigate the extent of Information Technology penetration in Power sector, taking KPCL, Karnataka Power Corporation Ltd., a premier power generating, a state owned public sector organization as an example. Any organization to flourish, adoption of Information Technology is inevitable in the days of fast changing technological advancements. It is not merely the investment on IT which helps but adoption of right IT solutions and the optimum use of the same does matter and becomes most critical. A strong infrastructure coupled with modern technical and management concepts has helped KPCL to meet the challenges of the rising energy demands of Karnataka.',
	 'authors': u'T.P. Pushpavathi, N.R. Shashi Kumar, R. Selvarani,',
	 'category': u'Computer Science ',
	 'date': '2010-2-13',
	 'pdflink': u'http://arxiv.org/pdf/1002.2687',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nIT in Power Sector A KPCL Implementation',
	 'urllink': u'http://arxiv.org/abs/1002.2687'}
2015-03-24 00:18:39+0000 [xxu46_1] INFO: Crawled 104 pages (at 1 pages/min), scraped 98 items (at 1 items/min)
2015-03-24 00:19:24+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2686> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:19:24+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2686>
	{'abstract': u'A Data Warehouse stores integrated information as materialized views over data from one or more remote sources. These materialized views must be maintained in response to actual relation updates in the remote sources. The data warehouse view maintenance techniques are classified into four major categories self maintainable recomputation, not self maintainable recomputation, self maintainable incremental maintenance, and not self maintainable incremental maintenance. This paper provides a comprehensive comparison of the techniques in these four categories in terms of the data warehouse space usage and number of rows accessed in order to propagate an update from a remote data source to a target materialized view in the data warehouse.',
	 'authors': u'S. Prakasha, R. Selvarani,',
	 'category': u'Computer Science ',
	 'date': '2010-2-13',
	 'pdflink': u'http://arxiv.org/pdf/1002.2686',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nPerformance Analysis of View Maintenance Techniques for DW',
	 'urllink': u'http://arxiv.org/abs/1002.2686'}
2015-03-24 00:19:39+0000 [xxu46_1] INFO: Crawled 105 pages (at 1 pages/min), scraped 99 items (at 1 items/min)
2015-03-24 00:20:39+0000 [xxu46_1] INFO: Crawled 105 pages (at 0 pages/min), scraped 99 items (at 0 items/min)
2015-03-24 00:21:08+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2655> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:21:08+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2655>
	{'abstract': u'Multicast transmission, wherein the same packet must be delivered to multiple receivers, is an important aspect of sensor and tactical networks and has several distinctive traits as opposed to more commonly studied unicast networks. Specially, these include (i) identical packets must be delivered successfully to several nodes, (ii) outage at any receiver requires the packet to be retransmitted at least to that receiver, and (iii) the multicast rate is dominated by the receiver with the weakest link in order to minimize outage and retransmission. A first contribution of this paper is the development of a tractable multicast model and throughput metric that captures each of these key traits in a multicast wireless network. We utilize a Poisson cluster process (PCP) consisting of a distinct Poisson point process (PPP) for the transmitters and receivers, and then define the multicast transmission capacity (MTC) as the maximum achievable multicast rate per transmission attempt times the maximum intensity of multicast clusters under decoding delay and multicast outage constraints. A multicast cluster is a contiguous area over which a packet is multicasted, and to reduce outage it can be tessellated into smaller regions of multicast. The second contribution of the paper is the analysis of several key aspects of this model, for which we develop the following main result. Assuming transmission attempts are allowed for each tessellated region in a multicast cluster, we show that the MTC is where , and are functions of and depending on the network size and intensity, and is the average number of the intended receivers in a cluster. We derive for a number of regimes of interest, and also show that an appropriate number of retransmissions can significantly enhance the MTC.',
	 'authors': u'Chun-Hung Liu, Jeffrey G. Andrews,',
	 'category': u'Computer Science ',
	 'date': '2010-2-12',
	 'pdflink': u'http://arxiv.org/pdf/1002.2655',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nMulticast Outage Probability and Transmission Capacity of Multihop  Wireless Networks',
	 'urllink': u'http://arxiv.org/abs/1002.2655'}
2015-03-24 00:21:39+0000 [xxu46_1] INFO: Crawled 106 pages (at 1 pages/min), scraped 100 items (at 1 items/min)
2015-03-24 00:22:08+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2654> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:22:08+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2654>
	{'abstract': u'This study shows the means to evaluate the wind farm impact on the radar. It proposes the set of tools, which can be used to realise this objective. The big part of report covers the study of complex pattern propagation factor as the critical issue of the Advanced Propagation Model (APM). Finally, the reader can find here the implementation of this algorithm - the real scenario in Inverness airport (the United Kingdom), where the ATC radar STAR 2000, developed by Thales Air Systems, operates in the presence of several wind farms. Basically, the project is based on terms of the department "Strategy Technology &amp; Innovation", where it has been done. Also you can find here how the radar industry can act with the problem engendered by wind farms. The current strategies in this area are presented, such as a wind turbine production, improvements of air traffic handling procedures and the collaboration between developers of radars and wind turbines. The possible strategy for Thales as a main pioneer was given as well.',
	 'authors': u'Evgeny D. Norman,',
	 'category': u'Computer Science ',
	 'date': '2010-2-13',
	 'pdflink': u'http://arxiv.org/pdf/1002.2654',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nAssessment Of The Wind Farm Impact On The Radar',
	 'urllink': u'http://arxiv.org/abs/1002.2654'}
2015-03-24 00:22:39+0000 [xxu46_1] INFO: Crawled 107 pages (at 1 pages/min), scraped 101 items (at 1 items/min)
2015-03-24 00:23:39+0000 [xxu46_1] INFO: Crawled 107 pages (at 0 pages/min), scraped 101 items (at 0 items/min)
2015-03-24 00:23:39+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2625> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:23:39+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2625>
	{'abstract': u'A new algorithm to generate all Dyck words is presented, which is used in ranking and unranking Dyck words. We emphasize the importance of using Dyck words in encoding objects related to Catalan numbers. As a consequence of formulas used in the ranking algorithm we can obtain a recursive formula for the nth Catalan number.',
	 'authors': u'Zoltan Kasa,',
	 'category': u'Computer Science ',
	 'date': '2010-2-12',
	 'pdflink': u'http://arxiv.org/pdf/1002.2625',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nGenerating and ranking of Dyck words',
	 'urllink': u'http://arxiv.org/abs/1002.2625'}
2015-03-24 00:24:39+0000 [xxu46_1] INFO: Crawled 108 pages (at 1 pages/min), scraped 102 items (at 1 items/min)
2015-03-24 00:25:09+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2594> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:25:09+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2594>
	{'abstract': u"An Artin-Schreier tower over the finite field F_p is a tower of field extensions generated by polynomials of the form X^p - X - a. Following Cantor and Couveignes, we give algorithms with quasi-linear time complexity for arithmetic operations in such towers. As an application, we present an implementation of Couveignes' algorithm for computing isogenies between elliptic curves using the p-torsion.",
	 'authors': u'Luca De Feo, \xc9ric Schost,',
	 'category': u'Computer Science ',
	 'date': '2010-2-12',
	 'pdflink': u'http://arxiv.org/pdf/1002.2594',
	 'subjects': u'Symbolic Computation (cs.SC)',
	 'title': u'\nFast Arithmetics in Artin-Schreier Towers over Finite Fields',
	 'urllink': u'http://arxiv.org/abs/1002.2594'}
2015-03-24 00:25:39+0000 [xxu46_1] INFO: Crawled 109 pages (at 1 pages/min), scraped 103 items (at 1 items/min)
2015-03-24 00:26:39+0000 [xxu46_1] INFO: Crawled 109 pages (at 0 pages/min), scraped 103 items (at 0 items/min)
2015-03-24 00:26:47+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2586> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:26:47+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2586>
	{'abstract': u'The fundamental principle underlying compressed sensing is that a signal, which is sparse under some basis representation, can be recovered from a small number of linear measurements. However, prior knowledge of the sparsity basis is essential for the recovery process. This work introduces the concept of blind compressed sensing, which avoids the need to know the sparsity basis in both the sampling and the recovery process. We suggest three possible constraints on the sparsity basis that can be added to the problem in order to make its solution unique. For each constraint we prove conditions for uniqueness, and suggest a simple method to retrieve the solution. Under the uniqueness conditions, and as long as the signals are sparse enough, we demonstrate through simulations that without knowing the sparsity basis our methods can achieve results similar to those of standard compressed sensing, which relay on prior knowledge of the sparsity basis. This offers a general sampling and reconstruction system that fits all sparse signals, regardless of the sparsity basis, under the conditions and constraints presented in this work.',
	 'authors': u'Sivan Gleichman, Yonina C. Eldar,',
	 'category': u'Computer Science ',
	 'date': '2010-2-12',
	 'pdflink': u'http://arxiv.org/pdf/1002.2586',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nBlind Compressed Sensing',
	 'urllink': u'http://arxiv.org/abs/1002.2586'}
2015-03-24 00:27:39+0000 [xxu46_1] INFO: Crawled 110 pages (at 1 pages/min), scraped 104 items (at 1 items/min)
2015-03-24 00:28:35+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2580> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:28:35+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2580>
	{'abstract': u'In this paper we consider imprecise terrains, that is, triangulated terrains with a vertical error interval in the vertices. In particular, we study the problem of removing as many local extrema (minima and maxima) as possible from the terrain. We show that removing only minima or only maxima can be done optimally in O(n log n) time, for a terrain with n vertices. Interestingly, however, removing both the minima and maxima simultaneously is NP-hard, and is even hard to approximate within a factor of O(log log n) unless P=NP. Moreover, we show that even a simplified version of the problem where vertices can have only two different heights is already NP-hard, a result we obtain by proving hardness of a special case of 2-Disjoint Connected Subgraphs, a problem that has lately received considerable attention from the graph-algorithms community.',
	 'authors': u'Chris Gray, Frank Kammer, Maarten Loffler, Rodrigo I. Silveira,',
	 'category': u'Computer Science ',
	 'date': '2010-2-12',
	 'pdflink': u'http://arxiv.org/pdf/1002.2580',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nRemoving Local Extrema from Imprecise Terrains',
	 'urllink': u'http://arxiv.org/abs/1002.2580'}
2015-03-24 00:28:39+0000 [xxu46_1] INFO: Crawled 111 pages (at 1 pages/min), scraped 105 items (at 1 items/min)
2015-03-24 00:29:25+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2578> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:29:25+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2578>
	{'abstract': u"Fixed point combinators (and their generalization: looping combinators) are classic notions belonging to the heart of lambda-calculus and logic. We start with an exploration of the structure of fixed point combinators (fpc's), vastly generalizing the well-known fact that if Y is an fpc, Y(SI) is again an fpc, generating the Boehm sequence of fpc's. Using the infinitary lambda-calculus we devise infinitely many other generation schemes for fpc's. In this way we find schemes and building blocks to construct new fpc's in a modular way. Having created a plethora of new fixed point combinators, the task is to prove that they are indeed new. That is, we have to prove their beta-inconvertibility. Known techniques via Boehm Trees do not apply, because all fpc's have the same Boehm Tree (BT). Therefore, we employ `clocked BT's', with annotations that convey information of the tempo in which the data in the BT are produced. BT's are thus enriched with an intrinsic clock behaviour, leading to a refined discrimination method for lambda-terms. The corresponding equality is strictly intermediate between beta-convertibility and BT-equality, the equality in the classical models of lambda-calculus. An analogous approach pertains to Levy-Longo Berarducci trees. Finally, we increase the discrimination power by a precision of the clock notion that we call `atomic clock'.",
	 'authors': u'Joerg Endrullis, Dimitri Hendriks, Jan Willem Klop,',
	 'category': u'Computer Science ',
	 'date': '2010-2-12',
	 'pdflink': u'http://arxiv.org/pdf/1002.2578',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nModular Construction of Fixed Point Combinators and Clocked Boehm Trees',
	 'urllink': u'http://arxiv.org/abs/1002.2578'}
2015-03-24 00:29:39+0000 [xxu46_1] INFO: Crawled 112 pages (at 1 pages/min), scraped 106 items (at 1 items/min)
2015-03-24 00:30:39+0000 [xxu46_1] INFO: Crawled 112 pages (at 0 pages/min), scraped 106 items (at 0 items/min)
2015-03-24 00:30:59+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2557> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:30:59+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2557>
	{'abstract': u'We consider two-player turn-based games with zero-reachability and zero-safety objectives generated by extended vector addition systems with states. Although the problem of deciding the winner in such games is undecidable in general, we identify several decidable and even tractable subcases of this problem obtained by restricting the number of counters and/or the sets of target configurations.',
	 'authors': u'Tomas Brazdil, Petr Jancar, Antonin Kucera,',
	 'category': u'Computer Science ',
	 'date': '2010-2-12',
	 'pdflink': u'http://arxiv.org/pdf/1002.2557',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nReachability Games on Extended Vector Addition Systems with States',
	 'urllink': u'http://arxiv.org/abs/1002.2557'}
2015-03-24 00:31:39+0000 [xxu46_1] INFO: Crawled 113 pages (at 1 pages/min), scraped 107 items (at 1 items/min)
2015-03-24 00:32:39+0000 [xxu46_1] INFO: Crawled 113 pages (at 0 pages/min), scraped 107 items (at 0 items/min)
2015-03-24 00:32:44+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2527> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:32:44+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2527>
	{'abstract': u'Human users have a tough time remembering long cryptographic keys. Hence, researchers, for so long, have been examining ways to utilize biometric features of the user instead of a memorable password or passphrase, in an effort to generate strong and repeatable cryptographic keys. Our objective is to incorporate the volatility of the users biometric features into the generated key, so as to make the key unguessable to an attacker lacking significant knowledge of the users biometrics. We go one step further trying to incorporate multiple biometric modalities into cryptographic key generation so as to provide better security. In this article, we propose an efficient approach based on multimodal biometrics (Iris and fingerprint) for generation of secure cryptographic key. The proposed approach is composed of three modules namely, 1) Feature extraction, 2) Multimodal biometric template generation and 3) Cryptographic key generation. Initially, the features, minutiae points and texture properties are extracted from the fingerprint and iris images respectively. Subsequently, the extracted features are fused together at the feature level to construct the multibiometric template. Finally, a 256bit secure cryptographic key is generated from the multibiometric template. For experimentation, we have employed the fingerprint images obtained from publicly available sources and the iris images from CASIA Iris Database. The experimental results demonstrate the effectiveness of the proposed approach.',
	 'authors': u'A. Jagadeesan, K. Duraiswamy,',
	 'category': u'Computer Science ',
	 'date': '2010-2-12',
	 'pdflink': u'http://arxiv.org/pdf/1002.2527',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nSecured Cryptographic Key Generation From Multimodal Biometrics Feature  Level Fusion Of Fingerprint And Iris',
	 'urllink': u'http://arxiv.org/abs/1002.2527'}
2015-03-24 00:33:39+0000 [xxu46_1] INFO: Crawled 114 pages (at 1 pages/min), scraped 108 items (at 1 items/min)
2015-03-24 00:34:12+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2523> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:34:12+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2523>
	{'abstract': u'The aim of this paper is to study the fusion at feature extraction level for face and fingerprint biometrics. The proposed approach is based on the fusion of the two traits by extracting independent feature pointsets from the two modalities, and making the two pointsets compatible for concatenation. Moreover, to handle the problem of curse of dimensionality, the feature pointsets are properly reduced in dimension. Different feature reduction techniques are implemented, prior and after the feature pointsets fusion, and the results are duly recorded. The fused feature pointset for the database and the query face and fingerprint images are matched using techniques based on either the point pattern matching, or the Delaunay triangulation. Comparative experiments are conducted on chimeric and real databases, to assess the actual advantage of the fusion performed at the feature extraction level, in comparison to the matching score level.',
	 'authors': u'Ajita Rattani, Dakshina Ranjan Kisku, Manuele Bicego, Massimo Tistarelli,',
	 'category': u'Computer Science ',
	 'date': '2010-2-12',
	 'pdflink': u'http://arxiv.org/pdf/1002.2523',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nFeature Level Fusion of Face and Fingerprint Biometrics',
	 'urllink': u'http://arxiv.org/abs/1002.2523'}
2015-03-24 00:34:39+0000 [xxu46_1] INFO: Crawled 115 pages (at 1 pages/min), scraped 109 items (at 1 items/min)
2015-03-24 00:35:39+0000 [xxu46_1] INFO: Crawled 115 pages (at 0 pages/min), scraped 109 items (at 0 items/min)
2015-03-24 00:35:52+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2477> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:35:52+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2477>
	{'abstract': u"The existing literature on optimal auctions focuses on optimizing the expected revenue of the seller, and is appropriate for risk-neutral sellers. In this paper, we identify good mechanisms for risk-averse sellers. As is standard in the economics literature, we model the risk-aversion of a seller by endowing the seller with a monotone concave utility function. We then seek robust mechanisms that are approximately optimal for all sellers, no matter what their levels of risk-aversion are. We have two main results for multi-unit auctions with unit-demand bidders whose valuations are drawn i.i.d. from a regular distribution. First, we identify a posted-price mechanism called the Hedge mechanism, which gives a universal constant factor approximation; we also show for the unlimited supply case that this mechanism is in a sense the best possible. Second, we show that the VCG mechanism gives a universal constant factor approximation when the number of bidders is even only a small multiple of the number of items. Along the way we point out that Myerson's characterization of the optimal mechanisms fails to extend to utility-maximization for risk-averse sellers, and establish interesting properties of regular distributions and monotone hazard rate distributions.",
	 'authors': u'Mukund Sundararajan, Qiqi Yan,',
	 'category': u'Computer Science ',
	 'date': '2010-2-12',
	 'pdflink': u'http://arxiv.org/pdf/1002.2477',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nRobust Mechanisms for Risk-Averse Sellers',
	 'urllink': u'http://arxiv.org/abs/1002.2477'}
2015-03-24 00:36:39+0000 [xxu46_1] INFO: Crawled 116 pages (at 1 pages/min), scraped 110 items (at 1 items/min)
2015-03-24 00:36:52+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2456> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:36:52+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2456>
	{'abstract': u'We give the class of finite groups which arise as the permutation groups of cyclic codes over finite fields. Furthermore, we extend the results of Brand and Huffman et al. and we find the properties of the set of permutations by which two cyclic codes of length p^r can be equivalent. We also find the set of permutations by which two quasi-cyclic codes can be equivalent.',
	 'authors': u'Kenza Guenda,',
	 'category': u'Computer Science ',
	 'date': '2010-2-12',
	 'pdflink': u'http://arxiv.org/pdf/1002.2456',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nThe Permutation Groups and the Equivalence of Cyclic and Quasi-Cyclic  Codes',
	 'urllink': u'http://arxiv.org/abs/1002.2456'}
2015-03-24 00:37:39+0000 [xxu46_1] INFO: Crawled 117 pages (at 1 pages/min), scraped 111 items (at 1 items/min)
2015-03-24 00:38:08+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2450> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:38:08+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2450>
	{'abstract': u'This paper is devoted to the theoretical analysis of a problem derived from interaction between two Iplanet products: Web Proxy Server and the Directory Server. In particular, a probabilistic and stochastic-approximation model is proposed to minimize the occurrence of LDAP connection failures in Iplanet Web Proxy 3.6 Server. The proposed model serves not only to provide a parameterization of the aforementioned phenomena, but also to provide meaningful insights illustrating and supporting these theoretical results. In addition, we shall also address practical considerations when estimating the parameters of the proposed model from experimental data. Finally, we shall provide some interesting results from real-world data collected from our customers.',
	 'authors': u'Alejandro Chinea Manrique de Lara,',
	 'category': u'Computer Science ',
	 'date': '2010-2-11',
	 'pdflink': u'http://arxiv.org/pdf/1002.2450',
	 'subjects': u'Performance (cs.PF)',
	 'title': u'\nModeling the Probability of Failure on LDAP Binding Operations in  Iplanet Web Proxy 3.6 Server',
	 'urllink': u'http://arxiv.org/abs/1002.2450'}
2015-03-24 00:38:39+0000 [xxu46_1] INFO: Crawled 118 pages (at 1 pages/min), scraped 112 items (at 1 items/min)
2015-03-24 00:39:39+0000 [xxu46_1] INFO: Crawled 118 pages (at 0 pages/min), scraped 112 items (at 0 items/min)
2015-03-24 00:39:41+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2440> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:39:41+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2440>
	{'abstract': u'The list update problem is a classical online problem, with an optimal competitive ratio that is still open, known to be somewhere between 1.5 and 1.6. An algorithm with competitive ratio 1.6, the smallest known to date, is COMB, a randomized combination of BIT and the TIMESTAMP algorithm TS. This and almost all other list update algorithms, like MTF, are projective in the sense that they can be defined by looking only at any pair of list items at a time. Projectivity (also known as "list factoring") simplifies both the description of the algorithm and its analysis, and so far seems to be the only way to define a good online algorithm for lists of arbitrary length. In this paper we characterize all projective list update algorithms and show that their competitive ratio is never smaller than 1.6 in the partial cost model. Therefore, COMB is a best possible projective algorithm in this model.',
	 'authors': u'Christoph Ambuehl, Bernd Gaertner, Bernhard von Stengel,',
	 'category': u'Computer Science ',
	 'date': '2010-2-11',
	 'pdflink': u'http://arxiv.org/pdf/1002.2440',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nOptimal Lower Bounds for Projective List Update Algorithms',
	 'urllink': u'http://arxiv.org/abs/1002.2440'}
2015-03-24 00:40:39+0000 [xxu46_1] INFO: Crawled 119 pages (at 1 pages/min), scraped 113 items (at 1 items/min)
2015-03-24 00:41:26+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2439> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:41:26+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2439>
	{'abstract': u"Titles are denoted by the TITLE element within a web page. We queried the title against the the Yahoo search engine to determine the page's status (found, not found). We conducted several tests based on elements of the title. These tests were used to discern whether we could predict a pages status based on the title. Our results increase our ability to determine bad titles but not our ability to determine good titles.",
	 'authors': u'Jeffery L. Shipman, Martin Klein, Michael L. Nelson,',
	 'category': u'Computer Science ',
	 'date': '2010-2-11',
	 'pdflink': u'http://arxiv.org/pdf/1002.2439',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nUsing Web Page Titles to Rediscover Lost Web Pages',
	 'urllink': u'http://arxiv.org/abs/1002.2439'}
2015-03-24 00:41:39+0000 [xxu46_1] INFO: Crawled 120 pages (at 1 pages/min), scraped 114 items (at 1 items/min)
2015-03-24 00:42:39+0000 [xxu46_1] INFO: Crawled 120 pages (at 0 pages/min), scraped 114 items (at 0 items/min)
2015-03-24 00:42:40+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2425> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:42:40+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2425>
	{'abstract': u'The ability to monitor the progress of students academic performance is a critical issue to the academic community of higher learning. A system for analyzing students results based on cluster analysis and uses standard statistical algorithms to arrange their scores data according to the level of their performance is described. In this paper, we also implemented k mean clustering algorithm for analyzing students result data. The model was combined with the deterministic model to analyze the students results of a private Institution in Nigeria which is a good benchmark to monitor the progression of academic performance of students in higher Institution for the purpose of making an effective decision by the academic planners.',
	 'authors': u'O. J. Oyelade, O. O. Oladipupo, I. C. Obagbuwa,',
	 'category': u'Computer Science ',
	 'date': '2010-2-11',
	 'pdflink': u'http://arxiv.org/pdf/1002.2425',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nApplication of k Means Clustering algorithm for prediction of Students  Academic Performance',
	 'urllink': u'http://arxiv.org/abs/1002.2425'}
2015-03-24 00:43:33+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2423> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:43:33+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2423>
	{'abstract': u'Recently an alternative of DDoS attacks called shrew attacks or Reduction of Quality (RoQ) has been identified which is very much difficult to detect. The RoQ attacks can use source and destination IP address spoofing, and they do not have distinct periodicity, and may not filter the attack packets precisely. In this paper, we propose to design the MAC layer based defense architecture for RoQ attacks in Wireless LAN which includes the detection and response stages. The attackers are detected by checking the RTS CTS packets from the MAC layer and the corresponding attack flows are blocked or rejected. By our simulation results, we show that our proposed technique achieves reduces the attack throughput there by increasing the received bandwidth and reducing the packet loss of legitimate users.',
	 'authors': u'Jatinder Singh, Savita Gupta, Lakhwinder Kaur,',
	 'category': u'Computer Science ',
	 'date': '2010-2-11',
	 'pdflink': u'http://arxiv.org/pdf/1002.2423',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nA MAC Layer Based Defense Architecture for Reduction of Quality (RoQ)  Attacks in Wireless LAN',
	 'urllink': u'http://arxiv.org/abs/1002.2423'}
2015-03-24 00:43:39+0000 [xxu46_1] INFO: Crawled 122 pages (at 2 pages/min), scraped 116 items (at 2 items/min)
2015-03-24 00:44:39+0000 [xxu46_1] INFO: Crawled 122 pages (at 0 pages/min), scraped 116 items (at 0 items/min)
2015-03-24 00:44:49+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2420> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:44:49+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2420>
	{'abstract': u'Networks on Chip is a recent solution paradigm adopted to increase the performance of Multicore designs. The key idea is to interconnect various computation modules (IP cores) in a network fashion and transport packets simultaneously across them, thereby gaining performance. In addition to improving performance by having multiple packets in flight, NoCs also present a host of other advantages including scalability, power efficiency, and component reuse through modular design. This work focuses on design and development of high performance communication architectures for FPGAs using NoCs Once completely developed, the above methodology could be used to augment the current FPGA design flow for implementing multicore SoC applications. We design and implement an NoC framework for FPGAs, MultiClock OnChip Network for Reconfigurable Systems (MoCReS). We propose a novel microarchitecture for a hybrid two layer router that supports both packetswitched communications, across its local and directional ports, as well as, time multiplexed circuitswitched communications among the multiple IP cores directly connected to it. Results from place and route VHDL models of the advanced router architecture show an average improvement of 20.4 percent in NoC bandwidth (maximum of 24 percent compared to a traditional NoC). We parameterize the hybrid router model over the number of ports, channel width and bRAM depth and develop a library of network components (MoClib Library). For your paper to be published in the conference proceedings, you must use this document as both an instruction set and as a template into which you can type your own text. If your paper does not conform to the required format, you will be asked to fix it.',
	 'authors': u'P. Ezhumalai, S. Manojkumar, C. Arun, P. Sakthivel, D. Sridharan,',
	 'category': u'Computer Science ',
	 'date': '2010-2-11',
	 'pdflink': u'http://arxiv.org/pdf/1002.2420',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nHigh Performance Hybrid Two Layer Router Architecture for FPGAs Using  Network On Chip',
	 'urllink': u'http://arxiv.org/abs/1002.2420'}
2015-03-24 00:45:39+0000 [xxu46_1] INFO: Crawled 123 pages (at 1 pages/min), scraped 117 items (at 1 items/min)
2015-03-24 00:46:04+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2418> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:46:04+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2418>
	{'abstract': u'In this paper offers a simple and lossless compression method for compression of medical images. Method is based on wavelet decomposition of the medical images followed by the correlation analysis of coefficients. The correlation analyses are the basis of prediction equation for each sub band. Predictor variable selection is performed through coefficient graphic method to avoid multicollinearity problem and to achieve high prediction accuracy and compression rate. The method is applied on MRI and CT images. Results show that the proposed approach gives a high compression rate for MRI and CT images comparing with state of the art methods.',
	 'authors': u'S. M. Ramesh, A. Shanmugam,',
	 'category': u'Computer Science ',
	 'date': '2010-2-11',
	 'pdflink': u'http://arxiv.org/pdf/1002.2418',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nMedical Image Compression using Wavelet Decomposition for Prediction  Method',
	 'urllink': u'http://arxiv.org/abs/1002.2418'}
2015-03-24 00:46:39+0000 [xxu46_1] INFO: Crawled 124 pages (at 1 pages/min), scraped 118 items (at 1 items/min)
2015-03-24 00:47:22+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2416> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:47:22+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2416>
	{'abstract': u'A Previously traditional methods were sufficient to protect the information, since it is simplicity in the past does not need complicated methods but with the progress of information technology, it become easy to attack systems, and detection of encryption methods became necessary to find ways parallel with the differing methods used by hackers, so the embedding methods could be under surveillance from system managers in an organization that requires the high level of security. This fact requires researches on new hiding methods and cover objects which hidden information is embedded in. It is the result from the researches to embed information in executable files, but when will use the executable file for cover they have many challenges must be taken into consideration which is any changes made to the file will be firstly detected by untie viruses, secondly the functionality of the file is not still functioning. In this paper, a new information hiding system is presented. The aim of the proposed system is to hide information (data file) within image page of execution file (EXEfile) to make sure changes made to the file will not be detected by universe and the functionality of the exe.file is still functioning after hiding process. Meanwhile, since the cover file might be used to identify hiding information, the proposed system considers overcoming this dilemma by using the execution file as a cover file.',
	 'authors': u'Rafiqul Islam, A.W. Naji, A. A. Zaidan, B. B. Zaidan,',
	 'category': u'Computer Science ',
	 'date': '2010-2-11',
	 'pdflink': u'http://arxiv.org/pdf/1002.2416',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nNew System for Secure Cover File of Hidden Data in the Image Page within  Executable File Using Statistical Steganography Techniques',
	 'urllink': u'http://arxiv.org/abs/1002.2416'}
2015-03-24 00:47:39+0000 [xxu46_1] INFO: Crawled 125 pages (at 1 pages/min), scraped 119 items (at 1 items/min)
2015-03-24 00:48:39+0000 [xxu46_1] INFO: Crawled 125 pages (at 0 pages/min), scraped 119 items (at 0 items/min)
2015-03-24 00:49:11+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2415> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:49:11+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2415>
	{'abstract': u'This paper addresses the methodology for achieving the user interface design reusability of a qualitative software system and effort minimization by applying the inference on the stored design documents. The pictorial design documents are stored in a special format in the form of keyword text [DGML tag based design]. The design document storage mechanism will expose the keywords per design stored. This methodology is having an inference engine. Inference mechanism search for the requirements and find the match for them in the available design repository. A match found will success in reusing it after checking the quality parameters of the found design module in the result set. DGML notations produces qualitative designs which helps in minimizing the efforts of software development life cycle.',
	 'authors': u'P. K. Suri, Gurdev Singh,',
	 'category': u'Computer Science ',
	 'date': '2010-2-11',
	 'pdflink': u'http://arxiv.org/pdf/1002.2415',
	 'subjects': u'Human-Computer Interaction (cs.HC)',
	 'title': u'\nEffort minimization in UI development by reusing existing DGML based UI  design for qualitative software development',
	 'urllink': u'http://arxiv.org/abs/1002.2415'}
2015-03-24 00:49:39+0000 [xxu46_1] INFO: Crawled 126 pages (at 1 pages/min), scraped 120 items (at 1 items/min)
2015-03-24 00:50:39+0000 [xxu46_1] INFO: Crawled 126 pages (at 0 pages/min), scraped 120 items (at 0 items/min)
2015-03-24 00:50:54+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2414> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:50:54+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2414>
	{'abstract': u'Digital Watermarking is used for copyright protection and authentication. In the proposed system, a Dual Watermarking Scheme based on DWT SVD with chaos encryption algorithm, will be developed to improve the robustness and protection along with security. DWT and SVD have been used as a mathematical tool to embed watermark in the image. Two watermarks are embedded in the host image. The secondary is embedded into primary watermark and the resultant watermarked image is encrypted using chaos based logistic map. This provides an efficient and secure way for image encryption and transmission. The watermarked image is decrypted and a reliable watermark extraction scheme is developed for the extraction of the primary as well as secondary watermark from the distorted image.',
	 'authors': u'R. Dhanalakshmi, K. Thaiyalnayaki,',
	 'category': u'Computer Science ',
	 'date': '2010-2-11',
	 'pdflink': u'http://arxiv.org/pdf/1002.2414',
	 'subjects': u'Multimedia (cs.MM)',
	 'title': u'\nDual Watermarking Scheme with Encryption',
	 'urllink': u'http://arxiv.org/abs/1002.2414'}
2015-03-24 00:51:39+0000 [xxu46_1] INFO: Crawled 127 pages (at 1 pages/min), scraped 121 items (at 1 items/min)
2015-03-24 00:52:34+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2409> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:52:34+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2409>
	{'abstract': u'Secure sum computation of private data inputs is an important component of Secure Multi party Computation (SMC).In this paper we provide a protocol to compute the sum of individual data inputs with zero probability of data leakage. In our proposed protocol we break input of each party into number of segments and change the arrangement of the parties such that in each round of the computation the neighbors are changed. In this protocol it becomes impossible for semi honest parties to know the private data of some other party.',
	 'authors': u'Rashid Sheikh, Beerendra Kumar, Durgesh Kumar Mishra,',
	 'category': u'Computer Science ',
	 'date': '2010-2-11',
	 'pdflink': u'http://arxiv.org/pdf/1002.2409',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nChanging Neighbors k Secure Sum Protocol for Secure Multi Party  Computation',
	 'urllink': u'http://arxiv.org/abs/1002.2409'}
2015-03-24 00:52:39+0000 [xxu46_1] INFO: Crawled 128 pages (at 1 pages/min), scraped 122 items (at 1 items/min)
2015-03-24 00:53:39+0000 [xxu46_1] INFO: Crawled 128 pages (at 0 pages/min), scraped 122 items (at 0 items/min)
2015-03-24 00:54:05+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2408> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:54:05+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2408>
	{'abstract': u'Teleophthalmology holds a great potential to improve the quality, access, and affordability in health care. For patients, it can reduce the need for travel and provide the access to a superspecialist. Ophthalmology lends itself easily to telemedicine as it is a largely image based diagnosis. The main goal of the proposed system is to diagnose the type of disease in the retina and to automatically detect and segment retinal diseases without human supervision or interaction. The proposed system will diagnose the disease present in the retina using a neural network based classifier.The extent of the disease spread in the retina can be identified by extracting the textural features of the retina. This system will diagnose the following type of diseases: Diabetic Retinopathy and Drusen.',
	 'authors': u'D. Jayanthi, N. Devi, S. SwarnaParvathi,',
	 'category': u'Computer Science ',
	 'date': '2010-2-11',
	 'pdflink': u'http://arxiv.org/pdf/1002.2408',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nAutomatic diagnosis of retinal diseases from color retinal images',
	 'urllink': u'http://arxiv.org/abs/1002.2408'}
2015-03-24 00:54:39+0000 [xxu46_1] INFO: Crawled 129 pages (at 1 pages/min), scraped 123 items (at 1 items/min)
2015-03-24 00:55:37+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2403> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:55:37+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2403>
	{'abstract': u'Initially TCP was designed with the notion in mind that wired networks are generally reliable and any segment loss in a transmission is due to congestion in the network rather than an unreliable medium (The assumptions is that the packet loss caused by damage is much less than 1 percent) . This notion doesnt hold in wireless parts of the network. Wireless links are highly unreliable and they lose segments all the time due to a number of factors. Very few papers are available which uses TCP for MANET. In this paper, an attempt have been made to justify the use of TCP variants (Tahoe and Reno) for loss of packet due to random noise introduces in the MANET. For the present analysis the simulation has been carried out for TCP variants (Tahoe and Reno) by introduces 0, 10, 20 and 30 percent noise. The comparison of TCP variants is made by running simulation for 0, 10, 20 and 30 percent of data packet loss due to noise in the transmission link and the effect of throughput and congestion window has been examined. During the simulation we have observed that throughput has been decreased when a drop of multiple segments happens, further we have observed in the case of TCP variant (Reno) throughput is better at 1 percent (Figure 5) which implies a network with short burst of error and low BER, causing only one segment to be lost. When multiple segments are lost due to error prone nature of link, Tahoe perform better than Reno (Figure 13), that gives a significant saving of time (64.28 percent) in comparison with Reno (Table 4). Several simulations have been run with ns 2 simulator in order to acquire a better understanding of these TCP variants and the way they perform their function. We conclude with a discussion of whether these TCP versions can be used in Mobile Ad hoc Network.',
	 'authors': u'Shamimul Qamar, Kumar Manoj,',
	 'category': u'Computer Science ',
	 'date': '2010-2-11',
	 'pdflink': u'http://arxiv.org/pdf/1002.2403',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nImpact of Random Loss on TCP Performance in Mobile Ad hoc Networks (IEEE  802.11), A Simulation-Based Analysis',
	 'urllink': u'http://arxiv.org/abs/1002.2403'}
2015-03-24 00:55:39+0000 [xxu46_1] INFO: Crawled 130 pages (at 1 pages/min), scraped 124 items (at 1 items/min)
2015-03-24 00:56:39+0000 [xxu46_1] INFO: Crawled 130 pages (at 0 pages/min), scraped 124 items (at 0 items/min)
2015-03-24 00:57:15+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2385> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:57:15+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2385>
	{'abstract': u'As passive optical networks (PON) are increasingly deployed to provide high speed Internet access, it is important to understand their fundamental traffic capacity limits. The paper discusses performance models applicable to wavelength division multiplexing (WDM) EPONs and GPONs under the assumption that users access the fibre via optical network units equipped with tunable transmitters. The considered stochastic models are based on multiserver polling systems for which explicit analytical results are not known. A large system asymptotic, mean-field approximation, is used to derive closed form solutions of these complex systems. Convergence of the mean field dynamics is proved in the case of a simple network configuration. Simulation results show that, for a realistic sized PON, the mean field approximation is accurate.',
	 'authors': u'Nelson Antunes, Christine Fricker, Philippe Robert, James Roberts,',
	 'category': u'Computer Science ',
	 'date': '2010-2-11',
	 'pdflink': u'http://arxiv.org/pdf/1002.2385',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nTraffic Capacity of Large WDM Passive Optical Networks',
	 'urllink': u'http://arxiv.org/abs/1002.2385'}
2015-03-24 00:57:39+0000 [xxu46_1] INFO: Crawled 131 pages (at 1 pages/min), scraped 125 items (at 1 items/min)
2015-03-24 00:58:39+0000 [xxu46_1] INFO: Crawled 131 pages (at 0 pages/min), scraped 125 items (at 0 items/min)
2015-03-24 00:58:42+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2384> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 00:58:42+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2384>
	{'abstract': u'Passive optical networks are increasingly used for access to the Internet and it is important to understand the performance of future long-reach, multi-channel variants. In this paper we discuss requirements on the dynamic bandwidth allocation (DBA) algorithm used to manage the upstream resource in a WDM EPON and propose a simple novel DBA algorithm that is considerably more efficient than classical approaches. We demonstrate that the algorithm emulates a multi-server polling system and derive capacity formulas that are valid for general traffic processes. We evaluate delay performance by simulation demonstrating the superiority of the proposed scheduler. The proposed scheduler offers considerable flexibility and is particularly efficient in long-reach access networks where propagation times are high.',
	 'authors': u'Nelson Antunes, Christine Fricker, Philippe Robert, James Roberts,',
	 'category': u'Computer Science ',
	 'date': '2010-2-11',
	 'pdflink': u'http://arxiv.org/pdf/1002.2384',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nUpstream traffic capacity of a WDM EPON under online GATE-driven  scheduling',
	 'urllink': u'http://arxiv.org/abs/1002.2384'}
2015-03-24 00:59:39+0000 [xxu46_1] INFO: Crawled 132 pages (at 1 pages/min), scraped 126 items (at 1 items/min)
2015-03-24 01:00:23+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2353> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:00:23+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2353>
	{'abstract': u'Online advertising is currently the greatest source of revenue for many Internet giants. The increased number of specialized websites and modern profiling techniques, have all contributed to an explosion of the income of ad brokers from online advertising. The single biggest threat to this growth, is however, click-fraud. Trained botnets and even individuals are hired by click-fraud specialists in order to maximize the revenue of certain users from the ads they publish on their websites, or to launch an attack between competing businesses. In this note we wish to raise the awareness of the networking research community on potential research areas within this emerging field. As an example strategy, we present Bluff ads; a class of ads that join forces in order to increase the effort level for click-fraud spammers. Bluff ads are either targeted ads, with irrelevant display text, or highly relevant display text, with irrelevant targeting information. They act as a litmus test for the legitimacy of the individual clicking on the ads. Together with standard threshold-based methods, fake ads help to decrease click-fraud levels.',
	 'authors': u'Hamed Haddadi,',
	 'category': u'Computer Science ',
	 'date': '2010-2-11',
	 'pdflink': u'http://arxiv.org/pdf/1002.2353',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nFighting Online Click-Fraud Using Bluff Ads',
	 'urllink': u'http://arxiv.org/abs/1002.2353'}
2015-03-24 01:00:39+0000 [xxu46_1] INFO: Crawled 133 pages (at 1 pages/min), scraped 127 items (at 1 items/min)
2015-03-24 01:01:39+0000 [xxu46_1] INFO: Crawled 133 pages (at 0 pages/min), scraped 127 items (at 0 items/min)
2015-03-24 01:01:55+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2334> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:01:55+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2334>
	{'abstract': u'We study a novel class of mechanism design problems in which the outcomes are constrained by the payments. This basic class of mechanism design problems captures many common economic situations, and yet it has not been studied, to our knowledge, in the past. We focus on the case of procurement auctions in which sellers have private costs, and the auctioneer aims to maximize a utility function on subsets of items, under the constraint that the sum of the payments provided by the mechanism does not exceed a given budget. Standard mechanism design ideas such as the VCG mechanism and its variants are not applicable here. We show that, for general functions, the budget constraint can render mechanisms arbitrarily bad in terms of the utility of the buyer. However, our main result shows that for the important class of submodular functions, a bounded approximation ratio is achievable. Better approximation results are obtained for subclasses of the submodular functions. We explore the space of budget feasible mechanisms in other domains and give a characterization under more restricted conditions.',
	 'authors': u'Yaron Singer,',
	 'category': u'Computer Science ',
	 'date': '2010-2-11',
	 'pdflink': u'http://arxiv.org/pdf/1002.2334',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nBudget Feasible Mechanisms',
	 'urllink': u'http://arxiv.org/abs/1002.2334'}
2015-03-24 01:02:39+0000 [xxu46_1] INFO: Crawled 134 pages (at 1 pages/min), scraped 128 items (at 1 items/min)
2015-03-24 01:03:12+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2297> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:03:12+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2297>
	{'abstract': u'More and more people rely on Web information and with the advance of Web 2.0 technologies they can increasingly easily participate to the creation of this information. Country-level politicians could not ignore this trend and have started to use the Web to promote them or to demote their opponents. This paper presents how candidates to a French mayor local election and with less budget have engineered their Web campaign and online reputation. After presenting the settings of the local election, the Web tools used by the different candidates and the local journalists are detailed. These tools are evaluated from a security point of view and the legal issues that they have created are underlined.',
	 'authors': u'Jean-Marc Seigneur,',
	 'category': u'Computer Science ',
	 'date': '2010-2-11',
	 'pdflink': u'http://arxiv.org/pdf/1002.2297',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nLocal ePolitics Reputation Case Study',
	 'urllink': u'http://arxiv.org/abs/1002.2297'}
2015-03-24 01:03:39+0000 [xxu46_1] INFO: Crawled 135 pages (at 1 pages/min), scraped 129 items (at 1 items/min)
2015-03-24 01:04:39+0000 [xxu46_1] INFO: Crawled 135 pages (at 0 pages/min), scraped 129 items (at 0 items/min)
2015-03-24 01:04:45+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2294> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:04:45+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2294>
	{'abstract': u'Nowadays, mobile users can switch between different available networks, for example, nearby WiFi networks or their standard mobile operator network. Soon it will be extended to other operators. However, unless telecommunication operators can directly benefit from allowing a user to switch to another operator, operators have an incentive to keep their network quality of service confidential to avoid that their users decide to switch to another network. In contrast, in a user-centric way, the users should be allowed to share their observations regarding the networks that they have used. In this paper, we present our work in progress towards attack-resistant sharing of quality of service information and network provider reputation among mobile users.',
	 'authors': u'Jean-Marc Seigneur, Xavier Titi,',
	 'category': u'Computer Science ',
	 'date': '2010-2-11',
	 'pdflink': u'http://arxiv.org/pdf/1002.2294',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nReputation-based Telecommunication Network Selection',
	 'urllink': u'http://arxiv.org/abs/1002.2294'}
2015-03-24 01:05:39+0000 [xxu46_1] INFO: Crawled 136 pages (at 1 pages/min), scraped 130 items (at 1 items/min)
2015-03-24 01:06:02+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2293> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:06:02+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2293>
	{'abstract': u'Motivated by linear network coding, communication channels perform linear operation over finite fields, namely linear operator channels (LOCs), are studied in this paper. For such a channel, its output vector is a linear transform of its input vector, and the transformation matrix is randomly and independently generated. The transformation matrix is assumed to remain constant for every T input vectors and to be unknown to both the transmitter and the receiver. There are NO constraints on the distribution of the transformation matrix and the field size. Specifically, the optimality of subspace coding over LOCs is investigated. A lower bound on the maximum achievable rate of subspace coding is obtained and it is shown to be tight for some cases. The maximum achievable rate of constant-dimensional subspace coding is characterized and the loss of rate incurred by using constant-dimensional subspace coding is insignificant. The maximum achievable rate of channel training is close to the lower bound on the maximum achievable rate of subspace coding. Two coding approaches based on channel training are proposed and their performances are evaluated. Our first approach makes use of rank-metric codes and its optimality depends on the existence of maximum rank distance codes. Our second approach applies linear coding and it can achieve the maximum achievable rate of channel training. Our code designs require only the knowledge of the expectation of the rank of the transformation matrix. The second scheme can also be realized ratelessly without a priori knowledge of the channel statistics.',
	 'authors': u'Shenghao Yang, Siu-Wai Ho, Jin Meng, En-hui Yang, Raymond W. Yeung,',
	 'category': u'Computer Science ',
	 'date': '2010-2-11',
	 'pdflink': u'http://arxiv.org/pdf/1002.2293',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOn Linear Operator Channels over Finite Fields',
	 'urllink': u'http://arxiv.org/abs/1002.2293'}
2015-03-24 01:06:39+0000 [xxu46_1] INFO: Crawled 137 pages (at 1 pages/min), scraped 131 items (at 1 items/min)
2015-03-24 01:06:42+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2271> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:06:42+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2271>
	{'abstract': u'This paper studies network information theory problems where the external noise is Gaussian distributed. In particular, the Gaussian broadcast channel with coherent fading and the Gaussian interference channel are investigated. It is shown that in these problems, non-Gaussian code ensembles can achieve higher rates than the Gaussian ones. It is also shown that the strong Shamai-Laroia conjecture on the Gaussian ISI channel does not hold. In order to analyze non-Gaussian code ensembles over Gaussian networks, a geometrical tool using the Hermite polynomials is proposed. This tool provides a coordinate system to analyze a class of non-Gaussian input distributions that are invariant over Gaussian networks.',
	 'authors': u'Emmanuel Abbe, Lizhong Zheng,',
	 'category': u'Computer Science ',
	 'date': '2010-2-11',
	 'pdflink': u'http://arxiv.org/pdf/1002.2271',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nA Coordinate System for Gaussian Networks',
	 'urllink': u'http://arxiv.org/abs/1002.2271'}
2015-03-24 01:07:34+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2259> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:07:34+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2259>
	{'abstract': u'Given a set system (V,S), V= and S=, the minimum discrepancy problem is to find a 2-coloring of V, such that each set is colored as evenly as possible. In this paper we give the first polynomial time algorithms for discrepancy minimization that achieve bounds similar to those known existentially using the so-called Entropy Method. We also give a first approximation-like result for discrepancy. The main idea in our algorithms is to produce a coloring over time by letting the color of the elements perform a random walk (with tiny increments) starting from 0 until they reach or . At each time step the random hops for various elements are correlated using the solution to a semidefinite program, where this program is determined by the current state and the entropy method.',
	 'authors': u'Nikhil Bansal,',
	 'category': u'Computer Science ',
	 'date': '2010-2-11',
	 'pdflink': u'http://arxiv.org/pdf/1002.2259',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nConstructive Algorithms for Discrepancy Minimization',
	 'urllink': u'http://arxiv.org/abs/1002.2259'}
2015-03-24 01:07:39+0000 [xxu46_1] INFO: Crawled 139 pages (at 2 pages/min), scraped 133 items (at 2 items/min)
2015-03-24 01:08:35+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2244> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:08:35+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2244>
	{'abstract': u'The basic goal in combinatorial group testing is to identify a set of up to defective items within a large population of size using a pooling strategy. Namely, the items can be grouped together in pools, and a single measurement would reveal whether there are one or more defectives in the pool. The threshold model is a generalization of this idea where a measurement returns positive if the number of defectives in the pool reaches a fixed threshold , negative if this number is no more than a fixed lower threshold , and may behave arbitrarily otherwise. We study non-adaptive threshold group testing (in a possibly noisy setting) and show that, for this problem, measurements (where and is any fixed constant) suffice to identify the defectives, and also present almost matching lower bounds. This significantly improves the previously known (non-constructive) upper bound . Moreover, we obtain a framework for explicit construction of measurement schemes using lossless condensers. The number of measurements resulting from this scheme is ideally bounded by . Using state-of-the-art constructions of lossless condensers, however, we obtain explicit testing schemes with and measurements, for arbitrary constant .',
	 'authors': u'Mahdi Cheraghchi,',
	 'category': u'Computer Science ',
	 'date': '2010-2-10',
	 'pdflink': u'http://arxiv.org/pdf/1002.2244',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nImproved Constructions for Non-adaptive Threshold Group Testing',
	 'urllink': u'http://arxiv.org/abs/1002.2244'}
2015-03-24 01:08:39+0000 [xxu46_1] INFO: Crawled 140 pages (at 1 pages/min), scraped 134 items (at 1 items/min)
2015-03-24 01:09:39+0000 [xxu46_1] INFO: Crawled 140 pages (at 0 pages/min), scraped 134 items (at 0 items/min)
2015-03-24 01:09:50+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2240> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:09:50+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2240>
	{'abstract': u"We extend the Chow-Liu algorithm for general random variables while the previous versions only considered finite cases. In particular, this paper applies the generalization to Suzuki's learning algorithm that generates from data forests rather than trees based on the minimum description length by balancing the fitness of the data to the forest and the simplicity of the forest. As a result, we successfully obtain an algorithm when both of the Gaussian and finite random variables are present.",
	 'authors': u'Joe Suzuki,',
	 'category': u'Computer Science ',
	 'date': '2010-2-10',
	 'pdflink': u'http://arxiv.org/pdf/1002.2240',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nA Generalization of the Chow-Liu Algorithm and its Application to  Statistical Learning',
	 'urllink': u'http://arxiv.org/abs/1002.2240'}
2015-03-24 01:10:39+0000 [xxu46_1] INFO: Crawled 141 pages (at 1 pages/min), scraped 135 items (at 1 items/min)
2015-03-24 01:11:32+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2236> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:11:32+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2236>
	{'abstract': u'We define and study a new abstract domain which is a fine-grained combination of zonotopes with polyhedric domains such as the interval, octagon, linear templates or polyhedron domain. While abstract transfer functions are still rather inexpensive and accurate even for interpreting non-linear computations, we are able to also interpret tests (i.e. intersections) efficiently. This fixes a known drawback of zonotopic methods, as used for reachability analysis for hybrid sys- tems as well as for invariant generation in abstract interpretation: intersection of zonotopes are not always zonotopes, and there is not even a best zonotopic over-approximation of the intersection. We describe some examples and an im- plementation of our method in the APRON library, and discuss some further in- teresting combinations of zonotopes with non-linear or non-convex domains such as quadratic templates and maxplus polyhedra.',
	 'authors': u'Khalil Ghorbal, Eric Goubault, Sylvie Putot,',
	 'category': u'Computer Science ',
	 'date': '2010-2-10',
	 'pdflink': u'http://arxiv.org/pdf/1002.2236',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nA Logical Product Approach to Zonotope Intersection',
	 'urllink': u'http://arxiv.org/abs/1002.2236'}
2015-03-24 01:11:39+0000 [xxu46_1] INFO: Crawled 142 pages (at 1 pages/min), scraped 136 items (at 1 items/min)
2015-03-24 01:12:39+0000 [xxu46_1] INFO: Crawled 142 pages (at 0 pages/min), scraped 136 items (at 0 items/min)
2015-03-24 01:13:04+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2222> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:13:04+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2222>
	{'abstract': u'Exact String Matching is an essential issue in many computer science applications. Unfortunately, the performance of Exact String Matching algorithms, namely, executing time, does not address the needs of these applications. This paper proposes a general platform for improving the existing Exact String Matching algorithms executing time, called the PXSMAlg platform. The function of this platform is to parallelize the Exact String Matching algorithms using the MPI model over the Master or Slaves paradigms. The PXSMAlg platform parallelization process is done by dividing the Text into several parts and working on these parts simultaneously. This improves the executing time of the Exact String Matching algorithms. We have simulated the PXSMAlg platform in order to show its competence, through applying the Quick Search algorithm on the PXSMAlg platform. The simulation result showed significant improvement in the Quick Search executing time, and therefore extreme competence in the PXSMAlg platform.',
	 'authors': u'Mosleh M. Abu Alhaj, M. Halaiyqah, Muhannad A. Abu Hashem, Adnan A. Hnaif, O. Abouabdalla, Ahmed M. Manasrah,',
	 'category': u'Computer Science ',
	 'date': '2010-2-11',
	 'pdflink': u'http://arxiv.org/pdf/1002.2222',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nAn innovative platform to improve the performance of exact string  matching algorithms',
	 'urllink': u'http://arxiv.org/abs/1002.2222'}
2015-03-24 01:13:39+0000 [xxu46_1] INFO: Crawled 143 pages (at 1 pages/min), scraped 137 items (at 1 items/min)
2015-03-24 01:14:39+0000 [xxu46_1] INFO: Crawled 143 pages (at 0 pages/min), scraped 137 items (at 0 items/min)
2015-03-24 01:14:45+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2203> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:14:45+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2203>
	{'abstract': u'We propose an algorithm that test membership for regular expressions and show that the algorithm is correct. This algorithm is written in the style of a sequent proof system. The advantage of this algorithm over traditional ones is that the complex conversion process from regular expressions to finite automata is not needed. As a consequence, our algorithm is simple and extends easily to various extensions to regular expressions such as timed regular expressions or regular languages with the intersection.',
	 'authors': u'Keehang Kwon, Hong Pyo Ha, Jiseung Kim,',
	 'category': u'Computer Science ',
	 'date': '2010-2-10',
	 'pdflink': u'http://arxiv.org/pdf/1002.2203',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nA proof Procedure for Testing Membership in Regular Expressions',
	 'urllink': u'http://arxiv.org/abs/1002.2203'}
2015-03-24 01:15:39+0000 [xxu46_1] INFO: Crawled 144 pages (at 1 pages/min), scraped 138 items (at 1 items/min)
2015-03-24 01:16:07+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2202> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:16:07+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2202>
	{'abstract': u'Currently, criminals profile (CP) is obtained from investigators or forensic psychologists interpretation, linking crime scene characteristics and an offenders behavior to his or her characteristics and psychological profile. This paper seeks an efficient and systematic discovery of nonobvious and valuable patterns between variables from a large database of solved cases via a probabilistic network (PN) modeling approach. The PN structure can be used to extract behavioral patterns and to gain insight into what factors influence these behaviors. Thus, when a new case is being investigated and the profile variables are unknown because the offender has yet to be identified, the observed crime scene variables are used to infer the unknown variables based on their connections in the structure and the corresponding numerical (probabilistic) weights. The objective is to produce a more systematic and empirical approach to profiling, and to use the resulting PN model as a decision tool.',
	 'authors': u'Ramesh Kumar Gopala Pillai, Dr. Ramakanth Kumar .P,',
	 'category': u'Computer Science ',
	 'date': '2010-2-10',
	 'pdflink': u'http://arxiv.org/pdf/1002.2202',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nModeling of Human Criminal Behavior using Probabilistic Networks',
	 'urllink': u'http://arxiv.org/abs/1002.2202'}
2015-03-24 01:16:39+0000 [xxu46_1] INFO: Crawled 145 pages (at 1 pages/min), scraped 139 items (at 1 items/min)
2015-03-24 01:17:28+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2199> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:17:28+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2199>
	{'abstract': u'The explosive growth of spatial data and extensive utilization of spatial databases emphasize the necessity for the automated discovery of spatial knowledge. In modern times, spatial data mining has emerged as an area of voluminous research. Forest fires are a chief environmental concern, causing economical and ecological damage while endangering human lives across the world. The fast or early detection of forest fires is a vital element for controlling such phenomenon. The application of remote sensing is at present a significant method for forest fires monitoring, particularly in vast and remote areas. Different methods have been presented by researchers for forest fire detection. The motivation behind this research is to obtain beneficial information from images in the forest spatial data and use the same in the determination of regions at the risk of fires by utilizing Image Processing and Artificial Intelligence techniques. This paper presents an intelligent system to detect the presence of forest fires in the forest spatial data using Artificial Neural Networks. The digital images in the forest spatial data are converted from RGB to XYZ color space and then segmented by employing anisotropic diffusion to identify the fire regions. Subsequently, Radial Basis Function Neural Network is employed in the design of the intelligent system, which is trained with the color space values of the segmented fire regions. Extensive experimental assessments on publicly available spatial data illustrated the efficiency of the proposed system in effectively detecting forest fires.',
	 'authors': u'K. Angayarkkani, N. Radhakrishnan,',
	 'category': u'Computer Science ',
	 'date': '2010-2-10',
	 'pdflink': u'http://arxiv.org/pdf/1002.2199',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nAn Intelligent System For Effective Forest Fire Detection Using Spatial  Data',
	 'urllink': u'http://arxiv.org/abs/1002.2199'}
2015-03-24 01:17:39+0000 [xxu46_1] INFO: Crawled 146 pages (at 1 pages/min), scraped 140 items (at 1 items/min)
2015-03-24 01:18:39+0000 [xxu46_1] INFO: Crawled 146 pages (at 0 pages/min), scraped 140 items (at 0 items/min)
2015-03-24 01:19:03+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2197> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:19:03+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2197>
	{'abstract': u'Software testing is the important phase of software development process. But, this phase can be easily missed by software developers because of their limited time to complete the project. Since, software developers finish their software nearer to the delivery time; they dont get enough time to test their program by creating effective test cases. . One of the major difficulties in software testing is the generation of test cases that satisfy the given adequacy criterion Moreover, creating manual test cases is a tedious work for software developers in the final rush hours. A new approach which generates test cases can help the software developers to create test cases from software specifications in early stage of software development (before coding) and as well as from program execution traces from after software development (after coding). Heuristic techniques can be applied for creating quality test cases. Mutation testing is a technique for testing software units that has great potential for improving the quality of testing, and to assure the high reliability of software. In this paper, a mutation testing based test cases generation technique has been proposed to generate test cases from program execution trace, so that the test cases can be generated after coding. The paper details about the mutation testing implementation to generate test cases. The proposed algorithm has been demonstrated for an example.',
	 'authors': u'Mrs. R. Jeevarathinam, Dr. Antony Selvadoss Thanamani,',
	 'category': u'Computer Science ',
	 'date': '2010-2-10',
	 'pdflink': u'http://arxiv.org/pdf/1002.2197',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nTest Case Generation using Mutation Operators and Fault Classification',
	 'urllink': u'http://arxiv.org/abs/1002.2197'}
2015-03-24 01:19:39+0000 [xxu46_1] INFO: Crawled 147 pages (at 1 pages/min), scraped 141 items (at 1 items/min)
2015-03-24 01:20:39+0000 [xxu46_1] INFO: Crawled 147 pages (at 0 pages/min), scraped 141 items (at 0 items/min)
2015-03-24 01:20:45+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2196> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:20:45+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2196>
	{'abstract': u'With information revolution, increased globalization and competition, supply chain has become longer and more complicated than ever before. These developments bring supply chain management to the forefront of the managements attention. Inventories are very important in a supply chain. The total investment in inventories is enormous, and the management of inventory is crucial to avoid shortages or delivery delays for the customers and serious drain on a companys financial resources. The supply chain cost increases because of the influence of lead times for supplying the stocks as well as the raw materials. Practically, the lead times will not be same through out all the periods. Maintaining abundant stocks in order to avoid the impact of high lead time increases the holding cost. Similarly, maintaining fewer stocks because of ballpark lead time may lead to shortage of stocks. This also happens in the case of lead time involved in supplying raw materials. A better optimization methodology that utilizes the Particle Swarm Optimization algorithm, one of the best optimization algorithms, is proposed to overcome the impasse in maintaining the optimal stock levels in each member of the supply chain. Taking into account the stock levels thus obtained from the proposed methodology, an appropriate stock levels to be maintained in the approaching periods that will minimize the supply chain inventory cost can be arrived at.',
	 'authors': u'S. Narmadha, Dr. V. Selladurai, G. Sathish,',
	 'category': u'Computer Science ',
	 'date': '2010-2-10',
	 'pdflink': u'http://arxiv.org/pdf/1002.2196',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nEfficient Inventory Optimization of Multi Product, Multiple Suppliers  with Lead Time using PSO',
	 'urllink': u'http://arxiv.org/abs/1002.2196'}
2015-03-24 01:21:39+0000 [xxu46_1] INFO: Crawled 148 pages (at 1 pages/min), scraped 142 items (at 1 items/min)
2015-03-24 01:22:04+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2195> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:22:04+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2195>
	{'abstract': u'Inventory management is considered to be an important field in Supply Chain Management because the cost of inventories in a supply chain accounts for about 30 percent of the value of the product. The service provided to the customer eventually gets enhanced once the efficient and effective management of inventory is carried out all through the supply chain. The precise estimation of optimal inventory is essential since shortage of inventory yields to lost sales, while excess of inventory may result in pointless storage costs. Thus the determination of the inventory to be held at various levels in a supply chain becomes inevitable so as to ensure minimal cost for the supply chain. The minimization of the total supply chain cost can only be achieved when optimization of the base stock level is carried out at each member of the supply chain. This paper deals with the problem of determination of base stock levels in a ten member serial supply chain with multiple products produced by factories using Uniform Crossover Genetic Algorithms. The complexity of the problem increases when more distribution centers and agents and multiple products were involved. These considerations leading to very complex inventory management process has been resolved in this work.',
	 'authors': u'S. Narmadha, Dr. V. Selladurai, G. Sathish,',
	 'category': u'Computer Science ',
	 'date': '2010-2-10',
	 'pdflink': u'http://arxiv.org/pdf/1002.2195',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nMulti Product Inventory Optimization using Uniform Crossover Genetic  Algorithm',
	 'urllink': u'http://arxiv.org/abs/1002.2195'}
2015-03-24 01:22:39+0000 [xxu46_1] INFO: Crawled 149 pages (at 1 pages/min), scraped 143 items (at 1 items/min)
2015-03-24 01:23:36+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2194> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:23:36+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2194>
	{'abstract': u'In this paper, we have to concentrate on implementation of Weighted Clustering Algorithm with the help of Genetic Algorithm (GA).Here we have developed new algorithm for the implementation of GA-based approach with the help of Weighted Clustering Algorithm (WCA) (4). ClusterHead chosen is a important thing for clustering in adhoc networks. So, we have shown the optimization technique for the minimization of ClusterHeads(CH) based on some parameter such as degree difference, Battery power (Pv), degree of mobility, and sum of the distances of a node in adhoc networks. ClusterHeads selection of adhoc networks is an important thing for clustering. Here, we have discussed the performance comparison between deterministic approach and GA based approach. In this performance comparison, we have seen that GA does not always give the good result compare to deterministic WCA algorithm. Here we have seen connectivity (connectivity can be measured by the probability that a node is reachable to any other node.) is better than the deterministic WCA algorithm (4).',
	 'authors': u'Bhaskar Nandi, Subhabrata Barman, Soumen Paul,',
	 'category': u'Computer Science ',
	 'date': '2010-2-10',
	 'pdflink': u'http://arxiv.org/pdf/1002.2194',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nGenetic Algorithm Based Optimization of Clustering in Ad Hoc Networks',
	 'urllink': u'http://arxiv.org/abs/1002.2194'}
2015-03-24 01:23:39+0000 [xxu46_1] INFO: Crawled 150 pages (at 1 pages/min), scraped 144 items (at 1 items/min)
2015-03-24 01:24:39+0000 [xxu46_1] INFO: Crawled 150 pages (at 0 pages/min), scraped 144 items (at 0 items/min)
2015-03-24 01:25:18+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2193> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:25:18+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2193>
	{'abstract': u'Although content-based image retrieval (CBIR) is not a new subject, it keeps attracting more and more attention, as the amount of images grow tremendously due to internet, inexpensive hardware and automation of image acquisition. One of the applications of CBIR is fetching images from a database. This paper presents a new method for automatic image retrieval using moment invariants and image entropy, our technique could be used to find semi or perfect matches based on query by example manner, experimental results demonstrate that the purposed technique is scalable and efficient.',
	 'authors': u'Ismail I. Amr, Mohamed Amin, Passent El Kafrawy, Amr M. Sauber,',
	 'category': u'Computer Science ',
	 'date': '2010-2-10',
	 'pdflink': u'http://arxiv.org/pdf/1002.2193',
	 'subjects': u'Multimedia (cs.MM)',
	 'title': u'\nUsing Statistical Moment Invariants and Entropy in Image Retrieval',
	 'urllink': u'http://arxiv.org/abs/1002.2193'}
2015-03-24 01:25:39+0000 [xxu46_1] INFO: Crawled 151 pages (at 1 pages/min), scraped 145 items (at 1 items/min)
2015-03-24 01:26:39+0000 [xxu46_1] INFO: Crawled 151 pages (at 0 pages/min), scraped 145 items (at 0 items/min)
2015-03-24 01:27:02+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2191> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:27:02+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2191>
	{'abstract': u'A Human Computer Interface (HCI) System for playing games is designed here for more natural communication with the machines. The system presented here is a vision-based system for detection of long voluntary eye blinks and interpretation of blink patterns for communication between man and machine. This system replaces the mouse with the human face as a new way to interact with the computer. Facial features (nose tip and eyes) are detected and tracked in realtime to use their actions as mouse events. The coordinates and movement of the nose tip in the live video feed are translated to become the coordinates and movement of the mouse pointer on the application. The left or right eye blinks fire left or right mouse click events. The system works with inexpensive USB cameras and runs at a frame rate of 30 frames per second.',
	 'authors': u'S. Sumathi, S. K. Srivatsa, M. Uma Maheswari,',
	 'category': u'Computer Science ',
	 'date': '2010-2-10',
	 'pdflink': u'http://arxiv.org/pdf/1002.2191',
	 'subjects': u'Human-Computer Interaction (cs.HC)',
	 'title': u'\nVision Based Game Development Using Human Computer Interaction',
	 'urllink': u'http://arxiv.org/abs/1002.2191'}
2015-03-24 01:27:39+0000 [xxu46_1] INFO: Crawled 152 pages (at 1 pages/min), scraped 146 items (at 1 items/min)
2015-03-24 01:28:39+0000 [xxu46_1] INFO: Crawled 152 pages (at 0 pages/min), scraped 146 items (at 0 items/min)
2015-03-24 01:28:40+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2189> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:28:40+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2189>
	{'abstract': u'With the proliferation of mobile computing devices, the demand for continuous network connectivity regardless of physical location has spurred interest in the use of mobile ad hoc networks. Since Transmission Control Protocol (TCP) is the standard network protocol for communication in the internet, any wireless network with Internet service need to be compatible with TCP. TCP is tuned to perform well in traditional wired networks, where packet losses occur mostly because of congestion. However, TCP connections in Ad-hoc mobile networks are plagued by problems such as high bit error rates, frequent route changes, multipath routing and temporary network partitions. The throughput of TCP over such connection is not satisfactory, because TCP misinterprets the packet loss or delay as congestion and invokes congestion control and avoidance algorithm. In this research, the performance of TCP in Adhoc mobile network with high Bit Error rate (BER) and mobility is studied and investigated. Simulation model is implemented and experiments are performed using the Network Simulatior 2 (NS2).',
	 'authors': u'Foez Ahmed, Sateesh Kumar Pradhan, Nayeema Islam, Sumon Kumar Debnath,',
	 'category': u'Computer Science ',
	 'date': '2010-2-10',
	 'pdflink': u'http://arxiv.org/pdf/1002.2189',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nPerformance Evaluation of TCP over Mobile Ad hoc Networks',
	 'urllink': u'http://arxiv.org/abs/1002.2189'}
2015-03-24 01:29:39+0000 [xxu46_1] INFO: Crawled 153 pages (at 1 pages/min), scraped 147 items (at 1 items/min)
2015-03-24 01:30:23+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2187> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:30:23+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2187>
	{'abstract': u'Channel properties influence the development of wireless communication systems. Unlike wired channels that are stationary and predictable, radio channels are extremely random and dont offer easy analysis. A Radio Propagation Model (RPM), also known as the Radio Wave Propagation Model (RWPM), is an empirical mathematical formulation for the characterization of radio wave propagation as a function of frequency. In mobile radio systems, path loss models are necessary for proper planning, interference estimations, frequency assignments and cell parameters which are the basic for network planning process as well as Location Based Services (LBS) techniques. Propagation models that predict the mean signal strength for an arbitrary transmitter receiver (T R) separation distance which is useful in estimating the radio coverage area of a transmitter are called large scale propagation models, since they characterize signal strength over large TR separation distances. In this paper, the large scale propagation performance of Okumura, Hata, and Lee models has been compared varying Mobile Station (MS) antenna height, Transmitter Receiver (TR) distance and Base Station (BS) antenna height, considering the system to operate at 900 MHz. Through the MATLAB simulation it is turned out that the Okumura model shows the better performance than that of the other large scale propagation models.',
	 'authors': u'M. A. Alim, M. M. Rahman, M. M. Hossain, A. Al Nahid,',
	 'category': u'Computer Science ',
	 'date': '2010-2-10',
	 'pdflink': u'http://arxiv.org/pdf/1002.2187',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nAnalysis of Large Scale Propagation Models for Mobile Communications in  Urban Area',
	 'urllink': u'http://arxiv.org/abs/1002.2187'}
2015-03-24 01:30:39+0000 [xxu46_1] INFO: Crawled 154 pages (at 1 pages/min), scraped 148 items (at 1 items/min)
2015-03-24 01:31:39+0000 [xxu46_1] INFO: Crawled 154 pages (at 0 pages/min), scraped 148 items (at 0 items/min)
2015-03-24 01:31:44+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2186> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:31:44+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2186>
	{'abstract': u'The capability to provide network service even under a significant network system element disruption is the backbone for the survival of route optimize of mobile network Technology in today s world. Keeping this view in mind, the present paper highlights a new method based on memetic algorithm.',
	 'authors': u'K. K. Guatam, Anurag Rai,',
	 'category': u'Computer Science ',
	 'date': '2010-2-10',
	 'pdflink': u'http://arxiv.org/pdf/1002.2186',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nA Survivability Strategy in Route Optimization Mobile Network by Memetic  Algorithm',
	 'urllink': u'http://arxiv.org/abs/1002.2186'}
2015-03-24 01:32:39+0000 [xxu46_1] INFO: Crawled 155 pages (at 1 pages/min), scraped 149 items (at 1 items/min)
2015-03-24 01:33:28+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2184> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:33:28+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2184>
	{'abstract': u'A method for the design of Fast Haar wavelet for signal processing and image processing has been proposed. In the proposed work, the analysis bank and synthesis bank of Haar wavelet is modified by using polyphase structure. Finally, the Fast Haar wavelet was designed and it satisfies alias free and perfect reconstruction condition. Computational time and computational complexity is reduced in Fast Haar wavelet transform.',
	 'authors': u'V. Ashok, T. Balakumaran, C. Gowrishankar, I.L.A. Vennila, A. Nirmal kumar,',
	 'category': u'Computer Science ',
	 'date': '2010-2-10',
	 'pdflink': u'http://arxiv.org/pdf/1002.2184',
	 'subjects': u'Multimedia (cs.MM)',
	 'title': u'\nThe Fast Haar Wavelet Transform for Signal & Image Processing',
	 'urllink': u'http://arxiv.org/abs/1002.2184'}
2015-03-24 01:33:39+0000 [xxu46_1] INFO: Crawled 156 pages (at 1 pages/min), scraped 150 items (at 1 items/min)
2015-03-24 01:34:39+0000 [xxu46_1] INFO: Crawled 156 pages (at 0 pages/min), scraped 150 items (at 0 items/min)
2015-03-24 01:35:06+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2182> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:35:06+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2182>
	{'abstract': u'Microcalcifications in mammogram have been mainly targeted as a reliable earliest sign of breast cancer and their early detection is vital to improve its prognosis. Since their size is very small and may be easily overlooked by the examining radiologist, computer-based detection output can assist the radiologist to improve the diagnostic accuracy. In this paper, we have proposed an algorithm for detecting microcalcification in mammogram. The proposed microcalcification detection algorithm involves mammogram quality enhancement using multirresolution analysis based on the dyadic wavelet transform and microcalcification detection by fuzzy shell clustering. It may be possible to detect nodular components such as microcalcification accurately by introducing shape information. The effectiveness of the proposed algorithm for microcalcification detection is confirmed by experimental results.',
	 'authors': u'T. Balakumaran, I.L.A. Vennila, C. Gowri Shankar,',
	 'category': u'Computer Science ',
	 'date': '2010-2-10',
	 'pdflink': u'http://arxiv.org/pdf/1002.2182',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nDetection of Microcalcification in Mammograms Using Wavelet Transform  and Fuzzy Shell Clustering',
	 'urllink': u'http://arxiv.org/abs/1002.2182'}
2015-03-24 01:35:39+0000 [xxu46_1] INFO: Crawled 157 pages (at 1 pages/min), scraped 151 items (at 1 items/min)
2015-03-24 01:36:39+0000 [xxu46_1] INFO: Crawled 157 pages (at 0 pages/min), scraped 151 items (at 0 items/min)
2015-03-24 01:36:46+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2166> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:36:46+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2166>
	{'abstract': u'A partial monoid is a set with a partial multiplication (and total identity ) which satisfies some associativity axiom. The partial monoid may be embedded in a free monoid and the product is simulated by a string rewriting system on that consists in evaluating the concatenation of two letters as a product in , when it is defined, and a letter as the empty word . In this paper we study the profound relations between confluence for such a system and associativity of the multiplication. Moreover we develop a reduction strategy to ensure confluence and which allows us to define a multiplication on normal forms associative up to a given congruence of . Finally we show that this operation is associative if, and only if, the rewriting system under consideration is confluent.',
	 'authors': u'Laurent Poinsot, G\xe9rard Duchamp, Christophe Tollu,',
	 'category': u'Computer Science ',
	 'date': '2010-2-10',
	 'pdflink': u'http://arxiv.org/pdf/1002.2166',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nPartial monoids: associativity and confluence',
	 'urllink': u'http://arxiv.org/abs/1002.2166'}
2015-03-24 01:37:39+0000 [xxu46_1] INFO: Crawled 158 pages (at 1 pages/min), scraped 152 items (at 1 items/min)
2015-03-24 01:38:23+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2164> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:38:23+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2164>
	{'abstract': u'Log-likelihood ratio (LLR) computation for non-binary modulations over fading channels is complicated. A measure of LLR accuracy on asymmetric binary channels is introduced to facilitate good LLR approximations for non-binary modulations. Considering piecewise linear LLR approximations, we prove convexity of optimizing the coefficients according to this measure. For the optimized approximate LLRs, we report negligible performance losses compared to true LLRs.',
	 'authors': u'Raman Yazdani, Masoud Ardakani,',
	 'category': u'Computer Science ',
	 'date': '2010-2-10',
	 'pdflink': u'http://arxiv.org/pdf/1002.2164',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nEfficient LLR Calculation for Non-Binary Modulations over Fading  Channels',
	 'urllink': u'http://arxiv.org/abs/1002.2164'}
2015-03-24 01:38:39+0000 [xxu46_1] INFO: Crawled 159 pages (at 1 pages/min), scraped 153 items (at 1 items/min)
2015-03-24 01:39:35+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2147> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:39:35+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2147>
	{'abstract': u'A natural way to deal with multiple, partially conflicting objectives is turning all the objectives but one into budget constraints. Some classical polynomial-time optimization problems, such as spanning tree and forest, shortest path, (perfect) matching, independent set (basis) in a matroid or in the intersection of two matroids, become NP-hard even with one budget constraint. Still, for most of these problems deterministic and randomized polynomial-time approximation schemes are known. In the case of two or more budgets, typically only multi-criteria approximation schemes are available, which return slightly infeasible solutions. Not much is known however for the case of strict budget constraints: filling this gap is the main goal of this paper. We show that shortest path, perfect matching, and spanning tree (and hence matroid basis and matroid intersection basis) are inapproximable already with two budget constraints. For the remaining problems, whose set of solutions forms an independence system, we present deterministic and randomized polynomial-time approximation schemes for a constant number k of budget constraints. Our results are based on a variety of techniques: 1. We present a simple and powerful mechanism to transform multi-criteria approximation schemes into pure approximation schemes. 2. We show that points in low dimensional faces of any matroid polytope are almost integral, an interesting result on its own. This gives a deterministic approximation scheme for k-budgeted matroid independent set. 3. We present a deterministic approximation scheme for 2-budgeted matching. The backbone of this result is a purely topological property of curves in R^2.',
	 'authors': u'Fabrizio Grandoni, Rico Zenklusen,',
	 'category': u'Computer Science ',
	 'date': '2010-2-10',
	 'pdflink': u'http://arxiv.org/pdf/1002.2147',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nOptimization with More than One Budget',
	 'urllink': u'http://arxiv.org/abs/1002.2147'}
2015-03-24 01:39:39+0000 [xxu46_1] INFO: Crawled 160 pages (at 1 pages/min), scraped 154 items (at 1 items/min)
2015-03-24 01:40:31+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2134> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:40:31+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2134>
	{'abstract': u'We have seen in last few decades that the progress of information technology with leaps and bounds, which have completely changed the way of life in the developed nations. While internet has changed the established working practice and opened new vistas and provided a platform to connect, this gives the opportunity for collaborative work space that goes beyond the global boundary. ICT promises a fundamental change in all aspects of our lives, including knowledge dissemination, social interaction, economic and business practices, political engagement, media, education, health, leisure and entertainment...This paper introduces the application of ICT for rural development. The paper aims at improving the delivery of information to rural masses such as, technology information, marketing information, and information advice. This paper focuses digital divide and poverty eradication, good governance and the significance of internet for rural development. The paper concludes that ICTs offer the developing country, the opportunity to look ahead several stages of rural development by the use of internet. Effective use of ICT can demolish geographical boundaries and can bring rural communities closer to global economic systems and be of meaningful help to the underprivileged.',
	 'authors': u'S.K. Nayak, S. B. Thorat, N.V. Kalyankar,',
	 'category': u'Computer Science ',
	 'date': '2010-2-10',
	 'pdflink': u'http://arxiv.org/pdf/1002.2134',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nReaching the Unreached A Role of ICT in Sustainable Rural Development',
	 'urllink': u'http://arxiv.org/abs/1002.2134'}
2015-03-24 01:40:39+0000 [xxu46_1] INFO: Crawled 161 pages (at 1 pages/min), scraped 155 items (at 1 items/min)
2015-03-24 01:41:39+0000 [xxu46_1] INFO: Crawled 161 pages (at 0 pages/min), scraped 155 items (at 0 items/min)
2015-03-24 01:42:09+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2084> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:42:09+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2084>
	{'abstract': u"An instance of the tollbooth problem consists of an undirected network and a collection of single-minded customers, each of which is interested in purchasing a fixed path subject to an individual budget constraint. The objective is to assign a per-unit price to each edge in a way that maximizes the collective revenue obtained from all customers. The revenue generated by any customer is equal to the overall price of the edges in her desired path, when this cost falls within her budget; otherwise, that customer will not purchase any edge. Our main result is a deterministic algorithm for the tollbooth problem on trees whose approximation ratio is O(log m / log log m), where m denotes the number of edges in the underlying graph. This finding improves on the currently best performance guarantees for trees, due to Elbassioni et al. (SAGT '09), as well as for paths (commonly known as the highway problem), due to Balcan and Blum (EC '06). An additional interesting consequence is a computational separation between tollbooth pricing on trees and the original prototype problem of single-minded unlimited supply pricing, under a plausible hardness hypothesis due to Demaine et al. (SODA '06).",
	 'authors': u'Iftah Gamzu, Danny Segev,',
	 'category': u'Computer Science ',
	 'date': '2010-2-10',
	 'pdflink': u'http://arxiv.org/pdf/1002.2084',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nA Sublogarithmic Approximation for Highway and Tollbooth Pricing',
	 'urllink': u'http://arxiv.org/abs/1002.2084'}
2015-03-24 01:42:39+0000 [xxu46_1] INFO: Crawled 162 pages (at 1 pages/min), scraped 156 items (at 1 items/min)
2015-03-24 01:43:34+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.2178> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 01:43:34+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.2178>
	{'abstract': u'The most expensive source of errors and the more difficult to detect in a formal development is the error during specification. Hence, the first step in a formal development usually consists in exhibiting the set of all behaviors of the specification, for instance with an automaton. Starting from this observation, many researches are about the generation of a B machine from a behavioral specification, such as UML. However, no backward verification are done. This is why, we propose the GeneSyst tool, which aims at generating an automaton describing at least all behaviors of the specification. The refinement step is considered and appears as sub-automatons in the produced SLTS.',
	 'authors': u'Xavier Morselli, Marie-Laure Potet, Nicolas Stouls,',
	 'category': u'Computer Science ',
	 'date': '2010-4-13',
	 'pdflink': u'http://arxiv.org/pdf/1004.2178',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u"\nG\xe9n\xe9Syst : G\xe9n\xe9ration d'un syst\xe8me de transitions  \xe9tiquet\xe9es \xe0 partir d'une sp\xe9cification B \xe9v\xe9nementiel",
	 'urllink': u'http://arxiv.org/abs/1004.2178'}
2015-03-24 01:43:39+0000 [xxu46_1] INFO: Crawled 163 pages (at 1 pages/min), scraped 157 items (at 1 items/min)
2015-03-24 01:44:39+0000 [xxu46_1] INFO: Crawled 163 pages (at 0 pages/min), scraped 157 items (at 0 items/min)
2015-03-24 01:45:12+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2050> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:45:12+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2050>
	{'abstract': u'Estimating intrinsic dimensionality of data is a classic problem in pattern recognition and statistics. Principal Component Analysis (PCA) is a powerful tool in discovering dimensionality of data sets with a linear structure; it, however, becomes ineffective when data have a nonlinear structure. In this paper, we propose a new PCA-based method to estimate intrinsic dimension of data with nonlinear structures. Our method works by first finding a minimal cover of the data set, then performing PCA locally on each subset in the cover and finally giving the estimation result by checking up the data variance on all small neighborhood regions. The proposed method utilizes the whole data set to estimate its intrinsic dimension and is convenient for incremental learning. In addition, our new PCA procedure can filter out noise in data and converge to a stable estimation with the neighborhood region size increasing. Experiments on synthetic and real world data sets show effectiveness of the proposed method.',
	 'authors': u'Mingyu Fan, Nannan Gu, Hong Qiao, Bo Zhang,',
	 'category': u'Computer Science ',
	 'date': '2010-2-10',
	 'pdflink': u'http://arxiv.org/pdf/1002.2050',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nIntrinsic dimension estimation of data by principal component analysis',
	 'urllink': u'http://arxiv.org/abs/1002.2050'}
2015-03-24 01:45:39+0000 [xxu46_1] INFO: Crawled 164 pages (at 1 pages/min), scraped 158 items (at 1 items/min)
2015-03-24 01:46:33+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.2159> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 01:46:33+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.2159>
	{'abstract': u"We study possible formulations of algebraic propositional proof systems operating with noncommutative formulas. We observe that a simple formulation gives rise to systems at least as strong as Frege---yielding a semantic way to define a Cook-Reckhow (i.e., polynomially verifiable) algebraic analog of Frege proofs, different from that given in [BIKPRS96,GH03]. We then turn to an apparently weaker system, namely, polynomial calculus (PC) where polynomials are written as ordered formulas (PC over ordered formulas, for short): an ordered polynomial is a noncommutative polynomial in which the order of products in every monomial respects a fixed linear order on variables; an algebraic formula is ordered if the polynomial computed by each of its subformulas is ordered. We show that PC over ordered formulas is strictly stronger than resolution, polynomial calculus and polynomial calculus with resolution (PCR) and admits polynomial-size refutations for the pigeonhole principle and the Tseitin's formulas. We conclude by proposing an approach for establishing lower bounds on PC over ordered formulas proofs, and related systems, based on properties of lower bounds on noncommutative formulas. The motivation behind this work is developing techniques incorporating rank arguments (similar to those used in algebraic circuit complexity) for establishing lower bounds on propositional proofs.",
	 'authors': u'Iddo Tzameret,',
	 'category': u'Computer Science ',
	 'date': '2010-4-13',
	 'pdflink': u'http://arxiv.org/pdf/1004.2159',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nAlgebraic Proofs over Noncommutative Formulas',
	 'urllink': u'http://arxiv.org/abs/1004.2159'}
2015-03-24 01:46:39+0000 [xxu46_1] INFO: Crawled 165 pages (at 1 pages/min), scraped 159 items (at 1 items/min)
2015-03-24 01:47:39+0000 [xxu46_1] INFO: Crawled 165 pages (at 0 pages/min), scraped 159 items (at 0 items/min)
2015-03-24 01:48:07+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2044> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:48:07+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2044>
	{'abstract': u'Recently Kutin and Niyogi investigated several notions of algorithmic stability--a property of a learning map conceptually similar to continuity--showing that training-stability is sufficient for consistency of Empirical Risk Minimization while distribution-free CV-stability is necessary and sufficient for having finite VC-dimension. This paper concerns a phase transition in the training stability of ERM, conjectured by the same authors. Kutin and Niyogi proved that ERM on finite hypothesis spaces containing a unique risk minimizer has training stability that scales exponentially with sample size, and conjectured that the existence of multiple risk minimizers prevents even super-quadratic convergence. We prove this result for the strictly weaker notion of CV-stability, positively resolving the conjecture.',
	 'authors': u'Benjamin I. P. Rubinstein, Aleksandr Simma,',
	 'category': u'Computer Science ',
	 'date': '2010-2-10',
	 'pdflink': u'http://arxiv.org/pdf/1002.2044',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nOn the Stability of Empirical Risk Minimization in the Presence of  Multiple Risk Minimizers',
	 'urllink': u'http://arxiv.org/abs/1002.2044'}
2015-03-24 01:48:39+0000 [xxu46_1] INFO: Crawled 166 pages (at 1 pages/min), scraped 160 items (at 1 items/min)
2015-03-24 01:49:39+0000 [xxu46_1] INFO: Crawled 166 pages (at 0 pages/min), scraped 160 items (at 0 items/min)
2015-03-24 01:49:43+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.2155> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 01:49:43+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.2155>
	{'abstract': u'Distributed heterogeneous data sources need to be queried uniformly using global schema. Query on global schema is reformulated so that it can be executed on local data sources. Constraints in global schema and mappings are used for source selection, query optimization,and querying partitioned and replicated data sources. The provided system is all XML-based which poses query in XML form, transforms, and integrates local results in an XML document. Contributions include the use of constraints in our existing global schema which help in source selection and query optimization, and a global query distribution framework for querying distributed heterogeneous data sources.',
	 'authors': u'Ahmad Kamran Malik, Muhammad Abdul Qadir, Nadeem Iftikhar, Muhammad Usman,',
	 'category': u'Computer Science ',
	 'date': '2010-4-13',
	 'pdflink': u'http://arxiv.org/pdf/1004.2155',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nConstraint-based Query Distribution Framework for an Integrated Global  Schema',
	 'urllink': u'http://arxiv.org/abs/1004.2155'}
2015-03-24 01:50:39+0000 [xxu46_1] INFO: Crawled 167 pages (at 1 pages/min), scraped 161 items (at 1 items/min)
2015-03-24 01:51:13+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2034> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:51:13+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2034>
	{'abstract': u'The conceptual modelling built from text is rarely an ontology. As a matter of fact, such a conceptualization is corpus-dependent and does not offer the main properties we expect from ontology. Furthermore, ontology extracted from text in general does not match ontology defined by expert using a formal language. It is not surprising since ontology is an extra-linguistic conceptualization whereas knowledge extracted from text is the concern of textual linguistics. Incompleteness of text and using rhetorical figures, like ellipsis, modify the perception of the conceptualization we may have. Ontological knowledge, which is necessary for text understanding, is not in general embedded into documents.',
	 'authors': u'Christophe Roche,',
	 'category': u'Computer Science ',
	 'date': '2010-2-10',
	 'pdflink': u'http://arxiv.org/pdf/1002.2034',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u"\nDire n'est pas concevoir",
	 'urllink': u'http://arxiv.org/abs/1002.2034'}
2015-03-24 01:51:39+0000 [xxu46_1] INFO: Crawled 168 pages (at 1 pages/min), scraped 162 items (at 1 items/min)
2015-03-24 01:52:03+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.2132> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 01:52:03+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.2132>
	{'abstract': u'Steganography is an emerging area which is used for secured data transmission over any public media.Steganography is a process that involves hiding a message in an appropriate carrier like image or audio. It is of Greek origin and means "covered or hidden writing". The carrier can be sent to a receiver without any one except the authenticated receiver knowing the existence of this information. In this paper, a specific image based steganography technique for communicating information more securely between two locations is proposed. The author incorporated the idea of secret key and password security features for authentication at both ends in order to achieve high level of security. As a further improvement of security level, the information has been permuted, encoded and then finally embedded on an image to form the stego image. In addition segmented objects extraction and reassembly of the stego image through normalized cut method has been carried out at the sender side and receiver side respectively in order to prevent distortion of the Stego image during transmission.',
	 'authors': u'Mamta Juneja, Parvinder singh Sandhu,',
	 'category': u'Computer Science ',
	 'date': '2010-4-13',
	 'pdflink': u'http://arxiv.org/pdf/1004.2132',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nImproved information security using robust Steganography system',
	 'urllink': u'http://arxiv.org/abs/1004.2132'}
2015-03-24 01:52:39+0000 [xxu46_1] INFO: Crawled 169 pages (at 1 pages/min), scraped 163 items (at 1 items/min)
2015-03-24 01:53:39+0000 [xxu46_1] INFO: Crawled 169 pages (at 0 pages/min), scraped 163 items (at 0 items/min)
2015-03-24 01:53:51+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.2012> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:53:51+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.2012>
	{'abstract': u"Since their conception in 1975, Genetic Algorithms have been an extremely popular approach to find exact or approximate solutions to optimization and search problems. Over the last years there has been an enhanced interest in the field with related techniques, such as grammatical evolution, being developed. Unfortunately, work on developing genetic optimizations for low-end embedded architectures hasn't embraced the same enthusiasm. This short paper tackles that situation by demonstrating how genetic algorithms can be implemented in Arduino Duemilanove, a 16 MHz open-source micro-controller, with limited computation power and storage resources. As part of this short paper, the libraries used in this implementation are released into the public domain under a GPL license.",
	 'authors': u'Nuno Alves,',
	 'category': u'Computer Science ',
	 'date': '2010-2-10',
	 'pdflink': u'http://arxiv.org/pdf/1002.2012',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nImplementing Genetic Algorithms on Arduino Micro-Controllers',
	 'urllink': u'http://arxiv.org/abs/1002.2012'}
2015-03-24 01:54:39+0000 [xxu46_1] INFO: Crawled 170 pages (at 1 pages/min), scraped 164 items (at 1 items/min)
2015-03-24 01:55:34+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.2131> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 01:55:34+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.2131>
	{'abstract': u"Recently, Guo and Xia gave sufficient conditions for an STBC to achieve full diversity when a PIC (Partial Interference Cancellation) or a PIC-SIC (PIC with Successive Interference Cancellation) decoder is used at the receiver. In this paper, we give alternative conditions for an STBC to achieve full diversity with PIC and PIC-SIC decoders, which are equivalent to Guo and Xia's conditions, but are much easier to check. Using these conditions, we construct a new class of full diversity PIC-SIC decodable codes, which contain the Toeplitz codes and a family of codes recently proposed by Zhang, Xu et. al. as proper subclasses. With the help of the new criteria, we also show that a class of PIC-SIC decodable codes recently proposed by Zhang, Shi et. al. can be decoded with much lower complexity than what is reported, without compromising on full diversity.",
	 'authors': u'Lakshmi Prasad Natarajan, B. Sundar Rajan,',
	 'category': u'Computer Science ',
	 'date': '2010-4-13',
	 'pdflink': u'http://arxiv.org/pdf/1004.2131',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nA New Full-diversity Criterion and Low-complexity STBCs with Partial  Interference Cancellation Decoding',
	 'urllink': u'http://arxiv.org/abs/1004.2131'}
2015-03-24 01:55:39+0000 [xxu46_1] INFO: Crawled 171 pages (at 1 pages/min), scraped 165 items (at 1 items/min)
2015-03-24 01:56:39+0000 [xxu46_1] INFO: Crawled 171 pages (at 0 pages/min), scraped 165 items (at 0 items/min)
2015-03-24 01:57:21+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1985> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 01:57:21+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1985>
	{'abstract': u"A multiple-perspective co-citation analysis method is introduced for characterizing and interpreting the structure and dynamics of co-citation clusters. The method facilitates analytic and sense making tasks by integrating network visualization, spectral clustering, automatic cluster labeling, and text summarization. Co-citation networks are decomposed into co-citation clusters. The interpretation of these clusters is augmented by automatic cluster labeling and summarization. The method focuses on the interrelations between a co-citation cluster's members and their citers. The generic method is applied to a three-part analysis of the field of Information Science as defined by 12 journals published between 1996 and 2008: 1) a comparative author co-citation analysis (ACA), 2) a progressive ACA of a time series of co-citation networks, and 3) a progressive document co-citation analysis (DCA). Results show that the multiple-perspective method increases the interpretability and accountability of both ACA and DCA networks.",
	 'authors': u'Chaomei Chen, Fidelia Ibekwe-SanJuan, Jianhua Hou,',
	 'category': u'Computer Science ',
	 'date': '2010-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1002.1985',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nThe Structure and Dynamics of Co-Citation Clusters: A  Multiple-Perspective Co-Citation Analysis',
	 'urllink': u'http://arxiv.org/abs/1002.1985'}
2015-03-24 01:57:39+0000 [xxu46_1] INFO: Crawled 172 pages (at 1 pages/min), scraped 166 items (at 1 items/min)
2015-03-24 01:58:39+0000 [xxu46_1] INFO: Crawled 172 pages (at 0 pages/min), scraped 166 items (at 0 items/min)
2015-03-24 01:59:07+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.2104> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 01:59:07+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.2104>
	{'abstract': u"This paper studies a family of genie-MAC (multiple access channel) outer bounds for K-user Gaussian interference channels. This family is inspired by existing genie-aided bounding mechanisms, but differs from current approaches in its optimization problem formulation and application. The fundamental idea behind these bounds is to create a group of genie receivers that form multiple access channels that can decode a subset of the original interference channel's messages. The MAC sum capacity of each of the genie receivers provides an outer bound on the sum of rates for this subset. The genie-MAC outer bounds are used to derive new sum-capacity results. In particular, this paper derives sum-capacity in closed-form for the class of K-user Gaussian degraded interference channels. The sum-capacity achieving scheme is shown to be a successive interference cancellation scheme. This result generalizes a known result for two-user channels to K-user channels.",
	 'authors': u'Jubin Jose, Sriram Vishwanath,',
	 'category': u'Computer Science ',
	 'date': '2010-4-13',
	 'pdflink': u'http://arxiv.org/pdf/1004.2104',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nSum Capacity of K User Gaussian Degraded Interference Channels',
	 'urllink': u'http://arxiv.org/abs/1004.2104'}
2015-03-24 01:59:39+0000 [xxu46_1] INFO: Crawled 173 pages (at 1 pages/min), scraped 167 items (at 1 items/min)
2015-03-24 02:00:16+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1955> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 02:00:16+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1955>
	{'abstract': u'Over the recent years a considerable amount of effort has been devoted towards the performance evaluation and prediction of Mobile Networks. Performance modeling and evaluation of mobile networks are very important in view of their ever expending usage and the multiplicity of their component parts together with the complexity of their functioning. The present paper addresses current issues in traffic management and congestion control by (signal to interference plus noise ratio) SINR prediction congestion control, routing and optimization of cellular mobile networks.',
	 'authors': u'K. K. Guatam, Anurag Rai,',
	 'category': u'Computer Science ',
	 'date': '2010-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1002.1955',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nPerformance Modeling and Evaluation of Traffic management for Mobile  Networks by SINR Prediction',
	 'urllink': u'http://arxiv.org/abs/1002.1955'}
2015-03-24 02:00:39+0000 [xxu46_1] INFO: Crawled 174 pages (at 1 pages/min), scraped 168 items (at 1 items/min)
2015-03-24 02:01:18+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.2091> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 02:01:18+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.2091>
	{'abstract': u'The best known algorithm to compute the Jacobi symbol of two n-bit integers runs in time O(M(n) log n), using Sch "onhage\'s fast continued fraction algorithm combined with an identity due to Gauss. We give a different O(M(n) log n) algorithm based on the binary recursive gcd algorithm of Stehl \'e and Zimmermann. Our implementation - which to our knowledge is the first to run in time O(M(n) log n) - is faster than GMP\'s quadratic implementation for inputs larger than about 10000 decimal digits.',
	 'authors': u'Richard P. Brent, Paul Zimmermann,',
	 'category': u'Computer Science ',
	 'date': '2010-4-13',
	 'pdflink': u'http://arxiv.org/pdf/1004.2091',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nAn O(M(n) log n) algorithm for the Jacobi symbol',
	 'urllink': u'http://arxiv.org/abs/1004.2091'}
2015-03-24 02:01:39+0000 [xxu46_1] INFO: Crawled 175 pages (at 1 pages/min), scraped 169 items (at 1 items/min)
2015-03-24 02:02:31+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1954> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 02:02:31+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1954>
	{'abstract': u'WiMAX technology is based on the IEEE 802.16 specification of which IEEE 802.16-2004 and 802.16e amendment are Physical (PHY) layer specifications. IEEE 802.16-2004 currently supports several multiple-antenna options including Space-Time Codes (STC), Multiple-Input Multiple-Output (MIMO) antenna systems and Adaptive Antenna Systems (AAS). The most recent WiMAX standard (802.16e) supports broadband applications to mobile terminals and laptops. Using Adaptive Modulation and Coding (AMC) we analyze the performance of OFDM physical layer in WiMAX based on the simulation results of Bit Error Rate (BER), and data throughput. The performance analysis of OFDM PHY is done. In this paper, an extension to the basic SISO mode, a number of 2 by 2 MIMO extensions are analysed under different combinations of digital modulation (QPSK, 16QAM and 64QAM) and Convolutional Code (CC) with half, two-third and three quarter rated codes. The intent of this paper is to provide an idea of the benefits of multiple antenna systems over single antenna systems in WiMAX type deployments.',
	 'authors': u'Hadj Zerrouki, Mohamed Feham,',
	 'category': u'Computer Science ',
	 'date': '2010-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1002.1954',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nHigh Throughput of WiMAX MIMO OFDM Including Adaptive Modulation and  Coding',
	 'urllink': u'http://arxiv.org/abs/1002.1954'}
2015-03-24 02:02:39+0000 [xxu46_1] INFO: Crawled 176 pages (at 1 pages/min), scraped 170 items (at 1 items/min)
2015-03-24 02:03:27+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.2090> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 02:03:27+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.2090>
	{'abstract': u"Insa and Pauer presented a basic theory of Groebner basis for differential operators with coefficients in a commutative ring in 1998, and a criterion was proposed to determine if a set of differential operators is a Groebner basis. In this paper, we will give a new criterion such that Insa and Pauer's criterion could be concluded as a special case and one could compute the Groebner basis more efficiently by this new criterion.",
	 'authors': u'Xiaodong Ma, Yao Sun, Dingkang Wang,',
	 'category': u'Computer Science ',
	 'date': '2010-4-13',
	 'pdflink': u'http://arxiv.org/pdf/1004.2090',
	 'subjects': u'Symbolic Computation (cs.SC)',
	 'title': u'\nOn Computing Groebner Basis in the Rings of Differential Operators',
	 'urllink': u'http://arxiv.org/abs/1004.2090'}
2015-03-24 02:03:39+0000 [xxu46_1] INFO: Crawled 177 pages (at 1 pages/min), scraped 171 items (at 1 items/min)
2015-03-24 02:04:39+0000 [xxu46_1] INFO: Crawled 177 pages (at 0 pages/min), scraped 171 items (at 0 items/min)
2015-03-24 02:05:04+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1953> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 02:05:04+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1953>
	{'abstract': u'DDR SDRAM is similar in function to the regular SDRAM but doubles the bandwidth of the memory by transferring data on both edges of the clock cycles. DDR SDRAM most commonly used in various embedded application like networking, image or video processing, Laptops ete. Now a days many applications needs more and more cheap and fast memory. Especially in the field of signal processing, requires significant amount of memory. The most used type of dynamic memory for that purpose is DDR SDRAM. For FPGA design the IC manufacturers are providing commercial memory controller IP cores working only on their products. Main disadvantage is the lack of memory access optimization for random memory access patterns. The data path part of those controllers can be used free of charge. This work propose an architecture of a DDR SDRAM controller, which takes advantage of those available and well tested data paths and can be used for any FPGA device or ASIC design.(5). In most of the SOC design, DDR SDRAM is commonly used. ARM processor is widely used in SOCs; so that we focused to implement AHB compatible DDR SDRAM controller suitable for ARM based SOC design.',
	 'authors': u'Dr. R. Shashikumar, C. N. Vijay Kumar, M. Nagendrakumar, C. S. Hemanthkumar,',
	 'category': u'Computer Science ',
	 'date': '2010-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1002.1953',
	 'subjects': u'Hardware Architecture (cs.AR)',
	 'title': u'\nAhb Compatible DDR Sdram Controller Ip Core for Arm Based Soc',
	 'urllink': u'http://arxiv.org/abs/1002.1953'}
2015-03-24 02:05:39+0000 [xxu46_1] INFO: Crawled 178 pages (at 1 pages/min), scraped 172 items (at 1 items/min)
2015-03-24 02:06:34+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.2079> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 02:06:34+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.2079>
	{'abstract': u"We consider a one-sided assignment market or exchange network with transferable utility and propose a model for the dynamics of bargaining in such a market. Our dynamical model is local, involving iterative updates of 'offers' based on estimated best alternative matches, in the spirit of pairwise Nash bargaining. We establish that when a balanced outcome (a generalization of the pairwise Nash bargaining solution to networks) exists, our dynamics converges rapidly to such an outcome. We extend our results to the cases of (i) general agent 'capacity constraints', i.e., an agent may be allowed to participate in multiple matches, and (ii) 'unequal bargaining powers' (where we also find a surprising change in rate of convergence).",
	 'authors': u'Mohsen Bayati, Christian Borgs, Jennifer Chayes, Yashodhan Kanoria, Andrea Montanari,',
	 'category': u'Computer Science ',
	 'date': '2010-4-12',
	 'pdflink': u'http://arxiv.org/pdf/1004.2079',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nBargaining dynamics in exchange networks',
	 'urllink': u'http://arxiv.org/abs/1004.2079'}
2015-03-24 02:06:39+0000 [xxu46_1] INFO: Crawled 179 pages (at 1 pages/min), scraped 173 items (at 1 items/min)
2015-03-24 02:07:39+0000 [xxu46_1] INFO: Crawled 179 pages (at 0 pages/min), scraped 173 items (at 0 items/min)
2015-03-24 02:08:13+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1951> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 02:08:13+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1951>
	{'abstract': u'The purpose of this Paper is to describe our research on different feature extraction and matching techniques in designing a Content Based Image Retrieval (CBIR) system. Due to the enormous increase in image database sizes, as well as its vast deployment in various applications, the need for CBIR development arose. Firstly, this paper outlines a description of the primitive feature extraction techniques like, texture, colour, and shape. Once these features are extracted and used as the basis for a similarity check between images, the various matching techniques are discussed. Furthermore, the results of its performance are illustrated by a detailed example.',
	 'authors': u'Mr. Kondekar V. H., Mr. Kolkure V. S., Prof. Kore S.N,',
	 'category': u'Computer Science ',
	 'date': '2010-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1002.1951',
	 'subjects': u'Multimedia (cs.MM)',
	 'title': u'\nImage Retrieval Techniques based on Image Features, A State of Art  approach for CBIR',
	 'urllink': u'http://arxiv.org/abs/1002.1951'}
2015-03-24 02:08:39+0000 [xxu46_1] INFO: Crawled 180 pages (at 1 pages/min), scraped 174 items (at 1 items/min)
2015-03-24 02:09:10+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.2033> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 02:09:10+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.2033>
	{'abstract': u'We give the first algorithm for testing the feasibility of a system of sporadic real-time tasks on a set of identical processors, solving one major open problem in the area of multiprocessor real-time scheduling [S.K. Baruah and K. Pruhs, Journal of Scheduling, 2009]. We also investigate the related notion of schedulability and a notion that we call online feasibility. Finally, we show that discrete-time schedules are as powerful as continuous-time schedules, which answers another open question in the above mentioned survey.',
	 'authors': u'Vincenzo Bonifaci, Alberto Marchetti-Spaccamela,',
	 'category': u'Computer Science ',
	 'date': '2010-4-12',
	 'pdflink': u'http://arxiv.org/pdf/1004.2033',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nFeasibility Analysis of Sporadic Real-Time Multiprocessor Task Systems',
	 'urllink': u'http://arxiv.org/abs/1004.2033'}
2015-03-24 02:09:39+0000 [xxu46_1] INFO: Crawled 181 pages (at 1 pages/min), scraped 175 items (at 1 items/min)
2015-03-24 02:10:39+0000 [xxu46_1] INFO: Crawled 181 pages (at 0 pages/min), scraped 175 items (at 0 items/min)
2015-03-24 02:10:48+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1950> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 02:10:48+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1950>
	{'abstract': u'As physical and information security boundaries have become increasingly blurry many organizations are experiencing challenges with how to effectively and efficiently manage security within the corporate. There is no current standard or best practice offered by the security community regarding convergence; however many organizations such as the Alliance for Enterprise Security Risk Management (AESRM) offer some excellent suggestions for integrating a converged security program. This paper reports on how organizations have traditionally managed asset protection, why that is changing and how to establish convergence to optimize security value to the business within an enterprise.',
	 'authors': u'Syed, M. Rahman, Shannon E. Donahue,',
	 'category': u'Computer Science ',
	 'date': '2010-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1002.1950',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nConvergence of Corporate and Information Security',
	 'urllink': u'http://arxiv.org/abs/1002.1950'}
2015-03-24 02:11:39+0000 [xxu46_1] INFO: Crawled 182 pages (at 1 pages/min), scraped 176 items (at 1 items/min)
2015-03-24 02:12:31+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.2027> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 02:12:31+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.2027>
	{'abstract': u'In this paper, we propose a novel policy iteration method, called dynamic policy programming (DPP), to estimate the optimal policy in the infinite-horizon Markov decision processes. We prove the finite-iteration and asymptotic l infty-norm performance-loss bounds for DPP in the presence of approximation/estimation error. The bounds are expressed in terms of the l infty-norm of the average accumulated error as opposed to the l infty-norm of the error in the case of the standard approximate value iteration (AVI) and the approximate policy iteration (API). This suggests that DPP can achieve a better performance than AVI and API since it averages out the simulation noise caused by Monte-Carlo sampling throughout the learning process. We examine this theoretical results numerically by com- paring the performance of the approximate variants of DPP with existing reinforcement learning (RL) methods on different problem domains. Our results show that, in all cases, DPP-based algorithms outperform other RL methods by a wide margin.',
	 'authors': u'Mohammad Gheshlaghi Azar, Vicenc Gomez, Hilbert J. Kappen,',
	 'category': u'Computer Science ',
	 'date': '2010-4-12',
	 'pdflink': u'http://arxiv.org/pdf/1004.2027',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nDynamic Policy Programming',
	 'urllink': u'http://arxiv.org/abs/1004.2027'}
2015-03-24 02:12:39+0000 [xxu46_1] INFO: Crawled 183 pages (at 1 pages/min), scraped 177 items (at 1 items/min)
2015-03-24 02:13:39+0000 [xxu46_1] INFO: Crawled 183 pages (at 0 pages/min), scraped 177 items (at 0 items/min)
2015-03-24 02:14:12+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1937> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 02:14:12+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1937>
	{'abstract': u'Persistence homology is a tool used to measure topological features that are present in data sets and functions. Persistence pairs births and deaths of these features as we iterate through the sublevel sets of the data or function of interest. I am concerned with using persistence to characterize the difference between two functions f, g : M -&gt; R, where M is a topological space. Furthermore, I formulate a homotopy from g to f by applying the heat equation to the difference function g-f. By stacking the persistence diagrams associated with this homotopy, we create a vineyard of curves that connect the points in the diagram for f with the points in the diagram for g. I look at the diagrams where M is a square, a sphere, a torus, and a Klein bottle. Looking at these four topologies, we notice trends (and differences) as the persistence diagrams change with respect to time.',
	 'authors': u'Brittany Terese Fasy,',
	 'category': u'Computer Science ',
	 'date': '2010-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1002.1937',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nPersistence Diagrams and the Heat Equation Homotopy',
	 'urllink': u'http://arxiv.org/abs/1002.1937'}
2015-03-24 02:14:39+0000 [xxu46_1] INFO: Crawled 184 pages (at 1 pages/min), scraped 178 items (at 1 items/min)
2015-03-24 02:15:39+0000 [xxu46_1] INFO: Crawled 184 pages (at 0 pages/min), scraped 178 items (at 0 items/min)
2015-03-24 02:15:43+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.2008> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 02:15:43+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.2008>
	{'abstract': u'The Nystrom method is an efficient technique to speed up large-scale learning applications by generating low-rank approximations. Crucial to the performance of this technique is the assumption that a matrix can be well approximated by working exclusively with a subset of its columns. In this work we relate this assumption to the concept of matrix coherence and connect matrix coherence to the performance of the Nystrom method. Making use of related work in the compressed sensing and the matrix completion literature, we derive novel coherence-based bounds for the Nystrom method in the low-rank setting. We then present empirical results that corroborate these theoretical bounds. Finally, we present more general empirical results for the full-rank setting that convincingly demonstrate the ability of matrix coherence to measure the degree to which information can be extracted from a subset of columns.',
	 'authors': u'Ameet Talwalkar, Afshin Rostamizadeh,',
	 'category': u'Computer Science ',
	 'date': '2010-4-12',
	 'pdflink': u'http://arxiv.org/pdf/1004.2008',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nMatrix Coherence and the Nystrom Method',
	 'urllink': u'http://arxiv.org/abs/1004.2008'}
2015-03-24 02:16:33+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1936> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 02:16:33+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1936>
	{'abstract': u'We introduce a new visual analytic approach to the study of scientific discoveries and knowledge diffusion. Our approach enhances contemporary co-citation network analysis by enabling analysts to identify co-citation clusters of cited references intuitively, synthesize thematic contexts in which these clusters are cited, and trace how research focus evolves over time. The new approach integrates and streamlines a few previously isolated techniques such as spectral clustering and feature selection algorithms. The integrative procedure is expected to empower and strengthen analytical and sense making capabilities of scientists, learners, and researchers to understand the dynamics of the evolution of scientific domains in a wide range of scientific fields, science studies, and science policy evaluation and planning. We demonstrate the potential of our approach through a visual analysis of the evolution of astronomical research associated with the Sloan Digital Sky Survey (SDSS) using bibliographic data between 1994 and 2008. In addition, we also demonstrate that the approach can be consistently applied to a set of heterogeneous data sources such as e-prints on arXiv, publications on ADS, and NSF awards related to the same topic of SDSS.',
	 'authors': u'Chaomei Chen, Jian Zhang, Michael S. Vogeley,',
	 'category': u'Computer Science ',
	 'date': '2010-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1002.1936',
	 'subjects': u'General Literature (cs.GL)',
	 'title': u'\nMaking Sense of the Evolution of a Scientific Domain: A Visual Analytic  Study of the Sloan Digital Sky Survey Research',
	 'urllink': u'http://arxiv.org/abs/1002.1936'}
2015-03-24 02:16:39+0000 [xxu46_1] INFO: Crawled 186 pages (at 2 pages/min), scraped 180 items (at 2 items/min)
2015-03-24 02:17:39+0000 [xxu46_1] INFO: Crawled 186 pages (at 0 pages/min), scraped 180 items (at 0 items/min)
2015-03-24 02:17:58+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.2003> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 02:17:58+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.2003>
	{'abstract': u'We have an audacious dream, we would like to develop a simulation and virtual reality system to support the decision making in European football (soccer). In this review, we summarize the efforts that we have made to fulfil this dream until recently. In addition, an introductory version of FerSML (Footballer and Football Simulation Markup Language) is presented in this paper.',
	 'authors': u'Norbert B\xe1tfai,',
	 'category': u'Computer Science ',
	 'date': '2010-4-12',
	 'pdflink': u'http://arxiv.org/pdf/1004.2003',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nThe Socceral Force',
	 'urllink': u'http://arxiv.org/abs/1004.2003'}
2015-03-24 02:18:39+0000 [xxu46_1] INFO: Crawled 187 pages (at 1 pages/min), scraped 181 items (at 1 items/min)
2015-03-24 02:18:53+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1928> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 02:18:53+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1928>
	{'abstract': u'Let S be a finite set of words over an alphabet Sigma. The set S is said to be complete if every word w over the alphabet Sigma is a factor of some element of S*, i.e. w belongs to Fact(S*). Otherwise if S is not complete, we are interested in finding bounds on the minimal length of words in Sigma* which are not elements of Fact(S*) in terms of the maximal length of words in S.',
	 'authors': u'Gabriele Fici, Elena V. Pribavkina, Jacques Sakarovitch,',
	 'category': u'Computer Science ',
	 'date': '2010-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1002.1928',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nOn the Minimal Uncompletable Word Problem',
	 'urllink': u'http://arxiv.org/abs/1002.1928'}
2015-03-24 02:19:39+0000 [xxu46_1] INFO: Crawled 188 pages (at 1 pages/min), scraped 182 items (at 1 items/min)
2015-03-24 02:20:33+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1999> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 02:20:33+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1999>
	{'abstract': u"Despite its obvious relevance, meaning has been outside most theoretical approaches to information in biology. As a consequence, functional responses based on an appropriate interpretation of signals has been replaced by a probabilistic description of correlations between emitted and received symbols. This assumption leads to potential paradoxes, such as the presence of a maximum information associated to a channel that would actually create completely wrong interpretations of the signals. Game-theoretic models of language evolution use this view of Shannon's theory, but other approaches considering embodied communicating agents show that the correct (meaningful) match resulting from agent-agent exchanges is always achieved and natural systems obviously solve the problem correctly. How can Shannon's theory be expanded in such a way that meaning -at least, in its minimal referential form- is properly incorporated? Inspired by the concept of stated by the swiss linguist Ferdinand de Saussure, here we present a complete description of the minimal system necessary to measure the amount of information that is consistently decoded. Several consequences of our developments are investigated, such the uselessness of an amount of information properly transmitted for communication among autonomous agents.",
	 'authors': u'Bernat Corominas Murtra, Jordi Fortuny Andreu, Ricard Sol\xe9,',
	 'category': u'Computer Science ',
	 'date': '2010-4-12',
	 'pdflink': u'http://arxiv.org/pdf/1004.1999',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nTowards a mathematical theory of meaningful communication',
	 'urllink': u'http://arxiv.org/abs/1004.1999'}
2015-03-24 02:20:39+0000 [xxu46_1] INFO: Crawled 189 pages (at 1 pages/min), scraped 183 items (at 1 items/min)
2015-03-24 02:21:39+0000 [xxu46_1] INFO: Crawled 189 pages (at 0 pages/min), scraped 183 items (at 0 items/min)
2015-03-24 02:22:17+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1919> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 02:22:17+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1919>
	{'abstract': u'Rhetorical structure analysis (RSA) explores discourse relations among elementary discourse units (EDUs) in a text. It is very useful in many text processing tasks employing relationships among EDUs such as text understanding, summarization, and question-answering. Thai language with its distinctive linguistic characteristics requires a unique technique. This article proposes an approach for Thai rhetorical structure analysis. First, EDUs are segmented by two hidden Markov models derived from syntactic rules. A rhetorical structure tree is constructed from a clustering technique with its similarity measure derived from Thai semantic rules. Then, a decision tree whose features derived from the semantic rules is used to determine discourse relations.',
	 'authors': u'Somnuk Sinthupoun, Ohm Sornil,',
	 'category': u'Computer Science ',
	 'date': '2010-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1002.1919',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nThai Rhetorical Structure Analysis',
	 'urllink': u'http://arxiv.org/abs/1002.1919'}
2015-03-24 02:22:39+0000 [xxu46_1] INFO: Crawled 190 pages (at 1 pages/min), scraped 184 items (at 1 items/min)
2015-03-24 02:23:30+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1997> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 02:23:30+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1997>
	{'abstract': u'Back-propagation with gradient method is the most popular learning algorithm for feed-forward neural networks. However, it is critical to determine a proper fixed learning rate for the algorithm. In this paper, an optimized recursive algorithm is presented for online learning based on matrix operation and optimization methods analytically, which can avoid the trouble to select a proper learning rate for the gradient method. The proof of weak convergence of the proposed algorithm also is given. Although this approach is proposed for three-layer, feed-forward neural networks, it could be extended to multiple layer feed-forward neural networks. The effectiveness of the proposed algorithms applied to the identification of behavior of a two-input and two-output non-linear dynamic system is demonstrated by simulation experiments.',
	 'authors': u'Daohang Sha, Vladimir B. Bajic,',
	 'category': u'Computer Science ',
	 'date': '2010-4-12',
	 'pdflink': u'http://arxiv.org/pdf/1004.1997',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nAn optimized recursive learning algorithm for three-layer feedforward  neural networks for mimo nonlinear system identifications',
	 'urllink': u'http://arxiv.org/abs/1004.1997'}
2015-03-24 02:23:39+0000 [xxu46_1] INFO: Crawled 191 pages (at 1 pages/min), scraped 185 items (at 1 items/min)
2015-03-24 02:24:38+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1916> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 02:24:38+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1916>
	{'abstract': u'Secure multi-party computation is a central problem in modern cryptography. An important sub-class of this are problems of the following form: Alice and Bob desire to produce sample(s) of a pair of jointly distributed random variables. Each party must learn nothing more about the other party\'s output than what its own output reveals. To aid in this, they have available a set up - correlated random variables whose distribution is different from the desired distribution - as well as unlimited noiseless communication. In this paper we present an upperbound on how efficiently a given set up can be used to produce samples from a desired distribution. The key tool we develop is a generalization of the concept of common information of two dependent random variables [Gacs-Korner, 1973]. Our generalization - a three-dimensional region - remedies some of the limitations of the original definition which captured only a limited form of dependence. It also includes as a special case Wyner\'s common information [Wyner, 1975]. To derive the cryptographic bounds, we rely on a monotonicity property of this region: the region of the "views" of Alice and Bob engaged in any protocol can only monotonically expand and not shrink. Thus, by comparing the regions for the target random variables and the given random variables, we obtain our upperbound.',
	 'authors': u'Vinod Prabhakaran, Manoj Prabhakaran,',
	 'category': u'Computer Science ',
	 'date': '2010-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1002.1916',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nAssisted Common Information with Applications to Secure Two-Party  Computation',
	 'urllink': u'http://arxiv.org/abs/1002.1916'}
2015-03-24 02:24:39+0000 [xxu46_1] INFO: Crawled 192 pages (at 1 pages/min), scraped 186 items (at 1 items/min)
2015-03-24 02:25:39+0000 [xxu46_1] INFO: Crawled 192 pages (at 0 pages/min), scraped 186 items (at 0 items/min)
2015-03-24 02:25:52+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1983> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 02:25:52+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1983>
	{'abstract': u'In case of realization of successful business, gain analysis is essential. In this paper we have cited some new techniques of gain expectation on the basis of neural property of perceptron. Support rule and Sequence mining based artificial intelligence oriented practices have also been done in this context. In the view of above fuzzy and statistical based gain sensing is also pointed out.',
	 'authors': u'P. Chakrabarti,',
	 'category': u'Computer Science ',
	 'date': '2010-4-8',
	 'pdflink': u'http://arxiv.org/pdf/1004.1983',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nPredictive Gain Estimation - A mathematical analysis',
	 'urllink': u'http://arxiv.org/abs/1004.1983'}
2015-03-24 02:26:39+0000 [xxu46_1] INFO: Crawled 193 pages (at 1 pages/min), scraped 187 items (at 1 items/min)
2015-03-24 02:27:14+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1897> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 02:27:14+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1897>
	{'abstract': u'We propose an adaptive transmission technique for free space optical (FSO) systems, operating in atmospheric turbulence and employing subcarrier phase shift keying (S-PSK) intensity modulation. Exploiting the constant envelope characteristics of S-PSK, the proposed technique offers efficient utilization of the FSO channel capacity by adapting the modulation order of S-PSK, according to the instantaneous state of turbulence induced fading and a pre-defined bit error rate (BER) requirement. Novel expressions for the spectral efficiency and average BER of the proposed adaptive FSO system are presented and performance investigations under various turbulence conditions and target BER requirements are carried out. Numerical results indicate that significant spectral efficiency gains are offered without increasing the transmitted average optical power or sacrificing BER requirements, in moderate-to-strong turbulence conditions. Furthermore, the proposed variable rate transmission technique is applied to multiple input multiple output (MIMO) FSO systems, providing additional improvement in the achieved spectral efficiency as the number of the transmit and/or receive apertures increases.',
	 'authors': u'Nestor D. Chatzidiamantis, Athanasios S. Lioumpas, George K. Karagiannidis, Shlomi Arnon,',
	 'category': u'Computer Science ',
	 'date': '2010-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1002.1897',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nAdaptive Subcarrier PSK Intensity Modulation in Free Space Optical  Systems',
	 'urllink': u'http://arxiv.org/abs/1002.1897'}
2015-03-24 02:27:39+0000 [xxu46_1] INFO: Crawled 194 pages (at 1 pages/min), scraped 188 items (at 1 items/min)
2015-03-24 02:28:39+0000 [xxu46_1] INFO: Crawled 194 pages (at 0 pages/min), scraped 188 items (at 0 items/min)
2015-03-24 02:29:00+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1982> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 02:29:00+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1982>
	{'abstract': u'This paper proposes a novel similarity measure for clustering sequential data. We first construct a common state-space by training a single probabilistic model with all the sequences in order to get a unified representation for the dataset. Then, distances are obtained attending to the transition matrices induced by each sequence in that state-space. This approach solves some of the usual overfitting and scalability issues of the existing semi-parametric techniques, that rely on training a model for each sequence. Empirical studies on both synthetic and real-world datasets illustrate the advantages of the proposed similarity measure for clustering sequences.',
	 'authors': u'Dar\xedo Garc\xeda-Garc\xeda, Emilio Parrado-Hern\xe1ndez, Fernando D\xedaz-de-Mar\xeda,',
	 'category': u'Computer Science ',
	 'date': '2010-4-9',
	 'pdflink': u'http://arxiv.org/pdf/1004.1982',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nState-Space Dynamics Distance for Clustering Sequential Data',
	 'urllink': u'http://arxiv.org/abs/1004.1982'}
2015-03-24 02:29:39+0000 [xxu46_1] INFO: Crawled 195 pages (at 1 pages/min), scraped 189 items (at 1 items/min)
2015-03-24 02:30:39+0000 [xxu46_1] INFO: Crawled 195 pages (at 0 pages/min), scraped 189 items (at 0 items/min)
2015-03-24 02:30:40+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1887> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 02:30:40+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1887>
	{'abstract': u'We study hierarchical segmentation in the framework of edge-weighted graphs. We define ultrametric watersheds as topological watersheds null on the minima. We prove that there exists a bijection between the set of ultrametric watersheds and the set of hierarchical segmentations. We end this paper by showing how to use the proposed framework in practice in the example of constrained connectivity; in particular it allows to compute such a hierarchy following a classical watershed-based morphological scheme, which provides an efficient algorithm to compute the whole hierarchy.',
	 'authors': u'Laurent Najman,',
	 'category': u'Computer Science ',
	 'date': '2010-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1002.1887',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nOn the equivalence between hierarchical segmentations and ultrametric  watersheds',
	 'urllink': u'http://arxiv.org/abs/1002.1887'}
2015-03-24 02:31:39+0000 [xxu46_1] INFO: Crawled 196 pages (at 1 pages/min), scraped 190 items (at 1 items/min)
2015-03-24 02:32:22+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1956> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 02:32:22+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1956>
	{'abstract': u'A ternary Permutation-CSP is specified by a subset of the symmetric group . An instance of such a problem consists of a set of variables and a multiset of constraints, which are ordered triples of distinct variables of The objective is to find a linear ordering of that maximizes the number of triples whose ordering (under ) follows a permutation in . We prove that all ternary Permutation-CSPs parameterized above average have kernels with quadratic numbers of variables.',
	 'authors': u'Gregory Gutin, Leo van Iersel, Matthias Mnich, Anders Yeo,',
	 'category': u'Computer Science ',
	 'date': '2010-4-12',
	 'pdflink': u'http://arxiv.org/pdf/1004.1956',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nAll Ternary Permutation Constraint Satisfaction Problems Parameterized  Above Average Have Kernels with Quadratic Numbers of Variables',
	 'urllink': u'http://arxiv.org/abs/1004.1956'}
2015-03-24 02:32:39+0000 [xxu46_1] INFO: Crawled 197 pages (at 1 pages/min), scraped 191 items (at 1 items/min)
2015-03-24 02:33:36+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1881> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 02:33:36+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1881>
	{'abstract': u'The aim of this paper is to present an adaptable Fat Tree NoC architecture for Field Programmable Gate Array (FPGA) designed for image analysis applications. Traditional NoCs (Network on Chip) are not optimal for dataflow applications with large amount of data. On the opposite, point to point communications are designed from the algorithm requirements but they are expensives in terms of resource and wire. We propose a dedicated communication architecture for image analysis algorithms. This communication mechanism is a generic NoC infrastructure dedicated to dataflow image processing applications, mixing circuit-switching and packet-switching communications. The complete architecture integrates two dedicated communication architectures and reusable IP blocks. Communications are based on the NoC concept to support the high bandwidth required for a large number and type of data.',
	 'authors': u'Linlin Zhang, Virginie Fresse, Mohammed Khalid, Dominique Houzet, Anne-Claire Legrand,',
	 'category': u'Computer Science ',
	 'date': '2010-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1002.1881',
	 'subjects': u'Hardware Architecture (cs.AR)',
	 'title': u'\nEvaluation and Design Space Exploration of a Time-Division Multiplexed  NoC on FPGA for Image Analysis Applications',
	 'urllink': u'http://arxiv.org/abs/1002.1881'}
2015-03-24 02:33:39+0000 [xxu46_1] INFO: Crawled 198 pages (at 1 pages/min), scraped 192 items (at 1 items/min)
2015-03-24 02:34:39+0000 [xxu46_1] INFO: Crawled 198 pages (at 0 pages/min), scraped 192 items (at 0 items/min)
2015-03-24 02:35:23+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1955> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 02:35:23+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1955>
	{'abstract': u'We consider the problem of communicating over a multiple-input multiple-output (MIMO) real valued channel for which no mathematical model is specified, and achievable rates are given as a function of the channel input and output sequences known a-posteriori. This paper extends previous results regarding individual channels by presenting a rate function for the MIMO individual channel, and showing its achievability in a fixed transmission rate communication scenario.',
	 'authors': u'Yuval Lomnitz, Meir Feder,',
	 'category': u'Computer Science ',
	 'date': '2010-4-12',
	 'pdflink': u'http://arxiv.org/pdf/1004.1955',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nAn Achievable Rate for the MIMO Individual Channel',
	 'urllink': u'http://arxiv.org/abs/1004.1955'}
2015-03-24 02:35:39+0000 [xxu46_1] INFO: Crawled 199 pages (at 1 pages/min), scraped 193 items (at 1 items/min)
2015-03-24 02:36:39+0000 [xxu46_1] INFO: Crawled 199 pages (at 0 pages/min), scraped 193 items (at 0 items/min)
2015-03-24 02:36:44+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1880> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 02:36:44+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1880>
	{'abstract': u'The problems studied in this article originate from the Graph Motif problem introduced by Lacroix et al. in the context of biological networks. The problem is to decide if a vertex-colored graph has a connected subgraph whose colors equal a given multiset of colors . It is a graph pattern-matching problem variant, where the structure of the occurrence of the pattern is not of interest but the only requirement is the connectedness. Using an algebraic framework recently introduced by Koutis et al., we obtain new FPT algorithms for Graph Motif and variants, with improved running times. We also obtain results on the counting versions of this problem, proving that the counting problem is FPT if M is a set, but becomes W[1]-hard if M is a multiset with two colors. Finally, we present an experimental evaluation of this approach on real datasets, showing that its performance compares favorably with existing software.',
	 'authors': u'Sylvain Guillemot, Florian Sikora,',
	 'category': u'Computer Science ',
	 'date': '2010-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1002.1880',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nFinding and counting vertex-colored subtrees',
	 'urllink': u'http://arxiv.org/abs/1002.1880'}
2015-03-24 02:37:39+0000 [xxu46_1] INFO: Crawled 200 pages (at 1 pages/min), scraped 194 items (at 1 items/min)
2015-03-24 02:38:10+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1947> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 02:38:10+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1947>
	{'abstract': u'We study simple type theory with primitive equality (STT) and its first-order fragment EFO, which restricts equality and quantification to base types but retains lambda abstraction and higher-order variables. As deductive system we employ a cut-free tableau calculus. We consider completeness, compactness, and existence of countable models. We prove these properties for STT with respect to Henkin models and for EFO with respect to standard models. We also show that the tableau system yields a decision procedure for three EFO fragments.',
	 'authors': u'Chad E. Brown, Gert Smolka,',
	 'category': u'Computer Science ',
	 'date': '2010-4-12',
	 'pdflink': u'http://arxiv.org/pdf/1004.1947',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nAnalytic Tableaux for Simple Type Theory and its First-Order Fragment',
	 'urllink': u'http://arxiv.org/abs/1004.1947'}
2015-03-24 02:38:39+0000 [xxu46_1] INFO: Crawled 201 pages (at 1 pages/min), scraped 195 items (at 1 items/min)
2015-03-24 02:39:39+0000 [xxu46_1] INFO: Crawled 201 pages (at 0 pages/min), scraped 195 items (at 0 items/min)
2015-03-24 02:39:45+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1874> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 02:39:45+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1874>
	{'abstract': u'Wireless mobile grids are one of the emerging grid types, which help to pool the resources of several willing and cooperative mobile devices to resolve a computationally intensive task. The mobile grids exhibit stronger challenges like mobility management of devices, providing transparent access to grid resources, task management and handling of limited resources so that resources are shared efficiently. Task execution on these devices should not be affected by their mobility. The proposed work presents performance evaluation of wireless mobile grid using normal walk mobility model. The normal walk model represents daily motion of users and the direction of motion is mostly symmetric in a real life environment, thus it is effective in location updating of a mobile station and in turn helps task distribution among these available mobile stations. Some of the performance parameters such as Task Execution Time, task failure rate, communication overhead on Brokering Server and Monitoring Cost are discussed.',
	 'authors': u'A. S. Nandeppanavar, M. N. Birje, S. S. Manvi, Shridhar,',
	 'category': u'Computer Science ',
	 'date': '2010-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1002.1874',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nMobility Impact on Performance of Mobile Grids',
	 'urllink': u'http://arxiv.org/abs/1002.1874'}
2015-03-24 02:40:39+0000 [xxu46_1] INFO: Crawled 202 pages (at 1 pages/min), scraped 196 items (at 1 items/min)
2015-03-24 02:40:52+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1946> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 02:40:52+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1946>
	{'abstract': u'A regular language L is said to be cellular if there exists a 1-dimensional cellular automaton CA such that L is the language consisting of the finite blocks associated with CA. It is shown that cellularity of a regular language is decidable using a new characterization of cellular languages formulated by Freiling, Goldstein and Moews and implied by a deep result of Boyle in symbolic dynamics.',
	 'authors': u'Udayan B.Darji, Steve W. Seif,',
	 'category': u'Computer Science ',
	 'date': '2010-4-12',
	 'pdflink': u'http://arxiv.org/pdf/1004.1946',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nA note on decidability of cellularity',
	 'urllink': u'http://arxiv.org/abs/1004.1946'}
2015-03-24 02:41:39+0000 [xxu46_1] INFO: Crawled 203 pages (at 1 pages/min), scraped 197 items (at 1 items/min)
2015-03-24 02:42:31+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1843> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 02:42:31+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1843>
	{'abstract': u'This paper defines the Arrwwid number of a recursive tiling (or space-filling curve) as the smallest number w such that any ball Q can be covered by w tiles (or curve sections) with total volume O(vol(Q)). Recursive tilings and space-filling curves with low Arrwwid numbers can be applied to optimise disk, memory or server access patterns when processing sets of points in d-dimensional space. This paper presents recursive tilings and space-filling curves with optimal Arrwwid numbers. For d &gt;= 3, we see that regular cube tilings and space-filling curves cannot have optimal Arrwwid number, and we see how to construct alternatives with better Arrwwid numbers.',
	 'authors': u'Herman Haverkort,',
	 'category': u'Computer Science ',
	 'date': '2010-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1002.1843',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nRecursive tilings and space-filling curves with little fragmentation',
	 'urllink': u'http://arxiv.org/abs/1002.1843'}
2015-03-24 02:42:39+0000 [xxu46_1] INFO: Crawled 204 pages (at 1 pages/min), scraped 198 items (at 1 items/min)
2015-03-24 02:43:39+0000 [xxu46_1] INFO: Crawled 204 pages (at 0 pages/min), scraped 198 items (at 0 items/min)
2015-03-24 02:44:17+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1938> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 02:44:17+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1938>
	{'abstract': u'Motivated by the set-antiset method for codes over permutations under the infinity norm, we study anticodes under this metric. For half of the parameter range we classify all the optimal anticodes, which is equivalent to finding the maximum permanent of certain -matrices. For the rest of the cases we show constraints on the structure of optimal anticodes.',
	 'authors': u'Itzhak Tamo, Moshe Schwartz,',
	 'category': u'Computer Science ',
	 'date': '2010-4-12',
	 'pdflink': u'http://arxiv.org/pdf/1004.1938',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOn Optimal Anticodes over Permutations with the Infinity Norm',
	 'urllink': u'http://arxiv.org/abs/1004.1938'}
2015-03-24 02:44:39+0000 [xxu46_1] INFO: Crawled 205 pages (at 1 pages/min), scraped 199 items (at 1 items/min)
2015-03-24 02:45:39+0000 [xxu46_1] INFO: Crawled 205 pages (at 0 pages/min), scraped 199 items (at 0 items/min)
2015-03-24 02:45:57+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1836> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 02:45:57+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1836>
	{'abstract': u'We propose a method for inferring emph for logic programs as solutions for systems of constraints over sets of finite ground Herbrand terms (set constraint systems). Such parameterized regular types generalize emph regular types by extending the scope of the parameters in the type definitions so that such parameters can relate the types of different predicates. We propose a number of enhancements to the procedure for solving the constraint systems that improve the precision of the type descriptions inferred. The resulting algorithm, together with a procedure to establish a set constraint system from a logic program, yields a program analysis that infers tighter safe approximations of the success types of the program than previous comparable work, offering a new and useful efficiency vs. precision trade-off. This is supported by experimental results, which show the feasibility of our analysis.',
	 'authors': u'F. Bueno, J. Navas, M. Hermenegildo,',
	 'category': u'Computer Science ',
	 'date': '2010-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1002.1836',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nTowards Parameterized Regular Type Inference Using Set Constraints',
	 'urllink': u'http://arxiv.org/abs/1002.1836'}
2015-03-24 02:46:39+0000 [xxu46_1] INFO: Crawled 206 pages (at 1 pages/min), scraped 200 items (at 1 items/min)
2015-03-24 02:47:14+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1917> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 02:47:14+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1917>
	{'abstract': u'In the k-edge-connected spanning subgraph problem we are given a graph (V, E) and costs for each edge, and want to find a minimum-cost subset F of E such that (V, F) is k-edge-connected. We show there is a constant eps &gt; 0 so that for all k &gt; 1, finding a (1 + eps)-approximation for k-ECSS is NP-hard, establishing a gap between the unit-cost and general-cost versions. Next, we consider the multi-subgraph cousin of k-ECSS, in which we purchase a multi-subset F of E, with unlimited parallel copies available at the same cost as the original edge. We conjecture that a (1 + Theta(1/k))-approximation algorithm exists, and we describe an approach based on graph decompositions applied to its natural linear programming (LP) relaxation. The LP is essentially equivalent to the Held-Karp LP for TSP and the undirected LP for Steiner tree. We give a family of extreme points for the LP which are more complex than those previously known.',
	 'authors': u'David Pritchard,',
	 'category': u'Computer Science ',
	 'date': '2010-4-12',
	 'pdflink': u'http://arxiv.org/pdf/1004.1917',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nk-Edge-Connectivity: Approximation and LP Relaxation',
	 'urllink': u'http://arxiv.org/abs/1004.1917'}
2015-03-24 02:47:39+0000 [xxu46_1] INFO: Crawled 207 pages (at 1 pages/min), scraped 201 items (at 1 items/min)
2015-03-24 02:48:23+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1834> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 02:48:23+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1834>
	{'abstract': u"WLAN localization has become an active research field recently. Due to the wide WLAN deployment, WLAN localization provides ubiquitous coverage and adds to the value of the wireless network by providing the location of its users without using any additional hardware. However, WLAN localization systems usually require constructing a radio map, which is a major barrier of WLAN localization systems' deployment. The radio map stores information about the signal strength from different signal strength streams at selected locations in the site of interest. Typical construction of a radio map involves measurements and calibrations making it a tedious and time-consuming operation. In this paper, we present the AROMA system that automatically constructs accurate active and passive radio maps for both device-based and device-free WLAN localization systems. AROMA has three main goals: high accuracy, low computational requirements, and minimum user overhead. To achieve high accuracy, AROMA uses 3D ray tracing enhanced with the uniform theory of diffraction (UTD) to model the electric field behavior and the human shadowing effect. AROMA also automates a number of routine tasks, such as importing building models and automatic sampling of the area of interest, to reduce the user's overhead. Finally, AROMA uses a number of optimization techniques to reduce the computational requirements. We present our system architecture and describe the details of its different components that allow AROMA to achieve its goals. We evaluate AROMA in two different testbeds. Our experiments show that the predicted signal strength differs from the measurements by a maximum average absolute error of 3.18 dBm achieving a maximum localization error of 2.44m for both the device-based and device-free cases.",
	 'authors': u'Ahmed Eleryan, Mohamed Elsabagh, Moustafa Youssef,',
	 'category': u'Computer Science ',
	 'date': '2010-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1002.1834',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nAROMA: Automatic Generation of Radio Maps for Localization Systems',
	 'urllink': u'http://arxiv.org/abs/1002.1834'}
2015-03-24 02:48:39+0000 [xxu46_1] INFO: Crawled 208 pages (at 1 pages/min), scraped 202 items (at 1 items/min)
2015-03-24 02:49:39+0000 [xxu46_1] INFO: Crawled 208 pages (at 0 pages/min), scraped 202 items (at 0 items/min)
2015-03-24 02:49:49+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1887> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 02:49:49+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1887>
	{'abstract': u'This paper presents a robust and dynamic face recognition technique based on the extraction and matching of devised probabilistic graphs drawn on SIFT features related to independent face areas. The face matching strategy is based on matching individual salient facial graph characterized by SIFT features as connected to facial landmarks such as the eyes and the mouth. In order to reduce the face matching errors, the Dempster-Shafer decision theory is applied to fuse the individual matching scores obtained from each pair of salient facial features. The proposed algorithm is evaluated with the ORL and the IITK face databases. The experimental results demonstrate the effectiveness and potential of the proposed face recognition technique also in case of partially occluded faces.',
	 'authors': u'Phalguni Gupta, Dakshina Ranjan Kisku, Jamuna Kanta Sing, Massimo Tistarelli,',
	 'category': u'Computer Science ',
	 'date': '2010-4-12',
	 'pdflink': u'http://arxiv.org/pdf/1004.1887',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nMaximized Posteriori Attributes Selection from Facial Salient Landmarks  for Face Recognition',
	 'urllink': u'http://arxiv.org/abs/1004.1887'}
2015-03-24 02:50:39+0000 [xxu46_1] INFO: Crawled 209 pages (at 1 pages/min), scraped 203 items (at 1 items/min)
2015-03-24 02:51:30+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1833> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 02:51:30+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1833>
	{'abstract': u'Developing suitable formal semantics can be of great help in the understanding, design and implementation of a programming language, and act as a guide for software development tools like analyzers or partial evaluators. In this sense, full abstraction is a highly desirable property, indicating a perfect correspondence between the semantics and the observable behavior of program pieces. In this work we address the question of full abstraction for the family of modern functional logic languages, in which functions can be higher order and non-deterministic, and where the semantics adopted for non-determinism is emph. We show that, with respect to natural notions of emph, any semantics based on emph functions is necessarily unsound; in contrast, we show that the higher order version of emph, a well-known existing semantic framework for functional logic programming, based on an emph view of functions, turns out to be fully abstract and compositional.',
	 'authors': u'F.J. L\xf3pez-Fraguas, J. Rodr\xedguez-Hortal\xe1,',
	 'category': u'Computer Science ',
	 'date': '2010-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1002.1833',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nThe Full Abstraction Problem for Higher Order Functional-Logic Programs',
	 'urllink': u'http://arxiv.org/abs/1002.1833'}
2015-03-24 02:51:39+0000 [xxu46_1] INFO: Crawled 210 pages (at 1 pages/min), scraped 204 items (at 1 items/min)
2015-03-24 02:52:39+0000 [xxu46_1] INFO: Crawled 210 pages (at 0 pages/min), scraped 204 items (at 0 items/min)
2015-03-24 02:53:06+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1886> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 02:53:06+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1886>
	{'abstract': u'This paper presents a feature level fusion approach which uses the improved K-medoids clustering algorithm and isomorphic graph for face and palmprint biometrics. Partitioning around medoids (PAM) algorithm is used to partition the set of n invariant feature points of the face and palmprint images into k clusters. By partitioning the face and palmprint images with scale invariant features SIFT points, a number of clusters is formed on both the images. Then on each cluster, an isomorphic graph is drawn. In the next step, the most probable pair of graphs is searched using iterative relaxation algorithm from all possible isomorphic graphs for a pair of corresponding face and palmprint images. Finally, graphs are fused by pairing the isomorphic graphs into augmented groups in terms of addition of invariant SIFT points and in terms of combining pair of keypoint descriptors by concatenation rule. Experimental results obtained from the extensive evaluation show that the proposed feature level fusion with the improved K-medoids partitioning algorithm increases the performance of the system with utmost level of accuracy.',
	 'authors': u'Dakshina Ranjan Kisku, Phalguni Gupta, Jamuna Kanta Sing,',
	 'category': u'Computer Science ',
	 'date': '2010-4-12',
	 'pdflink': u'http://arxiv.org/pdf/1004.1886',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nFeature Level Fusion of Face and Palmprint Biometrics by Isomorphic  Graph-based Improved K-Medoids Partitioning',
	 'urllink': u'http://arxiv.org/abs/1004.1886'}
2015-03-24 02:53:39+0000 [xxu46_1] INFO: Crawled 211 pages (at 1 pages/min), scraped 205 items (at 1 items/min)
2015-03-24 02:54:33+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1828> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 02:54:33+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1828>
	{'abstract': u'We establish a limit formula for the median of the distance between two leaves in a fully resolved unrooted phylogenetic tree with n leaves. More precisely, we prove that this median is equal, in the limit, to the square root of 4*ln(2)*n.',
	 'authors': u'Arnau Mir, Francesc Rossello,',
	 'category': u'Computer Science ',
	 'date': '2010-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1002.1828',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nThe median of the distance between two leaves in a phylogenetic tree',
	 'urllink': u'http://arxiv.org/abs/1002.1828'}
2015-03-24 02:54:39+0000 [xxu46_1] INFO: Crawled 212 pages (at 1 pages/min), scraped 206 items (at 1 items/min)
2015-03-24 02:55:39+0000 [xxu46_1] INFO: Crawled 212 pages (at 0 pages/min), scraped 206 items (at 0 items/min)
2015-03-24 02:56:05+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1864> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 02:56:05+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1864>
	{'abstract': u'The Low Latency Fault Tolerance (LLFT) system provides fault tolerance for distributed applications, using the leader-follower replication technique. The LLFT system provides application-transparent replication, with strong replica consistency, for applications that involve multiple interacting processes or threads. The LLFT system comprises a Low Latency Messaging Protocol, a Leader-Determined Membership Protocol, and a Virtual Determinizer Framework. The Low Latency Messaging Protocol provides reliable, totally ordered message delivery by employing a direct group-to-group multicast, where the message ordering is determined by the primary replica in the group. The Leader-Determined Membership Protocol provides reconfiguration and recovery when a replica becomes faulty and when a replica joins or leaves a group, where the membership of the group is determined by the primary replica. The Virtual Determinizer Framework captures the ordering information at the primary replica and enforces the same ordering at the backup replicas for major sources of non-determinism, including multi-threading, time-related operations and socket communication. The LLFT system achieves low latency message delivery during normal operation and low latency reconfiguration and recovery when a fault occurs.',
	 'authors': u'Wenbing Zhao, P. M. Melliar-Smith, L. E. Moser,',
	 'category': u'Computer Science ',
	 'date': '2010-4-12',
	 'pdflink': u'http://arxiv.org/pdf/1004.1864',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nThe Low Latency Fault Tolerance System',
	 'urllink': u'http://arxiv.org/abs/1004.1864'}
2015-03-24 02:56:39+0000 [xxu46_1] INFO: Crawled 213 pages (at 1 pages/min), scraped 207 items (at 1 items/min)
2015-03-24 02:57:39+0000 [xxu46_1] INFO: Crawled 213 pages (at 0 pages/min), scraped 207 items (at 0 items/min)
2015-03-24 02:57:49+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1796> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 02:57:49+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1796>
	{'abstract': u'This paper discusses highly general mechanisms for specifying the refinement of a real-time system as a collection of lower level parallel components that preserve the timing and functional requirements of the upper level specification. These mechanisms are discussed in the context of ASTRAL, which is a formal specification language for real-time systems. Refinement is accomplished by mapping all of the elements of an upper level specification into lower level elements that may be split among several parallel components. In addition, actions that can occur in the upper level are mapped to actions of components operating at the lower level. This allows several types of implementation strategies to be specified in a natural way, while the price for generality (in terms of complexity) is paid only when necessary. The refinement mechanisms are first illustrated using a simple digital circuit; then, through a highly complex phone system; finally, design guidelines gleaned from these specifications are presented.',
	 'authors': u'Paul Z. Kolano, Carlo A. Furia, Richard A. Kemmerer, Dino Mandrioli,',
	 'category': u'Computer Science ',
	 'date': '2010-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1002.1796',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nRefinement and Verification of Real-Time Systems',
	 'urllink': u'http://arxiv.org/abs/1002.1796'}
2015-03-24 02:58:39+0000 [xxu46_1] INFO: Crawled 214 pages (at 1 pages/min), scraped 208 items (at 1 items/min)
2015-03-24 02:59:22+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1854> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 02:59:22+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1854>
	{'abstract': u'We consider network contribution games, where each agent in a social network has a budget of effort that he can contribute to different collaborative projects or relationships. Depending on the contribution of the involved agents a relationship will flourish or drown, and to measure the success we use a reward function for each relationship. Every agent is trying to maximize the reward from all relationships that it is involved in. We consider pairwise equilibria of this game, and characterize the existence, computational complexity, and quality of equilibrium based on the types of reward functions involved. For example, when all reward functions are concave, we prove that the price of anarchy is at most 2. For convex functions the same only holds under some special but very natural conditions. A special focus of the paper are minimum effort games, where the reward of a relationship depends only on the minimum effort of any of the participants. Finally, we show tight bounds for approximate equilibria and convergence of dynamics in these games.',
	 'authors': u'Elliot Anshelevich, Martin Hoefer,',
	 'category': u'Computer Science ',
	 'date': '2010-4-11',
	 'pdflink': u'http://arxiv.org/pdf/1004.1854',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nContribution Games in Social Networks',
	 'urllink': u'http://arxiv.org/abs/1004.1854'}
2015-03-24 02:59:39+0000 [xxu46_1] INFO: Crawled 215 pages (at 1 pages/min), scraped 209 items (at 1 items/min)
2015-03-24 03:00:39+0000 [xxu46_1] INFO: Crawled 215 pages (at 0 pages/min), scraped 209 items (at 0 items/min)
2015-03-24 03:00:47+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1782> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 03:00:47+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1782>
	{'abstract': u'A key problem in sensor networks is to decide which sensors to query when, in order to obtain the most useful information (e.g., for performing accurate prediction), subject to constraints (e.g., on power and bandwidth). In many applications the utility function is not known a priori, must be learned from data, and can even change over time. Furthermore for large sensor networks solving a centralized optimization problem to select sensors is not feasible, and thus we seek a fully distributed solution. In this paper, we present Distributed Online Greedy (DOG), an efficient, distributed algorithm for repeatedly selecting sensors online, only receiving feedback about the utility of the selected sensors. We prove very strong theoretical no-regret guarantees that apply whenever the (unknown) utility function satisfies a natural diminishing returns property called submodularity. Our algorithm has extremely low communication requirements, and scales well to large sensor deployments. We extend DOG to allow observation-dependent sensor selection. We empirically demonstrate the effectiveness of our algorithm on several real-world sensing tasks.',
	 'authors': u'Daniel Golovin, Matthew Faulkner, Andreas Krause,',
	 'category': u'Computer Science ',
	 'date': '2010-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1002.1782',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nOnline Distributed Sensor Selection',
	 'urllink': u'http://arxiv.org/abs/1002.1782'}
2015-03-24 03:01:39+0000 [xxu46_1] INFO: Crawled 216 pages (at 1 pages/min), scraped 210 items (at 1 items/min)
2015-03-24 03:02:17+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1845> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 03:02:17+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1845>
	{'abstract': u'We see how nested sequents, a natural generalisation of hypersequents, allow us to develop a systematic proof theory for modal logics. As opposed to other prominent formalisms, such as the display calculus and labelled sequents, nested sequents stay inside the modal language and allow for proof systems which enjoy the subformula property in the literal sense. In the first part we study a systematic set of nested sequent systems for all normal modal logics formed by some combination of the axioms for seriality, reflexivity, symmetry, transitivity and euclideanness. We establish soundness and completeness and some of their good properties, such as invertibility of all rules, admissibility of the structural rules, termination of proof-search, as well as syntactic cut-elimination. In the second part we study the logic of common knowledge, a modal logic with a fixpoint modality. We look at two infinitary proof systems for this logic: an existing one based on ordinary sequents, for which no syntactic cut-elimination procedure is known, and a new one based on nested sequents. We see how nested sequents, in contrast to ordinary sequents, allow for syntactic cut-elimination and thus allow us to obtain an ordinal upper bound on the length of proofs.',
	 'authors': u'Kai Br\xfcnnler,',
	 'category': u'Computer Science ',
	 'date': '2010-4-11',
	 'pdflink': u'http://arxiv.org/pdf/1004.1845',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nNested Sequents',
	 'urllink': u'http://arxiv.org/abs/1004.1845'}
2015-03-24 03:02:39+0000 [xxu46_1] INFO: Crawled 217 pages (at 1 pages/min), scraped 211 items (at 1 items/min)
2015-03-24 03:03:39+0000 [xxu46_1] INFO: Crawled 217 pages (at 0 pages/min), scraped 211 items (at 0 items/min)
2015-03-24 03:03:56+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1781> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 03:03:56+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1781>
	{'abstract': u"The capacity region of the N-sender Gaussian multiple access channel with feedback is not known in general. This paper studies the class of linear-feedback codes that includes (nonlinear) nonfeedback codes at one extreme and the linear-feedback codes by Schalkwijk and Kailath, Ozarow, and Kramer at the other extreme. The linear-feedback sum-capacity C_L(N,P) under symmetric power constraints P is characterized, the maximum sum-rate achieved by linear-feedback codes when each sender has the equal block power constraint P. In particular, it is shown that Kramer's code achieves this linear-feedback sum-capacity. The proof involves the dependence balance condition introduced by Hekstra and Willems and extended by Kramer and Gastpar, and the analysis of the resulting nonconvex optimization problem via a Lagrange dual formulation. Finally, an observation is presented based on the properties of the conditional maximal correlation---an extension of the Hirschfeld--Gebelein--Renyi maximal correlation---which reinforces the conjecture that Kramer's code achieves not only the linear-feedback sum-capacity, but also the sum-capacity itself (the maximum sum-rate achieved by arbitrary feedback codes).",
	 'authors': u'Ehsan Ardestanizadeh, Michele A. Wigger, Young-Han Kim, Tara Javidi,',
	 'category': u'Computer Science ',
	 'date': '2010-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1002.1781',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nLinear Sum Capacity for Gaussian Multiple Access Channels with Feedback',
	 'urllink': u'http://arxiv.org/abs/1002.1781'}
2015-03-24 03:04:39+0000 [xxu46_1] INFO: Crawled 218 pages (at 1 pages/min), scraped 212 items (at 1 items/min)
2015-03-24 03:05:36+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1842> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 03:05:36+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1842>
	{'abstract': u'Transceiver impairments, including phase noise, residual frequency offset, and imperfect channel estimation, significantly affect the performance of Multiple-Input Multiple-Output (MIMO) system. However, these impairments are not well addressed when analyzing the throughput performance of MIMO Ad Hoc networks. In this paper, we present an analytical framework to evaluate the throughput of MIMO OFDM system under the impairments of phase noise, residual frequency offset, and imperfect channel estimation. Using this framework, we evaluate the Maximum Sum Throughput (MST) in Ad Hoc networks by optimizing the power and modulation schemes of each user. Simulations are conducted to demonstrate not only the improvement in the MST from using multiple antennas, but also the loss in the MST due to the transceiver impairments. The proposed analytical framework is further applied for the distributed implementation of MST in Ad Hoc networks, where the loss caused by impairments is also evaluated.',
	 'authors': u'Pengkai Zhao, Babak Daneshrad,',
	 'category': u'Computer Science ',
	 'date': '2010-4-11',
	 'pdflink': u'http://arxiv.org/pdf/1004.1842',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nThroughput Enhancement Using Multiple Antennas in OFDM-based Ad Hoc  Networks under Transceiver Impairments',
	 'urllink': u'http://arxiv.org/abs/1004.1842'}
2015-03-24 03:05:39+0000 [xxu46_1] INFO: Crawled 219 pages (at 1 pages/min), scraped 213 items (at 1 items/min)
2015-03-24 03:06:39+0000 [xxu46_1] INFO: Crawled 219 pages (at 0 pages/min), scraped 213 items (at 0 items/min)
2015-03-24 03:06:47+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1774> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 03:06:47+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1774>
	{'abstract': u'The paper presents the position analysis of a spatial structure composed of two platforms mutually connected by one RRP and three SS serial kinematic chains, where R, P, and S stand for revolute, prismatic, and spherical kinematic pair respectively. A set of three compatibility equations is laid down that, following algebraic elimination, results in a 28th-order univariate algebraic equation, which in turn provides the addressed problem with 28 solutions in the complex domain. Among the applications of the results presented in this paper is the solution to the forward kinematics of the Tricept, a well-known in-parallel-actuated spatial manipulator. Numerical examples show adoption of the proposed method in dealing with two case studies.',
	 'authors': u'Carlo Innocenti, Philippe Wenger,',
	 'category': u'Computer Science ',
	 'date': '2010-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1002.1774',
	 'subjects': u'Robotics (cs.RO)',
	 'title': u'\nPosition Analysis of the RRP-3(SS) Multi-Loop Spatial Structure',
	 'urllink': u'http://arxiv.org/abs/1002.1774'}
2015-03-24 03:07:39+0000 [xxu46_1] INFO: Crawled 220 pages (at 1 pages/min), scraped 214 items (at 1 items/min)
2015-03-24 03:08:28+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1836> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 03:08:28+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1836>
	{'abstract': u'We investigate the complexity of approximately counting stable matchings in the -attribute model, where the preference lists are determined by dot products of "preference vectors" with "attribute vectors", or by Euclidean distances between "preference points" and "attribute points". Irving and Leather proved that counting the number of stable matchings in the general case is -complete. Counting the number of stable matchings is reducible to counting the number of downsets in a (related) partial order and is interreducible, in an approximation-preserving sense, to a class of problems that includes counting the number of independent sets in a bipartite graph (). It is conjectured that no FPRAS exists for this class of problems. We show this approximation-preserving interreducibilty remains even in the restricted -attribute setting when (dot products) or (Euclidean distances). Finally, we show it is easy to count the number of stable matchings in the 1-attribute dot-product setting.',
	 'authors': u'Prasad Chebolu, Leslie Ann Goldberg, Russell Martin,',
	 'category': u'Computer Science ',
	 'date': '2010-4-11',
	 'pdflink': u'http://arxiv.org/pdf/1004.1836',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nThe Complexity of Approximately Counting Stable Matchings',
	 'urllink': u'http://arxiv.org/abs/1004.1836'}
2015-03-24 03:08:39+0000 [xxu46_1] INFO: Crawled 221 pages (at 1 pages/min), scraped 215 items (at 1 items/min)
2015-03-24 03:09:39+0000 [xxu46_1] INFO: Crawled 221 pages (at 0 pages/min), scraped 215 items (at 0 items/min)
2015-03-24 03:10:06+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1773> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 03:10:06+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1773>
	{'abstract': u'This article synthezises the most important results on the kinematics of cuspidal manipulators i.e. nonredundant manipulators that can change posture without meeting a singularity. The characteristic surfaces, the uniqueness domains and the regions of feasible paths in the workspace are defined. Then, several sufficient geometric conditions for a manipulator to be noncuspidal are enumerated and a general necessary and sufficient condition for a manipulator to be cuspidal is provided. An explicit DH-parameter-based condition for an orthogonal manipulator to be cuspidal is derived. The full classification of 3R orthogonal manipulators is provided and all types of cuspidal and noncuspidal orthogonal manipulators are enumerated. Finally, some facts about cuspidal and noncuspidal 6R manipulators are reported.',
	 'authors': u'Philippe Wenger,',
	 'category': u'Computer Science ',
	 'date': '2010-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1002.1773',
	 'subjects': u'Robotics (cs.RO)',
	 'title': u'\nCuspidal and Noncuspidal Robot Manipulators',
	 'urllink': u'http://arxiv.org/abs/1002.1773'}
2015-03-24 03:10:39+0000 [xxu46_1] INFO: Crawled 222 pages (at 1 pages/min), scraped 216 items (at 1 items/min)
2015-03-24 03:11:11+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1830> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 03:11:11+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1830>
	{'abstract': u'In this paper, we look at two ways to implement determinisitic one dimensional cellular automata into hyperbolic cellular automata in three contexts: the pentagrid, the heptagrid and the dodecagrid, these tilings being classically denoted by , and respectively.',
	 'authors': u'Maurice Margenstern,',
	 'category': u'Computer Science ',
	 'date': '2010-4-11',
	 'pdflink': u'http://arxiv.org/pdf/1004.1830',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nAbout the embedding of one dimensional cellular automata into hyperbolic  cellular automata',
	 'urllink': u'http://arxiv.org/abs/1004.1830'}
2015-03-24 03:11:39+0000 [xxu46_1] INFO: Crawled 223 pages (at 1 pages/min), scraped 217 items (at 1 items/min)
2015-03-24 03:12:39+0000 [xxu46_1] INFO: Crawled 223 pages (at 0 pages/min), scraped 217 items (at 0 items/min)
2015-03-24 03:12:56+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1751> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 03:12:56+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1751>
	{'abstract': u'Estimating characteristics of large graphs via sampling is a vital part of the study of complex networks. Current sampling methods such as (independent) random vertex and random walks are useful but have drawbacks. Random vertex sampling may require too many resources (time, bandwidth, or money). Random walks, which normally require fewer resources per sample, can suffer from large estimation errors in the presence of disconnected or loosely connected graphs. In this work we propose a new -dimensional random walk that uses dependent random walkers. We show that the proposed sampling method, which we call Frontier sampling, exhibits all of the nice sampling properties of a regular random walk. At the same time, our simulations over large real world graphs show that, in the presence of disconnected or loosely connected components, Frontier sampling exhibits lower estimation errors than regular random walks. We also show that Frontier sampling is more suitable than random vertex sampling to sample the tail of the degree distribution of the graph.',
	 'authors': u'Bruno Ribeiro, Don Towsley,',
	 'category': u'Computer Science ',
	 'date': '2010-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1002.1751',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nEstimating and Sampling Graphs with Multidimensional Random Walks',
	 'urllink': u'http://arxiv.org/abs/1002.1751'}
2015-03-24 03:13:39+0000 [xxu46_1] INFO: Crawled 224 pages (at 1 pages/min), scraped 218 items (at 1 items/min)
2015-03-24 03:13:47+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1823> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 03:13:47+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1823>
	{'abstract': u'There has been much progress on efficient algorithms for clustering data points generated by a mixture of probability distributions under the assumption that the means of the distributions are well-separated, i.e., the distance between the means of any two distributions is at least standard deviations. These results generally make heavy use of the generative model and particular properties of the distributions. In this paper, we show that a simple clustering algorithm works without assuming any generative (probabilistic) model. Our only assumption is what we call a "proximity condition": the projection of any data point onto the line joining its cluster center to any other cluster center is standard deviations closer to its own center than the other center. Here the notion of standard deviations is based on the spectral norm of the matrix whose rows represent the difference between a point and the mean of the cluster to which it belongs. We show that in the generative models studied, our proximity condition is satisfied and so we are able to derive most known results for generative models as corollaries of our main result. We also prove some new results for generative models - e.g., we can cluster all but a small fraction of points only assuming a bound on the variance. Our algorithm relies on the well known -means algorithm, and along the way, we prove a result of independent interest -- that the -means algorithm converges to the "true centers" even in the presence of spurious points provided the initial (estimated) centers are close enough to the corresponding actual centers and all but a small fraction of the points satisfy the proximity condition. Finally, we present a new technique for boosting the ratio of inter-center separation to standard deviation.',
	 'authors': u'Amit Kumar, Ravindran Kannan,',
	 'category': u'Computer Science ',
	 'date': '2010-4-11',
	 'pdflink': u'http://arxiv.org/pdf/1004.1823',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nClustering with Spectral Norm and the k-means Algorithm',
	 'urllink': u'http://arxiv.org/abs/1004.1823'}
2015-03-24 03:14:39+0000 [xxu46_1] INFO: Crawled 225 pages (at 1 pages/min), scraped 219 items (at 1 items/min)
2015-03-24 03:14:54+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1744> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 03:14:54+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1744>
	{'abstract': u'We study suitable parameters and relations in a numerical semigroup S. When S is the Weierstrass semigroup at a rational point P of a projective curve C, we evaluate the Feng-Rao order bound of the associated family of Goppa codes. Further we conjecture that the order bound is always greater than a fixed value easily deduced from the parameters of the semigroup: we also prove this inequality in several cases.',
	 'authors': u'Anna Oneto, Grazia Tamone,',
	 'category': u'Computer Science ',
	 'date': '2010-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1002.1744',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOn some invariants in numerical semigroups and estimations of the order  bound',
	 'urllink': u'http://arxiv.org/abs/1002.1744'}
2015-03-24 03:15:39+0000 [xxu46_1] INFO: Crawled 226 pages (at 1 pages/min), scraped 220 items (at 1 items/min)
2015-03-24 03:15:52+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1821> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 03:15:52+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1821>
	{'abstract': u"A major enterprise in compressed sensing and sparse approximation is the design and analysis of computationally tractable algorithms for recovering sparse, exact or approximate, solutions of underdetermined linear systems of equations. Many such algorithms have now been proven to have optimal-order uniform recovery guarantees using the ubiquitous Restricted Isometry Property (RIP). However, it is unclear when the RIP-based sufficient conditions on the algorithm are satisfied. We present a framework in which this task can be achieved; translating these conditions for Gaussian measurement matrices into requirements on the signal's sparsity level, length, and number of measurements. We illustrate this approach on three of the state-of-the-art greedy algorithms: CoSaMP, Subspace Pursuit (SP), and Iterative Hard Thresholding (IHT). Designed to allow a direct comparison of existing theory, our framework implies that, according to the best known bounds, IHT requires the fewest number of compressed sensing measurements and has the lowest per iteration computational cost of the three algorithms compared here.",
	 'authors': u'Jeffrey D. Blanchard, Coralia Cartis, Jared Tanner, Andrew Thompson,',
	 'category': u'Computer Science ',
	 'date': '2010-4-11',
	 'pdflink': u'http://arxiv.org/pdf/1004.1821',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nPhase Transitions for Greedy Sparse Approximation Algorithms',
	 'urllink': u'http://arxiv.org/abs/1004.1821'}
2015-03-24 03:16:39+0000 [xxu46_1] INFO: Crawled 227 pages (at 1 pages/min), scraped 221 items (at 1 items/min)
2015-03-24 03:16:50+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1727> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 03:16:50+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1727>
	{'abstract': u'Motivated by the work of Uehara et al. [1], an improved method to recover DC coefficients from AC coefficients of DCT-transformed images is investigated in this work, which finds applications in cryptanalysis of selective multimedia encryption. The proposed under/over-flow rate minimization (FRM) method employs an optimization process to get a statistically more accurate estimation of unknown DC coefficients, thus achieving a better recovery performance. It was shown by experimental results based on 200 test images that the proposed DC recovery method significantly improves the quality of most recovered images in terms of the PSNR values and several state-of-the-art objective image quality assessment (IQA) metrics such as SSIM and MS-SSIM.',
	 'authors': u'Shujun Li, Junaid Jameel Ahmad, Dietmar Saupe, C.-C. Jay Kuo,',
	 'category': u'Computer Science ',
	 'date': '2010-2-8',
	 'pdflink': u'http://arxiv.org/pdf/1002.1727',
	 'subjects': u'Multimedia (cs.MM)',
	 'title': u'\nAn Improved DC Recovery Method from AC Coefficients of DCT-Transformed  Images',
	 'urllink': u'http://arxiv.org/abs/1002.1727'}
2015-03-24 03:17:39+0000 [xxu46_1] INFO: Crawled 228 pages (at 1 pages/min), scraped 222 items (at 1 items/min)
2015-03-24 03:18:04+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1814> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 03:18:04+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1814>
	{'abstract': u"We show that the maximum clique problem (decision version) can be expressed in existential second order (ESO) logic, where the first order part is a Horn formula in second-order quantified predicates. Without ordering, the first order part is Horn; if ordering is used, then it is universal Horn (in which case, the second order variables can be determined in polynomial time). UPDATE: Manuscript withdrawn, because results are incorrect. If phi = phi_1 AND phi_2, and phi is a Horn formula, it does NOT mean that both phi_1 and phi_2 are Horn formulae. Furthermore, the cardinality constraint CANNOT be expressed as a universal Horn sentence in ESO (NOT even when the structure is ordered). Graedel's theorem is valid at a lower (machine) level, but probably NOT at a higher level.",
	 'authors': u'Prabhu Manyem,',
	 'category': u'Computer Science ',
	 'date': '2010-4-11',
	 'pdflink': u'http://arxiv.org/e-print/1004.1814',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nExistential Second Order Logic Expression With Horn First Order for  Maximum Clique (Decision Version)',
	 'urllink': u'http://arxiv.org/abs/1004.1814'}
2015-03-24 03:18:39+0000 [xxu46_1] INFO: Crawled 229 pages (at 1 pages/min), scraped 223 items (at 1 items/min)
2015-03-24 03:19:39+0000 [xxu46_1] INFO: Crawled 229 pages (at 0 pages/min), scraped 223 items (at 0 items/min)
2015-03-24 03:19:52+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1718> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 03:19:52+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1718>
	{'abstract': u"This paper presents a technique for approximating, up to any precision, the set of subgame-perfect equilibria (SPE) in discounted repeated games. The process starts with a single hypercube approximation of the set of SPE. Then the initial hypercube is gradually partitioned on to a set of smaller adjacent hypercubes, while those hypercubes that cannot contain any point belonging to the set of SPE are simultaneously withdrawn. Whether a given hypercube can contain an equilibrium point is verified by an appropriate mathematical program. Three different formulations of the algorithm for both approximately computing the set of SPE payoffs and extracting players' strategies are then proposed: the first two that do not assume the presence of an external coordination between players, and the third one that assumes a certain level of coordination during game play for convexifying the set of continuation payoffs after any repeated game history. A special attention is paid to the question of extracting players' strategies and their representability in form of finite automata, an important feature for artificial agent systems.",
	 'authors': u'Andriy Burkov, Brahim Chaib-draa,',
	 'category': u'Computer Science ',
	 'date': '2010-2-8',
	 'pdflink': u'http://arxiv.org/pdf/1002.1718',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nAn Approximate Subgame-Perfect Equilibrium Computation Technique for  Repeated Games',
	 'urllink': u'http://arxiv.org/abs/1002.1718'}
2015-03-24 03:20:39+0000 [xxu46_1] INFO: Crawled 230 pages (at 1 pages/min), scraped 224 items (at 1 items/min)
2015-03-24 03:21:27+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1808> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 03:21:27+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1808>
	{'abstract': u'This article deals with new polynomial time algorithm for graph isomorphism testing.',
	 'authors': u'Michael I. Trofimov,',
	 'category': u'Computer Science ',
	 'date': '2010-4-11',
	 'pdflink': u'http://arxiv.org/pdf/1004.1808',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nPolynomial Time Algorithm for Graph Isomorphism Testing',
	 'urllink': u'http://arxiv.org/abs/1004.1808'}
2015-03-24 03:21:39+0000 [xxu46_1] INFO: Crawled 231 pages (at 1 pages/min), scraped 225 items (at 1 items/min)
2015-03-24 03:22:39+0000 [xxu46_1] INFO: Crawled 231 pages (at 0 pages/min), scraped 225 items (at 0 items/min)
2015-03-24 03:22:48+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1692> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 03:22:48+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1692>
	{'abstract': u'UCMs (Use Case Maps) model describes functional requirements and high-level designs with causal paths superimposed on a structure of components. It could provide useful resources for software acceptance testing. However until now statistical testing technologies for large scale software is not considered yet in UCMs model. Thus if one applies UCMs model to a large scale software using traditional coverage based exhaustive tasting, then it requires too much costs for the quality assurance. Therefore this paper proposes an importance analysis of UCMs model with Markov chains. With this approach not only highly frequently used usage scenarios but also important objects such as components, responsibilities, stubs and plugins can also be identified from UCMs specifications. Therefore careful analysis, design, implementation and efficient testing could be possible with the importance of scenarios and objects during the full software life cycle. Consequently product reliability can be obtained with low costs. This paper includes an importance analysis method that identifies important scenarios and objects and a case study to illustrate the applicability of the proposed approach.',
	 'authors': u'Yaping Feng, Lee Sub Lee,',
	 'category': u'Computer Science ',
	 'date': '2010-2-8',
	 'pdflink': u'http://arxiv.org/pdf/1002.1692',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nThe Importance Analysis of Use Case Map with Markov Chains',
	 'urllink': u'http://arxiv.org/abs/1002.1692'}
2015-03-24 03:23:39+0000 [xxu46_1] INFO: Crawled 232 pages (at 1 pages/min), scraped 226 items (at 1 items/min)
2015-03-24 03:24:34+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1796> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 03:24:34+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1796>
	{'abstract': u'This paper illustrates the Principal Direction Divisive Partitioning (PDDP) algorithm and describes its drawbacks and introduces a combinatorial framework of the Principal Direction Divisive Partitioning (PDDP) algorithm, then describes the simplified version of the EM algorithm called the spherical Gaussian EM (sGEM) algorithm and Information Bottleneck method (IB) is a technique for finding accuracy, complexity and time space. The PDDP algorithm recursively splits the data samples into two sub clusters using the hyper plane normal to the principal direction derived from the covariance matrix, which is the central logic of the algorithm. However, the PDDP algorithm can yield poor results, especially when clusters are not well separated from one another. To improve the quality of the clustering results problem, it is resolved by reallocating new cluster membership using the IB algorithm with different settings. IB Method gives accuracy but time consumption is more. Furthermore, based on the theoretical background of the sGEM algorithm and sequential Information Bottleneck method(sIB), it can be obvious to extend the framework to cover the problem of estimating the number of clusters using the Bayesian Information Criterion. Experimental results are given to show the effectiveness of the proposed algorithm with comparison to the existing algorithm.',
	 'authors': u'P.J.Gayathri, S.C. Punitha, M. Punithavalli,',
	 'category': u'Computer Science ',
	 'date': '2010-4-11',
	 'pdflink': u'http://arxiv.org/pdf/1004.1796',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nDocument Clustering using Sequential Information Bottleneck Method',
	 'urllink': u'http://arxiv.org/abs/1004.1796'}
2015-03-24 03:24:39+0000 [xxu46_1] INFO: Crawled 233 pages (at 1 pages/min), scraped 227 items (at 1 items/min)
2015-03-24 03:25:39+0000 [xxu46_1] INFO: Crawled 233 pages (at 0 pages/min), scraped 227 items (at 0 items/min)
2015-03-24 03:25:55+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1691> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 03:25:55+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1691>
	{'abstract': u'Efficient routing mechanism is a challenging issue for group oriented computing in Mobile Ad Hoc Networks (MANETs). The ability of MANETs to support adequate Quality of Service (QoS) for group communication is limited by the ability of the underlying ad-hoc routing protocols to provide consistent behavior despite the dynamic properties of mobile computing devices. In MANET QoS requirements can be quantified in terms of Packet Delivery Ratio (PDR), Data Latency, Packet Loss Probability, Routing Overhead, Medium Access Control (MAC) Overhead and Data Throughput etc. This paper presents an in depth study of one to many and many to many communications in MANETs and provides a comparative performance evaluation of unicast and broadcast routing protocols. Dynamic Source Routing protocol (DSR) is used as unicast protocol and BCAST is used to represent broadcast protocol. The performance differentials are analyzed using ns2 network simulator varying multicast group size (number of data senders and data receivers). Both protocols are simulated with identical traffic loads and mobility models. Simulation result shows that BCAST performs better than DSR in most cases.',
	 'authors': u'Sumon Kumar Debnath, Foez Ahmed, Nayeema Islam,',
	 'category': u'Computer Science ',
	 'date': '2010-2-8',
	 'pdflink': u'http://arxiv.org/pdf/1002.1691',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nPerformance Evaluation of Unicast and Broadcast Mobile Ad hoc Network  Routing Protocols',
	 'urllink': u'http://arxiv.org/abs/1002.1691'}
2015-03-24 03:26:39+0000 [xxu46_1] INFO: Crawled 234 pages (at 1 pages/min), scraped 228 items (at 1 items/min)
2015-03-24 03:27:23+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1794> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 03:27:23+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1794>
	{'abstract': u"Most of the web user's requirements are search or navigation time and getting correctly matched result. These constrains can be satisfied with some additional modules attached to the existing search engines and web servers. This paper proposes that powerful architecture for search engines with the title of Probabilistic Semantic Web Mining named from the methods used. With the increase of larger and larger collection of various data resources on the World Wide Web (WWW), Web Mining has become one of the most important requirements for the web users. Web servers will store various formats of data including text, image, audio, video etc., but servers can not identify the contents of the data. These search techniques can be improved by adding some special techniques including semantic web mining and probabilistic analysis to get more accurate results. Semantic web mining technique can provide meaningful search of data resources by eliminating useless information with mining process. In this technique web servers will maintain Meta information of each and every data resources available in that particular web server. This will help the search engine to retrieve information that is relevant to user given input string. This paper proposing the idea of combing these two techniques Semantic web mining and Probabilistic analysis for efficient and accurate search results of web mining. SPF can be calculated by considering both semantic accuracy and syntactic accuracy of data with the input string. This will be the deciding factor for producing results.",
	 'authors': u'T.Krishna Kishore, T.Sasi Vardhan, N.Lakshmi Narayana,',
	 'category': u'Computer Science ',
	 'date': '2010-4-11',
	 'pdflink': u'http://arxiv.org/pdf/1004.1794',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nProbabilistic Semantic Web Mining Using Artificial Neural Analysis',
	 'urllink': u'http://arxiv.org/abs/1004.1794'}
2015-03-24 03:27:39+0000 [xxu46_1] INFO: Crawled 235 pages (at 1 pages/min), scraped 229 items (at 1 items/min)
2015-03-24 03:28:34+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1689> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 03:28:34+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1689>
	{'abstract': u'Distributed contention based Medium Access Control (MAC) protocols are the fundamental components for IEEE 802.11 based Wireless Local Area Networks (WLANs). Contention windows (CW) change dynamically to adapt to the current contention level, Upon each packet collision, a station doubles its CW to reduce further collision of packets. IEEE 802.11 Distributed Coordination Function (DCF) suffers from a common problem in erroneous channel. They cannot distinguish noise lost packets from collision lost packets. In both situations a station does not receive its ACK and doubles the CW to reduce further packet collisions. This increases backoff overhead unnecessarily in addition to the noise lost packets, reduces the throughput significantly. Furthermore, the aggregate throughput of a practical WLAN strongly depends on the channel conditions. In real radio environment, the received signal power at the access point from a station is subjected to deterministic path loss, shadowing and fast multipath fading. In this paper, we propose a new saturation throughput analysis for IEEE 802.11 DCF considering erroneous channel and capture effects. To alleviate the low performance of IEEE 802.11 DCF, we introduce a mechanism that greatly outperforms under noisy environment with low network traffic and compare their performances to the existing standards. We extend the multidimensional Markov chain model initially proposed by Bianchi(3) to characterize the behavior of DCF in order to account both real channel conditions and capture effects, especially in a high interference radio environment.',
	 'authors': u'Ponnusamy Kumar, A. Krishnan,',
	 'category': u'Computer Science ',
	 'date': '2010-2-8',
	 'pdflink': u'http://arxiv.org/pdf/1002.1689',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nSaturation Throughput Analysis of IEEE 802.11b Wireless Local Area  Networks under High Interference Considering Capture Effects',
	 'urllink': u'http://arxiv.org/abs/1002.1689'}
2015-03-24 03:28:39+0000 [xxu46_1] INFO: Crawled 236 pages (at 1 pages/min), scraped 230 items (at 1 items/min)
2015-03-24 03:29:39+0000 [xxu46_1] INFO: Crawled 236 pages (at 0 pages/min), scraped 230 items (at 0 items/min)
2015-03-24 03:29:53+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1793> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 03:29:53+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1793>
	{'abstract': u'The country India follows the planning through planning commission. This is on the basis of information collected by traditional, tedious and manual method which is too slow to sustain. Now we are in the age of 21th century. We have seen in last few decades that the progress of information technology with leaps and bounds, which have completely changed the way of life in the developed nations. While internet has changed the established working practice and opened new vistas and provided a platform to connect, this gives the opportunity for collaborative work space that goes beyond the global boundary. We are living in the global economy and India leading towards Liberalize Market Oriented Economy (LMOE). Considering this things, focusing on GIS, we proposed a system for collection of socio economic data and water resource management information of rural area via internet.',
	 'authors': u'S.K. Nayak, S.B.Thorat, N.V. Kalyankar,',
	 'category': u'Computer Science ',
	 'date': '2010-4-11',
	 'pdflink': u'http://arxiv.org/pdf/1004.1793',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nGIS: Geographic Information System An application for socio-economical  data collection for rural area',
	 'urllink': u'http://arxiv.org/abs/1004.1793'}
2015-03-24 03:30:39+0000 [xxu46_1] INFO: Crawled 237 pages (at 1 pages/min), scraped 231 items (at 1 items/min)
2015-03-24 03:31:21+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1687> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 03:31:21+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1687>
	{'abstract': u'The traditional TCP congestion control mechanism encounters a number of new problems and suffers a poor performance when the IEEE 802.11 MAC protocol is used in multihop ad hoc networks. Many of the problems result from medium contention at the MAC layer. In this paper, I first illustrate that severe medium contention and congestion are intimately coupled, and TCP s congestion control algorithm becomes too coarse in its granularity, causing throughput instability and excessively long delay. Further, we illustrate TCP s severe unfairness problem due to the medium contention and the tradeoff between aggregate throughput and fairness. Then, based on the novel use of channel busyness ratio, a more accurate metric to characterize the network utilization and congestion status, I propose a new wireless congestion control protocol (WCCP) to efficiently and fairly support the transport service in multihop ad hoc networks. In this protocol, each forwarding node along a traffic flow exercises the internode and intranode fair resource allocation and determines the MAC layer feedback accordingly. The endtoend feedback, which is ultimately determined by the bottleneck node along the flow, is carried back to the source to control its sending rate. Extensive simulations show that WCCP significantly outperforms traditional TCP in terms of channel utilization, delay, and fairness, and eliminates the starvation problem.',
	 'authors': u'Mahendra kumar. S, Senthil Prakash. K,',
	 'category': u'Computer Science ',
	 'date': '2010-2-8',
	 'pdflink': u'http://arxiv.org/pdf/1002.1687',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nWireless Congestion Control Protocol For Multihop Ad Hoc Networks',
	 'urllink': u'http://arxiv.org/abs/1002.1687'}
2015-03-24 03:31:39+0000 [xxu46_1] INFO: Crawled 238 pages (at 1 pages/min), scraped 232 items (at 1 items/min)
2015-03-24 03:32:36+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1791> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 03:32:36+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1791>
	{'abstract': u'A method of lossless data hiding in images using integer wavelet transform and histogram shifting for gray scale images is proposed. The method shifts part of the histogram, to create space for embedding the watermark information bits. The method embeds watermark while maintaining the visual quality well. The method is completely reversible. The original image and the watermark data can be recovered without any loss.',
	 'authors': u'S. Kurshid Jinna, L. Ganesan,',
	 'category': u'Computer Science ',
	 'date': '2010-4-11',
	 'pdflink': u'http://arxiv.org/pdf/1004.1791',
	 'subjects': u'Multimedia (cs.MM)',
	 'title': u'\nReversible Image data Hiding using Lifting wavelet Transform and  Histogram Shifting',
	 'urllink': u'http://arxiv.org/abs/1004.1791'}
2015-03-24 03:32:39+0000 [xxu46_1] INFO: Crawled 239 pages (at 1 pages/min), scraped 233 items (at 1 items/min)
2015-03-24 03:33:39+0000 [xxu46_1] INFO: Crawled 239 pages (at 0 pages/min), scraped 233 items (at 0 items/min)
2015-03-24 03:34:12+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1683> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 03:34:12+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1683>
	{'abstract': u'In this paper, design of current controller for a two quadrant DC motor drive was proposed with the help of model order reduction technique. The calculation of current controller gain with some approximations in the conventional design process is replaced by proposed model order reduction method. The model order reduction technique proposed in this paper gives the better controller gain value for the DC motor drive. The proposed model order reduction method is a mixed method, where the numerator polynomial of reduced order model is obtained by using stability equation method and the denominator polynomial is obtained by using some approximation technique preceded in this paper. The designed controllers responses were simulated with the help of MATLAB to show the validity of the proposed method.',
	 'authors': u'K. Ramesh, K. Ayyar, A. Nirmalkumar, G. Gurusamy,',
	 'category': u'Computer Science ',
	 'date': '2010-2-8',
	 'pdflink': u'http://arxiv.org/pdf/1002.1683',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nDesign of Current Controller for Two Quadrant DC Motor Drive by Using  Model Order Reduction Technique',
	 'urllink': u'http://arxiv.org/abs/1002.1683'}
2015-03-24 03:34:39+0000 [xxu46_1] INFO: Crawled 240 pages (at 1 pages/min), scraped 234 items (at 1 items/min)
2015-03-24 03:35:39+0000 [xxu46_1] INFO: Crawled 240 pages (at 0 pages/min), scraped 234 items (at 0 items/min)
2015-03-24 03:35:46+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1789> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 03:35:46+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1789>
	{'abstract': u"The development and application of various remote sensing platforms result in the production of huge amounts of satellite image data. Therefore, there is an increasing need for effective querying and browsing in these image databases. In order to take advantage and make good use of satellite images data, we must be able to extract meaningful information from the imagery. Hence we proposed a new algorithm for SAR image segmentation. In this paper we propose segmentation using vector quantization technique on entropy image. Initially, we obtain entropy image and in second step we use Kekre's Fast Codebook Generation (KFCG) algorithm for segmentation of the entropy image. Thereafter, a codebook of size 128 was generated for the Entropy image. These code vectors were further clustered in 8 clusters using same KFCG algorithm and converted into 8 images. These 8 images were displayed as a result. This approach does not lead to over segmentation or under segmentation. We compared these results with well known Gray Level Co-occurrence Matrix. The proposed algorithm gives better segmentation with less complexity.",
	 'authors': u'H. B. Kekre, Saylee Gharge, Tanuja K. Sarode,',
	 'category': u'Computer Science ',
	 'date': '2010-4-11',
	 'pdflink': u'http://arxiv.org/pdf/1004.1789',
	 'subjects': u'Multimedia (cs.MM)',
	 'title': u'\nSAR Image Segmentation using Vector Quantization Technique on Entropy  Images',
	 'urllink': u'http://arxiv.org/abs/1004.1789'}
2015-03-24 03:36:39+0000 [xxu46_1] INFO: Crawled 241 pages (at 1 pages/min), scraped 235 items (at 1 items/min)
2015-03-24 03:37:30+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1681> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 03:37:30+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1681>
	{'abstract': u'In wireless ad hoc networks, the absence of any control on packets forwarding, make these networks vulnerable by various deny of service attacks (DoS). A node, in wireless ad hoc network, counts always on intermediate nodes to send these packets to a given destination node. An intermediate node, which takes part in packets forwarding, may behave maliciously and drop packets which goes through it, instead of forwarding them to the following node. Such behavior is called black hole attack. In this paper, after having specified the black hole attack, a secure mechanism, which consists in checking the good forwarding of packets by an intermediate node, was proposed. The proposed solution avoids the black hole and the cooperative black hole attacks. Evaluation metrics were considered in simulation to show the effectiveness of the suggested solution.',
	 'authors': u'Abderrahmane Baadache, Ali Belmehdi,',
	 'category': u'Computer Science ',
	 'date': '2010-2-8',
	 'pdflink': u'http://arxiv.org/pdf/1002.1681',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nAvoiding Black Hole and Cooperative Black Hole Attacks in Wireless Ad  hoc Networks',
	 'urllink': u'http://arxiv.org/abs/1002.1681'}
2015-03-24 03:37:39+0000 [xxu46_1] INFO: Crawled 242 pages (at 1 pages/min), scraped 236 items (at 1 items/min)
2015-03-24 03:38:39+0000 [xxu46_1] INFO: Crawled 242 pages (at 0 pages/min), scraped 236 items (at 0 items/min)
2015-03-24 03:39:03+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1788> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 03:39:03+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1788>
	{'abstract': u"This paper intends to look deeper into finding an ideal mobile broadband solution. Special stress has been put in the South Asian region through some comparative analysis. Proving their competency in numerous aspects, WiMAX and LTE already have already made a strong position in telecommunication industry. Both WiMAX and LTE are 4G technologies designed to move data rather than voice having IP networks based on OFDM technology. So, they aren't like typical technological rivals as of GSM and CDMA. But still a gesture of hostility seems to outburst long before the stable commercial launch of LTE. In this paper various aspects of WiMAX and LTE for deployment have been analyzed. Again, we tried to make every possible consideration with respect to south Asia i.e. how mass people of this region may be benefited. As a result, it might be regarded as a good source in case of making major BWA deployment decisions in this region. Besides these, it also opens the path for further research and in depth thinking in this issue.",
	 'authors': u'Nafiz Imtiaz Bin Hamid, Md. Zakir Hossain, Md. R. H. Khandokar, Taskin Jamal, Md.A. Shoeb,',
	 'category': u'Computer Science ',
	 'date': '2010-4-11',
	 'pdflink': u'http://arxiv.org/pdf/1004.1788',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nMobile Broadband Possibilities considering the Arrival of IEEE 802.16m &  LTE with an Emphasis on South Asia',
	 'urllink': u'http://arxiv.org/abs/1004.1788'}
2015-03-24 03:39:39+0000 [xxu46_1] INFO: Crawled 243 pages (at 1 pages/min), scraped 237 items (at 1 items/min)
2015-03-24 03:40:25+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1678> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 03:40:25+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1678>
	{'abstract': u'The number of malware variants is growing tremendously and the study of malware attacks on the Internet is still a demanding research domain. In this research, various logs from different OSI layer are explore to identify the traces leave on the attacker and victim logs, and the attack worm trace pattern are establish in order to reveal true attacker or victim. For the purpose of this paper, it will only concentrate on cybercrime that caused by malware network intrusion and used the traditional worm namely blaster worm variants. This research creates the concept of trace pattern by fusing the attackers and victims perspective. Therefore, the objective of this paper is to propose on attackers, victims and multistep, attacker or victim, trace patterns by combining both perspectives. These three proposed worm trace patterns can be extended into research areas in alert correlation and computer forensic investigation.',
	 'authors': u'S. Siti Rahayu, Y. Robiah, S. Shahrin, Mohd M. Zaki, R. Irda, M.A. Faizal,',
	 'category': u'Computer Science ',
	 'date': '2010-2-8',
	 'pdflink': u'http://arxiv.org/pdf/1002.1678',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nScenario Based Worm Trace Pattern Identification Technique',
	 'urllink': u'http://arxiv.org/abs/1002.1678'}
2015-03-24 03:40:39+0000 [xxu46_1] INFO: Crawled 244 pages (at 1 pages/min), scraped 238 items (at 1 items/min)
2015-03-24 03:41:39+0000 [xxu46_1] INFO: Crawled 244 pages (at 0 pages/min), scraped 238 items (at 0 items/min)
2015-03-24 03:42:11+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1774> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 03:42:11+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1774>
	{'abstract': u'In Wireless Mesh Networks (WMN), a channel assignment has to balance the objectives of maintaining connectivity and increasing the aggregate bandwidth. The main aim of the channel assignment algorithm is to assign the channels to the network interfaces, from the given expected load on each virtual link. From the existing work done so far, we can examine that there is no combined solution of multi-channel assignment with routing and congestion control. In this paper, we propose a congestion control routing protocol along with multi-channel assignment. We use a traffic aware metric in this protocol in order to provide quality of service. The proposed protocol can improve the throughput and channel utilization to very high extent because it provides solution for multi-channel assignment and congestion control. The proposed algorithm assigns the channels in a way that, congestion is avoided and co-channel interference levels among links with same channel are reduced. By our simulation results in NS2, we show that the proposed protocol attains high throughput and channel utilization along with reduced latency.',
	 'authors': u'K.Valarmathi, N. Malmurugan,',
	 'category': u'Computer Science ',
	 'date': '2010-4-11',
	 'pdflink': u'http://arxiv.org/pdf/1004.1774',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nJoint Design of Congestion Control Routing With Distributed Multi  Channel Assignment in Wireless Mesh Networks',
	 'urllink': u'http://arxiv.org/abs/1004.1774'}
2015-03-24 03:42:39+0000 [xxu46_1] INFO: Crawled 245 pages (at 1 pages/min), scraped 239 items (at 1 items/min)
2015-03-24 03:43:39+0000 [xxu46_1] INFO: Crawled 245 pages (at 0 pages/min), scraped 239 items (at 0 items/min)
2015-03-24 03:43:50+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1636> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 03:43:50+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1636>
	{'abstract': u'We give a new insight into the upper bounding of the 3-SAT threshold by the first moment method. The best criteria developed so far to select the solutions to be counted discriminate among neighboring solutions on the basis of uniform information about each individual free variable. What we mean by uniform information, is information which does not depend on the solution: e.g. the number of positive/negative occurrences of the considered variable. What is new in our approach is that we use non uniform information about variables. Thus we are able to make a more precise tuning, resulting in a slight improvement on upper bounding the 3-SAT threshold for various models of formulas defined by their distributions.',
	 'authors': u'Thomas Hugel, Yacine Boufkhad,',
	 'category': u'Computer Science ',
	 'date': '2010-2-8',
	 'pdflink': u'http://arxiv.org/pdf/1002.1636',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nNon Uniform Selection of Solutions for Upper Bounding the 3-SAT  Threshold',
	 'urllink': u'http://arxiv.org/abs/1002.1636'}
2015-03-24 03:44:39+0000 [xxu46_1] INFO: Crawled 246 pages (at 1 pages/min), scraped 240 items (at 1 items/min)
2015-03-24 03:45:04+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1773> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 03:45:04+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1773>
	{'abstract': u'Cloud computing is an emerging platform of service computing designed for swift and dynamic delivery of assured computing resources. Cloud computing provide Service-Level Agreements (SLAs) for guaranteed uptime availability for enabling convenient and on-demand network access to the distributed and shared computing resources. Though the cloud computing paradigm holds its potential status in the field of distributed computing, cloud platforms are not yet to the attention of majority of the researchers and practitioners. More specifically, still the researchers and practitioners community has fragmented and imperfect knowledge on cloud computing principles and techniques. In this context, one of the primary motivations of the work presented in this paper is to reveal the versatile merits of cloud computing paradigm and hence the objective of this work is defined to bring out the remarkable significances of cloud computing paradigm through an application environment. In this work, a cloud computing model for software testing is developed.',
	 'authors': u'T. Vengattaraman, P. Dhavachelvan, R. Baskaran,',
	 'category': u'Computer Science ',
	 'date': '2010-4-11',
	 'pdflink': u'http://arxiv.org/pdf/1004.1773',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nA Model of Cloud Based Application Environment for Software Testing',
	 'urllink': u'http://arxiv.org/abs/1004.1773'}
2015-03-24 03:45:39+0000 [xxu46_1] INFO: Crawled 247 pages (at 1 pages/min), scraped 241 items (at 1 items/min)
2015-03-24 03:46:32+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1629> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 03:46:32+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1629>
	{'abstract': u'In this paper we propose two analytically tractable stochastic models of non-slotted Aloha for Mobile Ad-hoc NETworks (MANETs): one model assumes a static pattern of nodes while the other assumes that the pattern of nodes varies over time. Both models feature transmitters randomly located in the Euclidean plane, according to a Poisson point process with the receivers randomly located at a fixed distance from the emitters. We concentrate on the so-called outage scenario, where a successful transmission requires a Signal-to-Interference-and-Noise Ratio (SINR) larger than a given threshold. With Rayleigh fading and the SINR averaged over the duration of the packet transmission, both models lead to closed form expressions for the probability of successful transmission. We show an excellent matching of these results with simulations. Using our models we compare the performances of non-slotted Aloha to previously studied slotted Aloha. We observe that when the path loss is not very strong both models, when appropriately optimized, exhibit similar performance. For stronger path loss non-slotted Aloha performs worse than slotted Aloha, however when the path loss exponent is equal to 4 its density of successfully received packets is still 75% of that in the slotted scheme. This is still much more than the 50% predicted by the well-known analysis where simultaneous transmissions are never successful. Moreover, in any path loss scenario, both schemes exhibit the same energy efficiency.',
	 'authors': u'Bartek Blaszczyszyn, Paul Muhlethaler,',
	 'category': u'Computer Science ',
	 'date': '2010-2-8',
	 'pdflink': u'http://arxiv.org/pdf/1002.1629',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nStochastic Analysis of Non-slotted Aloha in Wireless Ad-Hoc Networks',
	 'urllink': u'http://arxiv.org/abs/1002.1629'}
2015-03-24 03:46:39+0000 [xxu46_1] INFO: Crawled 248 pages (at 1 pages/min), scraped 242 items (at 1 items/min)
2015-03-24 03:47:38+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1772> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 03:47:38+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1772>
	{'abstract': u'Terrorism has led to many problems in Thai societies, not only property damage but also civilian casualties. Predicting terrorism activities in advance can help prepare and manage risk from sabotage by these activities. This paper proposes a framework focusing on event classification in terrorism domain using fuzzy inference systems (FISs). Each FIS is a decision-making model combining fuzzy logic and approximate reasoning. It is generated in five main parts: the input interface, the fuzzification interface, knowledge base unit, decision making unit and output defuzzification interface. Adaptive neuro-fuzzy inference system (ANFIS) is a FIS model adapted by combining the fuzzy logic and neural network. The ANFIS utilizes automatic identification of fuzzy logic rules and adjustment of membership function (MF). Moreover, neural network can directly learn from data set to construct fuzzy logic rules and MF implemented in various applications. FIS settings are evaluated based on two comparisons. The first evaluation is the comparison between unstructured and structured events using the same FIS setting. The second comparison is the model settings between FIS and ANFIS for classifying structured events. The data set consists of news articles related to terrorism events in three southern provinces of Thailand. The experimental results show that the classification performance of the FIS resulting from structured events achieves satisfactory accuracy and is better than the unstructured events. In addition, the classification of structured events using ANFIS gives higher performance than the events using only FIS in the prediction of terrorism events.',
	 'authors': u'Uraiwan Inyaem, Choochart Haruechaiyasak, Phayung Meesad, Dat Tran,',
	 'category': u'Computer Science ',
	 'date': '2010-4-11',
	 'pdflink': u'http://arxiv.org/pdf/1004.1772',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nTerrorism Event Classification Using Fuzzy Inference Systems',
	 'urllink': u'http://arxiv.org/abs/1004.1772'}
2015-03-24 03:47:39+0000 [xxu46_1] INFO: Crawled 249 pages (at 1 pages/min), scraped 243 items (at 1 items/min)
2015-03-24 03:48:39+0000 [xxu46_1] INFO: Crawled 249 pages (at 0 pages/min), scraped 243 items (at 0 items/min)
2015-03-24 03:49:00+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1624> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 03:49:00+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1624>
	{'abstract': u"An algebraic linear ordering is a component of the initial solution of a first-order recursion scheme over the continuous categorical algebra of countable linear orderings equipped with the sum operation and the constant 1. Due to a general Mezei-Wright type result, algebraic linear orderings are exactly those isomorphic to the linear ordering of the leaves of an algebraic tree. Using Courcelle's characterization of algebraic trees, we obtain the fact that a linear ordering is algebraic if and only if it can be represented as the lexicographic ordering of a deterministic context-free language. When the algebraic linear ordering is a well-ordering, its order type is an algebraic ordinal. We prove that the Hausdorff rank of any scattered algebraic linear ordering is less than . It follows that the algebraic ordinals are exactly those less than .",
	 'authors': u'Stephen L. Bloom, Zoltan Esik,',
	 'category': u'Computer Science ',
	 'date': '2010-2-8',
	 'pdflink': u'http://arxiv.org/pdf/1002.1624',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nAlgebraic Linear Orderings',
	 'urllink': u'http://arxiv.org/abs/1002.1624'}
2015-03-24 03:49:39+0000 [xxu46_1] INFO: Crawled 250 pages (at 1 pages/min), scraped 244 items (at 1 items/min)
2015-03-24 03:49:52+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1770> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 03:49:52+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1770>
	{'abstract': u'There has been a remarkable increase in the data exchange over web and the widespread use of digital media. As a result, multimedia data transfers also had a boost up. The mounting interest with reference to digital watermarking throughout the last decade is certainly due to the increase in the need of copyright protection of digital content. This is also enhanced due to commercial prospective. Applications of video watermarking in copy control, broadcast monitoring, fingerprinting, video authentication, copyright protection etc is immensely rising. The main aspects of information hiding are capacity, security and robustness. Capacity deals with the amount of information that can be hidden. The skill of anyone detecting the information is security and robustness refers to the resistance to modification of the cover content before concealed information is destroyed. Video watermarking algorithms normally prefers robustness. In a robust algorithm it is not possible to eliminate the watermark without rigorous degradation of the cover content. In this paper, we introduce the notion of Video Watermarking and the features required to design a robust watermarked video for a valuable application. We review several algorithms, and introduce frequently used key techniques. The aim of this paper is to focus on the various domains of video watermarking techniques. The majority of the reviewed methods based on video watermarking emphasize on the notion of robustness of the algorithm.',
	 'authors': u'Neeta Deshpande, Archana Rajurkar, R Manthalkar,',
	 'category': u'Computer Science ',
	 'date': '2010-4-11',
	 'pdflink': u'http://arxiv.org/pdf/1004.1770',
	 'subjects': u'Multimedia (cs.MM)',
	 'title': u'\nReview of Robust Video Watermarking Algorithms',
	 'urllink': u'http://arxiv.org/abs/1004.1770'}
2015-03-24 03:50:39+0000 [xxu46_1] INFO: Crawled 251 pages (at 1 pages/min), scraped 245 items (at 1 items/min)
2015-03-24 03:51:30+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1606> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 03:51:30+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1606>
	{'abstract': u'A PCP is a proof system for NP in which the proof can be checked by a probabilistic verifier. The verifier is only allowed to read a very small portion of the proof, and in return is allowed to err with some bounded probability. The probability that the verifier accepts a false proof is called the soundness error, and is an important parameter of a PCP system that one seeks to minimize. Constructing PCPs with sub-constant soundness error and, at the same time, a minimal number of queries into the proof (namely two) is especially important due to applications for inapproximability. In this work we construct such PCP verifiers, i.e., PCPs that make only two queries and have sub-constant soundness error. Our construction can be viewed as a combinatorial alternative to the "manifold vs. point" construction, which is the only construction in the literature for this parameter range. The "manifold vs. point" PCP is based on a low degree test, while our construction is based on a direct product test. We also extend our construction to yield a decodable PCP (dPCP) with the same parameters. By plugging in this dPCP into the scheme of Dinur and Harsha (FOCS 2009) one gets an alternative construction of the result of Moshkovitz and Raz (FOCS 2008), namely: a construction of two-query PCPs with small soundness error and small alphabet size. Our construction of a PCP is based on extending the derandomized direct product test of Impagliazzo, Kabanets and Wigderson (STOC 09) to a derandomized parallel repetition theorem. More accurately, our PCP construction is obtained in two steps. We first prove a derandomized parallel repetition theorem for specially structured PCPs. Then, we show that any PCP can be transformed into one that has the required structure, by embedding it on a de-Bruijn graph.',
	 'authors': u'Irit Dinur, Or Meir,',
	 'category': u'Computer Science ',
	 'date': '2010-2-8',
	 'pdflink': u'http://arxiv.org/pdf/1002.1606',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nDerandomized Parallel Repetition via Structured PCPs',
	 'urllink': u'http://arxiv.org/abs/1002.1606'}
2015-03-24 03:51:39+0000 [xxu46_1] INFO: Crawled 252 pages (at 1 pages/min), scraped 246 items (at 1 items/min)
2015-03-24 03:52:24+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1769> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 03:52:24+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1769>
	{'abstract': u"Cross Site Scripting (XSS) Flaws are currently the most popular security problems in modern web applications. These Flaws make use of vulnerabilities in the code of web-applications, resulting in serious consequences, such as theft of cookies, passwords and other personal credentials. Cross-Site scripting Flaws occur when accessing information in intermediate trusted sites. Client side solution acts as a web proxy to mitigate Cross Site Scripting Flaws which manually generated rules to mitigate Cross Site Scripting attempts. Client side solution effectively protects against information leakage from the user's environment. Cross Site Scripting Flaws are easy to execute, but difficult to detect and prevent. This paper provides client-side solution to mitigate cross-site scripting Flaws. The existing client-side solutions degrade the performance of client's system resulting in a poor web surfing experience. In this project provides a client side solution that uses a step by step approach to protect cross site scripting, without degrading much the user's web browsing experience.",
	 'authors': u'K. Selvamani, A. Duraisamy, A. Kannan,',
	 'category': u'Computer Science ',
	 'date': '2010-4-11',
	 'pdflink': u'http://arxiv.org/pdf/1004.1769',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nProtection of Web Applications from Cross-Site Scripting Attacks in  Browser Side',
	 'urllink': u'http://arxiv.org/abs/1004.1769'}
2015-03-24 03:52:39+0000 [xxu46_1] INFO: Crawled 253 pages (at 1 pages/min), scraped 247 items (at 1 items/min)
2015-03-24 03:53:35+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1584> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 03:53:35+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1584>
	{'abstract': u'We investigate power allocation for users in a spectrum underlay cognitive network. Our objective is to find a power control scheme that allocates transmit power for both primary and secondary users so that the overall network throughput is maximized while maintaining the quality of service (QoS) of the primary users greater than a certain minimum limit. Since an optimum solution to our problem is computationally intractable, as the optimization problem is non-convex, we propose an iterative algorithm based on sequential geometric programming, that is proved to converge to at least a local optimum solution. We use the proposed algorithm to show how a spectrum underlay network would achieve higher throughput with secondary users operation than with primary users operating alone. Also, we show via simulations that the loss in primary throughput due to the admission of the secondary users is accompanied by a reduction in the total primary transmit power.',
	 'authors': u'John Tadrous, Ahmed Sultan, Mohammed Nafie, Amr El-Keyi,',
	 'category': u'Computer Science ',
	 'date': '2010-2-8',
	 'pdflink': u'http://arxiv.org/pdf/1002.1584',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nPower Control for Maximum Throughput in Spectrum Underlay Cognitive  Radio Networks',
	 'urllink': u'http://arxiv.org/abs/1002.1584'}
2015-03-24 03:53:39+0000 [xxu46_1] INFO: Crawled 254 pages (at 1 pages/min), scraped 248 items (at 1 items/min)
2015-03-24 03:54:39+0000 [xxu46_1] INFO: Crawled 254 pages (at 0 pages/min), scraped 248 items (at 0 items/min)
2015-03-24 03:55:22+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1768> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 03:55:22+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1768>
	{'abstract': u'Image segmentation is a vital part of image processing. Segmentation has its application widespread in the field of medical images in order to diagnose curious diseases. The same medical images can be segmented manually. But the accuracy of image segmentation using the segmentation algorithms is more when compared with the manual segmentation. In the field of medical diagnosis an extensive diversity of imaging techniques is presently available, such as radiography, computed tomography (CT) and magnetic resonance imaging (MRI). Medical image segmentation is an essential step for most consequent image analysis tasks. Although the original FCM algorithm yields good results for segmenting noise free images, it fails to segment images corrupted by noise, outliers and other imaging artifact. This paper presents an image segmentation approach using Modified Fuzzy C-Means (FCM) algorithm and Fuzzy Possibilistic c-means algorithm (FPCM). This approach is a generalized version of standard Fuzzy CMeans Clustering (FCM) algorithm. The limitation of the conventional FCM technique is eliminated in modifying the standard technique. The Modified FCM algorithm is formulated by modifying the distance measurement of the standard FCM algorithm to permit the labeling of a pixel to be influenced by other pixels and to restrain the noise effect during segmentation. Instead of having one term in the objective function, a second term is included, forcing the membership to be as high as possible without a maximum limit constraint of one. Experiments are conducted on real images to investigate the performance of the proposed modified FCM technique in segmenting the medical images. Standard FCM, Modified FCM, Fuzzy Possibilistic CMeans algorithm (FPCM) are compared to explore the accuracy of our proposed approach.',
	 'authors': u'M. Gomathi, P.Thangaraj,',
	 'category': u'Computer Science ',
	 'date': '2010-4-11',
	 'pdflink': u'http://arxiv.org/pdf/1004.1768',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nA New Approach to Lung Image Segmentation using Fuzzy Possibilistic  C-Means Algorithm',
	 'urllink': u'http://arxiv.org/abs/1004.1768'}
2015-03-24 03:55:39+0000 [xxu46_1] INFO: Crawled 255 pages (at 1 pages/min), scraped 249 items (at 1 items/min)
2015-03-24 03:56:39+0000 [xxu46_1] INFO: Crawled 255 pages (at 0 pages/min), scraped 249 items (at 0 items/min)
2015-03-24 03:57:09+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1581> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 03:57:09+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1581>
	{'abstract': u'In this paper we build upon the recent observation that the 802.11 rate region is log-convex and, for the first time, characterise max-min fair rate allocations for a large class of 802.11 wireless mesh networks. By exploiting features of the 802.11e/n MAC, in particular TXOP packet bursting, we are able to use this characterisation to establish a straightforward, practically implementable approach for achieving max-min throughput fairness. We demonstrate that this approach can be readily extended to encompass time-based fairness in multi-rate 802.11 mesh networks.',
	 'authors': u'Douglas J. Leith, Qizhi Cao, Vijay G. Subramanian,',
	 'category': u'Computer Science ',
	 'date': '2010-2-8',
	 'pdflink': u'http://arxiv.org/pdf/1002.1581',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nMax-min Fairness in 802.11 Mesh Networks',
	 'urllink': u'http://arxiv.org/abs/1002.1581'}
2015-03-24 03:57:39+0000 [xxu46_1] INFO: Crawled 256 pages (at 1 pages/min), scraped 250 items (at 1 items/min)
2015-03-24 03:58:39+0000 [xxu46_1] INFO: Crawled 256 pages (at 0 pages/min), scraped 250 items (at 0 items/min)
2015-03-24 03:58:39+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1757> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 03:58:39+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1757>
	{'abstract': u'The objective of this paper is to implement the Active Network based Active Queue Management Technique for providing Quality of Service (QoS) using Network Processor(NP) based router to enhance multimedia applications. The performance is evaluated using Intel IXP2400 NP Simulator. The results demonstrate that, Active Network based Active Queue Management has better performance than RED algorithm in case of congestion and is well suited to achieve high speed packet classification to support multimedia applications with minimum delay and Queue loss. Using simulation, we show that the proposed system can provide assurance for prioritized flows with improved network utilization where bandwidth is shared among the flows according to the levels of priority. We first analyze the feasibility and optimality of the load distribution schemes and then present separate solutions for non-delay sensitive streams and delay-sensitive streams. Rigorous simulations and experiments have been carried out to evaluate the performance.',
	 'authors': u'N. Saravana Selvam, S. Radhakrishnan,',
	 'category': u'Computer Science ',
	 'date': '2010-4-11',
	 'pdflink': u'http://arxiv.org/pdf/1004.1757',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nProcessor Based Active Queue Management for providing QoS in Multimedia  Application',
	 'urllink': u'http://arxiv.org/abs/1004.1757'}
2015-03-24 03:59:39+0000 [xxu46_1] INFO: Crawled 257 pages (at 1 pages/min), scraped 251 items (at 1 items/min)
2015-03-24 03:59:41+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1559> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 03:59:41+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1559>
	{'abstract': u'A new negative result for nonparametric estimation of binary ergodic processes is shown. I The problem of estimation of distribution with any degree of accuracy is studied. Then it is shown that for any countable class of estimators there is a zero-entropy binary ergodic process that is inconsistent with the class of estimators. Our result is different from other negative results for universal forecasting scheme of ergodic processes.',
	 'authors': u'Hayato Takahashi,',
	 'category': u'Computer Science ',
	 'date': '2010-2-8',
	 'pdflink': u'http://arxiv.org/pdf/1002.1559',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nComputational limits to nonparametric estimation for ergodic processes',
	 'urllink': u'http://arxiv.org/abs/1002.1559'}
2015-03-24 04:00:39+0000 [xxu46_1] INFO: Crawled 258 pages (at 1 pages/min), scraped 252 items (at 1 items/min)
2015-03-24 04:00:56+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1752> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 04:00:56+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1752>
	{'abstract': u'One-point codes on the Hermitian curve produce long codes with excellent parameters. Feng and Rao introduced a modified construction that improves the parameters while still using one-point divisors. A separate improvement of the parameters was introduced by Matthews considering the classical construction but with two-point divisors. Those two approaches are combined to describe an elementary construction of two-point improved codes. Upon analysis of their minimum distance and redundancy, it is observed that they improve on the previous constructions for a large range of designed distances.',
	 'authors': u'Iwan Duursma, Radoslav Kirov,',
	 'category': u'Computer Science ',
	 'date': '2010-4-10',
	 'pdflink': u'http://arxiv.org/pdf/1004.1752',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nImproved Two-Point Codes on Hermitian Curves',
	 'urllink': u'http://arxiv.org/abs/1004.1752'}
2015-03-24 04:01:39+0000 [xxu46_1] INFO: Crawled 259 pages (at 1 pages/min), scraped 253 items (at 1 items/min)
2015-03-24 04:02:26+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1549> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 04:02:26+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1549>
	{'abstract': u'Parser generators generate translators from language specifications. In many cases, such specifications contain semantic actions written in the same language as the generated code. Since these actions are subject to little static checking, they are usually a source of errors which are discovered only when generated code is compiled. In this paper we propose a parser generator front-end which statically checks semantic actions for typing errors and prevents such errors from appearing in generated code. The type checking procedure is extensible to support many implementation languages. An extension for Java is presented along with an extension for declarative type system descriptions.',
	 'authors': u'Andrey Breslav,',
	 'category': u'Computer Science ',
	 'date': '2010-2-8',
	 'pdflink': u'http://arxiv.org/pdf/1002.1549',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nExtensible type checker for parser generation',
	 'urllink': u'http://arxiv.org/abs/1002.1549'}
2015-03-24 04:02:39+0000 [xxu46_1] INFO: Crawled 260 pages (at 1 pages/min), scraped 254 items (at 1 items/min)
2015-03-24 04:03:39+0000 [xxu46_1] INFO: Crawled 260 pages (at 0 pages/min), scraped 254 items (at 0 items/min)
2015-03-24 04:04:09+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1749> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 04:04:09+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1749>
	{'abstract': u'The concept and existence of sphere-bound-achieving and capacity-achieving lattices has been explained on AWGN channels by Forney. LDPC lattices, introduced by Sadeghi, perform very well under iterative decoding algorithm. In this work, we focus on an ensemble of regular LDPC lattices. We produce and investigate an ensemble of LDPC lattices with known properties. It is shown that these lattices are sphere-bound-achieving and capacity-achieving. As byproducts we find the minimum distance, coding gain, kissing number and an upper bound for probability of error for this special ensemble of regular LDPC lattices.',
	 'authors': u'Mohammad-Reza Sadeghi, Amin Sakzad,',
	 'category': u'Computer Science ',
	 'date': '2010-4-10',
	 'pdflink': u'http://arxiv.org/e-print/1004.1749',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nCapacity Achieving Low Density Parity Check Lattices',
	 'urllink': u'http://arxiv.org/abs/1004.1749'}
2015-03-24 04:04:39+0000 [xxu46_1] INFO: Crawled 261 pages (at 1 pages/min), scraped 255 items (at 1 items/min)
2015-03-24 04:05:39+0000 [xxu46_1] INFO: Crawled 261 pages (at 0 pages/min), scraped 255 items (at 0 items/min)
2015-03-24 04:05:45+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1532> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 04:05:45+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1532>
	{'abstract': u'This paper has been withdrawn by the author(s) for revision.',
	 'authors': u'Chinmay S. Vaze, Mahesh K. Varanasi,',
	 'category': u'Computer Science ',
	 'date': '2010-2-8',
	 'pdflink': u'http://arxiv.org/e-print/1002.1532',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOn the scaling of feedback bits to achieve the full multiplexing gain  over the Gaussian broadcast channel using DPC',
	 'urllink': u'http://arxiv.org/abs/1002.1532'}
2015-03-24 04:06:39+0000 [xxu46_1] INFO: Crawled 262 pages (at 1 pages/min), scraped 256 items (at 1 items/min)
2015-03-24 04:07:16+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1748> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 04:07:16+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1748>
	{'abstract': u'Biometrics deal with automated methods of identifying a person or verifying the identity of a person based on physiological or behavioral characteristics. Visual cryptography is a secret sharing scheme where a secret image is encrypted into the shares which independently disclose no information about the original secret image. As biometric template are stored in the centralized database, due to security threats biometric template may be modified by attacker. If biometric template is altered authorized user will not be allowed to access the resource. To deal this issue visual cryptography schemes can be applied to secure the iris template. Visual cryptography provides great means for helping such security needs as well as extra layer of authentication.',
	 'authors': u'P.S. Revenkar, Anisa Anjum, W. Z. Gandhare,',
	 'category': u'Computer Science ',
	 'date': '2010-4-10',
	 'pdflink': u'http://arxiv.org/pdf/1004.1748',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nSecure Iris Authentication Using Visual Cryptography',
	 'urllink': u'http://arxiv.org/abs/1004.1748'}
2015-03-24 04:07:39+0000 [xxu46_1] INFO: Crawled 263 pages (at 1 pages/min), scraped 257 items (at 1 items/min)
2015-03-24 04:08:39+0000 [xxu46_1] INFO: Crawled 263 pages (at 0 pages/min), scraped 257 items (at 0 items/min)
2015-03-24 04:08:47+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1531> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 04:08:47+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1531>
	{'abstract': u'The Gaussian broadcast channel (GBC) with transmit antennas and single-antenna users is considered for the case in which the channel state information is obtained at the transmitter via a finite-rate feedback link of capacity bits per user. The throughput (i.e., the sum-rate normalized by ) of the GBC is analyzed in the limit as with . Considering the transmission strategy of zeroforcing dirty paper coding (ZFDPC), a closed-form expression for the asymptotic throughput is derived. It is observed that, even under the finite-rate feedback setting, ZFDPC achieves a significantly higher throughput than zeroforcing beamforming. Using the asymptotic throughput expression, the problem of obtaining the number of users to be selected in order to maximize the throughput is solved.',
	 'authors': u'Chinmay S. Vaze, Mahesh K. Varanasi,',
	 'category': u'Computer Science ',
	 'date': '2010-2-8',
	 'pdflink': u'http://arxiv.org/pdf/1002.1531',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nA Large-System Analysis of the Imperfect-CSIT Gaussian Broadcast Channel  with a DPC-based Transmission Strategy',
	 'urllink': u'http://arxiv.org/abs/1002.1531'}
2015-03-24 04:09:39+0000 [xxu46_1] INFO: Crawled 264 pages (at 1 pages/min), scraped 258 items (at 1 items/min)
2015-03-24 04:10:19+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1747> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 04:10:19+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1747>
	{'abstract': u'The rapidly expanding technology of mobile communication will give mobile users capability of accessing information from anywhere and any time. The wireless technology has made it possible to achieve continuous connectivity in mobile environment. When the query is specified as continuous, the requesting mobile user can obtain continuously changing result. In order to provide accurate and timely outcome to requesting mobile user, the locations of moving object has to be closely monitored. The objective of paper is to discuss the problem related to the role of personal and terminal mobility and query processing in the mobile environment.',
	 'authors': u'Samidha Dwivedi Sharma, Dr. R. S. Kasana,',
	 'category': u'Computer Science ',
	 'date': '2010-4-10',
	 'pdflink': u'http://arxiv.org/pdf/1004.1747',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nMobile Database System: Role of Mobility on the Query Processing',
	 'urllink': u'http://arxiv.org/abs/1004.1747'}
2015-03-24 04:10:39+0000 [xxu46_1] INFO: Crawled 265 pages (at 1 pages/min), scraped 259 items (at 1 items/min)
2015-03-24 04:11:19+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1530> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 04:11:19+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1530>
	{'abstract': u'This paper has been withdrawn by the author(s) for revision.',
	 'authors': u'Chinmay S. Vaze, Mahesh K. Varanasi,',
	 'category': u'Computer Science ',
	 'date': '2010-2-8',
	 'pdflink': u'http://arxiv.org/e-print/1002.1530',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nThe Degrees of Freedom Region of the MIMO Cognitive Interference Channel  with No CSIT',
	 'urllink': u'http://arxiv.org/abs/1002.1530'}
2015-03-24 04:11:39+0000 [xxu46_1] INFO: Crawled 266 pages (at 1 pages/min), scraped 260 items (at 1 items/min)
2015-03-24 04:12:39+0000 [xxu46_1] INFO: Crawled 266 pages (at 0 pages/min), scraped 260 items (at 0 items/min)
2015-03-24 04:13:03+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1746> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 04:13:03+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1746>
	{'abstract': u'After decades of engineering development and infrastructural investment, Internet connections have become commodity product in many countries, and Internet scale "cloud computing" has started to compete with traditional software business through its technological advantages and economy of scale. Cloud computing is a promising enabling technology of Internet ware Cloud Computing is termed as the next big thing in the modern corporate world. Apart from the present day software and technologies, cloud computing will have a growing impact on enterprise IT and business activities in many large organizations. This paper provides an insight to cloud computing, its impacts and discusses various issues that business organizations face while implementing cloud computing. Further, it recommends various strategies that organizations need to adopt while migrating to cloud computing. The purpose of this paper is to develop an understanding of cloud computing in the modern world and its impact on organizations and businesses. Initially the paper provides a brief description of the cloud computing model introduction and its purposes. Further it discusses various technical and non-technical issues that need to be overcome in order for the benefits of cloud computing to be realized in corporate businesses and organizations. It then provides various recommendations and strategies that businesses need to work on before stepping into new technologies.',
	 'authors': u'S Qamar, Niranjan Lal, Mrityunjay Singh,',
	 'category': u'Computer Science ',
	 'date': '2010-4-10',
	 'pdflink': u'http://arxiv.org/pdf/1004.1746',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nInternet ware cloud computing :Challenges',
	 'urllink': u'http://arxiv.org/abs/1004.1746'}
2015-03-24 04:13:39+0000 [xxu46_1] INFO: Crawled 267 pages (at 1 pages/min), scraped 261 items (at 1 items/min)
2015-03-24 04:14:39+0000 [xxu46_1] INFO: Crawled 267 pages (at 0 pages/min), scraped 261 items (at 0 items/min)
2015-03-24 04:14:41+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1496> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 04:14:41+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1496>
	{'abstract': u'In this paper we study algebraic branching programs (ABPs) with restrictions on the order and the number of reads of variables in the program. Given a permutation of variables, for a -ordered ABP (-OABP), for any directed path from source to sink, a variable can appear at most once on , and the order in which variables appear on must respect . An ABP is said to be of read , if any variable appears at most times in . Our main result pertains to the identity testing problem. Over any field and in the black-box model, i.e. given only query access to the polynomial, we have the following result: read -OABP computable polynomials can be tested in . Our next set of results investigates the computational limitations of OABPs. It is shown that any OABP computing the determinant or permanent requires size and read . We give a multilinear polynomial in variables over some specifically selected field , such that any OABP computing must read some variable at least times. We show that the elementary symmetric polynomial of degree in variables can be computed by a size read OABP, but not by a read OABP, for any . Finally, we give an example of a polynomial and two variables orders , such that can be computed by a read-once -OABP, but where any -OABP computing must read some variable at least',
	 'authors': u'Maurice Jansen, Youming Qiao, Jayalal Sarma,',
	 'category': u'Computer Science ',
	 'date': '2010-2-7',
	 'pdflink': u'http://arxiv.org/pdf/1002.1496',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nDeterministic Black-Box Identity Testing $\u03c0$-Ordered Algebraic  Branching Programs',
	 'urllink': u'http://arxiv.org/abs/1002.1496'}
2015-03-24 04:15:39+0000 [xxu46_1] INFO: Crawled 268 pages (at 1 pages/min), scraped 262 items (at 1 items/min)
2015-03-24 04:15:58+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1745> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 04:15:58+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1745>
	{'abstract': u'A few papers have been interested by the fixed switching frequency direct torque control fed by direct matrix converters, where we can find just the use of direct torque controlled space vector modulated method. In this present paper, we present an improved method used for a fixed switching frequency direct torque control (DTC) using a direct matrix converter (DMC). This method is characterized by a simple structure, a fixed switching frequency which causes minimal torque ripple and a unity input power factor. Using this strategy, we combine the direct matrix converters advantages with those of direct torque control (DTC) schemes. The used technique for constant frequency is combined with the input current space vector to create the switching table of direct matrix converter (DMC). Simulation results clearly demonstrate a better dynamic and steady state performances of the proposed method.',
	 'authors': u'Nabil Taib, Toufik Rekioua, Bruno Francois,',
	 'category': u'Computer Science ',
	 'date': '2010-4-10',
	 'pdflink': u'http://arxiv.org/pdf/1004.1745',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nAn Improved Fixed Switching Frequency Direct Torque Control of Induction  Motor Drives Fed by Direct Matrix Converter',
	 'urllink': u'http://arxiv.org/abs/1004.1745'}
2015-03-24 04:16:39+0000 [xxu46_1] INFO: Crawled 269 pages (at 1 pages/min), scraped 263 items (at 1 items/min)
2015-03-24 04:17:33+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1480> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 04:17:33+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1480>
	{'abstract': u"Adaptive control problems are notoriously difficult to solve even in the presence of plant-specific controllers. One way to by-pass the intractable computation of the optimal policy is to restate the adaptive control as the minimization of the relative entropy of a controller that ignores the true plant dynamics from an informed controller. The solution is given by the Bayesian control rule-a set of equations characterizing a stochastic adaptive controller for the class of possible plant dynamics. Here, the Bayesian control rule is applied to derive BCR-MDP, a controller to solve undiscounted Markov decision processes with finite state and action spaces and unknown dynamics. In particular, we derive a non-parametric conjugate prior distribution over the policy space that encapsulates the agent's whole relevant history and we present a Gibbs sampler to draw random policies from this distribution. Preliminary results show that BCR-MDP successfully avoids sub-optimal limit cycles due to its built-in mechanism to balance exploration versus exploitation.",
	 'authors': u'Pedro A. Ortega, Daniel A. Braun,',
	 'category': u'Computer Science ',
	 'date': '2010-2-7',
	 'pdflink': u'http://arxiv.org/pdf/1002.1480',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nA Minimum Relative Entropy Controller for Undiscounted Markov Decision  Processes',
	 'urllink': u'http://arxiv.org/abs/1002.1480'}
2015-03-24 04:17:39+0000 [xxu46_1] INFO: Crawled 270 pages (at 1 pages/min), scraped 264 items (at 1 items/min)
2015-03-24 04:18:39+0000 [xxu46_1] INFO: Crawled 270 pages (at 0 pages/min), scraped 264 items (at 0 items/min)
2015-03-24 04:18:52+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1744> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 04:18:52+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1744>
	{'abstract': u'In this paper, we have given an idea of area specification and its corresponding sensing of nodes in a dynamic network. We have applied the concept of Monte Carlo methods in this respect. We have cited certain statistical as well as artificial intelligence based techniques for realizing the position of a node. We have also applied curve fitting concept for node detection and relative verification.',
	 'authors': u'A. Kumar, P. Chakrabarti, P. Saini,',
	 'category': u'Computer Science ',
	 'date': '2010-4-10',
	 'pdflink': u'http://arxiv.org/pdf/1004.1744',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nNode inspection and analysis thereof in the light of area estimation and  curve fitting',
	 'urllink': u'http://arxiv.org/abs/1004.1744'}
2015-03-24 04:19:39+0000 [xxu46_1] INFO: Crawled 271 pages (at 1 pages/min), scraped 265 items (at 1 items/min)
2015-03-24 04:20:38+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1465> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 04:20:38+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1465>
	{'abstract': u'We consider the problem of data exchange by a group of closely-located wireless nodes. In this problem each node holds a set of packets and needs to obtain all the packets held by other nodes. Each of the nodes can broadcast the packets in its possession (or a combination thereof) via a noiseless broadcast channel of capacity one packet per channel use. The goal is to minimize the total number of transmissions needed to satisfy the demands of all the nodes, assuming that they can cooperate with each other and are fully aware of the packet sets available to other nodes. This problem arises in several practical settings, such as peer-to-peer systems and wireless data broadcast. In this paper, we establish upper and lower bounds on the optimal number of transmissions and present an efficient algorithm with provable performance guarantees. The effectiveness of our algorithms is established through numerical simulations.',
	 'authors': u'Salim El Rouayheb, Alex Sprintson, Parastoo Sadeghi,',
	 'category': u'Computer Science ',
	 'date': '2010-2-7',
	 'pdflink': u'http://arxiv.org/pdf/1002.1465',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOn Coding for Cooperative Data Exchange',
	 'urllink': u'http://arxiv.org/abs/1002.1465'}
2015-03-24 04:20:39+0000 [xxu46_1] INFO: Crawled 272 pages (at 1 pages/min), scraped 266 items (at 1 items/min)
2015-03-24 04:21:39+0000 [xxu46_1] INFO: Crawled 272 pages (at 0 pages/min), scraped 266 items (at 0 items/min)
2015-03-24 04:22:17+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1743> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 04:22:17+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1743>
	{'abstract': u'Clustering is an unsupervised learning method that constitutes a cornerstone of an intelligent data analysis process. It is used for the exploration of inter-relationships among a collection of patterns, by organizing them into homogeneous clusters. Clustering has been dynamically applied to a variety of tasks in the field of Information Retrieval (IR). Clustering has become one of the most active area of research and the development. Clustering attempts to discover the set of consequential groups where those within each group are more closely related to one another than the others assigned to different groups. The resultant clusters can provide a structure for organizing large bodies of text for efficient browsing and searching. There exists a wide variety of clustering algorithms that has been intensively studied in the clustering problem. Among the algorithms that remain the most common and effectual, the iterative optimization clustering algorithms have been demonstrated reasonable performance for clustering, e.g. the Expectation Maximization (EM) algorithm and its variants, and the well known k-means algorithm. This paper presents an analysis on how partition method clustering techniques - EM, K -means and K* Means algorithm work on heartspect dataset with below mentioned features - Purity, Entropy, CPU time, Cluster wise analysis, Mean value analysis and inter cluster distance. Thus the paper finally provides the experimental results of datasets for five clusters to strengthen the results that the quality of the behavior in clusters in EM algorithm is far better than k-means algorithm and k*means algorithm.',
	 'authors': u'G. Nathiya, S. C. Punitha, M. Punithavalli,',
	 'category': u'Computer Science ',
	 'date': '2010-4-10',
	 'pdflink': u'http://arxiv.org/pdf/1004.1743',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nAn Analytical Study on Behavior of Clusters Using K Means, EM and K*  Means Algorithm',
	 'urllink': u'http://arxiv.org/abs/1004.1743'}
2015-03-24 04:22:39+0000 [xxu46_1] INFO: Crawled 273 pages (at 1 pages/min), scraped 267 items (at 1 items/min)
2015-03-24 04:23:39+0000 [xxu46_1] INFO: Crawled 273 pages (at 0 pages/min), scraped 267 items (at 0 items/min)
2015-03-24 04:23:48+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1464> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 04:23:48+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1464>
	{'abstract': u'We show that the Parikh image of the language of an NFA with n states over an alphabet of size k can be described as a finite union of linear sets with at most k generators and total size 2^, i.e., polynomial for all fixed k &gt;= 1. Previously, it was not known whether the number of generators could be made independent of n, and best upper bounds on the total size were exponential in n. Furthermore, we give an algorithm for performing such a translation in time 2^. Our proof exploits a previously unknown connection to the theory of convex sets, and establishes a normal form theorem for semilinear sets, which is of independent interests. To complement these results, we show that our upper bounds are tight and that the results cannot be extended to context-free languages. We give four applications: (1) a new polynomial fragment of integer programming, (2) precise complexity of membership for Parikh images of NFAs, (3) an answer to an open question about polynomial PAC-learnability of semilinear sets, and (4) an optimal algorithm for LTL model checking over discrete-timed reversal-bounded counter systems.',
	 'authors': u'Anthony Widjaja To,',
	 'category': u'Computer Science ',
	 'date': '2010-2-7',
	 'pdflink': u'http://arxiv.org/pdf/1002.1464',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nParikh Images of Regular Languages: Complexity and Applications',
	 'urllink': u'http://arxiv.org/abs/1002.1464'}
2015-03-24 04:24:39+0000 [xxu46_1] INFO: Crawled 274 pages (at 1 pages/min), scraped 268 items (at 1 items/min)
2015-03-24 04:25:30+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1741> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 04:25:30+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1741>
	{'abstract': u'Stencil computations consume a major part of runtime in many scientific simulation codes. As prototypes for this class of algorithms we consider the iterative Jacobi and Gauss-Seidel smoothers and aim at highly efficient parallel implementations for cache-based multicore architectures. Temporal cache blocking is a known advanced optimization technique, which can reduce the pressure on the memory bus significantly. We apply and refine this optimization for a recently presented temporal blocking strategy designed to explicitly utilize multicore characteristics. Especially for the case of Gauss-Seidel smoothers we show that simultaneous multi-threading (SMT) can yield substantial performance improvements for our optimized algorithm.',
	 'authors': u'Jan Treibig, Gerhard Wellein, Georg Hager,',
	 'category': u'Computer Science ',
	 'date': '2010-4-10',
	 'pdflink': u'http://arxiv.org/pdf/1004.1741',
	 'subjects': u'Performance (cs.PF)',
	 'title': u'\nEfficient multicore-aware parallelization strategies for iterative  stencil computations',
	 'urllink': u'http://arxiv.org/abs/1004.1741'}
2015-03-24 04:25:39+0000 [xxu46_1] INFO: Crawled 275 pages (at 1 pages/min), scraped 269 items (at 1 items/min)
2015-03-24 04:26:39+0000 [xxu46_1] INFO: Crawled 275 pages (at 0 pages/min), scraped 269 items (at 0 items/min)
2015-03-24 04:26:44+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1456> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 04:26:44+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1456>
	{'abstract': u'Iterated regret minimization has been introduced recently by J.Y. Halpern and R. Pass in classical strategic games. For many games of interest, this new solution concept provides solutions that are judged more reasonable than solutions offered by traditional game concepts -- such as Nash equilibrium --. Although computing iterated regret on explicit matrix game is conceptually and computationally easy, nothing is known about computing the iterated regret on games whose matrices are defined implicitly using game tree, game DAG or, more generally game graphs. In this paper, we investigate iterated regret minimization for infinite duration two-player quantitative non-zero sum games played on graphs. We consider reachability objectives that are not necessarily antagonist. Edges are weighted by integers -- one for each player --, and the payoffs are defined by the sum of the weights along the paths. Depending on the class of graphs, we give either polynomial or pseudo-polynomial time algorithms to compute a strategy that minimizes the regret for a fixed player. We finally give algorithms to compute the strategies of the two players that minimize the iterated regret for trees, and for graphs with strictly positive weights only.',
	 'authors': u'Emmanuel Filiot, Tristan Le Gall, Jean-Fran\xe7ois Raskin,',
	 'category': u'Computer Science ',
	 'date': '2010-2-7',
	 'pdflink': u'http://arxiv.org/pdf/1002.1456',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nIterated Regret Minimization in Game Graphs',
	 'urllink': u'http://arxiv.org/abs/1002.1456'}
2015-03-24 04:27:39+0000 [xxu46_1] INFO: Crawled 276 pages (at 1 pages/min), scraped 270 items (at 1 items/min)
2015-03-24 04:28:17+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1736> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 04:28:17+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1736>
	{'abstract': u'We prove that there exists no algorithm to decide whether the language generated by a context-free grammar is dense with respect to the lexicographic ordering. As a corollary to this result, we show that it is undecidable whether the lexicographic orderings of the languages generated by two context-free grammars have the same order type.',
	 'authors': u'Zoltan Esik,',
	 'category': u'Computer Science ',
	 'date': '2010-4-10',
	 'pdflink': u'http://arxiv.org/pdf/1004.1736',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nAn undecidable property of context-free languages',
	 'urllink': u'http://arxiv.org/abs/1004.1736'}
2015-03-24 04:28:39+0000 [xxu46_1] INFO: Crawled 277 pages (at 1 pages/min), scraped 271 items (at 1 items/min)
2015-03-24 04:29:39+0000 [xxu46_1] INFO: Crawled 277 pages (at 0 pages/min), scraped 271 items (at 0 items/min)
2015-03-24 04:29:54+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1447> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 04:29:54+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1447>
	{'abstract': u'Active Constellation Extension (ACE) is one of techniques introduced for Peak to Average Power Ratio (PAPR) reduction for OFDM systems. In this technique, the constellation points are extended such that the PAPR is minimized but the minimum distance of the constellation points does not decrease. In this paper, an iterative ACE method is extended to spatially encoded OFDM systems. The proposed methods are such that the PAPR is reduced simultaneously at all antennas, while the spatial encoding relationships still hold. It will be shown that the original ACE method can be employed before Space Time Block Coding (STBC). But in case of Space Frequency Block Coding (SFBC), two modified techniques have been proposed. In the first method, the OFDM frame is separated by several subframes and the ACE method is applied to these subframes independently to reduce their corresponding PAPRs. Then the low PAPR subframes are recombined based on SFBC relationships to yield the transmitted signals from different antennas. In the second method, for each iteration, the ACE is applied to the antenna with the maximum PAPR, and the signals of the other antennas are generated from that of this antenna. Simulation results show that both algorithms converge, but the second method outperforms the first one when the number of antennas is increased.',
	 'authors': u'Mahmoud Ferdosizadeh Naeiny, Farokh Marvasti,',
	 'category': u'Computer Science ',
	 'date': '2010-2-7',
	 'pdflink': u'http://arxiv.org/pdf/1002.1447',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nPAPR reduction of space-time and space-frequency coded OFDM systems  using active constellation extension',
	 'urllink': u'http://arxiv.org/abs/1002.1447'}
2015-03-24 04:30:39+0000 [xxu46_1] INFO: Crawled 278 pages (at 1 pages/min), scraped 272 items (at 1 items/min)
2015-03-24 04:31:33+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1729> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 04:31:33+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1729>
	{'abstract': u'Breadth First Search (BFS) and other graph traversal techniques are widely used for measuring large unknown graphs, such as online social networks. It has been empirically observed that an incomplete BFS is biased toward high degree nodes. In contrast to more studied sampling techniques, such as random walks, the precise bias of BFS has not been characterized to date. In this paper, we quantify the degree bias of BFS sampling. In particular, we calculate the node degree distribution expected to be observed by BFS as a function of the fraction of covered nodes, in a random graph with a given degree distribution . Furthermore, we also show that, for , all commonly used graph traversal techniques (BFS, DFS, Forest Fire, and Snowball Sampling) lead to the same bias, and we show how to correct for this bias. To give a broader perspective, we compare this class of exploration techniques to random walks that are well-studied and easier to analyze. Next, we study by simulation the effect of graph properties not captured directly by our model. We find that the bias gets amplified in graphs with strong positive assortativity. Finally, we demonstrate the above results by sampling the Facebook social network, and we provide some practical guidelines for graph sampling in practice.',
	 'authors': u'Maciej Kurant, Athina Markopoulou, Patrick Thiran,',
	 'category': u'Computer Science ',
	 'date': '2010-4-10',
	 'pdflink': u'http://arxiv.org/pdf/1004.1729',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nOn the bias of BFS',
	 'urllink': u'http://arxiv.org/abs/1004.1729'}
2015-03-24 04:31:39+0000 [xxu46_1] INFO: Crawled 279 pages (at 1 pages/min), scraped 273 items (at 1 items/min)
2015-03-24 04:32:39+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1446> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 04:32:39+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1446>
	{'abstract': u'Directed information theory deals with communication channels with feedback. When applied to networks, a natural extension based on causal conditioning is needed. We show here that measures built from directed information theory in networks can be used to assess Granger causality graphs of stochastic processes. We show that directed information theory includes measures such as the transfer entropy, and that it is the adequate information theoretic framework needed for neuroscience applications, such as connectivity inference problems.',
	 'authors': u'P.O. Amblard, O.J.J. Michel,',
	 'category': u'Computer Science ',
	 'date': '2010-2-7',
	 'pdflink': u'http://arxiv.org/pdf/1002.1446',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOn directed information theory and Granger causality graphs',
	 'urllink': u'http://arxiv.org/abs/1002.1446'}
2015-03-24 04:32:39+0000 [xxu46_1] INFO: Crawled 280 pages (at 1 pages/min), scraped 274 items (at 1 items/min)
2015-03-24 04:33:39+0000 [xxu46_1] INFO: Crawled 280 pages (at 0 pages/min), scraped 274 items (at 0 items/min)
2015-03-24 04:34:12+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1708> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 04:34:12+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1708>
	{'abstract': u'Mathematics has many useful properties for developing of complex software systems. One is that it can exactly describe a physical situation of the object or outcome of an action. Mathematics support abstraction and this is an excellent medium for modeling, since it is an exact medium there is a little possibility of ambiguity. This paper demonstrates that mathematics provides a high level of validation when it is used as a software medium. It also outlines distinguishing characteristics of structural testing which is based on the source code of the program tested. Structural testing methods are very amenable to rigorous definition, mathematical analysis and precise measurement. Finally, it also discusses functional and structural testing debate to have a sense of complete testing. Any program can be considered to be a function in the sense that program input forms its domain and program outputs form its range. In general discrete mathematics is more applicable to functional testing, while graph theory pertains more to structural testing.',
	 'authors': u'Manoranjan Kumar Singh, Rakesh. L,',
	 'category': u'Computer Science ',
	 'date': '2010-4-10',
	 'pdflink': u'http://arxiv.org/pdf/1004.1708',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nMathematical Principles in Software Quality Engineering',
	 'urllink': u'http://arxiv.org/abs/1004.1708'}
2015-03-24 04:34:39+0000 [xxu46_1] INFO: Crawled 281 pages (at 1 pages/min), scraped 275 items (at 1 items/min)
2015-03-24 04:35:39+0000 [xxu46_1] INFO: Crawled 281 pages (at 0 pages/min), scraped 275 items (at 0 items/min)
2015-03-24 04:35:48+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1443> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 04:35:48+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1443>
	{'abstract': u'Visibly pushdown transducers form a subclass of pushdown transducers that (strictly) extends finite state transducers with a stack. Like visibly pushdown automata, the input symbols determine the stack operations. In this paper, we prove that functionality is decidable in PSpace for visibly pushdown transducers. The proof is done via a pumping argument: if a word with two outputs has a sufficiently large nesting depth, there exists a nested word with two outputs whose nesting depth is strictly smaller. The proof uses technics of word combinatorics. As a consequence of decidability of functionality, we also show that equivalence of functional visibly pushdown transducers is Exptime-Complete.',
	 'authors': u'Emmanuel Filiot, Jean-Fran\xe7ois Raskin, Pierre-Alain Reynier, Fr\xe9d\xe9ric Servais, Jean-Marc Talbot,',
	 'category': u'Computer Science ',
	 'date': '2010-2-7',
	 'pdflink': u'http://arxiv.org/pdf/1002.1443',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nOn Functionality of Visibly Pushdown Transducers',
	 'urllink': u'http://arxiv.org/abs/1002.1443'}
2015-03-24 04:36:39+0000 [xxu46_1] INFO: Crawled 282 pages (at 1 pages/min), scraped 276 items (at 1 items/min)
2015-03-24 04:37:23+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1707> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 04:37:23+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1707>
	{'abstract': u'As wireless communication systems look intently to compose the transition from voice communication to interactive Internet data, achieving higher bit rates becomes both increasingly desirable and challenging. Space-time coding (STC) is a communications technique for wireless systems that inhabit multiple transmit antennas and single or multiple receive antennas. Space-time codes make use of advantage of both the spatial diversity provided by multiple antennas and the temporal diversity available with time-varying fading. Space-time codes can be divided into block codes and trellis codes. Space-time trellis coding merges signal processing at the receiver with coding techniques appropriate to multiple transmit antennas. The advantages of space-time codes (STC) make it extremely remarkable for high-rate wireless applications. Initial STC research efforts focused on narrowband flat-fading channels. The decoding complexity of Space-time turbo codes STTC increases exponentially as a function of the diversity level and transmission rate. This proposed paper provides an over view on various techniques used for the design of space-time turbo codes. This paper also discusses the techniques handled by researchers to built encoder and decoder section for multiple transmits and receives antennas. In addition the future enhancement gives a general idea for improvement and development of various codes which will involve implementing viterbi decoder with soft decoding in a multi-antenna scenario. In addition the space-time code may be analyzed using some of the available metrics and finally to simulate it for different receive antenna configurations.',
	 'authors': u'C. V. Seshaiah, S. Nagarani,',
	 'category': u'Computer Science ',
	 'date': '2010-4-10',
	 'pdflink': u'http://arxiv.org/pdf/1004.1707',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nA Survey on Space-Time Turbo Codes',
	 'urllink': u'http://arxiv.org/abs/1004.1707'}
2015-03-24 04:37:39+0000 [xxu46_1] INFO: Crawled 283 pages (at 1 pages/min), scraped 277 items (at 1 items/min)
2015-03-24 04:38:39+0000 [xxu46_1] INFO: Crawled 283 pages (at 0 pages/min), scraped 277 items (at 0 items/min)
2015-03-24 04:38:57+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1436> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 04:38:57+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1436>
	{'abstract': u'We consider the local rank-modulation scheme in which a sliding window going over a sequence of real-valued variables induces a sequence of permutations. The local rank-modulation, as a generalization of the rank-modulation scheme, has been recently suggested as a way of storing information in flash memory. We study constant-weight Gray codes for the local rank-modulation scheme in order to simulate conventional multi-level flash cells while retaining the benefits of rank modulation. We provide necessary conditions for the existence of cyclic and cyclic optimal Gray codes. We then specifically study codes of weight 2 and upper bound their efficiency, thus proving that there are no such asymptotically-optimal cyclic codes. In contrast, we study codes of weight 3 and efficiently construct codes which are asymptotically-optimal.',
	 'authors': u'Moshe Schwartz,',
	 'category': u'Computer Science ',
	 'date': '2010-2-7',
	 'pdflink': u'http://arxiv.org/pdf/1002.1436',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nConstant-Weight Gray Codes for Local Rank Modulation',
	 'urllink': u'http://arxiv.org/abs/1002.1436'}
2015-03-24 04:39:39+0000 [xxu46_1] INFO: Crawled 284 pages (at 1 pages/min), scraped 278 items (at 1 items/min)
2015-03-24 04:40:34+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1706> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 04:40:34+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1706>
	{'abstract': u'Due to mobility in Ad-Hoc network the topology of the network may change randomly, rapidly and unexpectedly, because of these aspects, the routes in the network often disappear and new to arise. To avoid frequent route discovery and route failure EAOMDV was proposed based on existing routing protocol AOMDV. The EAOMDV (Enhanced Ad-Hoc on Demand Multipath Distance Vector) Routing protocol was proposed to solve the "route failure" problem in AOMDV. EAOMDV protocol reduces the route failure problem by preemptively predicting the link failure by the signal power received by the receiver (pr). This proposed protocol controls overhead, increases throughput and reduces the delay. The EAOMDV protocol was implemented on NS-2 and evaluation results show that the EAOMDV outperformed AOMDV.',
	 'authors': u'Sujata V. Mallapur, Sujata Terdal,',
	 'category': u'Computer Science ',
	 'date': '2010-4-10',
	 'pdflink': u'http://arxiv.org/pdf/1004.1706',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nEnhanced Ad-Hoc on Demand Multipath Distance Vector Routing protocol',
	 'urllink': u'http://arxiv.org/abs/1004.1706'}
2015-03-24 04:40:39+0000 [xxu46_1] INFO: Crawled 285 pages (at 1 pages/min), scraped 279 items (at 1 items/min)
2015-03-24 04:41:39+0000 [xxu46_1] INFO: Crawled 285 pages (at 0 pages/min), scraped 279 items (at 0 items/min)
2015-03-24 04:41:56+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1422> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 04:41:56+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1422>
	{'abstract': u'The CLP scheme uses Horn clauses and SLD resolution to generate multiple constraint satisfaction problems (CSPs). The possible CSPs include rational trees (giving Prolog) and numerical algorithms for solving linear equations and linear programs (giving CLP(R)). In this paper we develop a form of CSP for interval constraints. In this way one obtains a logic semantics for the efficient floating-point hardware that is available on most computers. The need for the method arises because in the practice of scheduling and engineering design it is not enough to solve a single CSP. Ideally one should be able to consider thousands of CSPs and efficiently solve them or show them to be unsolvable. This is what CLP/NCSP, the new subscheme of CLP described in this paper is designed to do.',
	 'authors': u'M.H. van Emden,',
	 'category': u'Computer Science ',
	 'date': '2010-2-7',
	 'pdflink': u'http://arxiv.org/pdf/1002.1422',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nIntegrating Interval Constraints into Logic Programming',
	 'urllink': u'http://arxiv.org/abs/1002.1422'}
2015-03-24 04:42:39+0000 [xxu46_1] INFO: Crawled 286 pages (at 1 pages/min), scraped 280 items (at 1 items/min)
2015-03-24 04:43:39+0000 [xxu46_1] INFO: Crawled 286 pages (at 0 pages/min), scraped 280 items (at 0 items/min)
2015-03-24 04:43:42+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1701> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 04:43:42+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1701>
	{'abstract': u"Two papers have been archived to which this letter is complementary: 1) Opthof and Leydesdorff arxiv:1002.2769 2) Van Raan et al. arxiv:1003.2113 Van Raan at all claims that the order of operations (first dividing then adding) does not apply to citation analysis. In my contribution I discuss a few analogues in Physics and Medicine and argue that in no other field of science where quantities have physical or financial meaning, implying that that numbers have a real unit of measure, it would be allowed to ignore the rule of operations. Hence, the claim of CWTS that the order of operations is not relevant brings studies ignoring this rule as done by CWTS in the category 'Pseudo Science'.",
	 'authors': u'Jos AE Spaan,',
	 'category': u'Computer Science ',
	 'date': '2010-4-10',
	 'pdflink': u'http://arxiv.org/pdf/1004.1701',
	 'subjects': u'Digital Libraries (cs.DL)',
	 'title': u'\nThe danger of pseudo science in Informetrics',
	 'urllink': u'http://arxiv.org/abs/1004.1701'}
2015-03-24 04:44:39+0000 [xxu46_1] INFO: Crawled 287 pages (at 1 pages/min), scraped 281 items (at 1 items/min)
2015-03-24 04:44:44+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1408> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 04:44:44+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1408>
	{'abstract': u'The Second International Workshop on Programming Language Approaches to Concurrency and Communication-cEntric Software (PLACES) was co-located with ETAPS 2009 in the city of York, England. The workshop took place on Sunday 22nd March 2009. The workshop focused on the challenges raised by the changing landscape of computer software. Traditionally, most software was written for a single computer with one CPU. However applications on the web today are built using numerous interacting services deployed on across many machines; soon off-the-shelf CPUs will host thousands of cores, and sensor networks will be composed from a large number of processing units. Many normal applications will soon need to make effective use of thousands of computing nodes. At some level of granularity, computation in such systems will be inherently concurrent and communication-centred. The development of effective programming methodologies for the coming computing paradigm demands exploration and understanding of a wide variety of ideas and techniques. This workshop offered a forum where researchers from different fields could exchange new ideas on one of the central challenges for programming in the near future, the development of programming methodologies and infrastructures where concurrency and distribution are the norm rather than a marginal concern.',
	 'authors': u'Alastair R. Beresford, Simon Gay,',
	 'category': u'Computer Science ',
	 'date': '2010-2-6',
	 'pdflink': u'http://arxiv.org/html/1002.1408',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nProceedings Second International Workshop on Programming Language  Approaches to Concurrency and Communication-cEntric Software',
	 'urllink': u'http://arxiv.org/abs/1002.1408'}
2015-03-24 04:45:39+0000 [xxu46_1] INFO: Crawled 288 pages (at 1 pages/min), scraped 282 items (at 1 items/min)
2015-03-24 04:46:11+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1686> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 04:46:11+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1686>
	{'abstract': u"The paper presents new clustering algorithm. The proposed algorithm gives less distortion as compared to well known Linde Buzo Gray (LBG) algorithm and Kekre's Proportionate Error (KPE) Algorithm. Constant error is added every time to split the clusters in LBG, resulting in formation of cluster in one direction which is 1350 in 2-dimensional case. Because of this reason clustering is inefficient resulting in high MSE in LBG. To overcome this drawback of LBG proportionate error is added to change the cluster orientation in KPE. Though the cluster orientation in KPE is changed its variation is limited to +/- 450 over 1350. The proposed algorithm takes care of this problem by introducing new orientation every time to split the clusters. The proposed method reduces PSNR by 2db to 5db for codebook size 128 to 1024 with respect to LBG.",
	 'authors': u'H. B. Kekre, Tanuja K. Sarode,',
	 'category': u'Computer Science ',
	 'date': '2010-4-10',
	 'pdflink': u'http://arxiv.org/pdf/1004.1686',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nNew Clustering Algorithm for Vector Quantization using Rotation of Error  Vector',
	 'urllink': u'http://arxiv.org/abs/1004.1686'}
2015-03-24 04:46:39+0000 [xxu46_1] INFO: Crawled 289 pages (at 1 pages/min), scraped 283 items (at 1 items/min)
2015-03-24 04:47:39+0000 [xxu46_1] INFO: Crawled 289 pages (at 0 pages/min), scraped 283 items (at 0 items/min)
2015-03-24 04:47:42+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1407> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 04:47:42+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1407>
	{'abstract': u'Coding over subsets (known as generations) rather than over all content blocks in P2P distribution networks and other applications is necessary for a number of practical reasons such as computational complexity. A penalty for coding only within generations is an overall throughput reduction. It has been previously shown that allowing contiguous generations to overlap in a head-to-toe manner improves the throughput. We here propose and study a scheme, referred to as the , that creates shared packets between any two generations at random rather than only the neighboring ones. By optimizing very few design parameters, we obtain a simple scheme that outperforms both the non-overlapping and the head-to-toe overlapping schemes of comparable computational complexity, both in the expected throughput and in the rate of convergence of the probability of decoding failure to zero. We provide a practical algorithm for accurate analysis of the expected throughput of the random annex code for finite-length information. This algorithm enables us to quantify the throughput vs.computational complexity tradeoff, which is necessary for optimal selection of the scheme parameters.',
	 'authors': u'Yao Li, Emina Soljanin, Predrag Spasojevic,',
	 'category': u'Computer Science ',
	 'date': '2010-2-6',
	 'pdflink': u'http://arxiv.org/pdf/1002.1407',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nCollecting Coded Coupons over Overlapping Generations',
	 'urllink': u'http://arxiv.org/abs/1002.1407'}
2015-03-24 04:48:39+0000 [xxu46_1] INFO: Crawled 290 pages (at 1 pages/min), scraped 284 items (at 1 items/min)
2015-03-24 04:48:40+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1683> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 04:48:40+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1683>
	{'abstract': u"In our proposed model, the route selection is a function of following parameters: hop count, trust level of node and security level of application. In this paper, to focus on secure neighbor detection, trust factor evaluation, operational mode, route discovery and route selection. The paper mainly address the security of geographic routing. The watchdog identifies misbehaving nodes, while the Pathselector avoids routing packets through these nodes. The watchdog, the pathselector is run by each server. In order to keep the source informed about the destination's mobility, the destination keeps sending the alert message to its previous hop telling that it has changed its position and any reference to it for data packet forwarding be informed to the VHR server.",
	 'authors': u'Sudhakar Sengan, S.Chenthur Pandian,',
	 'category': u'Computer Science ',
	 'date': '2010-4-10',
	 'pdflink': u'http://arxiv.org/pdf/1004.1683',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nEnhanced Authentication and Locality Aided - Destination Mobility in  Dynamic Routing Protocol for MANET',
	 'urllink': u'http://arxiv.org/abs/1004.1683'}
2015-03-24 04:49:39+0000 [xxu46_1] INFO: Crawled 291 pages (at 1 pages/min), scraped 285 items (at 1 items/min)
2015-03-24 04:50:26+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1406> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 04:50:26+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1406>
	{'abstract': u"To reduce computational complexity and delay in randomized network coded content distribution (and for some other practical reasons), coding is not performed simultaneously over all content blocks but over much smaller subsets known as generations. A penalty is throughput reduction. We model coding over generations as the coupon collector's brotherhood problem. This model enables us to theoretically compute the expected number of coded packets needed for successful decoding of the entire content, as well as a bound on the probability of decoding failure, and further, to quantify the tradeoff between computational complexity and throughput. Interestingly, with a moderate increase in the generation size, throughput quickly approaches link capacity. As an additional contribution, we derive new results for the generalized collector's brotherhood problem which can also be used for further study of many other aspects of coding over generations.",
	 'authors': u'Yao Li, Emina Soljanin, Predrag Spasojevic,',
	 'category': u'Computer Science ',
	 'date': '2010-2-6',
	 'pdflink': u'http://arxiv.org/pdf/1002.1406',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nCollecting Coded Coupons over Generations',
	 'urllink': u'http://arxiv.org/abs/1002.1406'}
2015-03-24 04:50:39+0000 [xxu46_1] INFO: Crawled 292 pages (at 1 pages/min), scraped 286 items (at 1 items/min)
2015-03-24 04:51:39+0000 [xxu46_1] INFO: Crawled 292 pages (at 0 pages/min), scraped 286 items (at 0 items/min)
2015-03-24 04:51:54+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1682> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 04:51:54+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1682>
	{'abstract': u"...The steganography scheme makes it possible to hide the medical image in different bit locations of host media without inviting suspicion. The Secret file is embedded in a cover media with a key. At the receiving end the key can be derived by all the classes which are higher in the hierarchy using symmetric polynomial and the medical image file can be retrieved. The system is implemented and found to be secure, fast and scalable. Simulation results show that the system is dynamic in nature and allows any type of hierarchy. The proposed approach performs better even during frequent member joins and leaves. The computation cost is reduced as the same algorithm is used for key computation and descendant key derivation. Steganographic technique used in this paper does not use the conventional LSB's and uses two bit positions and the hidden data occurs only from a frame which is dictated by the key that is used. Hence the quality of stego data is improved.",
	 'authors': u'J.Nafeesa Begum, K. Kumar, V. Sumathy,',
	 'category': u'Computer Science ',
	 'date': '2010-4-10',
	 'pdflink': u'http://arxiv.org/pdf/1004.1682',
	 'subjects': u'Multimedia (cs.MM)',
	 'title': u'\nDesign And Implementation Of Multilevel Access Control In Medical Image  Transmission Using Symmetric Polynomial Based Audio Steganography',
	 'urllink': u'http://arxiv.org/abs/1004.1682'}
2015-03-24 04:52:39+0000 [xxu46_1] INFO: Crawled 293 pages (at 1 pages/min), scraped 287 items (at 1 items/min)
2015-03-24 04:52:44+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1363> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 04:52:44+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1363>
	{'abstract': u"We consider the computational complexity of pure Nash equilibria in graphical games. It is known that the problem is NP-complete in general, but tractable (i.e., in P) for special classes of graphs such as those with bounded treewidth. It is then natural to ask: is it possible to characterize all tractable classes of graphs for this problem? In this work, we provide such a characterization for the case of bounded in-degree graphs, thereby resolving the gap between existing hardness and tractability results. In particular, we analyze the complexity of PUREGG(C, -), the problem of deciding the existence of pure Nash equilibria in graphical games whose underlying graphs are restricted to class C. We prove that, under reasonable complexity theoretic assumptions, for every recursively enumerable class C of directed graphs with bounded in-degree, PUREGG(C, -) is in polynomial time if and only if the reduced graphs (the graphs resulting from iterated removal of sinks) of C have bounded treewidth. We also give a characterization for PURECHG(C,-), the problem of deciding the existence of pure Nash equilibria in colored hypergraphical games, a game representation that can express the additional structure that some of the players have identical local utility functions. We show that the tractable classes of bounded-arity colored hypergraphical games are precisely those whose reduced graphs have bounded treewidth modulo homomorphic equivalence. Our proofs make novel use of Grohe's characterization of the complexity of homomorphism problems.",
	 'authors': u'Albert Xin Jiang, MohammadAli Safari,',
	 'category': u'Computer Science ',
	 'date': '2010-2-6',
	 'pdflink': u'http://arxiv.org/pdf/1002.1363',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nPure Nash Equilibria: Complete Characterization of Hard and Easy  Graphical Games',
	 'urllink': u'http://arxiv.org/abs/1002.1363'}
2015-03-24 04:53:39+0000 [xxu46_1] INFO: Crawled 294 pages (at 1 pages/min), scraped 288 items (at 1 items/min)
2015-03-24 04:54:27+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1680> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 04:54:27+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1680>
	{'abstract': u"We present magneto-hydrodynamic simulation results for heterogeneous systems. Heterogeneous architectures combine high floating point performance many-core units hosted in conventional server nodes. Examples include Graphics Processing Units (GPU's) and Cell. They have potentially large gains in performance, at modest power and monetary cost. We implemented a magneto-hydrodynamic (MHD) simulation code on a variety of heterogeneous and multi-core architectures --- multi-core x86, Cell, Nvidia and ATI GPU --- in different languages, FORTRAN, C, Cell, CUDA and OpenCL. We present initial performance results for these systems. To our knowledge, this is the widest comparison of heterogeneous systems for MHD simulations. We review the different challenges faced in each architecture, and potential bottlenecks. We conclude that substantial gains in performance over traditional systems are possible, and in particular that is possible to extract a greater percentage of peak theoretical performance from some systems when compared to x86 architectures.",
	 'authors': u'Bijia Pang, Ue-li Pen, Michael Perrone,',
	 'category': u'Computer Science ',
	 'date': '2010-4-10',
	 'pdflink': u'http://arxiv.org/pdf/1004.1680',
	 'subjects': u'Performance (cs.PF)',
	 'title': u'\nMagnetohydrodynamics on Heterogeneous architectures: a performance  comparison',
	 'urllink': u'http://arxiv.org/abs/1004.1680'}
2015-03-24 04:54:39+0000 [xxu46_1] INFO: Crawled 295 pages (at 1 pages/min), scraped 289 items (at 1 items/min)
2015-03-24 04:55:34+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1347> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 04:55:34+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1347>
	{'abstract': u'The problem of private information "leakage" (inadvertently or by malicious design) from the myriad large centralized searchable data repositories drives the need for an analytical framework that quantifies unequivocally how safe private data can be (privacy) while still providing useful benefit (utility) to multiple legitimate information consumers. Rate distortion theory is shown to be a natural choice to develop such a framework which includes the following: modeling of data sources, developing application independent utility and privacy metrics, quantifying utility-privacy tradeoffs irrespective of the type of data sources or the methods of providing privacy, developing a side-information model for dealing with questions of external knowledge, and studying a successive disclosure problem for multiple query data sources.',
	 'authors': u'Lalitha Sankar, S. Raj Rajagopalan, H. Vincent Poor,',
	 'category': u'Computer Science ',
	 'date': '2010-2-6',
	 'pdflink': u'http://arxiv.org/pdf/1002.1347',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nUtility and Privacy of Data Sources: Can Shannon Help Conceal and Reveal  Information?',
	 'urllink': u'http://arxiv.org/abs/1002.1347'}
2015-03-24 04:55:39+0000 [xxu46_1] INFO: Crawled 296 pages (at 1 pages/min), scraped 290 items (at 1 items/min)
2015-03-24 04:56:39+0000 [xxu46_1] INFO: Crawled 296 pages (at 0 pages/min), scraped 290 items (at 0 items/min)
2015-03-24 04:57:16+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1679> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 04:57:16+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1679>
	{'abstract': u'Medical image segmentation demands an efficient and robust segmentation algorithm against noise. The conventional fuzzy c-means algorithm is an efficient clustering algorithm that is used in medical image segmentation. But FCM is highly vulnerable to noise since it uses only intensity values for clustering the images. This paper aims to develop a novel and efficient fuzzy spatial c-means clustering algorithm which is robust to noise. The proposed clustering algorithm uses fuzzy spatial information to calculate membership value. The input image is clustered using proposed ISFCM algorithm. A comparative study has been made between the conventional FCM and proposed ISFCM. The proposed approach is found to be outperforming the conventional FCM.',
	 'authors': u'S. Zulaikha Beevi, M. Mohammed Sathik, K. Senthamaraikannan,',
	 'category': u'Computer Science ',
	 'date': '2010-4-10',
	 'pdflink': u'http://arxiv.org/pdf/1004.1679',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nA Robust Fuzzy Clustering Technique with Spatial Neighborhood  Information for Effective Medical Image Segmentation',
	 'urllink': u'http://arxiv.org/abs/1004.1679'}
2015-03-24 04:57:39+0000 [xxu46_1] INFO: Crawled 297 pages (at 1 pages/min), scraped 291 items (at 1 items/min)
2015-03-24 04:58:27+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1337> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 04:58:28+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1337>
	{'abstract': u'In this paper, we characterize the information-theoretic capacity scaling of wireless ad hoc networks with randomly distributed nodes. By using an exact channel model from Maxwell\'s equations, we successfully resolve the conflict in the literature between the linear capacity scaling by "zg "r et al. and the degrees of freedom limit given as the ratio of the network diameter and the wavelength by Franceschetti et al. In dense networks where the network area is fixed, the capacity scaling is given as the minimum of and the degrees of freedom limit to within an arbitrarily small exponent. In extended networks where the network area is linear in , the capacity scaling is given as the minimum of and the degrees of freedom limit to within an arbitrarily small exponent. Hence, we recover the linear capacity scaling by "zg "r et al. if in dense networks and if in extended networks. Otherwise, the capacity scaling is given as the degrees of freedom limit characterized by Franceschetti et al. For achievability, a modified hierarchical cooperation is proposed based on a lower bound on the capacity of multiple-input multiple-output channel between two node clusters using our channel model.',
	 'authors': u'Si-Hyeon Lee, Sae-Young Chung,',
	 'category': u'Computer Science ',
	 'date': '2010-2-6',
	 'pdflink': u'http://arxiv.org/pdf/1002.1337',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nCapacity Scaling of Wireless Ad Hoc Networks: Shannon Meets Maxwell',
	 'urllink': u'http://arxiv.org/abs/1002.1337'}
2015-03-24 04:58:39+0000 [xxu46_1] INFO: Crawled 298 pages (at 1 pages/min), scraped 292 items (at 1 items/min)
2015-03-24 04:59:37+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1678> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 04:59:37+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1678>
	{'abstract': u"The applications of Wireless Sensor Networks (WSN) contain a wide variety of scenarios. In most of them, the network is composed of a significant number of nodes deployed in an extensive area in which not all nodes are directly connected. Then, the data exchange is supported by multihop communications. Routing protocols are in charge of discovering and maintaining the routes in the network. However, the correctness of a particular routing protocol mainly depends on the capabilities of the nodes and on the application requirements. This paper presents a dynamic discover routing method for communication between sensor nodes and a base station in WSN. This method tolerates failures of arbitrary individual nodes in the network (node failure) or a small part of the network (area failure). Each node in the network does only local routing preservation, needs to record only its neighbor nodes' information, and incurs no extra routing overhead during failure free periods. It dynamically discovers new routes when an intermediate node or a small part of the network in the path from a sensor node to a base station fails. In our planned method, every node decides its path based only on local information, such as its parent node and neighbor nodes' routing information. So, it is possible to form a loop in the routing path. We believe that the loop problem in sensor network routing is not as serious as that in the Internet routing or traditional mobile ad-hoc routing. We are trying to find all possible loops and eliminate the loops as far as possible in WSN.",
	 'authors': u'Arabinda Nanda, Amiya Kumar Rath, Saroj Kumar Rout,',
	 'category': u'Computer Science ',
	 'date': '2010-4-10',
	 'pdflink': u'http://arxiv.org/pdf/1004.1678',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nNode Sensing & Dynamic Discovering Routes for Wireless Sensor Networks',
	 'urllink': u'http://arxiv.org/abs/1004.1678'}
2015-03-24 04:59:39+0000 [xxu46_1] INFO: Crawled 299 pages (at 1 pages/min), scraped 293 items (at 1 items/min)
2015-03-24 05:00:39+0000 [xxu46_1] INFO: Crawled 299 pages (at 0 pages/min), scraped 293 items (at 0 items/min)
2015-03-24 05:00:56+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1335> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 05:00:56+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1335>
	{'abstract': u'We study the spread of influence in a social network based on the Linear Threshold model. We derive an analytical expression for evaluating the expected size of the eventual influenced set for a given initial set, using the probability of activation for each node in the social network. We then provide an equivalent interpretation for the influence spread, in terms of acyclic path probabilities in the Markov chain obtained by reversing the edges in the social network influence graph. We use some properties of such acyclic path probabilities to provide an alternate proof for the submodularity of the influence function. We illustrate the usefulness of the analytical expression in estimating the most influential set, in special cases such as the UILT(Uniform Influence Linear Threshold), USLT(Uniform Susceptance Linear Threshold) and node-degree based influence models. We show that the PageRank heuristic is either provably optimal or performs very well in the above models, and explore its limitations in more general cases. Finally, based on the insights obtained from the analytical expressions, we provide an efficient algorithm which approximates the greedy algorithm for the influence maximization problem.',
	 'authors': u'Srinivasan Venkatramanan, Anurag Kumar,',
	 'category': u'Computer Science ',
	 'date': '2010-2-6',
	 'pdflink': u'http://arxiv.org/pdf/1002.1335',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nNew Insights from an Analysis of Social Influence Networks under the  Linear Threshold Model',
	 'urllink': u'http://arxiv.org/abs/1002.1335'}
2015-03-24 05:01:39+0000 [xxu46_1] INFO: Crawled 300 pages (at 1 pages/min), scraped 294 items (at 1 items/min)
2015-03-24 05:02:39+0000 [xxu46_1] INFO: Crawled 300 pages (at 0 pages/min), scraped 294 items (at 0 items/min)
2015-03-24 05:02:42+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1677> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 05:02:42+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1677>
	{'abstract': u"Association rule mining is an active data mining research area and most ARM algorithms cater to a centralized environment. Centralized data mining to discover useful patterns in distributed databases isn't always feasible because merging data sets from different sites incurs huge network communication costs. In this paper, an Improved algorithm based on good performance level for data mining is being proposed. In local sites, it runs the application based on the improved LMatrix algorithm, which is used to calculate local support counts. Local Site also finds a centre site to manage every message exchanged to obtain all globally frequent item sets. It also reduces the time of scan of partition database by using LMatrix which increases the performance of the algorithm. Therefore, the research is to develop a distributed algorithm for geographically distributed data sets that reduces communication costs, superior running efficiency, and stronger scalability than direct application of a sequential algorithm in distributed databases.",
	 'authors': u'J. Arokia Renjit, K. L. Shunmuganathan,',
	 'category': u'Computer Science ',
	 'date': '2010-4-10',
	 'pdflink': u'http://arxiv.org/pdf/1004.1677',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nMining The Data From Distributed Database Using An Improved Mining  Algorithm',
	 'urllink': u'http://arxiv.org/abs/1004.1677'}
2015-03-24 05:03:39+0000 [xxu46_1] INFO: Crawled 301 pages (at 1 pages/min), scraped 295 items (at 1 items/min)
2015-03-24 05:04:26+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1313> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 05:04:26+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1313>
	{'abstract': u"In this paper we study the problem of half-duplex active eavesdropping in fast fading channels. The active eavesdropper is a more powerful adversary than the classical eavesdropper. It can choose between two functional modes: eavesdropping the transmission between the legitimate parties (Ex mode), and jamming it (Jx mode) -- the active eavesdropper cannot function in full duplex mode. We consider a conservative scenario, when the active eavesdropper can choose its strategy based on the legitimate transmitter-receiver pair's strategy -- and thus the transmitter and legitimate receiver have to plan for the worst. We show that conventional physical-layer secrecy approaches perform poorly (if at all), and we introduce a novel encoding scheme, based on very limited and unsecured feedback -- the Block-Markov Wyner (BMW) encoding scheme -- which outperforms any schemes currently available.",
	 'authors': u'George T. Amariucai, Shuangqing Wei,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1313',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nHalf-Duplex Active Eavesdropping in Fast Fading Channels: A Block-Markov  Wyner Secrecy Encoding Scheme',
	 'urllink': u'http://arxiv.org/abs/1002.1313'}
2015-03-24 05:04:39+0000 [xxu46_1] INFO: Crawled 302 pages (at 1 pages/min), scraped 296 items (at 1 items/min)
2015-03-24 05:05:30+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1676> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 05:05:30+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1676>
	{'abstract': u'As the multimedia and internet technologies are growing fast, the transmission of digital media plays an important role in communication. The various digital media like audio, video and images are being transferred through internet. There are a lot of threats for the digital data that are transferred through internet. Also, a number of security techniques have been employed to protect the data that is transferred through internet. This paper proposes a new technique for sending secret messages securely, using steganographic technique. Since the proposed system uses multiple level of security for data hiding, where the data is hidden in an image file and the stego file is again concealed in another image. Previously, the secret message is being encrypted with the encryption algorithm which ensures the achievement of high security enabled data transfer through internet.',
	 'authors': u'P. Mohan Kumar, K. L. Shunmuganathan,',
	 'category': u'Computer Science ',
	 'date': '2010-4-10',
	 'pdflink': u'http://arxiv.org/pdf/1004.1676',
	 'subjects': u'Multimedia (cs.MM)',
	 'title': u'\nA reversible high embedding capacity data hiding technique for hiding  secret data in images',
	 'urllink': u'http://arxiv.org/abs/1004.1676'}
2015-03-24 05:05:39+0000 [xxu46_1] INFO: Crawled 303 pages (at 1 pages/min), scraped 297 items (at 1 items/min)
2015-03-24 05:06:39+0000 [xxu46_1] INFO: Crawled 303 pages (at 0 pages/min), scraped 297 items (at 0 items/min)
2015-03-24 05:07:07+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1300> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 05:07:07+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1300>
	{'abstract': u'We prove that in order to communicate independent sources (this is the unicast problem) between various users over an unknown medium to within various distortion levels, it is sufficient to consider source-channel separation based architectures: architectures which first compress the sources to within the corresponding distortion levels followed by reliable communication over the unknown medium. We are reducing the problem of universal rate-distortion communication of independent sources over a network to the universal reliable communication problem over networks. This is a reductionist view. We are not solving the reliable communication problem in networks.',
	 'authors': u'Mukul Agarwal, Sanjoy Mitter,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1300',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nArchitecture for communication with a fidelity criterion in unknown  networks',
	 'urllink': u'http://arxiv.org/abs/1002.1300'}
2015-03-24 05:07:39+0000 [xxu46_1] INFO: Crawled 304 pages (at 1 pages/min), scraped 298 items (at 1 items/min)
2015-03-24 05:08:39+0000 [xxu46_1] INFO: Crawled 304 pages (at 0 pages/min), scraped 298 items (at 0 items/min)
2015-03-24 05:08:40+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1675> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 05:08:40+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1675>
	{'abstract': u'... This paper is to describe exploratory research on the design of a modular autonomous mobile robot controller. The controller incorporates a fuzzy logic [8] [9] approach for steering and speed control [37], a FL approach for ultrasound sensing and an overall expert system for guidance. The advantages of a modular system are related to portability and transportability, i.e. any vehicle can become autonomous with minimal modifications. A mobile robot test bed has been constructed in university of Cincinnati using a golf cart base. This cart has full speed control with guidance provided by a vision system and obstacle avoidance using ultrasonic sensors. The speed and steering fuzzy logic controller is supervised through a multi-axis motion controller. The obstacle avoidance system is based on a microcontroller interfaced with ultrasonic transducers. This micro-controller independently handles all timing and distance calculations and sends distance information back to the fuzzy logic controller via the serial line. This design yields a portable independent system in which high speed computer communication is not necessary. Vision guidance has been accomplished with the use of CCD cameras judging the current position of the robot.[34] [35][36] It will be generating a good image for reducing an uncertain wrong command from ground coordinate to tackle the parameter uncertainties of the system, and to obtain good WMR dynamic response.[1] Here we Apply 3D line following mythology. It transforms from 3D to 2D and also maps the image coordinates and vice versa, leading to the improved accuracy of the WMR position. ...',
	 'authors': u'Shailja Shukla, Mukesh Tiwari,',
	 'category': u'Computer Science ',
	 'date': '2010-4-10',
	 'pdflink': u'http://arxiv.org/pdf/1004.1675',
	 'subjects': u'Robotics (cs.RO)',
	 'title': u'\nFuzzy Logic of Speed and Steering Control System for Three Dimensional  Line Following of an Autonomous Vehicle',
	 'urllink': u'http://arxiv.org/abs/1004.1675'}
2015-03-24 05:09:39+0000 [xxu46_1] INFO: Crawled 305 pages (at 1 pages/min), scraped 299 items (at 1 items/min)
2015-03-24 05:10:24+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1292> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 05:10:24+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1292>
	{'abstract': u'We address in this paper a new computational biology problem that aims at understanding a mechanism that could potentially be used to genetically manipulate natural insect populations infected by inherited, intra-cellular parasitic bacteria. In this problem, that we denote by textsc, we are given a boolean matrix and the goal is to find two other boolean matrices with a minimum number of columns such that an appropriately defined operation on these matrices gives back the input. We show that this is formally equivalent to the textsc problem and derive some complexity results for our problem using this equivalence. We provide a new, fixed-parameter tractability approach for solving both that slightly improves upon a previously published algorithm for the textsc. Finally, we present experimental results where we applied some of our techniques to a real-life data set.',
	 'authors': u'Igor Nor, Danny Hermelin, Sylvain Charlat, Jan Engelstadter, Max Reuter, Olivier Duron, Marie-France Sagot,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1292',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nMod/Resc Parsimony Inference',
	 'urllink': u'http://arxiv.org/abs/1002.1292'}
2015-03-24 05:10:39+0000 [xxu46_1] INFO: Crawled 306 pages (at 1 pages/min), scraped 300 items (at 1 items/min)
2015-03-24 05:11:39+0000 [xxu46_1] INFO: Crawled 306 pages (at 0 pages/min), scraped 300 items (at 0 items/min)
2015-03-24 05:11:57+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1674> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 05:11:57+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1674>
	{'abstract': u'Heterogeneous Networks is the integration of all existing networks under a single environment with an understanding between the functional operations and also includes the ability to make use of multiple broadband transport technologies and to support generalized mobility. It is a challenging feature for Heterogeneous networks to integrate several IP-based access technologies in a seamless way. The focus of this paper is on the requirements of a mobility management scheme for multimedia real-time communication services - Mobile Video Conferencing. Nowadays, the range of available wireless access network technologies includes cellular or wide-area wireless systems, such as cellular networks (GSM/GPRS/UMTS) or Wi-Max, local area Network or personal area wireless systems, comprising for example, WLAN (802.11 a/b/g) and Bluetooth. As the mobile video conferencing is considered, the more advanced mobile terminals are capable of having more than one interface active at the same time. In addition, the heterogeneity of access technologies and also the seamless flow of information will increase in the future, making the seamless integration of the access network a key challenge for mobility management in a heterogeneous network environment. Services must be provided to the user regardless of the particular access technology and also the type of service provider or the network used.',
	 'authors': u'Adiline Macriga. T, Dr. P. Anandha Kumar,',
	 'category': u'Computer Science ',
	 'date': '2010-4-10',
	 'pdflink': u'http://arxiv.org/pdf/1004.1674',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nSeamless Data Services for Real Time Communication in a Heterogeneous  Networks using Network Tracking and Management',
	 'urllink': u'http://arxiv.org/abs/1004.1674'}
2015-03-24 05:12:39+0000 [xxu46_1] INFO: Crawled 307 pages (at 1 pages/min), scraped 301 items (at 1 items/min)
2015-03-24 05:13:39+0000 [xxu46_1] INFO: Crawled 307 pages (at 0 pages/min), scraped 301 items (at 0 items/min)
2015-03-24 05:13:39+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1290> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 05:13:39+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1290>
	{'abstract': u'We consider the regular model of formula generation in conjunctive normal form (CNF) introduced by Boufkhad et. al. We derive an upper bound on the satisfiability threshold and NAE-satisfiability threshold for regular random -SAT for any . We show that these bounds matches with the corresponding bound for the uniform model of formula generation. We derive lower bound on the threshold by applying the second moment method to the number of satisfying assignments. For large , we note that the obtained lower bounds on the threshold of a regular random formula converges to the lower bound obtained for the uniform model. Thus, we answer the question posed in cite regarding the performance of the second moment method for regular random formulas.',
	 'authors': u'Vishwambhar Rathi, Erik Aurell, Lars Rasmussen, Mikael Skoglund,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1290',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nBounds on Threshold of Regular Random $k$-SAT',
	 'urllink': u'http://arxiv.org/abs/1002.1290'}
2015-03-24 05:14:39+0000 [xxu46_1] INFO: Crawled 308 pages (at 1 pages/min), scraped 302 items (at 1 items/min)
2015-03-24 05:15:21+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1673> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 05:15:21+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1673>
	{'abstract': u"Specifying QoS properties can limit the selection of some good web services that the user will have considered; this is because the algorithm used strictly ensures that there is a match between QoS properties of the consumer with that of the available services. This is to say that, a situation may arise that some services might not have all that the user specifies but are rated high in those they have. With some tradeoffs specified in form of weight, these services will be made available to the user for consideration. This assertion is from the fact that, the user's requirements for the specified QoS properties are of varying degree i.e. he will always prefer one ahead of the other. This can be captured in form of weight i.e. the one preferred most will have the highest weight. If a consumer specifies light weight for those QoS properties that a web service is deficient in and high weight for those it has, this will minimize the difference between them. Hence the service can be returned.",
	 'authors': u'Agushaka J. O., Lawal M. M., Bagiwa, A. M., Abdullahi B. F,',
	 'category': u'Computer Science ',
	 'date': '2010-4-10',
	 'pdflink': u'http://arxiv.org/pdf/1004.1673',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nEffect of Weighting Scheme to QoS Properties in Web Service Discovery',
	 'urllink': u'http://arxiv.org/abs/1004.1673'}
2015-03-24 05:15:39+0000 [xxu46_1] INFO: Crawled 309 pages (at 1 pages/min), scraped 303 items (at 1 items/min)
2015-03-24 05:16:39+0000 [xxu46_1] INFO: Crawled 309 pages (at 0 pages/min), scraped 303 items (at 0 items/min)
2015-03-24 05:17:08+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1288> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 05:17:08+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1288>
	{'abstract': u'This paper investigates, using prior shape models and the concept of ball scale (b-scale), ways of automatically recognizing objects in 3D images without performing elaborate searches or optimization. That is, the goal is to place the model in a single shot close to the right pose (position, orientation, and scale) in a given image so that the model boundaries fall in the close vicinity of object boundaries in the image. This is achieved via the following set of key ideas: (a) A semi-automatic way of constructing a multi-object shape model assembly. (b) A novel strategy of encoding, via b-scale, the pose relationship between objects in the training images and their intensity patterns captured in b-scale images. (c) A hierarchical mechanism of positioning the model, in a one-shot way, in a given image from a knowledge of the learnt pose relationship and the b-scale image of the given image to be segmented. The evaluation results on a set of 20 routine clinical abdominal female and male CT data sets indicate the following: (1) Incorporating a large number of objects improves the recognition accuracy dramatically. (2) The recognition algorithm can be thought as a hierarchical framework such that quick replacement of the model assembly is defined as coarse recognition and delineation itself is known as finest recognition. (3) Scale yields useful information about the relationship between the model assembly and any given image such that the recognition results in a placement of the model close to the actual pose without doing any elaborate searches or optimization. (4) Effective object recognition can make delineation most accurate.',
	 'authors': u'Ulas Bagci, Jayaram K. Udupa, Xinjian Chen,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1288',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nBall-Scale Based Hierarchical Multi-Object Recognition in 3D Medical  Images',
	 'urllink': u'http://arxiv.org/abs/1002.1288'}
2015-03-24 05:17:39+0000 [xxu46_1] INFO: Crawled 310 pages (at 1 pages/min), scraped 304 items (at 1 items/min)
2015-03-24 05:18:21+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1672> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 05:18:21+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1672>
	{'abstract': u'We present a new parameterized algorithm for the problem () on undirected graphs. We approach the problem by considering a variation of it, the problem (), which finds a feedback vertex set of size that has no overlap with a given feedback vertex set of the graph . We develop an improved kernelization algorithm for and show that can be solved in polynomial time when all vertices in have degrees upper bounded by three. We then propose a new branch-and-search process on , and introduce a new branch-and-search measure. The process effectively reduces a given graph to a graph on which becomes polynomial-time solvable, and the new measure more accurately evaluates the efficiency of the process. These algorithmic and combinatorial studies enable us to develop an -time parameterized algorithm for the general problem, improving all previous algorithms for the problem.',
	 'authors': u'Yixin Cao, Jianer Chen, Yang Liu,',
	 'category': u'Computer Science ',
	 'date': '2010-4-10',
	 'pdflink': u'http://arxiv.org/pdf/1004.1672',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nOn Feedback Vertex Set: New Measure and New Structures',
	 'urllink': u'http://arxiv.org/abs/1004.1672'}
2015-03-24 05:18:39+0000 [xxu46_1] INFO: Crawled 311 pages (at 1 pages/min), scraped 305 items (at 1 items/min)
2015-03-24 05:19:26+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1285> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 05:19:26+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1285>
	{'abstract': u'Acquisition-to-acquisition signal intensity variations (non-standardness) are inherent in MR images. Standardization is a post processing method for correcting inter-subject intensity variations through transforming all images from the given image gray scale into a standard gray scale wherein similar intensities achieve similar tissue meanings. The lack of a standard image intensity scale in MRI leads to many difficulties in tissue characterizability, image display, and analysis, including image segmentation. This phenomenon has been documented well; however, effects of standardization on medical image registration have not been studied yet. In this paper, we investigate the influence of intensity standardization in registration tasks with systematic and analytic evaluations involving clinical MR images. We conducted nearly 20,000 clinical MR image registration experiments and evaluated the quality of registrations both quantitatively and qualitatively. The evaluations show that intensity variations between images degrades the accuracy of registration performance. The results imply that the accuracy of image registration not only depends on spatial and geometric similarity but also on the similarity of the intensity values for the same tissues in different images.',
	 'authors': u'Ulas Bagci, Jayaram K. Udupa, Li Bai,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1285',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nThe Influence of Intensity Standardization on Medical Image Registration',
	 'urllink': u'http://arxiv.org/abs/1002.1285'}
2015-03-24 05:19:39+0000 [xxu46_1] INFO: Crawled 312 pages (at 1 pages/min), scraped 306 items (at 1 items/min)
2015-03-24 05:20:39+0000 [xxu46_1] INFO: Crawled 312 pages (at 0 pages/min), scraped 306 items (at 0 items/min)
2015-03-24 05:21:10+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1666> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 05:21:10+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1666>
	{'abstract': u'It has been shown by Indyk and Sidiropoulos [IS07] that any graph of genus g&gt;0 can be stochastically embedded into a distribution over planar graphs with distortion 2^O(g). This bound was later improved to O(g^2) by Borradaile, Lee and Sidiropoulos [BLS09]. We give an embedding with distortion O(log g), which is asymptotically optimal. Apart from the improved distortion, another advantage of our embedding is that it can be computed in polynomial time. In contrast, the algorithm of [BLS09] requires solving an NP-hard problem. Our result implies in particular a reduction for a large class of geometric optimization problems from instances on genus-g graphs, to corresponding ones on planar graphs, with a O(log g) loss factor in the approximation guarantee.',
	 'authors': u'Anastasios Sidiropoulos,',
	 'category': u'Computer Science ',
	 'date': '2010-4-10',
	 'pdflink': u'http://arxiv.org/pdf/1004.1666',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nOptimal stochastic planarization',
	 'urllink': u'http://arxiv.org/abs/1004.1666'}
2015-03-24 05:21:39+0000 [xxu46_1] INFO: Crawled 313 pages (at 1 pages/min), scraped 307 items (at 1 items/min)
2015-03-24 05:22:39+0000 [xxu46_1] INFO: Crawled 313 pages (at 0 pages/min), scraped 307 items (at 0 items/min)
2015-03-24 05:22:48+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1201> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 05:22:48+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1201>
	{'abstract': u"Online communities are the gatherings of like-minded people, brought together in cyberspace by shared interests. The shared interest has hidden social capital aspects and can be of bridging or bonding type. Creating such communities is not a big challenge but sustaining member's participation is. This study examines the formation and maintenance of social capital in social network sites. In addition to assessing bonding and bridging social capital, we explore a dimension of social capital that assesses one's ability to stay connected with members of a previously inhabited community, which we call maintained social capital. Such dimension is enacted here in terms of Hypothesis.",
	 'authors': u'S. S. Phulari, S. D. Khamitkar, N. K. Deshmukh, P. U. Bhalchandra, S. N. Lokhande, A. R. Shinde,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1201',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nUnderstanding Formulation of Social Capital in Online Social Network  Sites (SNS)',
	 'urllink': u'http://arxiv.org/abs/1002.1201'}
2015-03-24 05:23:39+0000 [xxu46_1] INFO: Crawled 314 pages (at 1 pages/min), scraped 308 items (at 1 items/min)
2015-03-24 05:24:21+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1632> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 05:24:21+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1632>
	{'abstract': u'We present an empirical comparison between two normalization mechanisms for citation-based indicators of research performance. These mechanisms aim to normalize citation counts for the field and the year in which a publication was published. One mechanism is applied in the current so-called crown indicator of our institute. The other mechanism is applied in the new crown indicator that our institute is planning to adopt. We find that at high aggregation levels, such as at the level of large research institutions or at the level of countries, the differences between the two mechanisms are very small. At lower aggregation levels, such as at the level of research groups or at the level of journals, the differences between the two mechanisms are somewhat larger. We pay special attention to the way in which recent publications are handled. These publications typically have very low citation counts and should therefore be handled with special care.',
	 'authors': u'Ludo Waltman, Nees Jan van Eck, Thed N. van Leeuwen, Martijn S. Visser, Anthony F.J. van Raan,',
	 'category': u'Computer Science ',
	 'date': '2010-4-9',
	 'pdflink': u'http://arxiv.org/pdf/1004.1632',
	 'subjects': u'Digital Libraries (cs.DL)',
	 'title': u'\nTowards a new crown indicator: An empirical analysis',
	 'urllink': u'http://arxiv.org/abs/1004.1632'}
2015-03-24 05:24:39+0000 [xxu46_1] INFO: Crawled 315 pages (at 1 pages/min), scraped 309 items (at 1 items/min)
2015-03-24 05:25:39+0000 [xxu46_1] INFO: Crawled 315 pages (at 0 pages/min), scraped 309 items (at 0 items/min)
2015-03-24 05:26:00+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1200> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 05:26:00+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1200>
	{'abstract': u"A bot is a piece of software that is usually installed on an infected machine without the user's knowledge. A bot is controlled remotely by the attacker under a Command and Control structure. Recent statistics show that bots represent one of the fastest growing threats to our network by performing malicious activities such as email spamming or keylogging. However, few bot detection techniques have been developed to date. In this paper, we investigate a behavioural algorithm to detect a single bot that uses keylogging activity. Our approach involves the use of function calls analysis for the detection of the bot with a keylogging component. Correlation of the frequency of a specified time-window is performed to enhance he detection scheme. We perform a range of experiments with the spybot. Our results show that there is a high correlation between some function calls executed by this bot which indicates abnormal activity in our system.",
	 'authors': u'Yousof Al-Hammadi, Uwe Aickelin,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1200',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nDetecting Bots Based on Keylogging Activities',
	 'urllink': u'http://arxiv.org/abs/1002.1200'}
2015-03-24 05:26:39+0000 [xxu46_1] INFO: Crawled 316 pages (at 1 pages/min), scraped 310 items (at 1 items/min)
2015-03-24 05:27:37+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1614> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 05:27:37+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1614>
	{'abstract': u'Complex information extraction (IE) pipelines assembled by plumbing together off-the-shelf operators, specially customized operators, and operators re-used from other text processing pipelines are becoming an integral component of most text processing frameworks. A critical task faced by the IE pipeline user is to run a post-mortem analysis on the output. Due to the diverse nature of extraction operators (often implemented by independent groups), it is time consuming and error-prone to describe operator semantics formally or operationally to a provenance system. We introduce the first system that helps IE users analyze pipeline semantics and infer provenance interactively while debugging. This allows the effort to be proportional to the need, and to focus on the portions of the pipeline under the greatest suspicion. We present a generic debugger for running post-execution analysis of any IE pipeline consisting of arbitrary types of operators. We propose an effective provenance model for IE pipelines which captures a variety of operator types, ranging from those for which full or no specifications are available. We present a suite of algorithms to effectively build provenance and facilitate debugging. Finally, we present an extensive experimental study on large-scale real-world extractions from an index of ~500 million Web documents.',
	 'authors': u'Anish Das Sarma, Alpa Jain, Philip Bohannon,',
	 'category': u'Computer Science ',
	 'date': '2010-4-9',
	 'pdflink': u'http://arxiv.org/pdf/1004.1614',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nPROBER: Ad-Hoc Debugging of Extraction and Integration Pipelines',
	 'urllink': u'http://arxiv.org/abs/1004.1614'}
2015-03-24 05:27:39+0000 [xxu46_1] INFO: Crawled 317 pages (at 1 pages/min), scraped 311 items (at 1 items/min)
2015-03-24 05:28:39+0000 [xxu46_1] INFO: Crawled 317 pages (at 0 pages/min), scraped 311 items (at 0 items/min)
2015-03-24 05:28:52+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1199> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 05:28:52+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1199>
	{'abstract': u'Writing requirements is a two-way process. In this paper we use to classify Functional Requirements (FR) and Non Functional Requirements (NFR) statements from Software Requirements Specification (SRS) documents. This is systematically transformed into state charts considering all relevant information. The current paper outlines how test cases can be automatically generated from these state charts. The application of the states yields the different test cases as solutions to a planning problem. The test cases can be used for automated or manual software testing on system level. And also the paper presents a method for reduction of test suite by using mining methods thereby facilitating the mining and knowledge extraction from test cases.',
	 'authors': u'Lilly Raamesh, G. V. Uma,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1199',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nReliable Mining of Automatically Generated Test Cases from Software  Requirements Specification (SRS)',
	 'urllink': u'http://arxiv.org/abs/1002.1199'}
2015-03-24 05:29:39+0000 [xxu46_1] INFO: Crawled 318 pages (at 1 pages/min), scraped 312 items (at 1 items/min)
2015-03-24 05:30:14+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1588> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 05:30:14+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1588>
	{'abstract': u'We address the point-to-face approximate shortest path problem in R: Given a set of polyhedral obstacles with a total of n vertices, a source point s, an obstacle face f, and a real positive parameter epsilon, compute a path from s to f that avoids the interior of the obstacles and has length at most (1+epsilon) times the length of the shortest obstacle avoiding path from s to f. We present three approximation algorithms that take by extending three well-known "point-to-point" shortest path algorithms.',
	 'authors': u'Yam Ki Cheung, Ovidiu Daescu,',
	 'category': u'Computer Science ',
	 'date': '2010-4-9',
	 'pdflink': u'http://arxiv.org/pdf/1004.1588',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nApproximate Point-to-Face Shortest Paths in R^3',
	 'urllink': u'http://arxiv.org/abs/1004.1588'}
2015-03-24 05:30:39+0000 [xxu46_1] INFO: Crawled 319 pages (at 1 pages/min), scraped 313 items (at 1 items/min)
2015-03-24 05:31:39+0000 [xxu46_1] INFO: Crawled 319 pages (at 0 pages/min), scraped 313 items (at 0 items/min)
2015-03-24 05:31:57+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1198> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 05:31:57+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1198>
	{'abstract': u'The previous link adaptation algorithms on ofdm based systems use equal modulation order for all sub carrier index within a block. For multimedia transmission using ofdm as the modulation technique, unequal constellation is used within one ofdm subcarrier block, a set of subcarriers for audio and another set for video transmissions. A generic model has been shown for such a transmission and link adaptation algorithm has been proposed using EESM (Effective Exponential SNR mapping) method as basic method. Mathematical model has been derived for the channel based on bivariate Gaussian distribution in which the amplitude varies two dimensionally in the same envelope. From the Moment generating function of bivariate distribution, Probability of error has been theoretically derived. Results have been shown for BER performance of an ofdm system using unequal constellation. BER performances have been shown for different values of correlation parameter and fading figure.',
	 'authors': u'R. Sandanalakshmi, Athilakshmi, K. Manivannan,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1198',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nModified EESM Based Link Adaptation Algorithm for Multimedia  Transmission in Multicarrier Systems',
	 'urllink': u'http://arxiv.org/abs/1002.1198'}
2015-03-24 05:32:39+0000 [xxu46_1] INFO: Crawled 320 pages (at 1 pages/min), scraped 314 items (at 1 items/min)
2015-03-24 05:33:08+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1586> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 05:33:08+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1586>
	{'abstract': u'Message passing type algorithms such as the so-called Belief Propagation algorithm have recently gained a lot of attention in the statistics, signal processing and machine learning communities as attractive algorithms for solving a variety of optimization and inference problems. As a decentralized, easy to implement and empirically successful algorithm, BP deserves attention from the theoretical standpoint, and here not much is known at the present stage. In order to fill this gap we consider the performance of the BP algorithm in the context of the capacitated minimum-cost network flow problem - the classical problem in the operations research field. We prove that BP converges to the optimal solution in the pseudo-polynomial time, provided that the optimal solution of the underlying problem is unique and the problem input is integral. Moreover, we present a simple modification of the BP algorithm which gives a fully polynomial-time randomized approximation scheme (FPRAS) for the same problem, which no longer requires the uniqueness of the optimal solution. This is the first instance where BP is proved to have fully-polynomial running time. Our results thus provide a theoretical justification for the viability of BP as an attractive method to solve an important class of optimization problems.',
	 'authors': u'David Gamarnik, Devavrat Shah, Yehua Wei,',
	 'category': u'Computer Science ',
	 'date': '2010-4-9',
	 'pdflink': u'http://arxiv.org/pdf/1004.1586',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nBelief Propagation for Min-cost Network Flow: Convergence and  Correctness',
	 'urllink': u'http://arxiv.org/abs/1004.1586'}
2015-03-24 05:33:39+0000 [xxu46_1] INFO: Crawled 321 pages (at 1 pages/min), scraped 315 items (at 1 items/min)
2015-03-24 05:34:35+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1195> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 05:34:35+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1195>
	{'abstract': u"In a video on demand system, the main video repository may be far away from the user and generally has limited streaming capacities. Since a high quality video's size is huge, it requires high bandwidth for streaming over the internet. In order to achieve a higher video hit ratio, reduced client waiting time, distributed server's architecture can be used, in which multiple local servers are placed close to clients and, based on their regional demands video contents are cached dynamically from the main server. As the cost of proxy server is decreasing and demand for reduced waiting time is increasing day by day, newer architectures are explored, innovative schemes are arrived at. In this paper we present novel 3 layer architecture, includes main multimedia server, a Tracker and Proxy servers. This architecture targets to optimize the client waiting time. We also propose an efficient prefix caching and load sharing algorithm at the proxy server to allocate the cache according to regional popularity of the video. The simulation results demonstrate that it achieves significantly lower client's waiting time, when compared to the other existing algorithms.",
	 'authors': u'T. R. GopalaKrishnan Nair, M. Dakshayini,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1195',
	 'subjects': u'Multimedia (cs.MM)',
	 'title': u'\nStochastic Model Based Proxy Servers Architecture for VoD to Achieve  Reduced Client Waiting Time',
	 'urllink': u'http://arxiv.org/abs/1002.1195'}
2015-03-24 05:34:39+0000 [xxu46_1] INFO: Crawled 322 pages (at 1 pages/min), scraped 316 items (at 1 items/min)
2015-03-24 05:35:39+0000 [xxu46_1] INFO: Crawled 322 pages (at 0 pages/min), scraped 316 items (at 0 items/min)
2015-03-24 05:36:05+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1578> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 05:36:05+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1578>
	{'abstract': u"We introduce a new class of games called the networked common goods game (NCGG), which generalizes the well-known common goods game. We focus on a fairly general subclass of the game where each agent's utility functions are the same across all goods the agent is entitled to and satisfy certain natural properties (diminishing return and smoothness). We give a comprehensive set of technical results listed as follows. * We show the optimization problem faced by a single agent can be solved efficiently in this subclass. The discrete version of the problem is however NP-hard but admits an fully polynomial time approximation scheme (FPTAS). * We show uniqueness results of pure strategy Nash equilibrium of NCGG, and that the equilibrium is fully characterized by the structure of the network and independent of the choices and combinations of agent utility functions. * We show NCGG is a potential game, and give an implementation of best/better response Nash dynamics that lead to fast convergence to an -approximate pure strategy Nash equilibrium. * Lastly, we show the price of anarchy of NCGG can be as large as (for any ), which means selfish behavior in NCGG can lead to extremely inefficient social outcomes.",
	 'authors': u'Jinsong Tan,',
	 'category': u'Computer Science ',
	 'date': '2010-4-9',
	 'pdflink': u'http://arxiv.org/pdf/1004.1578',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nThe Networked Common Goods Game',
	 'urllink': u'http://arxiv.org/abs/1004.1578'}
2015-03-24 05:36:39+0000 [xxu46_1] INFO: Crawled 323 pages (at 1 pages/min), scraped 317 items (at 1 items/min)
2015-03-24 05:37:29+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1193> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 05:37:29+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1193>
	{'abstract': u'This study presents a comparative SWOT analysis to comprehend the pattern of development of ICT within six universities of western Himalayan region of India. With the objective of achieving quality and excellence in higher education system in the region, this study provides a basis to decision makers to exploit opportunities and minimize the external threats. The SWOT analysis of different universities, placed under three categories, has been undertaken within the four-tier framework used earlier by the authors. Guided by the initiatives of National Mission on Education through ICT (NMEICT) for SWOT analysis, findings of this paper reveal, relative consistency of these three categories of universities, with the earlier study. A few suggestions, as opportunities, with an emphasis on problem solving orientation in higher education, have been made to strengthen the leadership of universities in the field of ICT.',
	 'authors': u'Dhirendra Sharma, Vikram Singh,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1193',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nICT in Universities of the Western Himalayan Region of India II: A  Comparative SWOT Analysis',
	 'urllink': u'http://arxiv.org/abs/1002.1193'}
2015-03-24 05:37:39+0000 [xxu46_1] INFO: Crawled 324 pages (at 1 pages/min), scraped 318 items (at 1 items/min)
2015-03-24 05:38:30+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1569> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 05:38:30+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1569>
	{'abstract': u"The efficient estimation of frequency moments of a data stream in one-pass using limited space and time per item is one of the most fundamental problem in data stream processing. An especially important estimation is to find the number of distinct elements in a data stream, which is generally referred to as the zeroth frequency moment and denoted by . In this paper, we consider streams of rectangles defined over a discrete space and the task is to compute the total number of distinct points covered by the rectangles. This is known as the Klee's measure problem in 2 dimensions. We present and analyze a randomized streaming approximation algorithm which gives an -approximation of for the total area of Klee's measure problem in 2 dimensions. Our algorithm achieves the following complexity bounds: (a) the amortized processing time per rectangle is ; (b) the space complexity is bits; and (c) the time to answer a query for is , respectively. To our knowledge, this is the first streaming approximation for the Klee's measure problem that achieves sub-polynomial bounds.",
	 'authors': u'Gokarna Sharma, Costas Busch, Srikanta Tirthapura,',
	 'category': u'Computer Science ',
	 'date': '2010-4-9',
	 'pdflink': u'http://arxiv.org/e-print/1004.1569',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u"\nA Streaming Approximation Algorithm for Klee's Measure Problem",
	 'urllink': u'http://arxiv.org/abs/1004.1569'}
2015-03-24 05:38:39+0000 [xxu46_1] INFO: Crawled 325 pages (at 1 pages/min), scraped 319 items (at 1 items/min)
2015-03-24 05:39:39+0000 [xxu46_1] INFO: Crawled 325 pages (at 0 pages/min), scraped 319 items (at 0 items/min)
2015-03-24 05:39:51+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1191> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 05:39:51+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1191>
	{'abstract': u'In order to achieve fault tolerance, highly reliable system often require the ability to detect errors as soon as they occur and prevent the speared of erroneous information throughout the system. Thus, the need for codes capable of detecting and correcting byte errors are extremely important since many memory systems use b-bit-per-chip organization. Redundancy on the chip must be put to make fault-tolerant design available. This paper examined several methods of computer memory systems, and then a proposed technique is designed to choose a suitable method depending on the organization of memory systems. The constructed codes require a minimum number of check bits with respect to codes used previously, then it is optimized to fit the organization of memory systems according to the requirements for data and byte lengths.',
	 'authors': u'Muzhir Al-Ani, Qeethara Al-Shayea,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1191',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nUnidirectional Error Correcting Codes for Memory Systems: A Comparative  Study',
	 'urllink': u'http://arxiv.org/abs/1002.1191'}
2015-03-24 05:40:39+0000 [xxu46_1] INFO: Crawled 326 pages (at 1 pages/min), scraped 320 items (at 1 items/min)
2015-03-24 05:41:36+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1564> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 05:41:36+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1564>
	{'abstract': u'The problem of network coding for multicasting a single source to multiple sinks has first been studied by Ahlswede, Cai, Li and Yeung in 2000, in which they have established the celebrated max-flow mini-cut theorem on non-physical information flow over a network of independent channels. On the other hand, in 1980, Han has studied the case with correlated multiple sources and a single sink from the viewpoint of polymatroidal functions in which a necessary and sufficient condition has been demonstrated for reliable transmission over the network. This paper presents an attempt to unify both cases, which leads to establish a necessary and sufficient condition for reliable transmission over a noisy network for multicasting all the correlated multiple sources to all the multiple sinks. Furthermore, we address also the problem of transmitting "independent" sources over a multiple-access-type of network as well as over a broadcast-type of network, which reveals that the (co-) polymatroidal structures are intrinsically involved in these types of network coding.',
	 'authors': u'Te Sun Han,',
	 'category': u'Computer Science ',
	 'date': '2010-4-9',
	 'pdflink': u'http://arxiv.org/pdf/1004.1564',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nPolymatroids with Network Coding',
	 'urllink': u'http://arxiv.org/abs/1004.1564'}
2015-03-24 05:41:39+0000 [xxu46_1] INFO: Crawled 327 pages (at 1 pages/min), scraped 321 items (at 1 items/min)
2015-03-24 05:42:39+0000 [xxu46_1] INFO: Crawled 327 pages (at 0 pages/min), scraped 321 items (at 0 items/min)
2015-03-24 05:43:14+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1188> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 05:43:14+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1188>
	{'abstract': u'Software Visualization encompasses the development and evaluation of methods for graphically representing different aspects of methods of software, including its structure, execution and evolution. Creating visualizations helps the user to better understand complex phenomena. It is also found by the software engineering community that visualization is essential and important. In order to visualize the evolution of the models in Model-Driven Software Evolution, authors have proposed a framework which consists of 7 key areas (views) and 22 key features for the assessment of Model Driven Software Evolution process and addresses a number of stakeholder concerns. The framework is derived by the application of the Goal Question Metric Paradigm. This paper aims to describe an application of the framework by considering different visualization tools/CASE tools which are used to visualize the models in different views and to capture the information of models during their evolution. Comparison of such tools is also possible by using the framework.',
	 'authors': u'Akepogu Anand Rao, Karanam Madhavi,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1188',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nFramework for Visualizing Model-Driven Software Evolution and its  Application',
	 'urllink': u'http://arxiv.org/abs/1002.1188'}
2015-03-24 05:43:39+0000 [xxu46_1] INFO: Crawled 328 pages (at 1 pages/min), scraped 322 items (at 1 items/min)
2015-03-24 05:44:39+0000 [xxu46_1] INFO: Crawled 328 pages (at 0 pages/min), scraped 322 items (at 0 items/min)
2015-03-24 05:44:43+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1540> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 05:44:43+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1540>
	{'abstract': u'We present in this paper some examples of how to compute by hand the PCR5 fusion rule for three sources, so the reader will better understand its mechanism. We also take into consideration the importance of sources, which is different from the classical discounting of sources.',
	 'authors': u'Florentin Smarandache, Jean Dezert,',
	 'category': u'Computer Science ',
	 'date': '2010-4-9',
	 'pdflink': u'http://arxiv.org/pdf/1004.1540',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nImportance of Sources using the Repeated Fusion Method and the  Proportional Conflict Redistribution Rules #5 and #6',
	 'urllink': u'http://arxiv.org/abs/1004.1540'}
2015-03-24 05:45:39+0000 [xxu46_1] INFO: Crawled 329 pages (at 1 pages/min), scraped 323 items (at 1 items/min)
2015-03-24 05:46:22+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1186> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 05:46:22+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1186>
	{'abstract': u'VANETs (Vehicular Ad hoc Networks) are highly mobile wireless ad hoc networks and will play an important role in public safety communications and commercial applications. Routing of data in VANETs is a challenging task due to rapidly changing topology and high speed mobility of vehicles. Conventional routing protocols in MANETs (Mobile Ad hoc Networks) are unable to fully address the unique characteristics in vehicular networks. In this paper, we propose EBGR (Edge Node Based Greedy Routing), a reliable greedy position based routing approach to forward packets to the node present in the edge of the transmission range of source/forwarding node as most suitable next hop, with consideration of nodes moving in the direction of the destination. We propose Revival Mobility model (RMM) to evaluate the performance of our routing technique. This paper presents a detailed description of our approach and simulation results show that packet delivery ratio is improved considerably compared to other routing techniques of VANET.',
	 'authors': u'K. Prasanth, K. Duraiswamy, K. Jayasudha, C. Chandrasekar,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1186',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nEfficient Packet Forwarding Approach in Vehicular Ad Hoc Networks Using  EBGR Algorithm',
	 'urllink': u'http://arxiv.org/abs/1002.1186'}
2015-03-24 05:46:39+0000 [xxu46_1] INFO: Crawled 330 pages (at 1 pages/min), scraped 324 items (at 1 items/min)
2015-03-24 05:47:39+0000 [xxu46_1] INFO: Crawled 330 pages (at 0 pages/min), scraped 324 items (at 0 items/min)
2015-03-24 05:47:52+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1511> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 05:47:52+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1511>
	{'abstract': u'We provide bounds for codes for a non-symmetric channel or, equivalently, for ternary codes with the Manhattan distance.',
	 'authors': u'Ludo Tolhuizen,',
	 'category': u'Computer Science ',
	 'date': '2010-4-9',
	 'pdflink': u'http://arxiv.org/pdf/1004.1511',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nBounds for codes for a non-symmetric ternary channel',
	 'urllink': u'http://arxiv.org/abs/1004.1511'}
2015-03-24 05:48:39+0000 [xxu46_1] INFO: Crawled 331 pages (at 1 pages/min), scraped 325 items (at 1 items/min)
2015-03-24 05:49:20+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1185> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 05:49:20+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1185>
	{'abstract': u"There is a considerable body of work on sequence mining of Web Log Data. We are using One Pass frequent Episode discovery (or FED) algorithm, takes a different approach than the traditional apriori class of pattern detection algorithms. In this approach significant intervals for each Website are computed first (independently) and these interval used for detecting frequent patterns/Episode and then the Analysis is performed on Significant Intervals and frequent patterns That can be used to forecast the user's behavior using previous trends and this can be also used for advertising purpose. This type of applications predicts the Website interest. In this approach, time-series data are folded over a periodicity (day, week, etc.) Which are used to form the Interval? Significant intervals are discovered from these time points that satisfy the criteria of minimum confidence and maximum interval length specified by the user.",
	 'authors': u'Kanak Saxena, Rahul Shukla,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1185',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nSignificant Interval and Frequent Pattern Discovery in Web Log Data',
	 'urllink': u'http://arxiv.org/abs/1002.1185'}
2015-03-24 05:49:39+0000 [xxu46_1] INFO: Crawled 332 pages (at 1 pages/min), scraped 326 items (at 1 items/min)
2015-03-24 05:50:39+0000 [xxu46_1] INFO: Crawled 332 pages (at 0 pages/min), scraped 326 items (at 0 items/min)
2015-03-24 05:50:46+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1503> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 05:50:46+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1503>
	{'abstract': u'A new construction for constant weight codes is presented. The codes are constructed from -dimensional subspaces of the vector space . These subspaces form a constant dimension code in the Grassmannian space . Some of the constructed codes are optimal constant weight codes with parameters not known before. An efficient algorithm for error-correction is given for the constructed codes. If the constant dimension code has an efficient encoding and decoding algorithms then also the constructed constant weight code has an efficient encoding and decoding algorithms.',
	 'authors': u'Tuvi Etzion, Alexander Vardy,',
	 'category': u'Computer Science ',
	 'date': '2010-4-9',
	 'pdflink': u'http://arxiv.org/pdf/1004.1503',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nA New Construction for Constant Weight Codes',
	 'urllink': u'http://arxiv.org/abs/1004.1503'}
2015-03-24 05:51:39+0000 [xxu46_1] INFO: Crawled 333 pages (at 1 pages/min), scraped 327 items (at 1 items/min)
2015-03-24 05:51:42+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1184> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 05:51:42+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1184>
	{'abstract': u'The Application of Bio Inspired Algorithms to complicated Power System Stability Problems has recently attracted the researchers in the field of Artificial Intelligence. Low frequency oscillations after a disturbance in a Power system, if not sufficiently damped, can drive the system unstable. This paper provides a systematic procedure to damp the low frequency oscillations based on Bio Inspired Genetic (GA) and Particle Swarm Optimization (PSO) algorithms. The proposed controller design is based on formulating a System Damping ratio enhancement based Optimization criterion to compute the optimal controller parameters for better stability. The Novel and contrasting feature of this work is the mathematical modeling and simulation of the Synchronous generator model including the Steam Governor Turbine (GT) dynamics. To show the robustness of the proposed controller, Non linear Time domain simulations have been carried out under various system operating conditions. Also, a detailed Comparative study has been done to show the superiority of the Bio inspired algorithm based controllers over the Conventional Lead lag controller.',
	 'authors': u'R. Shivakumar, R. Lakshmipathi,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1184',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nImplementation of an Innovative Bio Inspired GA and PSO Algorithm for  Controller design considering Steam GT Dynamics',
	 'urllink': u'http://arxiv.org/abs/1002.1184'}
2015-03-24 05:52:39+0000 [xxu46_1] INFO: Crawled 334 pages (at 1 pages/min), scraped 328 items (at 1 items/min)
2015-03-24 05:53:06+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1485> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 05:53:06+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1485>
	{'abstract': u'Several different measures for digraph width have appeared in the last few years. However, none of them shares all the "nice" properties of treewidth: First, being emph i.e. admitting polynomial-time algorithms for all -definable problems on digraphs of bounded width. And, second, having nice emph i.e. being monotone under taking subdigraphs and some form of arc contractions. As for the former, (undirected) seems to be the least common denominator of all reasonably expressive logical languages on digraphs that can speak about the edge/arc relation on the vertex set.The latter property is a necessary condition for a width measure to be characterizable by some version of the cops-and-robber game characterizing the ordinary treewidth. Our main result is that emph algorithmically useful and structurally nice digraph measure cannot be substantially different from the treewidth of the underlying undirected graph. Moreover, we introduce emph and argue that they are the weakest useful notion of minors for digraphs.',
	 'authors': u'Robert Ganian, Petr Hlin\u011bn\xfd, Joachim Kneis, Daniel Meister, Jan Obdr\u017e\xe1lek, Peter Rossmanith, Somnath Sikdar,',
	 'category': u'Computer Science ',
	 'date': '2010-4-9',
	 'pdflink': u'http://arxiv.org/pdf/1004.1485',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nAre there any good digraph width measures?',
	 'urllink': u'http://arxiv.org/abs/1004.1485'}
2015-03-24 05:53:39+0000 [xxu46_1] INFO: Crawled 335 pages (at 1 pages/min), scraped 329 items (at 1 items/min)
2015-03-24 05:54:39+0000 [xxu46_1] INFO: Crawled 335 pages (at 0 pages/min), scraped 329 items (at 0 items/min)
2015-03-24 05:54:42+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5444> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 05:54:42+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5444>
	{'abstract': u"Algorithmic historiography was proposed by Eugene Garfield in collaboration with Irving Sher in the 1960s, but further developed only recently into HistCite^ with Alexander Pudovkin. As in history writing, HistCite^ reconstructs by drawing intellectual lineages. In addition to cited references, however, documents can be attributed a multitude of other variables such as title words, keywords, journal names, author names, and even full texts. New developments in multidimensional scaling (MDS) enable us not only to visualize these patterns at each moment of time, but also to animate them over time. Using title words, co-authors, and journal names in Garfield's oeuvre, the method is demonstrated and further developed in this paper (and in the animation at this http URL). The variety and substantive content of the animation enables us to write, visualize, and animate the author's intellectual history.",
	 'authors': u'Loet Leydesdorff,',
	 'category': u'Computer Science ',
	 'date': '2010-5-29',
	 'pdflink': u'http://arxiv.org/pdf/1005.5444',
	 'subjects': u'Digital Libraries (cs.DL)',
	 'title': u'\nEugene Garfield and Algorithmic Historiography: Co-Words, Co-Authors,  and Journal Names',
	 'urllink': u'http://arxiv.org/abs/1005.5444'}
2015-03-24 05:55:39+0000 [xxu46_1] INFO: Crawled 336 pages (at 1 pages/min), scraped 330 items (at 1 items/min)
2015-03-24 05:56:17+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1181> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 05:56:17+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1181>
	{'abstract': u'Recently, the academic community has been giving much attention to Cooperative Learning System, a group learning method combined with pedagogy and social psychology. It allows group members to gain knowledge through collaborations and interactions. Nowadays, most Internet cooperative learning systems are designed to provide students mainly with a convenient online environment to study theoretical courses but rarely with an online environment to operate practical instruments. Hence, this paper designed a 3D online cooperative learning system for operating virtual instruments with circuit-measuring function. By integrating with Virtual Reality, Remote Control Parameter Transmission and embedded system techniques, this system gives learners not only a cooperative learning environment via networking to jointly operate the 3D virtual instruments (for example, multi-meters, power supplies and oscilloscopes) but also the functions of instant messages and 3D puzzles to interact with one another. Therefore, learners can effectively improve learning interests and results.',
	 'authors': u'Fu-Chien Kao, Siang-Ru Wang, Ting-Hao Huang,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1181',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nThe Design of Circuit-Measuring Collaborative Learning System with  Embedded Broker',
	 'urllink': u'http://arxiv.org/abs/1002.1181'}
2015-03-24 05:56:39+0000 [xxu46_1] INFO: Crawled 337 pages (at 1 pages/min), scraped 331 items (at 1 items/min)
2015-03-24 05:57:21+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1472> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 05:57:21+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1472>
	{'abstract': u'In this paper, we present a method and a tool to build symbolic labelled transition systems from B specifications. The tool, called GeneSyst, can take into account refinement levels and can visualize the decomposition of abstract states in concrete hierarchical states. The resulting symbolic transition system represents all the behaviors of the initial B event system. So, it can be used to reason about them. We illustrate the use of GeneSyst to check security properties on a model of electronic purse.',
	 'authors': u'Didier Bert, Marie-Laure Potet, Nicolas Stouls,',
	 'category': u'Computer Science ',
	 'date': '2010-4-9',
	 'pdflink': u'http://arxiv.org/pdf/1004.1472',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nGeneSyst: a Tool to Reason about Behavioral Aspects of B Event  Specifications. Application to Security Properties.',
	 'urllink': u'http://arxiv.org/abs/1004.1472'}
2015-03-24 05:57:39+0000 [xxu46_1] INFO: Crawled 338 pages (at 1 pages/min), scraped 332 items (at 1 items/min)
2015-03-24 05:58:39+0000 [xxu46_1] INFO: Crawled 338 pages (at 0 pages/min), scraped 332 items (at 0 items/min)
2015-03-24 05:58:53+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5440> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 05:58:53+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5440>
	{'abstract': u"Coordinated checkpointing is an effective fault tolerant technique in distributed system as it avoids the domino effect and require minimum storage requirement. Most of the earlier coordinated checkpoint algorithms block their computation during checkpointing and forces minimum-process or non-blocking but forces all nodes to takes checkpoint even though many of them may not be necessary or non-blocking minimum-process but takes useless checkpoints or reduced useless checkpoint but has higher synchronization message overhead or has high checkpoint request propagation time. Hence in mobile distributed systems there is a great need of minimizing the number of communication message and checkpointing overhead as it raise new issues such as mobility, low bandwidth of wireless channels, frequently disconnections, limited battery power and lack of reliable stable storage on mobile nodes. In this paper, we propose a minimum-process coordinated checkpointing algorithm for mobile distributed system where no useless checkpoints are taken, no blocking of processes takes place and enforces a minimum-number of processes to take checkpoints. Our algorithm imposes low memory and computation overheads on MH's and low communication overheads on wireless channels. It avoids awakening of an MH if it is not required to take its checkpoint and has reduced latency time as each process involved in a global checkpoint can forward its own decision directly to the checkpoint initiator.",
	 'authors': u'Surender Kumar, R.K.Chauhan, Parveen Kumar,',
	 'category': u'Computer Science ',
	 'date': '2010-5-29',
	 'pdflink': u'http://arxiv.org/pdf/1005.5440',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nA Low Overhead Minimum Process Global Snapshop Collection Algorithm for  Mobile Distributed System',
	 'urllink': u'http://arxiv.org/abs/1005.5440'}
2015-03-24 05:59:39+0000 [xxu46_1] INFO: Crawled 339 pages (at 1 pages/min), scraped 333 items (at 1 items/min)
2015-03-24 06:00:26+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1179> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 06:00:26+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1179>
	{'abstract': u"RFID is not a new technology and has passed through many decades of use in military, airline, library, security, healthcare, sports, animal farms and other areas. Industries use RFID for various applications such as personal/vehicle access control, departmental store security, equipment tracking, baggage, fast food establishments, logistics, etc. The enhancement in RFID technology has brought advantages that are related to resource optimization, increased efficiency within business processes, and enhanced customer care, overall improvements in business operations and healthcare. Our research is part of a big project; its aim is to produce a model for mobile technology implementation of hospital patients' movement process. However, the focus of this paper is to explore the main RFID components, i.e. the tag, antenna and reader. The results of the investigations conducted on the three RFID components will be used to develop our research model.",
	 'authors': u'Kamran Ahsan, Hanifa Shah, Paul Kingston,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1179',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nRFID Applications: An Introductory and Exploratory Study',
	 'urllink': u'http://arxiv.org/abs/1002.1179'}
2015-03-24 06:00:39+0000 [xxu46_1] INFO: Crawled 340 pages (at 1 pages/min), scraped 334 items (at 1 items/min)
2015-03-24 06:01:39+0000 [xxu46_1] INFO: Crawled 340 pages (at 0 pages/min), scraped 334 items (at 0 items/min)
2015-03-24 06:02:10+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1461> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 06:02:10+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1461>
	{'abstract': u"Privacy of users in P2P networks goes far beyond their current usage and is a fundamental requirement to the adoption of P2P protocols for legal usage. In a climate of cold war between these users and anti-piracy groups, more and more users are moving to anonymizing networks in an attempt to hide their identity. However, when not designed to protect users information, a P2P protocol would leak information that may compromise the identity of its users. In this paper, we first present three attacks targeting BitTorrent users on top of Tor that reveal their real IP addresses. In a second step, we analyze the Tor usage by BitTorrent users and compare it to its usage outside of Tor. Finally, we depict the risks induced by this de-anonymization and show that users' privacy violation goes beyond BitTorrent traffic and contaminates other protocols such as HTTP.",
	 'authors': u'Pere Manils, Chaabane Abdelberri, Stevens Le Blond, Mohamed Ali Kaafar, Claude Castelluccia, Arnaud Legout, Walid Dabbous,',
	 'category': u'Computer Science ',
	 'date': '2010-4-9',
	 'pdflink': u'http://arxiv.org/pdf/1004.1461',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nCompromising Tor Anonymity Exploiting P2P Information Leakage',
	 'urllink': u'http://arxiv.org/abs/1004.1461'}
2015-03-24 06:02:39+0000 [xxu46_1] INFO: Crawled 341 pages (at 1 pages/min), scraped 335 items (at 1 items/min)
2015-03-24 06:03:38+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5439> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 06:03:38+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5439>
	{'abstract': u'Wireless Capsule Endoscopy (WCE) is device to detect abnormalities in colon,esophagus,small intestinal and stomach, to distinguish bleeding in WCE images from non bleeding is a hard job by human reviewing and very time consuming. Consequently, automation for classifying bleeding frames not only will expedite the process but will reduce the burden on the doctors. Using the purity of the red color we can detect the Bleeding areas in WCE images. But, we could find various intensity of red color values in different parts of the small intestinal,so it is not enough to depend on the red color feature alone. We select RGB(Red,Green,Blue) because it takes raw level values and it is easy to use. In this paper we will put range ratio color for each of R,G,and B. Therefore, we divide each image into multiple pixels and apply the range ratio color condition for each pixel. Then we count the number of the pixels that achieved our condition. If the number of pixels grater than zero, then the frame is classified as a bleeding type. Otherwise, it is a non-bleeding. Our experimental results show that this method could achieve a very high accuracy in detecting bleeding images for the different parts of the small intestinal',
	 'authors': u'Amer A. Al-Rahayfeh, Abdelshakour A. Abuzneid,',
	 'category': u'Computer Science ',
	 'date': '2010-5-29',
	 'pdflink': u'http://arxiv.org/pdf/1005.5439',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nDetection of Bleeding in Wireless Capsule Endoscopy Images Using Range  Ratio Color',
	 'urllink': u'http://arxiv.org/abs/1005.5439'}
2015-03-24 06:03:39+0000 [xxu46_1] INFO: Crawled 342 pages (at 1 pages/min), scraped 336 items (at 1 items/min)
2015-03-24 06:04:39+0000 [xxu46_1] INFO: Crawled 342 pages (at 0 pages/min), scraped 336 items (at 0 items/min)
2015-03-24 06:05:02+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1178> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 06:05:02+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1178>
	{'abstract': u'Today, SIP is a protocol par Excellence in the field of communication over Internet. But, the fact that it belongs to the application layer constitutes a weakness vis-a-vis the NAT traversal. This weakness is due to the way in which the server replies to the requests of clients on the one hand. On the other, it is caused by the dynamic allocation of UDP ports for emission and reception of packets RTP/RTCP. The TURN Protocol may face this weakness. However, its use requires a certain number of exchanges between the clients and a TURN server before establishing the multimedia sessions and this increase the latent time. In this article, we propose to adapt TURN protocol for applications based on SIP protocol such as telephony over Internet, conference video, etc. This adaptation optimises the establishment of multimedia sessions by integrating a manager of TCP connections and multimedia flow controller into SIP Proxy server.',
	 'authors': u'Mustapha Guezouri, Ahmed Blaha, Mokhtar Keche,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1178',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nAdaptation of TURN protocol to SIP protocol',
	 'urllink': u'http://arxiv.org/abs/1002.1178'}
2015-03-24 06:05:39+0000 [xxu46_1] INFO: Crawled 343 pages (at 1 pages/min), scraped 337 items (at 1 items/min)
2015-03-24 06:06:14+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1460> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 06:06:14+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1460>
	{'abstract': u'In the area of networks, a common method to enforce a security policy expressed in a high-level language is based on an ad-hoc and manual rewriting process. We argue that it is possible to build a formal link between concrete and abstract terms, which can be dynamically computed from the environment data. In order to progressively introduce configuration data and then simplify the proof obligations, we use the B refinement process. We present a case study modeling a network monitor. This program, described by refinement following the layers of the TCP/IP suite protocol, has to warn for all observed events which do not respect the security policy. To design this model, we use the event-B method because it is suitable for modeling network concepts. This work has been done within the framework of the POTESTAT project, based on the research of network testing methods from a high-level security policy.',
	 'authors': u'Nicolas Stouls, Marie-Laure Potet,',
	 'category': u'Computer Science ',
	 'date': '2010-4-9',
	 'pdflink': u'http://arxiv.org/pdf/1004.1460',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nSecurity Policy Enforcement Through Refinement Process',
	 'urllink': u'http://arxiv.org/abs/1004.1460'}
2015-03-24 06:06:39+0000 [xxu46_1] INFO: Crawled 344 pages (at 1 pages/min), scraped 338 items (at 1 items/min)
2015-03-24 06:07:39+0000 [xxu46_1] INFO: Crawled 344 pages (at 0 pages/min), scraped 338 items (at 0 items/min)
2015-03-24 06:07:45+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5438> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 06:07:45+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5438>
	{'abstract': u'Sharing musical files via the Internet was the essential motivation of early P2P systems. Despite of the great success of the P2P file sharing systems, these systems support only "simple" queries. The focus in such systems is how to carry out an efficient query routing in order to find the nodes storing a desired file. Recently, several research works have been made to extend P2P systems to be able to share data having a fine granularity (i.e. atomic attribute) and to process queries written with a highly expressive language (i.e. SQL). These works have led to the emergence of P2P data sharing systems that represent a new generation of P2P systems and, on the other hand, a next stage in a long period of the database research area. ? The characteristics of P2P systems (e.g. large-scale, node autonomy and instability) make impractical to have a global catalog that represents often an essential component in traditional database systems. Usually, such a catalog stores information about data, schemas and data sources. Query routing and processing are two problems affected by the absence of a global catalog. Locating relevant data sources and generating a close to optimal execution plan become more difficult. In this paper, we concentrate our study on proposed solutions for the both problems. Furthermore, selected case studies of main P2P data sharing systems are analyzed and compared.',
	 'authors': u'Raddad Al King, Abdelkader Hameurlain, Franck Morvan,',
	 'category': u'Computer Science ',
	 'date': '2010-5-29',
	 'pdflink': u'http://arxiv.org/pdf/1005.5438',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nQuery Routing and Processing in Peer-To-Peer Data Sharing Systems',
	 'urllink': u'http://arxiv.org/abs/1005.5438'}
2015-03-24 06:08:39+0000 [xxu46_1] INFO: Crawled 345 pages (at 1 pages/min), scraped 339 items (at 1 items/min)
2015-03-24 06:09:22+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1176> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 06:09:22+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1176>
	{'abstract': u'This paper describes a new method for the synthesis of planar antenna arrays using fuzzy genetic algorithms (FGAs) by optimizing phase excitation coefficients to best meet a desired radiation pattern. We present the application of a rigorous optimization technique based on fuzzy genetic algorithms (FGAs), the optimizing algorithm is obtained by adjusting control parameters of a standard version of genetic algorithm (SGAs) using a fuzzy controller (FLC) depending on the best individual fitness and the population diversity measurements (PDM). The presented optimization algorithms were previously checked on specific mathematical test function and show their superior capabilities with respect to the standard version (SGAs). A planar array with rectangular cells using a probe feed is considered. Included example using FGA demonstrates the good agreement between the desired and calculated radiation patterns than those obtained by a SGA.',
	 'authors': u'Boufeldja Kadri, Miloud Boussahla, Fethi Tarik Bendimerad,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1176',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nPhase-Only Planar Antenna Array Synthesis with Fuzzy Genetic Algorithms',
	 'urllink': u'http://arxiv.org/abs/1002.1176'}
2015-03-24 06:09:39+0000 [xxu46_1] INFO: Crawled 346 pages (at 1 pages/min), scraped 340 items (at 1 items/min)
2015-03-24 06:10:39+0000 [xxu46_1] INFO: Crawled 346 pages (at 0 pages/min), scraped 340 items (at 0 items/min)
2015-03-24 06:11:06+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1449> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 06:11:06+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1449>
	{'abstract': u'We exhibit incentive compatible multi-unit auctions that are not affine maximizers (i.e., are not of the VCG family) and yet approximate the social welfare to within a factor of . For the case of two-item two-bidder auctions we show that these auctions, termed Triage auctions, are the only scalable ones that give an approximation factor better than 2. "Scalable" means that the allocation does not depend on the units in which the valuations are measured. We deduce from this that any scalable computationally-efficient incentive-compatible auction for items and bidders cannot approximate the social welfare to within a factor better than 2. This is in contrast to arbitrarily good approximations that can be reached under computational constraints alone, and in contrast to the fact that the optimal social welfare can be obtained under incentive constraints alone.',
	 'authors': u'Shahar Dobzinski, Noam Nisan,',
	 'category': u'Computer Science ',
	 'date': '2010-4-9',
	 'pdflink': u'http://arxiv.org/pdf/1004.1449',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nMulti-Unit Auctions: Beyond Roberts',
	 'urllink': u'http://arxiv.org/abs/1004.1449'}
2015-03-24 06:11:39+0000 [xxu46_1] INFO: Crawled 347 pages (at 1 pages/min), scraped 341 items (at 1 items/min)
2015-03-24 06:12:39+0000 [xxu46_1] INFO: Crawled 347 pages (at 0 pages/min), scraped 341 items (at 0 items/min)
2015-03-24 06:12:46+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5437> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 06:12:46+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5437>
	{'abstract': u'Content Based Image Retrieval (CBIR) systems based on shape using invariant image moments, viz., Moment Invariants (MI) and Zernike Moments (ZM) are available in the literature. MI and ZM are good at representing the shape features of an image. However, non-orthogonality of MI and poor reconstruction of ZM restrict their application in CBIR. Therefore, an efficient and orthogonal moment based CBIR system is needed. Legendre Moments (LM) are orthogonal, computationally faster, and can represent image shape features compactly. CBIR system using Exact Legendre Moments (ELM) for gray scale images is proposed in this work. Superiority of the proposed CBIR system is observed over other moment based methods, viz., MI and ZM in terms of retrieval efficiency and retrieval time. Further, the classification efficiency is improved by employing Support Vector Machine (SVM) classifier. Improved retrieval results are obtained over existing CBIR algorithm based on Stacked Euler Vector (SERVE) combined with Modified Moment Invariants (MMI).',
	 'authors': u'Ch.Srinivasa Rao, S.Srinivas Kumar, B.Chandra Mohan,',
	 'category': u'Computer Science ',
	 'date': '2010-5-29',
	 'pdflink': u'http://arxiv.org/pdf/1005.5437',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nContent Based Image Retrieval Using Exact Legendre Moments and Support  Vector Machine',
	 'urllink': u'http://arxiv.org/abs/1005.5437'}
2015-03-24 06:13:39+0000 [xxu46_1] INFO: Crawled 348 pages (at 1 pages/min), scraped 342 items (at 1 items/min)
2015-03-24 06:14:21+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1174> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 06:14:21+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1174>
	{'abstract': u'In last few decades large technology development raised various new needs. Financial sector has also no exception. People are approaching all over the world to fulfill there dreams. Any sector needs to understand changing need of customer. In order to satisfy financial need for customer banks are taking help of new technology such as internet. Only problem remain is of security. The aim of this work is to provide a secure environment in terms of security for transaction by various ways. In order to improve security we are making use of "Steganography" technique in the way never used before. Task of enhancing security include construction of formula for both data encryption and also for hiding pattern. Server should not process any fake request hence concept of custom "Session id" and "Request id" is introduced. Implementation of such a security constraints in banking sector not only help to serve customer in better way but also make customer confident and satisfy.',
	 'authors': u'Geeta S. Navale, Swati S. Joshi, Aaradhana A. Deshmukh,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1174',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nM-Banking Security - a futuristic improved security approach',
	 'urllink': u'http://arxiv.org/abs/1002.1174'}
2015-03-24 06:14:39+0000 [xxu46_1] INFO: Crawled 349 pages (at 1 pages/min), scraped 343 items (at 1 items/min)
2015-03-24 06:15:39+0000 [xxu46_1] INFO: Crawled 349 pages (at 0 pages/min), scraped 343 items (at 0 items/min)
2015-03-24 06:15:43+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1437> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 06:15:43+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1437>
	{'abstract': u"The primal-dual scheme has been used to provide approximation algorithms for many problems. Goemans and Williamson gave a (2-1/(n-1))-approximation for the Prize-Collecting Steiner Tree Problem that runs in O(n^3 log n) time. it applies the primal-dual scheme once for each of the n vertices of the graph. Johnson, Minkoff and Phillips proposed a faster implementation of Goemans and Williamson's algorithm. We give a proof that the approximation ratio of this implementation is exactly 2.",
	 'authors': u'Paulo Feofiloff, Cristina G. Fernandes, Carlos E. Ferreira, Jose Coelho de Pina,',
	 'category': u'Computer Science ',
	 'date': '2010-4-8',
	 'pdflink': u'http://arxiv.org/pdf/1004.1437',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u"\nA note on Johnson, Minkoff and Phillips' algorithm for the  Prize-Collecting Steiner Tree Problem",
	 'urllink': u'http://arxiv.org/abs/1004.1437'}
2015-03-24 06:16:39+0000 [xxu46_1] INFO: Crawled 350 pages (at 1 pages/min), scraped 344 items (at 1 items/min)
2015-03-24 06:17:05+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5436> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 06:17:05+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5436>
	{'abstract': u'In this paper, we propose an efficient client-to-client streaming approach to cooperatively stream the video using chaining technique with unicast communication among the clients. This approach considers two major issues of VoD 1) Prefix caching scheme to accommodate more number of videos closer to client, so that the request-service delay for the user can be minimized. 2) Cooperative proxy and client chaining scheme for streaming the videos using unicasting. This approach minimizes the client rejection rate and bandwidth requirement on server to proxy and proxy to client path. Our simulation results show that the proposed approach achieves reduced client waiting time and optimal prefix caching of videos minimizing server to proxy path bandwidth usage by utilizing the client to client bandwidth, which is occasionally used when compared to busy server to proxy path bandwidth.',
	 'authors': u'M. Dakshayini, T. R. Gopala Krishnan Nair,',
	 'category': u'Computer Science ',
	 'date': '2010-5-29',
	 'pdflink': u'http://arxiv.org/pdf/1005.5436',
	 'subjects': u'Multimedia (cs.MM)',
	 'title': u'\nClient-to-Client Streaming Scheme for VOD Applications',
	 'urllink': u'http://arxiv.org/abs/1005.5436'}
2015-03-24 06:17:39+0000 [xxu46_1] INFO: Crawled 351 pages (at 1 pages/min), scraped 345 items (at 1 items/min)
2015-03-24 06:18:39+0000 [xxu46_1] INFO: Crawled 351 pages (at 0 pages/min), scraped 345 items (at 0 items/min)
2015-03-24 06:18:45+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1169> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 06:18:45+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1169>
	{'abstract': u'Paper has been withdrawn due to non-compliance with IJCSI terms and conditions.',
	 'authors': u'V. N Kamalesh, S. K. Srivatsa,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/e-print/1002.1169',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nAdjacency Matrix based method to compute the node connectivity of a  Computer Communication Network',
	 'urllink': u'http://arxiv.org/abs/1002.1169'}
2015-03-24 06:19:39+0000 [xxu46_1] INFO: Crawled 352 pages (at 1 pages/min), scraped 346 items (at 1 items/min)
2015-03-24 06:20:16+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1423> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 06:20:16+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1423>
	{'abstract': u'We consider a Gaussian two-hop network where the source and the destination can communicate only via a relay node who is both an eavesdropper and a Byzantine adversary. Both the source and the destination nodes are allowed to transmit, and the relay receives a superposition of their transmitted signals. We propose a new coding scheme that satisfies two requirements simultaneously: the transmitted message must be kept secret from the relay node, and the destination must be able to detect any Byzantine attack that the relay node might launch reliably and fast. The three main components of the scheme are the nested lattice code, the privacy amplification and the algebraic manipulation detection (AMD)code. Specifically, for the Gaussian two-hop network, we show that lattice coding can successfully pair with AMD codes enabling its first application to a noisy channel model. We prove, using this new coding scheme, that the probability that the Byzantine attack goes undetected decreases exponentially fast with respect to the number of channel uses, while the loss in the secrecy rate, compared to the rate achievable when the relay is honest, can be made arbitrarily small. In addition, in contrast with prior work in Gaussian channels, the notion of secrecy provided here is strong secrecy.',
	 'authors': u'Xiang He, Aylin Yener,',
	 'category': u'Computer Science ',
	 'date': '2010-4-8',
	 'pdflink': u'http://arxiv.org/pdf/1004.1423',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nStrong Secrecy and Reliable Byzantine Detection in the Presence of an  Untrusted Relay',
	 'urllink': u'http://arxiv.org/abs/1004.1423'}
2015-03-24 06:20:39+0000 [xxu46_1] INFO: Crawled 353 pages (at 1 pages/min), scraped 347 items (at 1 items/min)
2015-03-24 06:21:39+0000 [xxu46_1] INFO: Crawled 353 pages (at 0 pages/min), scraped 347 items (at 0 items/min)
2015-03-24 06:21:58+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5435> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 06:21:58+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5435>
	{'abstract': u'Managing the transactions in real time distributed computing system is not easy, as it has heterogeneously networked computers to solve a single problem. If a transaction runs across some different sites, it may commit at some sites and may failure at another site, leading to an inconsistent transaction. The complexity is increase in real time applications by placing deadlines on the response time of the database system and transactions processing. Such a system needs to process Transactions before these deadlines expired. A series of simulation study have been performed to analyze the performance under different transaction management under conditions such as different workloads, distribution methods, execution mode-distribution and parallel etc. The scheduling of data accesses are done in order to meet their deadlines and to minimize the number of transactions that missed deadlines. A new concept is introduced to manage the transactions in dynamic ways rather than setting computing parameters in static ways. With this approach, the system gives a significant improvement in performance.',
	 'authors': u'Y. Jayanta Singh, Yumnam Somananda Singh, Ashok Gaikwad, S.C.Mehrotra,',
	 'category': u'Computer Science ',
	 'date': '2010-5-29',
	 'pdflink': u'http://arxiv.org/pdf/1005.5435',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nDynamic management of transactions in distributed real-time processing  system',
	 'urllink': u'http://arxiv.org/abs/1005.5435'}
2015-03-24 06:22:39+0000 [xxu46_1] INFO: Crawled 354 pages (at 1 pages/min), scraped 348 items (at 1 items/min)
2015-03-24 06:23:13+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1168> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 06:23:13+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1168>
	{'abstract': u'This paper presents a gradient based motion estimation algorithm based on shape-motion prediction, which takes advantage of the correlation between neighboring Binary Alpha Blocks (BABs), to match with the Mpeg-4 shape coding case and speed up the estimation process. The PSNR and computation time achieved by the proposed algorithm seem to be better than those obtained by most popular motion estimation techniques.',
	 'authors': u'F. Benboubker, F. Abdi, A. Ahaitouf,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1168',
	 'subjects': u'Multimedia (cs.MM)',
	 'title': u'\nShape-Adaptive Motion Estimation Algorithm for MPEG-4 Video Coding',
	 'urllink': u'http://arxiv.org/abs/1002.1168'}
2015-03-24 06:23:39+0000 [xxu46_1] INFO: Crawled 355 pages (at 1 pages/min), scraped 349 items (at 1 items/min)
2015-03-24 06:24:39+0000 [xxu46_1] INFO: Crawled 355 pages (at 0 pages/min), scraped 349 items (at 0 items/min)
2015-03-24 06:24:56+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1399> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 06:24:56+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1399>
	{'abstract': u'The paper makes the observation that all orders of information entropy are equal in signals composed of repeating units of distinct symbols where the units can be classified as a member of a symmetry group. This leads to an improved metric for measuring the information content of higher order entropies in data such as text, signals, or genetics and another measure of similarity to compare the incremental information content across entropy orders when comparing data of different sizes and symbol sets or when comparing entire sequences.',
	 'authors': u'Reginald D. Smith,',
	 'category': u'Computer Science ',
	 'date': '2010-4-8',
	 'pdflink': u'http://arxiv.org/e-print/1004.1399',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nA note on the entropy of repetitive sequences of symmetry group  permutations',
	 'urllink': u'http://arxiv.org/abs/1004.1399'}
2015-03-24 06:25:39+0000 [xxu46_1] INFO: Crawled 356 pages (at 1 pages/min), scraped 350 items (at 1 items/min)
2015-03-24 06:26:09+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5434> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 06:26:09+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5434>
	{'abstract': u'There have been many recent studies on sequential pattern mining. The sequential pattern mining on progressive databases is relatively very new, in which we progressively discover the sequential patterns in period of interest. Period of interest is a sliding window continuously advancing as the time goes by. As the focus of sliding window changes, the new items are added to the dataset of interest and obsolete items are removed from it and become up to date. In general, the existing proposals do not fully explore the real world scenario, such as items associated with support in data stream applications such as market basket analysis. Thus mining important knowledge from supported frequent items becomes a non trivial research issue. Our proposed novel approach efficiently mines frequent sequential pattern coupled with support using progressive mining tree.',
	 'authors': u'B.N. Keshavamurthy, Mitesh Sharma, Durga Toshniwal,',
	 'category': u'Computer Science ',
	 'date': '2010-5-29',
	 'pdflink': u'http://arxiv.org/pdf/1005.5434',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nEfficient Support Coupled Frequent Pattern Mining Over Progressive  Databases',
	 'urllink': u'http://arxiv.org/abs/1005.5434'}
2015-03-24 06:26:39+0000 [xxu46_1] INFO: Crawled 357 pages (at 1 pages/min), scraped 351 items (at 1 items/min)
2015-03-24 06:27:39+0000 [xxu46_1] INFO: Crawled 357 pages (at 0 pages/min), scraped 351 items (at 0 items/min)
2015-03-24 06:27:41+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1167> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 06:27:41+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1167>
	{'abstract': u'Geometric programming (GP) provides a power tool for solving a variety of optimization problems. In the real world, many applications of geometric programming (GP) are engineering design problems in which some of the problem parameters are estimating of actual values. This paper develops a solution procedure to solve nonlinear programming problems using GP technique by splitting the cost coefficients, constraint coefficients and exponents with the help of binary numbers. The equivalent mathematical programming problems are formulated to find their corresponding value of the objective function based on the duality theorem. The ability of calculating the cost coefficients, constraint coefficients and exponents developed in this paper might help lead to more realistic modeling efforts in engineering design areas. Standard nonlinear programming software has been used to solve the proposed optimization problem. Two numerical examples are presented to illustrate the method.',
	 'authors': u'A. K. Ojha, A. K. Das,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1167',
	 'subjects': u'Numerical Analysis (cs.NA)',
	 'title': u'\nGeometric Programming Problem with Co-Efficients and Exponents  Associated with Binary Numbers',
	 'urllink': u'http://arxiv.org/abs/1002.1167'}
2015-03-24 06:28:39+0000 [xxu46_1] INFO: Crawled 358 pages (at 1 pages/min), scraped 352 items (at 1 items/min)
2015-03-24 06:28:54+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1379> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 06:28:54+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1379>
	{'abstract': u'Index Coding has received considerable attention recently motivated in part by real-world applications and in part by its connection to Network Coding. The basic setting of Index Coding encodes the problem input as an undirected graph and the fundamental parameter is the broadcast rate , the average communication cost per bit for sufficiently long messages (i.e. the non-linear vector capacity). Recent nontrivial bounds on were derived from the study of other Index Coding capacities (e.g. the scalar capacity ) by Bar-Yossef et al (2006), Lubetzky and Stav (2007) and Alon et al (2008). However, these indirect bounds shed little light on the behavior of : there was no known polynomial-time algorithm for approximating in a general network to within a nontrivial (i.e. ) factor, and the exact value of remained unknown for any graph where Index Coding is nontrivial. Our main contribution is a direct information-theoretic analysis of the broadcast rate using linear programs, in contrast to previous approaches that compared with graph-theoretic parameters. This allows us to resolve the aforementioned two open questions. We provide a polynomial-time algorithm with a nontrivial approximation ratio for computing in a general network along with a polynomial-time decision procedure for recognizing instances with . In addition, we pinpoint precisely for various classes of graphs (e.g. for various Cayley graphs of cyclic groups) thereby simultaneously improving the previously known upper and lower bounds for these graphs. Via this approach we construct graphs where the difference between and its trivial lower bound is linear in the number of vertices and ones where is uniformly bounded while its upper bound derived from the naive encoding scheme is polynomially worse.',
	 'authors': u'Anna Blasiak, Robert Kleinberg, Eyal Lubetzky,',
	 'category': u'Computer Science ',
	 'date': '2010-4-8',
	 'pdflink': u'http://arxiv.org/pdf/1004.1379',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nIndex coding via linear programming',
	 'urllink': u'http://arxiv.org/abs/1004.1379'}
2015-03-24 06:29:39+0000 [xxu46_1] INFO: Crawled 359 pages (at 1 pages/min), scraped 353 items (at 1 items/min)
2015-03-24 06:30:28+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5433> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 06:30:28+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5433>
	{'abstract': u'Nowadays, Data Warehouse (DW) plays a crucial role in the process of decision making. However, their design remains a very delicate and difficult task either for expert or users. The goal of this paper is to propose a new approach based on the clover model, destined to assist users to design a DW. The proposed approach is based on two main steps. The first one aims to guide users in their choice of DW schema model. The second one aims to finalize the chosen model by offering to the designer views related to former successful DW design experiences.',
	 'authors': u'Nouha Arfaoui, Jalel Akaichi,',
	 'category': u'Computer Science ',
	 'date': '2010-5-29',
	 'pdflink': u'http://arxiv.org/pdf/1005.5433',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nA Data Warehouse Assistant Design System Based on Clover Model',
	 'urllink': u'http://arxiv.org/abs/1005.5433'}
2015-03-24 06:30:39+0000 [xxu46_1] INFO: Crawled 360 pages (at 1 pages/min), scraped 354 items (at 1 items/min)
2015-03-24 06:31:39+0000 [xxu46_1] INFO: Crawled 360 pages (at 0 pages/min), scraped 354 items (at 0 items/min)
2015-03-24 06:31:53+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1166> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 06:31:53+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1166>
	{'abstract': u'In this paper we have proposed a dynamic buffer allocation algorithm for the prefix, based on the popularity of the videos. More cache blocks are allocated for most popular videos and a few cache blocks are allocated for less popular videos. Buffer utilization is also maximized irrespective of the load on the Video-on-Demand system. Overload can lead the server getting slowed down. By storing the first few seconds of popular video clips, a multimedia local server can shield the users from the delay, throughput, and loss properties of the path between the local server and the central server. The key idea of controlled multicast is used to allow clients to share a segment of a video stream even when the requests arrive at different times. This dynamic buffer allocation algorithm is simulated and its performance is evaluated based on the buffer utilization by multimedia servers and average buffer allocation for the most popular videos. Our simulation results shows efficient utilization of network bandwidth and reduced hard disk utilization hence resulting in increase in the number of requests being served.',
	 'authors': u'T.R. GopalaKrishnan nair, P. Jayarekha,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1166',
	 'subjects': u'Multimedia (cs.MM)',
	 'title': u'\nA Strategy to enable Prefix of Multicast VoD through dynamic buffer  allocation',
	 'urllink': u'http://arxiv.org/abs/1002.1166'}
2015-03-24 06:32:39+0000 [xxu46_1] INFO: Crawled 361 pages (at 1 pages/min), scraped 355 items (at 1 items/min)
2015-03-24 06:33:30+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1324> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 06:33:30+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1324>
	{'abstract': u'This paper examines the problem of introducing advanced forms of fault-tolerance via reconfiguration into safety-critical avionic systems. This is required to enable increased availability after fault occurrence in distributed integrated avionic systems(compared to static federated systems). The approach taken is to identify a migration path from current architectures to those that incorporate re-configuration to a lesser or greater degree. Other challenges identified include change of the development process; incremental and flexible timing and safety analyses; configurable kernels applicable for safety-critical systems.',
	 'authors': u'Michael Burke, Neil Audsley,',
	 'category': u'Computer Science ',
	 'date': '2010-4-8',
	 'pdflink': u'http://arxiv.org/pdf/1004.1324',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nDistributed Fault-Tolerant Avionic Systems - A Real-Time Perspective',
	 'urllink': u'http://arxiv.org/abs/1004.1324'}
2015-03-24 06:33:39+0000 [xxu46_1] INFO: Crawled 362 pages (at 1 pages/min), scraped 356 items (at 1 items/min)
2015-03-24 06:34:39+0000 [xxu46_1] INFO: Crawled 362 pages (at 0 pages/min), scraped 356 items (at 0 items/min)
2015-03-24 06:34:45+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5432> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 06:34:45+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5432>
	{'abstract': u'This paper will propose a novel star schema attribute induction as a new attribute induction paradigm and as improving from current attribute oriented induction. A novel star schema attribute induction will be examined with current attribute oriented induction based on characteristic rule and using non rule based concept hierarchy by implementing both of approaches. In novel star schema attribute induction some improvements have been implemented like elimination threshold number as maximum tuples control for generalization result, there is no ANY as the most general concept, replacement the role concept hierarchy with concept tree, simplification for the generalization strategy steps and elimination attribute oriented induction algorithm. Novel star schema attribute induction is more powerful than the current attribute oriented induction since can produce small number final generalization tuples and there is no ANY in the results.',
	 'authors': u'Spits Warnars H.L.H,',
	 'category': u'Computer Science ',
	 'date': '2010-5-29',
	 'pdflink': u'http://arxiv.org/pdf/1005.5432',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nAttribute oriented induction with star schema',
	 'urllink': u'http://arxiv.org/abs/1005.5432'}
2015-03-24 06:35:39+0000 [xxu46_1] INFO: Crawled 363 pages (at 1 pages/min), scraped 357 items (at 1 items/min)
2015-03-24 06:36:26+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1164> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 06:36:26+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1164>
	{'abstract': u'The stability and convergence of the neural networks are the fundamental characteristics in the Hopfield type networks. Since time delay is ubiquitous in most physical and biological systems, more attention is being made for the delayed neural networks. The inclusion of time delay into a neural model is natural due to the finite transmission time of the interactions. The stability analysis of the neural networks depends on the Lyapunov function and hence it must be constructed for the given system. In this paper we have made an attempt to establish the logarithmic stability of the impulsive delayed neural networks by constructing suitable Lyapunov function.',
	 'authors': u'A. K. Ojha, Dushmanta Mallick, C. Mallick,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1164',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nExistence and Global Logarithmic Stability of Impulsive Neural Networks  with Time Delay',
	 'urllink': u'http://arxiv.org/abs/1002.1164'}
2015-03-24 06:36:39+0000 [xxu46_1] INFO: Crawled 364 pages (at 1 pages/min), scraped 358 items (at 1 items/min)
2015-03-24 06:37:39+0000 [xxu46_1] INFO: Crawled 364 pages (at 0 pages/min), scraped 358 items (at 0 items/min)
2015-03-24 06:37:59+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1304> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 06:37:59+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1304>
	{'abstract': u'According to actual needs, generalized signcryption scheme can flexibly work as an encryption scheme, a signature scheme or a signcryption scheme. In this paper, firstly, we give a security model for identity based generalized signcryption which is more complete than existing model. Secondly, we propose an identity based generalized signcryption scheme. Thirdly, we give the security proof of the new scheme in this complete model. Comparing with existing identity based generalized signcryption, the new scheme has less implementation complexity. Moreover, the new scheme has comparable computation complexity with the existing normal signcryption schemes.',
	 'authors': u'Gang Yu, Xiaoxiao Ma, Yong Shen, Wenbao Han,',
	 'category': u'Computer Science ',
	 'date': '2010-4-8',
	 'pdflink': u'http://arxiv.org/pdf/1004.1304',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nProvable Secure Identity Based Generalized Signcryption Scheme',
	 'urllink': u'http://arxiv.org/abs/1004.1304'}
2015-03-24 06:38:39+0000 [xxu46_1] INFO: Crawled 365 pages (at 1 pages/min), scraped 359 items (at 1 items/min)
2015-03-24 06:39:39+0000 [xxu46_1] INFO: Crawled 365 pages (at 0 pages/min), scraped 359 items (at 0 items/min)
2015-03-24 06:39:41+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5413> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 06:39:41+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5413>
	{'abstract': u'We prove that it is NP-hard to decide whether two points in a polygonal domain with holes can be connected by a wire. This implies that finding any approximation to the shortest path for a long snake amidst polygonal obstacles is NP-hard. On the positive side, we show that snake\'s problem is "length-tractable": if the snake is "fat", i.e., its length/width ratio is small, the shortest path can be computed in polynomial time.',
	 'authors': u'Irina Kostitsyna, Valentin Polishchuk,',
	 'category': u'Computer Science ',
	 'date': '2010-5-28',
	 'pdflink': u'http://arxiv.org/pdf/1005.5413',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nSimple Wriggling is Hard unless You Are a Fat Hippo',
	 'urllink': u'http://arxiv.org/abs/1005.5413'}
2015-03-24 06:40:39+0000 [xxu46_1] INFO: Crawled 366 pages (at 1 pages/min), scraped 360 items (at 1 items/min)
2015-03-24 06:41:15+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1163> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 06:41:15+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1163>
	{'abstract': u'In this paper, we will study Lee, Kim and Yoo, a verifier password typed key agreement scheme and demonstrate that the scheme is not secure. Then, the authors will propose an enhanced verifier typed key agreement scheme relied on Lee, Kim and Yoo scheme and demonstrate that the propose scheme resists against password guessing attack and stolen verifier attack. The authors are claimed that the proposed scheme is more secure and efficient compare with Lee, Kim and Yoo.',
	 'authors': u'Sattar J Aboud,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1163',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nEfficient Password-Typed Key Agreement Scheme',
	 'urllink': u'http://arxiv.org/abs/1002.1163'}
2015-03-24 06:41:39+0000 [xxu46_1] INFO: Crawled 367 pages (at 1 pages/min), scraped 361 items (at 1 items/min)
2015-03-24 06:42:25+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1298> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 06:42:25+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1298>
	{'abstract': u'Deterministic finite automata (DFAs) are constructed for various purposes in computational biology. Little attention, however, has been given to the efficient construction of minimal DFAs. In this article, we define simple non-deterministic finite automata (NFAs) and prove that the standard subset construction transforms NFAs of this type into minimal DFAs. Furthermore, we show how simple NFAs can be constructed from two types of patterns popular in bioinformatics, namely (sets of) generalized strings and (generalized) strings with a Hamming neighborhood.',
	 'authors': u'Tobias Marschall,',
	 'category': u'Computer Science ',
	 'date': '2010-4-8',
	 'pdflink': u'http://arxiv.org/pdf/1004.1298',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nConstruction of minimal DFAs from biological motifs',
	 'urllink': u'http://arxiv.org/abs/1004.1298'}
2015-03-24 06:42:39+0000 [xxu46_1] INFO: Crawled 368 pages (at 1 pages/min), scraped 362 items (at 1 items/min)
2015-03-24 06:43:39+0000 [xxu46_1] INFO: Crawled 368 pages (at 0 pages/min), scraped 362 items (at 0 items/min)
2015-03-24 06:43:46+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5412> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 06:43:46+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5412>
	{'abstract': u"Cooperative beamforming in relay networks is considered, in which a source transmits to its destination with the help of a set of cooperating nodes. The source first transmits locally. The cooperating nodes that receive the source signal retransmit a weighted version of it in an amplify-and-forward (AF) fashion. Assuming knowledge of the second-order statistics of the channel state information, beamforming weights are determined so that the signal-to-noise ratio (SNR) at the destination is maximized subject to two different power constraints, i.e., a total (source and relay) power constraint, and individual relay power constraints. For the former constraint, the original problem is transformed into a problem of one variable, which can be solved via Newton's method. For the latter constraint, the original problem is transformed into a homogeneous quadratically constrained quadratic programming (QCQP) problem. In this case, it is shown that when the number of relays does not exceed three the global solution can always be constructed via semidefinite programming (SDP) relaxation and the matrix rank-one decomposition technique. For the cases in which the SDP relaxation does not generate a rank one solution, two methods are proposed to solve the problem: the first one is based on the coordinate descent method, and the second one transforms the QCQP problem into an infinity norm maximization problem in which a smooth finite norm approximation can lead to the solution using the augmented Lagrangian method.",
	 'authors': u'Jiangyuan Li, Athina P. Petropulu, H. Vincent Poor,',
	 'category': u'Computer Science ',
	 'date': '2010-5-28',
	 'pdflink': u'http://arxiv.org/pdf/1005.5412',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOn Cooperative Beamforming Based on Second-Order Statistics of Channel  State Information',
	 'urllink': u'http://arxiv.org/abs/1005.5412'}
2015-03-24 06:44:39+0000 [xxu46_1] INFO: Crawled 369 pages (at 1 pages/min), scraped 363 items (at 1 items/min)
2015-03-24 06:45:15+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1162> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 06:45:15+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1162>
	{'abstract': u'Mobile Ad hoc Networks are highly dynamic networks. Quality of Service (QoS) routing in such networks is usually limited by the network breakage due to either node mobility or energy depletion of the mobile nodes. Also, to fulfill certain quality parameters, presence of multiple node-disjoint paths becomes essential. Such paths aid in the optimal traffic distribution and reliability in case of path breakages. Thus, to cater various challenges in QoS routing in Mobile Add hoc Networks, a Node Disjoint Multipath Routing Considering Link and Node Stability (NDMLNR) protocol has been proposed by the authors. The metric used to select the paths takes into account the stability of the nodes and the corresponding links. This paper studies various challenges in the QoS routing and presents the characteristic evaluation of NDMLNR w.r.t various existing protocols in this area.',
	 'authors': u'Shuchita Upadhayaya, Charu Gandhi,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1162',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nNode Disjoint Multipath Routing Considering Link and Node Stability  protocol: A characteristic Evaluation',
	 'urllink': u'http://arxiv.org/abs/1002.1162'}
2015-03-24 06:45:39+0000 [xxu46_1] INFO: Crawled 370 pages (at 1 pages/min), scraped 364 items (at 1 items/min)
2015-03-24 06:46:39+0000 [xxu46_1] INFO: Crawled 370 pages (at 0 pages/min), scraped 364 items (at 0 items/min)
2015-03-24 06:46:59+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1277> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 06:46:59+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1277>
	{'abstract': u'An opportunistic relay selection based on instantaneous knowledge of channels is considered to increase security against eavesdroppers. The closed-form expressions are derived for the average secrecy rates and the outage probability when the cooperative networks use Decode-and-Forward (DF) or Amplify-and-Forward (AF) strategy. These techniques are demonstrated analytically and with simulation results.',
	 'authors': u'Xiaojun Sun, Chunming Zhao, Ming Jiang,',
	 'category': u'Computer Science ',
	 'date': '2010-4-8',
	 'pdflink': u'http://arxiv.org/pdf/1004.1277',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nClosed-Form Expressions for Relay Selection with Secrecy Constraints',
	 'urllink': u'http://arxiv.org/abs/1004.1277'}
2015-03-24 06:47:39+0000 [xxu46_1] INFO: Crawled 371 pages (at 1 pages/min), scraped 365 items (at 1 items/min)
2015-03-24 06:48:28+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5395> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 06:48:28+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5395>
	{'abstract': u'We consider Golomb rulers and their construction. Common rulers feature marks at every unit measure, distances can often be measured with numerous pairs of marks. On Golomb rulers, for every distance there are at most two marks measuring it. The construction of optimal---with respect to shortest length for given number of marks or maximum number of marks for given length---is nontrivial, various problems regarding this are NP-complete. We give a simplified hardness proof for one of them. We use a hypergraph characterization of rulers and Golomb rulers to illuminate structural properties. This gives rise to a problem kernel in a fixed-parameter approach to a construction problem. We also take a short look at the practical implications of these considerations.',
	 'authors': u'Manuel Sorge,',
	 'category': u'Computer Science ',
	 'date': '2010-5-28',
	 'pdflink': u'http://arxiv.org/pdf/1005.5395',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nAlgorithmic Aspects of Golomb Ruler Construction',
	 'urllink': u'http://arxiv.org/abs/1005.5395'}
2015-03-24 06:48:39+0000 [xxu46_1] INFO: Crawled 372 pages (at 1 pages/min), scraped 366 items (at 1 items/min)
2015-03-24 06:49:39+0000 [xxu46_1] INFO: Crawled 372 pages (at 0 pages/min), scraped 366 items (at 0 items/min)
2015-03-24 06:50:12+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1160> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 06:50:12+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1160>
	{'abstract': u'The Session Initiation Protocol (SIP) has become the most predominant protocol for Voice over Internet Protocol (VoIP) signaling. Security of SIP is an important consideration for VoIP communication as the traffic is transmitted over the insecure IP network. And the authentication process in SIP ranges from pre-shared secret based solutions to Public Key Infrastructure (PKI) based solution. However, due to the limitations in PKI based solutions, some PKI less authentications mechanisms are proposed. This paper aims to present an overview of different authentication methods used in or together with SIP. We start by highlighting the security issues in SIP in the context of VoIP communication. Then we illustrate the current activities regarding the SIP authentication mechanisms including the recent developments in the research community and standardization efforts within the Internet Engineering Task Force (IETF). Finally we analyze the security aspects of these approaches.',
	 'authors': u'Abdullah Al Hasib, Abdullah Azfar, Md. Sarwar Morshed,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1160',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nTowards Public Key Infrastructure less authentication in Session  Initiation Protocol',
	 'urllink': u'http://arxiv.org/abs/1002.1160'}
2015-03-24 06:50:39+0000 [xxu46_1] INFO: Crawled 373 pages (at 1 pages/min), scraped 367 items (at 1 items/min)
2015-03-24 06:51:39+0000 [xxu46_1] INFO: Crawled 373 pages (at 0 pages/min), scraped 367 items (at 0 items/min)
2015-03-24 06:51:52+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1276> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 06:51:52+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1276>
	{'abstract': u'The basic idea behind Cloud computing is that resource providers offer elastic resources to end users. In this paper, we intend to answer one key question to the success of Cloud computing: in Cloud, can small or medium-scale scientific computing communities benefit from the economies of scale? Our research contributions are three-fold: first, we propose an enhanced scientific public cloud model (ESP) that encourages small- or medium-scale organizations to rent elastic resources from a public cloud provider; second, on a basis of the ESP model, we design and implement the DawningCloud system that can consolidate heterogeneous scientific workloads on a Cloud site; third, we propose an innovative emulation methodology and perform a comprehensive evaluation. We found that for two typical workloads: high throughput computing (HTC) and many task computing (MTC), DawningCloud saves the resource consumption maximally by 44.5% (HTC) and 72.6% (MTC) for service providers, and saves the total resource consumption maximally by 47.3% for a resource provider with respect to the previous two public Cloud solutions. To this end, we conclude that for typical workloads: HTC and MTC, DawningCloud can enable scientific communities to benefit from the economies of scale of public Clouds.',
	 'authors': u'Lei Wang, Jianfeng Zhan, Weisong Shi, Yi Liang,',
	 'category': u'Computer Science ',
	 'date': '2010-4-8',
	 'pdflink': u'http://arxiv.org/pdf/1004.1276',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nIn Cloud, Can Scientific Communities Benefit from the Economies of  Scale?',
	 'urllink': u'http://arxiv.org/abs/1004.1276'}
2015-03-24 06:52:39+0000 [xxu46_1] INFO: Crawled 374 pages (at 1 pages/min), scraped 368 items (at 1 items/min)
2015-03-24 06:53:27+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5375> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 06:53:27+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5375>
	{'abstract': u"We propose a new algorithm for solving a system of two nonlinear transcendental equations with two complex variables based on the Muller algorithm. The two-dimensional Muller algorithm is tested on systems of different type and is found to work comparably to Newton's method and Broyden's method in many cases. The new algorithm is particularly useful in systems featuring the Heun functions whose complexity may make the already known algorithms not efficient enough or not working at all. In those specific cases, the new algorithm gives distinctly better results than the other two methods. As an example for its application in physics, the new algorithm was used to find the quasi-normal modes (QNM) of Schwarzschild black hole described by the Regge-Wheeler equation. The numerical results obtained by our method are compared with the already published QNM frequencies and are found to coincide to a great extent with them. Also discussed are the QNM of the Kerr black hole, described by the Teukolsky Master equation.",
	 'authors': u'Plamen P. Fiziev, Denitsa R. Staicova,',
	 'category': u'Computer Science ',
	 'date': '2010-5-28',
	 'pdflink': u'http://arxiv.org/pdf/1005.5375',
	 'subjects': u'Numerical Analysis (cs.NA)',
	 'title': u'\nTwo-dimensional generalization of the Muller root-finding algorithm and  its applications',
	 'urllink': u'http://arxiv.org/abs/1005.5375'}
2015-03-24 06:53:39+0000 [xxu46_1] INFO: Crawled 375 pages (at 1 pages/min), scraped 369 items (at 1 items/min)
2015-03-24 06:54:39+0000 [xxu46_1] INFO: Crawled 375 pages (at 0 pages/min), scraped 369 items (at 0 items/min)
2015-03-24 06:55:09+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1159> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 06:55:09+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1159>
	{'abstract': u'The importance of finding the characteristics leading to either a success or a failure is one of the driving forces of data mining. The various application areas of finding success/failure factors cover vast variety of areas such as credit risk evaluation and granting loans, micro array analysis, health factors and health risk factors, and parameter combination leading to a product success. This paper presents a new approach for making inferences about dichotomous data. The objective is to determine rules that lead to a certain result. The method consists of four phases: in the first phase, the data is processed into a binary format of a truth table, in the second phase; rules are found by utilizing an algorithm that minimizes Boolean functions. In the third phase the rules are checked and filtered. In the fourth phase, simple rules that involve one to two features are revealed.',
	 'authors': u'Yuval Cohen,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1159',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nMining The Successful Binary Combinations: Methodology and A Simple Case  Study',
	 'urllink': u'http://arxiv.org/abs/1002.1159'}
2015-03-24 06:55:39+0000 [xxu46_1] INFO: Crawled 376 pages (at 1 pages/min), scraped 370 items (at 1 items/min)
2015-03-24 06:56:39+0000 [xxu46_1] INFO: Crawled 376 pages (at 0 pages/min), scraped 370 items (at 0 items/min)
2015-03-24 06:56:56+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1267> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 06:56:56+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1267>
	{'abstract': u'Some BitTorrent users are running BitTorrent on top of Tor to preserve their privacy. In this extended abstract, we discuss three different attacks to reveal the IP address of BitTorrent users on top of Tor. In addition, we exploit the multiplexing of streams from different applications into the same circuit to link non-BitTorrent applications to revealed IP addresses.',
	 'authors': u'Stevens Le Blond, Pere Manils, Abdelberi Chaabane, Mohamed Ali Kaafar, Arnaud Legout, Claude Castellucia, Walid Dabbous,',
	 'category': u'Computer Science ',
	 'date': '2010-4-8',
	 'pdflink': u'http://arxiv.org/pdf/1004.1267',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nDe-anonymizing BitTorrent Users on Tor',
	 'urllink': u'http://arxiv.org/abs/1004.1267'}
2015-03-24 06:57:39+0000 [xxu46_1] INFO: Crawled 377 pages (at 1 pages/min), scraped 371 items (at 1 items/min)
2015-03-24 06:58:30+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5367> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 06:58:30+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5367>
	{'abstract': u'In a virtualized infrastructure where physical resources are shared, a single physical server failure will terminate several virtual servers and crippling the virtual infrastructures which contained those virtual servers. In the worst case, more failures may cascade from overloading the remaining servers. To guarantee some level of reliability, each virtual infrastructure, at instantiation, should be augmented with backup virtual nodes and links that have sufficient capacities. This ensures that, when physical failures occur, sufficient computing resources are available and the virtual network topology is preserved. However, in doing so, the utilization of the physical infrastructure may be greatly reduced. This can be circumvented if backup resources are pooled and shared across multiple virtual infrastructures, and intelligently embedded in the physical infrastructure. These techniques can reduce the physical footprint of virtual backups while guaranteeing reliability.',
	 'authors': u'Wai-Leong Yeow, C\xe9dric Westphal, Ula\u015f C. Kozat,',
	 'category': u'Computer Science ',
	 'date': '2010-5-28',
	 'pdflink': u'http://arxiv.org/pdf/1005.5367',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nDesigning and Embedding Reliable Virtual Infrastructures',
	 'urllink': u'http://arxiv.org/abs/1005.5367'}
2015-03-24 06:58:39+0000 [xxu46_1] INFO: Crawled 378 pages (at 1 pages/min), scraped 372 items (at 1 items/min)
2015-03-24 06:59:39+0000 [xxu46_1] INFO: Crawled 378 pages (at 0 pages/min), scraped 372 items (at 0 items/min)
2015-03-24 06:59:54+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1157> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 06:59:54+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1157>
	{'abstract': u'In this paper, research on AI based modeling technique to optimize development of new alloys with necessitated improvements in properties and chemical mixture over existing alloys as per functional requirements of product is done. The current research work novels AI in lieu of predictions to establish association between material and product customary. Advanced computational simulation techniques like CFD, FEA interrogations are made viable to authenticate product dynamics in context to experimental investigations. Accordingly, the current research is focused towards binding relationships between material design and product design domains. The input to feed forward back propagation prediction network model constitutes of material design features. Parameters relevant to product design strategies are furnished as target outputs. The outcomes of ANN shows good sign of correlation between material and product design domains. The study enriches a new path to illustrate material factors at the time of new product development.',
	 'authors': u'K. Soorya Prakash, S. S. Mohamed Nazirudeen, M. Joseph Malvin Raj,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1157',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nEstablishment of Relationships between Material Design and Product  Design Domains by Hybrid FEM-ANN Technique',
	 'urllink': u'http://arxiv.org/abs/1002.1157'}
2015-03-24 07:00:39+0000 [xxu46_1] INFO: Crawled 379 pages (at 1 pages/min), scraped 373 items (at 1 items/min)
2015-03-24 07:01:24+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1262> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 07:01:24+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1262>
	{'abstract': u'In a model-based testing approach as well as for the verification of properties, B models provide an interesting solution. However, for industrial applications, the size of their state space often makes them hard to handle. To reduce the amount of states, an abstraction function can be used, often combining state variable elimination and domain abstractions of the remaining variables. This paper complements previous results, based on domain abstraction for test generation, by adding a preliminary syntactic abstraction phase, based on variable elimination. We define a syntactic transformation that suppresses some variables from a B event model, in addition to a method that chooses relevant variables according to a test purpose. We propose two methods to compute an abstraction A of an initial model M. The first one computes A as a simulation of M, and the second one computes A as a bisimulation of M. The abstraction process produces a finite state system. We apply this abstraction computation to a Model Based Testing process.',
	 'authors': u'Jacques Julliand, Nicolas Stouls, Pierre-Christophe Bu\xe9, Pierre-Alain Masson,',
	 'category': u'Computer Science ',
	 'date': '2010-4-8',
	 'pdflink': u'http://arxiv.org/pdf/1004.1262',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nSyntactic Abstraction of B Models to Generate Tests',
	 'urllink': u'http://arxiv.org/abs/1004.1262'}
2015-03-24 07:01:39+0000 [xxu46_1] INFO: Crawled 380 pages (at 1 pages/min), scraped 374 items (at 1 items/min)
2015-03-24 07:02:39+0000 [xxu46_1] INFO: Crawled 380 pages (at 0 pages/min), scraped 374 items (at 0 items/min)
2015-03-24 07:02:44+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5361> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 07:02:44+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5361>
	{'abstract': u'Turbo code is a great achievement in the field of communication system. It can be created by connecting a turbo encoder and a decoder serially. A Turbo encoder is build with parallel concatenation of two simple convolutional codes. By varying the number of memory element (encoder configuration), code rate (1/2 or 1/3), block size of data and iteration, we can achieve better BER performance. Turbo code also consists of interleaver unit and its BER performance also depends on interleaver size. Turbo Decoder can be implemented using different algorithm, but Log -MAP decoding algorithm is less computationaly complex with respect to MAP (maximux a posteriori) algorithm, without compromising its BER performance, nearer to Shannon limit. A register transfer level (RTL) turbo encoder is designed and simulated using VHDL (Very high speed integrated circuit Hardware Description Language). In this paper VHDL model of different turbo encoder are implemented using Log MAP decoder and its performance are compared and verified with corresponding MATLAB simulated results.',
	 'authors': u'Akash Kumar Gupta, Sanjeet Kumar,',
	 'category': u'Computer Science ',
	 'date': '2010-4-26',
	 'pdflink': u'http://arxiv.org/pdf/1005.5361',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nVHDL Implementation of different Turbo Encoder using Log-MAP Decoder',
	 'urllink': u'http://arxiv.org/abs/1005.5361'}
2015-03-24 07:03:39+0000 [xxu46_1] INFO: Crawled 381 pages (at 1 pages/min), scraped 375 items (at 1 items/min)
2015-03-24 07:04:29+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1156> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 07:04:29+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1156>
	{'abstract': u"The recent increase in dimensionality of data has thrown a great challenge to the existing dimensionality reduction methods in terms of their effectiveness. Dimensionality reduction has emerged as one of the significant preprocessing steps in machine learning applications and has been effective in removing inappropriate data, increasing learning accuracy, and improving comprehensibility. Feature redundancy exercises great influence on the performance of classification process. Towards the better classification performance, this paper addresses the usefulness of truncating the highly correlated and redundant attributes. Here, an effort has been made to verify the utility of dimensionality reduction by applying LVQ (Learning Vector Quantization) method on two Benchmark datasets of 'Pima Indian Diabetic patients' and 'Lung cancer patients'.",
	 'authors': u'M. Babu Reddy, L. S. S. Reddy,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1156',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nDimensionality Reduction: An Empirical Study on the Usability of IFE-CF  (Independent Feature Elimination- by C-Correlation and F-Correlation)  Measures',
	 'urllink': u'http://arxiv.org/abs/1002.1156'}
2015-03-24 07:04:39+0000 [xxu46_1] INFO: Crawled 382 pages (at 1 pages/min), scraped 376 items (at 1 items/min)
2015-03-24 07:05:39+0000 [xxu46_1] INFO: Crawled 382 pages (at 0 pages/min), scraped 376 items (at 0 items/min)
2015-03-24 07:06:16+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1257> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 07:06:16+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1257>
	{'abstract': u"World Wide Web is a huge repository of web pages and links. It provides abundance of information for the Internet users. The growth of web is tremendous as approximately one million pages are added daily. Users' accesses are recorded in web logs. Because of the tremendous usage of web, the web log files are growing at a faster rate and the size is becoming huge. Web data mining is the application of data mining techniques in web data. Web Usage Mining applies mining techniques in log data to extract the behavior of users which is used in various applications like personalized services, adaptive web sites, customer profiling, prefetching, creating attractive web sites etc., Web usage mining consists of three phases preprocessing, pattern discovery and pattern analysis. Web log data is usually noisy and ambiguous and preprocessing is an important process before mining. For discovering patterns sessions are to be constructed efficiently. This paper reviews existing work done in the preprocessing stage. A brief overview of various data mining techniques for discovering patterns, and pattern analysis are discussed. Finally a glimpse of various applications of web usage mining is also presented.",
	 'authors': u'V.Chitraa, Dr. Antony Selvdoss Davamani,',
	 'category': u'Computer Science ',
	 'date': '2010-4-8',
	 'pdflink': u'http://arxiv.org/pdf/1004.1257',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nA Survey on Preprocessing Methods for Web Usage Data',
	 'urllink': u'http://arxiv.org/abs/1004.1257'}
2015-03-24 07:06:39+0000 [xxu46_1] INFO: Crawled 383 pages (at 1 pages/min), scraped 377 items (at 1 items/min)
2015-03-24 07:07:39+0000 [xxu46_1] INFO: Crawled 383 pages (at 0 pages/min), scraped 377 items (at 0 items/min)
2015-03-24 07:07:57+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5337> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 07:07:57+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5337>
	{'abstract': u'Rapid identification of object from radar cross section (RCS) signals is important for many space and military applications. This identification is a problem in pattern recognition which either neural networks or support vector machines should prove to be high-speed. Bayesian networks would also provide value but require significant preprocessing of the signals. In this paper, we describe the use of a support vector machine for object identification from synthesized RCS data. Our best results are from data fusion of X-band and S-band signals, where we obtained 99.4%, 95.3%, 100% and 95.6% correct identification for cylinders, frusta, spheres, and polygons, respectively. We also compare our results with a Bayesian approach and show that the SVM is three orders of magnitude faster, as measured by the number of floating point operations.',
	 'authors': u'Marten F. Byl, James T. Demers, Edward A. Rietman,',
	 'category': u'Computer Science ',
	 'date': '2010-5-28',
	 'pdflink': u'http://arxiv.org/pdf/1005.5337',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nUsing a Kernel Adatron for Object Classification with RCS Data',
	 'urllink': u'http://arxiv.org/abs/1005.5337'}
2015-03-24 07:08:39+0000 [xxu46_1] INFO: Crawled 384 pages (at 1 pages/min), scraped 378 items (at 1 items/min)
2015-03-24 07:09:39+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1154> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 07:09:39+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1154>
	{'abstract': u'The complexity of multimedia applications in terms of intensity of computation and heterogeneity of treated data led the designers to embark them on multiprocessor systems on chip. The complexity of these systems on one hand and the expectations of the consumers on the other hand complicate the designers job to conceive and supply strong and successful systems in the shortest deadlines. They have to explore the different solutions of the design space and estimate their performances in order to deduce the solution that respects their design constraints. In this context, we propose the modeling of one of the design space possible solutions: the software to hardware task migration. This modeling exploits the synchronous dataflow graphs to take into account the different migration impacts and estimate their performances in terms of throughput.',
	 'authors': u'Dorsaf Sebai, Abderrazak Jemai, Imed Bennour,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1154',
	 'subjects': u'Performance (cs.PF)',
	 'title': u'\nPerformance Analysis of Software to Hardware Task Migration in Codesign',
	 'urllink': u'http://arxiv.org/abs/1002.1154'}
2015-03-24 07:09:39+0000 [xxu46_1] INFO: Crawled 385 pages (at 1 pages/min), scraped 379 items (at 1 items/min)
2015-03-24 07:10:39+0000 [xxu46_1] INFO: Crawled 385 pages (at 0 pages/min), scraped 379 items (at 0 items/min)
2015-03-24 07:10:46+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1253> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 07:10:46+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1253>
	{'abstract': u"While Spectral Methods have long been used for Principal Component Analysis, this survey focusses on work over the last 15 years with three salient features: (i) Spectral methods are useful not only for numerical problems, but also discrete optimization problems (Constraint Optimization Problems - CSP's) like the max. cut problem and similar mathematical considerations underlie both areas. (ii) Spectral methods can be extended to tensors. The theory and algorithms for tensors are not as simple/clean as for matrices, but the survey describes methods for low-rank approximation which extend to tensors. These tensor approximations help us solve Max--CSP's for as well as numerical tensor problems. (iii) Sampling on the fly plays a prominent role in these methods. A primary result is that for any matrix, a random submatrix of rows/columns picked with probabilities proportional to the squared lengths (of rows/columns), yields estimates of the singular values as well as an approximation to the whole matrix.",
	 'authors': u'Ravindran Kannan,',
	 'category': u'Computer Science ',
	 'date': '2010-4-8',
	 'pdflink': u'http://arxiv.org/pdf/1004.1253',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nSpectral Methods for Matrices and Tensors',
	 'urllink': u'http://arxiv.org/abs/1004.1253'}
2015-03-24 07:11:39+0000 [xxu46_1] INFO: Crawled 386 pages (at 1 pages/min), scraped 380 items (at 1 items/min)
2015-03-24 07:12:27+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5278> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 07:12:27+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5278>
	{'abstract': u'Previous deforestation and supercompilation algorithms may introduce accidental termination when applied to call-by-value programs. This hides looping bugs from the programmer, and changes the behavior of a program depending on whether it is optimized or not. We present a supercompilation algorithm for a higher-order call-by-value language and prove that the algorithm both terminates and preserves termination properties. This algorithm utilizes strictness information to decide whether to substitute or not and compares favorably with previous call-by-name transformations.',
	 'authors': u'Peter A. Jonsson, Johan Nordlander,',
	 'category': u'Computer Science ',
	 'date': '2010-5-28',
	 'pdflink': u'http://arxiv.org/pdf/1005.5278',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nPositive Supercompilation for a Higher-Order Call-By-Value Language',
	 'urllink': u'http://arxiv.org/abs/1005.5278'}
2015-03-24 07:12:39+0000 [xxu46_1] INFO: Crawled 387 pages (at 1 pages/min), scraped 381 items (at 1 items/min)
2015-03-24 07:13:39+0000 [xxu46_1] INFO: Crawled 387 pages (at 0 pages/min), scraped 381 items (at 0 items/min)
2015-03-24 07:14:05+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1152> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 07:14:05+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1152>
	{'abstract': u'A Virtual Private Network (VPN) provides private network connections over a publicly accessible shared network. The effective allocation of bandwidth for VPNs assumes significance in the present scenario due to varied traffic. Each VPN endpoint specifies bounds on the total amount of traffic that it is likely to send or receive at any time. The network provider tailors the VPN so that there is sufficient bandwidth for any traffic matrix that is consistent with these bounds. The approach incorporates the use of Ad-hoc On demand Distance Vector (AODV) protocol, with a view to accomplish an enhancement in the performance of the mobile networks. The NS2 based simulation results are evaluated in terms of its metrics for different bandwidth allocations, besides analyzing its performance in the event of exigencies such as link failures. The results highlight the suitability of the proposed strategy in the context of real time applications.',
	 'authors': u'Mahalakshmi Chidambara Natarajan, Ramaswamy Muthiah, Alamelu Nachiappan,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1152',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nPerformance Investigation of Virtual Private Networks with Different  Bandwidth Allocations',
	 'urllink': u'http://arxiv.org/abs/1002.1152'}
2015-03-24 07:14:39+0000 [xxu46_1] INFO: Crawled 388 pages (at 1 pages/min), scraped 382 items (at 1 items/min)
2015-03-24 07:15:39+0000 [xxu46_1] INFO: Crawled 388 pages (at 0 pages/min), scraped 382 items (at 0 items/min)
2015-03-24 07:15:46+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1249> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 07:15:46+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1249>
	{'abstract': u'To obtain good system performance, a DBA must choose a set of indices that is appropriate for the workload. The system can aid in this challenging task by providing recommendations for the index configuration. We propose a new index recommendation technique, termed semi-automatic tuning, that keeps the DBA "in the loop" by generating recommendations that use feedback about the DBA\'s preferences. The technique also works online, which avoids the limitations of commercial tools that require the workload to be known in advance. The foundation of our approach is the Work Function Algorithm, which can solve a wide variety of online optimization problems with strong competitive guarantees. We present an experimental analysis that validates the benefits of semi-automatic tuning in a wide variety of conditions.',
	 'authors': u'Karl Schnaitter, Neoklis Polyzotis,',
	 'category': u'Computer Science ',
	 'date': '2010-4-8',
	 'pdflink': u'http://arxiv.org/pdf/1004.1249',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nSemi-Automatic Index Tuning: Keeping DBAs in the Loop',
	 'urllink': u'http://arxiv.org/abs/1004.1249'}
2015-03-24 07:16:39+0000 [xxu46_1] INFO: Crawled 389 pages (at 1 pages/min), scraped 383 items (at 1 items/min)
2015-03-24 07:16:42+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5273> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 07:16:42+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5273>
	{'abstract': u'We give a new algorithm to find local maximum and minimum of a holonomic function and apply it for the Fisher-Bingham integral on the sphere , which is used in the directional statistics. The method utilizes the theory and algorithms of holonomic systems.',
	 'authors': u'Tomonari Sei, Nobuki Takayama, Akimichi Takemura, Hiromasa Nakayama, Kenta Nishiyama, Masayuki Noro, Katsuyoshi Ohara,',
	 'category': u'Computer Science ',
	 'date': '2010-5-28',
	 'pdflink': u'http://arxiv.org/pdf/1005.5273',
	 'subjects': u'Symbolic Computation (cs.SC)',
	 'title': u'\nHolonomic Gradient Descent and its Application to Fisher-Bingham  Integral',
	 'urllink': u'http://arxiv.org/abs/1005.5273'}
2015-03-24 07:17:39+0000 [xxu46_1] INFO: Crawled 390 pages (at 1 pages/min), scraped 384 items (at 1 items/min)
2015-03-24 07:17:50+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1151> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 07:17:50+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1151>
	{'abstract': u'This paper presents the realistic approach towards the quantitative analysis and simulation of Energy Efficient Hierarchical Cluster (EEHC)-based routing for wireless sensor networks. Here the efforts have been done to combine analytical hardware model with the modified EEHC-based routing model. The dependence of various performance metrics like: optimum number of clusters, Energy Consumption, and Energy consumed per round etc. based on analytical hardware sensor model and EEHC model has been presented.',
	 'authors': u'Manju Sharma, Lalit Awasthi,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1151',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nRealistic Approach towards Quantitative Analysis and Simulation of  EEHC-Based Routing for Wireless Sensor Networks',
	 'urllink': u'http://arxiv.org/abs/1002.1151'}
2015-03-24 07:18:39+0000 [xxu46_1] INFO: Crawled 391 pages (at 1 pages/min), scraped 385 items (at 1 items/min)
2015-03-24 07:19:19+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1239> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 07:19:19+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1239>
	{'abstract': u'Reliable effort estimation remains an ongoing challenge to software engineers. Accurate effort estimation is the state of art of software engineering, effort estimation of software is the preliminary phase between the client and the business enterprise. The relationship between the client and the business enterprise begins with the estimation of the software. The credibility of the client to the business enterprise increases with the accurate estimation. Effort estimation often requires generalizing from a small number of historical projects. Generalization from such limited experience is an inherently under constrained problem. Accurate estimation is a complex process because it can be visualized as software effort prediction, as the term indicates prediction never becomes an actual. This work follows the basics of the empirical software effort estimation models. The goal of this paper is to study the empirical software effort estimation. The primary conclusion is that no single technique is best for all situations, and that a careful comparison of the results of several approaches is most likely to produce realistic estimates.',
	 'authors': u'Saleem Basha, Dhavachelvan Ponnurangam,',
	 'category': u'Computer Science ',
	 'date': '2010-4-8',
	 'pdflink': u'http://arxiv.org/pdf/1004.1239',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nAnalysis of Empirical Software Effort Estimation Models',
	 'urllink': u'http://arxiv.org/abs/1004.1239'}
2015-03-24 07:19:39+0000 [xxu46_1] INFO: Crawled 392 pages (at 1 pages/min), scraped 386 items (at 1 items/min)
2015-03-24 07:20:03+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5271> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 07:20:03+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5271>
	{'abstract': u'Several steps are missing in the current high-speed race towards the holistic support of citizen needs in the domain of eGovernment. This paper is focused on how to provide support for the citizen profile. This profile, in a wide sense, includes personal information as well documents in possession of the citizen. This also involves the provision of those mechanisms required to publish, access and submit the convenient information to a Public Administration in due curse of a transactional services provided with the last one. Main features of the system are related to interoperability and possibilities for its inclusion in a cost effective manner in already developed platforms. To make that possible, this approach will take full advantage of semantic technologies and the RESTful paradigm to design the entire system. The paper presents the overall system with some notes on the deployment of the solution for its further reuse in similar contexts.',
	 'authors': u'Luis Alvarez Sabucedo, Luis Anido Rifon,',
	 'category': u'Computer Science ',
	 'date': '2010-5-28',
	 'pdflink': u'http://arxiv.org/pdf/1005.5271',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nA Restful Approach for Managing Citizen profiles Using A Semantic  Support',
	 'urllink': u'http://arxiv.org/abs/1005.5271'}
2015-03-24 07:20:39+0000 [xxu46_1] INFO: Crawled 393 pages (at 1 pages/min), scraped 387 items (at 1 items/min)
2015-03-24 07:21:39+0000 [xxu46_1] INFO: Crawled 393 pages (at 0 pages/min), scraped 387 items (at 0 items/min)
2015-03-24 07:21:44+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1150> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 07:21:44+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1150>
	{'abstract': u'Data mining is the task of discovering interesting patterns from large amounts of data. There are many data mining tasks, such as classification, clustering, association rule mining, and sequential pattern mining. Sequential pattern mining finds sets of data items that occur together frequently in some sequences. Sequential pattern mining, which extracts frequent subsequences from a sequence database, has attracted a great deal of interest during the recent data mining research because it is the basis of many applications, such as: web user analysis, stock trend prediction, DNA sequence analysis, finding language or linguistic patterns from natural language texts, and using the history of symptoms to predict certain kind of disease. The diversity of the applications may not be possible to apply a single sequential pattern model to all these problems. Each application may require a unique model and solution. A number of research projects were established in recent years to develop meaningful sequential pattern models and efficient algorithms for mining these patterns. In this paper, we theoretically provided a brief overview three types of sequential patterns model.',
	 'authors': u'Mahdi Esmaeili, Fazekas Gabor,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1150',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nFinding Sequential Patterns from Large Sequence Data',
	 'urllink': u'http://arxiv.org/abs/1002.1150'}
2015-03-24 07:22:39+0000 [xxu46_1] INFO: Crawled 394 pages (at 1 pages/min), scraped 388 items (at 1 items/min)
2015-03-24 07:23:28+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1237> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 07:23:28+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1237>
	{'abstract': u'Almost all existing RFID authentication schemes (tag/reader) are vulnerable to relay attacks, because of their inability to estimate the distance to the tag. These attacks are very serious since it can be mounted without the notice of neither the reader nor the tag and cannot be prevented by cryptographic protocols that operate at the application layer. Distance bounding protocols represent a promising way to thwart relay attacks, by measuring the round trip time of short authenticated messages. All the existing distance bounding protocols use random number generator and hash functions at the tag side which make them inapplicable at low cost RFID tags. This paper proposes a lightweight distance bound protocol for low cost RFID tags. The proposed protocol based on modified version of Gossamer mutual authentication protocol. The implementation of the proposed protocol meets the limited abilities of low-cost RFID tags.',
	 'authors': u'Eslam Gamal Ahmed, Eman Shaaban, Mohamed Hashem,',
	 'category': u'Computer Science ',
	 'date': '2010-4-8',
	 'pdflink': u'http://arxiv.org/e-print/1004.1237',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nLightweight Distance bound Protocol for Low Cost RFID Tags',
	 'urllink': u'http://arxiv.org/abs/1004.1237'}
2015-03-24 07:23:39+0000 [xxu46_1] INFO: Crawled 395 pages (at 1 pages/min), scraped 389 items (at 1 items/min)
2015-03-24 07:24:39+0000 [xxu46_1] INFO: Crawled 395 pages (at 0 pages/min), scraped 389 items (at 0 items/min)
2015-03-24 07:25:00+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5270> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 07:25:00+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5270>
	{'abstract': u'Symmetry is an important feature of many constraint programs. We show that any problem symmetry acting on a set of symmetry breaking constraints can be used to break symmetry. Different symmetries pick out different solutions in each symmetry class. This simple but powerful idea can be used in a number of different ways. We describe one application within model restarts, a search technique designed to reduce the conflict between symmetry breaking and the branching heuristic. In model restarts, we restart search periodically with a random symmetry of the symmetry breaking constraints. Experimental results show that this symmetry breaking technique is effective in practice on some standard benchmark problems.',
	 'authors': u'George Katsirelos, Toby Walsh,',
	 'category': u'Computer Science ',
	 'date': '2010-5-28',
	 'pdflink': u'http://arxiv.org/pdf/1005.5270',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nSymmetries of Symmetry Breaking Constraints',
	 'urllink': u'http://arxiv.org/abs/1005.5270'}
2015-03-24 07:25:39+0000 [xxu46_1] INFO: Crawled 396 pages (at 1 pages/min), scraped 390 items (at 1 items/min)
2015-03-24 07:26:39+0000 [xxu46_1] INFO: Crawled 396 pages (at 0 pages/min), scraped 390 items (at 0 items/min)
2015-03-24 07:26:42+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1149> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 07:26:42+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1149>
	{'abstract': u"Multiprocessor task scheduling is an important and computationally difficult problem. This paper proposes a comparison study of genetic algorithm and list scheduling algorithm. Both algorithms are naturally parallelizable but have heavy data dependencies. Based on experimental results, this paper presents a detailed analysis of the scalability, advantages and disadvantages of each algorithm. Multiprocessors have emerged as a powerful computing means for running real-time applications, especially where a uni-processor system would not be sufficient enough to execute all the tasks. The high performance and reliability of multiprocessors have made them a powerful computing resource. Such computing environment requires an efficient algorithm to determine when and on which processor a given task should execute. In multiprocessor systems, an efficient scheduling of a parallel program onto the processors that minimizes the entire execution time is vital for achieving a high performance. This scheduling problem is known to be NP- Hard. In multiprocessor scheduling problem, a given program is to be scheduled in a given multiprocessor system such that the program's execution time is minimized. The last job must be completed as early as possible. Genetic algorithm (GA) is one of the widely used techniques for constrained optimization.",
	 'authors': u'S. R. Vijayalakshmi, G. Padmavathi,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1149',
	 'subjects': u'Performance (cs.PF)',
	 'title': u'\nA Performance Study of GA and LSH in Multiprocessor Job Scheduling',
	 'urllink': u'http://arxiv.org/abs/1002.1149'}
2015-03-24 07:27:39+0000 [xxu46_1] INFO: Crawled 397 pages (at 1 pages/min), scraped 391 items (at 1 items/min)
2015-03-24 07:28:23+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1232> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 07:28:23+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1232>
	{'abstract': u"Botnet is most widespread and occurs commonly in today's cyber attacks, resulting in serious threats to our network assets and organization's properties. Botnets are collections of compromised computers (Bots) which are remotely controlled by its originator (BotMaster) under a common Command-and-Control (C&amp;C) infrastructure. They are used to distribute commands to the Bots for malicious activities such as distributed denial-of-service (DDoS) attacks, spam and phishing. Most of the existing Botnet detection approaches concentrate only on particular Botnet command and control (C&amp;C) protocols (e.g., IRC,HTTP) and structures (e.g., centralized), and can become ineffective as Botnets change their structure and C&amp;C techniques. In this paper at first we provide taxonomy of Botnets C&amp;C channels and evaluate well-known protocols which are being used in each of them. Then we proposed a new general detection framework which currently focuses on P2P based and IRC based Botnets. This proposed framework is based on definition of Botnets. Botnet has been defined as a group of bots that perform similar communication and malicious activity patterns within the same Botnet. The point that distinguishes our proposed detection framework from many other similar works is that there is no need for prior knowledge of Botnets such as Botnet signature.",
	 'authors': u'Hossein Rouhani Zeidanloo, Azizah Bt Abdul Manaf,',
	 'category': u'Computer Science ',
	 'date': '2010-4-8',
	 'pdflink': u'http://arxiv.org/pdf/1004.1232',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nBotnet Detection by Monitoring Similar Communication Patterns',
	 'urllink': u'http://arxiv.org/abs/1004.1232'}
2015-03-24 07:28:39+0000 [xxu46_1] INFO: Crawled 398 pages (at 1 pages/min), scraped 392 items (at 1 items/min)
2015-03-24 07:29:39+0000 [xxu46_1] INFO: Crawled 398 pages (at 0 pages/min), scraped 392 items (at 0 items/min)
2015-03-24 07:29:46+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5268> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 07:29:46+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5268>
	{'abstract': u'Voting is a simple mechanism to combine together the preferences of multiple agents. Agents may try to manipulate the result of voting by mis-reporting their preferences. One barrier that might exist to such manipulation is computational complexity. In particular, it has been shown that it is NP-hard to compute how to manipulate a number of different voting rules. However, NP-hardness only bounds the worst-case complexity. Recent theoretical results suggest that manipulation may often be easy in practice. In this paper, we study empirically the manipulability of single transferable voting (STV) to determine if computational complexity is really a barrier to manipulation. STV was one of the first voting rules shown to be NP-hard. It also appears one of the harder voting rules to manipulate. We sample a number of distributions of votes including uniform and real world elections. In almost every election in our experiments, it was easy to compute how a single agent could manipulate the election or to prove that manipulation by a single agent was impossible.',
	 'authors': u'Toby Walsh,',
	 'category': u'Computer Science ',
	 'date': '2010-5-28',
	 'pdflink': u'http://arxiv.org/pdf/1005.5268',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nAn Empirical Study of the Manipulability of Single Transferable Voting',
	 'urllink': u'http://arxiv.org/abs/1005.5268'}
2015-03-24 07:30:39+0000 [xxu46_1] INFO: Crawled 399 pages (at 1 pages/min), scraped 393 items (at 1 items/min)
2015-03-24 07:31:32+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1148> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 07:31:32+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1148>
	{'abstract': u'This paper attempts to undertake the study of three types of noise such as Salt and Pepper (SPN), Random variation Impulse Noise (RVIN), Speckle (SPKN). Different noise densities have been removed between 10% to 60% by using five types of filters as Mean Filter (MF), Adaptive Wiener Filter (AWF), Gaussian Filter (GF), Standard Median Filter (SMF) and Adaptive Median Filter (AMF). The same is applied to the Saturn remote sensing image and they are compared with one another. The comparative study is conducted with the help of Mean Square Errors (MSE) and Peak-Signal to Noise Ratio (PSNR). So as to choose the base method for removal of noise from remote sensing image.',
	 'authors': u'Salem Saleh Al-amri, N. V. Kalyankar, S.D. Khamitkar,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1148',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nA Comparative Study of Removal Noise from Remote Sensing Image',
	 'urllink': u'http://arxiv.org/abs/1002.1148'}
2015-03-24 07:31:39+0000 [xxu46_1] INFO: Crawled 400 pages (at 1 pages/min), scraped 394 items (at 1 items/min)
2015-03-24 07:32:39+0000 [xxu46_1] INFO: Crawled 400 pages (at 0 pages/min), scraped 394 items (at 0 items/min)
2015-03-24 07:32:43+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1230> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 07:32:43+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1230>
	{'abstract': u'This paper discusses the knowledge integration of clinical information extracted from distributed medical ontology in order to ameliorate a machine learning-based multi-label coding assignment system. The proposed approach is implemented using a decision tree based cascade hierarchical technique on the university hospital data for patients with Coronary Heart Disease (CHD). The preliminary results obtained show a satisfactory finding.',
	 'authors': u'Phanu Waraporn, Phayung Meesad, Gareth Clayton,',
	 'category': u'Computer Science ',
	 'date': '2010-4-8',
	 'pdflink': u'http://arxiv.org/pdf/1004.1230',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nOntology-supported processing of clinical text using medical knowledge  integration for multi-label classification of diagnosis coding',
	 'urllink': u'http://arxiv.org/abs/1004.1230'}
2015-03-24 07:33:39+0000 [xxu46_1] INFO: Crawled 401 pages (at 1 pages/min), scraped 395 items (at 1 items/min)
2015-03-24 07:34:02+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5253> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 07:34:02+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5253>
	{'abstract': u"The contribution of this paper is to provide a semantic model (using soft constraints) of the words used by web-users to describe objects in a language game; a game in which one user describes a selected object of those composing the scene, and another user has to guess which object has been described. The given description needs to be non ambiguous and accurate enough to allow other users to guess the described shape correctly. To build these semantic models the descriptions need to be analyzed to extract the syntax and words' classes used. We have modeled the meaning of these descriptions using soft constraints as a way for grounding the meaning. The descriptions generated by the system took into account the context of the object to avoid ambiguous descriptions, and allowed users to guess the described object correctly 72% of the times.",
	 'authors': u'Sergio Guadarrama, David P. Pancho,',
	 'category': u'Computer Science ',
	 'date': '2010-5-28',
	 'pdflink': u'http://arxiv.org/pdf/1005.5253',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nUsing Soft Constraints To Learn Semantic Models Of Descriptions Of  Shapes',
	 'urllink': u'http://arxiv.org/abs/1005.5253'}
2015-03-24 07:34:39+0000 [xxu46_1] INFO: Crawled 402 pages (at 1 pages/min), scraped 396 items (at 1 items/min)
2015-03-24 07:35:37+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1146> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 07:35:37+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1146>
	{'abstract': u'The increasing role of home automation in routine life and the rising demand for sensor networks enhanced wireless personal area networks (WPANs) development, pervasiveness of wireless &amp; wired network, and research. Soon arose the need of implementing the Internet Protocol in these devices in order to WPAN standards, raising the way for questions on how to provide seamless communication between wired and wireless technologies. After a quick overview of the Low-rate WPAN standard (IEEE 802.15.4) and the Zigbee stack, this paper focuses on understanding the implications when interconnecting low powered IEEE 802.15.4 devices and a wired IPv6 domain. Subsequently the focus will be on existing approaches to connect LoWPAN devices to the internet and on how these approaches try to solve these challenges, concluding with a critical analysis of interoperability problems.',
	 'authors': u'Md. Sakhawat Hossen, A. F. M. Sultanul Kabir, Razib Hayat Khan, Abdullah Azfar,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1146',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nInterconnection between 802.15.4 Devices and IPv6: Implications and  Existing Approaches',
	 'urllink': u'http://arxiv.org/abs/1002.1146'}
2015-03-24 07:35:39+0000 [xxu46_1] INFO: Crawled 403 pages (at 1 pages/min), scraped 397 items (at 1 items/min)
2015-03-24 07:36:39+0000 [xxu46_1] INFO: Crawled 403 pages (at 0 pages/min), scraped 397 items (at 0 items/min)
2015-03-24 07:37:11+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1229> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 07:37:11+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1229>
	{'abstract': u'This paper introduces a novel indexing and access method, called Feature- Based Adaptive Tolerance Tree (FATT), using wavelet transform is proposed to organize large image data sets efficiently and to support popular image access mechanisms like Content Based Image Retrieval (CBIR).Conventional database systems are designed for managing textual and numerical data and retrieving such data is often based on simple comparisons of text or numerical values. However, this method is no longer adequate for images, since the digital presentation of images does not convey the reality of images. Retrieval of images become difficult when the database is very large. This paper addresses such problems and presents a novel indexing technique, Feature Based Adaptive Tolerance Tree (FATT), which is designed to bring an effective solution especially for indexing large databases. The proposed indexing scheme is then used along with a query by image content, in order to achieve the ultimate goal from the user point of view that is retrieval of all relevant images. FATT indexing technique, features of the image is extracted using 2-dimensional discrete wavelet transform (2DDWT) and index code is generated from the determinant value of the features. Multiresolution analysis technique using 2D-DWT can decompose the image into components at different scales, so that the coarest scale components carry the global approximation information while the finer scale components contain the detailed information. Experimental results show that the FATT outperforms M-tree upto 200%, Slim-tree up to 120% and HCT upto 89%. FATT indexing technique is adopted to increase the efficiently of data storage and retrieval.',
	 'authors': u'Dr. P. AnandhaKumar, V. Balamurugan,',
	 'category': u'Computer Science ',
	 'date': '2010-4-8',
	 'pdflink': u'http://arxiv.org/pdf/1004.1229',
	 'subjects': u'Multimedia (cs.MM)',
	 'title': u'\nFeature-Based Adaptive Tolerance Tree (FATT): An Efficient Indexing  Technique for Content-Based Image Retrieval Using Wavelet Transform',
	 'urllink': u'http://arxiv.org/abs/1004.1229'}
2015-03-24 07:37:39+0000 [xxu46_1] INFO: Crawled 404 pages (at 1 pages/min), scraped 398 items (at 1 items/min)
2015-03-24 07:38:39+0000 [xxu46_1] INFO: Crawled 404 pages (at 0 pages/min), scraped 398 items (at 0 items/min)
2015-03-24 07:38:44+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5241> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 07:38:44+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5241>
	{'abstract': u"Under Windows operating system, existing I/O benchmarking tools does not allow a developer to efficiently define a file access strategy according to the applications' constraints. This is essentially due to the fact that the existing tools do allow only a restricted set of I/O workloads that does not generally correspond to the target applications. To cope with this problem, we designed and implemented a precise I/O simulator allowing to simulate whatever real I/O trace on a given defined architecture, and in which most of file and disk cache strategies, their interactions and the detailed storage system architecture are implemented. Simulation results on different workloads and architectures show a very high degree of precision. In fact, the mean error rate as compared to real measures is of about 6% with a maximum of 10% on global throughput.",
	 'authors': u'Jalil Boukhobza, Timsit Claude,',
	 'category': u'Computer Science ',
	 'date': '2010-5-28',
	 'pdflink': u'http://arxiv.org/pdf/1005.5241',
	 'subjects': u'Performance (cs.PF)',
	 'title': u"\nSimulation de traces r\xe9elles d'E/S disque de PC",
	 'urllink': u'http://arxiv.org/abs/1005.5241'}
2015-03-24 07:39:39+0000 [xxu46_1] INFO: Crawled 405 pages (at 1 pages/min), scraped 399 items (at 1 items/min)
2015-03-24 07:39:48+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1144> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 07:39:48+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1144>
	{'abstract': u"The performance in higher secondary school education in India is a turning point in the academic lives of all students. As this academic performance is influenced by many factors, it is essential to develop predictive data mining model for students' performance so as to identify the slow learners and study the influence of the dominant factors on their academic performance. In the present investigation, a survey cum experimental methodology was adopted to generate a database and it was constructed from a primary and a secondary source. While the primary data was collected from the regular students, the secondary data was gathered from the school and office of the Chief Educational Officer (CEO). A total of 1000 datasets of the year 2006 from five different schools in three different districts of Tamilnadu were collected. The raw data was preprocessed in terms of filling up missing values, transforming values in one form into another and relevant attribute/ variable selection. As a result, we had 772 student records, which were used for CHAID prediction model construction. A set of prediction rules were extracted from CHIAD prediction model and the efficiency of the generated CHIAD prediction model was found. The accuracy of the present model was compared with other model and it has been found to be satisfactory.",
	 'authors': u'M. Ramaswami, R. Bhaskaran,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1144',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nA CHAID Based Performance Prediction Model in Educational Data Mining',
	 'urllink': u'http://arxiv.org/abs/1002.1144'}
2015-03-24 07:40:39+0000 [xxu46_1] INFO: Crawled 406 pages (at 1 pages/min), scraped 400 items (at 1 items/min)
2015-03-24 07:41:21+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1227> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 07:41:21+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1227>
	{'abstract': u'This paper present a novel off-line signature recognition method based on multi scale Fourier Descriptor and wavelet transform . The main steps of constructing a signature recognition system are discussed and experiments on real data sets show that the average error rate can reach 1%. Finally we compare 8 distance measures between feature vectors with respect to the recognition performance. Key words: signature recognition; Fourier Descriptor; Wavelet transform; personal verification',
	 'authors': u'Ismail A. Ismail, Mohammed A. Ramadan, Talaat S. El danaf, Ahmed H. Samak,',
	 'category': u'Computer Science ',
	 'date': '2010-4-8',
	 'pdflink': u'http://arxiv.org/pdf/1004.1227',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nSignature Recognition using Multi Scale Fourier Descriptor And Wavelet  Transform',
	 'urllink': u'http://arxiv.org/abs/1004.1227'}
2015-03-24 07:41:39+0000 [xxu46_1] INFO: Crawled 407 pages (at 1 pages/min), scraped 401 items (at 1 items/min)
2015-03-24 07:42:39+0000 [xxu46_1] INFO: Crawled 407 pages (at 0 pages/min), scraped 401 items (at 0 items/min)
2015-03-24 07:43:04+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5232> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 07:43:04+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5232>
	{'abstract': u'MKM has been defined as the quest for technologies to manage mathematical knowledge. MKM "in the small" is well-studied, so the real problem is to scale up to large, highly interconnected corpora: "MKM in the large". We contend that advances in two areas are needed to reach this goal. We need representation languages that support incremental processing of all primitive MKM operations, and we need software architectures and implementations that implement these operations scalably on large knowledge bases. We present instances of both in this paper: the MMT framework for modular theory-graphs that integrates meta-logical foundations, which forms the base of the next OMDoc version; and TNTBase, a versioned storage system for XML-based document formats. TNTBase becomes an MMT database by instantiating it with special MKM operations for MMT.',
	 'authors': u'Michael Kohlhase, Florian Rabe, Vyacheslav Zholudev,',
	 'category': u'Computer Science ',
	 'date': '2010-5-28',
	 'pdflink': u'http://arxiv.org/pdf/1005.5232',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nTowards MKM in the Large: Modular Representation and Scalable Software  Architecture',
	 'urllink': u'http://arxiv.org/abs/1005.5232'}
2015-03-24 07:43:39+0000 [xxu46_1] INFO: Crawled 408 pages (at 1 pages/min), scraped 402 items (at 1 items/min)
2015-03-24 07:44:39+0000 [xxu46_1] INFO: Crawled 408 pages (at 0 pages/min), scraped 402 items (at 0 items/min)
2015-03-24 07:44:42+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1143> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 07:44:42+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1143>
	{'abstract': u'Time is one of the most difficult aspects to handle in real world applications such as database systems. Relational database management systems proposed by Codd offer very little built-in query language support for temporal data management. The model itself incorporates neither the concept of time nor any theory of temporal semantics. Many temporal extensions of the relational model have been proposed and some of them are also implemented. This paper offers a brief introduction to temporal database research. We propose a conceptual model for handling time varying attributes in the relational database model with minimal temporal attributes.',
	 'authors': u'Nadeem Mahmood, Aqil Burney, Kamran Ahsan,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1143',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nA Logical Temporal Relational Data Model',
	 'urllink': u'http://arxiv.org/abs/1002.1143'}
2015-03-24 07:45:39+0000 [xxu46_1] INFO: Crawled 409 pages (at 1 pages/min), scraped 403 items (at 1 items/min)
2015-03-24 07:46:02+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1224> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 07:46:02+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1224>
	{'abstract': u"The Personality and emotions are effective parameters in learning process. Thus, virtual learning environments should pay attention to these parameters. In this paper, a new e-learning model is designed and implemented according to these parameters. The Virtual learning environment that is presented here uses two agents: Virtual Tutor Agent (VTA), and Virtual Classmate Agent (VCA). During the learning process and depending on events happening in the environment, learner's emotions are changed. In this situation, learning style should be revised according to the personality traits as well as the learner's current emotions. VTA selects suitable learning style for the learners based on their personality traits. To improve the learning process, the system uses VCA in some of the learning steps. VCA is an intelligent agent and has its own personality. It is designed so that it can present an attractive and real learning environment in interaction with the learner. To recognize the learner's personality, this system uses MBTI test and to obtain emotion values uses OCC model. Finally, the results of system tested in real environments show that considering the human features in interaction with the learner increases learning quality and satisfies the learner.",
	 'authors': u'Somayeh Fatahi, Nasser Ghasem-Aghaee,',
	 'category': u'Computer Science ',
	 'date': '2010-4-8',
	 'pdflink': u'http://arxiv.org/pdf/1004.1224',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u"\nDesign and Implementation of an Intelligent Educational Model Based on  Personality and Learner's Emotion",
	 'urllink': u'http://arxiv.org/abs/1004.1224'}
2015-03-24 07:46:39+0000 [xxu46_1] INFO: Crawled 410 pages (at 1 pages/min), scraped 404 items (at 1 items/min)
2015-03-24 07:47:39+0000 [xxu46_1] INFO: Crawled 410 pages (at 0 pages/min), scraped 404 items (at 0 items/min)
2015-03-24 07:47:39+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5223> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 07:47:39+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5223>
	{'abstract': u'Self-stabilization is a versatile approach to fault-tolerance since it permits a distributed system to recover from any transient fault that arbitrarily corrupts the contents of all memories in the system. Byzantine tolerance is an attractive feature of distributed systems that permits to cope with arbitrary malicious behaviors. We consider the well known problem of constructing a breadth-first spanning tree in this context. Combining these two properties proves difficult: we demonstrate that it is impossible to contain the impact of Byzantine nodes in a strictly or strongly stabilizing manner. We then adopt the weaker scheme of topology-aware strict stabilization and we present a similar weakening of strong stabilization. We prove that the classical protocol has optimal Byzantine containment properties with respect to these criteria.',
	 'authors': u'Swan Dubois, Toshimitsu Masuzawa, S\xe9bastien Tixeuil,',
	 'category': u'Computer Science ',
	 'date': '2010-5-28',
	 'pdflink': u'http://arxiv.org/pdf/1005.5223',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nOn Byzantine Containment Properties of the $min+1$ Protocol',
	 'urllink': u'http://arxiv.org/abs/1005.5223'}
2015-03-24 07:48:39+0000 [xxu46_1] INFO: Crawled 411 pages (at 1 pages/min), scraped 405 items (at 1 items/min)
2015-03-24 07:48:58+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1104> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 07:48:58+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1104>
	{'abstract': u'As advances in technology allow for the collection, storage, and analysis of vast amounts of data, the task of screening and assessing the significance of discovered patterns is becoming a major challenge in data mining applications. In this work, we address significance in the context of frequent itemset mining. Specifically, we develop a novel methodology to identify a meaningful support threshold s* for a dataset, such that the number of itemsets with support at least s* represents a substantial deviation from what would be expected in a random dataset with the same number of transactions and the same individual item frequencies. These itemsets can then be flagged as statistically significant with a small false discovery rate. We present extensive experimental results to substantiate the effectiveness of our methodology.',
	 'authors': u'Adam Kirsch, Michael Mitzenmacher, Andrea Pietracaprina, Geppino Pucci, Eli Upfal, Fabio Vandin,',
	 'category': u'Computer Science ',
	 'date': '2010-2-4',
	 'pdflink': u'http://arxiv.org/pdf/1002.1104',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nAn Efficient Rigorous Approach for Identifying Statistically Significant  Frequent Itemsets',
	 'urllink': u'http://arxiv.org/abs/1002.1104'}
2015-03-24 07:49:39+0000 [xxu46_1] INFO: Crawled 412 pages (at 1 pages/min), scraped 406 items (at 1 items/min)
2015-03-24 07:50:32+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1220> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 07:50:32+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1220>
	{'abstract': u'In this paper we generalize and improve the multiscale organization of graphs by introducing a new measure that quantifies the "closeness" between two nodes. The calculation of the measure is linear in the number of edges in the graph and involves just a small number of relaxation sweeps. A similar notion of distance is then calculated and used at each coarser level. We demonstrate the use of this measure in multiscale methods for several important combinatorial optimization problems and discuss the multiscale graph organization.',
	 'authors': u'Dorit Ron, Ilya Safro, Achi Brandt,',
	 'category': u'Computer Science ',
	 'date': '2010-4-8',
	 'pdflink': u'http://arxiv.org/pdf/1004.1220',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nRelaxation-based coarsening and multiscale graph organization',
	 'urllink': u'http://arxiv.org/abs/1004.1220'}
2015-03-24 07:50:39+0000 [xxu46_1] INFO: Crawled 413 pages (at 1 pages/min), scraped 407 items (at 1 items/min)
2015-03-24 07:51:39+0000 [xxu46_1] INFO: Crawled 413 pages (at 0 pages/min), scraped 407 items (at 0 items/min)
2015-03-24 07:52:19+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5197> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 07:52:19+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5197>
	{'abstract': u'Most learning to rank research has assumed that the utility of different documents is independent, which results in learned ranking functions that return redundant results. The few approaches that avoid this have rather unsatisfyingly lacked theoretical foundations, or do not scale. We present a learning-to-rank formulation that optimizes the fraction of satisfied users, with several scalable algorithms that explicitly takes document similarity and ranking context into account. Our formulation is a non-trivial common generalization of two multi-armed bandit models from the literature: "ranked bandits" (Radlinski et al., ICML 2008) and "Lipschitz bandits" (Kleinberg et al., STOC 2008). We present theoretical justifications for this approach, as well as a near-optimal algorithm. Our evaluation adds optimizations that improve empirical performance, and shows that our algorithms learn orders of magnitude more quickly than previous approaches.',
	 'authors': u'Aleksandrs Slivkins, Filip Radlinski, Sreenivas Gollapudi,',
	 'category': u'Computer Science ',
	 'date': '2010-5-28',
	 'pdflink': u'http://arxiv.org/pdf/1005.5197',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nRanked bandits in metric spaces: learning optimally diverse rankings  over large document collections',
	 'urllink': u'http://arxiv.org/abs/1005.5197'}
2015-03-24 07:52:39+0000 [xxu46_1] INFO: Crawled 414 pages (at 1 pages/min), scraped 408 items (at 1 items/min)
2015-03-24 07:53:39+0000 [xxu46_1] INFO: Crawled 414 pages (at 0 pages/min), scraped 408 items (at 0 items/min)
2015-03-24 07:53:46+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1099> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 07:53:46+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1099>
	{'abstract': u'In this work, we discuss multiplayer pervasive games that rely on the use of ad hoc mobile sensor networks. The unique feature in such games is that players interact with each other and their surrounding environment by using movement and presence as a means of performing game-related actions, utilizing sensor devices. We discuss the fundamental issues and challenges related to these type of games and the scenarios associated with them. We also present and evaluate an example of such a game, called the "Hot Potato", developed using the Sun SPOT hardware platform. We provide a set of experimental results, so as to both evaluate our implementation and also to identify issues that arise in pervasive games which utilize sensor network nodes, which show that there is great potential in this type of games.',
	 'authors': u'Ioannis Chatzigiannakis, Georgios Mylonas, Orestis Akribopoulos, Marios Logaras, Panagiotis Kokkinos, Paul Spirakis,',
	 'category': u'Computer Science ',
	 'date': '2010-2-4',
	 'pdflink': u'http://arxiv.org/pdf/1002.1099',
	 'subjects': u'Human-Computer Interaction (cs.HC)',
	 'title': u'\nThe "Hot Potato" Case: Challenges in Multiplayer Pervasive Games Based  on Ad hoc Mobile Sensor Networks and the Experimental Evaluation of a  Prototype Game',
	 'urllink': u'http://arxiv.org/abs/1002.1099'}
2015-03-24 07:54:39+0000 [xxu46_1] INFO: Crawled 415 pages (at 1 pages/min), scraped 409 items (at 1 items/min)
2015-03-24 07:55:18+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1216> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 07:55:18+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1216>
	{'abstract': u'A (non-circular) de Bruijn sequence w of order n is a word such that every word of length n appears exactly once in w as a factor. In this paper, we generalize the concept to a multi-shift setting: a multi-shift de Bruijn sequence tau(m,n) of shift m and order n is a word such that every word of length n appears exactly once in w as a factor that starts at index im+1 for some integer i&gt;=0. We show the number of the multi-shift de Bruijn sequence tau(m,n) is (a^n)!a^ for 1&lt;=n&lt;=m and is (a^m!)^ for 1&lt;=m&lt;=n, where a=|Sigma|. We provide two algorithms for generating a tau(m,n). The multi-shift de Bruijn sequence is important in solving the Frobenius problem in a free monoid.',
	 'authors': u'Zhi Xu,',
	 'category': u'Computer Science ',
	 'date': '2010-4-8',
	 'pdflink': u'http://arxiv.org/pdf/1004.1216',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nMulti-Shift de Bruijn Sequence',
	 'urllink': u'http://arxiv.org/abs/1004.1216'}
2015-03-24 07:55:39+0000 [xxu46_1] INFO: Crawled 416 pages (at 1 pages/min), scraped 410 items (at 1 items/min)
2015-03-24 07:56:39+0000 [xxu46_1] INFO: Crawled 416 pages (at 0 pages/min), scraped 410 items (at 0 items/min)
2015-03-24 07:56:53+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5183> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 07:56:53+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5183>
	{'abstract': u"A novel language system has given rise to promising alternatives to standard formal and processor network models of computation. An interstring linked with a abstract machine environment, shares sub-expressions, transfers data, and spatially allocates resources for the parallel evaluation of dataflow. Formal models called the a-Ram family are introduced, designed to support interstring programming languages (interlanguages). Distinct from dataflow, graph rewriting, and FPGA models, a-Ram instructions are bit level and execute in situ. They support sequential and parallel languages without the space/time overheads associated with the Turing Machine and l-calculus, enabling massive programs to be simulated. The devices of one a-Ram model, called the Synchronic A-Ram, are fully connected and simpler than FPGA LUT's. A compiler for an interlanguage called Space, has been developed for the Synchronic A-Ram. Space is MIMD. strictly typed, and deterministic. Barring memory allocation and compilation, modules are referentially transparent. At a high level of abstraction, modules exhibit a state transition system, aiding verification. Data structures and parallel iteration are straightforward to implement, and allocations of sub-processes and data transfers to resources are implicit. Space points towards highly connected architectures called Synchronic Engines, that scale in a GALS manner. Synchronic Engines are more general purpose than systolic arrays and GPUs, and bypass programmability and conflict issues associated with multicores.",
	 'authors': u'Alexander Victor Berka,',
	 'category': u'Computer Science ',
	 'date': '2010-5-27',
	 'pdflink': u'http://arxiv.org/pdf/1005.5183',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nInterlanguages and synchronic models of computation',
	 'urllink': u'http://arxiv.org/abs/1005.5183'}
2015-03-24 07:57:39+0000 [xxu46_1] INFO: Crawled 417 pages (at 1 pages/min), scraped 411 items (at 1 items/min)
2015-03-24 07:58:38+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1095> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 07:58:38+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1095>
	{'abstract': u'This document discusses an approach and its rudimentary realization towards automatic classification of PPs; the topic, that has not received as much attention in NLP as NPs and VPs. The approach is a rule-based heuristics outlined in several levels of our research. There are 7 semantic categories of PPs considered in this document that we are able to classify from an annotated corpus.',
	 'authors': u'Frank Rudzicz, Serguei A. Mokhov,',
	 'category': u'Computer Science ',
	 'date': '2010-2-4',
	 'pdflink': u'http://arxiv.org/pdf/1002.1095',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nTowards a Heuristic Categorization of Prepositional Phrases in English  with WordNet',
	 'urllink': u'http://arxiv.org/abs/1002.1095'}
2015-03-24 07:58:39+0000 [xxu46_1] INFO: Crawled 418 pages (at 1 pages/min), scraped 412 items (at 1 items/min)
2015-03-24 07:59:39+0000 [xxu46_1] INFO: Crawled 418 pages (at 0 pages/min), scraped 412 items (at 0 items/min)
2015-03-24 08:00:18+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1215> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 08:00:18+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1215>
	{'abstract': u'Restoration of digital images from their degraded measurements has always been a problem of great theoretical and practical importance in numerous applications of imaging sciences. A specific solution to the problem of image restoration is generally determined by the nature of degradation phenomenon as well as by the statistical properties of measurement noises. The present study is concerned with the case in which the images of interest are corrupted by convolutional blurs and Poisson noises. To deal with such problems, there exists a range of solution methods which are based on the principles originating from the fixed-point algorithm of Richardson and Lucy (RL). In this paper, we provide conceptual and experimental proof that such methods tend to converge to sparse solutions, which makes them applicable only to those images which can be represented by a relatively small number of non-zero samples in the spatial domain. Unfortunately, the set of such images is relatively small, which restricts the applicability of RL-type methods. On the other hand, virtually all practical images admit sparse representations in the domain of a properly designed linear transform. To take advantage of this fact, it is therefore tempting to modify the RL algorithm so as to make it recover representation coefficients, rather than the values of their associated image. Such modification is introduced in this paper. Apart from the generality of its assumptions, the proposed method is also superior to many established reconstruction approaches in terms of estimation accuracy and computational complexity. This and other conclusions of this study are validated through a series of numerical experiments.',
	 'authors': u'Elad Shaked, Oleg Michailovich,',
	 'category': u'Computer Science ',
	 'date': '2010-4-8',
	 'pdflink': u'http://arxiv.org/pdf/1004.1215',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nRegularized Richardson-Lucy Algorithm for Sparse Reconstruction of  Poissonian Images',
	 'urllink': u'http://arxiv.org/abs/1004.1215'}
2015-03-24 08:00:39+0000 [xxu46_1] INFO: Crawled 419 pages (at 1 pages/min), scraped 413 items (at 1 items/min)
2015-03-24 08:01:36+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5181> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 08:01:36+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5181>
	{'abstract': u'This philosophical paper proposes a modified version of the scientific method, in which large databases are used instead of experimental observations as the necessary empirical ingredient. This change in the source of the empirical data allows the scientific method to be applied to several aspects of physical reality that previously resisted systematic interrogation. Under the new method, scientific theories are compared by instantiating them as compression programs, and examining the codelengths they achieve on a database of measurements related to a phenomenon of interest. Because of the impossibility of compressing random data, "real world" data can only be compressed by discovering and exploiting the empirical structure it exhibits. The method also provides a new way of thinking about two longstanding issues in the philosophy of science: the problem of induction and the problem of demarcation. The second part of the paper proposes to reformulate computer vision as an empirical science of visual reality, by applying the new method to large databases of natural images. The immediate goal of the proposed reformulation is to repair the chronic difficulties in evaluation experienced by the field of computer vision. The reformulation should bring a wide range of benefits, including a substantially increased degree of methodological rigor, the ability to justify complex theories without overfitting, a scalable evaluation paradigm, and the potential to make systematic progress. A crucial argument is that the change is not especially drastic, because most computer vision tasks can be reformulated as specialized image compression techniques. Finally, a concrete proposal is discussed in which a database is produced by recording from a roadside video camera, and compression is achieved by developing a computational understanding of the appearance of moving cars.',
	 'authors': u'Daniel Burfoot,',
	 'category': u'Computer Science ',
	 'date': '2010-5-27',
	 'pdflink': u'http://arxiv.org/pdf/1005.5181',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nCompression Rate Method for Empirical Science and Application to  Computer Vision',
	 'urllink': u'http://arxiv.org/abs/1005.5181'}
2015-03-24 08:01:39+0000 [xxu46_1] INFO: Crawled 420 pages (at 1 pages/min), scraped 414 items (at 1 items/min)
2015-03-24 08:02:39+0000 [xxu46_1] INFO: Crawled 420 pages (at 0 pages/min), scraped 414 items (at 0 items/min)
2015-03-24 08:03:03+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1092> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 08:03:03+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1092>
	{'abstract': u'Let R^d -&gt; A be a query problem over R^d for which there exists a data structure S that can compute P(q) in O(log n) time for any query point q in R^d. Let D be a probability measure over R^d representing a distribution of queries. We describe a data structure called the odds-on tree, of size O(n^ epsilon) that can be used as a filter that quickly computes P(q) for some query values q in R^d and relies on S for the remaining queries. With an odds-on tree, the expected query time for a point drawn according to D is O(H*+1), where H* is a lower-bound on the expected cost of any linear decision tree that solves P. Odds-on trees have a number of applications, including distribution-sensitive data structures for point location in 2-d, point-in-polytope testing in d dimensions, ray shooting in simple polygons, ray shooting in polytopes, nearest-neighbour queries in R^d, point-location in arrangements of hyperplanes in R^d, and many other geometric searching problems that can be solved in the linear-decision tree model. A standard lifting technique extends these results to algebraic decision trees of constant degree. A slightly different version of odds-on trees yields similar results for orthogonal searching problems that can be solved in the comparison tree model.',
	 'authors': u'Prosenjit Bose, Luc Devroye, Karim Douieb, Vida Dujmovic, James King, Pat Morin,',
	 'category': u'Computer Science ',
	 'date': '2010-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1002.1092',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nOdds-On Trees',
	 'urllink': u'http://arxiv.org/abs/1002.1092'}
2015-03-24 08:03:39+0000 [xxu46_1] INFO: Crawled 421 pages (at 1 pages/min), scraped 415 items (at 1 items/min)
2015-03-24 08:04:39+0000 [xxu46_1] INFO: Crawled 421 pages (at 0 pages/min), scraped 415 items (at 0 items/min)
2015-03-24 08:04:54+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1211> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 08:04:54+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1211>
	{'abstract': u"The dependency core calculus (DCC), a simple extension of the computational lambda calculus, captures a common notion of dependency that arises in many programming language settings. This notion of dependency is closely related to the notion of information flow in security; it is sensitive not only to data dependencies that cause explicit flows, but also to control dependencies that cause implicit flows. In this paper, we study variants of DCC in which the data and control dependencies are decoupled. This allows us to consider settings where a weaker notion of dependency---one that restricts only explicit flows---may usefully coexist with DCC's stronger notion of dependency. In particular, we show how strong, noninterference-based security may be reconciled with weak, trace-based security within the same system, enhancing soundness of the latter and completeness of the former.",
	 'authors': u'Avik Chaudhuri,',
	 'category': u'Computer Science ',
	 'date': '2010-4-7',
	 'pdflink': u'http://arxiv.org/pdf/1004.1211',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nLiberalizing Dependency',
	 'urllink': u'http://arxiv.org/abs/1004.1211'}
2015-03-24 08:05:39+0000 [xxu46_1] INFO: Crawled 422 pages (at 1 pages/min), scraped 416 items (at 1 items/min)
2015-03-24 08:06:08+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5180> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 08:06:08+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5180>
	{'abstract': u"Design and simulation of future mobile networks will center around human interests and behavior. We propose a design paradigm for mobile networks driven by realistic models of users' on-line behavior, based on mining of billions of wireless-LAN records. We introduce a systematic method for large-scale multi-dimensional coclustering of web activity for thousands of mobile users at 79 locations. We find surprisingly that users can be consistently modeled using ten clusters with disjoint profiles. Access patterns from multiple locations show differential user behavior. This is the first study to obtain such detailed results for mobile Internet usage.",
	 'authors': u'Saeed Moghaddam, Ahmed Helmy, Sanjay Ranka, Manas Somaiya,',
	 'category': u'Computer Science ',
	 'date': '2010-5-27',
	 'pdflink': u'http://arxiv.org/pdf/1005.5180',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nData-driven Co-clustering Model of Internet Usage in Large Mobile  Societies',
	 'urllink': u'http://arxiv.org/abs/1005.5180'}
2015-03-24 08:06:39+0000 [xxu46_1] INFO: Crawled 423 pages (at 1 pages/min), scraped 417 items (at 1 items/min)
2015-03-24 08:07:39+0000 [xxu46_1] INFO: Crawled 423 pages (at 0 pages/min), scraped 417 items (at 0 items/min)
2015-03-24 08:07:52+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1060> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 08:07:52+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1060>
	{'abstract': u"Ranking groups of researchers is important in several contexts and can serve many purposes such as the fair distribution of grants based on the scientist's publication output, concession of research projects, classification of journal editorial boards and many other applications in a social context. In this paper, we propose a method for measuring the performance of groups of researchers. The proposed method is called alpha-index and it is based on two parameters: (i) the homogeneity of the h-indexes of the researchers in the group; and (ii) the h-group, which is an extension of the h-index for groups. Our method integrates the concepts of homogeneity and absolute value of the h-index into a single measure which is appropriate for the evaluation of groups. We report on experiments that assess computer science conferences based on the h-indexes of their program committee members. Our results are similar to a manual classification scheme adopted by a research agency.",
	 'authors': u'Roberto da Silva, Jose Palazzo de Oliveira, Jose Valdeni de Lima, Viviane Moreira,',
	 'category': u'Computer Science ',
	 'date': '2010-2-4',
	 'pdflink': u'http://arxiv.org/pdf/1002.1060',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nStatistics for Ranking Program Committees and Editorial Boards',
	 'urllink': u'http://arxiv.org/abs/1002.1060'}
2015-03-24 08:08:39+0000 [xxu46_1] INFO: Crawled 424 pages (at 1 pages/min), scraped 418 items (at 1 items/min)
2015-03-24 08:09:14+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1208> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 08:09:14+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1208>
	{'abstract': u'In the vertex connectivity survivable network design problem we are given an undirected graph G = (V,E) and connectivity requirement r(u,v) for each pair of vertices u,v. We are also given a cost function on the set of edges. Our goal is to find the minimum cost subset of edges such that for every pair (u,v) of vertices we have r(u,v) vertex disjoint paths in the graph induced by the chosen edges. Recently, Chuzhoy and Khanna presented a randomized algorithm that achieves a factor of O(k^3 log n) for this problem where k is the maximum connectivity requirement. In this paper we derandomize their algorithm to get a deterministic O(k^3 log n) factor algorithm. Another problem of interest is the single source version of the problem, where there is a special vertex s and all non-zero connectivity requirements must involve s. We also give a deterministic O(k^2 log n) algorithm for this problem.',
	 'authors': u'Pushkar Tripathi,',
	 'category': u'Computer Science ',
	 'date': '2010-4-7',
	 'pdflink': u'http://arxiv.org/pdf/1004.1208',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nA Deterministic Algorithm for the Vertex Connectivity Survivable Network  Design Problem',
	 'urllink': u'http://arxiv.org/abs/1004.1208'}
2015-03-24 08:09:39+0000 [xxu46_1] INFO: Crawled 425 pages (at 1 pages/min), scraped 419 items (at 1 items/min)
2015-03-24 08:10:27+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5170> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 08:10:27+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5170>
	{'abstract': u"The present report, has been inspired by the need of the author and its colleagues to understand the underlying theory of Wirtinger's Calculus and to further extend it to include the kernel case. The aim of the present manuscript is twofold: a) it endeavors to provide a more rigorous presentation of the related material, focusing on aspects that the author finds more insightful and b) it extends the notions of Wirtinger's calculus on general Hilbert spaces (such as Reproducing Hilbert Kernel Spaces).",
	 'authors': u'P. Bouboulis,',
	 'category': u'Computer Science ',
	 'date': '2010-5-25',
	 'pdflink': u'http://arxiv.org/pdf/1005.5170',
	 'subjects': u'Learning (cs.LG)',
	 'title': u"\nWirtinger's Calculus in general Hilbert Spaces",
	 'urllink': u'http://arxiv.org/abs/1005.5170'}
2015-03-24 08:10:39+0000 [xxu46_1] INFO: Crawled 426 pages (at 1 pages/min), scraped 420 items (at 1 items/min)
2015-03-24 08:11:39+0000 [xxu46_1] INFO: Crawled 426 pages (at 0 pages/min), scraped 420 items (at 0 items/min)
2015-03-24 08:12:04+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1021> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 08:12:04+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1021>
	{'abstract': u'We present a new heuristic point-to-point routing algorithm based on contraction hierarchies (CH). Given an epsilon &gt;= 0, we can prove that the length of the path computed by our algorithm is at most (1+epsilon) times the length of the optimal (shortest) path. CH is based on node contraction: removing nodes from a network and adding shortcut edges to preserve shortest path distances. Our algorithm tries to avoid shortcuts even when a replacement path is epsilon times longer.',
	 'authors': u'Robert Geisberger,',
	 'category': u'Computer Science ',
	 'date': '2010-2-4',
	 'pdflink': u'http://arxiv.org/pdf/1002.1021',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nHeuristic Contraction Hierarchies with Approximation Guarantee',
	 'urllink': u'http://arxiv.org/abs/1002.1021'}
2015-03-24 08:12:39+0000 [xxu46_1] INFO: Crawled 427 pages (at 1 pages/min), scraped 421 items (at 1 items/min)
2015-03-24 08:13:05+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1198> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 08:13:05+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1198>
	{'abstract': u'This paper introduces a class of structured lowdensity parity-check (LDPC) codes whose parity check matrices are arrays of permutation matrices. The permutation matrices are obtained from Latin squares and form a finite field under some matrix operations. They are chosen so that the Tanner graphs do not contain subgraphs harmful to iterative decoding algorithms. The construction of column-weight-three codes is presented. Although the codes are optimized for the Gallager A/B algorithm over the binary symmetric channel (BSC), their error performance is very good on the additive white Gaussian noise channel (AWGNC) as well.',
	 'authors': u'Dung Viet Nguyen, Bane Vasic, Michael Marcellin, Shashi Kiran Chilappagari,',
	 'category': u'Computer Science ',
	 'date': '2010-4-7',
	 'pdflink': u'http://arxiv.org/pdf/1004.1198',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nStructured LDPC Codes from Permutation Matrices Free of Small Trapping  Sets',
	 'urllink': u'http://arxiv.org/abs/1004.1198'}
2015-03-24 08:13:39+0000 [xxu46_1] INFO: Crawled 428 pages (at 1 pages/min), scraped 422 items (at 1 items/min)
2015-03-24 08:14:28+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5142> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 08:14:28+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5142>
	{'abstract': u"We quickly review labelled Markov processes (LMP) and provide a counterexample showing that in general measurable spaces, event bisimilarity and state bisimilarity differ in LMP. This shows that the logic in Desharnais [*] does not characterize state bisimulation in non-analytic measurable spaces. Furthermore we show that, under current foundations of Mathematics, such logical characterization is unprovable for spaces that are projections of a coanalytic set. Underlying this construction there is a proof that stationary Markov processes over general measurable spaces do not have semi-pullbacks. ([*] J. Desharnais, Labelled Markov Processes. School of Computer Science. McGill University, Montr 'eal (1999))",
	 'authors': u'Pedro S\xe1nchez Terraf,',
	 'category': u'Computer Science ',
	 'date': '2010-5-27',
	 'pdflink': u'http://arxiv.org/pdf/1005.5142',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nUnprovability of the Logical Characterization of Bisimulation',
	 'urllink': u'http://arxiv.org/abs/1005.5142'}
2015-03-24 08:14:39+0000 [xxu46_1] INFO: Crawled 429 pages (at 1 pages/min), scraped 423 items (at 1 items/min)
2015-03-24 08:15:39+0000 [xxu46_1] INFO: Crawled 429 pages (at 0 pages/min), scraped 423 items (at 0 items/min)
2015-03-24 08:15:51+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1016> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 08:15:51+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1016>
	{'abstract': u'We introduce a new approach to model and analyze emph. It is fully based on discrete mathematics and yields a class of mobility models, called the emph Model. This model can be seen as the discrete version of the emph Model including all variants of the emph Model cite. We derive fundamental properties and emph analytical formulas for the emph yielded by the Markov Trace Model. Such results can be exploited to compute formulas and properties for concrete cases of the Markov Trace Model by just applying counting arguments. We apply the above general results to the discrete version of the emph over a square of bounded size. We get formulas for the total stationary distribution and for two important emph ones: the agent spatial and destination distributions. Our method makes the analysis of complex mobile systems a feasible task. As a further evidence of this important fact, we first model a complex vehicular-mobile system over a set of crossing streets. Several concrete issues are implemented such as parking zones, traffic lights, and variable vehicle speeds. By using a emph version of the Markov Trace Model, we get explicit formulas for the stationary distributions yielded by this vehicular-mobile model as well.',
	 'authors': u'Andrea Clementi, Angelo Monti, Riccardo Silvestri,',
	 'category': u'Computer Science ',
	 'date': '2010-2-4',
	 'pdflink': u'http://arxiv.org/pdf/1002.1016',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nModelling Mobility: A Discrete Revolution',
	 'urllink': u'http://arxiv.org/abs/1002.1016'}
2015-03-24 08:16:39+0000 [xxu46_1] INFO: Crawled 430 pages (at 1 pages/min), scraped 424 items (at 1 items/min)
2015-03-24 08:17:26+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1195> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 08:17:26+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1195>
	{'abstract': u'In this paper, pilot-symbol-assisted transmission in cognitive radio systems over time selective flat fading channels is studied. It is assumed that causal and noncausal Wiener filter estimators are used at the secondary receiver with the aid of training symbols to obtain the channel side information (CSI) under an interference power constraint. Cognitive radio model is described together with detection and false alarm probabilities determined by using a Neyman-Person detector for channel sensing. Subsequently, for both filters, the variances of estimate errors are calculated from the Doppler power spectrum of the channel, and achievable rate expressions are provided considering the scenarios which are results of channel sensing. Numerical results are obtained in Gauss-Markov modeled channels, and achievable rates obtained by using causal and noncausal filters are compared and it is shown that the difference is decreasing with increasing signal-to-noise ratio (SNR). Moreover, the optimal probability of detection and false alarm values are shown, and the tradeoff between these two parameters is discussed. Finally, optimal power distributions are provided.',
	 'authors': u'Sami Akin, Mustafa Cenk Gursoy,',
	 'category': u'Computer Science ',
	 'date': '2010-4-7',
	 'pdflink': u'http://arxiv.org/pdf/1004.1195',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nErgodic Capacity Analysis in Cognitive Radio Systems under Channel  Uncertainty',
	 'urllink': u'http://arxiv.org/abs/1004.1195'}
2015-03-24 08:17:39+0000 [xxu46_1] INFO: Crawled 431 pages (at 1 pages/min), scraped 425 items (at 1 items/min)
2015-03-24 08:18:39+0000 [xxu46_1] INFO: Crawled 431 pages (at 0 pages/min), scraped 425 items (at 0 items/min)
2015-03-24 08:19:11+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.1005> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 08:19:11+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.1005>
	{'abstract': u'Agile development processes and component-based software architectures are two software engineering approaches that contribute to enable the rapid building and evolution of applications. Nevertheless, few approaches have proposed a framework to combine agile and component-based development, allowing an application to be tested throughout the entire development cycle. To address this problematic, we have built CALICO, a model-based framework that allows applications to be safely developed in an iterative and incremental manner. The CALICO approach relies on the synchronization of a model view, which specifies the application properties, and a runtime view, which contains the application in its execution context. Tests on the application specifications that require values only known at runtime, are automatically integrated by CALICO into the running application, and the captured needed values are reified at execution time to resume the tests and inform the architect of potential problems. Any modification at the model level that does not introduce new errors is automatically propagated to the running system, allowing the safe evolution of the application. In this paper, we illustrate the CALICO development process with a concrete example and provide information on the current implementation of our framework.',
	 'authors': u'Guillaume Waignier, Est\xe9ban Duguep\xe9roux, Anne-Fran\xe7oise Le Meur, Laurence Duchien,',
	 'category': u'Computer Science ',
	 'date': '2010-2-4',
	 'pdflink': u'http://arxiv.org/pdf/1002.1005',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nA Framework for Agile Development of Component-Based Applications',
	 'urllink': u'http://arxiv.org/abs/1002.1005'}
2015-03-24 08:19:39+0000 [xxu46_1] INFO: Crawled 432 pages (at 1 pages/min), scraped 426 items (at 1 items/min)
2015-03-24 08:20:39+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1194> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 08:20:39+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1194>
	{'abstract': u'The edit distance problem is a classical fundamental problem in computer science in general, and in combinatorial pattern matching in particular. The standard dynamic programming solution for this problem computes the edit-distance between a pair of strings of total length O(N) in O(N^2) time. To this date, this quadratic upper-bound has never been substantially improved for general strings. However, there are known techniques for breaking this bound in case the strings are known to compress well under a particular compression scheme. The basic idea is to first compress the strings, and then to compute the edit distance between the compressed strings. As it turns out, practically all known o(N^2) edit-distance algorithms work, in some sense, under the same paradigm described above. It is therefore natural to ask whether there is a single edit-distance algorithm that works for strings which are compressed under any compression scheme. A rephrasing of this question is to ask whether a single algorithm can exploit the compressibility properties of strings under any compression method, even if each string is compressed using a di?erent compression. In this paper we set out to answer this question by using straight line programs. These provide a generic platform for representing many popular compression schemes including the LZ-family, Run-Length Encoding, Byte-Pair Encoding, and dictionary methods. For two strings of total length N having straight-line program representations of total size n, we present an algorithm running in O(nN log(N/n)) time for computing the edit-distance of these two strings under any rational scoring function, and an O(n^N^) time algorithm for arbitrary scoring functions. Our new result, while providing a signi cant speed up for highly compressible strings, does not surpass the quadratic time bound even in the worst case scenario.',
	 'authors': u'Danny Hermelin, Gad M. Landau, Shir Landau, Oren Weimann,',
	 'category': u'Computer Science ',
	 'date': '2010-4-7',
	 'pdflink': u'http://arxiv.org/pdf/1004.1194',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nUnified Compression-Based Acceleration of Edit-Distance Computation',
	 'urllink': u'http://arxiv.org/abs/1004.1194'}
2015-03-24 08:20:39+0000 [xxu46_1] INFO: Crawled 433 pages (at 1 pages/min), scraped 427 items (at 1 items/min)
2015-03-24 08:21:39+0000 [xxu46_1] INFO: Crawled 433 pages (at 0 pages/min), scraped 427 items (at 0 items/min)
2015-03-24 08:22:00+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5137> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 08:22:00+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5137>
	{'abstract': u"An important problem to be solved in modeling head-related impulse responses (HRIRs) is how to individualize HRIRs so that they are suitable for a listener. We modeled the entire magnitude head-related transfer functions (HRTFs), in frequency domain, for sound sources on horizontal plane of 37 subjects using principal components analysis (PCA). The individual magnitude HRTFs could be modeled adequately well by a linear combination of only ten orthonormal basis functions. The goal of this research was to establish multiple linear regression (MLR) between weights of basis functions obtained from PCA and fewer anthropometric measurements in order to individualize a given listener's HRTFs with his or her own anthropomety. We proposed here an improved individualization method based on MLR of weights of basis functions by utilizing 8 chosen out of 27 anthropometric measurements. Our objective experiments' results show a superior performance than that of our previous work on individualizing minimum phase HRIRs and also better than similar research. The proposed individualization method shows that the individualized magnitude HRTFs could approximated well the the original ones with small error. Moving sound employing the reconstructed HRIRs could be perceived as if it was moving around the horizontal plane.",
	 'authors': u'W. Wahab Hugeng, D. Gunawan,',
	 'category': u'Computer Science ',
	 'date': '2010-5-27',
	 'pdflink': u'http://arxiv.org/pdf/1005.5137',
	 'subjects': u'Sound (cs.SD)',
	 'title': u'\nImproved Method for Individualization of Head-Related Transfer Functions  on Horizontal Plane Using Reduced Number of Anthropometric Measurements',
	 'urllink': u'http://arxiv.org/abs/1005.5137'}
2015-03-24 08:22:39+0000 [xxu46_1] INFO: Crawled 434 pages (at 1 pages/min), scraped 428 items (at 1 items/min)
2015-03-24 08:23:08+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0986> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 08:23:08+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0986>
	{'abstract': u'We provide evidence that it is computationally difficult to approximate the partition function of the ferromagnetic q-state Potts model when q&gt;2. Specifically we show that the partition function is hard for the complexity class #RHPi_1 under approximation-preserving reducibility. Thus, it is as hard to approximate the partition function as it is to find approximate solutions to a wide range of counting problems, including that of determining the number of independent sets in a bipartite graph. Our proof exploits the first order phase transition of the "random cluster" model, which is a probability distribution on graphs that is closely related to the q-state Potts model.',
	 'authors': u'Leslie Ann Goldberg, Mark Jerrum,',
	 'category': u'Computer Science ',
	 'date': '2010-2-4',
	 'pdflink': u'http://arxiv.org/pdf/1002.0986',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nApproximating the partition function of the ferromagnetic Potts model',
	 'urllink': u'http://arxiv.org/abs/1002.0986'}
2015-03-24 08:23:39+0000 [xxu46_1] INFO: Crawled 435 pages (at 1 pages/min), scraped 429 items (at 1 items/min)
2015-03-24 08:24:32+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1184> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 08:24:32+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1184>
	{'abstract': u'This paper consists of three parts. The first part presents a large class of new binary quasi-cyclic (QC)-LDPC codes with girth of at least 6 whose parity-check matrices are constructed based on cyclic subgroups of finite fields. Experimental results show that the codes constructed perform well over the binary-input AWGN channel with iterative decoding using the sum-product algorithm (SPA). The second part analyzes the ranks of the parity-check matrices of codes constructed based on finite fields with characteristic of 2 and gives combinatorial expressions for these ranks. The third part identifies a subclass of constructed QC-LDPC codes that have large minimum distances. Decoding of codes in this subclass with the SPA converges very fast.',
	 'authors': u'Li Zhang, Shu Lin, Khaled Abdel-Ghaffar, Zhi Ding, Bo Zhou,',
	 'category': u'Computer Science ',
	 'date': '2010-4-7',
	 'pdflink': u'http://arxiv.org/pdf/1004.1184',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nCirculant Arrays on Cyclic Subgroups of Finite Fields: Rank Analysis and  Construction of Quasi-Cyclic LDPC Codes',
	 'urllink': u'http://arxiv.org/abs/1004.1184'}
2015-03-24 08:24:39+0000 [xxu46_1] INFO: Crawled 436 pages (at 1 pages/min), scraped 430 items (at 1 items/min)
2015-03-24 08:25:39+0000 [xxu46_1] INFO: Crawled 436 pages (at 0 pages/min), scraped 430 items (at 0 items/min)
2015-03-24 08:26:11+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5130> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 08:26:11+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5130>
	{'abstract': u'The research effort on mobile computing has focused mainly on routing and usually assumes that all mobile devices (MDs) are cooperative. These assumptions hold on military or search and rescue operations, where all hosts are from the same authority and their users have common goals. The application of mobile ad hoc networks (MANETs) as open networks has emerged recently but proliferated exponentially. Energy is a valuable commodity in MANETs due to the limited battery of the portable devices. Batteries typically cannot be replaced in MANETs, making their lifetime limited. Diverse users, with unlike goals, share the resources of their devices and ensuring global connectivity comes very low in their priority. This sort of communities can already be found in wired networks, namely on peer-to-peer networks. In this scenario, open MANETs will likely resemble social environments. A group of persons can provide benefits to each of its members as long as everyone provides his contribution. For our particular case, each element of a MANET will be called to forward messages and to participate on routing protocols. A selfish behavior threatens the entire community and also this behavior is infectious as, other MDs may also start to perform in the same way. In the extreme, this can take to the complete sabotage of the network. This paper investigates the prevalent malicious attacks in MANET and analyzes recent selfish trends in MANET. We analyzed the respective strengths and vulnerabilities of the existing selfish behaviour prevention scheme.',
	 'authors': u'P.K.Suri, Kavita Taneja,',
	 'category': u'Computer Science ',
	 'date': '2010-5-27',
	 'pdflink': u'http://arxiv.org/pdf/1005.5130',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nExploring Selfish Trends of Malicious Mobile Devices in MANET',
	 'urllink': u'http://arxiv.org/abs/1005.5130'}
2015-03-24 08:26:39+0000 [xxu46_1] INFO: Crawled 437 pages (at 1 pages/min), scraped 431 items (at 1 items/min)
2015-03-24 08:27:02+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0982> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 08:27:03+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0982>
	{'abstract': u'In this paper we show how certain techniques of image processing, having different scopes, can be joined together under a common "algebraic roof".',
	 'authors': u'Ciro Russo,',
	 'category': u'Computer Science ',
	 'date': '2010-2-4',
	 'pdflink': u'http://arxiv.org/pdf/1002.0982',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nA Unified Algebraic Framework for Fuzzy Image Compression and  Mathematical Morphology',
	 'urllink': u'http://arxiv.org/abs/1002.0982'}
2015-03-24 08:27:39+0000 [xxu46_1] INFO: Crawled 438 pages (at 1 pages/min), scraped 432 items (at 1 items/min)
2015-03-24 08:28:39+0000 [xxu46_1] INFO: Crawled 438 pages (at 0 pages/min), scraped 432 items (at 0 items/min)
2015-03-24 08:28:39+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1158> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 08:28:39+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1158>
	{'abstract': u'We construct MDS Euclidean and Hermitian self-dual codes over large finite fields of odd and even characteristics. Our codes arise from cyclic and negacyclic duadic codes.',
	 'authors': u'Kenza Guenda,',
	 'category': u'Computer Science ',
	 'date': '2010-4-7',
	 'pdflink': u'http://arxiv.org/pdf/1004.1158',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nNew MDS Self-Dual Codes over Large Finite Fields',
	 'urllink': u'http://arxiv.org/abs/1004.1158'}
2015-03-24 08:29:39+0000 [xxu46_1] INFO: Crawled 439 pages (at 1 pages/min), scraped 433 items (at 1 items/min)
2015-03-24 08:29:53+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5129> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 08:29:53+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5129>
	{'abstract': u'This paper defines the components of radio frequency identifiers (RFID). It also explores the different areas and sectors where RFID can be beneficial. The paper discusses the uses and advantages of RFID in deference, consumer packaged goods (CPG), healthcare, logistics, manufacturing, and retail.',
	 'authors': u'Ahmed Elmorshidy,',
	 'category': u'Computer Science ',
	 'date': '2010-5-27',
	 'pdflink': u'http://arxiv.org/pdf/1005.5129',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nRadio Frequency Identifiers: What are the Possibilities?',
	 'urllink': u'http://arxiv.org/abs/1005.5129'}
2015-03-24 08:30:39+0000 [xxu46_1] INFO: Crawled 440 pages (at 1 pages/min), scraped 434 items (at 1 items/min)
2015-03-24 08:30:56+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0971> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 08:30:56+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0971>
	{'abstract': u'In this paper we present the state of advancement of the French ANR WebStand project. The objective of this project is to construct a customizable XML based warehouse platform to acquire, transform, analyze, store, query and export data from the web, in particular mailing lists, with the final intension of using this data to perform sociological studies focused on social groups of World Wide Web, with a specific emphasis on the temporal aspects of this data. We are currently using this system to analyze the standardization process of the W3C, through its social network of standard setters.',
	 'authors': u'Benjamin Nguyen, Fran\xe7ois-Xavier Dudouet, Dario Colazzo, Antoine Vion, Ioana Manolescu, Pierre Senellart,',
	 'category': u'Computer Science ',
	 'date': '2010-2-4',
	 'pdflink': u'http://arxiv.org/pdf/1002.0971',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nThe WebStand Project',
	 'urllink': u'http://arxiv.org/abs/1002.0971'}
2015-03-24 08:31:39+0000 [xxu46_1] INFO: Crawled 441 pages (at 1 pages/min), scraped 435 items (at 1 items/min)
2015-03-24 08:32:39+0000 [xxu46_1] INFO: Crawled 441 pages (at 0 pages/min), scraped 435 items (at 0 items/min)
2015-03-24 08:32:44+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1155> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 08:32:44+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1155>
	{'abstract': u'We consider the optimal design of sequential transmission over broadcast channel with nested feedback. Nested feedback means that the channel output of the outer channel is also available at the decoder of the inner channel. We model the communication system as a decentralized team with three decision makers---the encoder and the two decoders. Structure of encoding and decoding strategies that minimize a total distortion measure over a finite horizon are determined. The results are applicable for real-time communication as well as for the information theoretic setup.',
	 'authors': u'Aditya Mahajan,',
	 'category': u'Computer Science ',
	 'date': '2010-4-7',
	 'pdflink': u'http://arxiv.org/pdf/1004.1155',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOptimal sequential transmission over broadcast channel with nested  feedback',
	 'urllink': u'http://arxiv.org/abs/1004.1155'}
2015-03-24 08:33:39+0000 [xxu46_1] INFO: Crawled 442 pages (at 1 pages/min), scraped 436 items (at 1 items/min)
2015-03-24 08:33:48+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5125> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 08:33:48+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5125>
	{'abstract': u'The IEEE 802.16 technology (WiMAX) is a promising technology for providing last-mile connectivity by radio link due to its high speed data rates, low cost of deployment, and large coverage area. However, the maximum number of channels defined in the current system may cause a potential bottleneck and limit the overall system capacity. The aim of this paper is to compare the impact on system performance of different solutions used to mitigate the impairments due to the radio channel. In particular, taking into account the WiMAX system capacity as well as application delays, the paper presents the simulation results obtained when a static QPSK 1/2 Modulation and Coding Scheme (MCS) is adopted. Then, the study is aimed at evaluating the improvements introduced by the adoption of an adaptive modulation and coding (AMC) and an AMC jointly with Hybrid Automatic Repeat reQuest (HARQ). Results indicate that the best strategy is to use an aggressive AMC table with the HARQ.',
	 'authors': u'Iwan Adhicandra,',
	 'category': u'Computer Science ',
	 'date': '2010-5-27',
	 'pdflink': u'http://arxiv.org/pdf/1005.5125',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nUsing AMC and HARQ to Optimize System Capacity and Application Delays in  WiMAX Networks',
	 'urllink': u'http://arxiv.org/abs/1005.5125'}
2015-03-24 08:34:39+0000 [xxu46_1] INFO: Crawled 443 pages (at 1 pages/min), scraped 437 items (at 1 items/min)
2015-03-24 08:35:20+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0963> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 08:35:20+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0963>
	{'abstract': u"As mobile devices with positioning capabilities continue to proliferate, data management for so-called trajectory databases that capture the historical movements of populations of moving objects becomes important. This paper considers the querying of such databases for convoys, a convoy being a group of objects that have traveled together for some time. More specifically, this paper formalizes the concept of a convoy query using density-based notions, in order to capture groups of arbitrary extents and shapes. Convoy discovery is relevant for real-life applications in throughput planning of trucks and carpooling of vehicles. Although there has been extensive research on trajectories in the literature, none of this can be applied to retrieve correctly exact convoy result sets. Motivated by this, we develop three efficient algorithms for convoy discovery that adopt the well-known filter-refinement framework. In the filter step, we apply line-simplification techniques on the trajectories and establish distance bounds between the simplified trajectories. This permits efficient convoy discovery over the simplified trajectories without missing any actual convoys. In the refinement step, the candidate convoys are further processed to obtain the actual convoys. Our comprehensive empirical study offers insight into the properties of the paper's proposals and demonstrates that the proposals are effective and efficient on real-world trajectory data.",
	 'authors': u'Hoyoung Jeung, Man Lung Yiu, Xiaofang Zhou, Christian S. Jensen, Heng Tao Shen,',
	 'category': u'Computer Science ',
	 'date': '2010-2-4',
	 'pdflink': u'http://arxiv.org/pdf/1002.0963',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nDiscovery of Convoys in Trajectory Databases',
	 'urllink': u'http://arxiv.org/abs/1002.0963'}
2015-03-24 08:35:39+0000 [xxu46_1] INFO: Crawled 444 pages (at 1 pages/min), scraped 438 items (at 1 items/min)
2015-03-24 08:36:39+0000 [xxu46_1] INFO: Crawled 444 pages (at 0 pages/min), scraped 438 items (at 0 items/min)
2015-03-24 08:36:59+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1086> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 08:36:59+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1086>
	{'abstract': u'Transmitted data may be corrupted by both noise and data loss. Grassmannian frames are in some sense optimal representations of data transmitted over a noisy channel that may lose some of the transmitted coefficients. Fusion frame (or frame of subspaces) theory is a new area that has potential to be applied to problems in such fields as distributed sensing and parallel processing. Grassmannian fusion frames combine elements from both theories. A simple, novel construction of Grassmannian fusion frames with an extension to Grassmannian fusion frames with local frames shall be presented. Some connections to sparse representations shall also be discussed.',
	 'authors': u'Emily J. King,',
	 'category': u'Computer Science ',
	 'date': '2010-4-5',
	 'pdflink': u'http://arxiv.org/pdf/1004.1086',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nGrassmannian Fusion Frames',
	 'urllink': u'http://arxiv.org/abs/1004.1086'}
2015-03-24 08:37:39+0000 [xxu46_1] INFO: Crawled 445 pages (at 1 pages/min), scraped 439 items (at 1 items/min)
2015-03-24 08:38:34+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5124> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 08:38:34+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5124>
	{'abstract': u'In logic there is a clear concept of what constitutes a proof and what not. A proof is essentially defined as a finite sequence of formulae which are either axioms or derived by proof rules from formulae earlier in the sequence. Sociologically, however, it is more difficult to say what should constitute a proof and what not. In this paper we will look at different forms of proofs and try to clarify the concept of proof in the wider meaning of the term. This has implications on how proofs should be represented formally.',
	 'authors': u'Manfred Kerber,',
	 'category': u'Computer Science ',
	 'date': '2010-5-27',
	 'pdflink': u'http://arxiv.org/pdf/1005.5124',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nProofs, proofs, proofs, and proofs',
	 'urllink': u'http://arxiv.org/abs/1005.5124'}
2015-03-24 08:38:39+0000 [xxu46_1] INFO: Crawled 446 pages (at 1 pages/min), scraped 440 items (at 1 items/min)
2015-03-24 08:39:39+0000 [xxu46_1] INFO: Crawled 446 pages (at 0 pages/min), scraped 440 items (at 0 items/min)
2015-03-24 08:39:59+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0942> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 08:39:59+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0942>
	{'abstract': u"We previously developed a polymorphic type system and a type checker for a multithreaded lock-based polymorphic typed assembly language (MIL) that ensures that well-typed programs do not encounter race conditions. This paper extends such work by taking into consideration deadlocks. The extended type system verifies that locks are acquired in the proper order. Towards this end we require a language with annotations that specify the locking order. Rather than asking the programmer (or the compiler's backend) to specifically annotate each newly introduced lock, we present an algorithm to infer the annotations. The result is a type checker whose input language is non-decorated as before, but that further checks that programs are exempt from deadlocks.",
	 'authors': u'Vasco T. Vasconcelos, Francisco Martins, Tiago Cogumbreiro,',
	 'category': u'Computer Science ',
	 'date': '2010-2-4',
	 'pdflink': u'http://arxiv.org/pdf/1002.0942',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nType Inference for Deadlock Detection in a Multithreaded Polymorphic  Typed Assembly Language',
	 'urllink': u'http://arxiv.org/abs/1002.0942'}
2015-03-24 08:40:39+0000 [xxu46_1] INFO: Crawled 447 pages (at 1 pages/min), scraped 441 items (at 1 items/min)
2015-03-24 08:41:24+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1077> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 08:41:24+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1077>
	{'abstract': u'We present CLTLB(D), an extension of PLTLB (PLTL with both past and future operators) augmented with atomic formulae built over a constraint system D. Even for decidable constraint systems, satisfiability and Model Checking problem of such logic can be undecidable. We introduce suitable restrictions and assumptions that are shown to make the satisfiability problem for the extended logic decidable. Moreover for a large class of constraint systems we propose an encoding that realize an effective decision procedure for the Bounded Reachability problem.',
	 'authors': u'Marcello M. Bersani, Achille Frigeri, Angelo Morzenti, Matteo Pradella, Matteo Rossi, Pierluigi San Pietro,',
	 'category': u'Computer Science ',
	 'date': '2010-4-7',
	 'pdflink': u'http://arxiv.org/pdf/1004.1077',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nBounded Reachability for Temporal Logic over Constraint Systems',
	 'urllink': u'http://arxiv.org/abs/1004.1077'}
2015-03-24 08:41:39+0000 [xxu46_1] INFO: Crawled 448 pages (at 1 pages/min), scraped 442 items (at 1 items/min)
2015-03-24 08:42:39+0000 [xxu46_1] INFO: Crawled 448 pages (at 0 pages/min), scraped 442 items (at 0 items/min)
2015-03-24 08:42:42+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5118> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 08:42:42+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5118>
	{'abstract': u'Wireless sensor networks are conceived to monitor a certain application or physical phenomena and are supposed to function for several years without any human intervention for maintenance. Thus, the main issue in sensor networks is often to extend the lifetime of the network by reducing energy consumption. On the other hand, some applications have high priority traffic that needs to be transferred within a bounded end-to-end delay while maintaining an energy efficient behavior. We propose MaCARI, a time segmentation protocol that saves energy, improves the overall performance of the network and enables quality of service in terms of guaranteed access to the medium and end-to-end delays. This time segmentation is achieved by synchronizing the activity of nodes using a tree-based beacon propagation and allocating activity periods for each cluster of nodes. The tree-based topology is inspired from the cluster-tree proposed by the ZigBee standard. The efficiency of our protocol is proven analytically, by simulation and through real testbed measurements.',
	 'authors': u'Gerard Chalhoub, Fran\xe7ois Delobel, Michel Misson,',
	 'category': u'Computer Science ',
	 'date': '2010-5-27',
	 'pdflink': u'http://arxiv.org/pdf/1005.5118',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nTime Segmentation Approach Allowing QoS and Energy Saving for Wireless  Sensor Networks',
	 'urllink': u'http://arxiv.org/abs/1005.5118'}
2015-03-24 08:43:39+0000 [xxu46_1] INFO: Crawled 449 pages (at 1 pages/min), scraped 443 items (at 1 items/min)
2015-03-24 08:44:10+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0940> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 08:44:10+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0940>
	{'abstract': u'A challenge for programming language research is to design and implement multi-threaded low-level languages providing static guarantees for memory safety and freedom from data races. Towards this goal, we present a concurrent language employing safe region-based memory management and hierarchical locking of regions. Both regions and locks are treated uniformly, and the language supports ownership transfer, early deallocation of regions and early release of locks in a safe manner.',
	 'authors': u'Prodromos Gerakios, Nikolaos Papaspyrou, Konstantinos Sagonas,',
	 'category': u'Computer Science ',
	 'date': '2010-2-4',
	 'pdflink': u'http://arxiv.org/pdf/1002.0940',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nA Concurrent Language with a Uniform Treatment of Regions and Locks',
	 'urllink': u'http://arxiv.org/abs/1002.0940'}
2015-03-24 08:44:39+0000 [xxu46_1] INFO: Crawled 450 pages (at 1 pages/min), scraped 444 items (at 1 items/min)
2015-03-24 08:45:34+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1061> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 08:45:34+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1061>
	{'abstract': u'In density estimation task, maximum entropy model (Maxent) can effectively use reliable prior information via certain constraints, i.e., linear constraints without empirical parameters. However, reliable prior information is often insufficient, and the selection of uncertain constraints becomes necessary but poses considerable implementation complexity. Improper setting of uncertain constraints can result in overfitting or underfitting. To solve this problem, a generalization of Maxent, under Tsallis entropy framework, is proposed. The proposed method introduces a convex quadratic constraint for the correction of (expected) Tsallis entropy bias (TEB). Specifically, we demonstrate that the expected Tsallis entropy of sampling distributions is smaller than the Tsallis entropy of the underlying real distribution. This expected entropy reduction is exactly the (expected) TEB, which can be expressed by a closed-form formula and act as a consistent and unbiased correction. TEB indicates that the entropy of a specific sampling distribution should be increased accordingly. This entails a quantitative re-interpretation of the Maxent principle. By compensating TEB and meanwhile forcing the resulting distribution to be close to the sampling distribution, our generalized TEBC Maxent can be expected to alleviate the overfitting and underfitting. We also present a connection between TEB and Lidstone estimator. As a result, TEB-Lidstone estimator is developed by analytically identifying the rate of probability correction in Lidstone. Extensive empirical evaluation shows promising performance of both TEBC Maxent and TEB-Lidstone in comparison with various state-of-the-art density estimation methods.',
	 'authors': u'Yuexian Hou, Tingxu Yan, Peng Zhang, Dawei Song, Wenjie Li,',
	 'category': u'Computer Science ',
	 'date': '2010-4-7',
	 'pdflink': u'http://arxiv.org/pdf/1004.1061',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nOn Tsallis Entropy Bias and Generalized Maximum Entropy Models',
	 'urllink': u'http://arxiv.org/abs/1004.1061'}
2015-03-24 08:45:39+0000 [xxu46_1] INFO: Crawled 451 pages (at 1 pages/min), scraped 445 items (at 1 items/min)
2015-03-24 08:46:39+0000 [xxu46_1] INFO: Crawled 451 pages (at 0 pages/min), scraped 445 items (at 0 items/min)
2015-03-24 08:47:13+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5115> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 08:47:13+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5115>
	{'abstract': u'The Global Positioning Systems (GPS) and Inertial Navigation System (INS) technology have attracted a considerable importance recently because of its large number of solutions serving both military as well as civilian applications. This paper aims to develop a more efficient and especially a faster method for processing the GPS signal in case of INS signal loss without losing the accuracy of the data. The conventional or usual method consists of processing data through a neural network and obtaining accurate positioning output data. The new or improved method adds selective filtering at the low-band frequency, the mid-band frequency and the high band frquency, before processing the GPS data through the neural network, so that the processing time is decreased significantly while the accuracy remains the same.',
	 'authors': u'M.Nguyen-H, C. Zhou,',
	 'category': u'Computer Science ',
	 'date': '2010-5-27',
	 'pdflink': u'http://arxiv.org/pdf/1005.5115',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nImproving GPS/INS Integration through Neural Networks',
	 'urllink': u'http://arxiv.org/abs/1005.5115'}
2015-03-24 08:47:39+0000 [xxu46_1] INFO: Crawled 452 pages (at 1 pages/min), scraped 446 items (at 1 items/min)
2015-03-24 08:47:56+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0939> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 08:47:56+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0939>
	{'abstract': u"The upcoming many-core architectures require software developers to exploit concurrency to utilize available computational power. Today's high-level language virtual machines (VMs), which are a cornerstone of software development, do not provide sufficient abstraction for concurrency concepts. We analyze concrete and abstract concurrency models and identify the challenges they impose for VMs. To provide sufficient concurrency support in VMs, we propose to integrate concurrency operations into VM instruction sets. Since there will always be VMs optimized for special purposes, our goal is to develop a methodology to design instruction sets with concurrency support. Therefore, we also propose a list of trade-offs that have to be investigated to advise the design of such instruction sets. As a first experiment, we implemented one instruction set extension for shared memory and one for non-shared memory concurrency. From our experimental results, we derived a list of requirements for a full-grown experimental environment for further research.",
	 'authors': u"Stefan Marr, Michael Haupt, Stijn Timbermont, Bram Adams, Theo D'Hondt, Pascal Costanza, Wolfgang De Meuter,",
	 'category': u'Computer Science ',
	 'date': '2010-2-4',
	 'pdflink': u'http://arxiv.org/pdf/1002.0939',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nVirtual Machine Support for Many-Core Architectures: Decoupling Abstract  from Concrete Concurrency Models',
	 'urllink': u'http://arxiv.org/abs/1002.0939'}
2015-03-24 08:48:39+0000 [xxu46_1] INFO: Crawled 453 pages (at 1 pages/min), scraped 447 items (at 1 items/min)
2015-03-24 08:48:51+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1058> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 08:48:51+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1058>
	{'abstract': u'Wireless networks equipped with the CSMA protocol are subject to collisions due to interference. For a given interference range we investigate the tradeoff between collisions (hidden nodes) and unused capacity (exposed nodes). We show that the sensing range that maximizes throughput critically depends on the activation rate of nodes. For infinite line networks, we prove the existence of a threshold: When the activation rate is below this threshold the optimal sensing range is small (to maximize spatial reuse). When the activation rate is above the threshold the optimal sensing range is just large enough to preclude all collisions. Simulations suggest that this threshold policy extends to more complex linear and non-linear topologies.',
	 'authors': u'P.M. van de Ven, A.J.E.M. Janssen, J.S.H. van Leeuwaarden,',
	 'category': u'Computer Science ',
	 'date': '2010-4-7',
	 'pdflink': u'http://arxiv.org/pdf/1004.1058',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nOptimal Tradeoff Between Exposed and Hidden Nodes in Large Wireless  Networks',
	 'urllink': u'http://arxiv.org/abs/1004.1058'}
2015-03-24 08:49:39+0000 [xxu46_1] INFO: Crawled 454 pages (at 1 pages/min), scraped 448 items (at 1 items/min)
2015-03-24 08:50:38+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5114> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 08:50:38+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5114>
	{'abstract': u'Many social Web sites allow users to annotate the content with descriptive metadata, such as tags, and more recently to organize content hierarchically. These types of structured metadata provide valuable evidence for learning how a community organizes knowledge. For instance, we can aggregate many personal hierarchies into a common taxonomy, also known as a folksonomy, that will aid users in visualizing and browsing social content, and also to help them in organizing their own content. However, learning from social metadata presents several challenges, since it is sparse, shallow, ambiguous, noisy, and inconsistent. We describe an approach to folksonomy learning based on relational clustering, which exploits structured metadata contained in personal hierarchies. Our approach clusters similar hierarchies using their structure and tag statistics, then incrementally weaves them into a deeper, bushier tree. We study folksonomy learning using social metadata extracted from the photo-sharing site Flickr, and demonstrate that the proposed approach addresses the challenges. Moreover, comparing to previous work, the approach produces larger, more accurate folksonomies, and in addition, scales better.',
	 'authors': u'Anon Plangprasopchok, Kristina Lerman, Lise Getoor,',
	 'category': u'Computer Science ',
	 'date': '2010-5-27',
	 'pdflink': u'http://arxiv.org/pdf/1005.5114',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nGrowing a Tree in the Forest: Constructing Folksonomies by Integrating  Structured Metadata',
	 'urllink': u'http://arxiv.org/abs/1005.5114'}
2015-03-24 08:50:39+0000 [xxu46_1] INFO: Crawled 455 pages (at 1 pages/min), scraped 449 items (at 1 items/min)
2015-03-24 08:51:39+0000 [xxu46_1] INFO: Crawled 455 pages (at 0 pages/min), scraped 449 items (at 0 items/min)
2015-03-24 08:52:14+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0937> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 08:52:14+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0937>
	{'abstract': u'Sensor networks are rather challenging to deploy, program, and debug. Current programming languages for these platforms suffer from a significant semantic gap between their specifications and underlying implementations. This fact precludes the development of (type-)safe applications, which would potentially simplify the task of programming and debugging deployed networks. In this paper we define a core calculus for programming sensor networks and propose to use it as an assembly language for developing type-safe, high-level programming languages.',
	 'authors': u'Francisco Martins, Lu\xeds Lopes, Jo\xe3o Barros,',
	 'category': u'Computer Science ',
	 'date': '2010-2-4',
	 'pdflink': u'http://arxiv.org/pdf/1002.0937',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nTowards the Safe Programming of Wireless Sensor Networks',
	 'urllink': u'http://arxiv.org/abs/1002.0937'}
2015-03-24 08:52:39+0000 [xxu46_1] INFO: Crawled 456 pages (at 1 pages/min), scraped 450 items (at 1 items/min)
2015-03-24 08:53:39+0000 [xxu46_1] INFO: Crawled 456 pages (at 0 pages/min), scraped 450 items (at 0 items/min)
2015-03-24 08:54:01+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1045> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 08:54:01+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1045>
	{'abstract': u'A novel channel representation for a two-hop decentralized wireless relay network (DWRN) is proposed, where the relays operate in a completely distributive fashion. The modeling paradigm applies an analogous approach to the description method for a double-directional multipath propagation channel, and takes into account the finite system spatial resolution and the extended relay listening/transmitting time. Specifically, the double-directional information azimuth spectrum (IAS) is formulated to provide a compact representation of information flows in a DWRN. The proposed channel representation is then analyzed from a geometrically-based statistical modeling perspective. Finally, we look into the problem of relay network tomography (RNT), which solves an inverse problem to infer the internal structure of a DWRN by using the instantaneous doubledirectional IAS recorded at multiple measuring nodes exterior to the relay region.',
	 'authors': u'Yifan Chen, Chau Yuen,',
	 'category': u'Computer Science ',
	 'date': '2010-4-7',
	 'pdflink': u'http://arxiv.org/pdf/1004.1045',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nDouble-Directional Information Azimuth Spectrum and Relay Network  Tomography for a Decentralized Wireless Relay Network',
	 'urllink': u'http://arxiv.org/abs/1004.1045'}
2015-03-24 08:54:39+0000 [xxu46_1] INFO: Crawled 457 pages (at 1 pages/min), scraped 451 items (at 1 items/min)
2015-03-24 08:55:39+0000 [xxu46_1] INFO: Crawled 457 pages (at 0 pages/min), scraped 451 items (at 0 items/min)
2015-03-24 08:55:44+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5065> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 08:55:44+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5065>
	{'abstract': u'Multiple-input multiple-output (MIMO) technology applied with orthogonal frequency division multiplexing (OFDM) is considered as the ultimate solution to increase channel capacity without any additional spectral resources. At the receiver side, the challenge resides in designing low complexity detection algorithms capable of separating independent streams sent simultaneously from different antennas. In this paper, we introduce an upper-lower bounded-complexity QRD-M algorithm (ULBC QRD-M). In the proposed algorithm we solve the problem of high extreme complexity of the conventional sphere decoding by fixing the upper bound complexity to that of the conventional QRD-M. On the other hand, ULBC QRD-M intelligently cancels all unnecessary hypotheses to achieve very low computational requirements. Analyses and simulation results show that the proposed algorithm achieves the performance of conventional QRD-M with only 26% of the required computations.',
	 'authors': u'Manar Mohaisen, KyungHi Chang,',
	 'category': u'Computer Science ',
	 'date': '2010-5-27',
	 'pdflink': u'http://arxiv.org/pdf/1005.5065',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nUpper-lower bounded-complexity QRD-M for spatial multiplexing MIMO-OFDM  systems',
	 'urllink': u'http://arxiv.org/abs/1005.5065'}
2015-03-24 08:56:39+0000 [xxu46_1] INFO: Crawled 458 pages (at 1 pages/min), scraped 452 items (at 1 items/min)
2015-03-24 08:57:31+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0936> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 08:57:31+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0936>
	{'abstract': u"Transactional events (TE) are an extension of Concurrent ML (CML), a programming model for synchronous message-passing. Prior work has focused on TE's formal semantics and its implementation. This paper considers programming idioms, particularly those that vary unexpectedly from the corresponding CML idioms. First, we solve a subtle problem with client-server protocols in TE. Second, we argue that CML's wrap and guard primitives do not translate well to TE, and we suggest useful workarounds. Finally, we discuss how to rewrite CML protocols that use abort actions.",
	 'authors': u'Matthew Kehrt, Laura Effinger-Dean, Michael Schmitz, Dan Grossman,',
	 'category': u'Computer Science ',
	 'date': '2010-2-4',
	 'pdflink': u'http://arxiv.org/pdf/1002.0936',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nProgramming Idioms for Transactional Events',
	 'urllink': u'http://arxiv.org/abs/1002.0936'}
2015-03-24 08:57:39+0000 [xxu46_1] INFO: Crawled 459 pages (at 1 pages/min), scraped 453 items (at 1 items/min)
2015-03-24 08:58:39+0000 [xxu46_1] INFO: Crawled 459 pages (at 0 pages/min), scraped 453 items (at 0 items/min)
2015-03-24 08:59:05+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1042> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 08:59:05+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1042>
	{'abstract': u'Multi-access networks may exhibit severe unfairness in throughput. Recent studies show that this unfairness is due to local differences in the neighborhood structure: Nodes with less neighbors receive better access. We study the unfairness in saturated linear networks, and adapt the multi-access CSMA protocol to remove the unfairness completely, by choosing the activation rates of nodes appropriately as a function of the number of neighbors. We then investigate the consequences of this choice of activation rates on the network-average saturated throughput, and we show that these rates perform well in a non-saturated setting.',
	 'authors': u'P.M. van de Ven, J.S.H. van Leeuwaarden, D. Denteneer, A.J.E.M. Janssen,',
	 'category': u'Computer Science ',
	 'date': '2010-4-7',
	 'pdflink': u'http://arxiv.org/pdf/1004.1042',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nSpatial fairness in linear wireless multi-access networks',
	 'urllink': u'http://arxiv.org/abs/1004.1042'}
2015-03-24 08:59:39+0000 [xxu46_1] INFO: Crawled 460 pages (at 1 pages/min), scraped 454 items (at 1 items/min)
2015-03-24 09:00:39+0000 [xxu46_1] INFO: Crawled 460 pages (at 0 pages/min), scraped 454 items (at 0 items/min)
2015-03-24 09:00:46+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5063> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 09:00:46+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5063>
	{'abstract': u'This paper develops a novel framework for sharing secret keys using the Automatic Repeat reQuest (ARQ) protocol. We first characterize the underlying information theoretic limits, under different assumptions on the channel spatial and temporal correlation function. Our analysis reveals a novel role of "dumb antennas" in overcoming the negative impact of spatial correlation on the achievable secrecy rates. We further develop an adaptive rate allocation policy, which achieves higher secrecy rates in temporally correlated channels, and explicit constructions for ARQ secrecy coding that enjoy low implementation complexity. Building on this theoretical foundation, we propose a unified framework for ARQ-based secrecy in Wi-Fi networks. By exploiting the existing ARQ mechanism in the IEEE 802.11 standard, we develop security overlays that offer strong security guarantees at the expense of only minor modifications in the medium access layer. Our numerical results establish the achievability of non-zero secrecy rates even when the eavesdropper channel is less noisy, on the average, than the legitimate channel, while our linux-based prototype demonstrates the efficiency of our ARQ overlays in mitigating all known, passive and active, Wi-Fi attacks at the expense of a minimal increase in the link setup time and a small loss in throughput.',
	 'authors': u'Yara Abdallah, Mohamed Abdel Latif, Moustafa Youssef, Ahmed Sultan, Hesham El Gamal,',
	 'category': u'Computer Science ',
	 'date': '2010-5-27',
	 'pdflink': u'http://arxiv.org/pdf/1005.5063',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nKeys through ARQ: Theory and Practice',
	 'urllink': u'http://arxiv.org/abs/1005.5063'}
2015-03-24 09:01:39+0000 [xxu46_1] INFO: Crawled 461 pages (at 1 pages/min), scraped 455 items (at 1 items/min)
2015-03-24 09:02:15+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0935> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 09:02:15+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0935>
	{'abstract': u'A choreography describes a transaction in which several principals interact. Since choreographies frequently describe business processes affecting substantial assets, we need a security infrastructure in order to implement them safely. As part of a line of work devoted to generating cryptoprotocols from choreographies, we focus here on the execution models suited to the two levels. We give a strand-style semantics for choreographies, and propose a special execution model in which choreography-level messages are faithfully delivered exactly once. We adapt this model to handle multiparty protocols in which some participants may be compromised. At level of cryptoprotocols, we use the standard Dolev-Yao execution model, with one alteration. Since many implementations use a "nonce cache" to discard multiply delivered messages, we provide a semantics for at-most-once delivery.',
	 'authors': u'Marco Carbone, Joshua Guttman,',
	 'category': u'Computer Science ',
	 'date': '2010-2-4',
	 'pdflink': u'http://arxiv.org/pdf/1002.0935',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nExecution Models for Choreographies and Cryptoprotocols',
	 'urllink': u'http://arxiv.org/abs/1002.0935'}
2015-03-24 09:02:39+0000 [xxu46_1] INFO: Crawled 462 pages (at 1 pages/min), scraped 456 items (at 1 items/min)
2015-03-24 09:03:39+0000 [xxu46_1] INFO: Crawled 462 pages (at 0 pages/min), scraped 456 items (at 0 items/min)
2015-03-24 09:03:44+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1027> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 09:03:44+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1027>
	{'abstract': u'The notion of computability is stable (i.e. independent of the choice of an indexing) over infinite-dimensional vector spaces provided they have a finite "tensorial dimension". Such vector spaces with a finite tensorial dimension permit to define an absolute notion of completeness for quantum computation models and give a precise meaning to the Church-Turing thesis in the framework of quantum theory. (Extra keywords: quantum programming languages, denotational semantics, universality.)',
	 'authors': u'Pablo Arrighi, Gilles Dowek,',
	 'category': u'Computer Science ',
	 'date': '2010-4-7',
	 'pdflink': u'http://arxiv.org/pdf/1004.1027',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nOn the completeness of quantum computation models',
	 'urllink': u'http://arxiv.org/abs/1004.1027'}
2015-03-24 09:04:39+0000 [xxu46_1] INFO: Crawled 463 pages (at 1 pages/min), scraped 457 items (at 1 items/min)
2015-03-24 09:05:03+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5060> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 09:05:03+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5060>
	{'abstract': u'The use of agile principles and practices in software development is becoming a powerful force in today\'s workplace. In our quest to develop better products, therefore, it is imperative that we strive to learn and understand the application of Agile methods, principles and techniques to the software development enterprise. Unfortunately, in many educational institutions courses and projects that emphasize Agile Software Development are minimal. At best, students have only limited exposure to the agile philosophy, principles and practices at the graduate and undergraduate levels of education. In an effort to address this concern, we offered a graduate-level course entitled "Agile Software Engineering" in the Department of Computer Science at Virginia Tech in Fall 2009. The primary objectives of the class were to introduce the values, principles and practices underlying the agile philosophy, and to do so in an atmosphere that encourages debate and critical thinking. The course was designed around three central components: (1) teaching the essentials of how one develops a product within an Agile framework, (2) having invited presentation by notable industry experts, and (3) having students present and discuss current research topics and issues. This paper describes our experiences during the offering of that course, and in particular, the unique perspectives of the class instructor, the teaching assistant and a student who was enrolled in the class.',
	 'authors': u'Shvetha Soundararajan, James D. Arthur, Amine Chigani,',
	 'category': u'Computer Science ',
	 'date': '2010-5-27',
	 'pdflink': u'http://arxiv.org/pdf/1005.5060',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nUnderstanding the Tenets of Agile Software Engineering: Lecturing,  Exploration and Critical Thinking',
	 'urllink': u'http://arxiv.org/abs/1005.5060'}
2015-03-24 09:05:39+0000 [xxu46_1] INFO: Crawled 464 pages (at 1 pages/min), scraped 458 items (at 1 items/min)
2015-03-24 09:06:39+0000 [xxu46_1] INFO: Crawled 464 pages (at 0 pages/min), scraped 458 items (at 0 items/min)
2015-03-24 09:06:44+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0933> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 09:06:44+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0933>
	{'abstract': u'This paper investigates session programming and typing of benchmark examples to compare productivity, safety and performance with other communications programming languages. Parallel algorithms are used to examine the above aspects due to their extensive use of message passing for interaction, and their increasing prominence in algorithmic research with the rising availability of hardware resources such as multicore machines and clusters. We contribute new benchmark results for SJ, an extension of Java for type-safe, binary session programming, against MPJ Express, a Java messaging system based on the MPI standard. In conclusion, we observe that (1) despite rich libraries and functionality, MPI remains a low-level API, and can suffer from commonly perceived disadvantages of explicit message passing such as deadlocks and unexpected message types, and (2) the benefits of high-level session abstraction, which has significant impact on program structure to improve readability and reliability, and session type-safety can greatly facilitate the task of communications programming whilst retaining competitive performance.',
	 'authors': u'Andi Bejleri, Raymond Hu, Nobuko Yoshida,',
	 'category': u'Computer Science ',
	 'date': '2010-2-4',
	 'pdflink': u'http://arxiv.org/pdf/1002.0933',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nSession-Based Programming for Parallel Algorithms: Expressiveness and  Performance',
	 'urllink': u'http://arxiv.org/abs/1002.0933'}
2015-03-24 09:07:39+0000 [xxu46_1] INFO: Crawled 465 pages (at 1 pages/min), scraped 459 items (at 1 items/min)
2015-03-24 09:08:25+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1003> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 09:08:25+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1003>
	{'abstract': u'This paper introduces a novel message-passing (MP) framework for the collaborative filtering (CF) problem associated with recommender systems. We model the movie-rating prediction problem popularized by the Netflix Prize, using a probabilistic factor graph model and study the model by deriving generalization error bounds in terms of the training error. Based on the model, we develop a new MP algorithm, termed IMP, for learning the model. To show superiority of the IMP algorithm, we compare it with the closely related expectation-maximization (EM) based algorithm and a number of other matrix completion algorithms. Our simulation results on Netflix data show that, while the methods perform similarly with large amounts of data, the IMP algorithm is superior for small amounts of data. This improves the cold-start problem of the CF systems in practice. Another advantage of the IMP algorithm is that it can be analyzed using the technique of density evolution (DE) that was originally developed for MP decoding of error-correcting codes.',
	 'authors': u'Byung-Hak Kim, Arvind Yedla, Henry D. Pfister,',
	 'category': u'Computer Science ',
	 'date': '2010-4-7',
	 'pdflink': u'http://arxiv.org/pdf/1004.1003',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nMessage-Passing Inference on a Factor Graph for Collaborative Filtering',
	 'urllink': u'http://arxiv.org/abs/1004.1003'}
2015-03-24 09:08:39+0000 [xxu46_1] INFO: Crawled 466 pages (at 1 pages/min), scraped 460 items (at 1 items/min)
2015-03-24 09:09:39+0000 [xxu46_1] INFO: Crawled 466 pages (at 0 pages/min), scraped 460 items (at 0 items/min)
2015-03-24 09:09:57+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5054> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 09:09:57+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5054>
	{'abstract': u'In this paper, we propose an adaptive coordinated Tx-Rx beamforming scheme for inter-user interference cancellation, when a base station (BS) communicates with multiple users that each has multiple receive antennas. The conventional coordinated Tx-Rx beamforming scheme transmits a fixed number of data streams for each user regardless of the instantaneous channel states, that is, all the users, no matter they are with ill-conditioned or well-conditioned channels, have the same number of data streams. However, in the proposed adaptive coordinated Tx-Rx beamforming scheme, we adaptively select the number of streams per user to solve the inefficient problem of the conventional coordinated Tx-Rx beamforming scheme. As a result, the BER performance is improved. Simulation results show that the proposed algorithm outperforms the conventional co-ordinated Tx-Rx beamforming algorithm by 2.5dB at a target BER of 10^-2',
	 'authors': u'HongSun An, Manar Mohaisen, DongKeol Han, KyungHi Chang,',
	 'category': u'Computer Science ',
	 'date': '2010-5-27',
	 'pdflink': u'http://arxiv.org/pdf/1005.5054',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nCoordinated transmit and receive processing with adaptive multi-stream  selection',
	 'urllink': u'http://arxiv.org/abs/1005.5054'}
2015-03-24 09:10:39+0000 [xxu46_1] INFO: Crawled 467 pages (at 1 pages/min), scraped 461 items (at 1 items/min)
2015-03-24 09:11:36+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0930> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 09:11:36+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0930>
	{'abstract': u'We present a unified framework for the declarative analysis of structured communications. By relying on a (timed) concurrent constraint programming language, we show that in addition to the usual operational techniques from process calculi, the analysis of structured communications can elegantly exploit logic-based reasoning techniques. We introduce a declarative interpretation of the language for structured communications proposed by Honda, Vasconcelos, and Kubo. Distinguishing features of our approach are: the possibility of including partial information (constraints) in the session model; the use of explicit time for reasoning about session duration and expiration; a tight correspondence with logic, which formally relates session execution and linear-time temporal logic formulas.',
	 'authors': u'Hugo A. L\xf3pez, Carlos Olarte, Jorge A. P\xe9rez,',
	 'category': u'Computer Science ',
	 'date': '2010-2-4',
	 'pdflink': u'http://arxiv.org/pdf/1002.0930',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nTowards a Unified Framework for Declarative Structured Communications',
	 'urllink': u'http://arxiv.org/abs/1002.0930'}
2015-03-24 09:11:39+0000 [xxu46_1] INFO: Crawled 468 pages (at 1 pages/min), scraped 462 items (at 1 items/min)
2015-03-24 09:12:39+0000 [xxu46_1] INFO: Crawled 468 pages (at 0 pages/min), scraped 462 items (at 0 items/min)
2015-03-24 09:13:12+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.1001> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 09:13:12+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.1001>
	{'abstract': u'A graph is a structure composed of a set of vertices (i.e.nodes, dots) connected to one another by a set of edges (i.e.links, lines). The concept of a graph has been around since the late 19 century, however, only in recent decades has there been a strong resurgence in both theoretical and applied graph research in mathematics, physics, and computer science. In applied computing, since the late 1960s, the interlinked table structure of the relational database has been the predominant information storage and retrieval model. With the growth of graph/network-based data and the need to efficiently process such data, new data management systems have been developed. In contrast to the index-intensive, set-theoretic operations of relational databases, graph databases make use of index-free, local traversals. This article discusses the graph traversal pattern and its use in computing.',
	 'authors': u'Marko A. Rodriguez, Peter Neubauer,',
	 'category': u'Computer Science ',
	 'date': '2010-4-7',
	 'pdflink': u'http://arxiv.org/pdf/1004.1001',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nThe Graph Traversal Pattern',
	 'urllink': u'http://arxiv.org/abs/1004.1001'}
2015-03-24 09:13:39+0000 [xxu46_1] INFO: Crawled 469 pages (at 1 pages/min), scraped 463 items (at 1 items/min)
2015-03-24 09:14:39+0000 [xxu46_1] INFO: Crawled 469 pages (at 0 pages/min), scraped 463 items (at 0 items/min)
2015-03-24 09:14:46+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5045> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 09:14:46+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5045>
	{'abstract': u'Web Operating Systems can be seen as an extension of traditional Operating Systems where the addresses used to manage files and execute programs (via the basic load/execution mechanism) are extended from local filesystem path-names to URLs. A first consequence is that, similarly as in traditional web technologies, executing a program at a given URL, can be done in two modalities: either the execution is performed client-side at the invoking machine (and relative URL addressing in the executed program set to refer to the invoked URL) or it is performed server-side at the machine addressed by the invoked URL (as, e.g., for a web service). Moreover in this context, user identification for access to programs and files and workflow-based composition of service programs is naturally based on token/session-like mechanisms. We propose a middleware based on client-server protocols and on a set primitives, for managing files/resources and executing programs (in the form of client-side/server-side components/services) in Web Operating Systems. We formally define the semantics of such middleware via a process algebraic approach.',
	 'authors': u'Mario Bravetti,',
	 'category': u'Computer Science ',
	 'date': '2010-5-27',
	 'pdflink': u'http://arxiv.org/pdf/1005.5045',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nFile Managing and Program Execution in Web Operating Systems',
	 'urllink': u'http://arxiv.org/abs/1005.5045'}
2015-03-24 09:15:39+0000 [xxu46_1] INFO: Crawled 470 pages (at 1 pages/min), scraped 464 items (at 1 items/min)
2015-03-24 09:16:31+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0908> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 09:16:31+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0908>
	{'abstract': u'Recently, Wang et al. discussed the properties of fuzzy information systems under homomorphisms in the paper [C. Wang, D. Chen, L. Zhu, Homomorphisms between fuzzy information systems, Applied Mathematics Letters 22 (2009) 1045-1050], where homomorphisms are based upon the concepts of consistent functions and fuzzy relation mappings. In this paper, we classify consistent functions as predecessor-consistent and successor-consistent, and then proceed to present more properties of consistent functions. In addition, we improve some characterizations of fuzzy relation mappings provided by Wang et al.',
	 'authors': u'Ping Zhu, Qiaoyan Wen,',
	 'category': u'Computer Science ',
	 'date': '2010-2-4',
	 'pdflink': u'http://arxiv.org/pdf/1002.0908',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nHomomorphisms between fuzzy information systems revisited',
	 'urllink': u'http://arxiv.org/abs/1002.0908'}
2015-03-24 09:16:39+0000 [xxu46_1] INFO: Crawled 471 pages (at 1 pages/min), scraped 465 items (at 1 items/min)
2015-03-24 09:17:39+0000 [xxu46_1] INFO: Crawled 471 pages (at 0 pages/min), scraped 465 items (at 0 items/min)
2015-03-24 09:17:45+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0995> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 09:17:45+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0995>
	{'abstract': u'We consider the problem of fault-tolerance in nanoscale algorithmic self-assembly. We employ a variant of Winfree\'s abstract Tile Assembly Model (aTAM), the two-handed aTAM, in which square "tiles" -- a model of molecules constructed from DNA for the purpose of engineering self-assembled nanostructures -- aggregate according to specific binding sites of varying strengths, and in which large aggregations of tiles may attach to each other, in contrast to the seeded aTAM, in which tiles aggregate one at a time to a single specially-designated "seed" assembly. We focus on a major cause of errors in tile-based self-assembly: that of unintended growth due to "weak" strength-1 bonds, which if allowed to persist, may be stabilized by subsequent attachment of neighboring tiles in the sense that at least energy 2 is now required to break apart the resulting assembly; i.e., the errant assembly is stable at temperature 2. We study a common self-assembly benchmark problem, that of assembling an n x n square using O(log n) unique tile types, under the two-handed model of self-assembly. Our main result achieves a much stronger notion of fault-tolerance than those achieved previously. Arbitrary strength-1 growth is allowed (i.e., the temperature is "fuzzy" and may drift from 2 to 1 for arbitrarily long); however, any assembly that grows sufficiently to become stable at temperature 2 is guaranteed to assemble at temperature 2 into the correct final assembly of an n x n square. In other words, errors due to insufficient attachment, which is the cause of errors studied in earlier papers on fault-tolerance, are prevented absolutely in our main construction, rather than only with high probability and for sufficiently small structures, as in previous fault-tolerance studies.',
	 'authors': u'David Doty, Matthew J. Patitz, Dustin Reishus, Robert T. Schweller, Scott M. Summers,',
	 'category': u'Computer Science ',
	 'date': '2010-4-7',
	 'pdflink': u'http://arxiv.org/pdf/1004.0995',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nStrong Fault-Tolerance for Self-Assembly with Fuzzy Temperature',
	 'urllink': u'http://arxiv.org/abs/1004.0995'}
2015-03-24 09:18:39+0000 [xxu46_1] INFO: Crawled 472 pages (at 1 pages/min), scraped 466 items (at 1 items/min)
2015-03-24 09:19:06+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5035> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 09:19:06+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5035>
	{'abstract': u"An accurate motion model is an important component in modern-day robotic systems, but building such a model for a complex system often requires an appreciable amount of manual effort. In this paper we present a motion model representation, the Dynamic Gaussian Mixture Model (DGMM), that alleviates the need to manually design the form of a motion model, and provides a direct means of incorporating auxiliary sensory data into the model. This representation and its accompanying algorithms are validated experimentally using an 8-legged kinematically complex robot, as well as a standard benchmark dataset. The presented method not only learns the robot's motion model, but also improves the model's accuracy by incorporating information about the terrain surrounding the robot.",
	 'authors': u'Mark Edgington, Yohannes Kassahun, Frank Kirchner,',
	 'category': u'Computer Science ',
	 'date': '2010-5-27',
	 'pdflink': u'http://arxiv.org/pdf/1005.5035',
	 'subjects': u'Robotics (cs.RO)',
	 'title': u'\nDynamic Motion Modelling for Legged Robots',
	 'urllink': u'http://arxiv.org/abs/1005.5035'}
2015-03-24 09:19:39+0000 [xxu46_1] INFO: Crawled 473 pages (at 1 pages/min), scraped 467 items (at 1 items/min)
2015-03-24 09:20:39+0000 [xxu46_1] INFO: Crawled 473 pages (at 0 pages/min), scraped 467 items (at 0 items/min)
2015-03-24 09:20:49+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0904> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 09:20:49+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0904>
	{'abstract': u'Using Pustejovsky\'s "The Syntax of Event Structure" and Fong\'s "On Mending a Torn Dress" we give a glimpse of a Pustejovsky-like analysis to some example sentences in Fong. We attempt to give a framework for semantics to the noun phrases and adverbs as appropriate as well as the lexical entries for all words in the examples and critique both papers in light of our findings and difficulties.',
	 'authors': u'Serguei A. Mokhov,',
	 'category': u'Computer Science ',
	 'date': '2010-2-4',
	 'pdflink': u'http://arxiv.org/pdf/1002.0904',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nOn Event Structure in the Torn Dress',
	 'urllink': u'http://arxiv.org/abs/1002.0904'}
2015-03-24 09:21:39+0000 [xxu46_1] INFO: Crawled 474 pages (at 1 pages/min), scraped 468 items (at 1 items/min)
2015-03-24 09:22:21+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0992> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 09:22:21+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0992>
	{'abstract': u'Partition functions of certain classes of "spin glass" models in statistical physics show strong connections to combinatorial graph invariants. Also known as homomorphism functions they allow for the representation of many such invariants, for example, the number of independent sets of a graph or the number nowhere zero k-flows. Contributing to recent developments on the complexity of partition functions we study the complexity of partition functions with complex values. These functions are usually determined by a square matrix A and it was shown by Goldberg, Grohe, Jerrum, and Thurley that for each real-valued symmetric matrix, the corresponding partition function is either polynomial time computable or #P-hard. Extending this result, we give a complete description of the complexity of partition functions definable by Hermitian matrices. These can also be classified into polynomial time computable and #P-hard ones. Although the criterion for polynomial time computability is not describable in a single line, we give a clear account of it in terms of structures associated with Abelian groups.',
	 'authors': u'Marc Thurley,',
	 'category': u'Computer Science ',
	 'date': '2010-4-7',
	 'pdflink': u'http://arxiv.org/pdf/1004.0992',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nThe Complexity of Partition Functions on Hermitian Matrices',
	 'urllink': u'http://arxiv.org/abs/1004.0992'}
2015-03-24 09:22:39+0000 [xxu46_1] INFO: Crawled 475 pages (at 1 pages/min), scraped 469 items (at 1 items/min)
2015-03-24 09:23:36+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5028> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 09:23:36+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5028>
	{'abstract': u'In 1998 [8], Patarin proposed an efficient cryptosystem called Little Dragon which was a variant a variant of Matsumoto Imai cryptosystem C*. However Patarin latter found that Little Dragon cryptosystem is not secure [8], [3]. In this paper we propose a cryptosystem Little Dragon Two which is as efficient as Little Dragon cryptosystem but secure against all the known attacks. Like Little Dragon cryptosystem the public key of Little Dragon Two is mixed type that is quadratic in plaintext and cipher text variables. So the public key size of Little Dragon Two is equal to Little Dragon Cryptosystem. Our public key algorithm is bijective and can be used for both encryption and signatures.',
	 'authors': u'Rajesh P Singh, Anupam Saikia, B. K. Sarma,',
	 'category': u'Computer Science ',
	 'date': '2010-5-27',
	 'pdflink': u'http://arxiv.org/pdf/1005.5028',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nLittle Dragon Two: An efficient Multivariate Public Key Cryptosystem',
	 'urllink': u'http://arxiv.org/abs/1005.5028'}
2015-03-24 09:23:39+0000 [xxu46_1] INFO: Crawled 476 pages (at 1 pages/min), scraped 470 items (at 1 items/min)
2015-03-24 09:24:39+0000 [xxu46_1] INFO: Crawled 476 pages (at 0 pages/min), scraped 470 items (at 0 items/min)
2015-03-24 09:25:14+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0874> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 09:25:14+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0874>
	{'abstract': u"We develop, analyze and experiment with a new tool, called MADMX, which extracts frequent motifs, possibly including don't care characters, from biological sequences. We introduce density, a simple and flexible measure for bounding the number of don't cares in a motif, defined as the ratio of solid (i.e., different from don't care) characters to the total length of the motif. By extracting only maximal dense motifs, MADMX reduces the output size and improves performance, while enhancing the quality of the discoveries. The efficiency of our approach relies on a newly defined combining operation, dubbed fusion, which allows for the construction of maximal dense motifs in a bottom-up fashion, while avoiding the generation of nonmaximal ones. We provide experimental evidence of the efficiency and the quality of the motifs returned by MADMX",
	 'authors': u'Roberto Grossi, Andrea Pietracaprina, Nadia Pisanti, Geppino Pucci, Eli Upfal, Fabio Vandin,',
	 'category': u'Computer Science ',
	 'date': '2010-2-4',
	 'pdflink': u'http://arxiv.org/pdf/1002.0874',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nMADMX: A Novel Strategy for Maximal Dense Motif Extraction',
	 'urllink': u'http://arxiv.org/abs/1002.0874'}
2015-03-24 09:25:39+0000 [xxu46_1] INFO: Crawled 477 pages (at 1 pages/min), scraped 471 items (at 1 items/min)
2015-03-24 09:26:39+0000 [xxu46_1] INFO: Crawled 477 pages (at 0 pages/min), scraped 471 items (at 0 items/min)
2015-03-24 09:27:01+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0944> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 09:27:01+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0944>
	{'abstract': u'The classical technique for proving termination of a generic sequential computer program involves the synthesis of a ranking function for each loop of the program. Linear ranking functions are particularly interesting because many terminating loops admit one and algorithms exist to automatically synthesize it. In this paper we present two such algorithms: one based on work dated 1991 by Sohn and Van Gelder; the other, due to Podelski and Rybalchenko, dated 2004. Remarkably, while the two algorithms will synthesize a linear ranking function under exactly the same set of conditions, the former is mostly unknown to the community of termination analysis and its general applicability has never been put forward before the present paper. In this paper we thoroughly justify both algorithms, we prove their correctness, we compare their worst-case complexity and experimentally evaluate their efficiency, and we present an open-source implementation of them that will make it very easy to include termination-analysis capabilities in automatic program verifiers.',
	 'authors': u'Roberto Bagnara, Fred Mesnard, Andrea Pescetti, Enea Zaffanella,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1004.0944',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nThe Automatic Synthesis of Linear Ranking Functions: The Complete  Unabridged Version',
	 'urllink': u'http://arxiv.org/abs/1004.0944'}
2015-03-24 09:27:39+0000 [xxu46_1] INFO: Crawled 478 pages (at 1 pages/min), scraped 472 items (at 1 items/min)
2015-03-24 09:27:53+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.5020> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 09:27:53+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.5020>
	{'abstract': u"In secure multi-party computation parties jointly evaluate an -variate function in the presence of an adversary which can corrupt up till parties. Almost all the works that have appeared in the literature so far assume the presence of authenticated channels between the parties. This assumption is far from realistic. Two directions of research have been borne from relaxing this (strong) assumption: (a) The adversary is virtually omnipotent and can control all the communication channels in the network, (b) Only a partially connected topology of authenticated channels is guaranteed and adversary controls a subset of the communication channels in the network. This work introduces a new setting for (unconditional) secure multiparty computation problem which is an interesting intermediate model with respect to the above well studied models from the literature (by sharing a salient feature from both the above models). We consider the problem of (unconditional) secure multi-party computation when 'some' of the communication channels connecting the parties can be corrupted passively as well as actively. For this setting, some honest parties may be connected to several other honest parties via corrupted channels and may not be able to authentically communicate with them. Such parties may not be assured the canonical guarantees of correctness or privacy. We present refined definitions of security for this new intermediate model of unconditional multiparty computation. We show how to adapt protocols for (Unconditional) secure multiparty computation to realize the definitions and also argue the tightness of the results achieved by us.",
	 'authors': u'Shailesh Vaya,',
	 'category': u'Computer Science ',
	 'date': '2010-5-27',
	 'pdflink': u'http://arxiv.org/pdf/1005.5020',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\n(Unconditional) Secure Multiparty Computation with Man-in-the-middle  Attacks',
	 'urllink': u'http://arxiv.org/abs/1005.5020'}
2015-03-24 09:28:39+0000 [xxu46_1] INFO: Crawled 479 pages (at 1 pages/min), scraped 473 items (at 1 items/min)
2015-03-24 09:29:34+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0865> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 09:29:34+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0865>
	{'abstract': u"Online social networking has quickly become one of the most common activities of Internet users. As social networks evolve, they encourage users to share more information, requiring the users, in turn, to place more trust into social networks. Peer-to-peer (P2P) overlays provide an environment that can return ownership of information, trust, and control to the users, away from centralized third-party social networks. In this paper, we present a novel concept, social profile overlays, which enable users to share their profile only with trusted peers in a scalable, reliable, and private manner. Each user's profile consists of a unique private, secure overlay, where members of that overlay have a friendship with the overlay owner. Profile data is made available without regard to the online state of the profile owner through the use of the profile overlay's distributed data store. Privacy and security are enforced through the use of a public key infrastructure (PKI), where the role of certificate authority (CA) is handled by the overlay owner and each member of the overlay has a CA-signed certificate. All members of the social network join a common public or directory overlay facilitating friend discovery and bootstrap connections into profile overlays. We define interfaces and present tools that can be used to implement this system, as well as explore some of the challenges related to it.",
	 'authors': u'David Isaac Wolinsky, Pierre St. Juste, P. Oscar Boykin, Renato Figueiredo,',
	 'category': u'Computer Science ',
	 'date': '2010-2-3',
	 'pdflink': u'http://arxiv.org/pdf/1002.0865',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nTowards Social Profile Based Overlays',
	 'urllink': u'http://arxiv.org/abs/1002.0865'}
2015-03-24 09:29:39+0000 [xxu46_1] INFO: Crawled 480 pages (at 1 pages/min), scraped 474 items (at 1 items/min)
2015-03-24 09:30:39+0000 [xxu46_1] INFO: Crawled 480 pages (at 0 pages/min), scraped 474 items (at 0 items/min)
2015-03-24 09:31:13+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0933> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 09:31:13+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0933>
	{'abstract': u"This paper focuses on a one person game called Indian policeman's dilemma (IPD). It represents the internal conflict between emotion and profession of a typical Indian police officer. We have 'split' the game to be played independently by different personality modules of the same player. Each module then appears as an independent individual player of the game. None of the players knows the exact payoff values of any of the others. Only greater than or less than type of inequalities among the payoff values across the players are to be inferred probabilistically. There are two Nash equilibrium (NE) points in this game signifying two completely opposing behavior by the policeman involved. With the help of the probabilistic inequalities probable propensities of the different behaviors have been determined. The model underscores the need for new surveys and data generation. A design of one such survey to measure professionalism of the police personnel has been outlined.",
	 'authors': u'Kaushik Kumar Majumdar,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1004.0933',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u"\nIndian policeman's dilemma: A game theoretic model",
	 'urllink': u'http://arxiv.org/abs/1004.0933'}
2015-03-24 09:31:39+0000 [xxu46_1] INFO: Crawled 481 pages (at 1 pages/min), scraped 475 items (at 1 items/min)
2015-03-24 09:32:39+0000 [xxu46_1] INFO: Crawled 481 pages (at 0 pages/min), scraped 475 items (at 0 items/min)
2015-03-24 09:32:53+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4997> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 09:32:53+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4997>
	{'abstract': u'Archaeological excavations in the sites of the Indus Valley civilization (2500-1900 BCE) in Pakistan and northwestern India have unearthed a large number of artifacts with inscriptions made up of hundreds of distinct signs. To date there is no generally accepted decipherment of these sign sequences and there have been suggestions that the signs could be non-linguistic. Here we apply complex network analysis techniques to a database of available Indus inscriptions, with the aim of detecting patterns indicative of syntactic organization. Our results show the presence of patterns, e.g., recursive structures in the segmentation trees of the sequences, that suggest the existence of a grammar underlying these inscriptions.',
	 'authors': u'Sitabhra Sinha, Md Izhar Ashraf, Raj Kumar Pan, Bryan Kenneth Wells,',
	 'category': u'Computer Science ',
	 'date': '2010-5-27',
	 'pdflink': u'http://arxiv.org/pdf/1005.4997',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nNetwork analysis of a corpus of undeciphered Indus civilization  inscriptions indicates syntactic organization',
	 'urllink': u'http://arxiv.org/abs/1005.4997'}
2015-03-24 09:33:39+0000 [xxu46_1] INFO: Crawled 482 pages (at 1 pages/min), scraped 476 items (at 1 items/min)
2015-03-24 09:34:37+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0855> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 09:34:37+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0855>
	{'abstract': u'We consider Mobile Ad-hoc Network (MANET) with transmitters located according to a Poisson point in the Euclidean plane, slotted Aloha Medium Access (MAC) protocol and the so-called outage scenario, where a successful transmission requires a Signal-to-Interference-and-Noise (SINR) larger than some threshold. We analyze the local delays in such a network, namely the number of times slots required for nodes to transmit a packet to their prescribed next-hop receivers. The analysis depends very much on the receiver scenario and on the variability of the fading. In most cases, each node has finite-mean geometric random delay and thus a positive next hop throughput. However, the spatial (or large population) averaging of these individual finite mean-delays leads to infinite values in several practical cases, including the Rayleigh fading and positive thermal noise case. In some cases it exhibits an interesting phase transition phenomenon where the spatial average is finite when certain model parameters are below a threshold and infinite above. We call this phenomenon, contention phase transition. We argue that the spatial average of the mean local delays is infinite primarily because of the outage logic, where one transmits full packets at time slots when the receiver is covered at the required SINR and where one wastes all the other time slots. This results in the "RESTART" mechanism, which in turn explains why we have infinite spatial average. Adaptive coding offers a nice way of breaking the outage/RESTART logic. We show examples where the average delays are finite in the adaptive coding case, whereas they are infinite in the outage case.',
	 'authors': u'Fran\xe7ois Baccelli, Bartek Blaszczyszyn,',
	 'category': u'Computer Science ',
	 'date': '2010-2-3',
	 'pdflink': u'http://arxiv.org/pdf/1002.0855',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nA New Phase Transition for Local Delays in MANETs',
	 'urllink': u'http://arxiv.org/abs/1002.0855'}
2015-03-24 09:34:39+0000 [xxu46_1] INFO: Crawled 483 pages (at 1 pages/min), scraped 477 items (at 1 items/min)
2015-03-24 09:35:39+0000 [xxu46_1] INFO: Crawled 483 pages (at 0 pages/min), scraped 477 items (at 0 items/min)
2015-03-24 09:36:15+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0930> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 09:36:15+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0930>
	{'abstract': u"This paper presents a set of exploits an adversary can use to continuously spy on most BitTorrent users of the Internet from a single machine and for a long period of time. Using these exploits for a period of 103 days, we collected 148 million IPs downloading 2 billion copies of contents. We identify the IP address of the content providers for 70% of the BitTorrent contents we spied on. We show that a few content providers inject most contents into BitTorrent and that those content providers are located in foreign data centers. We also show that an adversary can compromise the privacy of any peer in BitTorrent and identify the big downloaders that we define as the peers who subscribe to a large number of contents. This infringement on users' privacy poses a significant impediment to the legal adoption of BitTorrent.",
	 'authors': u'Stevens Le Blond, Arnaud Legout, Fabrice Le Fessant, Walid Dabbous, Mohamed Ali Kaafar,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1004.0930',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nSpying the World from your Laptop -- Identifying and Profiling Content  Providers and Big Downloaders in BitTorrent',
	 'urllink': u'http://arxiv.org/abs/1004.0930'}
2015-03-24 09:36:39+0000 [xxu46_1] INFO: Crawled 484 pages (at 1 pages/min), scraped 478 items (at 1 items/min)
2015-03-24 09:37:38+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4993> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 09:37:38+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4993>
	{'abstract': u"The enforcement of access control policies using cryptography has received considerable attention in recent years and the security of such enforcement schemes is increasingly well understood. Recent work in the area has considered the efficient enforcement of temporal and geo-spatial access control policies, and asymptotic results for the time and space complexity of efficient enforcement schemes have been obtained. However, for practical purposes, it is useful to have explicit bounds for the complexity of enforcement schemes. In this paper, we consider interval-based access control policies, of which temporal and geo-spatial access control policies are special cases. We define enforcement schemes for interval-based access control policies for which it is possible, in almost all cases, to obtain exact values for the schemes' complexity, thereby subsuming a substantial body of work in the literature. Moreover, our enforcement schemes are more practical than existing schemes, in the sense that they operate in the same way as standard cryptographic enforcement schemes, unlike other efficient schemes in the literature. The main difference between our approach and earlier work is that we develop techniques that are specific to the cryptographic enforcement of interval-based access control policies, rather than applying generic techniques that give rise to complex constructions and asymptotic bounds.",
	 'authors': u'Jason Crampton,',
	 'category': u'Computer Science ',
	 'date': '2010-5-27',
	 'pdflink': u'http://arxiv.org/pdf/1005.4993',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nPractical Constructions for the Efficient Cryptographic Enforcement of  Interval-Based Access Control Policies',
	 'urllink': u'http://arxiv.org/abs/1005.4993'}
2015-03-24 09:37:39+0000 [xxu46_1] INFO: Crawled 485 pages (at 1 pages/min), scraped 479 items (at 1 items/min)
2015-03-24 09:38:39+0000 [xxu46_1] INFO: Crawled 485 pages (at 0 pages/min), scraped 479 items (at 0 items/min)
2015-03-24 09:39:01+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0852> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 09:39:01+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0852>
	{'abstract': u'We consider the problem of deciding whether a highly incomplete signal lies within a given subspace. This problem, Matched Subspace Detection, is a classical, well-studied problem when the signal is completely observed. High- dimensional testing problems in which it may be prohibitive or impossible to obtain a complete observation motivate this work. The signal is represented as a vector in R^n, but we only observe m &lt;&lt; n of its elements. We show that reliable detection is possible, under mild incoherence conditions, as long as m is slightly greater than the dimension of the subspace in question.',
	 'authors': u'Laura Balzano, Bejamin Recht, Robert Nowak,',
	 'category': u'Computer Science ',
	 'date': '2010-2-3',
	 'pdflink': u'http://arxiv.org/pdf/1002.0852',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nHigh-Dimensional Matched Subspace Detection When Data are Missing',
	 'urllink': u'http://arxiv.org/abs/1002.0852'}
2015-03-24 09:39:39+0000 [xxu46_1] INFO: Crawled 486 pages (at 1 pages/min), scraped 480 items (at 1 items/min)
2015-03-24 09:40:39+0000 [xxu46_1] INFO: Crawled 486 pages (at 0 pages/min), scraped 480 items (at 0 items/min)
2015-03-24 09:40:41+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0914> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 09:40:41+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0914>
	{'abstract': u'In this paper, collaborative use of relays to form a beamforming system with the aid of perfect channel state information (CSI) and to provide communication in physicallayer security between a transmitter and two receivers is investigated. In particular, we describe decode-and-forward based null space beamforming schemes and optimize the relay weights jointly to obtain the largest secrecy rate region. Furthermore, the optimality of the proposed schemes is investigated by comparing them with the outer bound secrecy rate region',
	 'authors': u'Junwei Zhang, Mustafa Cenk Gursoy,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1004.0914',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nCollaborative Relay Beamforming for Secure Broadcasting',
	 'urllink': u'http://arxiv.org/abs/1004.0914'}
2015-03-24 09:41:39+0000 [xxu46_1] INFO: Crawled 487 pages (at 1 pages/min), scraped 481 items (at 1 items/min)
2015-03-24 09:42:16+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4989> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 09:42:16+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4989>
	{'abstract': u'The paper offers a mathematical formalization of the Turing test. This formalization makes it possible to establish the conditions under which some Turing machine will pass the Turing test and the conditions under which every Turing machine (or every Turing machine of the special class) will fail the Turing test.',
	 'authors': u'Evgeny Chutchev,',
	 'category': u'Computer Science ',
	 'date': '2010-5-27',
	 'pdflink': u'http://arxiv.org/pdf/1005.4989',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nA Formalization of the Turing Test',
	 'urllink': u'http://arxiv.org/abs/1005.4989'}
2015-03-24 09:42:39+0000 [xxu46_1] INFO: Crawled 488 pages (at 1 pages/min), scraped 482 items (at 1 items/min)
2015-03-24 09:43:39+0000 [xxu46_1] INFO: Crawled 488 pages (at 0 pages/min), scraped 482 items (at 0 items/min)
2015-03-24 09:43:54+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0783> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 09:43:54+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0783>
	{'abstract': u'A graph is class II, if its chromatic index is at least . Let be a maximum -edge-colorable subgraph of . The paper proves best possible lower bounds for , and structural properties of maximum -edge-colorable subgraphs. It is shown that every set of vertex-disjoint cycles of a class II graph with can be extended to a maximum -edge-colorable subgraph. Simple graphs have a maximum -edge-colorable subgraph such that the complement is a matching. Furthermore, a maximum -edge-colorable subgraph of a simple graph is always class I.',
	 'authors': u'Vahan V. Mkrtchyan, Eckhard Steffen,',
	 'category': u'Computer Science ',
	 'date': '2010-2-3',
	 'pdflink': u'http://arxiv.org/pdf/1002.0783',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nMaximum $\u0394$-edge-colorable subgraphs of class II graphs',
	 'urllink': u'http://arxiv.org/abs/1002.0783'}
2015-03-24 09:44:39+0000 [xxu46_1] INFO: Crawled 489 pages (at 1 pages/min), scraped 483 items (at 1 items/min)
2015-03-24 09:45:00+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0907> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 09:45:00+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0907>
	{'abstract': u'In this paper, cognitive transmission under quality of service (QoS) constraints is studied. In the cognitive radio channel model, it is assumed that both the secondary receiver and the secondary transmitter know the channel fading coefficients perfectly and optimize the power adaptation policy under given constraints, depending on the channel activity of the primary users, which is determined by channel sensing performed by the secondary users. The transmission rates are equal to the instantaneous channel capacity values. A state transition model with four states is constructed to model this cognitive transmission channel. Statistical limitations on the buffer lengths are imposed to take into account the QoS constraints. The maximum throughput under these statistical QoS constraints is identified by finding the effective capacity of the cognitive radio channel. The impact upon the effective capacity of several system parameters, including the channel sensing duration, detection threshold, detection and false alarm probabilities, and QoS parameters, is investigated.',
	 'authors': u'Sami Akin, Mustafa Cenk Gursoy,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1004.0907',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nQoS Analysis of Cognitive Radio Channels with Perfect CSI at both  Receiver and Transmitter',
	 'urllink': u'http://arxiv.org/abs/1004.0907'}
2015-03-24 09:45:39+0000 [xxu46_1] INFO: Crawled 490 pages (at 1 pages/min), scraped 484 items (at 1 items/min)
2015-03-24 09:45:59+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4985> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 09:45:59+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4985>
	{'abstract': u'Base station cooperative transmission, which is also known as coordinated multi-point (CoMP) transmission, is a promising technique to improve spectrum efficiency in future cellular systems. However, they need large signalling overhead to gather the channel information. In this paper, we consider low feedback user scheduling in downlink coherent CoMP systems exploiting their inherent channel asymmetry. Through the analysis of the statistics of the angle between channel vectors and the tightness of a lower bound of the orthogonally projected norm, we show that channel norm provides sufficient information to judge the orthogonality among users in asymmetric channels. Based on this observation, we propose a channel norm-based user scheduler (NUS), a local channel aided NUS (LocalNUS) and a large-scale fading-based user scheduler (LUS). Simulation results show that the LocalNUS performs very close to the existing greedy user scheduler (GUS) and semi-orthogonal user scheduler (SUS) with full channel state information but requiring much lower feedback overhead, the NUS performs close to or even outperforms the GUS and the SUS when limited feedback is considered, and the LUS is robust to time-varying channels.',
	 'authors': u'Shengqian Han, Chenyang Yang, Mats Bengtsson,',
	 'category': u'Computer Science ',
	 'date': '2010-5-27',
	 'pdflink': u'http://arxiv.org/pdf/1005.4985',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nChannel Norm-Based User Scheduling Exploiting Channel Asymmetry in Base  Station Cooperative Transmission Systems',
	 'urllink': u'http://arxiv.org/abs/1005.4985'}
2015-03-24 09:46:39+0000 [xxu46_1] INFO: Crawled 491 pages (at 1 pages/min), scraped 485 items (at 1 items/min)
2015-03-24 09:47:17+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0777> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 09:47:17+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0777>
	{'abstract': u"In this paper, polar codes for the -user multiple access channel (MAC) with binary inputs are constructed. It is shown that Arkan's polarization technique applied individually to each user transforms independent uses of a -user binary input MAC into successive uses of extremal MACs. This transformation has a number of desirable properties: (i) the `uniform sum rate' of the original MAC is preserved, (ii) the extremal MACs have uniform rate regions that are not only polymatroids but matroids and thus (iii) their uniform sum rate can be reached by each user transmitting either uncoded or fixed bits; in this sense they are easy to communicate over. A polar code can then be constructed with an encoding and decoding complexity of (where is the block length), a block error probability of , and capable of achieving the uniform sum rate of any binary input MAC with arbitrary many users. An application of this polar code construction to communicating on the AWGN channel is also discussed.",
	 'authors': u'Emmanuel Abbe, Emre Telatar,',
	 'category': u'Computer Science ',
	 'date': '2010-2-3',
	 'pdflink': u'http://arxiv.org/pdf/1002.0777',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nPolar Codes for the m-User MAC',
	 'urllink': u'http://arxiv.org/abs/1002.0777'}
2015-03-24 09:47:39+0000 [xxu46_1] INFO: Crawled 492 pages (at 1 pages/min), scraped 486 items (at 1 items/min)
2015-03-24 09:48:39+0000 [xxu46_1] INFO: Crawled 492 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2015-03-24 09:48:58+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4984> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 09:48:58+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4984>
	{'abstract': u'Backpressure-based adaptive routing algorithms where each packet is routed along a possibly different path have been extensively studied in the literature. However, such algorithms typically result in poor delay performance and involve high implementation complexity. In this paper, we develop a new adaptive routing algorithm built upon the widely-studied back-pressure algorithm. We decouple the routing and scheduling components of the algorithm by designing a probabilistic routing table which is used to route packets to per-destination queues. The scheduling decisions in the case of wireless networks are made using counters called shadow queues. The results are also extended to the case of networks which employ simple forms of network coding. In that case, our algorithm provides a low-complexity solution to optimally exploit the routing-coding tradeoff.',
	 'authors': u'Eleftheria Athanasopoulou, Loc Bui, Tianxiong Ji, R. Srikant, Alexander Stoylar,',
	 'category': u'Computer Science ',
	 'date': '2010-5-27',
	 'pdflink': u'http://arxiv.org/pdf/1005.4984',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nBackpressure-based Packet-by-Packet Adaptive Routing in Communication  Networks',
	 'urllink': u'http://arxiv.org/abs/1005.4984'}
2015-03-24 09:49:39+0000 [xxu46_1] INFO: Crawled 493 pages (at 1 pages/min), scraped 487 items (at 1 items/min)
2015-03-24 09:50:30+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0773> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 09:50:30+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0773>
	{'abstract': u"Maximum mutual information (MMI) is a model selection criterion used for hidden Markov model (HMM) parameter estimation that was developed more than twenty years ago as a discriminative alternative to the maximum likelihood criterion for HMM-based speech recognition. It has been shown in the speech recognition literature that parameter estimation using the current MMI paradigm, lattice-based MMI, consistently outperforms maximum likelihood estimation, but this is at the expense of undesirable convergence properties. In particular, recognition performance is sensitive to the number of times that the iterative MMI estimation algorithm, extended Baum-Welch, is performed. In fact, too many iterations of extended Baum-Welch will lead to degraded performance, despite the fact that the MMI criterion improves at each iteration. This phenomenon is at variance with the analogous behavior of maximum likelihood estimation -- at least for the HMMs used in speech recognition -- and it has previously been attributed to `over fitting'. In this paper, we present an analysis of lattice-based MMI that demonstrates, first of all, that the asymptotic behavior of lattice-based MMI is much worse than was previously understood, i.e. it does not appear to converge at all, and, second of all, that this is not due to `over fitting'. Instead, we demonstrate that the `over fitting' phenomenon is the result of standard methodology that exacerbates the poor behavior of two key approximations in the lattice-based MMI machinery. We also demonstrate that if we modify the standard methodology to improve the validity of these approximations, then the convergence properties of lattice-based MMI become benign without sacrificing improvements to recognition accuracy.",
	 'authors': u'Steven Wegmann,',
	 'category': u'Computer Science ',
	 'date': '2010-2-3',
	 'pdflink': u'http://arxiv.org/pdf/1002.0773',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nApproximations to the MMI criterion and their effect on lattice-based  MMI',
	 'urllink': u'http://arxiv.org/abs/1002.0773'}
2015-03-24 09:50:39+0000 [xxu46_1] INFO: Crawled 494 pages (at 1 pages/min), scraped 488 items (at 1 items/min)
2015-03-24 09:51:24+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0899> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 09:51:24+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0899>
	{'abstract': u'In this paper, collaborative use of relays to form a beamforming system and provide physical-layer security is investigated. In particular, amplify-and-forward (AF) relay beamforming designs under total and individual relay power constraints are studied with the goal of maximizing the secrecy rates when perfect channel state information (CSI) is available. In the AF scheme, not having analytical solutions for the optimal beamforming design under both total and individual power constraints, an iterative algorithm is proposed to numerically obtain the optimal beamforming structure and maximize the secrecy rates. Robust beamforming designs in the presence of imperfect CSI are investigated for decode-and-forward (DF) based relay beamforming, and optimization frameworks are provided.',
	 'authors': u'Junwei Zhang, Mustafa Cenk Gursoy,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1004.0899',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nRelay Beamforming Strategies for Physical-Layer Security',
	 'urllink': u'http://arxiv.org/abs/1004.0899'}
2015-03-24 09:51:39+0000 [xxu46_1] INFO: Crawled 495 pages (at 1 pages/min), scraped 489 items (at 1 items/min)
2015-03-24 09:52:39+0000 [xxu46_1] INFO: Crawled 495 pages (at 0 pages/min), scraped 489 items (at 0 items/min)
2015-03-24 09:52:43+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4975> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 09:52:43+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4975>
	{'abstract': u"Behavior Driven Development (NORTH, 2006) is a specification technique that is growing in acceptance in the Agile methods communities. BDD allows to securely verify that all functional requirements were treated properly by source code, by connecting the textual description of these requirements to tests. On the other side, the Enterprise Information Systems (EIS) researchers and practitioners defends the use of Business Process Modeling (BPM) to, before defining any part of the system, perform the modeling of the system's underlying business process. Therefore, it can be stated that, in the case of EIS, functional requirements are obtained by identifying Use Cases from the business process models. The aim of this paper is, in a narrower perspective, to propose the use of Finite State Machines (FSM) to model business process and then connect them to the BDD machinery, thus driving better quality for EIS. In a broader perspective, this article aims to provoke a discussion on the mapping of the various BPM notations, since there isn't a real standard for business process modeling (Moller et al., 2007), to BDD. Firstly a historical perspective of the evolution of previous proposals from which this one emerged will be presented, and then the reasons to change from Model Driven Development (MDD) to BDD will be presented also in a historical perspective. Finally the proposal of using FSM, specifically by using UML Statechart diagrams, will be presented, followed by some conclusions.",
	 'authors': u'Rogerio Atem de Carvalho, Rodrigo Soares Manh\xe3es, Fernando Luis de Carvalho e Silva,',
	 'category': u'Computer Science ',
	 'date': '2010-5-27',
	 'pdflink': u'http://arxiv.org/pdf/1005.4975',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nFilling the Gap between Business Process Modeling and Behavior Driven  Development',
	 'urllink': u'http://arxiv.org/abs/1005.4975'}
2015-03-24 09:53:39+0000 [xxu46_1] INFO: Crawled 496 pages (at 1 pages/min), scraped 490 items (at 1 items/min)
2015-03-24 09:54:20+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0757> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 09:54:20+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0757>
	{'abstract': u'We analyse the prequential plug-in codes relative to one-parameter exponential families M. We show that if data are sampled i.i.d. from some distribution outside M, then the redundancy of any plug-in prequential code grows at rate larger than 1/2 ln(n) in the worst case. This means that plug-in codes, such as the Rissanen-Dawid ML code, may behave inferior to other important universal codes such as the 2-part MDL, Shtarkov and Bayes codes, for which the redundancy is always 1/2 ln(n) + O(1). However, we also show that a slight modification of the ML plug-in code, "almost" in the model, does achieve the optimal redundancy even if the the true distribution is outside M.',
	 'authors': u'Peter Gr\xfcnwald, Wojciech Kot\u0142owski,',
	 'category': u'Computer Science ',
	 'date': '2010-2-3',
	 'pdflink': u'http://arxiv.org/pdf/1002.0757',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nPrequential Plug-In Codes that Achieve Optimal Redundancy Rates even if  the Model is Wrong',
	 'urllink': u'http://arxiv.org/abs/1002.0757'}
2015-03-24 09:54:39+0000 [xxu46_1] INFO: Crawled 497 pages (at 1 pages/min), scraped 491 items (at 1 items/min)
2015-03-24 09:55:25+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0897> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 09:55:25+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0897>
	{'abstract': u'In this paper, we have studied the energy efficiency of cooperative networks operating in either the fixed Amplifyand- Forward (AF) or the selective Decode-and-Forward (DF) mode. We consider the optimization of the M-ary quadrature amplitude modulation (MQAM) constellation size to minimize the bit energy consumption under given bit error rate (BER) constraints. In the computation of the energy expenditure, the circuit, transmission, and retransmission energies are taken into account. The link reliabilities and retransmission probabilities are determined through the outage probabilities under the Rayleigh fading assumption. Several interesting observations with practical implications are made. It is seen that while large constellations are preferred at small transmission distances, constellation size should be decreased as the distance increases; the cooperative gain is computed to compare direct transmission and cooperative transmission.',
	 'authors': u'Qing Chen, Mustafa Cenk Gursoy,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1004.0897',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nEnergy Efficiency Analysis in Amplify-and-Forward and Decode-and-Forward  Cooperative Networks',
	 'urllink': u'http://arxiv.org/abs/1004.0897'}
2015-03-24 09:55:39+0000 [xxu46_1] INFO: Crawled 498 pages (at 1 pages/min), scraped 492 items (at 1 items/min)
2015-03-24 09:56:39+0000 [xxu46_1] INFO: Crawled 498 pages (at 0 pages/min), scraped 492 items (at 0 items/min)
2015-03-24 09:57:07+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4973> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 09:57:07+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4973>
	{'abstract': u'This paper proposes a type of pseudorandom number generator, Mersenne Twister for Graphic Processor (MTGP), for efficient generation on graphic processessing units (GPUs). MTGP supports large state sizes such as 11213 bits, and uses the high parallelism of GPUs in computing many steps of the recursion in parallel. The second proposal is a parameter-set generator for MTGP, named MTGP Dynamic Creator (MTGPDC). MT- GPDC creates up to 2^32 distinct parameter sets which generate sequences with high-dimensional uniformity. This facility is suitable for a large grid of GPUs where each GPU requires separate random number streams. MTGP is based on linear recursion over the two-element field, and has better high-dimensional equidistribution than the Mersenne Twister pseudorandom number generator.',
	 'authors': u'Mutsuo Saito, Makoto Matsumoto,',
	 'category': u'Computer Science ',
	 'date': '2010-5-27',
	 'pdflink': u'http://arxiv.org/pdf/1005.4973',
	 'subjects': u'Mathematical Software (cs.MS)',
	 'title': u'\nVariants of Mersenne Twister Suitable for Graphic Processors',
	 'urllink': u'http://arxiv.org/abs/1005.4973'}
2015-03-24 09:57:39+0000 [xxu46_1] INFO: Crawled 499 pages (at 1 pages/min), scraped 493 items (at 1 items/min)
2015-03-24 09:58:39+0000 [xxu46_1] INFO: Crawled 499 pages (at 0 pages/min), scraped 493 items (at 0 items/min)
2015-03-24 09:58:53+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0745> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 09:58:54+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0745>
	{'abstract': u'CODEQ is a new, population-based meta-heuristic algorithm that is a hybrid of concepts from chaotic search, opposition-based learning, differential evolution and quantum mechanics. CODEQ has successfully been used to solve different types of problems (e.g. constrained, integer-programming, engineering) with excellent results. In this paper, CODEQ is used to train feed-forward neural networks. The proposed method is compared with particle swarm optimization and differential evolution algorithms on three data sets with encouraging results.',
	 'authors': u'Mahamed G. H. Omran, Faisal al-Adwani,',
	 'category': u'Computer Science ',
	 'date': '2010-2-3',
	 'pdflink': u'http://arxiv.org/pdf/1002.0745',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nUsing CODEQ to Train Feed-forward Neural Networks',
	 'urllink': u'http://arxiv.org/abs/1002.0745'}
2015-03-24 09:59:39+0000 [xxu46_1] INFO: Crawled 500 pages (at 1 pages/min), scraped 494 items (at 1 items/min)
2015-03-24 10:00:16+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0892> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 10:00:16+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0892>
	{'abstract': u'In this paper, the fading broadcast channel with confidential messages is studied in the presence of statistical quality of service (QoS) constraints in the form of limitations on the buffer length. We employ the effective capacity formulation to measure the throughput of the confidential and common messages. We assume that the channel side information (CSI) is available at both the transmitter and the receivers. Assuming average power constraints at the transmitter side, we first define the effective secure throughput region, and prove that the throughput region is convex. Then, we obtain the optimal power control policies that achieve the boundary points of the effective secure throughput region.',
	 'authors': u'Deli Qiao, Mustafa Cenk Gursoy, Senem Velipasalar,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1004.0892',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nSecure Broadcasting over Fading Channels with Statistical QoS  Constraints',
	 'urllink': u'http://arxiv.org/abs/1004.0892'}
2015-03-24 10:00:39+0000 [xxu46_1] INFO: Crawled 501 pages (at 1 pages/min), scraped 495 items (at 1 items/min)
2015-03-24 10:01:37+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4963> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 10:01:37+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4963>
	{'abstract': u'Structured and semi-structured data describing entities, taxonomies and ontologies appears in many domains. There is a huge interest in integrating structured information from multiple sources; however integrating structured data to infer complex common structures is a difficult task because the integration must aggregate similar structures while avoiding structural inconsistencies that may appear when the data is combined. In this work, we study the integration of structured social metadata: shallow personal hierarchies specified by many individual users on the SocialWeb, and focus on inferring a collection of integrated, consistent taxonomies. We frame this task as an optimization problem with structural constraints. We propose a new inference algorithm, which we refer to as Relational Affinity Propagation (RAP) that extends affinity propagation (Frey and Dueck 2007) by introducing structural constraints. We validate the approach on a real-world social media dataset, collected from the photosharing website Flickr. Our empirical results show that our proposed approach is able to construct deeper and denser structures compared to an approach using only the standard affinity propagation algorithm.',
	 'authors': u'Anon Plangprasopchok, Kristina Lerman, Lise Getoor,',
	 'category': u'Computer Science ',
	 'date': '2010-5-26',
	 'pdflink': u'http://arxiv.org/pdf/1005.4963',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nIntegrating Structured Metadata with Relational Affinity Propagation',
	 'urllink': u'http://arxiv.org/abs/1005.4963'}
2015-03-24 10:01:39+0000 [xxu46_1] INFO: Crawled 502 pages (at 1 pages/min), scraped 496 items (at 1 items/min)
2015-03-24 10:02:39+0000 [xxu46_1] INFO: Crawled 502 pages (at 0 pages/min), scraped 496 items (at 0 items/min)
2015-03-24 10:03:12+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0739> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 10:03:12+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0739>
	{'abstract': u'We present a lattice algorithm specifically designed for some classical applications of lattice reduction. The applications are for lattice bases with a generalized knapsack-type structure, where the target vectors are boundably short. For such applications, the complexity of the algorithm improves traditional lattice reduction by replacing some dependence on the bit-length of the input vectors by some dependence on the bound for the output vectors. If the bit-length of the target vectors is unrelated to the bit-length of the input, then our algorithm is only linear in the bit-length of the input entries, which is an improvement over the quadratic complexity floating-point LLL algorithms. To illustrate the usefulness of this algorithm we show that a direct application to factoring univariate polynomials over the integers leads to the first complexity bound improvement since 1984. A second application is algebraic number reconstruction, where a new complexity bound is obtained as well.',
	 'authors': u'Mark Van Hoeij, Andrew Novocin,',
	 'category': u'Computer Science ',
	 'date': '2010-2-3',
	 'pdflink': u'http://arxiv.org/pdf/1002.0739',
	 'subjects': u'Symbolic Computation (cs.SC)',
	 'title': u'\nGradual sub-lattice reduction and a new complexity for factoring  polynomials',
	 'urllink': u'http://arxiv.org/abs/1002.0739'}
2015-03-24 10:03:39+0000 [xxu46_1] INFO: Crawled 503 pages (at 1 pages/min), scraped 497 items (at 1 items/min)
2015-03-24 10:04:34+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0891> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 10:04:34+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0891>
	{'abstract': u'In this paper, the secure transmission of information over an ergodic fading channel is investigated in the presence of statistical quality of service (QoS) constraints. We employ effective capacity, which provides the maximum constant arrival rate that a given process can support while satisfying statistical delay constraints, to measure the secure throughput of the system, i.e., effective secure throughput. We assume that the channel side information (CSI) of the main channel is available at the transmitter side. Depending on the availability of the CSI of the eavesdropper channel, we obtain the corresponding optimal power control policies that maximize the effective secure throughput. In particular, when the CSI of the eavesdropper channel is available at the transmitter, the transmitter can no longer wait for transmission when the main channel is much better than the eavesdropper channel due to the introduction of QoS constraints. Moreover, the CSI of the eavesdropper channel becomes useless as QoS constraints become stringent.',
	 'authors': u'Deli Qiao, Mustafa Cenk Gursoy, Senem Velipasalar,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1004.0891',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nSecure Communication over Fading Channels with Statistical QoS  Constraints',
	 'urllink': u'http://arxiv.org/abs/1004.0891'}
2015-03-24 10:04:39+0000 [xxu46_1] INFO: Crawled 504 pages (at 1 pages/min), scraped 498 items (at 1 items/min)
2015-03-24 10:05:38+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4951> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 10:05:38+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4951>
	{'abstract': u'This paper has been withdrawn due to an error in one of the equations in the extended portion.',
	 'authors': u'Sanjay Karmakar, Mahesh K. Varanasi,',
	 'category': u'Computer Science ',
	 'date': '2010-5-26',
	 'pdflink': u'http://arxiv.org/e-print/1005.4951',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nThe diversity-multiplexing tradeoff of the symmetric MIMO half-duplex  relay channel',
	 'urllink': u'http://arxiv.org/abs/1005.4951'}
2015-03-24 10:05:39+0000 [xxu46_1] INFO: Crawled 505 pages (at 1 pages/min), scraped 499 items (at 1 items/min)
2015-03-24 10:06:39+0000 [xxu46_1] INFO: Crawled 505 pages (at 0 pages/min), scraped 499 items (at 0 items/min)
2015-03-24 10:07:02+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0722> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 10:07:02+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0722>
	{'abstract': u'Providing an analytical solution for the problem of finding Fastest Distributed Consensus (FDC) is one of the challenging problems in the field of sensor networks. Most of the methods proposed so far deal with the FDC averaging algorithm problem by numerical convex optimization methods and in general no closed-form solution for finding FDC has been offered up to now except in [3] where the conjectured answer for path has been proved. Here in this work we present an analytical solution for the problem of Fastest Distributed Consensus for the Path network using semidefinite programming particularly solving the slackness conditions, where the optimal weights are obtained by inductive comparing of the characteristic polynomials initiated by slackness conditions.',
	 'authors': u'Saber Jafarizadeh,',
	 'category': u'Computer Science ',
	 'date': '2010-2-3',
	 'pdflink': u'http://arxiv.org/pdf/1002.0722',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nFastest Distributed Consensus on Path Network',
	 'urllink': u'http://arxiv.org/abs/1002.0722'}
2015-03-24 10:07:39+0000 [xxu46_1] INFO: Crawled 506 pages (at 1 pages/min), scraped 500 items (at 1 items/min)
2015-03-24 10:08:39+0000 [xxu46_1] INFO: Crawled 506 pages (at 0 pages/min), scraped 500 items (at 0 items/min)
2015-03-24 10:08:47+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0871> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 10:08:47+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0871>
	{'abstract': u'In this paper, we study the complexity of computing locally optimal solutions for weighted versions of standard set problems such as SetCover, SetPacking, and many more. For our investigation, we use the framework of PLS, as defined in Johnson et al., [JPY88]. We show that for most of these problems, computing a locally optimal solution is already PLS-complete for a simple neighborhood of size one. For the local search versions of weighted SetPacking and SetCover, we derive tight bounds for a simple neighborhood of size two. To the best of our knowledge, these are one of the very few PLS results about local search for weighted standard set problems.',
	 'authors': u'Dominic Dumrauf, Tim S\xfc\xdf,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1004.0871',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nOn the Complexity of Local Search for Weighted Standard Set Problems',
	 'urllink': u'http://arxiv.org/abs/1004.0871'}
2015-03-24 10:09:39+0000 [xxu46_1] INFO: Crawled 507 pages (at 1 pages/min), scraped 501 items (at 1 items/min)
2015-03-24 10:09:47+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4906> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 10:09:47+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4906>
	{'abstract': u'This paper is a reply to the article "Scopus\'s Source Normalized Impact per Paper (SNIP) versus a Journal Impact Factor based on Fractional Counting of Citations", published by Loet Leydesdorff and Tobias Opthof (arXiv:1004.3580v2 [cs.DL]). It clarifies the relationship between SNIP and Elsevier\'s Scopus. Since Leydesdorff and Opthof\'s description of SNIP is not complete, it indicates four key differences between SNIP and the indicator proposed by the two authors, and argues why the former is more valid than the latter. Nevertheless, the idea of fractional citation counting deserves further exploration. The paper discusses difficulties that arise if one attempts to apply this principle at the level of individual (citing) papers.',
	 'authors': u'Henk F. Moed,',
	 'category': u'Computer Science ',
	 'date': '2010-5-26',
	 'pdflink': u'http://arxiv.org/pdf/1005.4906',
	 'subjects': u'Digital Libraries (cs.DL)',
	 'title': u'\nThe Source-Normalized Impact per Paper (SNIP) is a valid and  sophisticated indicator of journal citation impact',
	 'urllink': u'http://arxiv.org/abs/1005.4906'}
2015-03-24 10:10:39+0000 [xxu46_1] INFO: Crawled 508 pages (at 1 pages/min), scraped 502 items (at 1 items/min)
2015-03-24 10:11:18+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0712> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 10:11:18+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0712>
	{'abstract': u'In this paper we present the Chelonia storage cloud middleware. It was designed to fill the requirements gap between those of large, sophisticated scientific collaborations which have adopted the grid paradigm for their distributed storage needs, and of corporate business communities which are gravitating towards the cloud paradigm. The similarities to and differences between Chelonia and several well-known grid- and cloud-based storage solutions are commented. The design of Chelonia has been chosen to optimize high reliability and scalability of an integrated system of heterogeneous, geographically dispersed storage sites and the ability to easily expand the system dynamically. The architecture and implementation in term of web-services running inside the Advanced Resource Connector Hosting Environment Dameon (ARC HED) are described. We present results of tests in both local-area and wide-area networks that demonstrate the fault-tolerance, stability and scalability of Chelonia.',
	 'authors': u'Jon K. Nilsen, Salman Toor, Zsombor Nagy, Bjarte Mohn, Alex L. Read,',
	 'category': u'Computer Science ',
	 'date': '2010-2-3',
	 'pdflink': u'http://arxiv.org/pdf/1002.0712',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nPerformance and Stability of the Chelonia Storage Cloud',
	 'urllink': u'http://arxiv.org/abs/1002.0712'}
2015-03-24 10:11:39+0000 [xxu46_1] INFO: Crawled 509 pages (at 1 pages/min), scraped 503 items (at 1 items/min)
2015-03-24 10:12:39+0000 [xxu46_1] INFO: Crawled 509 pages (at 0 pages/min), scraped 503 items (at 0 items/min)
2015-03-24 10:12:45+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0838> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 10:12:45+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0838>
	{'abstract': u'In the theory of algorithmic randomness, one of the central notions is that of computable randomness. An infinite binary sequence X is computably random if no recursive martingale (strategy) can win an infinite amount of money by betting on the values of the bits of X. In the classical model, the martingales considered are real-valued, that is, the bets made by the martingale can be arbitrary real numbers. In this paper, we investigate a more restricted model, where only integer-valued martingales are considered, and we study the class of random sequences induced by this model.',
	 'authors': u'Laurent Bienvenu, Frank Stephan, Jason Teutsch,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1004.0838',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nHow powerful are integer-valued martingales?',
	 'urllink': u'http://arxiv.org/abs/1004.0838'}
2015-03-24 10:13:39+0000 [xxu46_1] INFO: Crawled 510 pages (at 1 pages/min), scraped 504 items (at 1 items/min)
2015-03-24 10:13:48+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4895> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 10:13:48+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4895>
	{'abstract': u'The QR Decomposition (QRD) of communication channel matrices is a fundamental prerequisite to several detection schemes in Multiple-Input Multiple-Output (MIMO) communication systems. Herein, the main feature of the QRD is to transform the non-causal system into a causal system, where consequently efficient detection algorithms based on the Successive Interference Cancellation (SIC) or Sphere Decoder (SD) become possible. Also, QRD can be used as a light but efficient antenna selection scheme. In this paper, we address the study of the QRD methods and compare their efficiency in terms of computational complexity and error rate performance. Moreover, a particular attention is paid to the parallelism of the QRD algorithms since it reduces the latency of the matrix factorization.',
	 'authors': u'Sebastien Aubert, Manar Mohaisen, Fabienne Nouvel, KyungHi Chang,',
	 'category': u'Computer Science ',
	 'date': '2010-5-26',
	 'pdflink': u'http://arxiv.org/pdf/1005.4895',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nParallel QR decomposition in LTE-A systems',
	 'urllink': u'http://arxiv.org/abs/1005.4895'}
2015-03-24 10:14:39+0000 [xxu46_1] INFO: Crawled 511 pages (at 1 pages/min), scraped 505 items (at 1 items/min)
2015-03-24 10:15:32+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0709> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 10:15:32+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0709>
	{'abstract': u'The paper deals with on-line regression settings with signals belonging to a Banach lattice. Our algorithms work in a semi-online setting where all the inputs are known in advance and outcomes are unknown and given step by step. We apply the Aggregating Algorithm to construct a prediction method whose cumulative loss over all the input vectors is comparable with the cumulative loss of any linear functional on the Banach lattice. As a by-product we get an algorithm that takes signals from an arbitrary domain. Its cumulative loss is comparable with the cumulative loss of any predictor function from Besov and Triebel-Lizorkin spaces. We describe several applications of our setting.',
	 'authors': u'Fedor Zhdanov, Alexey Chernov, Yuri Kalnishkan,',
	 'category': u'Computer Science ',
	 'date': '2010-2-3',
	 'pdflink': u'http://arxiv.org/pdf/1002.0709',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nAggregating Algorithm competing with Banach lattices',
	 'urllink': u'http://arxiv.org/abs/1002.0709'}
2015-03-24 10:15:39+0000 [xxu46_1] INFO: Crawled 512 pages (at 1 pages/min), scraped 506 items (at 1 items/min)
2015-03-24 10:16:38+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0817> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 10:16:38+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0817>
	{'abstract': u'We prove that NP differs from coNP and coNP is not a subset of MA in the number-on-forehead model of multiparty communication complexity for up to k = (1- epsilon)log(n) players, where epsilon&gt;0 is any constant. Specifically, we construct a function F with co-nondeterministic complexity O(log(n)) and Merlin-Arthur complexity n^. The problem was open for k &gt; 2.',
	 'authors': u'Dmitry Gavinsky, Alexander A. Sherstov,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1004.0817',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nA Separation of NP and coNP in Multiparty Communication Complexity',
	 'urllink': u'http://arxiv.org/abs/1004.0817'}
2015-03-24 10:16:39+0000 [xxu46_1] INFO: Crawled 513 pages (at 1 pages/min), scraped 507 items (at 1 items/min)
2015-03-24 10:17:39+0000 [xxu46_1] INFO: Crawled 513 pages (at 0 pages/min), scraped 507 items (at 0 items/min)
2015-03-24 10:17:58+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4882> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 10:17:58+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4882>
	{'abstract': u"Who are the influential people in an online social network? The answer to this question depends not only on the structure of the network, but also on details of the dynamic processes occurring on it. We classify these processes as conservative and non-conservative. A random walk on a network is an example of a conservative dynamic process, while information spread is non-conservative. The influence models used to rank network nodes can be similarly classified, depending on the dynamic process they implicitly emulate. We claim that in order to correctly rank network nodes, the influence model has to match the details of the dynamic process. We study a real-world network on the social news aggregator Digg, which allows users to post and vote for news stories. We empirically define influence as the number of in-network votes a user's post generates. This influence measure, and the resulting ranking, arises entirely from the dynamics of voting on Digg, which represents non-conservative information flow. We then compare predictions of different influence models with this empirical estimate of influence. The results show that non-conservative models are better able to predict influential users on Digg. We find that normalized alpha-centrality metric turns out to be one of the best predictors of influence. We also present a simple algorithm for computing this metric and the associated mathematical formulation and analytical proofs.",
	 'authors': u'Rumi Ghosh, Kristina Lerman,',
	 'category': u'Computer Science ',
	 'date': '2010-5-26',
	 'pdflink': u'http://arxiv.org/pdf/1005.4882',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nPredicting Influential Users in Online Social Networks',
	 'urllink': u'http://arxiv.org/abs/1005.4882'}
2015-03-24 10:18:39+0000 [xxu46_1] INFO: Crawled 514 pages (at 1 pages/min), scraped 508 items (at 1 items/min)
2015-03-24 10:19:33+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0705> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 10:19:33+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0705>
	{'abstract': u'The purpose of this paper is to show how existing scientific software can be parallelized using a separate thin layer of Python code where all parallel communication is implemented. We provide specific examples on such layers of code, and these examples may act as templates for parallelizing a wide set of serial scientific codes. The use of Python for parallelization is motivated by the fact that the language is well suited for reusing existing serial codes programmed in other languages. The extreme flexibility of Python with regard to handling functions makes it very easy to wrap up decomposed computational tasks of a serial scientific application as Python functions. Many parallelization-specific components can be implemented as generic Python functions, which may take as input those functions that perform concrete computational tasks. The overall programming effort needed by this parallelization approach is rather limited, and the resulting parallel Python scripts have a compact and clean structure. The usefulness of the parallelization approach is exemplified by three different classes of applications in natural and social sciences.',
	 'authors': u'Jon K. Nilsen, Xing Cai, Bjorn Hoyland, Hans Petter Langtangen,',
	 'category': u'Computer Science ',
	 'date': '2010-2-3',
	 'pdflink': u'http://arxiv.org/pdf/1002.0705',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nSimplifying Parallelization of Scientific Codes by a Function-Centric  Approach in Python',
	 'urllink': u'http://arxiv.org/abs/1002.0705'}
2015-03-24 10:19:39+0000 [xxu46_1] INFO: Crawled 515 pages (at 1 pages/min), scraped 509 items (at 1 items/min)
2015-03-24 10:20:39+0000 [xxu46_1] INFO: Crawled 515 pages (at 0 pages/min), scraped 509 items (at 0 items/min)
2015-03-24 10:21:06+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0816> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 10:21:06+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0816>
	{'abstract': u'Micro-blogging services such as Twitter allow anyone to publish anything, anytime. Needless to say, many of the available contents can be diminished as babble or spam. However, given the number and diversity of users, some valuable pieces of information should arise from the stream of tweets. Thus, such services can develop into valuable sources of up-to-date information (the so-called real-time web) provided a way to find the most relevant/trustworthy/authoritative users is available. Hence, this makes a highly pertinent question for which graph centrality methods can provide an answer. In this paper the author offers a comprehensive survey of feasible algorithms for ranking users in social networks, he examines their vulnerabilities to linking malpractice in such networks, and suggests an objective criterion against which to compare such algorithms. Additionally, he suggests a first step towards "desensitizing" prestige algorithms against cheating by spammers and other abusive users.',
	 'authors': u'Daniel Gayo-Avello,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1004.0816',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nNepotistic Relationships in Twitter and their Impact on Rank Prestige  Algorithms',
	 'urllink': u'http://arxiv.org/abs/1004.0816'}
2015-03-24 10:21:39+0000 [xxu46_1] INFO: Crawled 516 pages (at 1 pages/min), scraped 510 items (at 1 items/min)
2015-03-24 10:22:12+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4877> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 10:22:12+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4877>
	{'abstract': u"This paper studies the strategic manipulation of set-valued social choice functions according to Kelly's preference extension, which prescribes that one set of alternatives is preferred to another if and only if all elements of the former are preferred to all elements of the latter. It is shown that set-monotonicity---a new variant of Maskin-monotonicity---implies Kelly-strategyproofness in comprehensive subdomains of the linear domain. Interestingly, there are a handful of appealing Condorcet extensions---such as the top cycle, the minimal covering set, and the bipartisan set---that satisfy set-monotonicity even in the unrestricted linear domain, thereby answering questions raised independently by Barber `a (1977) and Kelly (1977).",
	 'authors': u'Felix Brandt,',
	 'category': u'Computer Science ',
	 'date': '2010-5-26',
	 'pdflink': u'http://arxiv.org/pdf/1005.4877',
	 'subjects': u'Multiagent Systems (cs.MA)',
	 'title': u'\nSet-Monotonicity Implies Kelly-Strategyproofness',
	 'urllink': u'http://arxiv.org/abs/1005.4877'}
2015-03-24 10:22:39+0000 [xxu46_1] INFO: Crawled 517 pages (at 1 pages/min), scraped 511 items (at 1 items/min)
2015-03-24 10:23:30+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0696> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 10:23:31+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0696>
	{'abstract': u'In recent years computer systems have become increasingly complex and consequently the challenge of protecting these systems has become increasingly difficult. Various techniques have been implemented to counteract the misuse of computer systems in the form of firewalls, anti-virus software and intrusion detection systems. The complexity of networks and dynamic nature of computer systems leaves current methods with significant room for improvement. Computer scientists have recently drawn inspiration from mechanisms found in biological systems and, in the context of computer security, have focused on the human immune system (HIS). The human immune system provides a high level of protection from constant attacks. By examining the precise mechanisms of the human immune system, it is hoped the paradigm will improve the performance of real intrusion detection systems. This paper presents an introduction to recent developments in the field of immunology. It discusses the incorporation of a novel immunological paradigm, Danger Theory, and how this concept is inspiring artificial immune systems (AIS). Applications within the context of computer security are outlined drawing direct reference to the underlying principles of Danger Theory and finally, the current state of intrusion detection systems is discussed and improvements suggested.',
	 'authors': u'Julie Greensmith, Uwe Aickelin, Jamie Twycross,',
	 'category': u'Computer Science ',
	 'date': '2010-2-3',
	 'pdflink': u'http://arxiv.org/pdf/1002.0696',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nDetecting Danger: Applying a Novel Immunological Concept to Intrusion  Detection Systems',
	 'urllink': u'http://arxiv.org/abs/1002.0696'}
2015-03-24 10:23:39+0000 [xxu46_1] INFO: Crawled 518 pages (at 1 pages/min), scraped 512 items (at 1 items/min)
2015-03-24 10:24:39+0000 [xxu46_1] INFO: Crawled 518 pages (at 0 pages/min), scraped 512 items (at 0 items/min)
2015-03-24 10:25:09+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0803> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 10:25:09+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0803>
	{'abstract': u'We explore the intricate interdependent relationship among counting problems, considered from three frameworks for such problems: Holant Problems, counting CSP and weighted H-colorings. We consider these problems for general complex valued functions that take boolean inputs. We show that results from one framework can be used to derive results in another, and this happens in both directions. Holographic reductions discover an underlying unity, which is only revealed when these counting problems are investigated in the complex domain . We prove three complexity dichotomy theorems, leading to a general theorem for Holant problems. This is the natural class of Holant problems where one can assign constants 0 or 1. More specifically, given any signature grid on over a set of symmetric functions, we completely classify the complexity to be in P or #P-hard, according to , of [ sum_ prod_ f_v( sigma mid_), ] where (, are the unary constant 0, 1 functions). Not only is holographic reduction the main tool, but also the final dichotomy can be only naturally stated in the language of holographic transformations. The proof goes through another dichotomy theorem on boolean complex weighted #CSP.',
	 'authors': u'Jin-Yi Cai, Sangxia Huang, Pinyan Lu,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1004.0803',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nFrom Holant To #CSP And Back: Dichotomy For Holant$^c$ Problems',
	 'urllink': u'http://arxiv.org/abs/1004.0803'}
2015-03-24 10:25:39+0000 [xxu46_1] INFO: Crawled 519 pages (at 1 pages/min), scraped 513 items (at 1 items/min)
2015-03-24 10:26:39+0000 [xxu46_1] INFO: Crawled 519 pages (at 0 pages/min), scraped 513 items (at 0 items/min)
2015-03-24 10:26:50+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4874> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 10:26:51+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4874>
	{'abstract': u"Schoening presents a simple randomized algorithm for (d,k)-CSP problems with running time (d(k-1)/k)^n poly(n). Here, d is the number of colors, k is the size of the constraints, and n is the number of variables. A derandomized version of this, given by Dantsin et al., achieves a running time of (dk/(k+1))^n poly(n), inferior to Schoening's. We come up with a simple modification of the deterministic algorithm, achieving a running time of (d(k-1)/k * k^d/(k^d-1))^n poly(n). Though not completely eleminating the gap, this comes very close to the randomized bound for all but very small values of d. Our main idea is to define a graph structure on the set of d colors to speed up local search.",
	 'authors': u'Dominik Scheder,',
	 'category': u'Computer Science ',
	 'date': '2010-5-26',
	 'pdflink': u'http://arxiv.org/pdf/1005.4874',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nUsing a Skewed Hamming Distance to Speed Up Deterministic Local Search',
	 'urllink': u'http://arxiv.org/abs/1005.4874'}
2015-03-24 10:27:39+0000 [xxu46_1] INFO: Crawled 520 pages (at 1 pages/min), scraped 514 items (at 1 items/min)
2015-03-24 10:28:15+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0682> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 10:28:15+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0682>
	{'abstract': u'The impact of the type of implementation is considered on the IR-UWB channel capacity. This study is lead for analog and mostly digital implementation. Key parameters and theirs impacts on the channel capacity are exposed in each case: data converters for mostly digital implementations and pulse generators capabilities for analog implementations. These two implementations are compared from a data rate point of view. Their behaviors regarding an increase of the operating frequency are also studied',
	 'authors': u'Aubin Lecointre, Daniela Dragomirescu, Robert Plana,',
	 'category': u'Computer Science ',
	 'date': '2010-2-3',
	 'pdflink': u'http://arxiv.org/pdf/1002.0682',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nIR-UWB Channel Capacity for Analog and Mostly Digital Implementation',
	 'urllink': u'http://arxiv.org/abs/1002.0682'}
2015-03-24 10:28:39+0000 [xxu46_1] INFO: Crawled 521 pages (at 1 pages/min), scraped 515 items (at 1 items/min)
2015-03-24 10:29:34+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0799> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 10:29:34+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0799>
	{'abstract': u'A source model for secret key generation between terminals is considered. Two users, namely users 1 and 2, at one side communicate with another user, namely user 3, at the other side via a public channel where three users can observe i.i.d. outputs of correlated sources. Each of users 1 and 2 intends to share a secret key with user 3 where user 1 acts as a wiretapper for user 2 and vice versa. In this model, two situations are considered: communication from users 1 and 2 to user 3 (the forward key strategy) and from user 3 to users 1 and 2 (the backward key strategy). In both situations, the goal is sharing a secret key between user 1 and user 3 while leaking no effective information about that key to user 2, and simultaneously, sharing another secret key between user 2 and user 3 while leaking no effective information about the latter key to user 1. This model is motivated by wireless communications when considering user 3 as a base station and users 1 and 2 as network users. In this paper, for both the forward and backward key strategies, inner and outer bounds of secret key capacity regions are derived. In special situations where one of users 1 and 2 is only interested in wiretapping and not key sharing, our results agree with that of Ahlswede and Csiszar. Also, we investigate some special cases in which the inner bound coincides with the outer bound and secret key capacity region is deduced.',
	 'authors': u'Somayeh Salimi, Mahmoud Salmasizadeh, Mohammad Reza Aref,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1004.0799',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nRate Regions of Secret Key Sharing in a New Source Model',
	 'urllink': u'http://arxiv.org/abs/1004.0799'}
2015-03-24 10:29:39+0000 [xxu46_1] INFO: Crawled 522 pages (at 1 pages/min), scraped 516 items (at 1 items/min)
2015-03-24 10:30:39+0000 [xxu46_1] INFO: Crawled 522 pages (at 0 pages/min), scraped 516 items (at 0 items/min)
2015-03-24 10:30:50+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4853> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 10:30:50+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4853>
	{'abstract': u"Analog (uncoded) transmission provides a simple and robust scheme for communicating a Gaussian source over a Gaussian channel under the mean squared error (MSE) distortion measure. Unfortunately, its performance is usually inferior to the all-digital, separation-based source-channel coding solution, which requires exact knowledge of the channel at the encoder. The loss comes from the fact that except for very special cases, e.g. white source and channel of matching bandwidth (BW), it is impossible to achieve perfect matching of source to channel and channel to source by linear means. We show that by combining prediction and modulo-lattice operations, it is possible to match any colored Gaussian source to any colored Gaussian noise channel (of possibly different BW), hence achieve Shannon's optimum attainable performance . Furthermore, when the source and channel BWs are equal (but otherwise their spectra are arbitrary), this scheme is asymptotically robust in the sense that for high signal-to-noise ratio a single encoder (independent of the noise variance) achieves the optimum performance. The derivation is based upon a recent modulo-lattice modulation scheme for transmitting a Wyner-Ziv source over a dirty-paper channel.",
	 'authors': u'Yuval Kochman, Ram Zamir,',
	 'category': u'Computer Science ',
	 'date': '2010-5-26',
	 'pdflink': u'http://arxiv.org/pdf/1005.4853',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nAnalog Matching of Colored Sources to Colored Channels',
	 'urllink': u'http://arxiv.org/abs/1005.4853'}
2015-03-24 10:31:39+0000 [xxu46_1] INFO: Crawled 523 pages (at 1 pages/min), scraped 517 items (at 1 items/min)
2015-03-24 10:32:18+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0680> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 10:32:18+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0680>
	{'abstract': u"The minimum mean square error of the estimation of a non Gaussian signal where observed from an additive white Gaussian noise channel's output, is analyzed. First, a quite general time-continuous channel model is assumed for which the behavior of the non-Gaussianess of the channel's output for small signal to noise ratio q, is proved. Then, It is assumed that the channel input's signal is composed of a (normalized) sum of N narrowband, mutually independent waves. It is shown that if N goes to infinity, then for any fixed q (no mater how big) both CMMSE and MMSE converge to the signal energy at a rate which is proportional to the inverse of N. Finally, a known result for the MMSE in the one-dimensional case, for small q, is used to show that all the first four terms in the Taylor expansion of the non-Gaussianess of the channel's output equal to zero.",
	 'authors': u'Jacob Binia,',
	 'category': u'Computer Science ',
	 'date': '2010-2-3',
	 'pdflink': u'http://arxiv.org/pdf/1002.0680',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nSome Relations between Divergence Derivatives and Estimation in Gaussian  channels',
	 'urllink': u'http://arxiv.org/abs/1002.0680'}
2015-03-24 10:32:39+0000 [xxu46_1] INFO: Crawled 524 pages (at 1 pages/min), scraped 518 items (at 1 items/min)
2015-03-24 10:33:39+0000 [xxu46_1] INFO: Crawled 524 pages (at 0 pages/min), scraped 518 items (at 0 items/min)
2015-03-24 10:33:56+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0798> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 10:33:56+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0798>
	{'abstract': u"In this paper, new inner and outer bounds on the achievable compression-equivocation rate region for generalized secure data compression with side information are given that do not match in general. In this setup, two senders, Alice and Charlie intend to transmit information to Bob via channels with limited capacity so that he can reliably reconstruct their observations. The eavesdropper, Eve, has access to one of the channels at each instant and is interested in the source of the same channel at the time. Bob and Eve also have their own observations which are correlated with Alice's and Charlie's observations. In this model, two equivocation and compression rates are defined with respect to the sources of Alice and Charlie. Furthermore, different special cases are discussed where the inner and outer bounds match. Our model covers the previously obtained results as well.",
	 'authors': u'Somayeh Salimi, Mahmoud Salmasizadeh, Mohammad Reza Aref,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1004.0798',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nGeneralized Secure Distributed Source Coding with Side Information',
	 'urllink': u'http://arxiv.org/abs/1004.0798'}
2015-03-24 10:34:39+0000 [xxu46_1] INFO: Crawled 525 pages (at 1 pages/min), scraped 519 items (at 1 items/min)
2015-03-24 10:34:55+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4844> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 10:34:55+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4844>
	{'abstract': u'We propose a method for automatically generating abstract transformers for static analysis by abstract interpretation. The method focuses on linear constraints on programs operating on rational, real or floating-point variables and containing linear assignments and tests. Given the specification of an abstract domain, and a program block, our method automatically outputs an implementation of the corresponding abstract transformer. It is thus a form of program transformation. In addition to loop-free code, the same method also applies for obtaining least fixed points as functions of the precondition, which permits the analysis of loops and recursive functions. The motivation of our work is data-flow synchronous programming languages, used for building control-command embedded systems, but it also applies to imperative and functional programming. Our algorithms are based on quantifier elimination and symbolic manipulation techniques over linear arithmetic formulas. We also give less general results for nonlinear constraints and nonlinear program constructs.',
	 'authors': u'David Monniaux,',
	 'category': u'Computer Science ',
	 'date': '2010-5-26',
	 'pdflink': u'http://arxiv.org/pdf/1005.4844',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nAutomatic Modular Abstractions for Template Numerical Constraints',
	 'urllink': u'http://arxiv.org/abs/1005.4844'}
2015-03-24 10:35:39+0000 [xxu46_1] INFO: Crawled 526 pages (at 1 pages/min), scraped 520 items (at 1 items/min)
2015-03-24 10:36:37+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0678> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 10:36:37+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0678>
	{'abstract': u'The draft paper defines a system, which is capable of maintaining bases of test cases for logical specifications. The specifications, which are subject to this system are transformed from their original shape in first-order logic to form-based expressions as originally introduced in logics of George Spencer-Brown. The innovation comes from the operations the system provides when injecting faults - so-called mutations - to the specifications. The system presented here applies to logical specifications from areas as different as programming, ontologies or hardware specifications.',
	 'authors': u'Andreas Faatz, Andreas Zinnen,',
	 'category': u'Computer Science ',
	 'date': '2010-2-3',
	 'pdflink': u'http://arxiv.org/pdf/1002.0678',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nFORMT: Form-based Mutation Testing of Logical Specifications',
	 'urllink': u'http://arxiv.org/abs/1002.0678'}
2015-03-24 10:36:39+0000 [xxu46_1] INFO: Crawled 527 pages (at 1 pages/min), scraped 521 items (at 1 items/min)
2015-03-24 10:37:39+0000 [xxu46_1] INFO: Crawled 527 pages (at 0 pages/min), scraped 521 items (at 0 items/min)
2015-03-24 10:37:42+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0785> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 10:37:42+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0785>
	{'abstract': u'Distributed storage systems are mainly justified due to the limited amount of storage capacity and improving the reliability through distributing data over multiple storage nodes. On the other hand, it may happen the data is stored in unreliable nodes, while it is desired the end user to have a reliable access to the stored data. So, in an event that a node is damaged, to prevent the system reliability to regress, it is necessary to regenerate a new node with the same amount of stored data as the damaged node to retain the number of storage nodes, thereby having the previous reliability. This requires the new node to connect to some of existing nodes and downloads the required information, thereby occupying some bandwidth, called the repair bandwidth. On the other hand, it is more likely the cost of downloading varies across different nodes. This paper aims at investigating the theoretical cost-bandwidth tradeoff, and more importantly, it is demonstrated that any point on this curve can be achieved through the use of the so called generalized regenerating codes which is an enhancement of the regeneration codes introduced by Dimakis et al. in [1].',
	 'authors': u'Soroush Akhlaghi, Abbas Kiani, Mohammad Reza Ghanavati,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1004.0785',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nCost-Bandwidth Tradeoff In Distributed Storage Systems',
	 'urllink': u'http://arxiv.org/abs/1004.0785'}
2015-03-24 10:38:39+0000 [xxu46_1] INFO: Crawled 528 pages (at 1 pages/min), scraped 522 items (at 1 items/min)
2015-03-24 10:39:08+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4834> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 10:39:08+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4834>
	{'abstract': u'This paper analyzes the asymptotic exponent of both the weight spectrum and the stopping set size spectrum for a class of generalized low-density parity-check (GLDPC) codes. Specifically, all variable nodes (VNs) are assumed to have the same degree (regular VN set), while the check node (CN) set is assumed to be composed of a mixture of different linear block codes (hybrid CN set). A simple expression for the exponent (which is also referred to as the growth rate or the spectral shape) is developed. This expression is consistent with previous results, including the case where the normalized weight or stopping set size tends to zero. Furthermore, it is shown how certain symmetry properties of the local weight distribution at the CNs induce a symmetry in the overall weight spectral shape function.',
	 'authors': u'Enrico Paolini, Mark F. Flanagan, Marco Chiani, Marc P.C. Fossorier,',
	 'category': u'Computer Science ',
	 'date': '2010-5-26',
	 'pdflink': u'http://arxiv.org/pdf/1005.4834',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nSpectral Shape of Check-Hybrid GLDPC Codes',
	 'urllink': u'http://arxiv.org/abs/1005.4834'}
2015-03-24 10:39:39+0000 [xxu46_1] INFO: Crawled 529 pages (at 1 pages/min), scraped 523 items (at 1 items/min)
2015-03-24 10:40:39+0000 [xxu46_1] INFO: Crawled 529 pages (at 0 pages/min), scraped 523 items (at 0 items/min)
2015-03-24 10:40:52+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0644> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 10:40:52+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0644>
	{'abstract': u'The IEEE 802.11 standard offers a cheap and promising solution for small scale wireless networks. Due to the self configuring nature, WLANs do not require large scale infrastructure deployment, and are scalable and easily maintainable which incited its popularity in both literature and industry. In real environment, these networks operate mostly under unsaturated condition. We investigate performance of such a network with m-retry limit BEB based DCF. We consider imperfect channel with provision for power capture. Our method employs a Markov model and represents the most common performance measures in terms of network parameters making the model and mathematical analysis useful in network design and planning. We also explore the effects of packet error, network size, initial contention window, and retry limit on overall performance of WLANs.',
	 'authors': u'Atiur Rahman Siddique, Joarder Kamruzzaman,',
	 'category': u'Computer Science ',
	 'date': '2010-2-3',
	 'pdflink': u'http://arxiv.org/pdf/1002.0644',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nPerformance Analysis of m-retry BEB based DCF under Unsaturated Traffic  Condition',
	 'urllink': u'http://arxiv.org/abs/1002.0644'}
2015-03-24 10:41:39+0000 [xxu46_1] INFO: Crawled 530 pages (at 1 pages/min), scraped 524 items (at 1 items/min)
2015-03-24 10:42:13+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0777> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 10:42:13+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0777>
	{'abstract': u'This article has been withdrawn by arXiv admins because it contains plagiarized content from International Conference on Computer Networks and Security (ICCNS 2008, September 27-28, 2008): "Securing AODV for MANETs using Message Digest with Secret Key", by Sunil J. Soni and Prashant B. Swadas.',
	 'authors': u'Kamaljit Lakhtaria, Bhaskar N. Patel, Satish G. Prajapati, N. N. Jani,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/e-print/1004.0777',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nSecuring AODV for MANETs using Message Digest with Secret Key',
	 'urllink': u'http://arxiv.org/abs/1004.0777'}
2015-03-24 10:42:39+0000 [xxu46_1] INFO: Crawled 531 pages (at 1 pages/min), scraped 525 items (at 1 items/min)
2015-03-24 10:43:39+0000 [xxu46_1] INFO: Crawled 531 pages (at 0 pages/min), scraped 525 items (at 0 items/min)
2015-03-24 10:43:43+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4826> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 10:43:43+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4826>
	{'abstract': u'In this paper, we show a construction of a weakly universal cellular automaton in the 3D hyperbolic space with two states. The cellular automaton is rotation invariant and, moreover, based on a new implementation of a railway circuit in the dodecagrid,the construction is a truly 3D-one.',
	 'authors': u'Maurice Margenstern,',
	 'category': u'Computer Science ',
	 'date': '2010-5-26',
	 'pdflink': u'http://arxiv.org/pdf/1005.4826',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nA new weakly universal cellular automaton in the 3D hyperbolic space  with two states',
	 'urllink': u'http://arxiv.org/abs/1005.4826'}
2015-03-24 10:44:39+0000 [xxu46_1] INFO: Crawled 532 pages (at 1 pages/min), scraped 526 items (at 1 items/min)
2015-03-24 10:45:13+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0580> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 10:45:13+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0580>
	{'abstract': u'We consider the indirect covering subtree problem (Kim et al., 1996). The input is an edge weighted tree graph along with customers located at the nodes. Each customer is associated with a radius and a penalty. The goal is to locate a tree-shaped facility such that the sum of setup and penalty cost is minimized. The setup cost equals the sum of edge lengths taken by the facility and the penalty cost is the sum of penalties of all customers whose distance to the facility exceeds their radius. The indirect covering subtree problem generalizes the single maximum coverage location problem on trees where the facility is a node rather than a subtree. Indirect covering subtree can be solved in time (Kim et al., 1996). A slightly faster algorithm for single maximum coverage location with a running time of has been provided (Spoerhase and Wirth, 2009). We achieve time for indirect covering subtree thereby providing the fastest known algorithm for both problems. Our result implies also faster algorithms for competitive location problems such as -medianoid and -centroid on trees. We complement our result by a lower bound of for single maximum coverage location and -medianoid on a real-number RAM model showing that our algorithm is optimal in running time.',
	 'authors': u'Joachim Spoerhase,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0580',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nAn Optimal Algorithm for the Indirect Covering Subtree Problem',
	 'urllink': u'http://arxiv.org/abs/1002.0580'}
2015-03-24 10:45:39+0000 [xxu46_1] INFO: Crawled 533 pages (at 1 pages/min), scraped 527 items (at 1 items/min)
2015-03-24 10:46:08+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0774> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 10:46:08+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0774>
	{'abstract': u'A Rapid evolution of mobile technologies has led to the development of more sophisticated mobile devices with better storage, processing and transmission power. These factors enable support to many types of application but also give rise to a necessity to find a model of service development. Actually, SOA (Service Oriented Architecture) is a good option to support application development. This paper presents a framework that allows the development of SOA based application in mobile environment. The objective of the framework is to give developers with tools for provision of services in this environment with the necessary security characteristics.',
	 'authors': u'Johnneth Fonseca, Zair Abdelouahab, Denivaldo Lopes, Sofiane Labidi,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1004.0774',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nA security framework for SOA applications in mobile environment',
	 'urllink': u'http://arxiv.org/abs/1004.0774'}
2015-03-24 10:46:39+0000 [xxu46_1] INFO: Crawled 534 pages (at 1 pages/min), scraped 528 items (at 1 items/min)
2015-03-24 10:47:38+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4815> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 10:47:38+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4815>
	{'abstract': u"Multi-agent systems where the agents are developed by parties with competing interests, and where there is no access to an agent's internal state, are often classified as `open'. The member agents of such systems may inadvertently fail to, or even deliberately choose not to, conform to the system specification. Consequently, it is necessary to specify the normative relations that may exist between the agents, such as permission, obligation, and institutional power. The specification of open agent systems of this sort is largely seen as a design-time activity. Moreover, there is no support for run-time specification modification. Due to environmental, social, or other conditions, however, it is often required to revise the specification during the system execution. To address this requirement, we present an infrastructure for `dynamic' specifications, that is, specifications that may be modified at run-time by the agents. The infrastructure consists of well-defined procedures for proposing a modification of the `rules of the game', as well as decision-making over and enactment of proposed modifications. We evaluate proposals for rule modification by modelling a dynamic specification as a metric space, and by considering the effects of accepting a proposal on system utility. Furthermore, we constrain the enactment of proposals that do not meet the evaluation criteria. We employ the action language C+ to formalise dynamic specifications, and the `Causal Calculator' implementation of C+ to execute the specifications. We illustrate our infrastructure by presenting a dynamic specification of a resource-sharing protocol.",
	 'authors': u'Alexander Artikis,',
	 'category': u'Computer Science ',
	 'date': '2010-5-26',
	 'pdflink': u'http://arxiv.org/pdf/1005.4815',
	 'subjects': u'Multiagent Systems (cs.MA)',
	 'title': u'\nA Formal Specification of Dynamic Protocols for Open Agent Systems',
	 'urllink': u'http://arxiv.org/abs/1005.4815'}
2015-03-24 10:47:39+0000 [xxu46_1] INFO: Crawled 535 pages (at 1 pages/min), scraped 529 items (at 1 items/min)
2015-03-24 10:48:39+0000 [xxu46_1] INFO: Crawled 535 pages (at 0 pages/min), scraped 529 items (at 0 items/min)
2015-03-24 10:49:15+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0577> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 10:49:15+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0577>
	{'abstract': u"This paper presents a work package realized for the G 'eOnto project. A new method is proposed for an enrichment of a first geographical ontology developed beforehand. This method relies on text analysis by lexico-syntactic patterns. From the retrieve of n-ary relations the method automatically detect those involved in a spatial and/or temporal relation in a context of a description of journeys.",
	 'authors': u'Tien Nguyen Van, Mauro Gaio, Christian Sallaberry,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0577',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u"\nRecherche de relations spatio-temporelles : une m\xe9thode bas\xe9e sur  l'analyse de corpus textuels",
	 'urllink': u'http://arxiv.org/abs/1002.0577'}
2015-03-24 10:49:39+0000 [xxu46_1] INFO: Crawled 536 pages (at 1 pages/min), scraped 530 items (at 1 items/min)
2015-03-24 10:50:39+0000 [xxu46_1] INFO: Crawled 536 pages (at 0 pages/min), scraped 530 items (at 0 items/min)
2015-03-24 10:50:42+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0772> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 10:50:42+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0772>
	{'abstract': u'This paper proposes to address new requirements of confidentiality, integrity and availability properties fitting to peer-to-peer domains of resources. The enforcement of security properties in an open peer-topeer network remains an open problem as the literature have mainly proposed contribution on availability of resources and anonymity of users. That paper proposes a novel architecture that eases the administration of a peer-to-peer network. It considers a network of safe peer-to-peer clients in the sense that it is a commune client software that is shared by all the participants to cope with the sharing of various resources associated with different security requirements. However, our proposal deals with possible malicious peers that attempt to compromise the requested security properties. Despite the safety of an open peer-to-peer network cannot be formally guaranteed, since a end user has privileges on the target host, our solution provides several advanced security enforcement. First, it enables to formally define the requested security properties of the various shared resources. Second, it evaluates the trust and the reputation of the requesting peer by sending challenges that test the fairness of its peer-to-peer security policy. Moreover, it proposes an advanced Mandatory Access Control that enforces the required peer-to-peer security properties through an automatic projection of the requested properties onto SELinux policies. Thus, the SELinux system of the requesting peer is automatically configured with respect to the required peer-to-peer security properties.',
	 'authors': u'Jean-Francois Lalande, David Rodriguez, Christian Toinard,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1004.0772',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nSecurity properties in an open peer-to-peer network',
	 'urllink': u'http://arxiv.org/abs/1004.0772'}
2015-03-24 10:51:39+0000 [xxu46_1] INFO: Crawled 537 pages (at 1 pages/min), scraped 531 items (at 1 items/min)
2015-03-24 10:52:08+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4798> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 10:52:08+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4798>
	{'abstract': u"A novel language system has given rise to promising alternatives to standard formal and processor network models of computation. An interstring linked with a abstract machine environment, shares sub-expressions, transfers data, and spatially allocates resources for the parallel evaluation of dataflow. Formal models called the a-Ram family are introduced, designed to support interstring programming languages (interlanguages). Distinct from dataflow, graph rewriting, and FPGA models, a-Ram instructions are bit level and execute in situ. They support sequential and parallel languages without the space/time overheads associated with the Turing Machine and lambda-calculus, enabling massive programs to be simulated. The devices of one a-Ram model, called the Synchronic A-Ram, are fully connected and simpler than FPGA LUT's. A compiler for an interlanguage called Space, has been developed for the Synchronic A-Ram. Space is MIMD. strictly typed, and deterministic. Barring memory allocation and compilation, modules are referentially transparent. At a high level of abstraction, modules exhibit a state transition system, aiding verification. Data structures and parallel iteration are straightforward to implement, and allocations of sub-processes and data transfers to resources are implicit. Space points towards highly connected architectures called Synchronic Engines, that are more general purpose than systolic arrays and GPUs, and bypass programmability and conflict issues associated with multicores.",
	 'authors': u'Alexander Victor Berka,',
	 'category': u'Computer Science ',
	 'date': '2010-5-26',
	 'pdflink': u'http://arxiv.org/pdf/1005.4798',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nIntroduction to the Report "Interlanguages and Synchronic Models of  Computation."',
	 'urllink': u'http://arxiv.org/abs/1005.4798'}
2015-03-24 10:52:39+0000 [xxu46_1] INFO: Crawled 538 pages (at 1 pages/min), scraped 532 items (at 1 items/min)
2015-03-24 10:53:04+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0576> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 10:53:04+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0576>
	{'abstract': u'A new model is proposed giving the channel capability of a MB-IR-UWB system versus the number of subband and the duty cycle. The architecture simulated shows data rate ranging from 1.434 Gbits/s to 0.9 Gbits/s for 16 to 10 subbands and duty cycle ranging from 20% to 12%.',
	 'authors': u'Aubin Lecointre, Daniela Dragomirescu, Robert Plana,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0576',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nNew methodology to design advanced MR-IRUWB communication system',
	 'urllink': u'http://arxiv.org/abs/1002.0576'}
2015-03-24 10:53:39+0000 [xxu46_1] INFO: Crawled 539 pages (at 1 pages/min), scraped 533 items (at 1 items/min)
2015-03-24 10:54:33+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0771> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 10:54:33+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0771>
	{'abstract': u"Mobile ip (mip) is an internet protocol that allows mobile nodes to have continuous network connectivity to the internet without changing their ip addresses while moving to other networks. The packets sent from correspondent node (cn) to a mobile node (mn) go first through the mobile node's home agent (ha), then the ha tunnels them to the mn's foreign network. One of the main problems in the original mip is the triangle routing problem. Triangle routing problem appears when the indirect path between cn and mn through the ha is longer than the direct path. This paper proposes a new technique to improve the performance of the original mip during the handoff. The proposed technique reduces the delay, the packet loss and the registration time for all the packets transferred between the cn and the mn. In this technique, tunneling occurs at two levels above the ha in a hierarchical network. To show the effectiveness of the proposed technique, it is compared with the original mip and another technique for solving the same problem in which tunneling occurs at one level above the ha. Simulation results presented in this paper are based on the ns2 mobility software on linux platform. The simulations results show that our proposed technique achieves better performance than the others, considering the packet delay, the packet losses during handoffs and the registration time, in different scenarios for the location of the mn with respect to the ha and fas.",
	 'authors': u'Moheb R Girgis, Tarek M Mahmoud, Youssef S Takroni, Hassan S Hassan,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1004.0771',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nPerformance evaluation of a new route optimization technique for mobile  IP',
	 'urllink': u'http://arxiv.org/abs/1004.0771'}
2015-03-24 10:54:39+0000 [xxu46_1] INFO: Crawled 540 pages (at 1 pages/min), scraped 534 items (at 1 items/min)
2015-03-24 10:55:39+0000 [xxu46_1] INFO: Crawled 540 pages (at 0 pages/min), scraped 534 items (at 0 items/min)
2015-03-24 10:56:03+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4774> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 10:56:03+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4774>
	{'abstract': u'The market economy deals with many interacting agents such as buyers and sellers who are autonomous intelligent agents pursuing their own interests. One such multi-agent system (MAS) that plays an important role in auctions is the combinatorial auctioning system (CAS). We use this framework to define our concept of fairness in terms of what we call as "basic fairness" and "extended fairness". The assumptions of quasilinear preferences and dominant strategies are taken into consideration while explaining fairness. We give an algorithm to ensure fairness in a CAS using a Generalized Vickrey Auction (GVA). We use an algorithm of Sandholm to achieve optimality. Basic and extended fairness are then analyzed according to the dominant strategy solution concept.',
	 'authors': u'Sumanth Sudeendra, Megha Saini, Shrisha Rao,',
	 'category': u'Computer Science ',
	 'date': '2010-5-26',
	 'pdflink': u'http://arxiv.org/pdf/1005.4774',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nFairness in Combinatorial Auctions',
	 'urllink': u'http://arxiv.org/abs/1005.4774'}
2015-03-24 10:56:39+0000 [xxu46_1] INFO: Crawled 541 pages (at 1 pages/min), scraped 535 items (at 1 items/min)
2015-03-24 10:57:39+0000 [xxu46_1] INFO: Crawled 541 pages (at 0 pages/min), scraped 535 items (at 0 items/min)
2015-03-24 10:57:43+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0575> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 10:57:43+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0575>
	{'abstract': u'This paper presents a performance evaluation of Wireless Sensor Networks (WSN) based on Impulse Radio Ultra Wideband (IR-UWB) over a new simulation platform developed for this purpose. The simulation platform is built on an existing network simulator: Global Mobile Information System Simulator (GloMoSim). It mainly focuses on the accurately modeling of IR-UWB PHYsical (PHY) and Medium Access Control (MAC) layer. Pulse collision is modeled according to the used time hopping sequence (THS) and the pulse propagation delay in order to increase the simulation fidelity. It also includes a detection and identification application based on a new sensing channel and new sensor device models. The proposed architecture is generic so it can be reused for any simulation platform. The performance evaluation is based on one of the typical WSN applications: local area protection, where sensor nodes are densely scattered in an access regulated area in order to detect, identify and report non authorized accesses to a base station for analysis. Two networks topologies using different protocol stacks are investigated. Their performance evaluation is presented in terms of reliability and latency.',
	 'authors': u'Aubin Lecointre, Abdoulaye Berthe, Daniela Dragomirescu, Robert Plana,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0575',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nPerformance Evaluation of Impluse Radio Ultra Wide Band Wireless Sensor  Networks',
	 'urllink': u'http://arxiv.org/abs/1002.0575'}
2015-03-24 10:58:39+0000 [xxu46_1] INFO: Crawled 542 pages (at 1 pages/min), scraped 536 items (at 1 items/min)
2015-03-24 10:59:21+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0770> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 10:59:21+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0770>
	{'abstract': u'In this paper we present a way of hiding the data in mobile devices from being compromised. We use two level data hiding technique, where in its first level data is encrypted and stored in special records and the second level being a typical password protection scheme. The second level is for secure access of information from the device. In the first level, encryption of the data is done using the location coordinates as key. Location Coordinates are rounded up figures of longitude and latitude information. In the second phase the password entry differs from conventional schemes. Here we have used the patterns of traditional Rangoli for specifying the password and gaining access, thus minimising the chances of data leak in hostile situations. The proposed structure would be a better trade off in comparison with the previous models which use Bio Metric authentication -- a relatively costly way of authentication.',
	 'authors': u'M Prabu Kumar, K Praneesh Kumar Yadav,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1004.0770',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nData security in mobile devices by geo locking',
	 'urllink': u'http://arxiv.org/abs/1004.0770'}
2015-03-24 10:59:39+0000 [xxu46_1] INFO: Crawled 543 pages (at 1 pages/min), scraped 537 items (at 1 items/min)
2015-03-24 11:00:39+0000 [xxu46_1] INFO: Crawled 543 pages (at 0 pages/min), scraped 537 items (at 0 items/min)
2015-03-24 11:01:02+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4769> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 11:01:02+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4769>
	{'abstract': u'Network tomography aims at inferring internal network characteristics based on measurements at the edge of the network. In loss tomography, in particular, the characteristic of interest is the loss rate of individual links and multicast and/or unicast end-to-end probes are typically used. Independently, recent advances in network coding have shown that there are advantages from allowing intermediate nodes to process and combine, in addition to just forward, packets. In this paper, we study the problem of loss tomography in networks with network coding capabilities. We design a framework for estimating link loss rates, which leverages network coding capabilities, and we show that it improves several aspects of tomography including the identifiability of links, the trade-off between estimation accuracy and bandwidth efficiency, and the complexity of probe path selection. We discuss the cases of inferring link loss rates in a tree topology and in a general topology. In the latter case, the benefits of our approach are even more pronounced compared to standard techniques, but we also face novel challenges, such as dealing with cycles and multiple paths between sources and receivers. Overall, this work makes the connection between active network tomography and network coding.',
	 'authors': u'Pegah Sattari, Athina Markopoulou, Christina Fragouli, Minas Gjoka,',
	 'category': u'Computer Science ',
	 'date': '2010-5-26',
	 'pdflink': u'http://arxiv.org/pdf/1005.4769',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nA Network Coding Approach to Loss Tomography',
	 'urllink': u'http://arxiv.org/abs/1005.4769'}
2015-03-24 11:01:39+0000 [xxu46_1] INFO: Crawled 544 pages (at 1 pages/min), scraped 538 items (at 1 items/min)
2015-03-24 11:02:30+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0574> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 11:02:30+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0574>
	{'abstract': u'Starting from the Shannon channel capacity, we propose an IR-UWB channel capacity based on the delay spread for multipath time variant channels. This IR-UWB channel capacity is obtained from the no ISI (Inter Symbol Interference) assumption and for binary modulations. The impact of the kind of implementation is considered on the IR-UWB channel capacity. This study is lead for mixed and mostly digital implementation. The key parameters and theirs impacts on the channel capacity are exposed in each case: the data converters for mostly digital implementations and the pulse generator capabilities for mixed implementations. Finally, these two implementations are compared from a data rate point of view. Their behaviors regarding an increase of the operating frequency are also studied.',
	 'authors': u'Aubin Lecointre, Daniela Dragomirescu, Robert Plana,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0574',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nChannel Capacity Limitations versus Hardware Implementation for UWB  Impulse Radio Communications',
	 'urllink': u'http://arxiv.org/abs/1002.0574'}
2015-03-24 11:02:39+0000 [xxu46_1] INFO: Crawled 545 pages (at 1 pages/min), scraped 539 items (at 1 items/min)
2015-03-24 11:03:30+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0769> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 11:03:30+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0769>
	{'abstract': u'Wireless networks are a common place nowadays and almost all of the modern devices support wireless communication in some form. These networks differ from more traditional computing systems due to the ad-hoc and spontaneous nature of interactions among devices. These systems are prone to security risks, such as eavesdropping and require different techniques as compared to traditional security mechanisms. Recently, secure device pairing in wireless environments has got substantial attention from many researchers. As a result, a significant set of techniques and protocols have been proposed to deal with this issue. Some of these techniques consider devices equipped with infrared, laser, ultrasound transceivers or 802.11 network interface cards; while others require embedded accelerometers, cameras and/or LEDs, displays, microphones and/or speakers. However, many of the proposed techniques or protocols have not been implemented at all; while others are implemented and evaluated in a stand-alone manner without being compared with other related work [1]. We believe that it is because of the lack of specialized tools that provide a common platform to test the pairing methods. As a consequence, we designed such a tool. In this paper, we are presenting design and development of the Pairing Simulator (PSim) that can be used to perform the analysis of device pairing methods.',
	 'authors': u'Yasir Arfat Malkani, Lachhman Das Dhomeja,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1004.0769',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nPSIM: A tool for analysis of device pairing methods',
	 'urllink': u'http://arxiv.org/abs/1004.0769'}
2015-03-24 11:03:39+0000 [xxu46_1] INFO: Crawled 546 pages (at 1 pages/min), scraped 540 items (at 1 items/min)
2015-03-24 11:04:39+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4762> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 11:04:39+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4762>
	{'abstract': u'Mathematical learning environments help students in mastering mathematical knowledge. Mature environments typically offer thousands of interactive exercises. Providing feedback to students solving interactive exercises requires domain reasoners for doing the exercise-specific calculations. Since a domain reasoner has to solve an exercise in the same way a student should solve it, the structure of domain reasoners should follow the layered structure of the mathematical domains. Furthermore, learners, teachers, and environment builders have different requirements for adapting domain reasoners, such as providing more details, disallowing or enforcing certain solutions, and combining multiple mathematical domains in a new domain. In previous work we have shown how domain reasoners for solving interactive exercises can be expressed in terms of rewrite strategies, rewrite rules, and views. This paper shows how users can adapt and configure such domain reasoners to their own needs. This is achieved by enabling users to explicitly communicate the components that are used for solving an exercise.',
	 'authors': u'Bastiaan Heeren, Johan Jeuring,',
	 'category': u'Computer Science ',
	 'date': '2010-5-26',
	 'pdflink': u'http://arxiv.org/pdf/1005.4762',
	 'subjects': u'Mathematical Software (cs.MS)',
	 'title': u'\nAdapting Mathematical Domain Reasoners',
	 'urllink': u'http://arxiv.org/abs/1005.4762'}
2015-03-24 11:04:39+0000 [xxu46_1] INFO: Crawled 547 pages (at 1 pages/min), scraped 541 items (at 1 items/min)
2015-03-24 11:05:39+0000 [xxu46_1] INFO: Crawled 547 pages (at 0 pages/min), scraped 541 items (at 0 items/min)
2015-03-24 11:06:18+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0573> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 11:06:18+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0573>
	{'abstract': u'This paper describes a detailed performance evaluation of distributed Medium Access Control (MAC) protocols for Wireless Sensor Networks based on Impulse Radio Ultra Wideband (IR-UWB) Physical layer (PHY). Two main classes of Medium Access Control protocol have been considered: Slotted and UnSlotted with reliability. The reliability is based on Automatic Repeat ReQuest (ARQ). The performance evaluation is performed using a complete Wireless Sensor Networks (WSN) simulator built on the Global Mobile Information System Simulator (GloMoSim). The optimal operating parameters are first discussed for IR-UWB in terms of slot size, retransmission delay and the number of retransmission, then a comparison between IR-UWB and other transmission techniques in terms of reliability latency and power efficiency.',
	 'authors': u'Abdoulaye Berthe, Aubin Lecointre, Daniela Dragomirescu, Robert Plana,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0573',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nMedium Access Control for Wireless Sensor Networks based on Impulse  Radio Ultra Wideband',
	 'urllink': u'http://arxiv.org/abs/1002.0573'}
2015-03-24 11:06:39+0000 [xxu46_1] INFO: Crawled 548 pages (at 1 pages/min), scraped 542 items (at 1 items/min)
2015-03-24 11:07:39+0000 [xxu46_1] INFO: Crawled 548 pages (at 0 pages/min), scraped 542 items (at 0 items/min)
2015-03-24 11:07:53+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0767> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 11:07:53+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0767>
	{'abstract': u"In 2004, Das, Saxena and Gulati proposed a dynamic ID-based remote user authentication scheme which has many advantage such as no verifier table, user freedom to choose and change password and so on. However the subsequent papers have shown that this scheme is completely insecure and vulnerable to many attacks. Since then many schemes with improvements to Das et al's scheme has been proposed but each has its pros and cons. Recently Yan-yan Wang et al. have proposed a scheme to overcome security weaknesses of Das et al.'s scheme. However this scheme too is vulnerable to various security attacks such as password guessing attack, masquerading attack, denial of service attack.",
	 'authors': u'Mohammed Aijaz Ahmed, D. Rajya Lakshmi, Sayed Abdul Sattar,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1004.0767',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nCryptanalysis of a more efficient and secure dynamic id-based remote  user authentication scheme',
	 'urllink': u'http://arxiv.org/abs/1004.0767'}
2015-03-24 11:08:39+0000 [xxu46_1] INFO: Crawled 549 pages (at 1 pages/min), scraped 543 items (at 1 items/min)
2015-03-24 11:09:25+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4752> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 11:09:25+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4752>
	{'abstract': u'In this report, we unify two quite distinct approaches to information retrieval: region models and language models. Region models were developed for structured document retrieval. They provide a well-defined behaviour as well as a simple query language that allows application developers to rapidly develop applications. Language models are particularly useful to reason about the ranking of search results, and for developing new ranking approaches. The unified model allows application developers to define complex language modeling approaches as logical queries on a textual database. We show a remarkable one-to-one relationship between region queries and the language models they represent for a wide variety of applications: simple ad-hoc search, cross-language retrieval, video retrieval, and web search.',
	 'authors': u'Djoerd Hiemstra, Vojkan Mihajlovic,',
	 'category': u'Computer Science ',
	 'date': '2010-5-26',
	 'pdflink': u'http://arxiv.org/pdf/1005.4752',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nA database approach to information retrieval: The remarkable  relationship between language models and region models',
	 'urllink': u'http://arxiv.org/abs/1005.4752'}
2015-03-24 11:09:39+0000 [xxu46_1] INFO: Crawled 550 pages (at 1 pages/min), scraped 544 items (at 1 items/min)
2015-03-24 11:10:39+0000 [xxu46_1] INFO: Crawled 550 pages (at 0 pages/min), scraped 544 items (at 0 items/min)
2015-03-24 11:10:45+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0570> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 11:10:45+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0570>
	{'abstract': u'Impulse Radio Ultra Wide Band (IR-UWB) is a promising technology to address Wireless Sensor Network (WSN) constraints. However, existing network simulation tools do not provide a complete WSN simulation architecture, with the IR-UWB specificities at the PHYsical (PHY) and the Medium Access Control (MAC) layers. In this paper, we propose a WSN simulation architecture based on the IR-UWB technique. At the PHY layer, we take into account the pulse collision by dealing with the pulse propagation delay. We also modelled MAC protocols specific to IRUWB, for WSN applications. To completely fit the WSN simulation requirements, we propose a generic and reusable sensor and sensing channel model. Most of the WSN application performances can be evaluated thanks to the proposed simulation architecture. The proposed models are implemented on a scalable and well known network simulator: Global Mobile Information System Simulator (GloMoSim). However, they can be reused for all other packet based simulation platforms.',
	 'authors': u'Abdoulaye Berthe, Aubin Lecointre, Daniela Dragomirescu, Robert Plana,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0570',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nSimulation Platform for Wireless Sensor Networks Based on Impulse Radio  Ultra Wide Band',
	 'urllink': u'http://arxiv.org/abs/1002.0570'}
2015-03-24 11:11:39+0000 [xxu46_1] INFO: Crawled 551 pages (at 1 pages/min), scraped 545 items (at 1 items/min)
2015-03-24 11:12:12+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0766> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 11:12:13+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0766>
	{'abstract': u'Separation of the text regions from background texture and graphics is an important step of any optical character recognition sytem for the images containg both texts and graphics. In this paper, we have presented a novel text/graphics separation technique for business card images captured with a cell-phone camera. At first, the background is eliminated at a coarse level based on intensity variance. This makes the foreground components distinct from each other. Then the non-text components are removed using various characteristic features of text and graphics. Finally, the text regions are skew corrected and binarized for further processing. Experimenting with business card images of various resolutions, we have found an optimum performance of 98.54% with 0.75 MP images, that takes 0.17 seconds processing time and 1.1 MB peak memory on a moderately powerful computer (DualCore 1.73 GHz Processor, 1 GB RAM, 1 MB L2 Cache). The developed technique is computationally efficient and consumes low memory so as to be applicable on mobile devices.',
	 'authors': u'Ayatullah Faruk Mollah, Subhadip Basu, Mita Nasipuri, Dipak Kumar Basu,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1004.0766',
	 'subjects': u'Graphics (cs.GR)',
	 'title': u'\nText/Graphics Separation for Business Card Images for Mobile Devices',
	 'urllink': u'http://arxiv.org/abs/1004.0766'}
2015-03-24 11:12:39+0000 [xxu46_1] INFO: Crawled 552 pages (at 1 pages/min), scraped 546 items (at 1 items/min)
2015-03-24 11:13:39+0000 [xxu46_1] INFO: Crawled 552 pages (at 0 pages/min), scraped 546 items (at 0 items/min)
2015-03-24 11:13:54+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4714> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 11:13:54+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4714>
	{'abstract': u'Functional dependencies -- traditional, approximate and conditional are of critical importance in relational databases, as they inform us about the relationships between attributes. They are useful in schema normalization, data rectification and source selection. Most of these were however developed in the context of deterministic data. Although uncertain databases have started receiving attention, these dependencies have not been defined for them, nor are fast algorithms available to evaluate their confidences. This paper defines the logical extensions of various forms of functional dependencies for probabilistic databases and explores the connections between them. We propose a pruning-based exact algorithm to evaluate the confidence of functional dependencies, a Monte-Carlo based algorithm to evaluate the confidence of approximate functional dependencies and algorithms for their conditional counterparts in probabilistic databases. Experiments are performed on both synthetic and real data evaluating the performance of these algorithms in assessing the confidence of dependencies and mining them from data. We believe that having these dependencies and algorithms available for probabilistic databases will drive adoption of probabilistic data storage in the industry.',
	 'authors': u'Sushovan De, Subbarao Kambhampati,',
	 'category': u'Computer Science ',
	 'date': '2010-5-26',
	 'pdflink': u'http://arxiv.org/pdf/1005.4714',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nDefining and Mining Functional Dependencies in Probabilistic Databases',
	 'urllink': u'http://arxiv.org/abs/1005.4714'}
2015-03-24 11:14:39+0000 [xxu46_1] INFO: Crawled 553 pages (at 1 pages/min), scraped 547 items (at 1 items/min)
2015-03-24 11:15:20+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0562> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 11:15:20+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0562>
	{'abstract': u'A neat 1972 result of Pohl asserts that [3n/2]-2 comparisons are sufficient, and also necessary in the worst case, for finding both the minimum and the maximum of an n-element totally ordered set. The set is accessed via an oracle for pairwise comparisons. More recently, the problem has been studied in the context of the Renyi-Ulam liar games, where the oracle may give up to k false answers. For large k, an upper bound due to Aigner shows that (k+O( sqrt))n comparisons suffice. We improve on this by providing an algorithm with at most (k+1+C)n+O(k^3) comparisons for some constant C. The known lower bounds are of the form (k+1+c_k)n-D, for some constant D, where c_0=0.5, c_1=23/32=0.71875, and c_k= Omega(2^) as k goes to infinity.',
	 'authors': u'Michael Hoffmann, Ji\u0159\xed Matou\u0161ek, Yoshio Okamoto, Philipp Zumstein,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0562',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nMinimum and maximum against k lies',
	 'urllink': u'http://arxiv.org/abs/1002.0562'}
2015-03-24 11:15:39+0000 [xxu46_1] INFO: Crawled 554 pages (at 1 pages/min), scraped 548 items (at 1 items/min)
2015-03-24 11:16:39+0000 [xxu46_1] INFO: Crawled 554 pages (at 0 pages/min), scraped 548 items (at 0 items/min)
2015-03-24 11:16:54+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0765> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 11:16:54+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0765>
	{'abstract': u'This paper is aimed at the stipulations which arise in the traditional online auctions as a result of various anomalies in the reputation and trust calculation mechanism. We try to improve the scalability and efficiency of the online auctions by providing efficient trust management methodology considering several factors into consideration. A comparison between the performance of the auctions system with and without the agent methodology is done with good results',
	 'authors': u'E.Sathiyamoorthy, N.Ch.Sriman Narayana Iyenger, V.Ramachandran,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1004.0765',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nAgent Based Trust Management Model Based on Weight Value Model for  Online Auctions',
	 'urllink': u'http://arxiv.org/abs/1004.0765'}
2015-03-24 11:17:39+0000 [xxu46_1] INFO: Crawled 555 pages (at 1 pages/min), scraped 549 items (at 1 items/min)
2015-03-24 11:18:28+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4697> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 11:18:28+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4697>
	{'abstract': u'The Lambek-Grishin calculus LG is the symmetric extension of the non-associative Lambek calculus NL. In this paper we prove that the derivability problem for LG is NP-complete.',
	 'authors': u'Jeroen Bransen,',
	 'category': u'Computer Science ',
	 'date': '2010-5-25',
	 'pdflink': u'http://arxiv.org/pdf/1005.4697',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nThe Lambek-Grishin calculus is NP-complete',
	 'urllink': u'http://arxiv.org/abs/1005.4697'}
2015-03-24 11:18:39+0000 [xxu46_1] INFO: Crawled 556 pages (at 1 pages/min), scraped 550 items (at 1 items/min)
2015-03-24 11:19:39+0000 [xxu46_1] INFO: Crawled 556 pages (at 0 pages/min), scraped 550 items (at 0 items/min)
2015-03-24 11:20:02+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0561> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 11:20:02+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0561>
	{'abstract': u'Before contributing new knowledge, individuals must attain requisite background knowledge or skills through schooling, training, practice, and experience. Given limited time, individuals often choose either to focus on few areas, where they build deep expertise, or to delve less deeply and distribute their attention and efforts across several areas. In this paper we measure the relationship between the narrowness of focus and the quality of contribution across a range of both traditional and recent knowledge sharing media, including scholarly articles, patents, Wikipedia, and online question and answer forums. Across all systems, we observe a small but significant positive correlation between focus and quality.',
	 'authors': u'Lada A. Adamic, Xiao Wei, Jiang Yang, Sean Gerrish, Kevin K. Nam, Gavin S. Clarkson,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0561',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nIndividual focus and knowledge contribution',
	 'urllink': u'http://arxiv.org/abs/1002.0561'}
2015-03-24 11:20:39+0000 [xxu46_1] INFO: Crawled 557 pages (at 1 pages/min), scraped 551 items (at 1 items/min)
2015-03-24 11:21:20+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0762> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 11:21:20+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0762>
	{'abstract': u'Nowadays, the IP Multimedia Subsystem (IMS) is a promising research field. Many ongoing works related to the security and the performances of its employment are presented to the research community. Although, the security and data privacy aspects are very important in the IMS global objectives, they observe little attention so far. Secure access to multimedia services is based on SIP and HTTP digest on top of IMS architecture. The standard deploys AKA-MD5 for the terminal authentication. The third Generation Partnership Project (3GPP) provided Generic Bootstrapping Architecture (GBA) to authenticate the subscriber before accessing multimedia services over HTTP. In this paper, we propose a new IMS Service Authentication scheme using Identity Based cryptography (IBC). This new scheme will lead to better performances when there are simultaneous authentication requests using Identity-based Batch Verification. We analyzed the security of our new protocol and we presented a performance evaluation of its cryptographic operations',
	 'authors': u'Mohamed Abid, Songbo Song, Hassnaa Moustafa, Hossam Afifi,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1004.0762',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nIntegrating identity-based cryptography in IMS service authentication',
	 'urllink': u'http://arxiv.org/abs/1004.0762'}
2015-03-24 11:21:39+0000 [xxu46_1] INFO: Crawled 558 pages (at 1 pages/min), scraped 552 items (at 1 items/min)
2015-03-24 11:22:39+0000 [xxu46_1] INFO: Crawled 558 pages (at 0 pages/min), scraped 552 items (at 0 items/min)
2015-03-24 11:22:57+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4695> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 11:22:57+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4695>
	{'abstract': u'Topology is a fundamental part of a network that governs connectivity between nodes, the amount of data flow and the efficiency of data flow between nodes. In traditional networks, due to physical limitations, topology remains static for the course of the network operation. Ubiquitous data networks (UDNs), alternatively, are more adaptive and can be configured for changes in their topology. This flexibility in controlling their topology makes them very appealing and an attractive medium for supporting "anywhere, any place" communication. However, it raises the problem of designing a dynamic topology. The dynamic topology design problem is of particular interest to application service providers who need to provide cost-effective data services on a ubiquitous network. In this paper we describe algorithms that decide when and how the topology should be reconfigured in response to a change in the data communication requirements of the network. In particular, we describe and compare a greedy algorithm, which is often used for topology reconfiguration, with a non-greedy algorithm based on metrical task systems. Experiments show the algorithm based on metrical task system has comparable performance to the greedy algorithm at a much lower reconfiguration cost.',
	 'authors': u'Tanu Malik, Raghvendra Prasad, Sanket Patil, Amitabh Chaudhary, Venkat Venkatasubramanian,',
	 'category': u'Computer Science ',
	 'date': '2010-5-25',
	 'pdflink': u'http://arxiv.org/pdf/1005.4695',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nProviding Scalable Data Services in Ubiquitous Networks',
	 'urllink': u'http://arxiv.org/abs/1005.4695'}
2015-03-24 11:23:39+0000 [xxu46_1] INFO: Crawled 559 pages (at 1 pages/min), scraped 553 items (at 1 items/min)
2015-03-24 11:24:12+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0532> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 11:24:12+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0532>
	{'abstract': u'The Actor Network represents heterogeneous entities as actants (Callon et al., 1983; 1986). Although computer programs for the visualization of social networks increasingly allow us to represent heterogeneity in a network using different shapes and colors for the visualization, hitherto this possibility has scarcely been exploited (Mogoutov et al., 2008). In this contribution to the Festschrift, I study the question of what heterogeneity can add specifically to the visualization of a network. How does an integrated network improve on the one-dimensional ones (such as co-word and co-author maps)? The oeuvre of Michel Callon is used as the case materials, that is, his 65 papers which can be retrieved from the (Social) Science Citation Index since 1975.',
	 'authors': u'Loet Leydesdorff,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0532',
	 'subjects': u'Digital Libraries (cs.DL)',
	 'title': u'\nWhat Can Heterogeneity Add to the Scientometric Map? Steps towards  algorithmic historiography',
	 'urllink': u'http://arxiv.org/abs/1002.0532'}
2015-03-24 11:24:39+0000 [xxu46_1] INFO: Crawled 560 pages (at 1 pages/min), scraped 554 items (at 1 items/min)
2015-03-24 11:25:36+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0755> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 11:25:36+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0755>
	{'abstract': u'In this paper a novel method called Extended Two-Dimensional PCA (E2DPCA) is proposed which is an extension to the original 2DPCA. We state that the covariance matrix of 2DPCA is equivalent to the average of the main diagonal of the covariance matrix of PCA. This implies that 2DPCA eliminates some covariance information that can be useful for recognition. E2DPCA instead of just using the main diagonal considers a radius of r diagonals around it and expands the averaging so as to include the covariance information within those diagonals. The parameter r unifies PCA and 2DPCA. r = 1 produces the covariance of 2DPCA, r = n that of PCA. Hence, by controlling r it is possible to control the trade-offs between recognition accuracy and energy compression (fewer coefficients), and between training and recognition complexity. Experiments on ORL face database show improvement in both recognition accuracy and recognition time over the original 2DPCA.',
	 'authors': u'Mehran Safayani, Mohammad T. Manzuri-Shalmani, Mahmoud Khademi,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1004.0755',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nExtended Two-Dimensional PCA for Efficient Face Representation and  Recognition',
	 'urllink': u'http://arxiv.org/abs/1004.0755'}
2015-03-24 11:25:39+0000 [xxu46_1] INFO: Crawled 561 pages (at 1 pages/min), scraped 555 items (at 1 items/min)
2015-03-24 11:26:39+0000 [xxu46_1] INFO: Crawled 561 pages (at 0 pages/min), scraped 555 items (at 0 items/min)
2015-03-24 11:26:45+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4661> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 11:26:45+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4661>
	{'abstract': u'This article introduces yet another representation of rotations in 3-space. The rotations form a 3-dimensional projective space, which fact has not been exploited in Computer Science. We use the four affine patches of this projective space to parametrize the rotations. This affine patch representation is more compact than quaternions (which require 4 components for calculations), encompasses the entire rotation group without singularities (unlike the Euler angles and rotation vector approaches), and requires only ratios of linear or quadratic polynomials for basic computations (unlike the Euler angles and rotation vector approaches which require transcendental functions). As an example, we derive the differential equation for the integration of angular velocity using this affine patch representation of rotations. We remark that the complexity of this equation is the same as the corresponding quaternion equation, but has advantages over the quaternion approach e.g. renormalization to unit length is not required, and state space has no dead directions.',
	 'authors': u'Norman J. Goldstein,',
	 'category': u'Computer Science ',
	 'date': '2010-5-22',
	 'pdflink': u'http://arxiv.org/pdf/1005.4661',
	 'subjects': u'Mathematical Software (cs.MS)',
	 'title': u'\nNonsingular Efficient Modeling of Rotations in 3-space using three  components',
	 'urllink': u'http://arxiv.org/abs/1005.4661'}
2015-03-24 11:27:39+0000 [xxu46_1] INFO: Crawled 562 pages (at 1 pages/min), scraped 556 items (at 1 items/min)
2015-03-24 11:28:17+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0511> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 11:28:17+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0511>
	{'abstract': u'This paper presents our approach of the radio interface problematic for Wireless Sensor Network. We introduce the WSN context and constraints associated. We propose an IR-UWB solution and illustrate why it could be a viable solution for WSN. A high level modelling and simulation platform for IR-UWB radio interface is proposed on Matlab. It allows us to determine according to BER versus Eb/N0 criteria and the WSN constraints what kind of design is more adequate. Moreover, a co-design co-simulation platform Matlab VHDL is proposed here. Using this platform we designed IR-UWB transceiver having reconfigurable capabilities, such as data rate reconfiguration, time hopping code, spectrum occupation and radio range reconfiguration.',
	 'authors': u'Daniela Dragomirescu, Aubin Lecointre, Robert Plana,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0511',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nSOPC Co-Design Platform for UWB Systems in Wireless Sensor Network  Context',
	 'urllink': u'http://arxiv.org/abs/1002.0511'}
2015-03-24 11:28:39+0000 [xxu46_1] INFO: Crawled 563 pages (at 1 pages/min), scraped 557 items (at 1 items/min)
2015-03-24 11:29:39+0000 [xxu46_1] INFO: Crawled 563 pages (at 0 pages/min), scraped 557 items (at 0 items/min)
2015-03-24 11:30:02+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0744> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 11:30:02+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0744>
	{'abstract': u'We consider the following problem: Given a finite set of straight line segments in the plane, determine the positions of a minimal number of points on the segments, from which guards can see all segments. This problem can be interpreted as looking for a minimal number of locations of policemen, guards, cameras or other sensors, that can observe a network of streets, corridors, tunnels, tubes, etc. We show that the problem is strongly NP-complete even for a set of segments with a cubic graph structure, but in P for tree structures.',
	 'authors': u'Valentin E. Brimkov,',
	 'category': u'Computer Science ',
	 'date': '2010-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1004.0744',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nPatrolling a Street Network is Strongly NP-Complete but in P for Tree  Structures',
	 'urllink': u'http://arxiv.org/abs/1004.0744'}
2015-03-24 11:30:39+0000 [xxu46_1] INFO: Crawled 564 pages (at 1 pages/min), scraped 558 items (at 1 items/min)
2015-03-24 11:31:27+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4652> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 11:31:27+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4652>
	{'abstract': u'The rank and select operations over a string of length n from an alphabet of size have been used widely in the design of succinct data structures. In many applications, the string itself need be maintained dynamically, allowing characters of the string to be inserted and deleted. Under the word RAM model with word size , we design a succinct representation of dynamic strings using bits to support rank, select, insert and delete in time. When the alphabet size is small, i.e. when , including the case in which the string is a bit vector, these operations are supported in time. Our data structures are more efficient than previous results on the same problem, and we have applied them to improve results on the design and construction of space-efficient text indexes.',
	 'authors': u'Meng He, J. Ian Munro,',
	 'category': u'Computer Science ',
	 'date': '2010-5-25',
	 'pdflink': u'http://arxiv.org/pdf/1005.4652',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nSuccinct Representations of Dynamic Strings',
	 'urllink': u'http://arxiv.org/abs/1005.4652'}
2015-03-24 11:31:39+0000 [xxu46_1] INFO: Crawled 565 pages (at 1 pages/min), scraped 559 items (at 1 items/min)
2015-03-24 11:32:39+0000 [xxu46_1] INFO: Crawled 565 pages (at 0 pages/min), scraped 559 items (at 0 items/min)
2015-03-24 11:32:46+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0509> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 11:32:46+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0509>
	{'abstract': u'We introduce the radio reconfigurability thanks to IRUWB mostly digital architecture for MANET context. This particular context implies some constraints on the radio interface such as low cost, low power, small dimensions and simplicity. Here, we propose an implementation of dynamic reconfigurable receiver on ASIC, and FPGA, after having explained the advantages of mostly digital radio for reconfigurability. In this paper, by studying our prototypes, we could prove that reconfigurability is on the contrary with MANET constraints needs. The proposed solution allows data rate, radio range, energy and spectrum occupation reconfigurability.',
	 'authors': u'Aubin Lecointre, Daniela Dragomirescu, Robert Plana,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0509',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nStudy of Reconfigurable Mostly Digital Radio for Manet',
	 'urllink': u'http://arxiv.org/abs/1002.0509'}
2015-03-24 11:33:39+0000 [xxu46_1] INFO: Crawled 566 pages (at 1 pages/min), scraped 560 items (at 1 items/min)
2015-03-24 11:34:15+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0739> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 11:34:15+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0739>
	{'abstract': u'Often one has a preference order among the different systems that satisfy a given specification. Under a probabilistic assumption about the possible inputs, such a preference order is naturally expressed by a weighted automaton, which assigns to each word a value, such that a system is preferred if it generates a higher expected value. We solve the following optimal-synthesis problem: given an omega-regular specification, a Markov chain that describes the distribution of inputs, and a weighted automaton that measures how well a system satisfies the given specification under the given input assumption, synthesize a system that optimizes the measured value. For safety specifications and measures given by mean-payoff automata, the optimal-synthesis problem amounts to finding a strategy in a Markov decision process (MDP) that is optimal for a long-run average reward objective, which can be done in polynomial time. For general omega-regular specifications, the solution rests on a new, polynomial-time algorithm for computing optimal strategies in MDPs with mean-payoff parity objectives. Our algorithm generates optimal strategies consisting of two memoryless strategies and a counter. This counter is in general not bounded. To obtain a finite-state system, we show how to construct an epsilon-optimal strategy with a bounded counter for any epsilon&gt;0. We also show how to decide in polynomial time if we can construct an optimal finite-state system (i.e., a system without a counter) for a given specification. We have implemented our approach in a tool that takes qualitative and quantitative specifications and automatically constructs a system that satisfies the qualitative specification and optimizes the quantitative specification, if such a system exists. We present experimental results showing optimal systems that were generated in this way.',
	 'authors': u'Krishnendu Chatterjee, Thomas A. Henzinger, Barbara Jobstmann, Rohit Singh,',
	 'category': u'Computer Science ',
	 'date': '2010-4-5',
	 'pdflink': u'http://arxiv.org/pdf/1004.0739',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nMeasuring and Synthesizing Systems in Probabilistic Environments',
	 'urllink': u'http://arxiv.org/abs/1004.0739'}
2015-03-24 11:34:39+0000 [xxu46_1] INFO: Crawled 567 pages (at 1 pages/min), scraped 561 items (at 1 items/min)
2015-03-24 11:35:39+0000 [xxu46_1] INFO: Crawled 567 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2015-03-24 11:35:59+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4616> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 11:35:59+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4616>
	{'abstract': u"A parametric analysis is an analysis whose input and output are parametrized with a number of parameters which can be instantiated to abstract properties after analysis is completed. This paper proposes to use Cousot and Cousot's Cardinal power domain to capture functional dependencies of analysis output on its input and obtain a parametric analysis by parametrizing a non-parametric base analysis. We illustrate the method by parametrizing a based groundness analysis of logic programs to a parametric groundness analysis. In addition, a prototype implementation shows that generality of the parametric groundness analysis comes with a negligible extra cost.",
	 'authors': u'Lunjin Lu,',
	 'category': u'Computer Science ',
	 'date': '2010-5-25',
	 'pdflink': u'http://arxiv.org/pdf/1005.4616',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nParametrizing Program Analysis by Lifting to Cardinal Power Domains',
	 'urllink': u'http://arxiv.org/abs/1005.4616'}
2015-03-24 11:36:39+0000 [xxu46_1] INFO: Crawled 568 pages (at 1 pages/min), scraped 562 items (at 1 items/min)
2015-03-24 11:37:03+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0508> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 11:37:03+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0508>
	{'abstract': u'This paper addresses the radio interface problematic for MANET (Mobile Ad-hoc NETwork) applications. Here we propose to study the radio reconfigurability in order to provide a unique physical layer which is able to deal with all MANET applications. For implementing this reconfigurable physical layer, we propose to use Impulse Radio Ultra WideBand (IRUWB). This paper presents also our two level design approach for obtaining our reconfigurable IR-UWB receiver on FPGA (Field Programmable Gate Array).',
	 'authors': u'Aubin Lecointre, Daniela Dragomirescu, Robert Plana,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0508',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nSoftware defined radio layer for IR-UWB systems in Wireless Sensor  Network Context',
	 'urllink': u'http://arxiv.org/abs/1002.0508'}
2015-03-24 11:37:39+0000 [xxu46_1] INFO: Crawled 569 pages (at 1 pages/min), scraped 563 items (at 1 items/min)
2015-03-24 11:38:24+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0728> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 11:38:24+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0728>
	{'abstract': u'Modern large-scale date centres, such as those used for cloud computing service provision, are becoming ever-larger as the operators of those data centres seek to maximise the benefits from economies of scale. With these increases in size comes a growth in system complexity, which is usually problematic. There is an increased desire for automated "self-star" configuration, management, and failure-recovery of the data-centre infrastructure, but many traditional techniques scale much worse than linearly as the number of nodes to be managed increases. As the number of nodes in a median-sized data-centre looks set to increase by two or three orders of magnitude in coming decades, it seems reasonable to attempt to explore and understand the scaling properties of the data-centre middleware before such data-centres are constructed. In [1] we presented SPECI, a simulator that predicts aspects of large-scale data-centre middleware performance, concentrating on the influence of status changes such as policy updates or routine node failures. [...]. In [1] we used a first-approximation assumption that such subscriptions are distributed wholly at random across the data centre. In this present paper, we explore the effects of introducing more realistic constraints to the structure of the internal network of subscriptions. We contrast the original results [...] exploring the effects of making the data-centre\'s subscription network have a regular lattice-like structure, and also semi-random network structures resulting from parameterised network generation functions that create "small-world" and "scale-free" networks. We show that for distributed middleware topologies, the structure and distribution of tasks carried out in the data centre can significantly influence the performance overhead imposed by the middleware.',
	 'authors': u'Ilango Sriram, Dave Cliff,',
	 'category': u'Computer Science ',
	 'date': '2010-4-5',
	 'pdflink': u'http://arxiv.org/pdf/1004.0728',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nEffects of component-subscription network topology on large-scale data  centre performance scaling',
	 'urllink': u'http://arxiv.org/abs/1004.0728'}
2015-03-24 11:38:39+0000 [xxu46_1] INFO: Crawled 570 pages (at 1 pages/min), scraped 564 items (at 1 items/min)
2015-03-24 11:39:39+0000 [xxu46_1] INFO: Crawled 570 pages (at 0 pages/min), scraped 564 items (at 0 items/min)
2015-03-24 11:39:56+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4592> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 11:39:56+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4592>
	{'abstract': u'This paper presents a combination of several automated reasoning and proof presentation tools with the Mizar system for formalization of mathematics. The combination forms an online service called MizAR, similar to the SystemOnTPTP service for first-order automated reasoning. The main differences to SystemOnTPTP are the use of the Mizar language that is oriented towards human mathematicians (rather than the pure first-order logic used in SystemOnTPTP), and setting the service in the context of the large Mizar Mathematical Library of previous theorems,definitions, and proofs (rather than the isolated problems that are solved in SystemOnTPTP). These differences poses new challenges and new opportunities for automated reasoning and for proof presentation tools. This paper describes the overall structure of MizAR, and presents the automated reasoning systems and proof presentation tools that are combined to make MizAR a useful mathematical service.',
	 'authors': u'Josef Urban, Geoff Sutcliffe,',
	 'category': u'Computer Science ',
	 'date': '2010-5-25',
	 'pdflink': u'http://arxiv.org/pdf/1005.4592',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nAutomated Reasoning and Presentation Support for Formalizing Mathematics  in Mizar',
	 'urllink': u'http://arxiv.org/abs/1005.4592'}
2015-03-24 11:40:39+0000 [xxu46_1] INFO: Crawled 571 pages (at 1 pages/min), scraped 565 items (at 1 items/min)
2015-03-24 11:41:33+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0507> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 11:41:33+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0507>
	{'abstract': u'This paper addresses an overview of the wireless sensor networks. It is shown that MEMS/NEMS technologies and SIP concept are well suited for advanced architectures. It is also shown analog architectures have to be compatible with digital signal techniques to develop smart network of microsystem.',
	 'authors': u'Aubin Lecointre, Daniela Dragomirescu, David Dubuc, Grenier Katia, Pons Patrick, Herv\xe9 Aubert, A. Muller, Pascal Berthou, Thierry Gayraud, Robert Plana,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0507',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nMiniaturized wireless sensor network',
	 'urllink': u'http://arxiv.org/abs/1002.0507'}
2015-03-24 11:41:39+0000 [xxu46_1] INFO: Crawled 572 pages (at 1 pages/min), scraped 566 items (at 1 items/min)
2015-03-24 11:42:39+0000 [xxu46_1] INFO: Crawled 572 pages (at 0 pages/min), scraped 566 items (at 0 items/min)
2015-03-24 11:42:46+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0727> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 11:42:46+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0727>
	{'abstract': u'We study matroidal networks introduced by Dougherty et al. We prove the converse of the following theorem: If a network is scalar-linearly solvable over some finite field, then the network is a matroidal network associated with a representable matroid over a finite field. It follows that a network is scalar-linearly solvable if and only if the network is a matroidal network associated with a representable matroid over a finite field. We note that this result combined with the construction method due to Dougherty et al. gives a method for generating scalar-linearly solvable networks. Using the converse implicitly, we demonstrate scalar-linear solvability of two classes of matroidal networks: networks constructed from uniform matroids and those constructed from graphic matroids.',
	 'authors': u'Anthony Kim, Muriel Medard,',
	 'category': u'Computer Science ',
	 'date': '2010-4-5',
	 'pdflink': u'http://arxiv.org/pdf/1004.0727',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nScalar-linear Solvability of Matroidal Networks Associated with  Representable Matroids',
	 'urllink': u'http://arxiv.org/abs/1004.0727'}
2015-03-24 11:43:39+0000 [xxu46_1] INFO: Crawled 573 pages (at 1 pages/min), scraped 567 items (at 1 items/min)
2015-03-24 11:43:46+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4585> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 11:43:46+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4585>
	{'abstract': u'The minimum spanning tree clustering algorithm is capable of detecting clusters with irregular boundaries. In this paper we propose two minimum spanning trees based clustering algorithm. The first algorithm produces k clusters with center and guaranteed intra-cluster similarity. The radius and diameter of k clusters are computed to find the tightness of k clusters. The variance of the k clusters are also computed to find the compactness of the clusters. The second algorithm is proposed to create a dendrogram using the k clusters as objects with guaranteed inter-cluster similarity. The algorithm is also finds central cluster from the k number of clusters. The first algorithm uses divisive approach, where as the second algorithm uses agglomerative approach. In this paper we used both the approaches to find Informative Meta similarity clusters.',
	 'authors': u'S. John Peter, S. P. Victor,',
	 'category': u'Computer Science ',
	 'date': '2010-5-6',
	 'pdflink': u'http://arxiv.org/pdf/1005.4585',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nA Novel Algorithm for Informative Meta Similarity Clusters Using Minimum  Spanning Tree',
	 'urllink': u'http://arxiv.org/abs/1005.4585'}
2015-03-24 11:44:39+0000 [xxu46_1] INFO: Crawled 574 pages (at 1 pages/min), scraped 568 items (at 1 items/min)
2015-03-24 11:45:20+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0485> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 11:45:20+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0485>
	{'abstract': u'We are developing electronic dictionaries and transducers for the automatic processing of the Albanian Language. We will analyze the words inside a linear segment of text. We will also study the relationship between units of sense and units of form. The composition of words takes different forms in Albanian. We have found that morphemes are frequently concatenated or simply juxtaposed or contracted. The inflected grammar of NooJ allows constructing the dictionaries of flexed forms (declensions or conjugations). The diversity of word structures requires tools to identify words created by simple concatenation, or to treat contractions. The morphological tools of NooJ allow us to create grammatical tools to represent and treat these phenomena. But certain problems exceed the morphological analysis and must be represented by syntactical grammars.',
	 'authors': u'Odile Piton, Klara Lagji,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0485',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nMorphological study of Albanian words, and processing with NooJ',
	 'urllink': u'http://arxiv.org/abs/1002.0485'}
2015-03-24 11:45:39+0000 [xxu46_1] INFO: Crawled 575 pages (at 1 pages/min), scraped 569 items (at 1 items/min)
2015-03-24 11:46:39+0000 [xxu46_1] INFO: Crawled 575 pages (at 0 pages/min), scraped 569 items (at 0 items/min)
2015-03-24 11:46:44+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0658> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 11:46:44+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0658>
	{'abstract': u'In 1975 Chaitin introduced his Omega number as a concrete example of random real. The real Omega is defined based on the set of all halting inputs for an optimal prefix-free machine U, which is a universal decoding algorithm used to define the notion of program-size complexity. Chaitin showed Omega to be random by discovering the property that the first n bits of the base-two expansion of Omega solve the halting problem of U for all binary inputs of length at most n. In this paper, we introduce a new representation Theta of Chaitin Omega number. The real Theta is defined based on the set of all compressible strings. We investigate the properties of Theta and show that Theta is random. In addition, we generalize Theta to two directions Theta(T) and bar(T) with a real T&gt;0. We then study their properties. In particular, we show that the computability of the real Theta(T) gives a sufficient condition for a real T in (0,1) to be a fixed point on partial randomness, i.e., to satisfy the condition that the compression rate of T equals to T.',
	 'authors': u'Kohtaro Tadaki,',
	 'category': u'Computer Science ',
	 'date': '2010-4-5',
	 'pdflink': u'http://arxiv.org/pdf/1004.0658',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nA new representation of Chaitin \u03a9number based on compressible  strings',
	 'urllink': u'http://arxiv.org/abs/1004.0658'}
2015-03-24 11:47:39+0000 [xxu46_1] INFO: Crawled 576 pages (at 1 pages/min), scraped 570 items (at 1 items/min)
2015-03-24 11:48:11+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4584> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 11:48:11+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4584>
	{'abstract': u"Web Based Query Management System (WBQMS) is a methodology to design and to implement Mobile Business, in which a server is the gateway to connect databases with clients which sends requests and receives responses in a distributive manner. The gateway, which communicates with mobile phone via GSM Modem, receives the coded queries from users and sends packed results back. The software which communicates with the gateway system via SHORT MESSAGE, packs users' requests, IDs and codes, and sends the package to the gateway; then interprets the packed data for the users to read on a page of GUI. Whenever and wherever they are, the customer can query the information by sending messages through the client device which may be mobile phone or PC. The mobile clients can get the appropriate services through the mobile business architecture in distributed environment. The messages are secured through the client side encoding mechanism to avoid the intruders. The gateway system is programmed by Java, while the software at clients by J2ME and the database is created by Oracle for reliable and interoperable services.",
	 'authors': u'R. Sivaraman, R.M. Chandrasekaran,',
	 'category': u'Computer Science ',
	 'date': '2010-5-6',
	 'pdflink': u'http://arxiv.org/pdf/1005.4584',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nEffective Query Retrieval System In Mobile Business Environment',
	 'urllink': u'http://arxiv.org/abs/1005.4584'}
2015-03-24 11:48:39+0000 [xxu46_1] INFO: Crawled 577 pages (at 1 pages/min), scraped 571 items (at 1 items/min)
2015-03-24 11:49:36+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0484> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 11:49:36+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0484>
	{'abstract': u'In order to make full use of geographic routing techniques developed for sensor networks, nodes must be localized. However, traditional localization and virtual localization techniques are dependent either on expensive and sometimes unavailable hardware (e.g. GPS) or on sophisticated localization calculus (e.g. triangulation) which are both error-prone and with a costly overhead. Instead of actually localizing nodes in the physical two-dimensional Euclidean space, we use directly the raw distance to a set of anchors to produce multi-dimensional coordinates. We prove that the image of the physical two-dimensional Euclidean space is a two-dimensional surface, and we show that it is possible to adapt geographic routing strategies on this surface, simply, efficiently and successfully.',
	 'authors': u'Aubin Jarry, Pierre Leone, Jose Rolim,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0484',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nVRAC: Theory #1',
	 'urllink': u'http://arxiv.org/abs/1002.0484'}
2015-03-24 11:49:39+0000 [xxu46_1] INFO: Crawled 578 pages (at 1 pages/min), scraped 572 items (at 1 items/min)
2015-03-24 11:50:39+0000 [xxu46_1] INFO: Crawled 578 pages (at 0 pages/min), scraped 572 items (at 0 items/min)
2015-03-24 11:51:01+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0653> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 11:51:01+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0653>
	{'abstract': u'We consider the links between Ramsey theory in the integers, based on van der Waerden\'s theorem, and (boolean, CNF) SAT solving. We aim at using the problems from exact Ramsey theory, concerned with computing Ramsey-type numbers, as a rich source of test problems, where especially methods for solving hard problems can be developed. In order to control the growth of the problem instances, we introduce "transversal extensions" as a natural way of constructing mixed parameter tuples (k_1, ..., k_m) for van-der-Waerden-like numbers N(k_1, ..., k_m), such that the growth of these numbers is guaranteed to be linear. Based on Green-Tao\'s theorem we introduce the "Green-Tao numbers" grt(k_1, ..., k_m), which in a sense combine the strict structure of van der Waerden problems with the (pseudo-)randomness of the distribution of prime numbers. Using standard SAT solvers (look-ahead, conflict-driven, and local search) we determine the basic values. It turns out that already for this single form of Ramsey-type problems, when considering the best-performing solvers a wide variety of solver types is covered. For m &gt; 2 the problems are non-boolean, and we introduce the "generic translation scheme", which offers an infinite variety of translations ("encodings") and covers the known methods. In most cases the special instance called "nested translation" proved to be far superior.',
	 'authors': u'Oliver Kullmann,',
	 'category': u'Computer Science ',
	 'date': '2010-4-5',
	 'pdflink': u'http://arxiv.org/pdf/1004.0653',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nExact Ramsey Theory: Green-Tao numbers and SAT',
	 'urllink': u'http://arxiv.org/abs/1004.0653'}
2015-03-24 11:51:39+0000 [xxu46_1] INFO: Crawled 579 pages (at 1 pages/min), scraped 573 items (at 1 items/min)
2015-03-24 11:52:39+0000 [xxu46_1] INFO: Crawled 579 pages (at 0 pages/min), scraped 573 items (at 0 items/min)
2015-03-24 11:52:41+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4564> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 11:52:41+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4564>
	{'abstract': u'The question of encoding movements such as those produced by human gestures may become central in the coming years, given the growing importance of movement data exchanges between heterogeneous systems and applications (musical applications, 3D motion control, virtual reality interaction, etc.). For the past 20 years, various formats have been proposed for encoding movement, especially gestures. Though, these formats, at different degrees, were designed in the context of quite specific applications (character animation, motion capture, musical gesture, biomechanical concerns...). The article introduce a new file format, called GMS (for \'Gesture and Motion Signal\'), with the aim of being more low-level and generic, by defining the minimal features a format carrying movement/gesture information needs, rather than by gathering all the information generally given by the existing formats. The article argues that, given its growing presence in virtual reality situations, the "gesture signal" itself must be encoded, and that a specific format is needed. The proposed format features the inner properties of such signals: dimensionality, structural features, types of variables, and spatial and temporal properties. The article first reviews the various situations with multisensory virtual objects in which gesture controls intervene. The proposed format is then deduced, as a mean to encode such versatile and variable "gestural and animated scene".',
	 'authors': u'Annie Luciani, Matthieu Evrard, Damien Courouss\xe9, Nicolas Castagn\xe9, Claude Cadoz, Jean-Loup Florens,',
	 'category': u'Computer Science ',
	 'date': '2010-5-25',
	 'pdflink': u'http://arxiv.org/pdf/1005.4564',
	 'subjects': u'Human-Computer Interaction (cs.HC)',
	 'title': u'\nA basic gesture and motion format for virtual reality multisensory  applications',
	 'urllink': u'http://arxiv.org/abs/1005.4564'}
2015-03-24 11:53:39+0000 [xxu46_1] INFO: Crawled 580 pages (at 1 pages/min), scraped 574 items (at 1 items/min)
2015-03-24 11:54:03+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0481> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 11:54:03+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0481>
	{'abstract': u"The recognition of Arabic Named Entities (NE) is a problem in different domains of Natural Language Processing (NLP) like automatic translation. Indeed, NE translation allows the access to multilingual in-formation. This translation doesn't always lead to expected result especially when NE contains a person name. For this reason and in order to ameliorate translation, we can transliterate some part of NE. In this context, we propose a method that integrates translation and transliteration together. We used the linguis-tic NooJ platform that is based on local grammars and transducers. In this paper, we focus on sport domain. We will firstly suggest a refinement of the typological model presented at the MUC Conferences we will describe the integration of an Arabic transliteration module into translation system. Finally, we will detail our method and give the results of the evaluation.",
	 'authors': u'Abdelmajid Ben Hamadou, Odile Piton, H\xe9la Fehri,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0481',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nRecognition and translation Arabic-French of Named Entities: case of the  Sport places',
	 'urllink': u'http://arxiv.org/abs/1002.0481'}
2015-03-24 11:54:39+0000 [xxu46_1] INFO: Crawled 581 pages (at 1 pages/min), scraped 575 items (at 1 items/min)
2015-03-24 11:55:39+0000 [xxu46_1] INFO: Crawled 581 pages (at 0 pages/min), scraped 575 items (at 0 items/min)
2015-03-24 11:55:45+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0610> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 11:55:45+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0610>
	{'abstract': u'The main result of this paper is that the isomorphism for omega-automatic trees of finite height is at least has hard as second-order arithmetic and therefore not analytical. This strengthens a recent result by Hjorth, Khoussainov, Montalban, and Nies showing that the isomorphism problem for omega-automatic structures is not . Moreover, assuming the continuum hypothesis CH, we can show that the isomorphism problem for omega-automatic trees of finite height is recursively equivalent with second-order arithmetic. On the way to our main results, we show lower and upper bounds for the isomorphism problem for omega-automatic trees of every finite height: (i) It is decidable (-complete, resp,) for height 1 (2, resp.), (ii) -hard and in for height 3, and (iii) - and -hard and in (assuming CH) for all n &gt; 3. All proofs are elementary and do not rely on theorems from set theory.',
	 'authors': u'Dietrich Kuske, Jiamou Liu, Markus Lohrey,',
	 'category': u'Computer Science ',
	 'date': '2010-4-5',
	 'pdflink': u'http://arxiv.org/pdf/1004.0610',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nThe Isomorphism Problem for omega-Automatic Trees',
	 'urllink': u'http://arxiv.org/abs/1004.0610'}
2015-03-24 11:56:39+0000 [xxu46_1] INFO: Crawled 582 pages (at 1 pages/min), scraped 576 items (at 1 items/min)
2015-03-24 11:57:11+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4563> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 11:57:11+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4563>
	{'abstract': u'This paper is focused on the question of simulation and visualiza- tion of 3D gel and paste dynamic effects. In a first part, we introduce a 3D physically based particle (or mass-interaction) model, with a small number of masses and few powerful interaction parameters, which is able to generate the dynamic features of both gels and pastes. This model proves that the 3D mass-interaction method is relevant for the simulation of such phenomena, without an explicit knowledge of their underly- ing physics. In a second part, we expose an original rendering process, the Flow Structuring Method that enhances the dynamic properties of the simulation and offers a realistic visualization. This process ignores all the properties of the underlying physical model. It leads to a reconstruction of the spatial structure of the gel (or paste) flow only through an analysis of the output of the simula- tion which is a set of unorganized points moving in a 3D space. Finally, the paper presents realistic renderings obtained by using implicit surfaces and ray-tracing techniques on the Structured Flow previously obtained.',
	 'authors': u'Claire Guilbaud, Annie Luciani, Nicolas Castagn\xe9,',
	 'category': u'Computer Science ',
	 'date': '2010-5-25',
	 'pdflink': u'http://arxiv.org/pdf/1005.4563',
	 'subjects': u'Graphics (cs.GR)',
	 'title': u'\nPhysically-based particle simulation and visualization of pastes and  gels',
	 'urllink': u'http://arxiv.org/abs/1005.4563'}
2015-03-24 11:57:39+0000 [xxu46_1] INFO: Crawled 583 pages (at 1 pages/min), scraped 577 items (at 1 items/min)
2015-03-24 11:58:39+0000 [xxu46_1] INFO: Crawled 583 pages (at 0 pages/min), scraped 577 items (at 0 items/min)
2015-03-24 11:58:47+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0479> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 11:58:47+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0479>
	{'abstract': u'If the use of the apostrophe in contemporary English often marks the Saxon genitive, it may also indicate the omission of one or more let-ters. Some writers (wrongly?) use it to mark the plural in symbols or abbreviations, visual-ised thanks to the isolation of the morpheme "s". This punctuation mark was imported from the Continent in the 16th century. During the 19th century its use was standardised. However the rules of its usage still seem problematic to many, including literate speakers of English. "All too often, the apostrophe is misplaced", or "errant apostrophes are springing up every-where" is a complaint that Internet users fre-quently come across when visiting grammar websites. Many of them detail its various uses and misuses, and attempt to correct the most common mistakes about it, especially its mis-use in the plural, called greengrocers\' apostro-phes and humorously misspelled "greengro-cers apostrophe\'s". While studying English travel accounts published in the seventeenth century, we noticed that the different uses of this symbol may accompany various models of metaplasms. We were able to highlight the linguistic variations of some lexemes, and trace the origin of modern grammar rules gov-erning its usage.',
	 'authors': u'Odile Piton, H\xe9l\xe8ne Pignot,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0479',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\n"Mind your p\'s and q\'s": or the peregrinations of an apostrophe in 17th  Century English',
	 'urllink': u'http://arxiv.org/abs/1002.0479'}
2015-03-24 11:59:39+0000 [xxu46_1] INFO: Crawled 584 pages (at 1 pages/min), scraped 578 items (at 1 items/min)
2015-03-24 12:00:13+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0605> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 12:00:13+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0605>
	{'abstract': u'We present an overview of quantum key distribution (QKD), a secure key exchange method based on the quantum laws of physics rather than computational complexity. We also provide an overview of the two most widely used commodity security protocols, IPsec and TLS. Pursuing a key exchange model, we propose how QKD could be integrated into these security applications. For such a QKD integration we propose a support layer that provides a set of common QKD services between the QKD protocol and the security applications',
	 'authors': u'Alan Mink, Sheila Frankel, Ray Perlner,',
	 'category': u'Computer Science ',
	 'date': '2010-4-5',
	 'pdflink': u'http://arxiv.org/pdf/1004.0605',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nQuantum Key Distribution (QKD) and Commodity Security Protocols:  Introduction and Integration',
	 'urllink': u'http://arxiv.org/abs/1004.0605'}
2015-03-24 12:00:39+0000 [xxu46_1] INFO: Crawled 585 pages (at 1 pages/min), scraped 579 items (at 1 items/min)
2015-03-24 12:01:26+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4552> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 12:01:26+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4552>
	{'abstract': u'Formal mathematics has so far not taken full advantage of ideas from collaborative tools such as wikis and distributed version control systems (DVCS). We argue that the field could profit from such tools, serving both newcomers and experts alike. We describe a preliminary system for such collaborative development based on the Git DVCS. We focus, initially, on the Mizar system and its library of formalized mathematics.',
	 'authors': u'Josef Urban, Jesse Alama, Piotr Rudnicki, Herman Geuvers,',
	 'category': u'Computer Science ',
	 'date': '2010-5-25',
	 'pdflink': u'http://arxiv.org/pdf/1005.4552',
	 'subjects': u'Digital Libraries (cs.DL)',
	 'title': u'\nA Wiki for Mizar: Motivation, Considerations, and Initial Prototype',
	 'urllink': u'http://arxiv.org/abs/1005.4552'}
2015-03-24 12:01:39+0000 [xxu46_1] INFO: Crawled 586 pages (at 1 pages/min), scraped 580 items (at 1 items/min)
2015-03-24 12:02:39+0000 [xxu46_1] INFO: Crawled 586 pages (at 0 pages/min), scraped 580 items (at 0 items/min)
2015-03-24 12:03:08+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0478> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 12:03:08+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0478>
	{'abstract': u"In this article, we record the main linguistic differences or singularities of 17th century English, analyse them morphologically and syntactically and propose equivalent forms in contemporary English. We show how 17th century texts may be transcribed into modern English, combining the use of electronic dictionaries with rules of transcription implemented as transducers. Apr `es avoir expos 'e la constitution du corpus, nous recensons les principales diff 'erences ou particularit 'es linguistiques de la langue anglaise du XVIIe si `ecle, les analysons du point de vue morphologique et syntaxique et proposons des 'equivalents en anglais contemporain (AC). Nous montrons comment nous pouvons effectuer une transcription automatique de textes anglais du XVIIe si `ecle en anglais moderne, en combinant l'utilisation de dictionnaires 'electroniques avec des r `egles de transcriptions impl 'ement 'ees sous forme de transducteurs.",
	 'authors': u'Odile Piton, H\xe9l\xe8ne Pignot,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0478',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u"\n\xc9tude et traitement automatique de l'anglais du XVIIe si\xe8cle :  outils morphosyntaxiques et dictionnaires",
	 'urllink': u'http://arxiv.org/abs/1002.0478'}
2015-03-24 12:03:39+0000 [xxu46_1] INFO: Crawled 587 pages (at 1 pages/min), scraped 581 items (at 1 items/min)
2015-03-24 12:04:39+0000 [xxu46_1] INFO: Crawled 587 pages (at 0 pages/min), scraped 581 items (at 0 items/min)
2015-03-24 12:04:53+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0604> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 12:04:53+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0604>
	{'abstract': u'Computer System Administration and Network Administration are few such areas where Practical Extraction Reporting Language (Perl) has robust utilization these days apart from Bioinformatics. The key role of a System/Network Administrator is to monitor log files. Log file are updated every day. To scan the summary of large log files and to quickly determine if there is anything wrong with the server or network we develop a Firewall Log Status Reporter (SRr). SRr helps to generate the reports based on the parameters of interest. SRr provides the facility to admin to generate the individual firewall report or all reports in one go. By scrutinizing the results of the reports admin can trace how many times a particular request has been made from which source to which destination and can track the errors easily. Perl scripts can be seen as the UNIX script replacement in future arena and SRr is one development with the same hope that we can believe in. SRr is a generalized and customizable utility completely written in Perl and may be used for text mining and data mining application in Bioinformatics research and development too.',
	 'authors': u'Sugam Sharma, Hari Cohly, Tzusheng Pei,',
	 'category': u'Computer Science ',
	 'date': '2010-4-5',
	 'pdflink': u'http://arxiv.org/pdf/1004.0604',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nOn Generation of Firewall Log Status Reporter (SRr) Using Perl',
	 'urllink': u'http://arxiv.org/abs/1004.0604'}
2015-03-24 12:05:39+0000 [xxu46_1] INFO: Crawled 588 pages (at 1 pages/min), scraped 582 items (at 1 items/min)
2015-03-24 12:06:35+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4540> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 12:06:35+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4540>
	{'abstract': u'We conduct a computational analysis of fair and optimal partitions in additively separable hedonic games. We show that, for strict preferences, a Pareto optimal partition can be found in polynomial time while verifying whether a given partition is Pareto optimal is coNP-complete, even when preferences are symmetric and strict. Moreover, computing a partition with maximum egalitarian or utilitarian social welfare or one which is both Pareto optimal and individually rational is NP-hard. We also prove that checking whether there exists a partition which is both Pareto optimal and envy-free is -complete. Even though an envy-free partition and a Nash stable partition are both guaranteed to exist for symmetric preferences, checking whether there exists a partition which is both envy-free and Nash stable is NP-complete.',
	 'authors': u'Haris Aziz, Felix Brandt, Hans Georg Seedig,',
	 'category': u'Computer Science ',
	 'date': '2010-5-25',
	 'pdflink': u'http://arxiv.org/pdf/1005.4540',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nOptimal Partitions in Additively Separable Hedonic Games',
	 'urllink': u'http://arxiv.org/abs/1005.4540'}
2015-03-24 12:06:39+0000 [xxu46_1] INFO: Crawled 589 pages (at 1 pages/min), scraped 583 items (at 1 items/min)
2015-03-24 12:07:36+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0449> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 12:07:36+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0449>
	{'abstract': u'To study the communication between information systems, Wang et al. [C. Wang, C. Wu, D. Chen, Q. Hu, and C. Wu, Communicating between information systems, Information Sciences 178 (2008) 3228-3239] proposed two concepts of type-1 and type-2 consistent functions. Some properties of such functions and induced relation mappings have been investigated there. In this paper, we provide an improvement of the aforementioned work by disclosing the symmetric relationship between type-1 and type-2 consistent functions. We present more properties of consistent functions and induced relation mappings and improve upon several deficient assertions in the original work. In particular, we unify and extend type-1 and type-2 consistent functions into the so-called neighborhood-consistent functions. This provides a convenient means for studying the communication between information systems based on various neighborhoods.',
	 'authors': u'Ping Zhu, Qiaoyan Wen,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0449',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nSome improved results on communication between information systems',
	 'urllink': u'http://arxiv.org/abs/1002.0449'}
2015-03-24 12:07:39+0000 [xxu46_1] INFO: Crawled 590 pages (at 1 pages/min), scraped 584 items (at 1 items/min)
2015-03-24 12:08:39+0000 [xxu46_1] INFO: Crawled 590 pages (at 0 pages/min), scraped 584 items (at 0 items/min)
2015-03-24 12:09:03+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0602> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 12:09:03+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0602>
	{'abstract': u'An intrusion detection system framework using mobile agents is a layered framework mechanism designed to support heterogeneous network environments to identify intruders at its best. Traditional computer misuse detection techniques can identify known attacks efficiently, but perform very poorly in other cases. Anomaly detection has the potential to detect unknown attacks; however, it is a very challenging task since its aim is to detect unknown attacks without any priori knowledge about specific intrusions. This technology is still at its early stage. The objective of this paper is that the system can detect anomalous user activity. Existing research in this area focuses either on user activity or on program operation but not on both simultaneously. In this paper, an attempt to look at both concurrently is presented. Based on an intrusion detection framework [1], a novel user anomaly detection system has been implemented and conducted several intrusion detection experiments in a simulated environment by analyzing user activity and program operation activities. The proposed framework is a layered framework, which is designed to satisfy the core purpose of IDS, and allows detecting the intrusion as quickly as possible with available data using mobile agents. This framework was mainly designed to provide security for the network using mobile agent mechanisms to add mobility features to monitor the user processes from different computational systems. The experimental results have shown that the system can detect anomalous user activity effectively.',
	 'authors': u'N.Jaisankar, R.Saravanan, K. Durai Swamy,',
	 'category': u'Computer Science ',
	 'date': '2010-4-5',
	 'pdflink': u'http://arxiv.org/pdf/1004.0602',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nIntelligent Detection System framework using Mobile agents',
	 'urllink': u'http://arxiv.org/abs/1004.0602'}
2015-03-24 12:09:39+0000 [xxu46_1] INFO: Crawled 591 pages (at 1 pages/min), scraped 585 items (at 1 items/min)
2015-03-24 12:10:39+0000 [xxu46_1] INFO: Crawled 591 pages (at 0 pages/min), scraped 585 items (at 0 items/min)
2015-03-24 12:10:41+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4525> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 12:10:41+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4525>
	{'abstract': u'Today, reusable components are available in several repositorys. These are certainly conceived for re-use. However, this re-use is not immediate, it requires, in effect, to pass by some essential conceptual operations, among which in particular, research, integration, adaptation, and composition. We are interested in the present work to the problem of semantic integration of heterogeneous Business Components. This problem is often put in syntactical terms, while the real stake is of semantic order. Our contribution concerns an architecture proposal for Business components integration and a resolution method of semantic naming conflicts, met during the integration of Business Components',
	 'authors': u'Hicham Elasri, Larbi Kzaz, Abderrahim Sekkaki,',
	 'category': u'Computer Science ',
	 'date': '2010-5-25',
	 'pdflink': u'http://arxiv.org/pdf/1005.4525',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nTowards an architecture for semantic integration of business components',
	 'urllink': u'http://arxiv.org/abs/1005.4525'}
2015-03-24 12:11:39+0000 [xxu46_1] INFO: Crawled 592 pages (at 1 pages/min), scraped 586 items (at 1 items/min)
2015-03-24 12:12:25+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0432> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 12:12:25+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0432>
	{'abstract': u"The search for patterns or motifs in data represents an area of key interest to many researchers. In this paper we present the Motif Tracking Algorithm, a novel immune inspired pattern identification tool that is able to identify unknown motifs which repeat within time series data. The power of the algorithm is derived from its use of a small number of parameters with minimal assumptions. The algorithm searches from a completely neutral perspective that is independent of the data being analysed, and the underlying motifs. In this paper the motif tracking algorithm is applied to the search for patterns within sequences of low level system calls between the Linux kernel and the operating system's user space. The MTA is able to compress data found in large system call data sets to a limited number of motifs which summarise that data. The motifs provide a resource from which a profile of executed processes can be built. The potential for these profiles and new implications for security research are highlighted. A higher level call system language for measuring similarity between patterns of such calls is also suggested.",
	 'authors': u'William O. Wilson, Jan Feyereisl, Uwe Aickelin,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0432',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nDetecting Motifs in System Call Sequences',
	 'urllink': u'http://arxiv.org/abs/1002.0432'}
2015-03-24 12:12:39+0000 [xxu46_1] INFO: Crawled 593 pages (at 1 pages/min), scraped 587 items (at 1 items/min)
2015-03-24 12:13:39+0000 [xxu46_1] INFO: Crawled 593 pages (at 0 pages/min), scraped 587 items (at 0 items/min)
2015-03-24 12:14:03+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0599> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 12:14:03+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0599>
	{'abstract': u'This letter proposes a novel key distribution protocol with no key exchange in advance, which is secure as the BB84 quantum key distribution protocol. Our protocol utilizes a photon in superposition state for single-bit data transmission instead of a classical electrical/optical signal. The security of this protocol relies on the fact, that the arbitrary quantum state cannot be cloned, known as the no-cloning theorem. This protocol can be implemented with current technologies.',
	 'authors': u'Yoshito Kanamori, Seong-Moo Yoo,',
	 'category': u'Computer Science ',
	 'date': '2010-4-5',
	 'pdflink': u'http://arxiv.org/pdf/1004.0599',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nQuantum Three-Pass protocol: Key distribution using quantum  superposition states',
	 'urllink': u'http://arxiv.org/abs/1004.0599'}
2015-03-24 12:14:39+0000 [xxu46_1] INFO: Crawled 594 pages (at 1 pages/min), scraped 588 items (at 1 items/min)
2015-03-24 12:15:26+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4518> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 12:15:26+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4518>
	{'abstract': u'The problem of estimating the proportion of satisfiable instances of a given CSP (constraint satisfaction problem) can be tackled through weighting. It consists in putting onto each solution a non-negative real value based on its neighborhood in a way that the total weight is at least 1 for each satisfiable instance. We define in this paper a general weighting scheme for the estimation of satisfiability of general CSPs. First we give some sufficient conditions for a weighting system to be correct. Then we show that this scheme allows for an improvement on the upper bound on the existence of non-trivial cores in 3-SAT obtained by Maneva and Sinclair (2008) to 4.419. Another more common way of estimating satisfiability is ordering. This consists in putting a total order on the domain, which induces an orientation between neighboring solutions in a way that prevents circuits from appearing, and then counting only minimal elements. We compare ordering and weighting under various conditions.',
	 'authors': u'Yacine Boufkhad, Thomas Hugel,',
	 'category': u'Computer Science ',
	 'date': '2010-5-25',
	 'pdflink': u'http://arxiv.org/pdf/1005.4518',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nEstimating Satisfiability',
	 'urllink': u'http://arxiv.org/abs/1005.4518'}
2015-03-24 12:15:39+0000 [xxu46_1] INFO: Crawled 595 pages (at 1 pages/min), scraped 589 items (at 1 items/min)
2015-03-24 12:16:39+0000 [xxu46_1] INFO: Crawled 595 pages (at 0 pages/min), scraped 589 items (at 0 items/min)
2015-03-24 12:16:40+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0424> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 12:16:40+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0424>
	{'abstract': u'Interference alignment is a transmission technique for exploiting all available degrees of freedom in the interference channel with an arbitrary number of users. Most prior work on interference alignment, however, neglects interference from other nodes in the network not participating in the alignment operation. This paper proposes three generalizations of interference alignment for the multiple-antenna interference channel with multiple users that account for colored noise, which models uncoordinated interference. First, a minimum interference-plus-noise leakage algorithm is presented, and shown to be equivalent to previous subspace methods when noise is spatially white or negligible. A joint minimum mean squared error design is then proposed that jointly optimizes the transmit precoders and receive spatial filters, whereas previous designs neglect the receive spatial filter. This algorithm is shown to be a generalization of previous joint MMSE designs for other system configurations such as the broadcast channel. Finally, a maximum signal-to-interference-plus-noise ratio algorithm is developed that is proven to converge, unlike previous maximum SINR algorithms. The latter two designs are shown to have increased complexity due to non-orthogonal precoders, more required iterations, or more channel state knowledge than the min INL or subspace methods. The sum throughput performance of these algorithms is simulated in the context of a network with uncoordinated co-channel interferers not participating in the alignment protocol. It is found that a network with cochannel interference can benefit from employing precoders designed to consider that interference, but in some cases, ignoring the co-channel interference is advantageous.',
	 'authors': u'Steven W. Peters, Robert W. Heath Jr,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0424',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nCooperative Algorithms for MIMO Interference Channels',
	 'urllink': u'http://arxiv.org/abs/1002.0424'}
2015-03-24 12:17:39+0000 [xxu46_1] INFO: Crawled 596 pages (at 1 pages/min), scraped 590 items (at 1 items/min)
2015-03-24 12:17:50+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0598> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 12:17:50+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0598>
	{'abstract': u'Many papers have been proposed in order to increase the wireless sensor networks performance; This kind of network has limited resources, where the energy in each sensor came from a small battery that sometime is hard to be replaced or recharged. Transmission energy is the most concern part where the higher energy consumption takes place. Clustered hierarchy has been proposed in many papers; in most cases, it provides the network with better performance than other protocols. In our paper, first we discuss some of techniques, relates to this protocol, that have been proposed for energy efficiency; some of them were proposed to provide the network with more security level. Our proposal then suggests some modifications to some of these techniques to provide the network with more energy saving that should lead to high performance; also we apply our technique on an existing one that proposed to increase the security level of cluster sensor networks.',
	 'authors': u'Mohammed Abuhelaleh, Khaled Elleithy, Thabet Mismar,',
	 'category': u'Computer Science ',
	 'date': '2010-4-5',
	 'pdflink': u'http://arxiv.org/pdf/1004.0598',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nClustered Hierarchy in Sensor Networks: Performance and Security',
	 'urllink': u'http://arxiv.org/abs/1004.0598'}
2015-03-24 12:18:39+0000 [xxu46_1] INFO: Crawled 597 pages (at 1 pages/min), scraped 591 items (at 1 items/min)
2015-03-24 12:19:16+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4508> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 12:19:16+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4508>
	{'abstract': u'We consider the problem of intruder deduction in security protocol analysis: that is, deciding whether a given message M can be deduced from a set of messages Gamma under the theory of blind signatures and arbitrary convergent equational theories modulo associativity and commutativity (AC) of certain binary operators. The traditional formulations of intruder deduction are usually given in natural-deduction-like systems and proving decidability requires significant effort in showing that the rules are "local" in some sense. By using the well-known translation between natural deduction and sequent calculus, we recast the intruder deduction problem as proof search in sequent calculus, in which locality is immediate. Using standard proof theoretic methods, such as permutability of rules and cut elimination, we show that the intruder deduction problem can be reduced, in polynomial time, to the elementary deduction problem, which amounts to solving certain equations in the underlying individual equational theories. We show that this result extends to combinations of disjoint AC-convergent theories whereby the decidability of intruder deduction under the combined theory reduces to the decidability of elementary deduction in each constituent theory. To further demonstrate the utility of the sequent-based approach, we show that, for Dolev-Yao intruders, our sequent-based techniques can be used to solve the more difficult problem of solving deducibility constraints, where the sequents to be deduced may contain gaps (or variables) representing possible messages the intruder may produce.',
	 'authors': u'Alwen F Tiu, Rajeev Gore, Jeremy Dawson,',
	 'category': u'Computer Science ',
	 'date': '2010-5-25',
	 'pdflink': u'http://arxiv.org/pdf/1005.4508',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nA Proof Theoretic Analysis of Intruder Theories',
	 'urllink': u'http://arxiv.org/abs/1005.4508'}
2015-03-24 12:19:39+0000 [xxu46_1] INFO: Crawled 598 pages (at 1 pages/min), scraped 592 items (at 1 items/min)
2015-03-24 12:20:39+0000 [xxu46_1] INFO: Crawled 598 pages (at 0 pages/min), scraped 592 items (at 0 items/min)
2015-03-24 12:20:59+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0416> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 12:20:59+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0416>
	{'abstract': u'This paper uses Support Vector Machines (SVM) to fuse multiple classifiers for an offline signature system. From the signature images, global and local features are extracted and the signatures are verified with the help of Gaussian empirical rule, Euclidean and Mahalanobis distance based classifiers. SVM is used to fuse matching scores of these matchers. Finally, recognition of query signatures is done by comparing it with all signatures of the database. The proposed system is tested on a signature database contains 5400 offline signatures of 600 individuals and the results are found to be promising.',
	 'authors': u'Dakshina Ranjan Kisku, Phalguni Gupta, Jamuna Kanta Sing,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0416',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nFusion of Multiple Matchers using SVM for Offline Signature  Identification',
	 'urllink': u'http://arxiv.org/abs/1002.0416'}
2015-03-24 12:21:39+0000 [xxu46_1] INFO: Crawled 599 pages (at 1 pages/min), scraped 593 items (at 1 items/min)
2015-03-24 12:22:16+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0596> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 12:22:16+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0596>
	{'abstract': u'As the explosive growth of the ISM band usage continues, there are many scenarios where different systems operate in the same place at the same time. One of growing concerns is the coexistence of heterogeneous wireless network systems. For the successful deployment of mission-critical systems such as wireless sensor networks, it is required to provide a solution for the coexistence. In this paper, we propose a new scheme using inter packet delay for the coexistence of IEEE 802.15.4 LRWPAN and IEEE 802.11b WLAN. To evaluate the effectiveness of the proposed scheme, measurement and simulation study are conducted using Qualnet 4.5 simulation software. The simulation results show that the proposed scheme is effective in performance improvement for coexistence network of IEEE 802.15.4 for various topologies.',
	 'authors': u'G.M.Tamilselvan, A.Shanmugam,',
	 'category': u'Computer Science ',
	 'date': '2010-4-5',
	 'pdflink': u'http://arxiv.org/pdf/1004.0596',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nEffect of Inter Packet Delay in performance analysis of coexistence  heterogeneous Wireless Packet Networks',
	 'urllink': u'http://arxiv.org/abs/1004.0596'}
2015-03-24 12:22:39+0000 [xxu46_1] INFO: Crawled 600 pages (at 1 pages/min), scraped 594 items (at 1 items/min)
2015-03-24 12:23:27+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4505> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 12:23:27+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4505>
	{'abstract': u'Mobile Ad hoc NETworks (MANETs) are leaving the confines of research laboratories, to find place in real-world deployments. Outside specialized domains (military, vehicular, etc.), city-wide communitynetworks are emerging, connecting regular Internet users with each other, and with the Internet, via MANETs. Growing to encompass more than a handful of "trusted participants", the question of preserving the MANET network connectivity, even when faced with careless or malicious participants, arises, and must be addressed. A first step towards protecting a MANET is to analyze the vulnerabilities of the routing protocol, managing the connectivity. By understanding how the algorithms of the routing protocol operate, and how these can be exploited by those with ill intent, countermeasures can be developed, readying MANETs for wider deployment and use. This paper takes an abstract look at the algorithms that constitute the Optimized Link State Routing Protocol version 2 (OLSRv2), and identifies for each protocol element the possible vulnerabilities and attacks -- in a certain way, provides a "cookbook" for how to best attack an operational OLSRv2 network, or for how to proceed with developing protective countermeasures against these attacks.',
	 'authors': u'Ulrich Herberg, Thomas Clausen,',
	 'category': u'Computer Science ',
	 'date': '2010-5-25',
	 'pdflink': u'http://arxiv.org/pdf/1005.4505',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nSecurity Issues in the Optimized Link State Routing Protocol Version 2  (OLSRV2)',
	 'urllink': u'http://arxiv.org/abs/1005.4505'}
2015-03-24 12:23:39+0000 [xxu46_1] INFO: Crawled 601 pages (at 1 pages/min), scraped 595 items (at 1 items/min)
2015-03-24 12:24:11+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0414> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 12:24:11+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0414>
	{'abstract': u'This paper presents a multimodal biometric system of fingerprint and ear biometrics. Scale Invariant Feature Transform (SIFT) descriptor based feature sets extracted from fingerprint and ear are fused. The fused set is encoded by K-medoids partitioning approach with less number of feature points in the set. K-medoids partition the whole dataset into clusters to minimize the error between data points belonging to the clusters and its center. Reduced feature set is used to match between two biometric sets. Matching scores are generated using wolf-lamb user-dependent feature weighting scheme introduced by Doddington. The technique is tested to exhibit its robust performance.',
	 'authors': u'Dakshina Ranjan Kisku, Phalguni Gupta, Jamuna Kanta Sing,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0414',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nFeature Level Fusion of Biometrics Cues: Human Identification with  Doddingtons Caricature',
	 'urllink': u'http://arxiv.org/abs/1002.0414'}
2015-03-24 12:24:39+0000 [xxu46_1] INFO: Crawled 602 pages (at 1 pages/min), scraped 596 items (at 1 items/min)
2015-03-24 12:25:39+0000 [xxu46_1] INFO: Crawled 602 pages (at 0 pages/min), scraped 596 items (at 0 items/min)
2015-03-24 12:25:54+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0594> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 12:25:54+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0594>
	{'abstract': u'Intrusion Detection &amp; Prevention Systems generally aims at detecting / preventing attacks against Information systems and networks. The basic task of IDPS is to monitor network &amp; system traffic for any malicious packets/patterns and hence to prevent any unwarranted incidents which leads the systems to insecure state. The monitoring is done by checking each packet for its validity against the signatures formulated for identified vulnerabilities. Since, signatures are the heart &amp; soul of an Intrusion Detection and Prevention System (IDPS), we, in this paper, discuss two methodologies we adapted in our research effort to improve the current Intrusion Detection and Prevention (IDP) systems. The first methodology RUDRAA is for formulating, verifying &amp; validating the potential signatures to be used with IDPS. The second methodology DSP-FED is aimed at processing the signatures in less time with our proposed fast elimination method using DFA. The research objectives of this project are 1) To formulate &amp; process potential IPS signatures to be used with Intrusion prevention system. 2) To propose a DFA based approach for signature processing which, upon a pattern match, could process the signatures faster else could eliminate it efficiently if not matched',
	 'authors': u'Mohammed Misbahuddin, Sachin Narayanan, Bishwa Ranjan Ghosh,',
	 'category': u'Computer Science ',
	 'date': '2010-4-5',
	 'pdflink': u'http://arxiv.org/pdf/1004.0594',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nDynamic IDP Signature processing by fast elimination using DFA',
	 'urllink': u'http://arxiv.org/abs/1004.0594'}
2015-03-24 12:26:39+0000 [xxu46_1] INFO: Crawled 603 pages (at 1 pages/min), scraped 597 items (at 1 items/min)
2015-03-24 12:27:08+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4504> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 12:27:08+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4504>
	{'abstract': u'Quantum Cryptography or Quantum key distribution (QKD) is a technique that allows the secure distribution of a bit string, used as key in cryptographic protocols. When it was noted that quantum computers could break public key cryptosystems based on number theory extensive studies have been undertaken on QKD. Based on quantum mechanics, QKD offers unconditionally secure communication. Now, the progress of research in this field allows the anticipation of QKD to be available outside of laboratories within the next few years. Efforts are made to improve the performance and reliability of the implemented technologies. But several challenges remain despite this big progress. The task of how to test the apparatuses of QKD For example did not yet receive enough attention. These devises become complex and demand a big verification effort. In this paper we are interested in an approach based on the technique of probabilistic model checking for studying quantum information. Precisely, we use the PRISM tool to analyze the security of BB84 protocol and we are focused on the specific security property of eavesdropping detection. We show that this property is affected by the parameters of quantum channel and the power of eavesdropper.',
	 'authors': u'Mohamed Elboukhari, Mostafa Azizi, Abdelmalek Azizi,',
	 'category': u'Computer Science ',
	 'date': '2010-5-25',
	 'pdflink': u'http://arxiv.org/pdf/1005.4504',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nAnalysis of the Security of BB84 by Model Checking',
	 'urllink': u'http://arxiv.org/abs/1005.4504'}
2015-03-24 12:27:39+0000 [xxu46_1] INFO: Crawled 604 pages (at 1 pages/min), scraped 598 items (at 1 items/min)
2015-03-24 12:28:38+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0412> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 12:28:38+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0412>
	{'abstract': u'Ear biometric is considered as one of the most reliable and invariant biometrics characteristics in line with iris and fingerprint characteristics. In many cases, ear biometrics can be compared with face biometrics regarding many physiological and texture characteristics. In this paper, a robust and efficient ear recognition system is presented, which uses Scale Invariant Feature Transform (SIFT) as feature descriptor for structural representation of ear images. In order to make it more robust to user authentication, only the regions having color probabilities in a certain ranges are considered for invariant SIFT feature extraction, where the K-L divergence is used for keeping color consistency. Ear skin color model is formed by Gaussian mixture model and clustering the ear color pattern using vector quantization. Finally, K-L divergence is applied to the GMM framework for recording the color similarity in the specified ranges by comparing color similarity between a pair of reference model and probe ear images. After segmentation of ear images in some color slice regions, SIFT keypoints are extracted and an augmented vector of extracted SIFT features are created for matching, which is accomplished between a pair of reference model and probe ear images. The proposed technique has been tested on the IITK Ear database and the experimental results show improvements in recognition accuracy while invariant features are extracted from color slice regions to maintain the robustness of the system.',
	 'authors': u'Dakshina Ranjan Kisku, Hunny Mehrotra, Phalguni Gupta, Jamuna Kanta Sing,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0412',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nSIFT-based Ear Recognition by Fusion of Detected Keypoints from Color  Similarity Slice Regions',
	 'urllink': u'http://arxiv.org/abs/1002.0412'}
2015-03-24 12:28:39+0000 [xxu46_1] INFO: Crawled 605 pages (at 1 pages/min), scraped 599 items (at 1 items/min)
2015-03-24 12:29:39+0000 [xxu46_1] INFO: Crawled 605 pages (at 0 pages/min), scraped 599 items (at 0 items/min)
2015-03-24 12:30:08+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0591> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 12:30:08+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0591>
	{'abstract': u'Traditional key management techniques, such as public key cryptography or key distribution center (e.g., Kerberos), are often not effective for wireless sensor networks for the serious limitations in terms of computational power, energy supply, network bandwidth. In order to balance the security and efficiency, we propose a new scheme by employing LU Composition techniques for mutual authenticated pairwise key establishment and integrating LU Matrix with Elliptic Curve Diffie-Hellman for anonymous pathkey establishment. At the meantime, it is able to achieve efficient group key agreement and management. Analysis shows that the new scheme has better performance and provides authenticity and anonymity for sensor to establish multiple kinds of keys, compared with previous related works.',
	 'authors': u'Eric Ke Wang, Lucas C.K.Hui, S.M.Yiu,',
	 'category': u'Computer Science ',
	 'date': '2010-4-5',
	 'pdflink': u'http://arxiv.org/pdf/1004.0591',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nA new key establishment scheme for wireless sensor networks',
	 'urllink': u'http://arxiv.org/abs/1004.0591'}
2015-03-24 12:30:39+0000 [xxu46_1] INFO: Crawled 606 pages (at 1 pages/min), scraped 600 items (at 1 items/min)
2015-03-24 12:31:39+0000 [xxu46_1] INFO: Crawled 606 pages (at 0 pages/min), scraped 600 items (at 0 items/min)
2015-03-24 12:31:45+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4501> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 12:31:45+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4501>
	{'abstract': u"The objective of this is to develop a Fuzzy aided Application layer Semantic Intrusion Detection System (FASIDS) which works in the application layer of the network stack. FASIDS consist of semantic IDS and Fuzzy based IDS. Rule based IDS looks for the specific pattern which is defined as malicious. A non-intrusive regular pattern can be malicious if it occurs several times with a short time interval. For detecting such malicious activities, FASIDS is proposed in this paper. At application layer, HTTP traffic's header and payload are analyzed for possible intrusion. In the proposed misuse detection module, the semantic intrusion detection system works on the basis of rules that define various application layer misuses that are found in the network. An attack identified by the IDS is based on a corresponding rule in the rule-base. An event that doesn't make a 'hit' on the rule-base is given to a Fuzzy Intrusion Detection System (FIDS) for further analysis.",
	 'authors': u'S.Sangeetha, V.Vaidehi,',
	 'category': u'Computer Science ',
	 'date': '2010-5-25',
	 'pdflink': u'http://arxiv.org/pdf/1005.4501',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nFuzzy Aided Application Layer Semantic Intrusion Detection System -  FASIDS',
	 'urllink': u'http://arxiv.org/abs/1005.4501'}
2015-03-24 12:32:39+0000 [xxu46_1] INFO: Crawled 607 pages (at 1 pages/min), scraped 601 items (at 1 items/min)
2015-03-24 12:33:09+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0411> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 12:33:09+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0411>
	{'abstract': u'This paper presents a new face identification system based on Graph Matching Technique on SIFT features extracted from face images. Although SIFT features have been successfully used for general object detection and recognition, only recently they were applied to face recognition. This paper further investigates the performance of identification techniques based on Graph matching topology drawn on SIFT features which are invariant to rotation, scaling and translation. Face projections on images, represented by a graph, can be matched onto new images by maximizing a similarity function taking into account spatial distortions and the similarities of the local features. Two graph based matching techniques have been investigated to deal with false pair assignment and reducing the number of features to find the optimal feature set between database and query face SIFT features. The experimental results, performed on the BANCA database, demonstrate the effectiveness of the proposed system for automatic face identification.',
	 'authors': u'Dakshina Ranjan Kisku, Ajita Rattani, Enrico Grosso, Massimo Tistarelli,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0411',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nFace Identification by SIFT-based Complete Graph Topology',
	 'urllink': u'http://arxiv.org/abs/1002.0411'}
2015-03-24 12:33:39+0000 [xxu46_1] INFO: Crawled 608 pages (at 1 pages/min), scraped 602 items (at 1 items/min)
2015-03-24 12:34:39+0000 [xxu46_1] INFO: Crawled 608 pages (at 0 pages/min), scraped 602 items (at 0 items/min)
2015-03-24 12:34:48+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0590> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 12:34:48+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0590>
	{'abstract': u'Cryptographic check values (digital signatures, MACs and H-MACs) are useful only if they are free of errors. For that reason all of errors in cryptographic check values should be corrected after the transmission over a noisy channel before their verification is performed. Soft Input Decryption is a method of combining SISO convolutional decoding and decrypting of cryptographic check values to improve the correction of errors in themselves. If Soft Input Decryption is successful, i.e. all wrong bit of a cryptographic check value are corrected, these bit are sent as feedback information to the channel decoder for a next iteration. The bit of the next iteration are corrected by channel decoding followed by another Soft Input Decryption. Iterative Soft Input Decryption uses interleaved blocks. If one block can be corrected by Soft Input Decryption, the decoding of the interleaved block is improved (serial scheme). If Soft Input Decryption is applied on both blocks and one of the blocks can be corrected, the corrected block is used for an improved decoding of the other block (parallel scheme). Both schemes show significant coding gains compared to convolutional decoding without iterative Soft Input Decryption.',
	 'authors': u'Natasa Zivic,',
	 'category': u'Computer Science ',
	 'date': '2010-4-5',
	 'pdflink': u'http://arxiv.org/pdf/1004.0590',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nIterative method for improvement of coding and decryption',
	 'urllink': u'http://arxiv.org/abs/1004.0590'}
2015-03-24 12:35:39+0000 [xxu46_1] INFO: Crawled 609 pages (at 1 pages/min), scraped 603 items (at 1 items/min)
2015-03-24 12:36:32+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4499> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 12:36:32+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4499>
	{'abstract': u'Radio Frequency Identification (RFID) technology one of the most promising technologies in the field of ubiquitous computing. Indeed, RFID technology may well replace barcode technology. Although it offers many advantages over other identification systems, there are also associated security risks that are not easy to be addressed. When designing a real lightweight authentication protocol for low cost RFID tags, a number of challenges arise due to the extremely limited computational, storage and communication abilities of Low-cost RFID tags. This paper proposes a real mutual authentication protocol for low cost RFID tags. The proposed protocol prevents passive attacks as active attacks are discounted when designing a protocol to meet the requirements of low cost RFID tags. However the implementation of the protocol meets the limited abilities of low cost RFID tags.',
	 'authors': u'Eslam Gamal Ahmed, Eman Shaaban, Mohamed Hashem,',
	 'category': u'Computer Science ',
	 'date': '2010-5-25',
	 'pdflink': u'http://arxiv.org/pdf/1005.4499',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nLightweight Mutual Authentication Protocol for Low Cost RFID Tags',
	 'urllink': u'http://arxiv.org/abs/1005.4499'}
2015-03-24 12:36:39+0000 [xxu46_1] INFO: Crawled 610 pages (at 1 pages/min), scraped 604 items (at 1 items/min)
2015-03-24 12:37:39+0000 [xxu46_1] INFO: Crawled 610 pages (at 0 pages/min), scraped 604 items (at 0 items/min)
2015-03-24 12:37:57+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0406> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 12:37:57+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0406>
	{'abstract': u'Physical transceiver implementations for multiple-input multiple-output (MIMO) wireless communication systems suffer from transmit-RF (Tx-RF) impairments. In this paper, we study the effect on channel capacity and error-rate performance of residual Tx-RF impairments that defy proper compensation. In particular, we demonstrate that such residual distortions severely degrade the performance of (near-)optimum MIMO detection algorithms. To mitigate this performance loss, we propose an efficient algorithm, which is based on an i.i.d. Gaussian model for the distortion caused by these impairments. In order to validate this model, we provide measurement results based on a 4-stream Tx-RF chain implementation for MIMO orthogonal frequency-division multiplexing (OFDM).',
	 'authors': u'Christoph Studer, Markus Wenk, Andreas Burg,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0406',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nMIMO Transmission with Residual Transmit-RF Impairments',
	 'urllink': u'http://arxiv.org/abs/1002.0406'}
2015-03-24 12:38:39+0000 [xxu46_1] INFO: Crawled 611 pages (at 1 pages/min), scraped 605 items (at 1 items/min)
2015-03-24 12:39:27+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0587> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 12:39:27+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0587>
	{'abstract': u"In multi-hop wireless systems, the need for cooperation among nodes to relay each other's packets exposes them to a wide range of security attacks. A particularly devastating attack is the wormhole attack, where a malicious node records control traffic at one location and tunnels it to another compromised node, possibly far away, which replays it locally. Routing security in ad hoc networks is often equated with strong and feasible node authentication and lightweight cryptography. Unfortunately, the wormhole attack can hardly be defeated by crypto graphical measures, as wormhole attackers do not create separate packets. They simply replay packets already existing on the network, which pass the cryptographic checks. Existing works on wormhole detection have often focused on detection using specialized hardware, such as directional antennas, etc. In this paper, we present a cluster based counter-measure for the wormhole attack, that alleviates these drawbacks and efficiently mitigates the wormhole attack in MANET. Simulation results on MATLab exhibit the effectiveness of the proposed algorithm in detecting wormhole attacks.",
	 'authors': u'Debdutta Barman Roy, Rituparna Chaki, Nabendu Chaki,',
	 'category': u'Computer Science ',
	 'date': '2010-4-5',
	 'pdflink': u'http://arxiv.org/pdf/1004.0587',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nA New Cluster-based Wormhole Intrusion detection algorithm for Mobile  Ad-Hoc Networks',
	 'urllink': u'http://arxiv.org/abs/1004.0587'}
2015-03-24 12:39:39+0000 [xxu46_1] INFO: Crawled 612 pages (at 1 pages/min), scraped 606 items (at 1 items/min)
2015-03-24 12:40:38+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4496> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 12:40:38+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4496>
	{'abstract': u'In this paper, a new learning algorithm for adaptive network intrusion detection using naive Bayesian classifier and decision tree is presented, which performs balance detections and keeps false positives at acceptable level for different types of network attacks, and eliminates redundant attributes as well as contradictory examples from training data that make the detection model complex. The proposed algorithm also addresses some difficulties of data mining such as handling continuous attribute, dealing with missing attribute values, and reducing noise in training data. Due to the large volumes of security audit data as well as the complex and dynamic properties of intrusion behaviours, several data miningbased intrusion detection techniques have been applied to network-based traffic data and host-based data in the last decades. However, there remain various issues needed to be examined towards current intrusion detection systems (IDS). We tested the performance of our proposed algorithm with existing learning algorithms by employing on the KDD99 benchmark intrusion detection dataset. The experimental results prove that the proposed algorithm achieved high detection rates (DR) and significant reduce false positives (FP) for different types of network intrusions using limited computational resources.',
	 'authors': u'Dewan Md. Farid, Nouria Harbi, Mohammad Zahidur Rahman,',
	 'category': u'Computer Science ',
	 'date': '2010-5-25',
	 'pdflink': u'http://arxiv.org/pdf/1005.4496',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nCombining Naive Bayes and Decision Tree for Adaptive Intrusion Detection',
	 'urllink': u'http://arxiv.org/abs/1005.4496'}
2015-03-24 12:40:39+0000 [xxu46_1] INFO: Crawled 613 pages (at 1 pages/min), scraped 607 items (at 1 items/min)
2015-03-24 12:41:39+0000 [xxu46_1] INFO: Crawled 613 pages (at 0 pages/min), scraped 607 items (at 0 items/min)
2015-03-24 12:42:21+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0383> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 12:42:21+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0383>
	{'abstract': u'This paper proposes an efficient technique for partitioning large biometric database during identification. In this technique feature vector which comprises of global and local descriptors extracted from offline signature are used by fuzzy clustering technique to partition the database. As biometric features posses no natural order of sorting, thus it is difficult to index them alphabetically or numerically. Hence, some supervised criteria is required to partition the search space. At the time of identification the fuzziness criterion is introduced to find the nearest clusters for declaring the identity of query sample. The system is tested using bin-miss rate and performs better in comparison to traditional k-means approach.',
	 'authors': u'Hunny Mehrotra, Dakshina Ranjan Kisku, V. Bhawani Radhika, Banshidhar Majhi, Phalguni Gupta,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0383',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nFeature Level Clustering of Large Biometric Database',
	 'urllink': u'http://arxiv.org/abs/1002.0383'}
2015-03-24 12:42:39+0000 [xxu46_1] INFO: Crawled 614 pages (at 1 pages/min), scraped 608 items (at 1 items/min)
2015-03-24 12:43:28+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0574> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 12:43:28+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0574>
	{'abstract': u'Genetic algorithms are a population-based Meta heuristics. They have been successfully applied to many optimization problems. However, premature convergence is an inherent characteristic of such classical genetic algorithms that makes them incapable of searching numerous solutions of the problem domain. A memetic algorithm is an extension of the traditional genetic algorithm. It uses a local search technique to reduce the likelihood of the premature convergence. The cryptanalysis of simplified data encryption standard can be formulated as NP-Hard combinatorial problem. In this paper, a comparison between memetic algorithm and genetic algorithm were made in order to investigate the performance for the cryptanalysis on simplified data encryption standard problems(SDES). The methods were tested and various experimental results show that memetic algorithm performs better than the genetic algorithms for such type of NP-Hard combinatorial problem. This paper represents our first effort toward efficient memetic algorithm for the cryptanalysis of SDES.',
	 'authors': u'Poonam Garg,',
	 'category': u'Computer Science ',
	 'date': '2010-4-5',
	 'pdflink': u'http://arxiv.org/pdf/1004.0574',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nA Comparison between Memetic algorithm and Genetic algorithm for the  cryptanalysis of Simplified Data Encryption Standard algorithm',
	 'urllink': u'http://arxiv.org/abs/1004.0574'}
2015-03-24 12:43:39+0000 [xxu46_1] INFO: Crawled 615 pages (at 1 pages/min), scraped 609 items (at 1 items/min)
2015-03-24 12:44:39+0000 [xxu46_1] INFO: Crawled 615 pages (at 0 pages/min), scraped 609 items (at 0 items/min)
2015-03-24 12:45:13+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4472> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 12:45:13+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4472>
	{'abstract': u'Distributed power control over interference limited network has received an increasing intensity of interest over the past few years. Distributed solutions (like the iterative water-filling, gradient projection, etc.) have been intensively investigated under emph channels. However, as such distributed solutions involve iterative updating and explicit message passing, it is unrealistic to assume that the wireless channel remains unchanged during the iterations. Unfortunately, the behavior of those distributed solutions under emph channels is in general unknown. In this paper, we shall investigate the distributed scaled gradient projection algorithm (DSGPA) in a pairs multicarrier interference network under a finite-state Markov channel (FSMC) model. We shall analyze the emph as well as emph of the proposed DSGPA. Our analysis shows that the proposed DSGPA converges to a limit region rather than a single point under the FSMC model. We also show that the order of growth of the tracking errors is given by , where is the emph of the FSMC. Based on the analysis, we shall derive the emph via Markov decision process modeling. We shall show that the tracking error optimal scaling matrices can be implemented distributively at each transmitter. The numerical results show the superior performance of the proposed DSGPA over three baseline schemes, such as the gradient projection algorithm with a constant stepsize.',
	 'authors': u'Yong Cheng, Vincent K. N. Lau,',
	 'category': u'Computer Science ',
	 'date': '2010-5-25',
	 'pdflink': u'http://arxiv.org/pdf/1005.4472',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nDistributive Power Control Algorithm for Multicarrier Interference  Network over Time-Varying Fading Channels - Tracking Performance Analysis and  Optimization',
	 'urllink': u'http://arxiv.org/abs/1005.4472'}
2015-03-24 12:45:39+0000 [xxu46_1] INFO: Crawled 616 pages (at 1 pages/min), scraped 610 items (at 1 items/min)
2015-03-24 12:46:29+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0382> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 12:46:29+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0382>
	{'abstract': u'Faces are highly deformable objects which may easily change their appearance over time. Not all face areas are subject to the same variability. Therefore decoupling the information from independent areas of the face is of paramount importance to improve the robustness of any face recognition technique. This paper presents a robust face recognition technique based on the extraction and matching of SIFT features related to independent face areas. Both a global and local (as recognition from parts) matching strategy is proposed. The local strategy is based on matching individual salient facial SIFT features as connected to facial landmarks such as the eyes and the mouth. As for the global matching strategy, all SIFT features are combined together to form a single feature. In order to reduce the identification errors, the Dempster-Shafer decision theory is applied to fuse the two matching techniques. The proposed algorithms are evaluated with the ORL and the IITK face databases. The experimental results demonstrate the effectiveness and potential of the proposed face recognition techniques also in the case of partially occluded faces or with missing information.',
	 'authors': u'Dakshina Ranjan Kisku, Massimo Tistarelli, Jamuna Kanta Sing, Phalguni Gupta,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0382',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nFace Recognition by Fusion of Local and Global Matching Scores using DS  Theory: An Evaluation with Uni-classifier and Multi-classifier Paradigm',
	 'urllink': u'http://arxiv.org/abs/1002.0382'}
2015-03-24 12:46:39+0000 [xxu46_1] INFO: Crawled 617 pages (at 1 pages/min), scraped 611 items (at 1 items/min)
2015-03-24 12:47:39+0000 [xxu46_1] INFO: Crawled 617 pages (at 0 pages/min), scraped 611 items (at 0 items/min)
2015-03-24 12:47:40+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0571> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 12:47:40+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0571>
	{'abstract': u'this paper demonstrates analysis of well known block cipher CAST-128 and its modified version using avalanche criterion and other tests namely encryption quality, correlation coefficient, histogram analysis and key sensitivity tests.',
	 'authors': u'G. N. Krishnamurthy, V. Ramaswamy,',
	 'category': u'Computer Science ',
	 'date': '2010-4-5',
	 'pdflink': u'http://arxiv.org/pdf/1004.0571',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nEncryption Quality Analysis and Security Evaluation of CAST-128  Algorithm and its Modified Version using Digital Images',
	 'urllink': u'http://arxiv.org/abs/1004.0571'}
2015-03-24 12:48:33+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4461> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 12:48:33+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4461>
	{'abstract': u'One popular approach to soft-decision decoding of Reed-Solomon (RS) codes is based on using multiple trials of a simple RS decoding algorithm in combination with erasing or flipping a set of symbols or bits in each trial. This paper presents a framework based on rate-distortion (RD) theory to analyze these multiple-decoding algorithms. By defining an appropriate distortion measure between an error pattern and an erasure pattern, the successful decoding condition, for a single errors-and-erasures decoding trial, becomes equivalent to distortion being less than a fixed threshold. Finding the best set of erasure patterns also turns into a covering problem which can be solved asymptotically by rate-distortion theory. Thus, the proposed approach can be used to understand the asymptotic performance-versus-complexity trade-off of multiple errors-and-erasures decoding of RS codes. This initial result is also extended a few directions. The rate-distortion exponent (RDE) is computed to give more precise results for moderate blocklengths. Multiple trials of algebraic soft-decision (ASD) decoding are analyzed using this framework. Analytical and numerical computations of the RD and RDE functions are also presented. Finally, simulation results show that sets of erasure patterns designed using the proposed methods outperform other algorithms with the same number of decoding trials.',
	 'authors': u'Phong S. Nguyen, Henry D. Pfister, Krishna R. Narayanan,',
	 'category': u'Computer Science ',
	 'date': '2010-5-25',
	 'pdflink': u'http://arxiv.org/pdf/1005.4461',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOn Multiple Decoding Attempts for Reed-Solomon Codes: A Rate-Distortion  Approach',
	 'urllink': u'http://arxiv.org/abs/1005.4461'}
2015-03-24 12:48:39+0000 [xxu46_1] INFO: Crawled 619 pages (at 2 pages/min), scraped 613 items (at 2 items/min)
2015-03-24 12:49:39+0000 [xxu46_1] INFO: Crawled 619 pages (at 0 pages/min), scraped 613 items (at 0 items/min)
2015-03-24 12:50:13+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0378> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 12:50:13+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0378>
	{'abstract': u'Auctions play an important role in electronic commerce, and have been used to solve problems in distributed computing. Automated approaches to designing effective auction mechanisms are helpful in reducing the burden of traditional game theoretic, analytic approaches and in searching through the large space of possible auction mechanisms. This paper presents an approach to automated mechanism design (AMD) in the domain of double auctions. We describe a novel parametrized space of double auctions, and then introduce an evolutionary search method that searches this space of parameters. The approach evaluates auction mechanisms using the framework of the TAC Market Design Game and relates the performance of the markets in that game to their constituent parts using reinforcement learning. Experiments show that the strongest mechanisms we found using this approach not only win the Market Design Game against known, strong opponents, but also exhibit desirable economic properties when they run in isolation.',
	 'authors': u'Jinzhong Niu, Kai Cai, Simon Parsons,',
	 'category': u'Computer Science ',
	 'date': '2010-2-2',
	 'pdflink': u'http://arxiv.org/pdf/1002.0378',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nA Grey-Box Approach to Automated Mechanism Design',
	 'urllink': u'http://arxiv.org/abs/1002.0378'}
2015-03-24 12:50:39+0000 [xxu46_1] INFO: Crawled 620 pages (at 1 pages/min), scraped 614 items (at 1 items/min)
2015-03-24 12:51:39+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0570> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 12:51:39+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0570>
	{'abstract': u'Network forensics deals with the capture, recording and analysis of network events in order to discover evidential information about the source of security attacks in a court of law. This paper discusses the different tools and techniques available to conduct network forensics. Some of the tools discussed include: eMailTrackerPro to identify the physical location of an email sender; Web Historian to find the duration of each visit and the files uploaded and downloaded from the visited website; packet sniffers like Etherea to capture and analyze the data exchanged among the different computers in the network. The second half of the paper presents a survey of different IP traceback techniques like packet marking that help a forensic investigator to identify the true sources of the attacking IP packets. We also discuss the use of Honeypots and Honeynets that gather intelligence about the enemy and the tools and tactics of network intruders.',
	 'authors': u'Natarajan Meghanathan, Sumanth Reddy Allam, Loretta A. Moore,',
	 'category': u'Computer Science ',
	 'date': '2010-4-5',
	 'pdflink': u'http://arxiv.org/pdf/1004.0570',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nTools and techniques for Network Forensics',
	 'urllink': u'http://arxiv.org/abs/1004.0570'}
2015-03-24 12:51:39+0000 [xxu46_1] INFO: Crawled 621 pages (at 1 pages/min), scraped 615 items (at 1 items/min)
2015-03-24 12:52:39+0000 [xxu46_1] INFO: Crawled 621 pages (at 0 pages/min), scraped 615 items (at 0 items/min)
2015-03-24 12:53:16+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4447> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 12:53:16+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4447>
	{'abstract': u'A research project aimed at the development of an automated theorem proving system was started in Kiev (Ukraine) in early 1960s. The mastermind of the project, Academician V.Glushkov, baptized it "Evidence Algorithm", EA. The work on the project lasted, off and on, more than 40 years. In the framework of the project, the Russian and English versions of the System for Automated Deduction, SAD, were constructed. They may be already seen as powerful theorem-proving assistants.',
	 'authors': u'Alexander Lyaletski, Konstantin Verchinine,',
	 'category': u'Computer Science ',
	 'date': '2010-5-24',
	 'pdflink': u'http://arxiv.org/pdf/1005.4447',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nEvidence Algorithm and System for Automated Deduction: A Retrospective  View',
	 'urllink': u'http://arxiv.org/abs/1005.4447'}
2015-03-24 12:53:39+0000 [xxu46_1] INFO: Crawled 622 pages (at 1 pages/min), scraped 616 items (at 1 items/min)
2015-03-24 12:54:39+0000 [xxu46_1] INFO: Crawled 622 pages (at 0 pages/min), scraped 616 items (at 0 items/min)
2015-03-24 12:54:55+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0298> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 12:54:55+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0298>
	{'abstract': u"This paper introduces the notion of a secure data capsule, which refers to an encapsulation of sensitive user information (such as a credit card number) along with code that implements an interface suitable for the use of such information (such as charging for purchases) by a service (such as an online merchant). In our capsule framework, users provide their data in the form of such capsules to web services rather than raw data. Capsules can be deployed in a variety of ways, either on a trusted third party or the user's own computer or at the service itself, through the use of a variety of hardware or software modules, such as a virtual machine monitor or trusted platform module: the only requirement is that the deployment mechanism must ensure that the user's data is only accessed via the interface sanctioned by the user. The framework further allows an user to specify policies regarding which services or machines may host her capsule, what parties are allowed to access the interface, and with what parameters. The combination of interface restrictions and policy control lets us bound the impact of an attacker who compromises the service to gain access to the user's capsule or a malicious insider at the service itself.",
	 'authors': u'Jayanthkumar Kannan, Petros Maniatis, Byung-Gon Chun,',
	 'category': u'Computer Science ',
	 'date': '2010-2-1',
	 'pdflink': u'http://arxiv.org/pdf/1002.0298',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nA Data Capsule Framework For Web Services: Providing Flexible Data  Access Control To Users',
	 'urllink': u'http://arxiv.org/abs/1002.0298'}
2015-03-24 12:55:39+0000 [xxu46_1] INFO: Crawled 623 pages (at 1 pages/min), scraped 617 items (at 1 items/min)
2015-03-24 12:56:27+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0567> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 12:56:27+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0567>
	{'abstract': u'The main function of IDS (Intrusion Detection System) is to protect the system, analyze and predict the behaviors of users. Then these behaviors will be considered an attack or a normal behavior. Though IDS has been developed for many years, the large number of return alert messages makes managers maintain system inefficiently. In this paper, we use RST (Rough Set Theory) and SVM (Support Vector Machine) to detect intrusions. First, RST is used to preprocess the data and reduce the dimensions. Next, the features were selected by RST will be sent to SVM model to learn and test respectively. The method is effective to decrease the space density of data. The experiments will compare the results with different methods and show RST and SVM schema could improve the false positive rate and accuracy.',
	 'authors': u'Rung-Ching Chen, Kai-Fan Cheng, Chia-Fen Hsieh,',
	 'category': u'Computer Science ',
	 'date': '2010-4-5',
	 'pdflink': u'http://arxiv.org/pdf/1004.0567',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nUsing Rough Set and Support Vector Machine for Network Intrusion  Detection',
	 'urllink': u'http://arxiv.org/abs/1004.0567'}
2015-03-24 12:56:39+0000 [xxu46_1] INFO: Crawled 624 pages (at 1 pages/min), scraped 618 items (at 1 items/min)
2015-03-24 12:57:27+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4446> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 12:57:27+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4446>
	{'abstract': u'In this paper we present a novel genetic algorithm (GA) solution to a simple yet challenging commercial puzzle game known as the Zen Puzzle Garden (ZPG). We describe the game in detail, before presenting a suitable encoding scheme and fitness function for candidate solutions. We then compare the performance of the genetic algorithm with that of the A* algorithm. Our results show that the GA is competitive with informed search in terms of solution quality, and significantly out-performs it in terms of computational resource requirements. We conclude with a brief discussion of the implications of our findings for game solving and other "real world" problems.',
	 'authors': u'Jack Coldridge, Martyn Amos,',
	 'category': u'Computer Science ',
	 'date': '2010-5-24',
	 'pdflink': u'http://arxiv.org/pdf/1005.4446',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nGenetic algorithms and the art of Zen',
	 'urllink': u'http://arxiv.org/abs/1005.4446'}
2015-03-24 12:57:39+0000 [xxu46_1] INFO: Crawled 625 pages (at 1 pages/min), scraped 619 items (at 1 items/min)
2015-03-24 12:58:39+0000 [xxu46_1] INFO: Crawled 625 pages (at 0 pages/min), scraped 619 items (at 0 items/min)
2015-03-24 12:59:12+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0295> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 12:59:12+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0295>
	{'abstract': u'In this paper we consider completely regular codes, obtained from perfect (Hamming) codes by lifting the ground field. More exactly, for a given perfect code C of length n=(q^m-1)/(q-1) over F_q with a parity check matrix H_m, we define a new code C_ of length n over F_, r &gt; 1, with this parity check matrix H_m. The resulting code C_ is completely regular with covering radius R = min. We compute the intersection numbers of such codes and, finally, we prove that Hamming codes are the only codes that, after lifting the ground field, result in completely regular codes.',
	 'authors': u'Josep Rifa Victor Zinoviev,',
	 'category': u'Computer Science ',
	 'date': '2010-2-1',
	 'pdflink': u'http://arxiv.org/pdf/1002.0295',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOn lifting perfect codes',
	 'urllink': u'http://arxiv.org/abs/1002.0295'}
2015-03-24 12:59:39+0000 [xxu46_1] INFO: Crawled 626 pages (at 1 pages/min), scraped 620 items (at 1 items/min)
2015-03-24 13:00:39+0000 [xxu46_1] INFO: Crawled 626 pages (at 0 pages/min), scraped 620 items (at 0 items/min)
2015-03-24 13:00:44+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0558> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 13:00:44+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0558>
	{'abstract': u'We study new types of geometric query problems defined as follows: given a geometric set , preprocess it such that given a query point , the location of the largest circle that does not contain any member of , but contains can be reported efficiently. The geometric sets we consider for are boundaries of convex and simple polygons, and point sets. While we primarily focus on circles as the desired shape, we also briefly discuss empty rectangles in the context of point sets.',
	 'authors': u'John Augustine, Sandip Das, Anil Maheshwari, Subhas Nandy, Sasanka Roy, Swami Sarvattomananda,',
	 'category': u'Computer Science ',
	 'date': '2010-4-5',
	 'pdflink': u'http://arxiv.org/pdf/1004.0558',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nQuerying for the Largest Empty Geometric Object in a Desired Location',
	 'urllink': u'http://arxiv.org/abs/1004.0558'}
2015-03-24 13:01:39+0000 [xxu46_1] INFO: Crawled 627 pages (at 1 pages/min), scraped 621 items (at 1 items/min)
2015-03-24 13:02:24+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4405> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 13:02:24+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4405>
	{'abstract': u'This paper presents a modeling process in order to produce a realistic simulation of crowds in the ancient Greek agora of Argos. This place was a social theater in which two kinds of collective phenomena took place: interpersonal interactions (small group discussion and negotiation, etc.) and global collective phenomena, such as flowing and jamming. In this paper, we focus on the second type of collective human phenomena, called non-deliberative emergent crowd phenomena. This is a typical case of collective emergent self-organization. When a great number of individuals move within a confined environment and under a common fate, collective structures appear spontaneously: jamming with inner collapses, organized flowing with queues, curls, and vortices, propagation effects, etc. These are particularly relevant features to enhance the realism - more precisely the "truthfulness" - of models of this kind of collective phenomena. We assume that this truthfulness is strongly associated with the concept of emergence: evolutions are not predetermined by the individual characters, but emerge from the interaction of numerous characters. The evolutions are not repetitive, and evolve on the basis of small changes. This paper demonstrates that the physically-based interacting particles system is an adequate candidate to model emergent crowd effects: it associates a large number of elementary dynamic actors via elementary non-linear dynamic interactions. Our model of the scene is regulated as a large, dynamically coupled network of second order differential automata. We take advantage of symbolic non-photorealistic and efficient visualization to render the style of the person, rather than the person itself. As an artistic representation, NPR reinforces the symbolic acceptance of the scene by the observer, triggering an immediate and intuitive recognition of the scene as a plausible scene from ancient Greece.',
	 'authors': u'Laure He\xefgeas, Annie Luciani, Jo\xeblle Thollot, Nicolas Castagn\xe9,',
	 'category': u'Computer Science ',
	 'date': '2010-5-19',
	 'pdflink': u'http://arxiv.org/pdf/1005.4405',
	 'subjects': u'Graphics (cs.GR)',
	 'title': u'\nA physically-based particle model of emergent crowd behaviors',
	 'urllink': u'http://arxiv.org/abs/1005.4405'}
2015-03-24 13:02:39+0000 [xxu46_1] INFO: Crawled 628 pages (at 1 pages/min), scraped 622 items (at 1 items/min)
2015-03-24 13:03:26+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0286> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 13:03:26+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0286>
	{'abstract': u"In the problem Max Lin, we are given a system of linear equations with variables over in which each equation is assigned a positive weight and we wish to find an assignment of values to the variables that maximizes the excess, which is the total weight of satisfied equations minus the total weight of falsified equations. Using an algebraic approach, we obtain a lower bound for the maximum excess. Max Lin Above Average (Max Lin AA) is a parameterized version of Max Lin introduced by Mahajan et al. (Proc. IWPEC'06 and J. Comput. Syst. Sci. 75, 2009). In Max Lin AA all weights are integral and we are to decide whether the maximum excess is at least , where is the parameter. It is not hard to see that we may assume that no two equations in have the same left-hand side and . Using our maximum excess results, we prove that, under these assumptions, Max Lin AA is fixed-parameter tractable for a wide special case: for an arbitrary fixed function . Max -Lin AA is a special case of Max Lin AA, where each equation has at most variables. In Max Exact -SAT AA we are given a multiset of clauses on variables such that each clause has variables and asked whether there is a truth assignment to the variables that satisfies at least clauses. Using our maximum excess results, we prove that for each fixed , Max -Lin AA and Max Exact -SAT AA can be solved in time This improves -time algorithms for the two problems obtained by Gutin et al. (IWPEC 2009) and Alon et al. (SODA 2010), respectively.",
	 'authors': u'R. Crowston, G. Gutin, M. Jones, E.J. Kim, I.Z. Ruzsa,',
	 'category': u'Computer Science ',
	 'date': '2010-2-1',
	 'pdflink': u'http://arxiv.org/pdf/1002.0286',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nSystems of Linear Equations over $\\mathbb{F}_2$ and Problems  Parameterized Above Average',
	 'urllink': u'http://arxiv.org/abs/1002.0286'}
2015-03-24 13:03:39+0000 [xxu46_1] INFO: Crawled 629 pages (at 1 pages/min), scraped 623 items (at 1 items/min)
2015-03-24 13:04:39+0000 [xxu46_1] INFO: Crawled 629 pages (at 0 pages/min), scraped 623 items (at 0 items/min)
2015-03-24 13:05:13+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0557> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 13:05:13+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0557>
	{'abstract': u'We use a generalization of the Lindeberg principle developed by Sourav Chatterjee to prove universality properties for various problems in communications, statistical learning and random matrix theory. We also show that these systems can be viewed as the limiting case of a properly defined sparse system. The latter result is useful when the sparse systems are easier to analyze than their dense counterparts. The list of problems we consider is by no means exhaustive. We believe that the ideas can be used in many other problems relevant for information theory.',
	 'authors': u'Satish Babu Korada, Andrea Montanari,',
	 'category': u'Computer Science ',
	 'date': '2010-4-5',
	 'pdflink': u'http://arxiv.org/pdf/1004.0557',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nApplications of Lindeberg Principle in Communications and Statistical  Learning',
	 'urllink': u'http://arxiv.org/abs/1004.0557'}
2015-03-24 13:05:39+0000 [xxu46_1] INFO: Crawled 630 pages (at 1 pages/min), scraped 624 items (at 1 items/min)
2015-03-24 13:06:39+0000 [xxu46_1] INFO: Crawled 630 pages (at 0 pages/min), scraped 624 items (at 0 items/min)
2015-03-24 13:06:48+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4395> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 13:06:48+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4395>
	{'abstract': u'We introduce a new OpenMath content dictionary, named tensor1, containing symbols for the expression of tensor formulas. These symbols support the expression of non-Cartesian coordinates and invariant, multilinear expressions in the context of coordinate transformations. While current OpenMath symbols support the expression of linear algebra formulas using matrices and vectors, we find that there is an underlying assumption of Cartesian, or standard, coordinates that makes the expression of general tensor formulas difficult, if not impossible. In introducing these new OpenMath symbols for the expression of tensor formulas, we attempt to maintain, as much as possible, consistency with prior OpenMath symbol definitions for linear algebra.',
	 'authors': u'Joseph B. Collins,',
	 'category': u'Computer Science ',
	 'date': '2010-5-24',
	 'pdflink': u'http://arxiv.org/pdf/1005.4395',
	 'subjects': u'Mathematical Software (cs.MS)',
	 'title': u'\nAn OpenMath Content Dictionary for Tensor Concepts',
	 'urllink': u'http://arxiv.org/abs/1005.4395'}
2015-03-24 13:07:39+0000 [xxu46_1] INFO: Crawled 631 pages (at 1 pages/min), scraped 625 items (at 1 items/min)
2015-03-24 13:08:20+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0276> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 13:08:20+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0276>
	{'abstract': u'Artificial immune systems have previously been applied to the problem of intrusion detection. The aim of this research is to develop an intrusion detection system based on the function of Dendritic Cells (DCs). DCs are antigen presenting cells and key to activation of the human immune system, behaviour which has been abstracted to form the Dendritic Cell Algorithm (DCA). In algorithmic terms, individual DCs perform multi-sensor data fusion, asynchronously correlating the the fused data signals with a secondary data stream. Aggregate output of a population of cells, is analysed and forms the basis of an anomaly detection system. In this paper the DCA is applied to the detection of outgoing port scans using TCP SYN packets. Results show that detection can be achieved with the DCA, yet some false positives can be encountered when simultaneously scanning and using other network services. Suggestions are made for using adaptive signals to alleviate this uncovered problem.',
	 'authors': u'Julie Greensmith, Uwe Aickelin,',
	 'category': u'Computer Science ',
	 'date': '2010-2-1',
	 'pdflink': u'http://arxiv.org/pdf/1002.0276',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nDendritic Cells for SYN Scan Detection',
	 'urllink': u'http://arxiv.org/abs/1002.0276'}
2015-03-24 13:08:39+0000 [xxu46_1] INFO: Crawled 632 pages (at 1 pages/min), scraped 626 items (at 1 items/min)
2015-03-24 13:09:33+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0542> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 13:09:33+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0542>
	{'abstract': u"Cognitive radio methodologies have the potential to dramatically increase the throughput of wireless systems. Herein, control strategies which enable the superposition in time and frequency of primary and secondary user transmissions are explored in contrast to more traditional sensing approaches which only allow the secondary user to transmit when the primary user is idle. In this work, the optimal transmission policy for the secondary user when the primary user adopts a retransmission based error control scheme is investigated. The policy aims to maximize the secondary users' throughput, with a constraint on the throughput loss and failure probability of the primary user. Due to the constraint, the optimal policy is randomized, and determines how often the secondary user transmits according to the retransmission state of the packet being served by the primary user. The resulting optimal strategy of the secondary user is proven to have a unique structure. In particular, the optimal throughput is achieved by the secondary user by concentrating its transmission, and thus its interference to the primary user, in the first transmissions of a primary user packet. The rather simple framework considered in this paper highlights two fundamental aspects of cognitive networks that have not been covered so far: (i) the networking mechanisms implemented by the primary users (error control by means of retransmissions in the considered model) react to secondary users' activity; (ii) if networking mechanisms are considered, then their state must be taken into account when optimizing secondary users' strategy, i.e., a strategy based on a binary active/idle perception of the primary users' state is suboptimal.",
	 'authors': u'Marco Levorato, Urbashi Mitra, Michele Zorzi,',
	 'category': u'Computer Science ',
	 'date': '2010-4-4',
	 'pdflink': u'http://arxiv.org/pdf/1004.0542',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nCognitive Interference Management in Retransmission-Based Wireless  Networks',
	 'urllink': u'http://arxiv.org/abs/1004.0542'}
2015-03-24 13:09:39+0000 [xxu46_1] INFO: Crawled 633 pages (at 1 pages/min), scraped 627 items (at 1 items/min)
2015-03-24 13:10:39+0000 [xxu46_1] INFO: Crawled 633 pages (at 0 pages/min), scraped 627 items (at 0 items/min)
2015-03-24 13:10:41+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4394> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 13:10:41+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4394>
	{'abstract': u'Motivated by providing quality-of-service differentiated services in the Internet, we consider buffer management algorithms for network switches. We study a multi-buffer model. A network switch consists of multiple size-bounded buffers such that at any time, the number of packets residing in each individual buffer cannot exceed its capacity. Packets arrive at the network switch over time; they have values, deadlines, and designated buffers. In each time step, at most one pending packet is allowed to be sent and this packet can be from any buffer. The objective is to maximize the total value of the packets sent by their respective deadlines. A 9.82-competitive online algorithm has been provided for this model (Azar and Levy. SWAT 2006), but no offline algorithms have been known yet. In this paper, We study the offline setting of the multi-buffer model. Our contributions include a few optimal offline algorithms for some variants of the model. Each variant has its unique and interesting algorithmic feature. These offline algorithms help us understand the model better in designing online algorithms.',
	 'authors': u'Fei Li,',
	 'category': u'Computer Science ',
	 'date': '2010-5-24',
	 'pdflink': u'http://arxiv.org/pdf/1005.4394',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nScheduling Packets with Values and Deadlines in Size-bounded Buffers',
	 'urllink': u'http://arxiv.org/abs/1005.4394'}
2015-03-24 13:11:39+0000 [xxu46_1] INFO: Crawled 634 pages (at 1 pages/min), scraped 628 items (at 1 items/min)
2015-03-24 13:12:25+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0270> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 13:12:25+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0270>
	{'abstract': u'Traditional tolerancing considers the conformity of a batch when the batch satisfies the specifications. The characteristic is considered for itself and not according to its incidence in the assembly. Inertial tolerancing proposes another alternative of tolerancing in order to guarantee the final assembly characteristic. The inertia I2 = sqrt is not toleranced by a tolerance interval but by a scalar representing the maximum inertia that the characteristic should not exceed. We detail how to calculate the inertial tolerances according to two cases, one aims to guarantee an inertia of the assembly characteristic the other a tolerance interval on the assembly characteristic by a Cpk capability index, in the particular but common case of uniform tolerances or more general with non uniform tolerances. An example will be detailed to show the results of the different tolerancing methods.',
	 'authors': u'Pierre-Antoine Adragna, Maurice Pillet, Fabien Formosa, Serge Samper,',
	 'category': u'Computer Science ',
	 'date': '2010-2-1',
	 'pdflink': u'http://arxiv.org/pdf/1002.0270',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nInertial tolerancing and capability indices in an assembly production',
	 'urllink': u'http://arxiv.org/abs/1002.0270'}
2015-03-24 13:12:39+0000 [xxu46_1] INFO: Crawled 635 pages (at 1 pages/min), scraped 629 items (at 1 items/min)
2015-03-24 13:13:39+0000 [xxu46_1] INFO: Crawled 635 pages (at 0 pages/min), scraped 629 items (at 0 items/min)
2015-03-24 13:14:05+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0534> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 13:14:05+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0534>
	{'abstract': u'We present an analytical framework for modeling a priority-based load balancing scheme in cellular networks based on a new algorithm called direct retry with truncated offloading channel resource pool (DR). The model, developed for a baseline case of two cell network, differs in many respects from previous works on load balancing. Foremost, it incorporates the call admission process, through random access. In specific, the proposed model implements the Physical Random Access Channel used in 3GPP network standards. Furthermore, the proposed model allows the differentiation of users based on their priorities. The quantitative results illustrate that, for example, cellular network operators can control the manner in which traffic is offloaded between neighboring cells by simply adjusting the length of the random access phase. Our analysis also allows for the quantitative determination of the blocking probability individual users will experience given a specific length of random access phase. Furthermore, we observe that the improvement in blocking probability per shared channel for load balanced users using DR is maximized at an intermediate number of shared channels, as opposed to the maximum number of these shared resources. This occurs because a balance is achieved between the number of users requesting connections and those that are already admitted to the network. We also present an extension of our analytical model to a multi-cell network (by means of an approximation) and an application of the proposed load balancing scheme in the context of opportunistic spectrum access.',
	 'authors': u'Przemys\u0142aw Pawe\u0142czak, Shaunak Joshi, Sateesh Addepalli, John Villasenor, Danijela \u010cabri\u0107,',
	 'category': u'Computer Science ',
	 'date': '2010-4-4',
	 'pdflink': u'http://arxiv.org/pdf/1004.0534',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nImpact of Connection Admission Process on the Direct Retry Load  Balancing Algorithm in Cellular Network',
	 'urllink': u'http://arxiv.org/abs/1004.0534'}
2015-03-24 13:14:39+0000 [xxu46_1] INFO: Crawled 636 pages (at 1 pages/min), scraped 630 items (at 1 items/min)
2015-03-24 13:15:16+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4379> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 13:15:16+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4379>
	{'abstract': u'Dependently typed lambda calculi such as the Logical Framework (LF) can encode relationships between terms in types and can naturally capture correspondences between formulas and their proofs. Such calculi can also be given a logic programming interpretation: the Twelf system is based on such an interpretation of LF. We consider here whether a conventional logic programming language can provide the benefits of a Twelf-like system for encoding type and proof-and-formula dependencies. In particular, we present a simple mapping from LF specifications to a set of formulas in the higher-order hereditary Harrop (hohh) language, that relates derivations and proof-search between the two frameworks. We then show that this encoding can be improved by exploiting knowledge of the well-formedness of the original LF specifications to elide much redundant type-checking information. The resulting logic program has a structure that closely resembles the original specification, thereby allowing LF specifications to be viewed as hohh meta-programs. Using the Teyjus implementation of lambdaProlog, we show that our translation provides an efficient means for executing LF specifications, complementing the ability that the Twelf system provides for reasoning about them.',
	 'authors': u'Zachary Snow, David Baelde, Gopalan Nadathur,',
	 'category': u'Computer Science ',
	 'date': '2010-5-24',
	 'pdflink': u'http://arxiv.org/pdf/1005.4379',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nA Meta-Programming Approach to Realizing Dependently Typed Logic  Programming',
	 'urllink': u'http://arxiv.org/abs/1005.4379'}
2015-03-24 13:15:39+0000 [xxu46_1] INFO: Crawled 637 pages (at 1 pages/min), scraped 631 items (at 1 items/min)
2015-03-24 13:16:39+0000 [xxu46_1] INFO: Crawled 637 pages (at 0 pages/min), scraped 631 items (at 0 items/min)
2015-03-24 13:16:48+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0262> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 13:16:48+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0262>
	{'abstract': u"This work is a development from the Inetforsmep European project. We proposed to realize a global optimization of a deep drawing industrial progression (made of several stages) for a cup manufacture. The objectives of the process were the thickness decrease and the geometrical parameters (especially the height). This paper improves on this previous work in the aim of mastering the contour error. From the optimal configuration, we expect to cut down the amount of the needed material and the number of forming operations. Our action is focused on the appearance of unexpected undulations (ears) located on the rim of the cups during forming due to a nonuniform crystallographic texture. Those undulations can cause a significant amount of scraps, productivity loss, and cost during manufacture. In this paper, this phenomenon causes the use of four forming operations for the cup manufacture. The aim is to cut down from four to two forming stages by defining an optimal blank (size and shape). The advantage is to reduce the cost of the tool manufacturing and to minimize the needed material (by suppressing the part flange). The chosen approach consists in defining a particular description of the ears' part by modal decomposition and then simulating several blank shapes and sizes generated by discrete cosine transformation (DCT). The use of a numerical simulation for the forming operation and the design of an experiment technique allow mathematical links between the ears' formation and the DCT coefficients. An optimization is then possible by using mathematical links. This original approach leads the ears' amplitude to be reduced by a factor of 10, with only 15 numerical experiments. Moreover, we have limited the number of forming stages from 4 to 2 with a minimal material use.",
	 'authors': u'Y. Ledoux, H. Favreliere, Serge Samper,',
	 'category': u'Computer Science ',
	 'date': '2010-2-1',
	 'pdflink': u'http://arxiv.org/pdf/1002.0262',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nOptimization of a Classical Stamping Progression by Modal Correction of  Anisotropy Ears',
	 'urllink': u'http://arxiv.org/abs/1002.0262'}
2015-03-24 13:17:39+0000 [xxu46_1] INFO: Crawled 638 pages (at 1 pages/min), scraped 632 items (at 1 items/min)
2015-03-24 13:18:29+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0526> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 13:18:29+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0526>
	{'abstract': u'A pair of unit clauses is called conflicting if it is of the form , . A CNF formula is unit-conflict free (UCF) if it contains no pair of conflicting unit clauses. Lieberherr and Specker (J. ACM 28, 1981) showed that for each UCF CNF formula with clauses we can simultaneously satisfy at least clauses, where . We improve the Lieberherr-Specker bound by showing that for each UCF CNF formula with clauses we can find, in polynomial time, a subformula with clauses such that we can simultaneously satisfy at least clauses (in ), where is the number of variables in which are not in . We consider two parameterized versions of MAX-SAT, where the parameter is the number of satisfied clauses above the bounds and . The former bound is tight for general formulas, and the later is tight for UCF formulas. Mahajan and Raman (J. Algorithms 31, 1999) showed that every instance of the first parameterized problem can be transformed, in polynomial time, into an equivalent one with at most variables and clauses. We improve this to variables and clauses. Mahajan and Raman conjectured that the second parameterized problem is fixed-parameter tractable (FPT). We show that the problem is indeed FPT by describing a polynomial-time algorithm that transforms any problem instance into an equivalent one with at most variables. Our results are obtained using our improvement of the Lieberherr-Specker bound above.',
	 'authors': u'R. Crowston, G. Gutin, M. Jones, A. Yeo,',
	 'category': u'Computer Science ',
	 'date': '2010-4-4',
	 'pdflink': u'http://arxiv.org/pdf/1004.0526',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nA New Lower Bound on the Maximum Number of Satisfied Clauses in Max-SAT  and its Algorithmic Applications',
	 'urllink': u'http://arxiv.org/abs/1004.0526'}
2015-03-24 13:18:39+0000 [xxu46_1] INFO: Crawled 639 pages (at 1 pages/min), scraped 633 items (at 1 items/min)
2015-03-24 13:19:39+0000 [xxu46_1] INFO: Crawled 639 pages (at 0 pages/min), scraped 633 items (at 0 items/min)
2015-03-24 13:19:55+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4363> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 13:19:55+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4363>
	{'abstract': u'Today, reusable components are available in several repositories. These last are certainly conceived for the reusing However, this re-use is not immediate; it requires, in the fact, to pass through some essential conceptual operations, among them in particular, research, integration, adaptation, and composition. We are interested in the present work to the problem of semantic integration of heterogeneous Business Components. This problem is often put in syntactical terms, while the real stake is of semantic order. Our contribution concerns a model proposal for Business components integration as well as resolution method of semantic naming conflicts, met during the integration of Business Components.',
	 'authors': u'Larbi Kzaz, Hicham Elasri, Abderrahim Sekkaki,',
	 'category': u'Computer Science ',
	 'date': '2010-5-24',
	 'pdflink': u'http://arxiv.org/pdf/1005.4363',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nA model for semantic integration of business components',
	 'urllink': u'http://arxiv.org/abs/1005.4363'}
2015-03-24 13:20:39+0000 [xxu46_1] INFO: Crawled 640 pages (at 1 pages/min), scraped 634 items (at 1 items/min)
2015-03-24 13:21:37+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0253> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 13:21:37+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0253>
	{'abstract': u'Tolerancing of assembly mechanisms is a major interest in the product life cycle. One can distinguish several models with growing complexity, from 1-dimensional (1D) to 3-dimensional (3D) (including form deviations), and two main tolerancing assumptions, the worst case and the statistical hypothesis. This paper presents an approach to 3D statistical tolerancing using a new acceptance criterion. Our approach is based on the 1D inertial acceptance criterion that is extended to 3D and form acceptance. The modal characterisation is used to describe the form deviation of a geometry as the combination of elementary deviations (location, orientation and form). The proposed 3D statistical tolerancing is applied on a simple mechanism with lever arm. It is also compared to the traditional worst-case tolerancing using a tolerance zone.',
	 'authors': u'Pierre-Antoine Adragna, Serge Samper, Maurice Pillet,',
	 'category': u'Computer Science ',
	 'date': '2010-2-1',
	 'pdflink': u'http://arxiv.org/pdf/1002.0253',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nA proposition of 3D inertial tolerancing to consider the statistical  combination of the location and orientation deviations',
	 'urllink': u'http://arxiv.org/abs/1002.0253'}
2015-03-24 13:21:39+0000 [xxu46_1] INFO: Crawled 641 pages (at 1 pages/min), scraped 635 items (at 1 items/min)
2015-03-24 13:22:36+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0517> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 13:22:36+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0517>
	{'abstract': u'In this paper a novel efficient method for representation of facial action units by encoding an image sequence as a fourth-order tensor is presented. The multilinear tensor-based extension of the biased discriminant analysis (BDA) algorithm, called multilinear biased discriminant analysis (MBDA), is first proposed. Then, we apply the MBDA and two-dimensional BDA (2DBDA) algorithms, as the dimensionality reduction techniques, to Gabor representations and the geometric features of the input image sequence respectively. The proposed scheme can deal with the asymmetry between positive and negative samples as well as curse of dimensionality dilemma. Extensive experiments on Cohn-Kanade database show the superiority of the proposed method for representation of the subtle changes and the temporal information involved in formation of the facial expressions. As an accurate tool, this representation can be applied to many areas such as recognition of spontaneous and deliberate facial expressions, multi modal/media human computer interaction and lie detection efforts.',
	 'authors': u'Mahmoud Khademi, Mehran Safayani, Mohammad T. Manzuri-Shalmani,',
	 'category': u'Computer Science ',
	 'date': '2010-4-4',
	 'pdflink': u'http://arxiv.org/pdf/1004.0517',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nMultilinear Biased Discriminant Analysis: A Novel Method for Facial  Action Unit Representation',
	 'urllink': u'http://arxiv.org/abs/1004.0517'}
2015-03-24 13:22:39+0000 [xxu46_1] INFO: Crawled 642 pages (at 1 pages/min), scraped 636 items (at 1 items/min)
2015-03-24 13:23:39+0000 [xxu46_1] INFO: Crawled 642 pages (at 0 pages/min), scraped 636 items (at 0 items/min)
2015-03-24 13:24:24+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4344> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 13:24:24+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4344>
	{'abstract': u'Max-stable random sketches can be computed efficiently on fast streaming positive data sets by using only sequential access to the data. They can be used to answer point and Lp-norm queries for the signal. There is an intriguing connection between the so-called p-stable (or sum-stable) and the max-stable sketches. Rigorous performance guarantees through error-probability estimates are derived and the algorithmic implementation is discussed.',
	 'authors': u'Stilian A. Stoev, Murad S. Taqqu,',
	 'category': u'Computer Science ',
	 'date': '2010-5-24',
	 'pdflink': u'http://arxiv.org/pdf/1005.4344',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nMax-stable sketches: estimation of Lp-norms, dominance norms and point  queries for non-negative signals',
	 'urllink': u'http://arxiv.org/abs/1005.4344'}
2015-03-24 13:24:39+0000 [xxu46_1] INFO: Crawled 643 pages (at 1 pages/min), scraped 637 items (at 1 items/min)
2015-03-24 13:25:36+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0251> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 13:25:36+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0251>
	{'abstract': u'The [ISO 1101] standard specifies the form errors with geometrical tolerances using the zone concept.To complete this concept, we present a generic method which adapts to any geometry and allows to describe any kind of errors. Thus,we can dissociate the part errors according to reference categories: position, orientation,form, waviness and roughnesses. Starting from a cloud of poinds representing the error measurement, the "modal" method decompose, like Fourier series,this error in a sum of sorted errors according to the ircomplexity degree (a number of "wavinesses"). In addition, we propose to show, on a simple example, that according to error complexity to be characterized, an interpolation by the modal method allows to optimize the measuring strategy.',
	 'authors': u'Hugues Favreliere, Serge Samper, Pierre-Antoine Adragna,',
	 'category': u'Computer Science ',
	 'date': '2010-2-1',
	 'pdflink': u'http://arxiv.org/pdf/1002.0251',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u"\nCaract\xe9risation des d\xe9fauts d'une surface sph\xe9rique par  d\xe9composition modale",
	 'urllink': u'http://arxiv.org/abs/1002.0251'}
2015-03-24 13:25:39+0000 [xxu46_1] INFO: Crawled 644 pages (at 1 pages/min), scraped 638 items (at 1 items/min)
2015-03-24 13:26:39+0000 [xxu46_1] INFO: Crawled 644 pages (at 0 pages/min), scraped 638 items (at 0 items/min)
2015-03-24 13:27:20+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0515> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 13:27:20+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0515>
	{'abstract': u'Facial Action Coding System consists of 44 action units (AUs) and more than 7000 combinations. Hidden Markov models (HMMs) classifier has been used successfully to recognize facial action units (AUs) and expressions due to its ability to deal with AU dynamics. However, a separate HMM is necessary for each single AU and each AU combination. Since combinations of AU numbering in thousands, a more efficient method will be needed. In this paper an accurate real-time sequence-based system for representation and recognition of facial AUs is presented. Our system has the following characteristics: 1) employing a mixture of HMMs and neural network, we develop a novel accurate classifier, which can deal with AU dynamics, recognize subtle changes, and it is also robust to intensity variations, 2) although we use an HMM for each single AU only, by employing a neural network we can recognize each single and combination AU, and 3) using both geometric and appearance-based features, and applying efficient dimension reduction techniques, our system is robust to illumination changes and it can represent the temporal information involved in formation of the facial expressions. Extensive experiments on Cohn-Kanade database show the superiority of the proposed method, in comparison with other classifiers. Keywords: classifier design and evaluation, data fusion, facial action units (AUs), hidden Markov models (HMMs), neural network (NN).',
	 'authors': u'Mahmoud Khademi, Mohammad T. Manzuri-Shalmani, Mohammad H. Kiapour, Ali A. Kiaei,',
	 'category': u'Computer Science ',
	 'date': '2010-4-4',
	 'pdflink': u'http://arxiv.org/pdf/1004.0515',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nRecognizing Combinations of Facial Action Units with Different Intensity  Using a Mixture of Hidden Markov Models and Neural Network',
	 'urllink': u'http://arxiv.org/abs/1004.0515'}
2015-03-24 13:27:39+0000 [xxu46_1] INFO: Crawled 645 pages (at 1 pages/min), scraped 639 items (at 1 items/min)
2015-03-24 13:28:37+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4337> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 13:28:37+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4337>
	{'abstract': u"We develop a probabilistic framework for global modeling of the traffic over a computer network. This model integrates existing single-link (-flow) traffic models with the routing over the network to capture the global traffic behavior. It arises from a limit approximation of the traffic fluctuations as the time--scale and the number of users sharing the network grow. The resulting probability model is comprised of a Gaussian and/or a stable, infinite variance components. They can be succinctly described and handled by certain 'space-time' random fields. The model is validated against simulated and real data. It is then applied to predict traffic fluctuations over unobserved links from a limited set of observed links. Further, applications to anomaly detection and network management are briefly discussed.",
	 'authors': u'Stilian A. Stoev, George Michailidis, Joel Vaughan,',
	 'category': u'Computer Science ',
	 'date': '2010-5-24',
	 'pdflink': u'http://arxiv.org/pdf/1005.4337',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nGlobal Modeling and Prediction of Computer Network Traffic',
	 'urllink': u'http://arxiv.org/abs/1005.4337'}
2015-03-24 13:28:39+0000 [xxu46_1] INFO: Crawled 646 pages (at 1 pages/min), scraped 640 items (at 1 items/min)
2015-03-24 13:29:39+0000 [xxu46_1] INFO: Crawled 646 pages (at 0 pages/min), scraped 640 items (at 0 items/min)
2015-03-24 13:30:21+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0239> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 13:30:21+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0239>
	{'abstract': u'Automatic construction of ontologies from text is generally based on retrieving text content. For a much more rich ontology we extend these approaches by taking into account the document structure and some external resources (like thesaurus of indexing terms of near domain). In this paper we describe how these external resources are at first analyzed and then exploited. This method has been applied on a geographical domain and the benefit has been evaluated.',
	 'authors': u'Eric Kergosien, Mouna Kamel, Christian Sallaberry, Marie-No\xeblle Bessagnet, Nathalie Aussenac- Gilles, Mauro Gaio,',
	 'category': u'Computer Science ',
	 'date': '2010-2-1',
	 'pdflink': u'http://arxiv.org/pdf/1002.0239',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u"\nConstruction et enrichissement automatique d'ontologie \xe0 partir de  ressources externes",
	 'urllink': u'http://arxiv.org/abs/1002.0239'}
2015-03-24 13:30:39+0000 [xxu46_1] INFO: Crawled 647 pages (at 1 pages/min), scraped 641 items (at 1 items/min)
2015-03-24 13:31:39+0000 [xxu46_1] INFO: Crawled 647 pages (at 0 pages/min), scraped 641 items (at 0 items/min)
2015-03-24 13:31:55+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0514> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 13:31:55+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0514>
	{'abstract': u"This paper extends the analogies employed in the development of quantum-inspired evolutionary algorithms by proposing quantum-inspired Hadamard walks, called QHW. A novel quantum-inspired evolutionary algorithm, called HQEA, for solving combinatorial optimization problems, is also proposed. The novelty of HQEA lies in it's incorporation of QHW Remote Search and QHW Local Search - the quantum equivalents of classical mutation and local search, that this paper defines. The intuitive reasoning behind this approach, and the exploration-exploitation balance thus occurring is explained. From the results of the experiments carried out on the 0,1-knapsack problem, HQEA performs significantly better than a conventional genetic algorithm, CGA, and two quantum-inspired evolutionary algorithms - QEA and NQEA, in terms of convergence speed and accuracy.",
	 'authors': u'Sisir Koppaka, Ashish Ranjan Hota,',
	 'category': u'Computer Science ',
	 'date': '2010-4-4',
	 'pdflink': u'http://arxiv.org/pdf/1004.0514',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nSuperior Exploration-Exploitation Balance with Quantum-Inspired Hadamard  Walks',
	 'urllink': u'http://arxiv.org/abs/1004.0514'}
2015-03-24 13:32:39+0000 [xxu46_1] INFO: Crawled 648 pages (at 1 pages/min), scraped 642 items (at 1 items/min)
2015-03-24 13:33:27+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4316> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 13:33:27+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4316>
	{'abstract': u'In this paper, we address the theoretical limitations in reconstructing sparse signals (in a known complete basis) using compressed sensing framework. We also divide the CS to non-blind and blind cases. Then, we compute the Bayesian Cramer-Rao bound for estimating the sparse coefficients while the measurement matrix elements are independent zero mean random variables. Simulation results show a large gap between the lower bound and the performance of the practical algorithms when the number of measurements are low.',
	 'authors': u'Hadi Zayyani, Massoud Babaie-Zadeh, Christian Jutten,',
	 'category': u'Computer Science ',
	 'date': '2010-5-24',
	 'pdflink': u'http://arxiv.org/pdf/1005.4316',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nBayesian Cram\xe9r-Rao Bound for Noisy Non-Blind and Blind Compressed  Sensing',
	 'urllink': u'http://arxiv.org/abs/1005.4316'}
2015-03-24 13:33:39+0000 [xxu46_1] INFO: Crawled 649 pages (at 1 pages/min), scraped 643 items (at 1 items/min)
2015-03-24 13:34:39+0000 [xxu46_1] INFO: Crawled 649 pages (at 0 pages/min), scraped 643 items (at 0 items/min)
2015-03-24 13:34:57+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0235> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 13:34:57+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0235>
	{'abstract': u"We consider a dense n-user Gaussian interference network formed by paired transmitters and receivers placed independently at random in Euclidean space. Under natural conditions on the node position distributions and signal attenuation, we prove convergence in probability of the average per-user capacity C_Sigma/n to 1/2 E log(1 + 2SNR). The achievability result follows directly from results based on an interference alignment scheme presented in recent work of Nazer et al. Our main contribution comes through the converse result, motivated by ideas of `bottleneck links' developed in recent work of Jafar. An information theoretic argument gives a capacity bound on such bottleneck links, and probabilistic counting arguments show there are sufficiently many such links to tightly bound the sum-capacity of the whole network.",
	 'authors': u'Matthew Aldridge, Oliver Johnson, Robert Piechocki,',
	 'category': u'Computer Science ',
	 'date': '2010-2-1',
	 'pdflink': u'http://arxiv.org/pdf/1002.0235',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nAsymptotic Sum-Capacity of Random Gaussian Interference Networks Using  Interference Alignment',
	 'urllink': u'http://arxiv.org/abs/1002.0235'}
2015-03-24 13:35:39+0000 [xxu46_1] INFO: Crawled 650 pages (at 1 pages/min), scraped 644 items (at 1 items/min)
2015-03-24 13:36:29+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0512> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 13:36:29+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0512>
	{'abstract': u'In this paper an accurate real-time sequence-based system for representation, recognition, interpretation, and analysis of the facial action units (AUs) and expressions is presented. Our system has the following characteristics: 1) employing adaptive-network-based fuzzy inference systems (ANFIS) and temporal information, we developed a classification scheme based on neuro-fuzzy modeling of the AU intensity, which is robust to intensity variations, 2) using both geometric and appearance-based features, and applying efficient dimension reduction techniques, our system is robust to illumination changes and it can represent the subtle changes as well as temporal information involved in formation of the facial expressions, and 3) by continuous values of intensity and employing top-down hierarchical rule-based classifiers, we can develop accurate human-interpretable AU-to-expression converters. Extensive experiments on Cohn-Kanade database show the superiority of the proposed method, in comparison with support vector machines, hidden Markov models, and neural network classifiers. Keywords: biased discriminant analysis (BDA), classifier design and evaluation, facial action units (AUs), hybrid learning, neuro-fuzzy modeling.',
	 'authors': u'Mahmoud Khademi, Mohammad Hadi Kiapour, Mohammad T. Manzuri-Shalmani, Ali A. Kiaei,',
	 'category': u'Computer Science ',
	 'date': '2010-4-4',
	 'pdflink': u'http://arxiv.org/pdf/1004.0512',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nAnalysis, Interpretation, and Recognition of Facial Action Units and  Expressions Using Neuro-Fuzzy Modeling',
	 'urllink': u'http://arxiv.org/abs/1004.0512'}
2015-03-24 13:36:39+0000 [xxu46_1] INFO: Crawled 651 pages (at 1 pages/min), scraped 645 items (at 1 items/min)
2015-03-24 13:37:39+0000 [xxu46_1] INFO: Crawled 651 pages (at 0 pages/min), scraped 645 items (at 0 items/min)
2015-03-24 13:37:42+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4298> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 13:37:42+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4298>
	{'abstract': u"Cross-document coreference, the problem of resolving entity mentions across multi-document collections, is crucial to automated knowledge base construction and data mining tasks. However, the scarcity of large labeled data sets has hindered supervised machine learning research for this task. In this paper we develop and demonstrate an approach based on ``distantly-labeling'' a data set from which we can train a discriminative cross-document coreference model. In particular we build a dataset of more than a million people mentions extracted from 3.5 years of New York Times articles, leverage Wikipedia for distant labeling with a generative model (and measure the reliability of such labeling); then we train and evaluate a conditional random field coreference model that has factors on cross-document entities as well as mention-pairs. This coreference model obtains high accuracy in resolving mentions and entities that are not present in the training data, indicating applicability to non-Wikipedia data. Given the large amount of data, our work is also an exercise demonstrating the scalability of our approach.",
	 'authors': u'Sameer Singh, Michael Wick, Andrew McCallum,',
	 'category': u'Computer Science ',
	 'date': '2010-5-24',
	 'pdflink': u'http://arxiv.org/pdf/1005.4298',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nDistantly Labeling Data for Large Scale Cross-Document Coreference',
	 'urllink': u'http://arxiv.org/abs/1005.4298'}
2015-03-24 13:38:39+0000 [xxu46_1] INFO: Crawled 652 pages (at 1 pages/min), scraped 646 items (at 1 items/min)
2015-03-24 13:39:05+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0215> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 13:39:05+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0215>
	{'abstract': u'Within the documentary system domain, the integration of thesauri for indexing and retrieval information steps is usual. In libraries, documents own rich descriptive information made by librarians, under descriptive notice based on Rameau thesaurus. We exploit two kinds of information in order to create a first semantic structure. A step of conceptualization allows us to define the various modules used to automatically build the semantic structure of the indexation work. Our current work focuses on an approach that aims to define an ontology based on a thesaurus. We hope to integrate new knowledge characterizing the territory of our structure (adding "toponyms" and links between concepts) thanks to a geographic information system (GIS).',
	 'authors': u'Marie-No\xeblle Bessagnet, Eric Kergosien, Mauro Gaio,',
	 'category': u'Computer Science ',
	 'date': '2010-2-1',
	 'pdflink': u'http://arxiv.org/pdf/1002.0215',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nExtraction de termes, reconnaissance et labellisation de relations dans  un th\xe9saurus',
	 'urllink': u'http://arxiv.org/abs/1002.0215'}
2015-03-24 13:39:39+0000 [xxu46_1] INFO: Crawled 653 pages (at 1 pages/min), scraped 647 items (at 1 items/min)
2015-03-24 13:40:39+0000 [xxu46_1] INFO: Crawled 653 pages (at 0 pages/min), scraped 647 items (at 0 items/min)
2015-03-24 13:40:39+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0459> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 13:40:39+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0459>
	{'abstract': u'In this paper, we suggest a novel data hiding technique in an HTML Web page. HTML Tags are case insensitive and hence an alphabet in lowercase and one in uppercase present inside an HTML tag are interpreted in the same manner by the browser,i.e., change in case in an web page is imperceptible to the browser. We basically exploit this redundancy and use it to embed secret data inside an web page, with no changes visible to the user of the web page, so that he can not even suspect about the data hiding. The embedded data can be recovered by viewing the source of the HTML page. This technique can easily be extended to embed secret message inside any piece of source-code where the standard interpreter of that language is case-insensitive.',
	 'authors': u'Sandipan Dey, Hameed Al-Qaheri, Sugata Sanyal,',
	 'category': u'Computer Science ',
	 'date': '2010-4-3',
	 'pdflink': u'http://arxiv.org/pdf/1004.0459',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nEmbedding Secret Data in HTML Web Page',
	 'urllink': u'http://arxiv.org/abs/1004.0459'}
2015-03-24 13:41:39+0000 [xxu46_1] INFO: Crawled 654 pages (at 1 pages/min), scraped 648 items (at 1 items/min)
2015-03-24 13:42:20+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4292> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 13:42:20+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4292>
	{'abstract': u'Segmentation of images holds an important position in the area of image processing. It becomes more important whi le typically dealing with medical images where presurgery and post surgery decisions are required for the purpose of initiating and speeding up the recovery process. Segmentation of 3-D tumor structures from magnetic resonance images (MRI) is a very challenging problem due to the variability of tumor geometry and intensity patterns. Level set evolution combining global smoothness with the flexibility of topology changes offers significant advantages over the conventional statistical classification followed by mathematical morphology. Level set evolution with constant propagation needs to be initialized either completely inside or outside the tumor and can leak through weak or missing boundary parts. Replacing the constant propagation term by a statistical force overcomes these limitations and results in a convergence to a stable solution. Using MR images presenting tumors, probabilities for background and tumor regions are calculated from a pre- and post-contrast difference image and mixture modeling fit of the histogram. The whole image is used for initialization of the level set evolution to segment the tumor boundaries.',
	 'authors': u'Mrigank Rajya, Sonal Rewri, Swati Sheoran,',
	 'category': u'Computer Science ',
	 'date': '2010-5-24',
	 'pdflink': u'http://arxiv.org/pdf/1005.4292',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nApplication Of Fuzzy System In Segmentation Of MRI Brain Tumor',
	 'urllink': u'http://arxiv.org/abs/1005.4292'}
2015-03-24 13:42:39+0000 [xxu46_1] INFO: Crawled 655 pages (at 1 pages/min), scraped 649 items (at 1 items/min)
2015-03-24 13:43:18+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0214> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 13:43:18+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0214>
	{'abstract': u'The tolerancing process links the virtual and the real worlds. From the former, tolerances define a variational geometrical language (geometric parameters). From the latter, there are values limiting those parameters. The beginning of a tolerancing process is in this duality. As high precision assemblies cannot be analyzed with the assumption that form errors are negligible, we propose to apply this process to assemblies with form errors through a new way of allowing to parameterize forms and solve their assemblies. The assembly process is calculated through a method of allowing to solve the 3D assemblies of pairs of surfaces having form errors using a static equilibrium. We have built a geometrical model based on the modal shapes of the ideal surface. We compute for the completely deterministic contact points between this pair of shapes according to a given assembly process. The solution gives an accurate evaluation of the assembly performance. Then we compare the results with or without taking into account the form errors. When we analyze a batch of assemblies, the problem is to compute for the nonconformity rate of a pilot production according to the functional requirements. We input probable errors of surfaces (position, orientation, and form) in our calculus and we evaluate the quality of the results compared with the functional requirements. The pilot production then can or cannot be validated.',
	 'authors': u'Serge Samper, Pierre-Antoine Adragna, Hugues Favreliere, Maurice Pillet,',
	 'category': u'Computer Science ',
	 'date': '2010-2-1',
	 'pdflink': u'http://arxiv.org/pdf/1002.0214',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nModeling of 2D and 3D Assemblies Taking Into Account Form Errors of  Plane Surfaces',
	 'urllink': u'http://arxiv.org/abs/1002.0214'}
2015-03-24 13:43:39+0000 [xxu46_1] INFO: Crawled 656 pages (at 1 pages/min), scraped 650 items (at 1 items/min)
2015-03-24 13:44:39+0000 [xxu46_1] INFO: Crawled 656 pages (at 0 pages/min), scraped 650 items (at 0 items/min)
2015-03-24 13:45:04+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0438> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 13:45:04+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0438>
	{'abstract': u"User-driven applications are the programs, in which the full control is given to the users. Designers of such programs are responsible only for developing an instrument for solving some task, but they do not enforce users to work with this instrument according with the predefined scenario. Users' control of the applications means that only users decide at any moment WHAT, WHEN, and HOW must appear on the screen. Such applications can be constructed only on the basis of moveable / resizable elements. Programs, based on such elements, have very interesting features and open absolutely new possibilities. This article describes the design of the user-driven applications and shows the consequences of switching to such type of programs on the samples from different areas.",
	 'authors': u'Sergey Andreyev,',
	 'category': u'Computer Science ',
	 'date': '2010-4-3',
	 'pdflink': u'http://arxiv.org/pdf/1004.0438',
	 'subjects': u'Human-Computer Interaction (cs.HC)',
	 'title': u'\nUser-driven applications',
	 'urllink': u'http://arxiv.org/abs/1004.0438'}
2015-03-24 13:45:39+0000 [xxu46_1] INFO: Crawled 657 pages (at 1 pages/min), scraped 651 items (at 1 items/min)
2015-03-24 13:46:28+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4290> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 13:46:28+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4290>
	{'abstract': u'An accident is unexpected, unusual, unintended and identifiable external event which occurs at any place and at any time. The major concern faced by the government and traffic officials is over speeding at limited speed zones like hospitals, schools or residential places leading to causalities and more deaths on the roads. Hence the speed of the vehicles is to be regulated and confined to the limits as prescribed by the traffic regulations. In this paper we propose a solution in the form of providing E-speed governor fitted with a wireless communication system consisting of a Rx which receives the information regarding the speed regulation for their zones. The TX will be made highly intelligent and decide when receiver should be made active to regulate the speed and unwarranted honking from the vehicles which can be deactivated in the silent zones.',
	 'authors': u'C. S. Sridhar, R. ShashiKumar, S. Madhava Kumar, Manjula Sridhar, Varun. D,',
	 'category': u'Computer Science ',
	 'date': '2010-5-24',
	 'pdflink': u'http://arxiv.org/pdf/1005.4290',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nE-Speed Governors For Public Transport Vehicles',
	 'urllink': u'http://arxiv.org/abs/1005.4290'}
2015-03-24 13:46:39+0000 [xxu46_1] INFO: Crawled 658 pages (at 1 pages/min), scraped 652 items (at 1 items/min)
2015-03-24 13:47:39+0000 [xxu46_1] INFO: Crawled 658 pages (at 0 pages/min), scraped 652 items (at 0 items/min)
2015-03-24 13:48:09+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0205> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 13:48:09+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0205>
	{'abstract': u'Full-rate space-time block codes with nonvanishing determinants have been extensively designed with cyclic division algebras. For these designs, smaller pairwise error probabilities of maximum likelihood detections require larger normalized diversity products, which can be obtained by choosing integer non-norm elements with smaller absolute values. All known methods have constructed and to be integer non-norm elements with the smallest absolute values over QAM for the number of transmit antennas : and , respectively. Via explicit constructions, this paper proves that is an integer non-norm element with the smallest absolute value over QAM for every .',
	 'authors': u'Hua-Chieh Li, Ming-Yang Chen, John M. Cioffi,',
	 'category': u'Computer Science ',
	 'date': '2010-2-1',
	 'pdflink': u'http://arxiv.org/pdf/1002.0205',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOn the Generality of $1+\\mathbf{i}$ as a Non-Norm Element',
	 'urllink': u'http://arxiv.org/abs/1002.0205'}
2015-03-24 13:48:39+0000 [xxu46_1] INFO: Crawled 659 pages (at 1 pages/min), scraped 653 items (at 1 items/min)
2015-03-24 13:49:39+0000 [xxu46_1] INFO: Crawled 659 pages (at 0 pages/min), scraped 653 items (at 0 items/min)
2015-03-24 13:49:52+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0436> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 13:49:52+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0436>
	{'abstract': u'The parity decision tree model extends the decision tree model by allowing the computation of a parity function in one step. We prove that the deterministic parity decision tree complexity of any Boolean function is polynomially related to the non-deterministic complexity of the function or its complement. We also show that they are polynomially related to an analogue of the block sensitivity. We further study parity decision trees in their relations with an intermediate variant of the decision trees, as well as with communication complexity.',
	 'authors': u'Zhiqiang Zhang, Yaoyun Shi,',
	 'category': u'Computer Science ',
	 'date': '2010-4-3',
	 'pdflink': u'http://arxiv.org/pdf/1004.0436',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nOn the parity complexity measures of Boolean functions',
	 'urllink': u'http://arxiv.org/abs/1004.0436'}
2015-03-24 13:50:39+0000 [xxu46_1] INFO: Crawled 660 pages (at 1 pages/min), scraped 654 items (at 1 items/min)
2015-03-24 13:51:25+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4272> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 13:51:25+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4272>
	{'abstract': u'In the last two decades, a number of methods have been proposed for forecasting based on fuzzy time series. Most of the fuzzy time series methods are presented for forecasting of car road accidents. However, the forecasting accuracy rates of the existing methods are not good enough. In this paper, we compared our proposed new method of fuzzy time series forecasting with existing methods. Our method is based on means based partitioning of the historical data of car road accidents. The proposed method belongs to the kth order and time-variant methods. The proposed method can get the best forecasting accuracy rate for forecasting the car road accidents than the existing methods.',
	 'authors': u'G. Arutchelvan, S. K. Srivatsa, R. Jagannathan,',
	 'category': u'Computer Science ',
	 'date': '2010-5-24',
	 'pdflink': u'http://arxiv.org/pdf/1005.4272',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nInaccuracy Minimization by Partioning Fuzzy Data Sets - Validation of  Analystical Methodology',
	 'urllink': u'http://arxiv.org/abs/1005.4272'}
2015-03-24 13:51:39+0000 [xxu46_1] INFO: Crawled 661 pages (at 1 pages/min), scraped 655 items (at 1 items/min)
2015-03-24 13:52:20+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0184> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 13:52:20+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0184>
	{'abstract': u'For the most of my life, I have earned my living as a computer vision professional busy with image processing tasks and problems. In the computer vision community there is a widespread belief that artificial vision systems faithfully replicate human vision abilities or at least very closely mimic them. It was a great surprise to me when one day I have realized that computer and human vision have next to nothing in common. The former is occupied with extensive data processing, carrying out massive pixel-based calculations, while the latter is busy with meaningful information processing, concerned with smart objects-based manipulations. And the gap between the two is insurmountable. To resolve this confusion, I had had to return and revaluate first the vision phenomenon itself, define more carefully what visual information is and how to treat it properly. In this work I have not been, as it is usually accepted, biologically inspired . On the contrary, I have drawn my inspirations from a pure mathematical theory, the Kolmogorov s complexity theory. The results of my work have been already published elsewhere. So the objective of this paper is to try and apply the insights gained in course of this my enterprise to a more general case of information processing in human brain and the challenging issue of human intelligence.',
	 'authors': u'Emanuel Diamant,',
	 'category': u'Computer Science ',
	 'date': '2010-2-1',
	 'pdflink': u'http://arxiv.org/pdf/1002.0184',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nSome considerations on how the human brain must be arranged in order to  make its replication in a thinking machine possible',
	 'urllink': u'http://arxiv.org/abs/1002.0184'}
2015-03-24 13:52:39+0000 [xxu46_1] INFO: Crawled 662 pages (at 1 pages/min), scraped 656 items (at 1 items/min)
2015-03-24 13:53:39+0000 [xxu46_1] INFO: Crawled 662 pages (at 0 pages/min), scraped 656 items (at 0 items/min)
2015-03-24 13:53:40+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0424> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 13:53:40+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0424>
	{'abstract': u'The and the are two well studied problems having a wide range of applications. In this paper we consider both problems with resource constraints, denoted as the Restricted Common Superstring (shortly textit) problem and the Restricted Common Supersequence (shortly textit). In the textit ( textit) problem we are given a set of strings, , , , , and a multiset , and the goal is to find a permutation to maximize the number of strings in that are substrings (subsequences) of (we call this ordering of the multiset, , a permutation of ). We first show that in its most general setting the textit problem is and hard to approximate within a factor of , for any , unless P = NP. Afterwards, we present two separate reductions to show that the textit problem remains NP-Hard even in the case where the elements of are drawn from a binary alphabet or for the case where all input strings are of length two. We then present some approximation results for several variants of the textit problem. In the second part of this paper, we turn to the textit problem, where we present some hardness results, tight lower bounds and approximation algorithms.',
	 'authors': u'Rapha\xebl Clifford, Zvi Gotthilf, Moshe Lewenstein, Alexandru Popa,',
	 'category': u'Computer Science ',
	 'date': '2010-4-3',
	 'pdflink': u'http://arxiv.org/pdf/1004.0424',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nRestricted Common Superstring and Restricted Common Supersequence',
	 'urllink': u'http://arxiv.org/abs/1004.0424'}
2015-03-24 13:54:39+0000 [xxu46_1] INFO: Crawled 663 pages (at 1 pages/min), scraped 657 items (at 1 items/min)
2015-03-24 13:55:24+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4271> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 13:55:24+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4271>
	{'abstract': u'The continuing process of software systems enlargement in size and complexity becomes system design extremely important for software production. In this way, the role of software architecture is significantly important in software development. It serves as an evaluation and implementation plan for software development and software evaluation. Consequently, choosing the correct architecture is a critical issue in software engineering domain. Moreover,software architecture selection is a multicriteria decision-making problem in which different goals and objectives must be taken into consideration. In this paper, more precise and suitable decisions in selection of architecture styles have been presented by using ANP inference to support decisions of software architects in order to exploit properties of styles in the best way to optimize the design of software architecture.',
	 'authors': u'K. Delhi Babu, P. Govinda Rajulu, A. Ramamohana Reddy, A.N. Aruna Kumari,',
	 'category': u'Computer Science ',
	 'date': '2010-5-24',
	 'pdflink': u'http://arxiv.org/pdf/1005.4271',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nSelection of Architecture Styles using Analytic Network Process for the  Optimization of Software Architecture',
	 'urllink': u'http://arxiv.org/abs/1005.4271'}
2015-03-24 13:55:39+0000 [xxu46_1] INFO: Crawled 664 pages (at 1 pages/min), scraped 658 items (at 1 items/min)
2015-03-24 13:56:39+0000 [xxu46_1] INFO: Crawled 664 pages (at 0 pages/min), scraped 658 items (at 0 items/min)
2015-03-24 13:56:49+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0182> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 13:56:49+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0182>
	{'abstract': u'Quantization of compressed sensing measurements is typically justified by the robust recovery results of Cand `es, Romberg and Tao, and of Donoho. These results guarantee that if a uniform quantizer of step size is used to quantize measurements of a -sparse signal , where satisfies the restricted isometry property, then the approximate recovery via -minimization is within of . The simplest and commonly assumed approach is to quantize each measurement independently. In this paper, we show that if instead an th order quantization scheme with the same output alphabet is used to quantize , then there is an alternative recovery method via Sobolev dual frames which guarantees a reduction of the approximation error by a factor of for any , if . The result holds with high probability on the initial draw of the measurement matrix from the Gaussian distribution, and uniformly for all -sparse signals that satisfy a mild size condition on their supports.',
	 'authors': u'S. G\xfcnt\xfcrk, A. Powell, R. Saab, \xd6. Y\u0131lmaz,',
	 'category': u'Computer Science ',
	 'date': '2010-2-1',
	 'pdflink': u'http://arxiv.org/pdf/1002.0182',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nSobolev Duals for Random Frames and Sigma-Delta Quantization of  Compressed Sensing Measurements',
	 'urllink': u'http://arxiv.org/abs/1002.0182'}
2015-03-24 13:57:39+0000 [xxu46_1] INFO: Crawled 665 pages (at 1 pages/min), scraped 659 items (at 1 items/min)
2015-03-24 13:58:29+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0422> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 13:58:29+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0422>
	{'abstract': u'Two-ray ground reflection model has been widely used as the propagation model to investigate the performance of an ad hoc network. But two-ray model is too simple to represent a real world network. A more realistic model namely shadowing propagation model has been used in this investigation. Under shadowing propagation model, a mobile node may receive a packet at a signal level that is below a required threshold level. This low signal level affects the routing protocol as well as the medium access control protocol of a network. An analytical model has been presented in this paper to investigate the shadowing effects on the network performance. The analytical model has been verified via simulation results. Simulation results show that the performance of a network becomes very poor if shadowing propagation model is used in compare to the simple two-ray model. Two solutions have also been proposed in this paper to overcome the effects of shadowing. One solution is a physical layer solution and the other one is a Medium Access Control (MAC) layer solution. Simulation results show that these two solutions reduce the shadowing effect and improve network performance.',
	 'authors': u'Anwar Hossain, Mohammed Tarique, Rumana Islam,',
	 'category': u'Computer Science ',
	 'date': '2010-4-3',
	 'pdflink': u'http://arxiv.org/pdf/1004.0422',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nShadowing Effects on Routing Protocol of Multihop Ad Hoc Networks',
	 'urllink': u'http://arxiv.org/abs/1004.0422'}
2015-03-24 13:58:39+0000 [xxu46_1] INFO: Crawled 666 pages (at 1 pages/min), scraped 660 items (at 1 items/min)
2015-03-24 13:59:39+0000 [xxu46_1] INFO: Crawled 666 pages (at 0 pages/min), scraped 660 items (at 0 items/min)
2015-03-24 14:00:18+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4270> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 14:00:18+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4270>
	{'abstract': u"Mining Time Series data has a tremendous growth of interest in today's world. To provide an indication various implementations are studied and summarized to identify the different problems in existing applications. Clustering time series is a trouble that has applications in an extensive assortment of fields and has recently attracted a large amount of research. Time series data are frequently large and may contain outliers. In addition, time series are a special type of data set where elements have a temporal ordering. Therefore clustering of such data stream is an important issue in the data mining process. Numerous techniques and clustering algorithms have been proposed earlier to assist clustering of time series data streams. The clustering algorithms and its effectiveness on various applications are compared to develop a new method to solve the existing problem. This paper presents a survey on various clustering algorithms available for time series datasets. Moreover, the distinctiveness and restriction of previous research are discussed and several achievable topics for future study are recognized. Furthermore the areas that utilize time series clustering are also summarized.",
	 'authors': u'V.Kavitha, M. Punithavalli,',
	 'category': u'Computer Science ',
	 'date': '2010-5-24',
	 'pdflink': u'http://arxiv.org/pdf/1005.4270',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nClustering Time Series Data Stream - A Literature Survey',
	 'urllink': u'http://arxiv.org/abs/1005.4270'}
2015-03-24 14:00:39+0000 [xxu46_1] INFO: Crawled 667 pages (at 1 pages/min), scraped 661 items (at 1 items/min)
2015-03-24 14:01:06+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0179> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 14:01:06+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0179>
	{'abstract': u"We consider finite sequences where is a commutative, unital, integral domain. We prove three sets of identities (possibly with repetitions), each involving polynomials associated to . The right-hand side of these identities is a recursively-defined (non-zero) 'product-of-discrepancies'. There are implied iterative algorithms (of quadratic complexity) for the left-hand side coefficients; when the ground domain is factorial, the identities are in effect B 'ezout identities. We give a number of applications: an algorithm to compute B 'ezout coefficients over a field; the outputs of the Berlekamp-Massey algorithm; sequences with perfect linear complexity profile; annihilating polynomials which do not vanish at zero and have minimal degree: we simplify and extend an algorithm of Salagean to sequences over . In the Appendix, we give a new proof of a theorem of Imamura and Yoshida on the linear complexity of reverse sequences, initially proved using Hankel matrices over a field and now valid for sequences over a factorial domain.",
	 'authors': u'Graham H. Norton,',
	 'category': u'Computer Science ',
	 'date': '2010-2-1',
	 'pdflink': u'http://arxiv.org/pdf/1002.0179',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nB\xe9zout Identities Associated to a Finite Sequence',
	 'urllink': u'http://arxiv.org/abs/1002.0179'}
2015-03-24 14:01:39+0000 [xxu46_1] INFO: Crawled 668 pages (at 1 pages/min), scraped 662 items (at 1 items/min)
2015-03-24 14:02:39+0000 [xxu46_1] INFO: Crawled 668 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2015-03-24 14:02:41+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0421> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 14:02:41+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0421>
	{'abstract': u'A wireless sensor network consists of light-weight, low power, small size sensor nodes. Routing in wireless sensor networks is a demanding task. This demand has led to a number of routing protocols which efficiently utilize the limited resources available at the sensor nodes. Most of these protocols are either based on single hop routing or multi hop routing and typically find the minimum energy path without addressing other issues such as time delay in delivering a packet, load balancing, and redundancy of data. Response time is very critical in environment monitoring sensor networks where typically the sensors are stationary and transmit data to a base station or a sink node. In this paper a faster load balancing routing protocol based on location with a hybrid approach is proposed.',
	 'authors': u'Jasmine Norman, J.Paulraj Joseph, P.Prapoorna Roja,',
	 'category': u'Computer Science ',
	 'date': '2010-4-3',
	 'pdflink': u'http://arxiv.org/pdf/1004.0421',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nA Faster Routing Scheme for Stationary Wireless Sensor Networks - A  Hybrid Approach',
	 'urllink': u'http://arxiv.org/abs/1004.0421'}
2015-03-24 14:03:39+0000 [xxu46_1] INFO: Crawled 669 pages (at 1 pages/min), scraped 663 items (at 1 items/min)
2015-03-24 14:04:12+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4268> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 14:04:12+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4268>
	{'abstract': u'Admission control schemes and scheduling algorithms are designed to offer QoS services in 802.16/802.16e networks and a number of studies have investigated these issues. But the channel condition and priority of traffic classes are very rarely considered in the existing scheduling algorithms. Although a number of energy saving mechanisms have been proposed for the IEEE 802.16e, to minimize the power consumption of IEEE 802.16e mobile stations with multiple real-time connections has not yet been investigated. Moreover, they mainly consider non real- time connections in IEEE 802.16e networks. In this paper, we propose to design an adaptive power efficient packet scheduling algorithm that provides a minimum fair allocation of the channel bandwidth for each packet flow and additionally minimizes the power consumption. In the adaptive scheduling algorithm, packets are transmitted as per allotted slots from different priority of traffic classes adaptively, depending on the channel condition. Suppose if the buffer size of the high priority traffic queues with bad channel condition exceeds a threshold, then the priority of those flows will be increased by adjusting the sleep duty cycle of existing low priority traffic, to prevent the starvation. By simulation results, we show that our proposed scheduler achieves better channel utilization while minimizing the delay and power consumption.',
	 'authors': u'R Murali Prasad, P. Satish Kumar,',
	 'category': u'Computer Science ',
	 'date': '2010-5-24',
	 'pdflink': u'http://arxiv.org/pdf/1005.4268',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nAn Adaptive Power Efficient Packet Scheduling Algorithm for Wimax  Networks',
	 'urllink': u'http://arxiv.org/abs/1005.4268'}
2015-03-24 14:04:39+0000 [xxu46_1] INFO: Crawled 670 pages (at 1 pages/min), scraped 664 items (at 1 items/min)
2015-03-24 14:05:39+0000 [xxu46_1] INFO: Crawled 670 pages (at 0 pages/min), scraped 664 items (at 0 items/min)
2015-03-24 14:05:48+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0177> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 14:05:48+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0177>
	{'abstract': u'Machine Consciousness is the study of consciousness in a biological, philosophical, mathematical and physical perspective and designing a model that can fit into a programmable system architecture. Prime objective of the study is to make the system architecture behave consciously like a biological model does. Present work has developed a feasible definition of consciousness, that characterizes consciousness with four parameters i.e., parasitic, symbiotic, self referral and reproduction. Present work has also developed a biologically inspired consciousness architecture that has following layers: quantum layer, cellular layer, organ layer and behavioral layer and traced the characteristics of consciousness at each layer. Finally, the work has estimated physical and algorithmic architecture to devise a system that can behave consciously.',
	 'authors': u'C.N. Padhy, R.R. Panda,',
	 'category': u'Computer Science ',
	 'date': '2010-2-1',
	 'pdflink': u'http://arxiv.org/pdf/1002.0177',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nLogical Evaluation of Consciousness: For Incorporating Consciousness  into Machine Architecture',
	 'urllink': u'http://arxiv.org/abs/1002.0177'}
2015-03-24 14:06:39+0000 [xxu46_1] INFO: Crawled 671 pages (at 1 pages/min), scraped 665 items (at 1 items/min)
2015-03-24 14:06:48+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0403> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 14:06:48+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0403>
	{'abstract': u"Bit arrays, or bitmaps, are used to significantly speed up set operations in several areas, such as data warehousing, information retrieval, and data mining, to cite a few. However, bitmaps usually use a large storage space, thus requiring compression. Nevertheless, there is a space-time tradeoff among compression schemes. The Word Aligned Hybrid (WAH) bitmap compression trades some space to allow for bitwise operations without first decompressing bitmaps. WAH has been recognized as the most efficient scheme in terms of computation time. In this paper we present CONCISE (Compressed 'n' Composable Integer Set), a new scheme that enjoys significatively better performances than those of WAH. In particular, when compared to WAH, our algorithm is able to reduce the required memory up to 50%, by having similar or better performance in terms of computation time. Further, we show that CONCISE can be efficiently used to manipulate bitmaps representing sets of integral numbers in lieu of well-known data structures such as arrays, lists, hashtables, and self-balancing binary search trees. Extensive experiments over synthetic data show the effectiveness of our approach.",
	 'authors': u'Alessandro Colantonio, Roberto Di Pietro,',
	 'category': u'Computer Science ',
	 'date': '2010-4-3',
	 'pdflink': u'http://arxiv.org/pdf/1004.0403',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u"\nCONCISE: Compressed 'n' Composable Integer Set",
	 'urllink': u'http://arxiv.org/abs/1004.0403'}
2015-03-24 14:07:39+0000 [xxu46_1] INFO: Crawled 672 pages (at 1 pages/min), scraped 666 items (at 1 items/min)
2015-03-24 14:07:49+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4267> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 14:07:49+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4267>
	{'abstract': u"The digital image data is rapidly expanding in quantity and heterogeneity. The traditional information retrieval techniques does not meet the user's demand, so there is need to develop an efficient system for content based image retrieval. Content based image retrieval means retrieval of images from database on the basis of visual features of image like as color, texture etc. In our proposed method feature are extracted after applying Phong shading on input image. Phong shading, flattering out the dull surfaces of the image The features are extracted using color, texture &amp; edge density methods. Feature extracted values are used to find the similarity between input query image and the data base image. It can be measure by the Euclidean distance formula. The experimental result shows that the proposed approach has a better retrieval results with phong shading.",
	 'authors': u'Uday Pratap Singh, Sanjeev Jain, Gulfishan Firdose Ahmed,',
	 'category': u'Computer Science ',
	 'date': '2010-5-24',
	 'pdflink': u'http://arxiv.org/pdf/1005.4267',
	 'subjects': u'Multimedia (cs.MM)',
	 'title': u'\nContent Base Image Retrieval Using Phong Shading',
	 'urllink': u'http://arxiv.org/abs/1005.4267'}
2015-03-24 14:08:39+0000 [xxu46_1] INFO: Crawled 673 pages (at 1 pages/min), scraped 667 items (at 1 items/min)
2015-03-24 14:09:33+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0172> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 14:09:33+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0172>
	{'abstract': u'We give an optimal (EXPTIME), sound and complete tableau-based algorithm for deciding satisfiability for propositional dynamic logic with converse (CPDL) which does not require the use of analytic cut. Our main contribution is a sound methodto combine our previous optimal method for tracking least fix-points in PDL with our previous optimal method for handling converse in the description logic ALCI. The extension is non-trivial as the two methods cannot be combined naively. We give sufficient details to enable an implementation by others. Our OCaml implementation seems to be the first theorem prover for CPDL.',
	 'authors': u'Rajeev Gor\xe9, Florian Widmann,',
	 'category': u'Computer Science ',
	 'date': '2010-2-1',
	 'pdflink': u'http://arxiv.org/pdf/1002.0172',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nOptimal and Cut-free Tableaux for Propositional Dynamic Logic with  Converse',
	 'urllink': u'http://arxiv.org/abs/1002.0172'}
2015-03-24 14:09:39+0000 [xxu46_1] INFO: Crawled 674 pages (at 1 pages/min), scraped 668 items (at 1 items/min)
2015-03-24 14:10:39+0000 [xxu46_1] INFO: Crawled 674 pages (at 0 pages/min), scraped 668 items (at 0 items/min)
2015-03-24 14:11:17+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0402> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 14:11:17+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0402>
	{'abstract': u'It is well known that minimization can be used to recover sufficiently sparse unknown signals from compressed linear measurements. In fact, exact thresholds on the sparsity, as a function of the ratio between the system dimensions, so that with high probability almost all sparse signals can be recovered from iid Gaussian measurements, have been computed and are referred to as "weak thresholds" cite. In this paper, we introduce a reweighted recovery algorithm composed of two steps: a standard minimization step to identify a set of entries where the signal is likely to reside, and a weighted minimization step where entries outside this set are penalized. For signals where the non-sparse component has iid Gaussian entries, we prove a "strict" improvement in the weak recovery threshold. Simulations suggest that the improvement can be quite impressive-over 20% in the example we consider.',
	 'authors': u'M. Amin Khajehnejad, Weiyu Xu, Salman Avestimehr, Babak Hassibi,',
	 'category': u'Computer Science ',
	 'date': '2010-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1004.0402',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nImproved Sparse Recovery Thresholds with Two-Step Reweighted $\\ell_1$  Minimization',
	 'urllink': u'http://arxiv.org/abs/1004.0402'}
2015-03-24 14:11:39+0000 [xxu46_1] INFO: Crawled 675 pages (at 1 pages/min), scraped 669 items (at 1 items/min)
2015-03-24 14:12:39+0000 [xxu46_1] INFO: Crawled 675 pages (at 0 pages/min), scraped 669 items (at 0 items/min)
2015-03-24 14:13:02+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4266> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 14:13:02+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4266>
	{'abstract': u'E-Commerce offers the banking industry great opportunity, but also creates a set of new risks and vulnerability such as security threats. Information security, therefore, is an essential management and technical requirement for any efficient and effective Payment transaction activities over the internet. Still, its definition is a complex endeavor due to the constant technological and business change and requires a coordinated match of algorithm and technical solutions. Ecommerce is not appropriate to all business transactions and, within e-commerce there is no one technology that can or should be appropriate to all requirements. E-commerce is not a new phenomenon; electronic markets, electronic data interchange and customer e-commerce. The use of electronic data interchanges as a universal and non-proprietary way of doing business. Through the electronic transaction the security is the most important phenomena to enhance the banking transaction security via payment transaction.',
	 'authors': u'Raju Barskar, Anjana Jayant Deen, Jyoti Bharti, Gulfishan Firdose Ahmed,',
	 'category': u'Computer Science ',
	 'date': '2010-5-24',
	 'pdflink': u'http://arxiv.org/pdf/1005.4266',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nThe Algorithm Analysis of E-Commerce Security Issues for Online Payment  Transaction System in Banking Technology',
	 'urllink': u'http://arxiv.org/abs/1005.4266'}
2015-03-24 14:13:39+0000 [xxu46_1] INFO: Crawled 676 pages (at 1 pages/min), scraped 670 items (at 1 items/min)
2015-03-24 14:14:39+0000 [xxu46_1] INFO: Crawled 676 pages (at 0 pages/min), scraped 670 items (at 0 items/min)
2015-03-24 14:14:47+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0170> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 14:14:47+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0170>
	{'abstract': u"In this paper, we study the dynamics of a viral spreading process in random geometric graphs (RGG). The spreading of the viral process we consider in this paper is closely related with the eigenvalues of the adjacency matrix of the graph. We deduce new explicit expressions for all the moments of the eigenvalue distribution of the adjacency matrix as a function of the spatial density of nodes and the radius of connection. We apply these expressions to study the behavior of the viral infection in an RGG. Based on our results, we deduce an analytical condition that can be used to design RGG's in order to tame an initial viral infection. Numerical simulations are in accordance with our analytical predictions.",
	 'authors': u'Victor M. Preciado, Ali Jadbabaie,',
	 'category': u'Computer Science ',
	 'date': '2010-2-1',
	 'pdflink': u'http://arxiv.org/pdf/1002.0170',
	 'subjects': u'Multiagent Systems (cs.MA)',
	 'title': u'\nSpectral Analysis of Virus Spreading in Random Geometric Networks',
	 'urllink': u'http://arxiv.org/abs/1002.0170'}
2015-03-24 14:15:39+0000 [xxu46_1] INFO: Crawled 677 pages (at 1 pages/min), scraped 671 items (at 1 items/min)
2015-03-24 14:16:07+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0400> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 14:16:07+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0400>
	{'abstract': u'Let be the capacity of the binary deletion channel with deletion probability . It was proved by Drinea and Mitzenmacher that, for all , . Fertonani and Duman recently showed that . In this paper, it is proved that exists and is equal to . This result suggests the conjecture that the curve my be convex in the interval . Furthermore, using currently known bounds for , it leads to the upper bound .',
	 'authors': u'Marco Dalai,',
	 'category': u'Computer Science ',
	 'date': '2010-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1004.0400',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nA new bound for the capacity of the deletion channel with high deletion  probabilities',
	 'urllink': u'http://arxiv.org/abs/1004.0400'}
2015-03-24 14:16:39+0000 [xxu46_1] INFO: Crawled 678 pages (at 1 pages/min), scraped 672 items (at 1 items/min)
2015-03-24 14:17:39+0000 [xxu46_1] INFO: Crawled 678 pages (at 0 pages/min), scraped 672 items (at 0 items/min)
2015-03-24 14:17:44+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4265> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 14:17:44+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4265>
	{'abstract': u'This paper describes the use of fuzzy logic controller for efficiency optimization control of a drive while keeping good dynamic response. At steady-state light-load condition, the fuzzy controller adaptively adjusts the excitation current with respect to the torque current to give the minimum total copper and iron loss. The measured input power such that, for a given load torque and speed, the drive settles down to the minimum input power, i.e., operates at maximum efficiency. The low-frequency pulsating torque due to decrementation of flux is compensated in a feed forward manner. If the load torque or speed commands changes, the efficiency search algorithm is abandoned and the rated flux is established to get the best dynamic response. The drive system with the proposed efficiency optimization controller has been simulated with lossy models of converter and machine, and its performance has been thoroughly investigated.',
	 'authors': u'C. Srisailam, Mukesh Tiwari, Anurag Trivedi,',
	 'category': u'Computer Science ',
	 'date': '2010-5-24',
	 'pdflink': u'http://arxiv.org/pdf/1005.4265',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nReduction in iron losses in Indirect Vector-Controlled IM Drive using  FLC',
	 'urllink': u'http://arxiv.org/abs/1005.4265'}
2015-03-24 14:18:39+0000 [xxu46_1] INFO: Crawled 679 pages (at 1 pages/min), scraped 673 items (at 1 items/min)
2015-03-24 14:19:28+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0169> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 14:19:28+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0169>
	{'abstract': u'In this paper, we investigate synchronization in a small-world network of coupled nonlinear oscillators. This network is constructed by introducing random shortcuts in a nearest-neighbors ring. The local stability of the synchronous state is closely related with the support of the eigenvalue distribution of the Laplacian matrix of the network. We introduce, for the first time, analytical expressions for the first three moments of the eigenvalue distribution of the Laplacian matrix as a function of the probability of shortcuts and the connectivity of the underlying nearest-neighbor coupled ring. We apply these expressions to estimate the spectral support of the Laplacian matrix in order to predict synchronization in small-world networks. We verify the efficiency of our predictions with numerical simulations.',
	 'authors': u'Victor M. Preciado, Ali Jadbabaie,',
	 'category': u'Computer Science ',
	 'date': '2010-2-1',
	 'pdflink': u'http://arxiv.org/pdf/1002.0169',
	 'subjects': u'Multiagent Systems (cs.MA)',
	 'title': u'\nMoment-Based Analysis of Synchronization in Small-World Networks of  Oscillators',
	 'urllink': u'http://arxiv.org/abs/1002.0169'}
2015-03-24 14:19:39+0000 [xxu46_1] INFO: Crawled 680 pages (at 1 pages/min), scraped 674 items (at 1 items/min)
2015-03-24 14:20:39+0000 [xxu46_1] INFO: Crawled 680 pages (at 0 pages/min), scraped 674 items (at 0 items/min)
2015-03-24 14:21:12+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0395> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 14:21:12+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0395>
	{'abstract': u"Peer-to-peer swarming is one of the emph solutions for distributed content dissemination in today's Internet. By leveraging resources provided by clients, swarming systems reduce the load on and costs to publishers. However, there is a limit to how much cost savings can be gained from swarming; for example, for unpopular content peers will always depend on the publisher in order to complete their downloads. In this paper, we investigate this dependence. For this purpose, we propose a new metric, namely emph. A swarm is referred to as self-sustaining if all its blocks are collectively held by peers; the self-sustainability of a swarm is the fraction of time in which the swarm is self-sustaining. We pose the following question: how does the self-sustainability of a swarm vary as a function of content popularity, the service capacity of the users, and the size of the file? We present a model to answer the posed question. We then propose efficient solution methods to compute self-sustainability. The accuracy of our estimates is validated against simulation. Finally, we also provide closed-form expressions for the fraction of time that a given number of blocks is collectively held by peers.",
	 'authors': u'Daniel S. Menasche, Antonio A. A. Rocha, Edmundo A. de Souza e Silva, Rosa M. Leao, Don Towsley, Arun Venkataramani,',
	 'category': u'Computer Science ',
	 'date': '2010-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1004.0395',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nEstimating Self-Sustainability in Peer-to-Peer Swarming Systems',
	 'urllink': u'http://arxiv.org/abs/1004.0395'}
2015-03-24 14:21:39+0000 [xxu46_1] INFO: Crawled 681 pages (at 1 pages/min), scraped 675 items (at 1 items/min)
2015-03-24 14:22:39+0000 [xxu46_1] INFO: Crawled 681 pages (at 0 pages/min), scraped 675 items (at 0 items/min)
2015-03-24 14:22:53+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4264> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 14:22:53+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4264>
	{'abstract': u'Biometrics deals with identity verification of an individual by using certain physiological or behavioral features associated with a person. Biometric identification systems using fingerprints patterns are called AFIS (Automatic Fingerprint Identification System). In this paper a composite method for Fingerprint recognition is considered using a combination of Fast Fourier Transform (FFT) and Sobel Filters for improvement of a poor quality fingerprint image. Steganography hides messages inside other messages in such a way that an "adversary" would not even know a secret message were present. The objective of our paper is to make a bio-secure system. In this paper bio-authentication has been implemented in terms of finger print recognition and the second part of the paper is an interactive steganographic system hides the user\'s data by two options- creating a songs list or hiding the data in an image.',
	 'authors': u'Najme Zehra, Mansi Sharma, Somya Ahuja, Shubha Bansal,',
	 'category': u'Computer Science ',
	 'date': '2010-5-24',
	 'pdflink': u'http://arxiv.org/pdf/1005.4264',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nBio-Authentication based Secure Transmission System using Steganography',
	 'urllink': u'http://arxiv.org/abs/1005.4264'}
2015-03-24 14:23:39+0000 [xxu46_1] INFO: Crawled 682 pages (at 1 pages/min), scraped 676 items (at 1 items/min)
2015-03-24 14:24:39+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0155> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 14:24:39+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0155>
	{'abstract': u'It is known that in the Minkowski sum of polytopes in dimension , with , the number of vertices of the sum can potentially be as high as the product of the number of vertices in each summand. However, the number of vertices for sums of more polytopes was unknown so far. In this paper, we study sums of polytopes in general orientations, and show a linear relation between the number of faces of a sum of polytopes in dimension , with , and the number of faces in the sums of less than of the summand polytopes. We deduce from this exact formula a tight bound on the maximum possible number of vertices of the Minkowski sum of any number of polytopes in any dimension. In particular, the linear relation implies that a sum of polytopes in dimension has a number of vertices in of the total number of vertices in the summands, even when . This bound is tight, in the sense that some sums do have that many vertices.',
	 'authors': u'Christophe Weibel,',
	 'category': u'Computer Science ',
	 'date': '2010-1-31',
	 'pdflink': u'http://arxiv.org/pdf/1002.0155',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nMaximal f-vectors of Minkowski sums of large numbers of polytopes',
	 'urllink': u'http://arxiv.org/abs/1002.0155'}
2015-03-24 14:24:39+0000 [xxu46_1] INFO: Crawled 683 pages (at 1 pages/min), scraped 677 items (at 1 items/min)
2015-03-24 14:25:39+0000 [xxu46_1] INFO: Crawled 683 pages (at 0 pages/min), scraped 677 items (at 0 items/min)
2015-03-24 14:25:59+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0393> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 14:26:00+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0393>
	{'abstract': u"We provide criteria for deciding whether a given planar curve is an image of a given spatial curve, obtained by a central or a parallel projection with unknown parameters. These criteria reduce the projection problem to a certain modification of the equivalence problem of planar curves under affine and projective transformations. The latter problem can be addressed using Cartan's moving frame method. This leads to a novel algorithmic solution of the projection problem for curves. The computational advantage of the algorithms presented here, in comparison to algorithms based on a straightforward solution, lies in a significant reduction of a number of real parameters that has to be eliminated in order to establish existence or non-existence of a projection that maps a given spatial curve to a given planar curve. The same approach can be used to decide whether a given finite set of ordered points on a plane is an image of a given finite set of ordered points in R^3. The motivation comes from the problem of establishing a correspondence between an object and an image, taken by a camera with unknown position and parameters.",
	 'authors': u'Joseph M. Burdis, Irina A. Kogan,',
	 'category': u'Computer Science ',
	 'date': '2010-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1004.0393',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nObject-image correspondence for curves under finite and affine cameras',
	 'urllink': u'http://arxiv.org/abs/1004.0393'}
2015-03-24 14:26:39+0000 [xxu46_1] INFO: Crawled 684 pages (at 1 pages/min), scraped 678 items (at 1 items/min)
2015-03-24 14:27:39+0000 [xxu46_1] INFO: Crawled 684 pages (at 0 pages/min), scraped 678 items (at 0 items/min)
2015-03-24 14:27:47+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4263> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 14:27:47+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4263>
	{'abstract': u'A facial recognition system is a computer application for automatically identifying or verifying a person from a digital image or a video frame from a video source. One of the way is to do this is by comparing selected facial features from the image and a facial database.It is typically used in security systems and can be compared to other biometrics such as fingerprint or eye iris recognition systems. In this paper we focus on 3-D facial recognition system and biometric facial recognision system. We do critics on facial recognision system giving effectiveness and weaknesses. This paper also introduces scope of recognision system in India.',
	 'authors': u'S.B.Thorat, S. K. Nayak, Jyoti P Dandale,',
	 'category': u'Computer Science ',
	 'date': '2010-5-24',
	 'pdflink': u'http://arxiv.org/pdf/1005.4263',
	 'subjects': u'Multiagent Systems (cs.MA)',
	 'title': u'\nFacial Recognition Technology: An analysis with scope in India',
	 'urllink': u'http://arxiv.org/abs/1005.4263'}
2015-03-24 14:28:39+0000 [xxu46_1] INFO: Crawled 685 pages (at 1 pages/min), scraped 679 items (at 1 items/min)
2015-03-24 14:28:43+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0154> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 14:28:43+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0154>
	{'abstract': u'This paper considers economic intelligence contribution to exploit individual and collective images of change, in ICT design decision-making. Technical devices meeting with real use situations often gives the opportunity to emerge mental images, that a innovation process, through its unprecedented nature, can not anticipate. Although methodologies exists for quality and design project management, the survey we conduct among small ICT publishers, show how they are not very suitable for small firms. This elements taken into account, we try to build a proposition of exploration ? analyze ? sum up process, adapted to this type of actors decisional process.',
	 'authors': u'Pierre Humbert,',
	 'category': u'Computer Science ',
	 'date': '2010-1-31',
	 'pdflink': u'http://arxiv.org/pdf/1002.0154',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u"\nUsages et conception des TIC : Proposition d'un mod\xe8le d'aide \xe0 la  repr\xe9sentation de probl\xe8me de conception",
	 'urllink': u'http://arxiv.org/abs/1002.0154'}
2015-03-24 14:29:39+0000 [xxu46_1] INFO: Crawled 686 pages (at 1 pages/min), scraped 680 items (at 1 items/min)
2015-03-24 14:30:05+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0383> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 14:30:05+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0383>
	{'abstract': u'Dynamic allocation of resources to the emph link in large multiuser networks offers considerable improvement in spectral efficiency. This gain, often referred to as emph, can be cast as double-logarithmic growth of the network throughput with the number of users. In this paper we consider large cognitive networks granted concurrent spectrum access with license-holding users. The primary network affords to share its under-utilized spectrum bands with the secondary users. We assess the optimal multiuser diversity gain in the cognitive networks by quantifying how the sum-rate throughput of the network scales with the number of secondary users. For this purpose we look at the optimal pairing of spectrum bands and secondary users, which is supervised by a central entity fully aware of the instantaneous channel conditions, and show that the throughput of the cognitive network scales double-logarithmically with the number of secondary users () and linearly with the number of available spectrum bands (), i.e., . We then propose a emph spectrum allocation scheme, which does not necessitate a central controller or any information exchange between different secondary users and still obeys the optimal throughput scaling law. This scheme requires that emph secondary transmitter-receiver pairs exchange information bits among themselves. We also show that the aggregate amount of information exchange between secondary transmitter-receiver pairs is equal to . Finally, we show that our distributed scheme guarantees fairness among the secondary users, meaning that they are equally likely to get access to an available spectrum band.',
	 'authors': u'Ali Tajer, Xiaodong Wang,',
	 'category': u'Computer Science ',
	 'date': '2010-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1004.0383',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nMultiuser Diversity Gain in Cognitive Networks',
	 'urllink': u'http://arxiv.org/abs/1004.0383'}
2015-03-24 14:30:39+0000 [xxu46_1] INFO: Crawled 687 pages (at 1 pages/min), scraped 681 items (at 1 items/min)
2015-03-24 14:31:39+0000 [xxu46_1] INFO: Crawled 687 pages (at 0 pages/min), scraped 681 items (at 0 items/min)
2015-03-24 14:31:49+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4262> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 14:31:49+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4262>
	{'abstract': u'Internet faces the problem of congestion due to its increased use. AQM algorithm is a solution to the problem of congestion control in the Internet. There are various existing algorithms that have evolved over the past few years to solve the problem of congestion in IP networks. Congested link causes many problems such as large delay, underutilization of the link and packet drops in burst. There are various existing algorithms that have evolved over the past few years to solve the problem of congestion in IP networks. In this paper, study of these existing algorithms is done. This paper discusses algorithms based on various congestion-metrics and classifies them based on certain factors. This helps in identifying the algorithms that regulate the congestion more effectively.',
	 'authors': u'K.Chitra, G. Padamavathi,',
	 'category': u'Computer Science ',
	 'date': '2010-5-24',
	 'pdflink': u'http://arxiv.org/pdf/1005.4262',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nClassification and Performance of AQM-Based Schemes for Congestion  Avoidance',
	 'urllink': u'http://arxiv.org/abs/1005.4262'}
2015-03-24 14:32:39+0000 [xxu46_1] INFO: Crawled 688 pages (at 1 pages/min), scraped 682 items (at 1 items/min)
2015-03-24 14:33:12+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0145> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 14:33:12+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0145>
	{'abstract': u'We study the problem of identity testing for depth-3 circuits of top fanin k and degree d. We give a new structure theorem for such identities. A direct application of our theorem improves the known deterministic d^-time black-box identity test over rationals (Kayal-Saraf, FOCS 2009) to one that takes d^-time. Our structure theorem essentially says that the number of independent variables in a real depth-3 identity is very small. This theorem settles affirmatively the stronger rank conjectures posed by Dvir-Shpilka (STOC 2005) and Kayal-Saraf (FOCS 2009). Our techniques provide a unified framework that actually beats all known rank bounds and hence gives the best running time (for every field) for black-box identity tests. Our main theorem (almost optimally) pins down the relation between higher dimensional Sylvester-Gallai theorems and the rank of depth-3 identities in a very transparent manner. The existence of this was hinted at by Dvir-Shpilka (STOC 2005), but first proven, for reals, by Kayal-Saraf (FOCS 2009). We introduce the concept of Sylvester-Gallai rank bounds for any field, and show the intimate connection between this and depth-3 identity rank bounds. We also prove the first ever theorem about high dimensional Sylvester-Gallai configurations over any field. Our proofs and techniques are very different from previous results and devise a very interesting ensemble of combinatorics and algebra. The latter concepts are ideal theoretic and involve a new Chinese remainder theorem. Our proof methods explain the structure of any depth-3 identity C: there is a nucleus of C that forms a low rank identity, while the remainder is a high dimensional Sylvester-Gallai configuration.',
	 'authors': u'Nitin Saxena, C. Seshadhri,',
	 'category': u'Computer Science ',
	 'date': '2010-1-31',
	 'pdflink': u'http://arxiv.org/pdf/1002.0145',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nFrom Sylvester-Gallai Configurations to Rank Bounds: Improved Black-box  Identity Test for Depth-3 Circuits',
	 'urllink': u'http://arxiv.org/abs/1002.0145'}
2015-03-24 14:33:39+0000 [xxu46_1] INFO: Crawled 689 pages (at 1 pages/min), scraped 683 items (at 1 items/min)
2015-03-24 14:34:39+0000 [xxu46_1] INFO: Crawled 689 pages (at 0 pages/min), scraped 683 items (at 0 items/min)
2015-03-24 14:34:59+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0381> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 14:34:59+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0381>
	{'abstract': u'The paper presents the gossip interactive Kalman filter (GIKF) for distributed Kalman filtering for networked systems and sensor networks, where inter-sensor communication and observations occur at the same time-scale. The communication among sensors is random; each sensor occasionally exchanges its filtering state information with a neighbor depending on the availability of the appropriate network link. We show that under a weak distributed detectability condition: 1. the GIKF error process remains stochastically bounded, irrespective of the instability properties of the random process dynamics; and 2. the network achieves emph, i.e., the conditional estimation error covariance at a (uniformly) randomly selected sensor converges in distribution to a unique invariant measure on the space of positive semi-definite matrices (independent of the initial state.) To prove these results, we interpret the filtered states (estimates and error covariances) at each node in the GIKF as stochastic particles with local interactions. We analyze the asymptotic properties of the error process by studying as a random dynamical system the associated switched (random) Riccati equation, the switching being dictated by a non-stationary Markov chain on the network graph.',
	 'authors': u'Soummya Kar, Jos\xe9 M. F. Moura,',
	 'category': u'Computer Science ',
	 'date': '2010-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1004.0381',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nGossip and Distributed Kalman Filtering: Weak Consensus under Weak  Detectability',
	 'urllink': u'http://arxiv.org/abs/1004.0381'}
2015-03-24 14:35:39+0000 [xxu46_1] INFO: Crawled 690 pages (at 1 pages/min), scraped 684 items (at 1 items/min)
2015-03-24 14:36:39+0000 [xxu46_1] INFO: Crawled 690 pages (at 0 pages/min), scraped 684 items (at 0 items/min)
2015-03-24 14:36:39+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4244> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 14:36:39+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4244>
	{'abstract': u'Very recently, Hartline and Lucier studied single-parameter mechanism design problems in the Bayesian setting. They proposed a black-box reduction that converted Bayesian approximation algorithms into Bayesian-Incentive-Compatible (BIC) mechanisms while preserving social welfare. It remains a major open question if one can find similar reduction in the more important multi-parameter setting. In this paper, we give positive answer to this question when the prior distribution has finite and small support. We propose a black-box reduction for designing BIC multi-parameter mechanisms. The reduction converts any algorithm into an eps-BIC mechanism with only marginal loss in social welfare. As a result, for combinatorial auctions with sub-additive agents we get an eps-BIC mechanism that achieves constant approximation.',
	 'authors': u'Xiaohui Bei, Zhiyi Huang,',
	 'category': u'Computer Science ',
	 'date': '2010-5-24',
	 'pdflink': u'http://arxiv.org/pdf/1005.4244',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nBayesian Incentive Compatibility via Fractional Assignments',
	 'urllink': u'http://arxiv.org/abs/1005.4244'}
2015-03-24 14:37:39+0000 [xxu46_1] INFO: Crawled 691 pages (at 1 pages/min), scraped 685 items (at 1 items/min)
2015-03-24 14:38:22+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0139> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 14:38:22+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0139>
	{'abstract': u'This paper studies the problem of identification and extraction of flat and nested data records from a given web page. With the explosive growth of information sources available on the World Wide Web, it has become increasingly difficult to identify the relevant pieces of information, since web pages are often cluttered with irrelevant content like advertisements, navigation-panels, copyright notices etc., surrounding the main content of the web page. Hence, it is useful to mine such data regions and data records in order to extract information from such web pages to provide value-added services. Currently available automatic techniques to mine data regions and data records from web pages are still unsatisfactory because of their poor performance. In this paper a novel method to identify and extract the flat and nested data records from the web pages automatically is proposed. It comprises of two steps : (1) Identification and Extraction of the data regions based on visual clues information. (2) Identification and extraction of flat and nested data records from the data region of a web page automatically. For step1, a novel and more effective method is proposed, which finds the data regions formed by all types of tags using visual clues. For step2, a more effective and efficient method namely, Visual Clue based Extraction of web Data (VCED), is proposed, which extracts each record from the data region and identifies it whether it is a flat or nested data record based on visual clue information the area covered by and the number of data items present in each record. Our experimental results show that the proposed technique is effective and better than existing techniques.',
	 'authors': u'P.S Hiremath, Siddu P. Algur,',
	 'category': u'Computer Science ',
	 'date': '2010-1-31',
	 'pdflink': u'http://arxiv.org/pdf/1002.0139',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nExtraction of Flat and Nested Data Records from Web Pages',
	 'urllink': u'http://arxiv.org/abs/1002.0139'}
2015-03-24 14:38:39+0000 [xxu46_1] INFO: Crawled 692 pages (at 1 pages/min), scraped 686 items (at 1 items/min)
2015-03-24 14:39:39+0000 [xxu46_1] INFO: Crawled 692 pages (at 0 pages/min), scraped 686 items (at 0 items/min)
2015-03-24 14:39:58+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0378> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 14:39:58+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0378>
	{'abstract': u'In this paper, a novel method for representation and recognition of the facial expressions in two-dimensional image sequences is presented. We apply a variation of two-dimensional heteroscedastic linear discriminant analysis (2DHLDA) algorithm, as an efficient dimensionality reduction technique, to Gabor representation of the input sequence. 2DHLDA is an extension of the two-dimensional linear discriminant analysis (2DLDA) approach and it removes the equal within-class covariance. By applying 2DHLDA in two directions, we eliminate the correlations between both image columns and image rows. Then, we perform a one-dimensional LDA on the new features. This combined method can alleviate the small sample size problem and instability encountered by HLDA. Also, employing both geometric and appearance features and using an ensemble learning scheme based on data fusion, we create a classifier which can efficiently classify the facial expressions. The proposed method is robust to illumination changes and it can properly represent temporal information as well as subtle changes in facial muscles. We provide experiments on Cohn-Kanade database that show the superiority of the proposed method. KEYWORDS: two-dimensional heteroscedastic linear discriminant analysis (2DHLDA), subspace learning, facial expression analysis, Gabor wavelets, ensemble learning.',
	 'authors': u'Mahmoud Khademi, Mohammad H. Kiapour, Mehran Safayani, Mohammad T. Manzuri, M. Shojaei,',
	 'category': u'Computer Science ',
	 'date': '2010-4-2',
	 'pdflink': u'http://arxiv.org/e-print/1004.0378',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nFacial Expression Representation and Recognition Using 2DHLDA, Gabor  Wavelets, and Ensemble Learning',
	 'urllink': u'http://arxiv.org/abs/1004.0378'}
2015-03-24 14:40:39+0000 [xxu46_1] INFO: Crawled 693 pages (at 1 pages/min), scraped 687 items (at 1 items/min)
2015-03-24 14:41:20+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4216> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 14:41:20+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4216>
	{'abstract': u'Maps are used to describe far-off places . It is an aid for navigation and military strategies. Mapping of the lands are important and the mapping work is based on (i). Natural resource management &amp; development (ii). Information technology ,(iii). Environmental development ,(iv). Facility management and (v). e-governance. The Landuse / Landcover system espoused by almost all Organisations and scientists, engineers and remote sensing community who are involved in mapping of earth surface features, is a system which is derived from the united States Geological Survey (USGS) LULC classification system. The application of RS and GIS involves influential of homogeneous zones, drift analysis of land use integration of new area changes or change detection etc.,National Remote Sensing Agency(NRSA) Govt. of India has devised a generalized LULC classification system respect to the Indian conditions based on the various categories of Earth surface features , resolution of available satellite data, capabilities of sensors and present and future applications. The profusion information of the earth surface offered by the high resolution satellite images for remote sensing applications. Using change detection methodologies to extract the target changes in the areas from high resolution images and rapidly updates geodatabase information processing.Traditionally, classification approaches have focused on per-pixel technologies. Pixels within areas assumed to be automatically homogeneous are analyzed independently.',
	 'authors': u'Y.Babykalpana, K.ThanushKodi,',
	 'category': u'Computer Science ',
	 'date': '2010-5-23',
	 'pdflink': u'http://arxiv.org/pdf/1005.4216',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nClassification of LULC Change Detection using Remotely Sensed Data for  Coimbatore City, Tamilnadu, India',
	 'urllink': u'http://arxiv.org/abs/1005.4216'}
2015-03-24 14:41:39+0000 [xxu46_1] INFO: Crawled 694 pages (at 1 pages/min), scraped 688 items (at 1 items/min)
2015-03-24 14:42:39+0000 [xxu46_1] INFO: Crawled 694 pages (at 0 pages/min), scraped 688 items (at 0 items/min)
2015-03-24 14:43:04+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0136> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 14:43:04+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0136>
	{'abstract': u'This paper proposes a design for a system to generate constraint solvers that are specialised for specific problem models. It describes the design in detail and gives preliminary experimental results showing the feasibility and effectiveness of the approach.',
	 'authors': u'Lars Kotthoff,',
	 'category': u'Computer Science ',
	 'date': '2010-1-31',
	 'pdflink': u'http://arxiv.org/pdf/1002.0136',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nDominion -- A constraint solver generator',
	 'urllink': u'http://arxiv.org/abs/1002.0136'}
2015-03-24 14:43:39+0000 [xxu46_1] INFO: Crawled 695 pages (at 1 pages/min), scraped 689 items (at 1 items/min)
2015-03-24 14:44:39+0000 [xxu46_1] INFO: Crawled 695 pages (at 0 pages/min), scraped 689 items (at 0 items/min)
2015-03-24 14:44:49+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0367> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 14:44:49+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0367>
	{'abstract': u'This paper presents a spatial encryption technique for secured transmission of data in networks. The algorithm is designed to break the ciphered data packets into multiple data which are to be packaged into a spatial template. A secure and efficient mechanism is provided to convey the information that is necessary for obtaining the original data at the receiver-end from its parts in the packets. An authentication code (MAC) is also used to ensure authenticity of every packet.',
	 'authors': u'Sk. Sarif Hassan, Pabitra Pal Choudhury, Sugata Sanyal,',
	 'category': u'Computer Science ',
	 'date': '2010-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1004.0367',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nA Spatial Crypto Technique for Secure Data Transmission',
	 'urllink': u'http://arxiv.org/abs/1004.0367'}
2015-03-24 14:45:39+0000 [xxu46_1] INFO: Crawled 696 pages (at 1 pages/min), scraped 690 items (at 1 items/min)
2015-03-24 14:46:18+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4200> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 14:46:18+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4200>
	{'abstract': u'Applying a sparse constraint on the beam pattern has been suggested to suppress the sidelobe level of a minimum variance distortionless response (MVDR) beamformer. In this letter, we introduce a weighted sparse constraint in the beamformer design to provide a lower sidelobe level and deeper nulls for interference avoidance, as compared with a conventional MVDR beamformer. The proposed beamformer also shows improved robustness against the mismatch between the steering angle and the direction of arrival (DOA) of the desired signal, caused by imperfect estimation of DOA.',
	 'authors': u'Yipeng Liu, Qun Wan, Xiaoli Chu,',
	 'category': u'Computer Science ',
	 'date': '2010-5-23',
	 'pdflink': u'http://arxiv.org/pdf/1005.4200',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nA Robust Beamformer Based on Weighted Sparse Constraint',
	 'urllink': u'http://arxiv.org/abs/1005.4200'}
2015-03-24 14:46:39+0000 [xxu46_1] INFO: Crawled 697 pages (at 1 pages/min), scraped 691 items (at 1 items/min)
2015-03-24 14:47:37+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0134> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 14:47:37+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0134>
	{'abstract': u'This paper presents an evaluation of the design decisions made in four state-of-the-art constraint solvers; Choco, ECLiPSe, Gecode, and Minion. To assess the impact of design decisions, instances of the five problem classes n-Queens, Golomb Ruler, Magic Square, Social Golfers, and Balanced Incomplete Block Design are modelled and solved with each solver. The results of the experiments are not meant to give an indication of the performance of a solver, but rather investigate what influence the choice of algorithms and data structures has. The analysis of the impact of the design decisions focuses on the different ways of memory management, behaviour with increasing problem size, and specialised algorithms for specific types of variables. It also briefly considers other, less significant decisions.',
	 'authors': u'Lars Kotthoff,',
	 'category': u'Computer Science ',
	 'date': '2010-1-31',
	 'pdflink': u'http://arxiv.org/pdf/1002.0134',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nConstraint solvers: An empirical evaluation of design decisions',
	 'urllink': u'http://arxiv.org/abs/1002.0134'}
2015-03-24 14:47:39+0000 [xxu46_1] INFO: Crawled 698 pages (at 1 pages/min), scraped 692 items (at 1 items/min)
2015-03-24 14:48:39+0000 [xxu46_1] INFO: Crawled 698 pages (at 0 pages/min), scraped 692 items (at 0 items/min)
2015-03-24 14:49:15+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0366> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 14:49:15+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0366>
	{'abstract': u'Several new applications and a number of new mathematical techniques have increased the research on error-correcting codes in the Lee metric in the last decade. In this work we consider several coding problems and constructions of error-correcting codes in the Lee metric. First, we consider constructions of dense error-correcting codes in relatively small dimensions over small alphabets. The second problem we solve is construction of diametric perfect codes with minimum distance four. We will construct such codes over various lengths and alphabet sizes. The third problem is to transfer an n-dimensional Lee sphere with large radius into a shape, with the same volume, located in a relatively small box. Hadamard matrices play an essential role in the solutions for all three problems. A construction of codes based on Hadamard matrices will start our discussion. These codes approach the sphere packing bound for very high rate range and appear to be the best known codes over some sets of parameters.',
	 'authors': u'Tuvi Etzion, Alexander Vardy, Eitan Yaakobi,',
	 'category': u'Computer Science ',
	 'date': '2010-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1004.0366',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nDense Error-Correcting Codes in the Lee Metric',
	 'urllink': u'http://arxiv.org/abs/1004.0366'}
2015-03-24 14:49:39+0000 [xxu46_1] INFO: Crawled 699 pages (at 1 pages/min), scraped 693 items (at 1 items/min)
2015-03-24 14:50:39+0000 [xxu46_1] INFO: Crawled 699 pages (at 0 pages/min), scraped 693 items (at 0 items/min)
2015-03-24 14:50:39+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4178> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 14:50:39+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4178>
	{'abstract': u'Regenerating codes are a class of distributed storage codes that optimally trade the bandwidth needed for repair of a failed node with the amount of data stored per node of the network. Minimum Storage Regenerating (MSR) codes minimize first, the amount of data stored per node, and then the repair bandwidth, while Minimum Bandwidth Regenerating (MBR) codes carry out the minimization in the reverse order. An [n, k, d] regenerating code permits the data to be recovered by connecting to any k of the n nodes in the network, while requiring that repair of a failed node be made possible by connecting (using links of lesser capacity) to any d nodes. Previous, explicit and general constructions of exact-regenerating codes have been confined to the case n=d+1. In this paper, we present optimal, explicit constructions of MBR codes for all feasible values of [n, k, d] and MSR codes for all [n, k, d &gt;= 2k-2], using a product-matrix framework. The particular product-matrix nature of the constructions is shown to significantly simplify system operation. To the best of our knowledge, these are the first constructions of exact-regenerating codes that allow the number n of nodes in the distributed storage network, to be chosen independent of the other parameters. The paper also contains a simpler description, in the product-matrix framework, of a previously constructed MSR code in which the parameter d satisfies [n=d+1, k, d &gt;= 2k-1].',
	 'authors': u'K. V. Rashmi, Nihar B. Shah, P. Vijay Kumar,',
	 'category': u'Computer Science ',
	 'date': '2010-5-23',
	 'pdflink': u'http://arxiv.org/pdf/1005.4178',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOptimal Exact-Regenerating Codes for Distributed Storage at the MSR and  MBR Points via a Product-Matrix Construction',
	 'urllink': u'http://arxiv.org/abs/1005.4178'}
2015-03-24 14:51:39+0000 [xxu46_1] INFO: Crawled 700 pages (at 1 pages/min), scraped 694 items (at 1 items/min)
2015-03-24 14:51:56+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0125> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 14:51:56+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0125>
	{'abstract': u'A local algorithm is a distributed algorithm that completes after a constant number of synchronous communication rounds. We present local approximation algorithms for the minimum dominating set problem and the maximum matching problem in 2-coloured and weakly 2-coloured graphs. In a weakly 2-coloured graph, both problems admit a local algorithm with the approximation factor , where is the maximum degree of the graph. We also give a matching lower bound proving that there is no local algorithm with a better approximation factor for either of these problems. Furthermore, we show that the stronger assumption of a 2-colouring does not help in the case of the dominating set problem, but there is a local approximation scheme for the maximum matching problem in 2-coloured graphs.',
	 'authors': u'Matti \xc5strand, Valentin Polishchuk, Joel Rybicki, Jukka Suomela, Jara Uitto,',
	 'category': u'Computer Science ',
	 'date': '2010-1-31',
	 'pdflink': u'http://arxiv.org/pdf/1002.0125',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nLocal algorithms in (weakly) coloured graphs',
	 'urllink': u'http://arxiv.org/abs/1002.0125'}
2015-03-24 14:52:39+0000 [xxu46_1] INFO: Crawled 701 pages (at 1 pages/min), scraped 695 items (at 1 items/min)
2015-03-24 14:53:31+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0351> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 14:53:31+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0351>
	{'abstract': u'We consider the problem of constructing a single spanning tree for the single-source buy-at-bulk network design problem for doubling-dimension graphs. We compute a spanning tree to route a set of demands (or data) along a graph to or from a designated root node. The demands could be aggregated at (or symmetrically distributed to) intermediate nodes where the fusion-cost is specified by a non-negative concave function . We describe a novel approach for developing an oblivious spanning tree in the sense that it is independent of the number of data sources (or demands) and cost function at intermediate nodes. To our knowledge, this is the first paper to propose a single spanning tree solution to this problem (as opposed to multiple overlay trees). There has been no prior work where the tree is oblivious to both the fusion cost function and the set of sources (demands). We present a deterministic, polynomial-time algorithm for constructing a spanning tree in low doubling graphs that guarantees -approximation over the optimal cost, where is the diameter of the graph and the total number of nodes. With constant fusion-cost function our spanning tree gives a -approximation for every Steiner tree to the root.',
	 'authors': u'Srivathsan Srinivasagopalan, Costas Busch, S.S. Iyengar,',
	 'category': u'Computer Science ',
	 'date': '2010-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1004.0351',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nAn Oblivious Spanning Tree for Buy-at-Bulk Network Design Problems',
	 'urllink': u'http://arxiv.org/abs/1004.0351'}
2015-03-24 14:53:39+0000 [xxu46_1] INFO: Crawled 702 pages (at 1 pages/min), scraped 696 items (at 1 items/min)
2015-03-24 14:54:33+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4159> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 14:54:33+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4159>
	{'abstract': u'An important problem in computational social choice theory is the complexity of undesirable behavior among agents, such as control, manipulation, and bribery in election systems. These kinds of voting strategies are often tempting at the individual level but disastrous for the agents as a whole. Creating election systems where the determination of such strategies is difficult is thus an important goal. An interesting set of elections is that of scoring protocols. Previous work in this area has demonstrated the complexity of misuse in cases involving a fixed number of candidates, and of specific election systems on unbounded number of candidates such as Borda. In contrast, we take the first step in generalizing the results of computational complexity of election misuse to cases of infinitely many scoring protocols on an unbounded number of candidates. Interesting families of systems include -approval and -veto elections, in which voters distinguish candidates from the candidate set. Our main result is to partition the problems of these families based on their complexity. We do so by showing they are polynomial-time computable, NP-hard, or polynomial-time equivalent to another problem of interest. We also demonstrate a surprising connection between manipulation in election systems and some graph theory problems.',
	 'authors': u'Andrew Lin,',
	 'category': u'Computer Science ',
	 'date': '2010-5-23',
	 'pdflink': u'http://arxiv.org/pdf/1005.4159',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nThe Complexity of Manipulating $k$-Approval Elections',
	 'urllink': u'http://arxiv.org/abs/1005.4159'}
2015-03-24 14:54:39+0000 [xxu46_1] INFO: Crawled 703 pages (at 1 pages/min), scraped 697 items (at 1 items/min)
2015-03-24 14:55:39+0000 [xxu46_1] INFO: Crawled 703 pages (at 0 pages/min), scraped 697 items (at 0 items/min)
2015-03-24 14:55:56+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0123> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 14:55:56+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0123>
	{'abstract': u'In a bi-directional relay channel, a pair of nodes wish to exchange independent messages over a shared wireless half-duplex channel with the help of relays. Recent work has mostly considered information theoretic limits of the bi-directional relay channel with two terminal nodes (or end users) and one relay. In this work we consider bi-directional relaying with one base station, multiple terminal nodes and one relay, all of which operate in half-duplex modes. We assume that each terminal node communicates with the base-station in a bi-directional fashion through the relay and do not place any restrictions on the channels between the users, relays and base-stations; that is, each node has a direct link with every other node. Our contributions are three-fold: 1) the introduction of four new temporal protocols which fully exploit the two-way nature of the data and outperform simple routing or multi-hop communication schemes by carefully combining network coding, random binning and user cooperation which exploit over-heard and own-message side information, 2) derivations of inner and outer bounds on the capacity region of the discrete-memoryless multi-pair two-way network, and 3) a numerical evaluation of the obtained achievable rate regions and outer bounds in Gaussian noise which illustrate the performance of the proposed protocols compared to simpler schemes, to each other, to the outer bounds, which highlight the relative gains achieved by network coding, random binning and compress-and-forward-type cooperation between terminal nodes.',
	 'authors': u'Sang Joon Kim, Besma Smida, Natasha Devroye,',
	 'category': u'Computer Science ',
	 'date': '2010-1-31',
	 'pdflink': u'http://arxiv.org/pdf/1002.0123',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nAchievable rate regions and outer bounds for a multi-pair bi-directional  relay network',
	 'urllink': u'http://arxiv.org/abs/1002.0123'}
2015-03-24 14:56:39+0000 [xxu46_1] INFO: Crawled 704 pages (at 1 pages/min), scraped 698 items (at 1 items/min)
2015-03-24 14:57:15+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0346> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 14:57:15+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0346>
	{'abstract': u'This paper addresses network code design for robust transmission of sources over an orthogonal two-hop wireless network with a broadcasting relay. The network consists of multiple sources and destinations in which each destination, benefiting the relay signal, intends to decode a subset of the sources. Two special instances of this network are orthogonal broadcast relay channel and the orthogonal multiple access relay channel. The focus is on complexity constrained scenarios, e.g., for wireless sensor networks, where channel coding is practically imperfect. Taking a source-channel and network coding approach, we design the network code (mapping) at the relay such that the average reconstruction distortion at the destinations is minimized. To this end, by decomposing the distortion into its components, an efficient design algorithm is proposed. The resulting network code is nonlinear and substantially outperforms the best performing linear network code. A motivating formulation of a family of structured nonlinear network codes is also presented. Numerical results and comparison with linear network coding at the relay and the corresponding distortion-power bound demonstrate the effectiveness of the proposed schemes and a promising research direction.',
	 'authors': u'Roghayeh Joda, Farshad Lahouti,',
	 'category': u'Computer Science ',
	 'date': '2010-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1004.0346',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nNetwork Code Design for Orthogonal Two-hop Network with Broadcasting  Relay: A Joint Source-Channel-Network Coding Approach',
	 'urllink': u'http://arxiv.org/abs/1004.0346'}
2015-03-24 14:57:39+0000 [xxu46_1] INFO: Crawled 705 pages (at 1 pages/min), scraped 699 items (at 1 items/min)
2015-03-24 14:58:35+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4155> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 14:58:35+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4155>
	{'abstract': u"In STOC'95 cite Arya et al. showed that for any set of points in , a -spanner with diameter at most 2 (respectively, 3) and edges (resp., edges) can be built in time. Moreover, it was shown in cite that for any , one can build in time a -spanner with diameter at most and edges. The function is the inverse of a certain function at the th level of the primitive recursive hierarchy, where , ldots, etc. It is also known cite that if one allows quadratic time then these bounds can be improved. Specifically, for any , a -spanner with diameter at most and edges can be constructed in time cite. A major open problem in this area is whether one can construct within time a -spanner with diameter at most and edges. In this paper we answer this question in the affirmative. Moreover, in fact, we provide a stronger result. Specifically, we show that for any , a -spanner with diameter at most and edges can be built in optimal time . The tradeoff between the diameter and number of edges of our spanners is tight up to constant factors in the entire range of parameters.",
	 'authors': u'Shay Solomon,',
	 'category': u'Computer Science ',
	 'date': '2010-5-22',
	 'pdflink': u'http://arxiv.org/pdf/1005.4155',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nAn Optimal-Time Construction of Euclidean Sparse Spanners with Tiny  Diameter',
	 'urllink': u'http://arxiv.org/abs/1005.4155'}
2015-03-24 14:58:39+0000 [xxu46_1] INFO: Crawled 706 pages (at 1 pages/min), scraped 700 items (at 1 items/min)
2015-03-24 14:59:39+0000 [xxu46_1] INFO: Crawled 706 pages (at 0 pages/min), scraped 700 items (at 0 items/min)
2015-03-24 15:00:04+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0110> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 15:00:04+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0110>
	{'abstract': u'We consider the estimation of a sparse parameter vector from measurements corrupted by white Gaussian noise. Our focus is on unbiased estimation as a setting under which the difficulty of the problem can be quantified analytically. We show that there are infinitely many unbiased estimators but none of them has uniformly minimum mean-squared error. We then provide lower and upper bounds on the Barankin bound, which describes the performance achievable by unbiased estimators. These bounds are used to predict the threshold region of practical estimators.',
	 'authors': u'Alexander Jung, Zvika Ben-Haim, Franz Hlawatsch, Yonina C. Eldar,',
	 'category': u'Computer Science ',
	 'date': '2010-2-1',
	 'pdflink': u'http://arxiv.org/pdf/1002.0110',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOn Unbiased Estimation of Sparse Vectors Corrupted by Gaussian Noise',
	 'urllink': u'http://arxiv.org/abs/1002.0110'}
2015-03-24 15:00:39+0000 [xxu46_1] INFO: Crawled 707 pages (at 1 pages/min), scraped 701 items (at 1 items/min)
2015-03-24 15:01:39+0000 [xxu46_1] INFO: Crawled 707 pages (at 0 pages/min), scraped 701 items (at 0 items/min)
2015-03-24 15:01:50+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0334> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 15:01:50+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0334>
	{'abstract': u"We study electoral campaign management scenarios in which an external party can buy votes, i.e., pay the voters to promote its preferred candidate in their preference rankings. The external party's goal is to make its preferred candidate a winner while paying as little as possible. We describe a 2-approximation algorithm for this problem for a large class of electoral systems known as scoring rules. Our result holds even for weighted voters, and has applications for campaign management in commercial settings. We also give approximation algorithms for our problem for two Condorcet-consistent rules, namely, the Copeland rule and maximin.",
	 'authors': u'Edith Elkind, Piotr Faliszewski,',
	 'category': u'Computer Science ',
	 'date': '2010-3-25',
	 'pdflink': u'http://arxiv.org/pdf/1004.0334',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nApproximation Algorithms for Campaign Management',
	 'urllink': u'http://arxiv.org/abs/1004.0334'}
2015-03-24 15:02:39+0000 [xxu46_1] INFO: Crawled 708 pages (at 1 pages/min), scraped 702 items (at 1 items/min)
2015-03-24 15:03:31+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4123> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 15:03:31+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4123>
	{'abstract': u'Agile Methods are designed for customization; they offer an organization or a team the flexibility to adopt a set of principles and practices based on their culture and values. While that flexibility is consistent with the agile philosophy, it can lead to the adoption of principles and practices that can be sub-optimal relative to the desired objectives. We question then, how can one determine if adopted practices are "in sync" with the identified principles, and to what extent those principles support organizational objectives? In this research, we focus on assessing the "goodness" of an agile method adopted by an organization based on (1) its adequacy, (2) the capability of the organization to provide the supporting environment to competently implement the method, and (3) its effectiveness. To guide our assessment, we propose the Objectives, Principles and Practices (OPP) framework. The design of the OPP framework revolves around the identification of the agile objectives, principles that support the achievement of those objectives, and practices that reflect the "spirit" of those principles. Well-defined linkages between the objectives and principles, and between the principles and practices are also established to support the assessment process. We traverse these linkages in a top-down fashion to assess adequacy and a bottom-up fashion to assess capability and effectiveness. This is a work-in-progress paper, outlining our proposed research, preliminary results and future directions.',
	 'authors': u'Shvetha Soundararajan, James. D. Arthur,',
	 'category': u'Computer Science ',
	 'date': '2010-5-22',
	 'pdflink': u'http://arxiv.org/pdf/1005.4123',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nA Structured Framework for Assessing the "Goodness" of Agile Methods',
	 'urllink': u'http://arxiv.org/abs/1005.4123'}
2015-03-24 15:03:39+0000 [xxu46_1] INFO: Crawled 709 pages (at 1 pages/min), scraped 703 items (at 1 items/min)
2015-03-24 15:04:39+0000 [xxu46_1] INFO: Crawled 709 pages (at 0 pages/min), scraped 703 items (at 0 items/min)
2015-03-24 15:05:09+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0108> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 15:05:09+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0108>
	{'abstract': u'This work was inspired by author experiences with a telescope scheduling. Author long time goal is to develop and further extend software for an autonomous observatory. The software shall provide users with all the facilities they need to take scientific images of the night sky, cooperate with other autonomous observatories, and possibly more. This works shows how genetic algorithm can be used for scheduling of a single observatory, as well as network of observatories.',
	 'authors': u'Petr Kubanek,',
	 'category': u'Computer Science ',
	 'date': '2010-1-31',
	 'pdflink': u'http://arxiv.org/pdf/1002.0108',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nGenetic algorithm for robotic telescope scheduling',
	 'urllink': u'http://arxiv.org/abs/1002.0108'}
2015-03-24 15:05:39+0000 [xxu46_1] INFO: Crawled 710 pages (at 1 pages/min), scraped 704 items (at 1 items/min)
2015-03-24 15:06:15+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0313> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 15:06:15+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0313>
	{'abstract': u'The area of networking games has had a growing impact on wireless networks. This reflects the recognition in the important scaling advantages that the service providers can benefit from by increasing the autonomy of mobiles in decision making. This may however result in inefficiencies that are inherent to equilibria in non-cooperative games. Due to the concern for efficiency, centralized protocols keep being considered and compared to decentralized ones. From the point of view of the network architecture, this implies the co-existence of network-centric and terminal centric radio resource management schemes. Instead of taking part within the debate among the supporters of each solution, we propose in this paper hybrid schemes where the wireless users are assisted in their decisions by the network that broadcasts aggregated load information. We derive the utilities related to the Quality of Service (QoS) perceived by the users and develop a Bayesian framework to obtain the equilibria. Numerical results illustrate the advantages of using our hybrid game framework in an association problem in a network composed of HSDPA and 3G LTE systems.',
	 'authors': u'Salah Eddine Elayoubi, Eitan Altman, Majed Haddad, Zwi Altman,',
	 'category': u'Computer Science ',
	 'date': '2010-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1004.0313',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nA hybrid decision approach for the association problem in heterogeneous  networks',
	 'urllink': u'http://arxiv.org/abs/1004.0313'}
2015-03-24 15:06:39+0000 [xxu46_1] INFO: Crawled 711 pages (at 1 pages/min), scraped 705 items (at 1 items/min)
2015-03-24 15:07:39+0000 [xxu46_1] INFO: Crawled 711 pages (at 0 pages/min), scraped 705 items (at 0 items/min)
2015-03-24 15:07:54+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4122> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 15:07:54+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4122>
	{'abstract': u'A new complete invariant for acyclic graphs is presented',
	 'authors': u'A. Prolubnikov,',
	 'category': u'Computer Science ',
	 'date': '2010-5-22',
	 'pdflink': u'http://arxiv.org/e-print/1005.4122',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nOn a new complete invariant of acyclic graphs',
	 'urllink': u'http://arxiv.org/abs/1005.4122'}
2015-03-24 15:08:39+0000 [xxu46_1] INFO: Crawled 712 pages (at 1 pages/min), scraped 706 items (at 1 items/min)
2015-03-24 15:09:24+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0102> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 15:09:24+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0102>
	{'abstract': u"In this paper we introduce a new method called alpha-Discounting Multi-Criteria Decision Making ( alpha-D MCDM), which is an aletrnative and extension of Saaty's Analytical Hierarchy Process (AHP). It works for any set of preferences that can be transformed into a system of homogeneous linear equations. A degree of consistency (and implicitly a degree of inconsistency) of a decision-making problem are defined. alpha-D MCDM is then generalized to a set of preferences that can be transformed into a system of linear and/or non-linear equations and/or inequalities. Many consistent, weak inconsistent, and strong inconsistent examples are given.",
	 'authors': u'Florentin Smarandache,',
	 'category': u'Computer Science ',
	 'date': '2010-1-31',
	 'pdflink': u'http://arxiv.org/pdf/1002.0102',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\n\u03b1-Discounting Multi-Criteria Decision Making (\u03b1-D MCDM)',
	 'urllink': u'http://arxiv.org/abs/1002.0102'}
2015-03-24 15:09:39+0000 [xxu46_1] INFO: Crawled 713 pages (at 1 pages/min), scraped 707 items (at 1 items/min)
2015-03-24 15:10:39+0000 [xxu46_1] INFO: Crawled 713 pages (at 0 pages/min), scraped 707 items (at 0 items/min)
2015-03-24 15:11:03+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0269> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 15:11:03+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0269>
	{'abstract': u"Providing security guarantees for wireless communication is critically important for today's applications. While previous work in this area has concentrated on radio frequency (RF) channels, providing security guarantees for RF channels is inherently difficult because they are prone to rapid variations due small scale fading. Wireless optical communication, on the other hand, is inherently more secure than RF communication due to the intrinsic aspects of the signal propagation in the optical and near-optical frequency range. In this paper, secure communication over wireless optical links is examined by studying the secrecy capacity of a direct detection system. For the degraded Poisson wiretap channel, a closed-form expression of the secrecy capacity is given. A complete characterization of the general rate-equivocation region is also presented. For achievability, an optimal code is explicitly constructed by using the structured code designed by Wyner for the Poisson channel. The converse is proved in two different ways: the first method relies only on simple properties of the conditional expectation and basic information theoretical inequalities, whereas the second method hinges on the recent link established between minimum mean square estimation and mutual information in Poisson channels.",
	 'authors': u'Amine Laourine, Aaron B. Wagner,',
	 'category': u'Computer Science ',
	 'date': '2010-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1004.0269',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nThe Degraded Poisson Wiretap Channel',
	 'urllink': u'http://arxiv.org/abs/1004.0269'}
2015-03-24 15:11:39+0000 [xxu46_1] INFO: Crawled 714 pages (at 1 pages/min), scraped 708 items (at 1 items/min)
2015-03-24 15:12:18+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4118> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 15:12:18+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4118>
	{'abstract': u"The ability to efficiently and accurately detect objects plays a very crucial role for many computer vision tasks. Recently, offline object detectors have shown a tremendous success. However, one major drawback of offline techniques is that a complete set of training data has to be collected beforehand. In addition, once learned, an offline detector can not make use of newly arriving data. To alleviate these drawbacks, online learning has been adopted with the following objectives: (1) the technique should be computationally and storage efficient; (2) the updated classifier must maintain its high classification accuracy. In this paper, we propose an effective and efficient framework for learning an adaptive online greedy sparse linear discriminant analysis (GSLDA) model. Unlike many existing online boosting detectors, which usually apply exponential or logistic loss, our online algorithm makes use of LDA's learning criterion that not only aims to maximize the class-separation criterion but also incorporates the asymmetrical property of training data distributions. We provide a better alternative for online boosting algorithms in the context of training a visual object detector. We demonstrate the robustness and efficiency of our methods on handwriting digit and face data sets. Our results confirm that object detection tasks benefit significantly when trained in an online manner.",
	 'authors': u'Sakrapee Paisitkriangkrai, Chunhua Shen, Jian Zhang,',
	 'category': u'Computer Science ',
	 'date': '2010-5-22',
	 'pdflink': u'http://arxiv.org/pdf/1005.4118',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nIncremental Training of a Detector Using Online Sparse  Eigen-decomposition',
	 'urllink': u'http://arxiv.org/abs/1005.4118'}
2015-03-24 15:12:39+0000 [xxu46_1] INFO: Crawled 715 pages (at 1 pages/min), scraped 709 items (at 1 items/min)
2015-03-24 15:13:39+0000 [xxu46_1] INFO: Crawled 715 pages (at 0 pages/min), scraped 709 items (at 0 items/min)
2015-03-24 15:13:45+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0097> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 15:13:45+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0097>
	{'abstract': u'We investigate the construction of prefix-free and fix-free codes with specified codeword compositions. We present a polynomial time algorithm which constructs a fix-free code with the same codeword compositions as a given code for a special class of codes called distinct codes. We consider the construction of optimal fix-free codes which minimizes the average codeword cost for general letter costs with uniform distribution of the codewords and present an approximation algorithm to find a near optimal fix-free code with a given constant cost.',
	 'authors': u'Ali Kakhbod, Morteza Zadimoghaddam,',
	 'category': u'Computer Science ',
	 'date': '2010-1-30',
	 'pdflink': u'http://arxiv.org/pdf/1002.0097',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOn the Construction of Prefix-Free and Fix-Free Codes with Specified  Codeword Compositions',
	 'urllink': u'http://arxiv.org/abs/1002.0097'}
2015-03-24 15:14:39+0000 [xxu46_1] INFO: Crawled 716 pages (at 1 pages/min), scraped 710 items (at 1 items/min)
2015-03-24 15:15:12+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0263> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 15:15:12+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0263>
	{'abstract': u"Since J. Mitola's work in 1992, Software Defined Radios (SDRs) have been quite a hot topic in wireless systems research. Though many notable achievements were reported in the field, the scarcity of computational power on general purpose CPUs has always constrained their wide adoption in production environments. If conveniently applied within an SDR context, classical concepts known in computer science as space/time tradeoffs can be extremely helpful when trying to mitigate this problem. Inspired by and building on those concepts, this paper presents a novel SDR implementation technique which we call Memory Acceleration (MA) that makes extensive use of the memory resources available on a general purpose computing system, in order to accelerate signal computation. MA can provide substantial acceleration factors when applied to conventional SDRs without reducing their peculiar flexibility. As a practical proof of this, an example of MA applied in the real world to the ETSI DVB-T Viterbi decoder is provided. Actually MA is shown able to provide, when applied to such Viterbi decoder, an acceleration factor of 10.4x, with no impact on error correction performances of the decoder and by making no use of any other typical performance enhancement techniques such as low level (Assembler) programming or parallel computation, which though remain compatible with MA. Opportunity for extending the MA approach to the entire radio system, thus implementing what we call a Memory-Based Software Defined Radio (MB-SDR) is finally considered and discussed.",
	 'authors': u'Vincenzo Pellegrini, Luca Rose, Mario Di Dio,',
	 'category': u'Computer Science ',
	 'date': '2010-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1004.0263',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nOn Memory Accelerated Signal Processing within Software Defined Radios',
	 'urllink': u'http://arxiv.org/abs/1004.0263'}
2015-03-24 15:15:39+0000 [xxu46_1] INFO: Crawled 717 pages (at 1 pages/min), scraped 711 items (at 1 items/min)
2015-03-24 15:15:59+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4115> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 15:15:59+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4115>
	{'abstract': u'Electoral control models ways of changing the outcome of an election via such actions as adding/deleting/partitioning either candidates or voters. These actions modify an election\'s participation structure and aim at either making a favorite candidate win ("constructive control") or prevent a despised candidate from winning ("destructive control"), which yields a total of 22 standard control scenarios. To protect elections from such control attempts, computational complexity has been used to show that electoral control, though not impossible, is computationally prohibitive. Among natural voting systems with a polynomial-time winner problem, the two systems with the highest number of proven resistances to control types (namely 19 out of 22) are "sincere-strategy preference-based approval voting" (SP-AV, a modification of a system proposed by Brams and Sanver) and fallback voting. Both are hybrid systems; e.g., fallback voting combines approval with Bucklin voting. In this paper, we study the control complexity of Bucklin voting itself and show that it behaves equally well in terms of control resistance for the 20 cases investigated so far. As Bucklin voting is a special case of fallback voting, all resistances shown for Bucklin voting in this paper strengthen the corresponding resistance for fallback voting.',
	 'authors': u'G\xe1bor Erd\xe9lyi, Lena Piras, J\xf6rg Rothe,',
	 'category': u'Computer Science ',
	 'date': '2010-5-22',
	 'pdflink': u'http://arxiv.org/pdf/1005.4115',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nBucklin Voting is Broadly Resistant to Control',
	 'urllink': u'http://arxiv.org/abs/1005.4115'}
2015-03-24 15:16:39+0000 [xxu46_1] INFO: Crawled 718 pages (at 1 pages/min), scraped 712 items (at 1 items/min)
2015-03-24 15:17:39+0000 [xxu46_1] INFO: Crawled 718 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2015-03-24 15:17:40+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0063> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 15:17:40+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0063>
	{'abstract': u'In this article we define a new reducibility based on the enumeration orders of r.e. sets.',
	 'authors': u'Ali Akbar Safilian, Farzad Didehvar,',
	 'category': u'Computer Science ',
	 'date': '2010-1-30',
	 'pdflink': u'http://arxiv.org/pdf/1002.0063',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nEnumeration Order Reducibility',
	 'urllink': u'http://arxiv.org/abs/1002.0063'}
2015-03-24 15:18:39+0000 [xxu46_1] INFO: Crawled 719 pages (at 1 pages/min), scraped 713 items (at 1 items/min)
2015-03-24 15:19:27+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0259> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 15:19:27+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0259>
	{'abstract': u'Assessing gameplay experience for gaze interaction games is a challenging task. For this study, a gaze interaction Half-Life 2 game modification was created that allowed eye tracking control. The mod was deployed during an experiment at Dreamhack 2007, where participants had to play with gaze navigation and afterwards rate their gameplay experience. The results show low tension and negative affects scores on the gameplay experience questionnaire as well as high positive challenge, immersion and flow ratings. The correlation between spatial presence and immersion for gaze interaction was high and yields further investigation. It is concluded that gameplay experience can be correctly assessed with the methodology presented in this paper.',
	 'authors': u'Lennart E. Nacke, Sophie Stellmach, Dennis Sasse, Craig A. Lindley,',
	 'category': u'Computer Science ',
	 'date': '2010-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1004.0259',
	 'subjects': u'Human-Computer Interaction (cs.HC)',
	 'title': u'\nGameplay experience in a gaze interaction game',
	 'urllink': u'http://arxiv.org/abs/1004.0259'}
2015-03-24 15:19:39+0000 [xxu46_1] INFO: Crawled 720 pages (at 1 pages/min), scraped 714 items (at 1 items/min)
2015-03-24 15:20:39+0000 [xxu46_1] INFO: Crawled 720 pages (at 0 pages/min), scraped 714 items (at 0 items/min)
2015-03-24 15:21:10+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4103> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 15:21:10+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4103>
	{'abstract': u'Object detection is one of the key tasks in computer vision. The cascade framework of Viola and Jones has become the de facto standard. A classifier in each node of the cascade is required to achieve extremely high detection rates, instead of low overall classification error. Although there are a few reported methods addressing this requirement in the context of object detection, there is no a principled feature selection method that explicitly takes into account this asymmetric node learning objective. We provide such a boosting algorithm in this work. It is inspired by the linear asymmetric classifier (LAC) of Wu et al. in that our boosting algorithm optimizes a similar cost function. The new totally-corrective boosting algorithm is implemented by the column generation technique in convex optimization. Experimental results on face detection suggest that our proposed boosting algorithms can improve the state-of-the-art methods in detection performance.',
	 'authors': u'Chunhua Shen, Peng Wang, Hanxi Li,',
	 'category': u'Computer Science ',
	 'date': '2010-5-22',
	 'pdflink': u'http://arxiv.org/pdf/1005.4103',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nLACBoost and FisherBoost: Optimally Building Cascade Classifiers',
	 'urllink': u'http://arxiv.org/abs/1005.4103'}
2015-03-24 15:21:39+0000 [xxu46_1] INFO: Crawled 721 pages (at 1 pages/min), scraped 715 items (at 1 items/min)
2015-03-24 15:22:39+0000 [xxu46_1] INFO: Crawled 721 pages (at 0 pages/min), scraped 715 items (at 0 items/min)
2015-03-24 15:22:52+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0049> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 15:22:52+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0049>
	{'abstract': u'Acute shortage of good, clean drinking water is a major problem for most developing countries of the world. In most cases, ponds, streams, wells and rivers are often polluted that they are unsafe for direct use as drinking water &gt;.Often water sources are brackish and or contain harmful bacteria. Therefore cannot be used for drinking .In addition there are many coastal locations where sea water is abundant but potable water is not available. Solar distillation is one of the important methods of utilizing solar energy for the supply of potable water to small communities where natural supply of fresh water is inadequate or of poor quality .In this direction an experimental performance analysis was carried out on a single basin still compared with FPC coupled one. Test were carried out for different water samples namely borewell water, sea water, river water for a water depth of 20 mm',
	 'authors': u'A.M. Rajesh, K.N. Bharath,',
	 'category': u'Computer Science ',
	 'date': '2010-1-30',
	 'pdflink': u'http://arxiv.org/pdf/1002.0049',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nSolar Still Coupled With Solar Collector and Storage Tank',
	 'urllink': u'http://arxiv.org/abs/1002.0049'}
2015-03-24 15:23:39+0000 [xxu46_1] INFO: Crawled 722 pages (at 1 pages/min), scraped 716 items (at 1 items/min)
2015-03-24 15:24:04+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0258> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 15:24:04+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0258>
	{'abstract': u"Visualizing gaze data is an effective way for the quick interpretation of eye tracking results. This paper presents a study investigation benefits and limitations of visual gaze analysis among eye tracking professionals and researchers. The results were used to create a tool for visual gaze analysis within a Master's project.",
	 'authors': u'Sophie Stellmach, Lennart E. Nacke, Raimund Dachselt, Craig A. Lindley,',
	 'category': u'Computer Science ',
	 'date': '2010-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1004.0258',
	 'subjects': u'Human-Computer Interaction (cs.HC)',
	 'title': u'\nTrends and Techniques in Visual Gaze Analysis',
	 'urllink': u'http://arxiv.org/abs/1004.0258'}
2015-03-24 15:24:39+0000 [xxu46_1] INFO: Crawled 723 pages (at 1 pages/min), scraped 717 items (at 1 items/min)
2015-03-24 15:25:17+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4044> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 15:25:17+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4044>
	{'abstract': u'In this paper we describe a procedure to reduce the size of the input feature vector. A complex pattern recognition problem like face recognition involves huge dimension of input feature vector. To reduce that dimension here we have used eigenspace projection (also called as Principal Component Analysis), which is basically transformation of space. To reduce further we have applied feature selection method to select indispensable features, which will remain in the final feature vectors. Features those are not selected are removed from the final feature vector considering them as redundant or superfluous. For selection of features we have used the concept of reduct and core from rough set theory. This method has shown very good performance. It is worth to mention that in some cases the recognition rate increases with the decrease in the feature vector dimension.',
	 'authors': u'Debotosh Bhattacharjee, Dipak Kumar Basu, Mita Nasipuri, M. Kundu,',
	 'category': u'Computer Science ',
	 'date': '2010-5-21',
	 'pdflink': u'http://arxiv.org/pdf/1005.4044',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nReduction of Feature Vectors Using Rough Set Theory for Human Face  Recognition',
	 'urllink': u'http://arxiv.org/abs/1005.4044'}
2015-03-24 15:25:39+0000 [xxu46_1] INFO: Crawled 724 pages (at 1 pages/min), scraped 718 items (at 1 items/min)
2015-03-24 15:26:39+0000 [xxu46_1] INFO: Crawled 724 pages (at 0 pages/min), scraped 718 items (at 0 items/min)
2015-03-24 15:26:46+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0046> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 15:26:46+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0046>
	{'abstract': u'This paper addresses the uniform random generation of words from a context-free language (over an alphabet of size ), while constraining every letter to a targeted frequency of occurrence. Our approach consists in a multidimensional extension of Boltzmann samplers cite. We show that, under mostly emph hypotheses, our samplers return a word of size in and exact frequency in expected time. Moreover, if we accept tolerance intervals of width in for the number of occurrences of each letters, our samplers perform an approximate-size generation of words in expected time. We illustrate these techniques on the generation of Tetris tessellations with uniform statistics in the different types of tetraminoes.',
	 'authors': u'Olivier Bodini, Yann Ponty,',
	 'category': u'Computer Science ',
	 'date': '2010-1-30',
	 'pdflink': u'http://arxiv.org/pdf/1002.0046',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nMulti-dimensional Boltzmann Sampling of Languages',
	 'urllink': u'http://arxiv.org/abs/1002.0046'}
2015-03-24 15:27:39+0000 [xxu46_1] INFO: Crawled 725 pages (at 1 pages/min), scraped 719 items (at 1 items/min)
2015-03-24 15:28:16+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0256> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 15:28:16+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0256>
	{'abstract': u'This paper presents a brief review of current game usability models. This leads to the conception of a high-level game development-centered usability model that integrates current usability approaches in game industry and game research.',
	 'authors': u'Lennart E. Nacke,',
	 'category': u'Computer Science ',
	 'date': '2010-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1004.0256',
	 'subjects': u'Human-Computer Interaction (cs.HC)',
	 'title': u'\nFrom Playability to a Hierarchical Game Usability Model',
	 'urllink': u'http://arxiv.org/abs/1004.0256'}
2015-03-24 15:28:39+0000 [xxu46_1] INFO: Crawled 726 pages (at 1 pages/min), scraped 720 items (at 1 items/min)
2015-03-24 15:29:39+0000 [xxu46_1] INFO: Crawled 726 pages (at 0 pages/min), scraped 720 items (at 0 items/min)
2015-03-24 15:29:40+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4035> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 15:29:40+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4035>
	{'abstract': u'This paper presents a novel approach to handle the challenges of face recognition. In this work thermal face images are considered, which minimizes the affect of illumination changes and occlusion due to moustache, beards, adornments etc. The proposed approach registers the training and testing thermal face images in polar coordinate, which is capable to handle complicacies introduced by scaling and rotation. Polar images are projected into eigenspace and finally classified using a multi-layer perceptron. In the experiments we have used Object Tracking and Classification Beyond Visible Spectrum (OTCBVS) database benchmark thermal face images. Experimental results show that the proposed approach significantly improves the verification and identification performance and the success rate is 97.05%.',
	 'authors': u'Mrinal Kanti Bhowmik, Debotosh Bhattacharjee, Mita Nasipuri, Dipak Kumar Basu, Mahantapas Kundu,',
	 'category': u'Computer Science ',
	 'date': '2010-5-21',
	 'pdflink': u'http://arxiv.org/pdf/1005.4035',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nClassification of Polar-Thermal Eigenfaces using Multilayer Perceptron  for Human Face Recognition',
	 'urllink': u'http://arxiv.org/abs/1005.4035'}
2015-03-24 15:30:37+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0043> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 15:30:37+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0043>
	{'abstract': u'Algorithms based on multiple decoding attempts of Reed-Solomon (RS) codes have recently attracted new attention. Choosing decoding candidates based on rate-distortion (R-D) theory, as proposed previously by the authors, currently provides the best performance-versus-complexity trade-off. In this paper, an analysis based on the rate-distortion exponent (RDE) is used to directly minimize the exponential decay rate of the error probability. This enables rigorous bounds on the error probability for finite-length RS codes and leads to modest performance gains. As a byproduct, a numerical method is derived that computes the rate-distortion exponent for independent non-identical sources. Analytical results are given for errors/erasures decoding.',
	 'authors': u'Phong S. Nguyen, Henry D. Pfister, Krishna R. Narayanan,',
	 'category': u'Computer Science ',
	 'date': '2010-1-30',
	 'pdflink': u'http://arxiv.org/pdf/1002.0043',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nA Rate-Distortion Exponent Approach to Multiple Decoding Attempts for  Reed-Solomon Codes',
	 'urllink': u'http://arxiv.org/abs/1002.0043'}
2015-03-24 15:30:39+0000 [xxu46_1] INFO: Crawled 728 pages (at 2 pages/min), scraped 722 items (at 2 items/min)
2015-03-24 15:31:39+0000 [xxu46_1] INFO: Crawled 728 pages (at 0 pages/min), scraped 722 items (at 0 items/min)
2015-03-24 15:31:50+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0248> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 15:31:50+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0248>
	{'abstract': u'Gameplay research about experiential phenomena is a challenging undertaking, given the variety of experiences that gamers encounter when playing and which currently do not have a formal taxonomy, such as flow, immersion, boredom, and fun. These informal terms require a scientific explanation. Ludologists also acknowledge the need to understand cognition, emotion, and goal- oriented behavior of players from a psychological perspective by establishing rigorous methodologies. This paper builds upon and extends prior work in an area for which we would like to coin the term "affective ludology." The area is concerned with the affective measurement of player-game interaction. The experimental study reported here investigated different traits of gameplay experience using subjective (i.e., questionnaires) and objective (i.e., psychophysiological) measures. Participants played three Half-Life 2 game level design modifications while measures such as electromyography (EMG), electrodermal activity (EDA) were taken and questionnaire responses were collected. A level designed for combat-oriented flow experience demonstrated significant high-arousal positive affect emotions. This method shows that emotional patterns emerge from different level designs, which has great potential for providing real-time emotional profiles of gameplay that may be generated together with self- reported subjective player experience descriptions.',
	 'authors': u'Lennart E. Nacke, Craig A. Lindley,',
	 'category': u'Computer Science ',
	 'date': '2010-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1004.0248',
	 'subjects': u'Human-Computer Interaction (cs.HC)',
	 'title': u'\nAffective Ludology, Flow and Immersion in a First- Person Shooter:  Measurement of Player Experience',
	 'urllink': u'http://arxiv.org/abs/1004.0248'}
2015-03-24 15:32:39+0000 [xxu46_1] INFO: Crawled 729 pages (at 1 pages/min), scraped 723 items (at 1 items/min)
2015-03-24 15:33:37+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4034> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 15:33:37+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4034>
	{'abstract': u'This paper aims at generating a new face based on the human like description using a new concept. The FASY (FAce SYnthesis) System is a Face Database Retrieval and new Face generation System that is under development. One of its main features is the generation of the requested face when it is not found in the existing database, which allows a continuous growing of the database also.',
	 'authors': u'Santanu Halder, Debotosh Bhattacharjee, Mita Nasipuri, Dipak Kumar Basu, Mahantapas Kundu,',
	 'category': u'Computer Science ',
	 'date': '2010-5-21',
	 'pdflink': u'http://arxiv.org/pdf/1005.4034',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nFace Synthesis (FASY) System for Generation of a Face Image from Human  Description',
	 'urllink': u'http://arxiv.org/abs/1005.4034'}
2015-03-24 15:33:39+0000 [xxu46_1] INFO: Crawled 730 pages (at 1 pages/min), scraped 724 items (at 1 items/min)
2015-03-24 15:34:39+0000 [xxu46_1] INFO: Crawled 730 pages (at 0 pages/min), scraped 724 items (at 0 items/min)
2015-03-24 15:35:04+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0035> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 15:35:04+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0035>
	{'abstract': u'We exhibit the rich structure of the set of correlated equilibria by analyzing the simplest of polynomial games: the mixed extension of matching pennies. We show that while the correlated equilibrium set is convex and compact, the structure of its extreme points can be quite complicated. In finite games the ratio of extreme correlated to extreme Nash equilibria can be greater than exponential in the size of the strategy spaces. In polynomial games there can exist extreme correlated equilibria which are not finitely supported; we construct a large family of examples using techniques from ergodic theory. We show that in general the set of correlated equilibrium distributions of a polynomial game cannot be described by conditions on finitely many moments (means, covariances, etc.), in marked contrast to the set of Nash equilibria which is always expressible in terms of finitely many moments.',
	 'authors': u'Noah D. Stein, Asuman Ozdaglar, Pablo A. Parrilo,',
	 'category': u'Computer Science ',
	 'date': '2010-1-30',
	 'pdflink': u'http://arxiv.org/pdf/1002.0035',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nStructure of Extreme Correlated Equilibria: a Zero-Sum Example and its  Implications',
	 'urllink': u'http://arxiv.org/abs/1002.0035'}
2015-03-24 15:35:39+0000 [xxu46_1] INFO: Crawled 731 pages (at 1 pages/min), scraped 725 items (at 1 items/min)
2015-03-24 15:36:31+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0243> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 15:36:31+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0243>
	{'abstract': u'In this paper, we report a case study using two easy-to-deploy psychophysiological measures - electrodermal activity (EDA) and heart rate (HR) - and correlating them with a gameplay experience questionnaire (GEQ) in an attempt to establish this mixed-methods approach for rapid application in a commercial game development context. Results indicate that there is a statistically significant correlation (p &lt; 0.01) between measures of psychophysiological arousal (HR, EDA) and self-reported UX in games (GEQ), with some variation between the EDA and HR measures. Results are consistent across three major commercial First-Person Shooter (FPS) games.',
	 'authors': u'Anders Drachen, Lennart E. Nacke, Georgios Yannakakis, Anja Lee Pedersen,',
	 'category': u'Computer Science ',
	 'date': '2010-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1004.0243',
	 'subjects': u'Human-Computer Interaction (cs.HC)',
	 'title': u'\nPsychophysiological Correlations with Gameplay Experience Dimensions',
	 'urllink': u'http://arxiv.org/abs/1004.0243'}
2015-03-24 15:36:39+0000 [xxu46_1] INFO: Crawled 732 pages (at 1 pages/min), scraped 726 items (at 1 items/min)
2015-03-24 15:37:30+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4033> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 15:37:30+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4033>
	{'abstract': u'We present a near-linear time algorithm that approximates the edit distance between two strings within a polylogarithmic factor; specifically, for strings of length n and every fixed epsilon&gt;0, it can compute a (log n)^O(1/epsilon) approximation in n^(1+epsilon) time. This is an exponential improvement over the previously known factor, 2^(O (sqrt(log n))), with a comparable running time (Ostrovsky and Rabani J.ACM 2007; Andoni and Onak STOC 2009). Previously, no efficient polylogarithmic approximation algorithm was known for any computational task involving edit distance (e.g., nearest neighbor search or sketching). This result arises naturally in the study of a new asymmetric query model. In this model, the input consists of two strings x and y, and an algorithm can access y in an unrestricted manner, while being charged for querying every symbol of x. Indeed, we obtain our main result by designing an algorithm that makes a small number of queries in this model. We then provide a nearly-matching lower bound on the number of queries. Our lower bound is the first to expose hardness of edit distance stemming from the input strings being "repetitive", which means that many of their substrings are approximately identical. Consequently, our lower bound provides the first rigorous separation between edit distance and Ulam distance, which is edit distance on non-repetitive strings, such as permutations.',
	 'authors': u'Alexandr Andoni, Robert Krauthgamer, Krzysztof Onak,',
	 'category': u'Computer Science ',
	 'date': '2010-5-21',
	 'pdflink': u'http://arxiv.org/pdf/1005.4033',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nPolylogarithmic Approximation for Edit Distance and the Asymmetric Query  Complexity',
	 'urllink': u'http://arxiv.org/abs/1005.4033'}
2015-03-24 15:37:39+0000 [xxu46_1] INFO: Crawled 733 pages (at 1 pages/min), scraped 727 items (at 1 items/min)
2015-03-24 15:38:39+0000 [xxu46_1] INFO: Crawled 733 pages (at 0 pages/min), scraped 727 items (at 0 items/min)
2015-03-24 15:38:53+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0026> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 15:38:53+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0026>
	{'abstract': u'Steganography is an information hiding application which aims to hide secret data imperceptibly into a commonly used media. Unfortunately, the theoretical hiding asymptotical capacity of steganographic systems is not attained by algorithms developed so far. In this paper, we describe a novel coding method based on Z2Z4-linear codes that conforms to +/-1-steganography, that is secret data is embedded into a cover message by distorting each symbol by one unit at most. This method solves some problems encountered by the most efficient methods known today, based on ternary Hamming codes. Finally, the performance of this new technique is compared with that of the mentioned methods and with the well-known theoretical upper bound.',
	 'authors': u'H. Rif\xe0-Pous, J. Rif\xe0, L. Ronquillo,',
	 'category': u'Computer Science ',
	 'date': '2010-2-1',
	 'pdflink': u'http://arxiv.org/pdf/1002.0026',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nPerfect Z2Z4-linear codes in Steganography',
	 'urllink': u'http://arxiv.org/abs/1002.0026'}
2015-03-24 15:39:39+0000 [xxu46_1] INFO: Crawled 734 pages (at 1 pages/min), scraped 728 items (at 1 items/min)
2015-03-24 15:40:33+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0208> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 15:40:33+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0208>
	{'abstract': u"Ergodic interference alignment, as introduced by Nazer et al (NGJV), is a technique that allows high-rate communication in n-user interference networks with fast fading. It works by splitting communication across a pair of fading matrices. However, it comes with the overhead of a long time delay until matchable matrices occur: the delay is q^n^2 for field size q. In this paper, we outline two new families of schemes, called JAP and JAP-B, that reduce the expected delay, sometimes at the cost of a reduction in rate from the NGJV scheme. In particular, we give examples of good schemes for networks with few users, and show that in large n-user networks, the delay scales like q^T, where T is quadratic in n for a constant per-user rate and T is constant for a constant sum-rate. We also show that half the single-user rate can be achieved while reducing NGJV's delay from q^n^2 to q^(n-1)(n-2). This extended version includes complete proofs and more details of good schemes for small n.",
	 'authors': u'Oliver Johnson, Matthew Aldridge, Robert Piechocki,',
	 'category': u'Computer Science ',
	 'date': '2010-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1004.0208',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nDelay-rate tradeoff in ergodic interference alignment',
	 'urllink': u'http://arxiv.org/abs/1004.0208'}
2015-03-24 15:40:39+0000 [xxu46_1] INFO: Crawled 735 pages (at 1 pages/min), scraped 729 items (at 1 items/min)
2015-03-24 15:41:32+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4032> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 15:41:32+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4032>
	{'abstract': u'In this paper we present an OCR for Handwritten Devnagari Characters. Basic symbols are recognized by neural classifier. We have used four feature extraction techniques namely, intersection, shadow feature, chain code histogram and straight line fitting features. Shadow features are computed globally for character image while intersection features, chain code histogram features and line fitting features are computed by dividing the character image into different segments. Weighted majority voting technique is used for combining the classification decision obtained from four Multi Layer Perceptron(MLP) based classifier. On experimentation with a dataset of 4900 samples the overall recognition rate observed is 92.80% as we considered top five choices results. This method is compared with other recent methods for Handwritten Devnagari Character Recognition and it has been observed that this approach has better success rate than other methods.',
	 'authors': u'Sandhya Arora, Debotosh Bhattacharjee, Mita Nasipuri, Dipak Kumar Basu, Mahantapas Kundu,',
	 'category': u'Computer Science ',
	 'date': '2010-5-21',
	 'pdflink': u'http://arxiv.org/pdf/1005.4032',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nCombining Multiple Feature Extraction Techniques for Handwritten  Devnagari Character Recognition',
	 'urllink': u'http://arxiv.org/abs/1005.4032'}
2015-03-24 15:41:39+0000 [xxu46_1] INFO: Crawled 736 pages (at 1 pages/min), scraped 730 items (at 1 items/min)
2015-03-24 15:42:39+0000 [xxu46_1] INFO: Crawled 736 pages (at 0 pages/min), scraped 730 items (at 0 items/min)
2015-03-24 15:42:59+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0019> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 15:42:59+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0019>
	{'abstract': u'We study the problem of sparse reconstruction from noisy undersampled measurements when the following two things are available. (1) We are given partial, and partly erroneous, knowledge of the signal\'s support, denoted by . (2) We are also given an erroneous estimate of the signal values on , denoted by . In practice, both these may be available from available prior knowledge. Alternatively, in recursive reconstruction applications, like real-time dynamic MRI, one can use the support estimate and the signal value estimate from the previous time instant as and . In this work, we introduce regularized modified-BPDN (reg-mod-BPDN) and obtain computable bounds on its reconstruction error. Reg-mod-BPDN tries to find the signal that is sparsest outside the set , while being "close enough" to on and while satisfying the data constraint. Corresponding results for modified-BPDN and BPDN follow as direct corollaries. A second key contribution is an approach to obtain computable error bounds that hold without any sufficient conditions. This makes it easy to compare the bounds for the various approaches. Empirical reconstruction error comparisons with many existing approaches are also provided.',
	 'authors': u'Wei Lu, Namrata Vaswani,',
	 'category': u'Computer Science ',
	 'date': '2010-1-29',
	 'pdflink': u'http://arxiv.org/pdf/1002.0019',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nRegularized Modified BPDN for Noisy Sparse Reconstruction with Partial  Erroneous Support and Signal Value Knowledge',
	 'urllink': u'http://arxiv.org/abs/1002.0019'}
2015-03-24 15:43:39+0000 [xxu46_1] INFO: Crawled 737 pages (at 1 pages/min), scraped 731 items (at 1 items/min)
2015-03-24 15:44:01+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0204> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 15:44:01+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0204>
	{'abstract': u'This paper gives an overview of radio interfaces devoted for high data rate Wireless Sensor Networks. Four aerospace applications of WSN are presented to underline the importance of achieving high data rate. Then, two modulation schemes by which High Data Rate can be achieved are compared : Multi carrier approaches, represented by the popular Orthogonal Frequency Division Multiplexing (OFDM) and Single carrier methods, represented by Single Carrier Frequency division Equalization and its application for multiple access Single Carrier Frequency division multiple Access (SC-FDMA). SC-FDMA, with a very low Peak Average Power Ratio (PAPR), is as strong alternative to the OFDM scheme for highly power constraint application. The Chosen radio interface will be, finally, tested by a model based design approach based on Simulink and FPGA realization. SC-FDMA, with a very low Peak Average Power Ratio (PAPR), is as strong alternative to the OFDM scheme for highly power constraint application. The Chosen radio interface will be, finally, tested by a model based design approach based on Simulink and FPGA realization.',
	 'authors': u'Julien Henaut, Aubin Lecointre, Daniela Dragomirescu, Robert Plana,',
	 'category': u'Computer Science ',
	 'date': '2010-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1004.0204',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nRadio Interface for High Data Rate Wireless Sensor Networks',
	 'urllink': u'http://arxiv.org/abs/1004.0204'}
2015-03-24 15:44:39+0000 [xxu46_1] INFO: Crawled 738 pages (at 1 pages/min), scraped 732 items (at 1 items/min)
2015-03-24 15:45:20+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4031> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 15:45:20+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4031>
	{'abstract': u'Clustering in wireless sensor networks (WSNs) is an important technique to ease topology management and routing. Clustering provides an effective method for prolonging lifetime of a WSN. This paper proposes energy efficient multi-level clustering schemes for wireless sensor networks. Wireless sensor nodes are extremely energy constrained with a limited transmission range. Due to large area of deployment, the network needs to have a multi-level clustering protocol that will enable far-off nodes to communicate with the base station. Simulation is used to analyze the proposed protocols and compare their performance with existing protocol EEMC. Simulation results demonstrate that our proposed protocols are effective in prolonging the network lifetime.',
	 'authors': u'Surender Soni, Narottam Chand,',
	 'category': u'Computer Science ',
	 'date': '2010-5-21',
	 'pdflink': u'http://arxiv.org/pdf/1005.4031',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nEnergy Efficient Multi-Level Clustering To Prolong The Lifetime of  Wireless Sensor Networks',
	 'urllink': u'http://arxiv.org/abs/1005.4031'}
2015-03-24 15:45:39+0000 [xxu46_1] INFO: Crawled 739 pages (at 1 pages/min), scraped 733 items (at 1 items/min)
2015-03-24 15:46:39+0000 [xxu46_1] INFO: Crawled 739 pages (at 0 pages/min), scraped 733 items (at 0 items/min)
2015-03-24 15:47:04+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1002.0012> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 15:47:04+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1002.0012>
	{'abstract': u'We observe that the vocabulary used to construct the "answer" to problems in computer algebra can have a dramatic effect on the computational complexity of solving that problem. We recall a formalization of this observation and explain the classic example of sparse polynomial arithmetic. For this case, we show that it is possible to extend the vocabulary so as reap the benefits of conciseness whilst avoiding the obvious pitfall of repeating the problem statement as the "solution". It is possible to extend the vocabulary either by irreducible cyclotomics or by : we look at the options and suggest that the pragmatist might opt for both.',
	 'authors': u'Jacques Carette, James H. Davenport,',
	 'category': u'Computer Science ',
	 'date': '2010-1-29',
	 'pdflink': u'http://arxiv.org/pdf/1002.0012',
	 'subjects': u'Symbolic Computation (cs.SC)',
	 'title': u'\nThe Power of Vocabulary: The Case of Cyclotomic Polynomials',
	 'urllink': u'http://arxiv.org/abs/1002.0012'}
2015-03-24 15:47:39+0000 [xxu46_1] INFO: Crawled 740 pages (at 1 pages/min), scraped 734 items (at 1 items/min)
2015-03-24 15:48:39+0000 [xxu46_1] INFO: Crawled 740 pages (at 0 pages/min), scraped 734 items (at 0 items/min)
2015-03-24 15:48:40+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0202> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 15:48:40+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0202>
	{'abstract': u'The design of embedded control systems is mainly done with model-based tools such as Matlab/Simulink. Numerical simulation is the central technique of development and verification of such tools. Floating-point arithmetic, that is well-known to only provide approximated results, is omnipresent in this activity. In order to validate the behaviors of numerical simulations using abstract interpretation-based static analysis, we present, theoretically and with experiments, a new partially relational abstract domain dedicated to floating-point variables. It comes from interval expansion of non-linear functions using slopes and it is able to mimic all the behaviors of the floating-point arithmetic. Hence it is adapted to prove the absence of run-time errors or to analyze the numerical precision of embedded control systems.',
	 'authors': u'Alexandre Chapoutot,',
	 'category': u'Computer Science ',
	 'date': '2010-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1004.0202',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nInterval Slopes as Numerical Abstract Domain for Floating-Point  Variables',
	 'urllink': u'http://arxiv.org/abs/1004.0202'}
2015-03-24 15:49:39+0000 [xxu46_1] INFO: Crawled 741 pages (at 1 pages/min), scraped 735 items (at 1 items/min)
2015-03-24 15:50:13+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4030> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 15:50:13+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4030>
	{'abstract': u"Cloud computing is a set of services that provide infrastructure resources using internet media and data storage on a third party server. SMEs are said to be the lifeblood of any vibrant economy. They are known to be the silent drivers of a nation's economy. SMEs of India are one of the most aggressive adopters of ERP Packages. Most of the Indian SMEs have adopted the traditional ERP Systems and have incurred a heavy cost while implementing these systems. This paper presents the cost savings and reduction in the level of difficulty in adopting a cloud computing Service (CCS) enabled ERP system. For the study, IT people from 30 North Indian SMEs were interviewed. In the cloud computing environment the SMEs will not have to own the infrastructure so they can abstain from any capital expenditure and instead they can utilize the resources as a service and pay as per their usage. We consider the results of the paper to be supportive to our proposed research concept.",
	 'authors': u'Monika Sharma, Ashwani Mehra, Haresh Jola, Anand Kumar, Madhvendra Misra, Vijayshri Tiwari,',
	 'category': u'Computer Science ',
	 'date': '2010-5-21',
	 'pdflink': u'http://arxiv.org/pdf/1005.4030',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nScope of cloud computing for SMEs in India',
	 'urllink': u'http://arxiv.org/abs/1005.4030'}
2015-03-24 15:50:39+0000 [xxu46_1] INFO: Crawled 742 pages (at 1 pages/min), scraped 736 items (at 1 items/min)
2015-03-24 15:51:39+0000 [xxu46_1] INFO: Crawled 742 pages (at 0 pages/min), scraped 736 items (at 0 items/min)
2015-03-24 15:51:52+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0180> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 15:51:52+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0180>
	{'abstract': u'Power line communication continues to draw increasing interest by promising a wide range of applications including cost-free last-mile communication solution. However, signal transmitted through the power lines deteriorates badly due to the presence of severe inter-symbol interference (ISI) and harsh random pulse noise. This work proposes a new precoded turbo equalization scheme specifically designed for the PLC channels. By introducing useful precoding to reshape ISI, optimizing maximum (MAP) detection to address the non-Gaussian pulse noise, and performing soft iterative decision refinement, the new equalizer demonstrates a gain significantly better than the existing turbo equalizers.',
	 'authors': u'Kai Xie, Jing,',
	 'category': u'Computer Science ',
	 'date': '2010-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1004.0180',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nPrecoded Turbo Equalizer for Power Line Communication Systems',
	 'urllink': u'http://arxiv.org/abs/1004.0180'}
2015-03-24 15:52:39+0000 [xxu46_1] INFO: Crawled 743 pages (at 1 pages/min), scraped 737 items (at 1 items/min)
2015-03-24 15:53:21+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4029> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 15:53:21+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4029>
	{'abstract': u'Because of the speed, flexibility, and efficiency that it offers, the Internet has become the means for conducting growing numbers of transactions between suppliers and large international corporations. In this way, the Internet has opened new markets to the world and has accelerated the diffusion of knowledge. The meaning of Internet markets or online business has been widely used in these days. The success of the business depends on its flexibility, availability and security. Since that the web-based systems should have a special way to design the system and implement it. Nowadays, the Internet Banking System widely used and the banks looking to provide the best quality system with highly available, fast response, secure and safe to use. The Unified Modelling Language (UML) is the uniquely language which is used to analyse and design any system. In this paper, the UML diagrams has been proposed to illustrate the design phase for any banking system. The authors, presented two types of architecture which is used for the Internet Banking System.',
	 'authors': u'Hamdan.O.Alanazi, Rami Alnaqeib, Ali K.Hmood, M.A.Zaidan, Yahya Al-Nabhani,',
	 'category': u'Computer Science ',
	 'date': '2010-5-21',
	 'pdflink': u'http://arxiv.org/pdf/1005.4029',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nOn the Module of Internet Banking System',
	 'urllink': u'http://arxiv.org/abs/1005.4029'}
2015-03-24 15:53:39+0000 [xxu46_1] INFO: Crawled 744 pages (at 1 pages/min), scraped 738 items (at 1 items/min)
2015-03-24 15:54:39+0000 [xxu46_1] INFO: Crawled 744 pages (at 0 pages/min), scraped 738 items (at 0 items/min)
2015-03-24 15:54:52+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1001.0597> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 15:54:52+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1001.0597>
	{'abstract': u'We consider the problem of analyzing the heterogeneity of clustering distributions for multiple groups of observed data, each of which is indexed by a covariate value, and inferring global clusters arising from observations aggregated over the covariate domain. We propose a novel Bayesian nonparametric method reposing on the formalism of spatial modeling and a nested hierarchy of Dirichlet processes. We provide an analysis of the model properties, relating and contrasting the notions of local and global clusters. We also provide an efficient inference algorithm, and demonstrate the utility of our method in several data examples, including the problem of object tracking and a global clustering analysis of functional data where the functional identity information is not available.',
	 'authors': u'XuanLong Nguyen,',
	 'category': u'Computer Science ',
	 'date': '2010-1-4',
	 'pdflink': u'http://arxiv.org/pdf/1001.0597',
	 'subjects': u'Methodology (stat.ME)',
	 'title': u'\nInference of global clusters from locally distributed data',
	 'urllink': u'http://arxiv.org/abs/1001.0597'}
2015-03-24 15:55:39+0000 [xxu46_1] INFO: Crawled 745 pages (at 1 pages/min), scraped 739 items (at 1 items/min)
2015-03-24 15:56:34+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0152> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 15:56:34+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0152>
	{'abstract': u'Opportunistic routing is a multi-hop routing scheme which allows for selection of the best immediately available relay. In blind opportunistic routing protocols, where transmitters blindly broadcast without knowledge of the surrounding nodes, two fundamental design parameters are the node transmission probability and the transmission spectral efficiency. In this paper these parameters are selected to maximize end-to-end performance, characterized by the product of transmitter density, hop distance and rate. Due to the intractability of the problem as stated, an approximation function is examined which proves reasonably accurate. Our results show how the above design parameters should be selected based on inherent system parameters such as the path loss exponent and the noise level.',
	 'authors': u'Joseph Blomer, Nihar Jindal,',
	 'category': u'Computer Science ',
	 'date': '2010-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1004.0152',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nOpportunistic Routing in Ad Hoc Networks: How many relays should there  be? What rate should nodes use?',
	 'urllink': u'http://arxiv.org/abs/1004.0152'}
2015-03-24 15:56:39+0000 [xxu46_1] INFO: Crawled 746 pages (at 1 pages/min), scraped 740 items (at 1 items/min)
2015-03-24 15:57:39+0000 [xxu46_1] INFO: Crawled 746 pages (at 0 pages/min), scraped 740 items (at 0 items/min)
2015-03-24 15:58:14+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4028> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 15:58:14+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4028>
	{'abstract': u'Internet Banking System refers to systems that enable bank customers to access accounts and general information on bank products and services through a personal computer or other intelligent device. Internet banking products and services can include detailed account information for corporate customers as well as account summery and transfer money. Ultimately, the products and services obtained through Internet Banking may mirror products and services offered through other bank delivery channels. In this paper, Internet Banking System Prototype has been proposed in order to illustrate the services which is provided by the Bank online services.',
	 'authors': u'Rami Alnaqeib, Hamdan. O. Alanazi, Hamid. A. Jalab, M. A. Zaidan, Ali K. Hmood,',
	 'category': u'Computer Science ',
	 'date': '2010-5-21',
	 'pdflink': u'http://arxiv.org/pdf/1005.4028',
	 'subjects': u'Human-Computer Interaction (cs.HC)',
	 'title': u'\nInternet Banking System Prototype',
	 'urllink': u'http://arxiv.org/abs/1005.4028'}
2015-03-24 15:58:39+0000 [xxu46_1] INFO: Crawled 747 pages (at 1 pages/min), scraped 741 items (at 1 items/min)
2015-03-24 15:59:30+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1001.1139> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 15:59:30+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1001.1139>
	{'abstract': u'The spatial search problem consists in minimizing the number of steps required to find a given site in a network, under the restriction that only oracle queries or translations to neighboring sites are allowed. In this paper, a quantum algorithm for the spatial search problem on a honeycomb lattice with sites and torus-like boundary conditions. The search algorithm is based on a modified quantum walk on a hexagonal lattice and the general framework proposed by Ambainis, Kempe and Rivosh is used to show that the time complexity of this quantum search algorithm is .',
	 'authors': u'G. Abal, R. Donangelo, F.L. Marquezino, R. Portugal,',
	 'category': u'Computer Science ',
	 'date': '2010-1-7',
	 'pdflink': u'http://arxiv.org/pdf/1001.1139',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nSpatial search in a honeycomb network',
	 'urllink': u'http://arxiv.org/abs/1001.1139'}
2015-03-24 15:59:39+0000 [xxu46_1] INFO: Crawled 748 pages (at 1 pages/min), scraped 742 items (at 1 items/min)
2015-03-24 16:00:39+0000 [xxu46_1] INFO: Crawled 748 pages (at 0 pages/min), scraped 742 items (at 0 items/min)
2015-03-24 16:01:02+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0105> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 16:01:02+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0105>
	{'abstract': u'A Direct Sum Theorem holds in a model of computation, when solving some k input instances together is k times as expensive as solving one. We show that Direct Sum Theorems hold in the models of deterministic and randomized decision trees for all relations. We also note that a near optimal Direct Sum Theorem holds for quantum decision trees for boolean functions.',
	 'authors': u'Rahul Jain, Hartmut Klauck, Miklos Santha,',
	 'category': u'Computer Science ',
	 'date': '2010-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1004.0105',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nOptimal Direct Sum Results for Deterministic and Randomized Decision  Tree Complexity',
	 'urllink': u'http://arxiv.org/abs/1004.0105'}
2015-03-24 16:01:39+0000 [xxu46_1] INFO: Crawled 749 pages (at 1 pages/min), scraped 743 items (at 1 items/min)
2015-03-24 16:02:39+0000 [xxu46_1] INFO: Crawled 749 pages (at 0 pages/min), scraped 743 items (at 0 items/min)
2015-03-24 16:02:45+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4026> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 16:02:45+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4026>
	{'abstract': u'Without a doubt, the electronic learning makes education quite flexible. Nowadays, all organizations and institutions are trying to avoid Monotony and the delay and inertia. As well the universities should be improving their systems continually to achieve success. Whereas, the students need to access the dissertations in the library. In this paper we will present Dissertations Repository System Using Context Module to allow the students to benefit the dissertations which is in the library flexibly.',
	 'authors': u'Ali K.Hmood, M.A.Zaidan, Hamdan.O.Alanazi, Rami Alnaqeib, Yahya Al-Nabhani,',
	 'category': u'Computer Science ',
	 'date': '2010-5-21',
	 'pdflink': u'http://arxiv.org/pdf/1005.4026',
	 'subjects': u'Digital Libraries (cs.DL)',
	 'title': u'\nDissertations Repository System Using Context Module',
	 'urllink': u'http://arxiv.org/abs/1005.4026'}
2015-03-24 16:03:39+0000 [xxu46_1] INFO: Crawled 750 pages (at 1 pages/min), scraped 744 items (at 1 items/min)
2015-03-24 16:03:39+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0092> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 16:03:39+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0092>
	{'abstract': u'Consider a family of sets and a single set, called the query set. How can one quickly find a member of the family which has a maximal intersection with the query set? Time constraints on the query and on a possible preprocessing of the set family make this problem challenging. Such maximal intersection queries arise in a wide range of applications, including web search, recommendation systems, and distributing on-line advertisements. In general, maximal intersection queries are computationally expensive. We investigate two well-motivated distributions over all families of sets and propose an algorithm for each of them. We show that with very high probability an almost optimal solution is found in time which is logarithmic in the size of the family. Moreover, we point out a threshold phenomenon on the probabilities of intersecting sets in each of our two input models which leads to the efficient algorithms mentioned above.',
	 'authors': u'Benjamin Hoffmann, Mikhail Lifshits, Yury Lifshits, Dirk Nowotka,',
	 'category': u'Computer Science ',
	 'date': '2010-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1004.0092',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nMaximal Intersection Queries in Randomized Input Models',
	 'urllink': u'http://arxiv.org/abs/1004.0092'}
2015-03-24 16:04:39+0000 [xxu46_1] INFO: Crawled 751 pages (at 1 pages/min), scraped 745 items (at 1 items/min)
2015-03-24 16:04:51+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4025> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 16:04:51+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4025>
	{'abstract': u"In this paper the author presents a kind of Soft Computing Technique, mainly an application of fuzzy set theory of Prof. Zadeh [16], on a problem of Medical Experts Systems. The choosen problem is on design of a physician's decision model which can take crisp as well as fuzzy data as input, unlike the traditional models. The author presents a mathematical model based on fuzzy set theory for physician aided evaluation of a complete representation of information emanating from the initial interview including patient past history, present symptoms, and signs observed upon physical examination and results of clinical and diagnostic tests.",
	 'authors': u'Siddharths Sankar Biswas,',
	 'category': u'Computer Science ',
	 'date': '2010-5-21',
	 'pdflink': u'http://arxiv.org/pdf/1005.4025',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u"\nA Soft Computing Model for Physicians' Decision Process",
	 'urllink': u'http://arxiv.org/abs/1005.4025'}
2015-03-24 16:05:39+0000 [xxu46_1] INFO: Crawled 752 pages (at 1 pages/min), scraped 746 items (at 1 items/min)
2015-03-24 16:06:21+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1001.3480> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 16:06:21+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1001.3480>
	{'abstract': u'Recent work has highlighted deep connections between sequence-length requirements for high-probability phylogeny reconstruction and the related problem of the estimation of ancestral sequences. In [Daskalakis et al.\'09], building on the work of [Mossel\'04], a tight sequence-length requirement was obtained for the CFN model. In particular the required sequence length for high-probability reconstruction was shown to undergo a sharp transition (from to , where is the number of leaves) at the "critical" branch length (if it exists) of the ancestral reconstruction problem. Here we consider the GTR model. For this model, recent results of [Roch\'09] show that the tree can be accurately reconstructed with sequences of length when the branch lengths are below , known as the Kesten-Stigum (KS) bound. Although for the CFN model , it is known that for the more general GTR models one has with a strict inequality in many cases. Here, we show that this phenomenon also holds for phylogenetic reconstruction by exhibiting a family of symmetric models and a phylogenetic reconstruction algorithm which recovers the tree from -length sequences for some branch lengths in the range . Second we prove that phylogenetic reconstruction under GTR models requires a polynomial sequence-length for branch lengths above .',
	 'authors': u'Elchanan Mossel, Sebastien Roch, Allan Sly,',
	 'category': u'Computer Science ',
	 'date': '2010-1-20',
	 'pdflink': u'http://arxiv.org/pdf/1001.3480',
	 'subjects': u'Probability (math.PR)',
	 'title': u'\nOn the inference of large phylogenies with long branches: How long is  too long?',
	 'urllink': u'http://arxiv.org/abs/1001.3480'}
2015-03-24 16:06:39+0000 [xxu46_1] INFO: Crawled 753 pages (at 1 pages/min), scraped 747 items (at 1 items/min)
2015-03-24 16:07:39+0000 [xxu46_1] INFO: Crawled 753 pages (at 0 pages/min), scraped 747 items (at 0 items/min)
2015-03-24 16:07:56+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0085> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 16:07:56+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0085>
	{'abstract': u'Recent studies in the field of human vision science suggest that the human responses to the stimuli on a visual display are non-deterministic. People may attend to different locations on the same visual input at the same time. Based on this knowledge, we propose a new stochastic model of visual attention by introducing a dynamic Bayesian network to predict the likelihood of where humans typically focus on a video scene. The proposed model is composed of a dynamic Bayesian network with 4 layers. Our model provides a framework that simulates and combines the visual saliency response and the cognitive state of a person to estimate the most probable attended regions. Sample-based inference with Markov chain Monte-Carlo based particle filter and stream processing with multi-core processors enable us to estimate human visual attention in near real time. Experimental results have demonstrated that our model performs significantly better in predicting human visual attention compared to the previous deterministic models.',
	 'authors': u'Akisato kimura, Derek Pang, Tatsuto Takeuchi, Kouji Miyazato, Junji Yamato, Kunio Kashino,',
	 'category': u'Computer Science ',
	 'date': '2010-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1004.0085',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nA stochastic model of human visual attention with a dynamic Bayesian  network',
	 'urllink': u'http://arxiv.org/abs/1004.0085'}
2015-03-24 16:08:39+0000 [xxu46_1] INFO: Crawled 754 pages (at 1 pages/min), scraped 748 items (at 1 items/min)
2015-03-24 16:09:00+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4023> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 16:09:00+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4023>
	{'abstract': u'The notion of an ad hoc network is a new paradigm that allows mobile hosts (nodes) to communicate without relying on a predefined infrastructure to keep the network connected. Most nodes are assumed to be mobile and communication is assumed to be wireless. The mobility of nodes in an ad-hoc network means that both the population and the topology of the network are highly dynamic. It is very difficult to design a once-for-all intrusion detection system. A secure protocol should atleast include mechanisms against known attack types. In addition, it should provide a scheme to easily add new security features in the future. The paper includes the detailed description of Proposed Intrusion Detection System based on Local Reputation Scheme. The proposed System also includes concept of Redemption and Fading these are mechanism that allow nodes previously considered malicious to become a part of the network again. The simulation of the proposed system is to be done using NS-2 simulator.',
	 'authors': u'Himani Bathla, Kanika Lakhani,',
	 'category': u'Computer Science ',
	 'date': '2010-5-21',
	 'pdflink': u'http://arxiv.org/pdf/1005.4023',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nA Novel Method for Intrusion Detection System to Enhance Security in Ad  hoc Network',
	 'urllink': u'http://arxiv.org/abs/1005.4023'}
2015-03-24 16:09:39+0000 [xxu46_1] INFO: Crawled 755 pages (at 1 pages/min), scraped 749 items (at 1 items/min)
2015-03-24 16:09:50+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1001.2612> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 16:09:50+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1001.2612>
	{'abstract': u"We consider a general multi-agent convex optimization problem where the agents are to collectively minimize a global objective function subject to a global inequality constraint, a global equality constraint, and a global constraint set. The objective function is defined by a sum of local objective functions, while the global constraint set is produced by the intersection of local constraint sets. In particular, we study two cases: one where the equality constraint is absent, and the other where the local constraint sets are identical. We devise two distributed primal-dual subgradient algorithms which are based on the characterization of the primal-dual optimal solutions as the saddle points of the Lagrangian and penalty functions. These algorithms can be implemented over networks with changing topologies but satisfying a standard connectivity property, and allow the agents to asymptotically agree on optimal solutions and optimal values of the optimization problem under the Slater's condition.",
	 'authors': u'Minghui Zhu, Sonia Martinez,',
	 'category': u'Computer Science ',
	 'date': '2010-1-15',
	 'pdflink': u'http://arxiv.org/pdf/1001.2612',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nOn distributed convex optimization under inequality and equality  constraints via primal-dual subgradient methods',
	 'urllink': u'http://arxiv.org/abs/1001.2612'}
2015-03-24 16:10:39+0000 [xxu46_1] INFO: Crawled 756 pages (at 1 pages/min), scraped 750 items (at 1 items/min)
2015-03-24 16:11:06+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0084> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 16:11:06+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0084>
	{'abstract': u'The famous F5 algorithm for computing Gr "obner basis was presented by Faug `ere in 2002 without complete proofs for its correctness. The current authors have simplified the original F5 algorithm into an F5 algorithm in Buchberger\'s style (F5B algorithm), which is equivalent to original F5 algorithm and may deduce some F5-like versions. In this paper, the F5B algorithm is briefly revisited and a new complete proof for the correctness of F5B algorithm is proposed. This new proof is not limited to homogeneous systems and does not depend on the strategy of selecting critical pairs (i.e. the strategy deciding which critical pair is computed first) such that any strategy could be utilized in F5B (F5) algorithm. From this new proof, we find that the special reduction procedure (F5-reduction) is the key of F5 algorithm, so maintaining this special reduction, various variation algorithms become available. A natural variation of F5 algorithm, which transforms original F5 algorithm to a non-incremental algorithm, is presented and proved in this paper as well. This natural variation has been implemented over the Boolean ring. The two revised criteria in this natural variation are also able to reject almost all unnecessary computations and few polynomials reduce to 0 in most examples.',
	 'authors': u'Yao Sun, Dingkang Wang,',
	 'category': u'Computer Science ',
	 'date': '2010-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1004.0084',
	 'subjects': u'Symbolic Computation (cs.SC)',
	 'title': u'\nA New Proof for the Correctness of F5 (F5-Like) Algorithm',
	 'urllink': u'http://arxiv.org/abs/1004.0084'}
2015-03-24 16:11:39+0000 [xxu46_1] INFO: Crawled 757 pages (at 1 pages/min), scraped 751 items (at 1 items/min)
2015-03-24 16:12:37+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4022> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 16:12:37+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4022>
	{'abstract': u'This research paper is proposing the idea of pseudo code representation to molecular programming used in designing molecular electronics devices. Already the schematic representation of logical gates like AND, OR, NOT etc.from molecular diodes or resonant tunneling diode are available. This paper is setting a generic pseudo code model so that various logic gates can be formulated. These molecular diodes have designed from organic molecules or Bio-molecules. Our focus is on to give a scenario of molecular computation through molecular programming. We have restricted our study to molecular rectifying diode and logic device as AND gate from organic molecules only.',
	 'authors': u'Manas Ranjan Pradhan, E.G. Rajan,',
	 'category': u'Computer Science ',
	 'date': '2010-5-21',
	 'pdflink': u'http://arxiv.org/pdf/1005.4022',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nMolecular Programming Pseudo-code Representation to Molecular  Electronics',
	 'urllink': u'http://arxiv.org/abs/1005.4022'}
2015-03-24 16:12:39+0000 [xxu46_1] INFO: Crawled 758 pages (at 1 pages/min), scraped 752 items (at 1 items/min)
2015-03-24 16:13:39+0000 [xxu46_1] INFO: Crawled 758 pages (at 0 pages/min), scraped 752 items (at 0 items/min)
2015-03-24 16:14:07+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0062> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 16:14:07+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0062>
	{'abstract': u'Researchers have proposed formal definitions of quantitative information flow based on information theoretic notions such as the Shannon entropy, the min entropy, the guessing entropy, and channel capacity. This paper investigates the hardness and possibilities of precisely checking and inferring quantitative information flow according to such definitions. We prove that, even for just comparing two programs on which has the larger flow, none of the definitions is a k-safety property for any k, and therefore is not amenable to the self-composition technique that has been successfully applied to precisely checking non-interference. We also show a complexity theoretic gap with non-interference by proving that, for loop-free boolean programs whose non-interference is coNP-complete, the comparison problem is #P-hard for all of the definitions. For positive results, we show that universally quantifying the distribution in the comparison problem, that is, comparing two programs according to the entropy based definitions on which has the larger flow for all distributions, is a 2-safety problem in general and is coNP-complete when restricted for loop-free boolean programs. We prove this by showing that the problem is equivalent to a simple relation naturally expressing the fact that one program is more secure than the other. We prove that the relation also refines the channel-capacity based definition, and that it can be precisely checked via the self-composition as well as the "interleaved" self-composition technique.',
	 'authors': u'Hirotoshi Yasuoka, Tachio Terauchi,',
	 'category': u'Computer Science ',
	 'date': '2010-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1004.0062',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nQuantitative Information Flow - Verification Hardness and Possibilities',
	 'urllink': u'http://arxiv.org/abs/1004.0062'}
2015-03-24 16:14:39+0000 [xxu46_1] INFO: Crawled 759 pages (at 1 pages/min), scraped 753 items (at 1 items/min)
2015-03-24 16:15:39+0000 [xxu46_1] INFO: Crawled 759 pages (at 0 pages/min), scraped 753 items (at 0 items/min)
2015-03-24 16:15:55+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4021> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 16:15:55+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4021>
	{'abstract': u'Software development effort estimation is one of the most major activities in software project management. A number of models have been proposed to construct a relationship between software size and effort; however we still have problems for effort estimation. This is because project data, available in the initial stages of project is often incomplete, inconsistent, uncertain and unclear. The need for accurate effort estimation in software industry is still a challenge. Artificial Neural Network models are more suitable in such situations. The present paper is concerned with developing software effort estimation models based on artificial neural networks. The models are designed to improve the performance of the network that suits to the COCOMO Model. Artificial Neural Network models are created using Radial Basis and Generalized Regression. A case study based on the COCOMO81 database compares the proposed neural network models with the Intermediate COCOMO. The results were analyzed using five different criterions MMRE, MARE, VARE, Mean BRE and Prediction. It is observed that the Radial Basis Neural Network provided better results',
	 'authors': u'P.V.G.D. Prasad Reddy, K.R. Sudha, P. Rama Sree, S.N.S.V.S.C. Ramesh,',
	 'category': u'Computer Science ',
	 'date': '2010-5-21',
	 'pdflink': u'http://arxiv.org/pdf/1005.4021',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nSoftware Effort Estimation using Radial Basis and Generalized Regression  Neural Networks',
	 'urllink': u'http://arxiv.org/abs/1005.4021'}
2015-03-24 16:16:39+0000 [xxu46_1] INFO: Crawled 760 pages (at 1 pages/min), scraped 754 items (at 1 items/min)
2015-03-24 16:17:36+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0056> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 16:17:36+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0056>
	{'abstract': u'This paper defines a class of labeled stratified order structures that characterizes exactly the notion of combined traces (i.e., comtraces) proposed by Janicki and Koutny in 1995. Our main technical contributions are the representation theorems showing that comtrace quotient monoid, combined dependency graph (Kleijn and Koutny 2008) and our labeled stratified order structure characterization are three different and yet equivalent ways to represent comtraces.',
	 'authors': u'Dai Tri Man Le,',
	 'category': u'Computer Science ',
	 'date': '2010-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1004.0056',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nA Characterization of Combined Traces Using Labeled Stratified Order  Structures',
	 'urllink': u'http://arxiv.org/abs/1004.0056'}
2015-03-24 16:17:39+0000 [xxu46_1] INFO: Crawled 761 pages (at 1 pages/min), scraped 755 items (at 1 items/min)
2015-03-24 16:18:39+0000 [xxu46_1] INFO: Crawled 761 pages (at 0 pages/min), scraped 755 items (at 0 items/min)
2015-03-24 16:19:14+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4020> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 16:19:14+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4020>
	{'abstract': u'This paper attempts to undertake the study of segmentation image techniques by using five threshold methods as Mean method, P-tile method, Histogram Dependent Technique (HDT), Edge Maximization Technique (EMT) and visual Technique and they are compared with one another so as to choose the best technique for threshold segmentation techniques image. These techniques applied on three satellite images to choose base guesses for threshold segmentation image.',
	 'authors': u'Salem Saleh Al-amri, N.V. Kalyankar, Khamitkar S.D.,',
	 'category': u'Computer Science ',
	 'date': '2010-5-21',
	 'pdflink': u'http://arxiv.org/pdf/1005.4020',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nImage Segmentation by Using Threshold Techniques',
	 'urllink': u'http://arxiv.org/abs/1005.4020'}
2015-03-24 16:19:39+0000 [xxu46_1] INFO: Crawled 762 pages (at 1 pages/min), scraped 756 items (at 1 items/min)
2015-03-24 16:20:39+0000 [xxu46_1] INFO: Crawled 762 pages (at 0 pages/min), scraped 756 items (at 0 items/min)
2015-03-24 16:20:55+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1001.3052> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 16:20:55+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1001.3052>
	{'abstract': u'The Banzhaf power index was introduced in cooperative game theory to measure the real power of players in a game. The Banzhaf interaction index was then proposed to measure the interaction degree inside coalitions of players. It was shown that the power and interaction indexes can be obtained as solutions of a standard least squares approximation problem for pseudo-Boolean functions. Considering certain weighted versions of this approximation problem, we define a class of weighted interaction indexes that generalize the Banzhaf interaction index. We show that these indexes define a subclass of the family of probabilistic interaction indexes and study their most important properties. Finally, we give an interpretation of the Banzhaf and Shapley interaction indexes as centers of mass of this subclass of interaction indexes.',
	 'authors': u'Jean-Luc Marichal, Pierre Mathonet,',
	 'category': u'Computer Science ',
	 'date': '2010-1-18',
	 'pdflink': u'http://arxiv.org/pdf/1001.3052',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nWeighted Banzhaf power and interaction indexes through weighted  approximations of games',
	 'urllink': u'http://arxiv.org/abs/1001.3052'}
2015-03-24 16:21:39+0000 [xxu46_1] INFO: Crawled 763 pages (at 1 pages/min), scraped 757 items (at 1 items/min)
2015-03-24 16:22:27+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0050> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 16:22:27+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0050>
	{'abstract': u"Bandwidth request-grant mechanisms are used in 802.16 networks to manage the uplink bandwidth needs of subscriber stations (SSs). Requests may be sent by SSs to the base station (BS) by means of several mechanisms defined in the standard. Based on the incoming requests, the BS (which handles most of the bandwidth scheduling in the system) schedules the transmission of uplink traffic, by assigning transmission opportunities to the SSs in an implementation-dependent manner. In this paper we present a study of some bandwidth allocation issues, arising from the management of the perception of subscriber stations' bandwidth needs at the base station. We illustrate how the bandwidth perception varies depending on the policy used to handle requests and grants. By means of ns-2 simulations, we evaluate the potential impact of such policies on the system's aggregate throughput when the traffic is composed of Best-Effort TCP flows.",
	 'authors': u'Andres Arcia-Moret, Yubo Yang, Nicolas Montavont, David Ros,',
	 'category': u'Computer Science ',
	 'date': '2010-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1004.0050',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nA Study of Bandwidth-Perception Management Mechanisms in IEEE 802.16  Networks',
	 'urllink': u'http://arxiv.org/abs/1004.0050'}
2015-03-24 16:22:39+0000 [xxu46_1] INFO: Crawled 764 pages (at 1 pages/min), scraped 758 items (at 1 items/min)
2015-03-24 16:23:39+0000 [xxu46_1] INFO: Crawled 764 pages (at 0 pages/min), scraped 758 items (at 0 items/min)
2015-03-24 16:23:50+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4018> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 16:23:50+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4018>
	{'abstract': u'This paper has been withdrawn.',
	 'authors': u'Fred Viezens,',
	 'category': u'Computer Science ',
	 'date': '2010-5-21',
	 'pdflink': u'http://arxiv.org/e-print/1005.4018',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nA grid environment consisting of heterogeneous compute resources for  high performance computation',
	 'urllink': u'http://arxiv.org/abs/1005.4018'}
2015-03-24 16:24:39+0000 [xxu46_1] INFO: Crawled 765 pages (at 1 pages/min), scraped 759 items (at 1 items/min)
2015-03-24 16:25:29+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0048> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 16:25:29+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0048>
	{'abstract': u"The increasing popularity of social networks has initiated a fertile research area in information extraction and data mining. Anonymization of these social graphs is important to facilitate publishing these data sets for analysis by external entities. Prior work has concentrated mostly on node identity anonymization and structural anonymization. But with the growing interest in analyzing social networks as a weighted network, edge weight anonymization is also gaining importance. We present An 'onimos, a Linear Programming based technique for anonymization of edge weights that preserves linear properties of graphs. Such properties form the foundation of many important graph-theoretic algorithms such as shortest paths problem, k-nearest neighbors, minimum cost spanning tree, and maximizing information spread. As a proof of concept, we apply An 'onimos to the shortest paths problem and its extensions, prove the correctness, analyze complexity, and experimentally evaluate it using real social network data sets. Our experiments demonstrate that An 'onimos anonymizes the weights, improves k-anonymity of the weights, and also scrambles the relative ordering of the edges sorted by weights, thereby providing robust and effective anonymization of the sensitive edge-weights. Additionally, we demonstrate the composability of different models generated using An 'onimos, a property that allows a single anonymized graph to preserve multiple linear properties.",
	 'authors': u'Sudipto Das, Omer Egecioglu, Amr El Abbadi,',
	 'category': u'Computer Science ',
	 'date': '2010-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1004.0048',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nAnonimos: An LP based Approach for Anonymizing Weighted Social Network  Graphs',
	 'urllink': u'http://arxiv.org/abs/1004.0048'}
2015-03-24 16:25:39+0000 [xxu46_1] INFO: Crawled 766 pages (at 1 pages/min), scraped 760 items (at 1 items/min)
2015-03-24 16:26:39+0000 [xxu46_1] INFO: Crawled 766 pages (at 0 pages/min), scraped 760 items (at 0 items/min)
2015-03-24 16:27:02+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4017> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 16:27:02+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4017>
	{'abstract': u"As the demand of, requesting the Internet without any disturbance by the mobile users of any network is increasing the IETF started working on Network Mobility (NEMO). Maintaining the session of all the nodes in mobile network with its home network and external nodes can be provided by the basic Network Mobility support protocol. It provides mobility at IP level to complete networks, allowing a Mobile Network to change its point of attachment to the Internet, while maintaining the ongoing sessions of the nodes of the network. The Mobile Router (MR) manages the mobility even though the nodes don't know the status of mobility. This article discusses few basic concepts and limitations of NEMO protocol and proposes two ways to optimize the NEMO routing technique for registered and unregistered Correspondent Nodes (CN) of the Mobile Network Node (MNN).",
	 'authors': u'M. Dinakaran, P. Balasubramanie,',
	 'category': u'Computer Science ',
	 'date': '2010-5-21',
	 'pdflink': u'http://arxiv.org/pdf/1005.4017',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u"\nA Route Optimization technique for registered and unregistered CN's in  NEMO",
	 'urllink': u'http://arxiv.org/abs/1005.4017'}
2015-03-24 16:27:39+0000 [xxu46_1] INFO: Crawled 767 pages (at 1 pages/min), scraped 761 items (at 1 items/min)
2015-03-24 16:27:52+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1001.5056> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 16:27:52+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1001.5056>
	{'abstract': u'We consider optimization of nonlinear objective functions that balance linear criteria over -element independence systems presented by linear-optimization oracles. For , we have previously shown that an -best approximate solution can be found in polynomial time. Here, using an extended Erd Hs-Ko-Rado theorem of Frankl, we show that for , finding a -best solution requires exponential time.',
	 'authors': u'Jon Lee, Shmuel Onn, Robert Weismantel,',
	 'category': u'Computer Science ',
	 'date': '2010-1-28',
	 'pdflink': u'http://arxiv.org/pdf/1001.5056',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nIntractability of approximate multi-dimensional nonlinear optimization  on independence systems',
	 'urllink': u'http://arxiv.org/abs/1001.5056'}
2015-03-24 16:28:39+0000 [xxu46_1] INFO: Crawled 768 pages (at 1 pages/min), scraped 762 items (at 1 items/min)
2015-03-24 16:28:46+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0027> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 16:28:46+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0027>
	{'abstract': u'Lattices are important as models for the node locations in wireless networks for two main reasons: (1) When network designers have control over the placement of the nodes, they often prefer a regular arrangement in a lattice for coverage and interference reasons. (2) If nodes are randomly distributed or mobile, good channel access schemes ensure that concurrent transmitters are regularly spaced, hence the locations of the transmitting nodes are well approximated by a lattice. In this paper, we introduce general interference bounding techniques that permit the derivation of tight closed-form upper and lower bounds for all lattice networks, and we present and analyze optimum or near-optimum channel access schemes for one-dimensional, square, and triangular lattices.',
	 'authors': u'Martin Haenggi,',
	 'category': u'Computer Science ',
	 'date': '2010-3-31',
	 'pdflink': u'http://arxiv.org/pdf/1004.0027',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nInterference in Lattice Networks',
	 'urllink': u'http://arxiv.org/abs/1004.0027'}
2015-03-24 16:29:39+0000 [xxu46_1] INFO: Crawled 769 pages (at 1 pages/min), scraped 763 items (at 1 items/min)
2015-03-24 16:30:27+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4016> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 16:30:27+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4016>
	{'abstract': u"This paper emphasizes a determinant aim of identifying different approaches, as comparing to the education and democracy ways specific to e-government system. Introducing the information technology should offer the possibility by which reform processes of the government should become more efficient, transparent and much more public for the citizens; in this way, their ability of participating directly to government activities should prove the carrying out of a democratic and free frame. One of the essential issues of such phenomenon is that of proving that adopting the information and communication technology programs to government process or electronic government depends upon a series of external factors, such as the level of state's development, the cultural level, the frame of developing the structures of central and local public authority, criteria that differentiate the applicability of such system, to various countries. This difference is especially seen as comparing to the East states of European Union. Information systems can be applied in order to allow the citizens to monitor and coordinate the providing of local services; such exchanges have created trust and the feeling of influence, encouraging the participation to political life. Carrying into effect the new informational technologies, aiming to issuing, informing and to participation of citizens to political life, will model the concept of democracy within a new frame.",
	 'authors': u'Bostan I,',
	 'category': u'Computer Science ',
	 'date': '2010-5-21',
	 'pdflink': u'http://arxiv.org/pdf/1005.4016',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nDemocracy, essential element of the electronic government',
	 'urllink': u'http://arxiv.org/abs/1005.4016'}
2015-03-24 16:30:39+0000 [xxu46_1] INFO: Crawled 770 pages (at 1 pages/min), scraped 764 items (at 1 items/min)
2015-03-24 16:31:31+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1001.0036> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 16:31:31+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1001.0036>
	{'abstract': u"Neurons perform computations, and convey the results of those computations through the statistical structure of their output spike trains. Here we present a practical method, grounded in the information-theoretic analysis of prediction, for inferring a minimal representation of that structure and for characterizing its complexity. Starting from spike trains, our approach finds their causal state models (CSMs), the minimal hidden Markov models or stochastic automata capable of generating statistically identical time series. We then use these CSMs to objectively quantify both the generalizable structure and the idiosyncratic randomness of the spike train. Specifically, we show that the expected algorithmic information content (the information needed to describe the spike train exactly) can be split into three parts describing (1) the time-invariant structure (complexity) of the minimal spike-generating process, which describes the spike train statistically; (2) the randomness (internal entropy rate) of the minimal spike-generating process; and (3) a residual pure noise term not described by the minimal spike-generating process. We use CSMs to approximate each of these quantities. The CSMs are inferred nonparametrically from the data, making only mild regularity assumptions, via the causal state splitting reconstruction algorithm. The methods presented here complement more traditional spike train analyses by describing not only spiking probability and spike train entropy, but also the complexity of a spike train's structure. We demonstrate our approach using both simulated spike trains and experimental data recorded in rat barrel cortex during vibrissa stimulation.",
	 'authors': u'Robert Haslinger, Kristina Lisa Klinkner, Cosma Rohilla Shalizi,',
	 'category': u'Computer Science ',
	 'date': '2015-01-01',
	 'pdflink': u'http://arxiv.org/pdf/1001.0036',
	 'subjects': u'Neurons and Cognition (q-bio.NC)',
	 'title': u'\nThe Computational Structure of Spike Trains',
	 'urllink': u'http://arxiv.org/abs/1001.0036'}
2015-03-24 16:31:39+0000 [xxu46_1] INFO: Crawled 771 pages (at 1 pages/min), scraped 765 items (at 1 items/min)
2015-03-24 16:32:26+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0024> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 16:32:26+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0024>
	{'abstract': u'Much of the current focus in high-performance computing is on multi-threading, multi-computing, and graphics processing unit (GPU) computing. However, vectorization and non-parallel optimization techniques, which can often be employed additionally, are less frequently discussed. In this paper, we present an analysis of several optimizations done on both central processing unit (CPU) and GPU implementations of a particular computationally intensive Metropolis Monte Carlo algorithm. Explicit vectorization on the CPU and the equivalent, explicit memory coalescing, on the GPU are found to be critical to achieving good performance of this algorithm in both environments. The fully-optimized CPU version achieves a 9x to 12x speedup over the original CPU version, in addition to speedup from multi-threading. This is 2x faster than the fully-optimized GPU version.',
	 'authors': u'Neil G. Dickson, Kamran Karimi, Firas Hamze,',
	 'category': u'Computer Science ',
	 'date': '2010-3-31',
	 'pdflink': u'http://arxiv.org/pdf/1004.0024',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nImportance of Explicit Vectorization for CPU and GPU Software  Performance',
	 'urllink': u'http://arxiv.org/abs/1004.0024'}
2015-03-24 16:32:39+0000 [xxu46_1] INFO: Crawled 772 pages (at 1 pages/min), scraped 766 items (at 1 items/min)
2015-03-24 16:33:39+0000 [xxu46_1] INFO: Crawled 772 pages (at 0 pages/min), scraped 766 items (at 0 items/min)
2015-03-24 16:33:53+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4015> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 16:33:53+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4015>
	{'abstract': u'In recent years, WLAN technology has been gaining popularity around the world with its sub standard 802.11b receiving major deployments in many indoor and outdoor environments. In this article we investigate the performance of IEEE 802.11b infrastructure networks in the lossless and lossy environments by means of a simulation study. Also, this study shows how the FIFO discipline of the 802.11b MAC affects on the global performance when at least one channel is under the influence of the bursty errors. Furthermore, this paper proposes a channel aware backoff algorithm for the Access Point (AP) to prioritize its transmissions and to accelerate the transmissions in the poor radio channels to enhance the performance of the real time applications. The final results of this simulation study showed that the proposed algorithm is able to enhance the throughput and the delay in lossy environment by an average of 49% and 83% respectively.',
	 'authors': u'A. N. Omara, Sherine M. Abd El-Kader, Hussein S. Eissa, S. El-Ramly,',
	 'category': u'Computer Science ',
	 'date': '2010-5-21',
	 'pdflink': u'http://arxiv.org/pdf/1005.4015',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nA Prioritized Access Point Algorithm for 802.11b Networks in a Lossy  Environment',
	 'urllink': u'http://arxiv.org/abs/1005.4015'}
2015-03-24 16:34:39+0000 [xxu46_1] INFO: Crawled 773 pages (at 1 pages/min), scraped 767 items (at 1 items/min)
2015-03-24 16:35:23+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1001.5454> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 16:35:23+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1001.5454>
	{'abstract': u"We consider a stable open queuing network as a steady non-equilibrium system of interacting particles. The network is completely specified by its underlying graphical structure, type of interaction at each node, and the Markovian transition rates between nodes. For such systems, we ask the question ``What is the most likely way for large currents to accumulate over time in a network ?'', where time is large compared to the system correlation time scale. We identify two interesting regimes. In the first regime, in which the accumulation of currents over time exceeds the expected value by a small to moderate amount (moderate large deviation), we find that the large-deviation distribution of currents is universal (independent of the interaction details), and there is no long-time and averaged over time accumulation of particles (condensation) at any nodes. In the second regime, in which the accumulation of currents over time exceeds the expected value by a large amount (severe large deviation), we find that the large-deviation current distribution is sensitive to interaction details, and there is a long-time accumulation of particles (condensation) at some nodes. The transition between the two regimes can be described as a dynamical second order phase transition. We illustrate these ideas using the simple, yet non-trivial, example of a single node with feedback.",
	 'authors': u'Vladimir Y.Chernyak, Michael Chertkov, David A. Goldberg, Konstantin Turitsyn,',
	 'category': u'Computer Science ',
	 'date': '2010-1-29',
	 'pdflink': u'http://arxiv.org/pdf/1001.5454',
	 'subjects': u'Statistical Mechanics (cond-mat.stat-mech)',
	 'title': u'\nNon-Equilibrium Statistical Physics of Currents in Queuing Networks',
	 'urllink': u'http://arxiv.org/abs/1001.5454'}
2015-03-24 16:35:39+0000 [xxu46_1] INFO: Crawled 774 pages (at 1 pages/min), scraped 768 items (at 1 items/min)
2015-03-24 16:36:39+0000 [xxu46_1] INFO: Crawled 774 pages (at 0 pages/min), scraped 768 items (at 0 items/min)
2015-03-24 16:37:10+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1004.0023> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 16:37:10+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1004.0023>
	{'abstract': u"This paper presents two conceptually simple methods for parallelizing a Parallel Tempering Monte Carlo simulation in a distributed volunteer computing context, where computers belonging to the general public are used. The first method uses conventional multi-threading. The second method uses CUDA, a graphics card computing system. Parallel Tempering is described, and challenges such as parallel random number generation and mapping of Monte Carlo chains to different threads are explained. While conventional multi-threading on CPUs is well-established, GPGPU programming techniques and technologies are still developing and present several challenges, such as the effective use of a relatively large number of threads. Having multiple chains in Parallel Tempering allows parallelization in a manner that is similar to the serial algorithm. Volunteer computing introduces important constraints to high performance computing, and we show that both versions of the application are able to adapt themselves to the varying and unpredictable computing resources of volunteers' computers, while leaving the machines responsive enough to use. We present experiments to show the scalable performance of these two approaches, and indicate that the efficiency of the methods increases with bigger problem sizes.",
	 'authors': u'Kamran Karimi, Neil G. Dickson, Firas Hamze,',
	 'category': u'Computer Science ',
	 'date': '2010-3-31',
	 'pdflink': u'http://arxiv.org/pdf/1004.0023',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nHigh-Performance Physics Simulations Using Multi-Core CPUs and GPGPUs in  a Volunteer Computing Context',
	 'urllink': u'http://arxiv.org/abs/1004.0023'}
2015-03-24 16:37:39+0000 [xxu46_1] INFO: Crawled 775 pages (at 1 pages/min), scraped 769 items (at 1 items/min)
2015-03-24 16:38:39+0000 [xxu46_1] INFO: Crawled 775 pages (at 0 pages/min), scraped 769 items (at 0 items/min)
2015-03-24 16:38:49+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4014> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 16:38:49+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4014>
	{'abstract': u'With the rapid development of computer technology, computer music has begun to appear in the laboratory. Many potential utility of computer music is gradually increasing. The purpose of this paper is attempted to analyze the possibility of integrating multimodal interaction such as vision-based hand gesture and speech interaction into musical conducting education. To achieve this purpose, this paper is focus on discuss some related research and the traditional musical conducting education. To do so, six musical conductors had been interviewed to share their musical conducting learning/ teaching experience. These interviews had been analyzed in this paper to show the syllabus and the focus of musical conducting education for beginners.',
	 'authors': u'Gilbert Phuah Leong Siang, Nor Azman Ismail, Pang Yee Yong,',
	 'category': u'Computer Science ',
	 'date': '2010-5-21',
	 'pdflink': u'http://arxiv.org/pdf/1005.4014',
	 'subjects': u'Multimedia (cs.MM)',
	 'title': u'\nA Study on Potential of Integrating Multimodal Interaction into Musical  Conducting Education',
	 'urllink': u'http://arxiv.org/abs/1005.4014'}
2015-03-24 16:39:39+0000 [xxu46_1] INFO: Crawled 776 pages (at 1 pages/min), scraped 770 items (at 1 items/min)
2015-03-24 16:40:30+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1001.5420> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 16:40:30+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1001.5420>
	{'abstract': u'Neurons are the central biological objects in understanding how the brain works. The famous Hodgkin-Huxley model, which describes how action potentials of a neuron are initiated and propagated, consists of four coupled nonlinear differential equations. Because these equations are difficult to deal with, there also exist several simplified models, of which many exhibit polynomial-like non-linearity. Examples of such models are the Fitzhugh-Nagumo (FHN) model, the Hindmarsh-Rose (HR) model, the Morris-Lecar (ML) model and the Izhikevich model. In this work, we first prescribe the biologically relevant parameter ranges for the FHN model and subsequently study the dynamical behaviour of coupled neurons on small networks of two or three nodes. To do this, we use a computational real algebraic geometry method called the Discriminant Variety (DV) method to perform the stability and bifurcation analysis of these small networks. A time series analysis of the FHN model can be found elsewhere in related work[15].',
	 'authors': u'William Hanan, Dhagash Mehta, Guillaume Moroz, Sepanda Pouryahya,',
	 'category': u'Computer Science ',
	 'date': '2010-1-29',
	 'pdflink': u'http://arxiv.org/pdf/1001.5420',
	 'subjects': u'Neurons and Cognition (q-bio.NC)',
	 'title': u'\nStability and Bifurcation Analysis of Coupled Fitzhugh-Nagumo  Oscillators',
	 'urllink': u'http://arxiv.org/abs/1001.5420'}
2015-03-24 16:40:39+0000 [xxu46_1] INFO: Crawled 777 pages (at 1 pages/min), scraped 771 items (at 1 items/min)
2015-03-24 16:41:39+0000 [xxu46_1] INFO: Crawled 777 pages (at 0 pages/min), scraped 771 items (at 0 items/min)
2015-03-24 16:41:52+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1003.2005> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 16:41:52+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1003.2005>
	{'abstract': u'This paper provides new results for control of complex flight maneuvers for a quadrotor unmanned aerial vehicle (UAV). The flight maneuvers are defined by a concatenation of flight modes or primitives, each of which is achieved by a nonlinear controller that solves an output tracking problem. A mathematical model of the quadrotor UAV rigid body dynamics, defined on the configuration space , is introduced as a basis for the analysis. The quadrotor UAV has four input degrees of freedom, namely the magnitudes of the four rotor thrusts; each flight mode is defined by solving an asymptotic optimal tracking problem. Although many flight modes can be studied, we focus on three output tracking problems, namely (1) outputs given by the vehicle attitude, (2) outputs given by the three position variables for the vehicle center of mass, and (3) output given by the three velocity variables for the vehicle center of mass. A nonlinear tracking controller is developed on the special Euclidean group for each flight mode, and the closed loop is shown to have desirable closed loop properties that are almost global in each case. Several numerical examples, including one example in which the quadrotor recovers from being initially upside down and another example that includes switching and transitions between different flight modes, illustrate the versatility and generality of the proposed approach.',
	 'authors': u'Taeyoung Lee, Melvin Leok, N. Harris McClamroch,',
	 'category': u'Computer Science ',
	 'date': '2010-3-10',
	 'pdflink': u'http://arxiv.org/pdf/1003.2005',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nControl of Complex Maneuvers for a Quadrotor UAV using Geometric Methods  on SE(3)',
	 'urllink': u'http://arxiv.org/abs/1003.2005'}
2015-03-24 16:42:39+0000 [xxu46_1] INFO: Crawled 778 pages (at 1 pages/min), scraped 772 items (at 1 items/min)
2015-03-24 16:43:13+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4013> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 16:43:13+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4013>
	{'abstract': u'Wireless Sensor Networks are basically used for gathering information needed by smart environments but they are particularly useful in unattended situations where terrain, climate and other environmental constraints may hinder in the deployment of wired/conventional networks. Unlike traditional networks, these sensor networks do not have a continuous power supply at their disposal. Rather the individual sensors are battery operated and the lifetime of the individual sensors and thus the overall network depend heavily on duty cycle of these sensors. Analysis on WSNs shows that communication module is the main part which consumes most of the sensor energy and that is why energy conservation is the major optimization goal. Since routing protocols and MAC protocols directly access the communication module therefore the design of protocols in these two domains should take into account the energy conservation goal. In this paper, we discuss different state-of-the-art protocols both in MAC and routing domains that have been proposed for WSNs to achieve the overall goal of prolonging the network lifetime. The routing protocols in WSNs are generally categorized into three groups - data centric, hierarchical and location-based but we focus on only the first two categories because location-based routing protocols generally require a prior knowledge about sensors location which most of the times is not available due to random deployment of the sensors. We then discuss how schedule-based and contention-based MAC protocols can contribute to achieve optimal utilization of the limited energy resource by avoiding or reducing the chances of collisions and thus the need for retransmission.',
	 'authors': u'Sami Halawani, Abdul Waheed Khan,',
	 'category': u'Computer Science ',
	 'date': '2010-5-21',
	 'pdflink': u'http://arxiv.org/pdf/1005.4013',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nSensors Lifetime Enhancement Techniques in Wireless Sensor Networks - A  Survey',
	 'urllink': u'http://arxiv.org/abs/1005.4013'}
2015-03-24 16:43:39+0000 [xxu46_1] INFO: Crawled 779 pages (at 1 pages/min), scraped 773 items (at 1 items/min)
2015-03-24 16:44:39+0000 [xxu46_1] INFO: Crawled 779 pages (at 0 pages/min), scraped 773 items (at 0 items/min)
2015-03-24 16:45:00+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1001.5311> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 16:45:00+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1001.5311>
	{'abstract': u'Adaptive sampling results in dramatic improvements in the recovery of sparse signals in white Gaussian noise. A sequential adaptive sampling-and-refinement procedure called Distilled Sensing (DS) is proposed and analyzed. DS is a form of multi-stage experimental design and testing. Because of the adaptive nature of the data collection, DS can detect and localize far weaker signals than possible from non-adaptive measurements. In particular, reliable detection and localization (support estimation) using non-adaptive samples is possible only if the signal amplitudes grow logarithmically with the problem dimension. Here it is shown that using adaptive sampling, reliable detection is possible provided the amplitude exceeds a constant, and localization is possible when the amplitude exceeds any arbitrarily slowly growing function of the dimension.',
	 'authors': u'Jarvis Haupt, Rui Castro, Robert Nowak,',
	 'category': u'Computer Science ',
	 'date': '2010-1-29',
	 'pdflink': u'http://arxiv.org/pdf/1001.5311',
	 'subjects': u'Statistics Theory (math.ST)',
	 'title': u'\nDistilled Sensing: Adaptive Sampling for Sparse Detection and Estimation',
	 'urllink': u'http://arxiv.org/abs/1001.5311'}
2015-03-24 16:45:39+0000 [xxu46_1] INFO: Crawled 780 pages (at 1 pages/min), scraped 774 items (at 1 items/min)
2015-03-24 16:46:28+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1003.2165> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 16:46:28+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1003.2165>
	{'abstract': u'We count ]B, C]-grained, k-factor integers which are simultaneously B-rough and C-smooth and have a fixed number k of prime factors. Our aim is to exploit explicit versions of the prime number theorem as much as possible to get good explicit bounds for the count of such integers. This analysis was inspired by certain inner procedures in the general number field sieve. The result should at least provide some insight in what happens there. We estimate the given count in terms of some recursively defined functions. Since they are still difficult to handle, only another approximation step reveals their orders. Finally, we use the obtained bounds to perform numerical experiments that show how good the desired count can be approximated for the parameters of the general number field sieve in the mentioned inspiring application.',
	 'authors': u'Daniel Loebenberger, Michael N\xfcsken,',
	 'category': u'Computer Science ',
	 'date': '2010-3-10',
	 'pdflink': u'http://arxiv.org/pdf/1003.2165',
	 'subjects': u'Number Theory (math.NT)',
	 'title': u'\nCoarse-grained integers - Smooth? Rough? Both!',
	 'urllink': u'http://arxiv.org/abs/1003.2165'}
2015-03-24 16:46:39+0000 [xxu46_1] INFO: Crawled 781 pages (at 1 pages/min), scraped 775 items (at 1 items/min)
2015-03-24 16:47:39+0000 [xxu46_1] INFO: Crawled 781 pages (at 0 pages/min), scraped 775 items (at 0 items/min)
2015-03-24 16:47:51+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4012> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 16:47:51+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4012>
	{'abstract': u'In this paper, we analyze a knapsack schemes. The one is suggested by Su, which is relied on a new method entitled permutation combination method. We demonstrate that this permutation method is useless to the security of the scheme. Since the special super increasing construction, we can break this scheme employ the algorithm provided by Shamir scheme. Finally, we provide an enhanced version of Su scheme to avoid these attacks.',
	 'authors': u'Sattar J. Aboud,',
	 'category': u'Computer Science ',
	 'date': '2010-5-21',
	 'pdflink': u'http://arxiv.org/pdf/1005.4012',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nCriticism of Knapsack Encryption Scheme',
	 'urllink': u'http://arxiv.org/abs/1005.4012'}
2015-03-24 16:48:39+0000 [xxu46_1] INFO: Crawled 782 pages (at 1 pages/min), scraped 776 items (at 1 items/min)
2015-03-24 16:49:36+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1001.2447> (referer: http://arxiv.org/list/cs/10?skip=0&show=1000)
2015-03-24 16:49:36+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1001.2447>
	{'abstract': u'We consider the problem of demodulating M-ary optical PPM (pulse-position modulation) waveforms, and propose a structured receiver whose mean probability of symbol error is smaller than all known receivers, and approaches the quantum limit. The receiver uses photodetection coupled with optimized phase-coherent optical feedback control and a phase-sensitive parametric amplifier. We present a general framework of optical receivers known as the conditional pulse nulling receiver, and present new results on ultimate limits and achievable regions of spectral versus photon efficiency tradeoffs for the single-spatial-mode pure-loss optical communication channel.',
	 'authors': u'Saikat Guha, Jonathan L. Habif, Masahiro Takeoka,',
	 'category': u'Computer Science ',
	 'date': '2010-1-14',
	 'pdflink': u'http://arxiv.org/pdf/1001.2447',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nPPM demodulation: On approaching fundamental limits of optical  communications',
	 'urllink': u'http://arxiv.org/abs/1001.2447'}
2015-03-24 16:49:39+0000 [xxu46_1] INFO: Crawled 783 pages (at 1 pages/min), scraped 777 items (at 1 items/min)
2015-03-24 16:50:39+0000 [xxu46_1] INFO: Crawled 783 pages (at 0 pages/min), scraped 777 items (at 0 items/min)
2015-03-24 16:51:18+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1003.3384> (referer: http://arxiv.org/list/cs/10?skip=1000&show=1000)
2015-03-24 16:51:18+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1003.3384>
	{'abstract': u"Scaling limits are analyzed for stochastic continuous opinion dynamics systems, also known as gossip models. In such models, agents update their vector-valued opinion to a convex combination (possibly agent- and opinion-dependent) of their current value and that of another observed agent. It is shown that, in the limit of large agent population size, the empirical opinion density concentrates, at an exponential probability rate, around the solution of a probability-measure-valued ordinary differential equation describing the system's mean-field dynamics. Properties of the associated initial value problem are studied. The asymptotic behavior of the solution is analyzed for bounded-confidence opinion dynamics, and in the presence of an heterogeneous influential environment.",
	 'authors': u'Giacomo Como, Fabio Fagnani,',
	 'category': u'Computer Science ',
	 'date': '2010-3-17',
	 'pdflink': u'http://arxiv.org/pdf/1003.3384',
	 'subjects': u'Probability (math.PR)',
	 'title': u'\nScaling limits for continuous opinion dynamics systems',
	 'urllink': u'http://arxiv.org/abs/1003.3384'}
2015-03-24 16:51:39+0000 [xxu46_1] INFO: Crawled 784 pages (at 1 pages/min), scraped 778 items (at 1 items/min)
2015-03-24 16:52:16+0000 [xxu46_1] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1005.4010> (referer: http://arxiv.org/list/cs/10?skip=2000&show=1000)
2015-03-24 16:52:16+0000 [xxu46_1] DEBUG: Scraped from <200 http://arxiv.org/abs/1005.4010>
	{'abstract': u'Multicast plays an important role in implementing the group communications in bandwidth scarce multihop mobile ad hoc networks. However, due to the dynamic topology of MANETs it is very difficult to build optimal multicast trees and maintaining group membership, making even more challenging to implement scalable and robust multicast in Mobile Ad hoc Networks (MANET). A scalable and energy efficient location aware multicast algorithm, called SEELAMP, for mobile ad hoc networks is presented in the paper that is based on creation of shared tree using the physical location of the nodes for the multicast sessions. It constructs a shared bi-directional multicast tree for its routing operations rather than a mesh, which helps in achieving more efficient multicast delivery. The algorithm uses the concept of small overlapped zones around each node for proactive topology maintenance with in the zone. Protocol depends on the location information obtained using a distributed location service, which effectively reduces the overheads for route searching and shared multicast tree maintenance. In this paper a new technique of local connectivity management is being proposed that attempts to improve the performance and reliability. It employs a preventive route reconfiguration to avoid the latency in case of link breakages and to prevent the network from splitting.',
	 'authors': u'Pariza Kamboj, A.K.Sharma,',
	 'category': u'Computer Science ',
	 'date': '2010-5-21',
	 'pdflink': u'http://arxiv.org/pdf/1005.4010',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nScalable Energy Efficient Location Aware Multicast Protocol for MANET  (SEELAMP)',
	 'urllink': u'http://arxiv.org/abs/1005.4010'}
2015-03-24 16:52:39+0000 [xxu46_1] INFO: Crawled 785 pages (at 1 pages/min), scraped 779 items (at 1 items/min)
