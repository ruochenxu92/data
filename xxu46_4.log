nohup: ignoring input
2015-03-23 21:41:20+0000 [scrapy] INFO: Scrapy 0.24.5 started (bot: superqq_spider)
2015-03-23 21:41:20+0000 [scrapy] INFO: Optional features available: ssl, http11, boto
2015-03-23 21:41:20+0000 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'superqq_spider.spiders', 'SPIDER_MODULES': ['superqq_spider.spiders'], 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 12, 'BOT_NAME': 'superqq_spider'}
2015-03-23 21:41:20+0000 [scrapy] INFO: Enabled extensions: LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, SpiderState
2015-03-23 21:41:20+0000 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentPoolMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-03-23 21:41:20+0000 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-03-23 21:41:20+0000 [scrapy] INFO: Enabled item pipelines: JsonWriterPipeline
2015-03-23 21:41:20+0000 [xxu46_4] INFO: Spider opened
2015-03-23 21:41:20+0000 [xxu46_4] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-03-23 21:41:20+0000 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6026
2015-03-23 21:41:20+0000 [scrapy] DEBUG: Web service listening on 127.0.0.1:6083
2015-03-23 21:41:29+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/list/cs/12?skip=6000&show=1000> (referer: None)
2015-03-23 21:42:06+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/list/cs/12?skip=5000&show=1000> (referer: None)
2015-03-23 21:42:19+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/list/cs/12?skip=4000&show=1000> (referer: None)
2015-03-23 21:42:20+0000 [xxu46_4] INFO: Crawled 3 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2015-03-23 21:42:27+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/list/cs/12?skip=3000&show=1000> (referer: None)
2015-03-23 21:42:45+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/list/cs/12?skip=2000&show=1000> (referer: None)
2015-03-23 21:42:55+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.7051> (referer: http://arxiv.org/list/cs/12?skip=6000&show=1000)
2015-03-23 21:42:57+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.7051>
	{'abstract': u'We develop stochastic variational inference, a scalable algorithm for approximating posterior distributions. We develop this technique for a large class of probabilistic models and we demonstrate it with two probabilistic topic models, latent Dirichlet allocation and the hierarchical Dirichlet process topic model. Using stochastic variational inference, we analyze several large collections of documents: 300K articles from Nature, 1.8M articles from The New York Times, and 3.8M articles from Wikipedia. Stochastic inference can easily handle data sets of this size and outperforms traditional variational inference, which can only handle a smaller subset. (We also show that the Bayesian nonparametric topic model outperforms its parametric counterpart.) Stochastic variational inference lets us apply complex Bayesian models to massive data sets.',
	 'authors': u'Matt Hoffman, David M. Blei, Chong Wang, John Paisley,',
	 'category': u'Computer Science ',
	 'date': '2012-6-29',
	 'pdflink': u'http://arxiv.org/pdf/1206.7051',
	 'subjects': u'Machine Learning (stat.ML)',
	 'title': u'\nStochastic Variational Inference',
	 'urllink': u'http://arxiv.org/abs/1206.7051'}
2015-03-23 21:42:59+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/list/cs/12?skip=1000&show=1000> (referer: None)
2015-03-23 21:43:13+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6391> (referer: http://arxiv.org/list/cs/12?skip=6000&show=1000)
2015-03-23 21:43:15+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6391>
	{'abstract': u'Direct quantile regression involves estimating a given quantile of a response variable as a function of input variables. We present a new framework for direct quantile regression where a Gaussian process model is learned, minimising the expected tilted loss function. The integration required in learning is not analytically tractable so to speed up the learning we employ the Expectation Propagation algorithm. We describe how this work relates to other quantile regression methods and apply the method on both synthetic and real data sets. The method is shown to be competitive with state of the art methods whilst allowing for the leverage of the full Gaussian process probabilistic framework.',
	 'authors': u'Alexis Boukouvalas, Remi Barillec, Dan Cornford,',
	 'category': u'Computer Science ',
	 'date': '2012-6-27',
	 'pdflink': u'http://arxiv.org/pdf/1206.6391',
	 'subjects': u'Methodology (stat.ME)',
	 'title': u'\nGaussian Process Quantile Regression using Expectation Propagation',
	 'urllink': u'http://arxiv.org/abs/1206.6391'}
2015-03-23 21:43:21+0000 [xxu46_4] INFO: Crawled 8 pages (at 5 pages/min), scraped 2 items (at 2 items/min)
2015-03-23 21:43:28+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6408> (referer: http://arxiv.org/list/cs/12?skip=6000&show=1000)
2015-03-23 21:43:30+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6408>
	{'abstract': u'We present algorithms for nonparametric regression in settings where the data are obtained sequentially. While traditional estimators select bandwidths that depend upon the sample size, for sequential data the effective sample size is dynamically changing. We propose a linear time algorithm that adjusts the bandwidth for each new data point, and show that the estimator achieves the optimal minimax rate of convergence. We also propose the use of online expert mixing algorithms to adapt to unknown smoothness of the regression function. We provide simulations that confirm the theoretical results, and demonstrate the effectiveness of the methods.',
	 'authors': u'Haijie Gu, John Lafferty,',
	 'category': u'Computer Science ',
	 'date': '2012-6-27',
	 'pdflink': u'http://arxiv.org/pdf/1206.6408',
	 'subjects': u'Methodology (stat.ME)',
	 'title': u'\nSequential Nonparametric Regression',
	 'urllink': u'http://arxiv.org/abs/1206.6408'}
2015-03-23 21:43:43+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6433> (referer: http://arxiv.org/list/cs/12?skip=6000&show=1000)
2015-03-23 21:43:44+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6433>
	{'abstract': u'We introduce a copula mixture model to perform dependency-seeking clustering when co-occurring samples from different data sources are available. The model takes advantage of the great flexibility offered by the copulas framework to extend mixtures of Canonical Correlation Analysis to multivariate data with arbitrary continuous marginal densities. We formulate our model as a non-parametric Bayesian mixture, while providing efficient MCMC inference. Experiments on synthetic and real data demonstrate that the increased flexibility of the copula mixture significantly improves the clustering and the interpretability of the results.',
	 'authors': u'Melanie Rey, Volker Roth,',
	 'category': u'Computer Science ',
	 'date': '2012-6-27',
	 'pdflink': u'http://arxiv.org/pdf/1206.6433',
	 'subjects': u'Methodology (stat.ME)',
	 'title': u'\nCopula Mixture Model for Dependency-seeking Clustering',
	 'urllink': u'http://arxiv.org/abs/1206.6433'}
2015-03-23 21:43:54+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6456> (referer: http://arxiv.org/list/cs/12?skip=6000&show=1000)
2015-03-23 21:43:55+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6456>
	{'abstract': u'In regression analysis of counts, a lack of simple and efficient algorithms for posterior computation has made Bayesian approaches appear unattractive and thus underdeveloped. We propose a lognormal and gamma mixed negative binomial (NB) regression model for counts, and present efficient closed-form Bayesian inference; unlike conventional Poisson models, the proposed approach has two free parameters to include two different kinds of random effects, and allows the incorporation of prior information, such as sparsity in the regression coefficients. By placing a gamma distribution prior on the NB dispersion parameter r, and connecting a lognormal distribution prior with the logit of the NB probability parameter p, efficient Gibbs sampling and variational Bayes inference are both developed. The closed-form updates are obtained by exploiting conditional conjugacy via both a compound Poisson representation and a Polya-Gamma distribution based data augmentation approach. The proposed Bayesian inference can be implemented routinely, while being easily generalizable to more complex settings involving multivariate dependence structures. The algorithms are illustrated using real examples.',
	 'authors': u'Mingyuan Zhou, Lingbo Li, David Dunson, Lawrence Carin,',
	 'category': u'Computer Science ',
	 'date': '2012-6-27',
	 'pdflink': u'http://arxiv.org/pdf/1206.6456',
	 'subjects': u'Applications (stat.AP)',
	 'title': u'\nLognormal and Gamma Mixed Negative Binomial Regression',
	 'urllink': u'http://arxiv.org/abs/1206.6456'}
2015-03-23 21:44:08+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6488> (referer: http://arxiv.org/list/cs/12?skip=6000&show=1000)
2015-03-23 21:44:10+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6488>
	{'abstract': u"We propose a semiparametric approach, named nonparanormal skeptic, for estimating high dimensional undirected graphical models. In terms of modeling, we consider the nonparanormal family proposed by Liu et al (2009). In terms of estimation, we exploit nonparametric rank-based correlation coefficient estimators including the Spearman's rho and Kendall's tau. In high dimensional settings, we prove that the nonparanormal skeptic achieves the optimal parametric rate of convergence in both graph and parameter estimation. This result suggests that the nonparanormal graphical models are a safe replacement of the Gaussian graphical models, even when the data are Gaussian.",
	 'authors': u'Han Liu, Fang Han, Ming Yuan, John Lafferty, Larry Wasserman,',
	 'category': u'Computer Science ',
	 'date': '2012-6-27',
	 'pdflink': u'http://arxiv.org/pdf/1206.6488',
	 'subjects': u'Methodology (stat.ME)',
	 'title': u'\nThe Nonparanormal SKEPTIC',
	 'urllink': u'http://arxiv.org/abs/1206.6488'}
2015-03-23 21:44:21+0000 [xxu46_4] INFO: Crawled 12 pages (at 4 pages/min), scraped 6 items (at 4 items/min)
2015-03-23 21:44:23+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.5057> (referer: http://arxiv.org/list/cs/12?skip=6000&show=1000)
2015-03-23 21:44:24+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.5057>
	{'abstract': u'In robust statistics, the breakdown point of an estimator is the percentage of outliers with which an estimator still generates reliable estimation. The upper bound of breakdown point is 50%, which means it is not possible to generate reliable estimation with more than half outliers. In this paper, it is shown that for majority of experiences, when the outliers exceed 50%, but if they are distributed randomly enough, it is still possible to generate a reliable estimation from minority good observations. The phenomenal of that the breakdown point is larger than 50% is named as super robustness. And, in this paper, a robust estimator is called strict robust if it generates a perfect estimation when all the good observations are perfect. More specifically, the super robustness of the maximum likelihood estimator of the exponential power distribution, or L^p estimation, where p&lt;1, is investigated. This paper starts with proving that L^p (p&lt;1) is a strict robust location estimator. Further, it is proved that L^p (p &lt; 1)has the property of strict super-robustness on translation, rotation, scaling transformation and robustness on Euclidean transform.',
	 'authors': u'Qinghuai Gao,',
	 'category': u'Computer Science ',
	 'date': '2012-6-22',
	 'pdflink': u'http://arxiv.org/pdf/1206.5057',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nThe Robustness and Super-Robustness of L^p Estimation, when p < 1',
	 'urllink': u'http://arxiv.org/abs/1206.5057'}
2015-03-23 21:44:40+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.3215> (referer: http://arxiv.org/list/cs/12?skip=6000&show=1000)
2015-03-23 21:44:42+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.3215>
	{'abstract': u'A comparison of PGI OpenACC, FORTRAN CUDA, and Nvidia CUDA pseudospectral methods on a single GPU and GCC FORTRAN on single and multiple CPU cores is reported. The GPU implementations use CuFFT and the CPU implementations use FFTW. Porting pre-existing FORTRAN codes to utilize a GPUs is efficient and easy to implement with OpenACC and CUDA FORTRAN. Example programs are provided.',
	 'authors': u'B. Cloutier, B. K. Muite, P. Rigge,',
	 'category': u'Computer Science ',
	 'date': '2012-6-14',
	 'pdflink': u'http://arxiv.org/pdf/1206.3215',
	 'subjects': u'Computational Physics (physics.comp-ph)',
	 'title': u'\nPerformance of FORTRAN and C GPU Extensions for a Benchmark Suite of  Fourier Pseudospectral Algorithms',
	 'urllink': u'http://arxiv.org/abs/1206.3215'}
2015-03-23 21:44:53+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.1121> (referer: http://arxiv.org/list/cs/12?skip=6000&show=1000)
2015-03-23 21:44:55+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.1121>
	{'abstract': u'Numerous data mining techniques have been developed to extract information and identify patterns and predict trends from large data sets. In this study, two classification techniques, the J48 implementation of the C4.5 algorithm and a Naive Bayes classifier are applied to predict lung cancer survivability from an extensive data set with fifteen years of patient records. The purpose of the project is to verify the predictive effectiveness of the two techniques on real, historical data. Besides the performance outcome that renders J48 marginally better than the Naive Bayes technique, there is a detailed description of the data and the required pre-processing activities. The performance results confirm expectations while some of the issues that appeared during experimentation, underscore the value of having domain-specific understanding to leverage any domain-specific characteristics inherent in the data.',
	 'authors': u'George Dimitoglou, James A. Adams, Carol M. Jim,',
	 'category': u'Computer Science ',
	 'date': '2012-6-6',
	 'pdflink': u'http://arxiv.org/pdf/1206.1121',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nComparison of the C4.5 and a Naive Bayes Classifier for the Prediction  of Lung Cancer Survivability',
	 'urllink': u'http://arxiv.org/abs/1206.1121'}
2015-03-23 21:45:05+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.4481> (referer: http://arxiv.org/list/cs/12?skip=6000&show=1000)
2015-03-23 21:45:07+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.4481>
	{'abstract': u'The classification of high dimensional data with kernel methods is considered in this article. Exploit- ing the emptiness property of high dimensional spaces, a kernel based on the Mahalanobis distance is proposed. The computation of the Mahalanobis distance requires the inversion of a covariance matrix. In high dimensional spaces, the estimated covariance matrix is ill-conditioned and its inversion is unstable or impossible. Using a parsimonious statistical model, namely the High Dimensional Discriminant Analysis model, the specific signal and noise subspaces are estimated for each considered class making the inverse of the class specific covariance matrix explicit and stable, leading to the definition of a parsimonious Mahalanobis kernel. A SVM based framework is used for selecting the hyperparameters of the parsimonious Mahalanobis kernel by optimizing the so-called radius-margin bound. Experimental results on three high dimensional data sets show that the proposed kernel is suitable for classifying high dimensional data, providing better classification accuracies than the conventional Gaussian kernel.',
	 'authors': u'M. Fauvel, A. Villa, J. Chanussot, J. A. Benediktsson,',
	 'category': u'Computer Science ',
	 'date': '2012-6-20',
	 'pdflink': u'http://arxiv.org/pdf/1206.4481',
	 'subjects': u'Numerical Analysis (cs.NA)',
	 'title': u'\nParsimonious Mahalanobis Kernel for the Classification of High  Dimensional Data',
	 'urllink': u'http://arxiv.org/abs/1206.4481'}
2015-03-23 21:45:12+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.1623> (referer: http://arxiv.org/list/cs/12?skip=6000&show=1000)
2015-03-23 21:45:35+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.1623>
	{'abstract': u'We generalize Newton-type methods for minimizing smooth functions to handle a sum of two convex functions: a smooth function and a nonsmooth function with a simple proximal mapping. We show that the resulting proximal Newton-type methods inherit the desirable convergence behavior of Newton-type methods for minimizing smooth functions, even when search directions are computed inexactly. Many popular methods tailored to problems arising in bioinformatics, signal processing, and statistical learning are special cases of proximal Newton-type methods, and our analysis yields new convergence results for some of these methods.',
	 'authors': u'Jason D. Lee, Yuekai Sun, Michael A. Saunders,',
	 'category': u'Computer Science ',
	 'date': '2012-6-7',
	 'pdflink': u'http://arxiv.org/pdf/1206.1623',
	 'subjects': u'Machine Learning (stat.ML)',
	 'title': u'\nProximal Newton-type methods for minimizing composite functions',
	 'urllink': u'http://arxiv.org/abs/1206.1623'}
2015-03-23 21:45:36+0000 [xxu46_4] INFO: Crawled 17 pages (at 5 pages/min), scraped 11 items (at 5 items/min)
2015-03-23 21:45:39+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1207.3636> (referer: http://arxiv.org/list/cs/12?skip=6000&show=1000)
2015-03-23 21:45:41+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1207.3636>
	{'abstract': u'Cloud computing is drastically growing technology which provides an on-demand software, hardware, infrastructure and data storage as services. This technology is used worldwide to improve the business infrastructure and performance. However, to utilize these services by intended customer, it is necessary to have strong password authentication. At present, cloud password authentication can be done in several ways, such as, textual password, graphical and 3D password. In this paper, we are proposing the strong password generation technique by considering multiple input parameters of cloud paradigm referred as a multidimensional password. This paper presents the multidimensional password generation technique along with architecture, sequence diagrams, algorithms and typical user interfaces. At the end, we derive the probability of breaking our authentication system.',
	 'authors': u'Dinesha H. A., V. K. Agrawa,',
	 'category': u'Computer Science ',
	 'date': '2012-7-16',
	 'pdflink': u'http://arxiv.org/pdf/1207.3636',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nMulti-dimensional password generation technique for accessing cloud  services',
	 'urllink': u'http://arxiv.org/abs/1207.3636'}
2015-03-23 21:45:57+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.1833> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-23 21:45:59+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.1833>
	{'abstract': u'In this paper we describe CyberChair, a web-based groupware application that supports the review process for technical contributions to conferences. CyberChair deals with most administrative tasks that are involved in the review process, such as storing author information, abstracts, (camera-ready) papers and reviews. It generates several overviews based on the reviews which support the Program Committee (PC) in selecting the best papers. CyberChair points out conflicting reviews and offers the reviewers means to easily communicate to solve these conflicts. In his paper Identify the Champion, O. Nierstrasz describes this review process in terms of a pattern language. CyberChair supports PCs by using these patterns in its implementation.',
	 'authors': u'Richard van de Stadt,',
	 'category': u'Computer Science ',
	 'date': '2012-6-8',
	 'pdflink': u'http://arxiv.org/pdf/1206.1833',
	 'subjects': u'Digital Libraries (cs.DL)',
	 'title': u'\nCyberChair: A Web-Based Groupware Application to Facilitate the Paper  Reviewing Process',
	 'urllink': u'http://arxiv.org/abs/1206.1833'}
2015-03-23 21:46:11+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.1144> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 21:46:13+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.1144>
	{'abstract': u'Design of Random Modulation Pre-Integration systems based on the restricted-isometry property may be suboptimal when the energy of the signals to be acquired is not evenly distributed, i.e. when they are both sparse and localized. To counter this, we introduce an additional design criterion, that we call rakeness, accounting for the amount of energy that the measurements capture from the signal to be acquired. Hence, for localized signals a proper system tuning increases the rakeness as well as the average SNR of the samples used in its reconstruction. Yet, maximizing average SNR may go against the need of capturing all the components that are potentially non-zero in a sparse signal, i.e., against the restricted isometry requirement ensuring reconstructability. What we propose is to administer the trade-off between rakeness and restricted isometry in a statistical way by laying down an optimization problem. The solution of such an optimization problem is the statistic of the process generating the random waveforms onto which the signal is projected to obtain the measurements. The formal definition of such a problems is given as well as its solution for signals that are either localized in frequency or in more generic domain. Sample applications, to ECG signals and small images of printed letters and numbers, show that rakeness-based design leads to non-negligible improvements in both cases.',
	 'authors': u'Mauro Mangia, Riccardo Rovatti, Gianluca Setti,',
	 'category': u'Computer Science ',
	 'date': '2012-5-5',
	 'pdflink': u'http://arxiv.org/pdf/1205.1144',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nRakeness in the design of Analog-to-Information Conversion of Sparse and  Localized Signals',
	 'urllink': u'http://arxiv.org/abs/1205.1144'}
2015-03-23 21:46:13+0000 [xxu46_4] DEBUG: Filtered duplicate request: <GET http://arxiv.org/abs/1206.4481> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2015-03-23 21:46:21+0000 [xxu46_4] INFO: Crawled 20 pages (at 3 pages/min), scraped 14 items (at 3 items/min)
2015-03-23 21:48:19+0000 [xxu46_4] INFO: Crawled 20 pages (at 0 pages/min), scraped 14 items (at 0 items/min)
2015-03-23 21:54:50+0000 [xxu46_4] INFO: Crawled 20 pages (at 0 pages/min), scraped 14 items (at 0 items/min)
2015-03-23 21:55:21+0000 [xxu46_4] INFO: Crawled 20 pages (at 0 pages/min), scraped 14 items (at 0 items/min)
2015-03-23 21:56:20+0000 [xxu46_4] INFO: Crawled 20 pages (at 0 pages/min), scraped 14 items (at 0 items/min)
2015-03-23 21:57:21+0000 [xxu46_4] INFO: Crawled 20 pages (at 0 pages/min), scraped 14 items (at 0 items/min)
2015-03-23 21:58:20+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.3074> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 21:58:20+0000 [xxu46_4] INFO: Crawled 21 pages (at 1 pages/min), scraped 14 items (at 0 items/min)
2015-03-23 21:58:21+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.3074>
	{'abstract': u'We present Conedy, a performant scientific tool to numerically investigate dynamics on complex networks. Conedy allows to create networks and provides automatic code generation and compilation to ensure performant treatment of arbitrary node dynamics. Conedy can be interfaced via an internal script interpreter or via a Python module.',
	 'authors': u'Alexander Rothkegel, Klaus Lehnertz,',
	 'category': u'Computer Science ',
	 'date': '2012-2-14',
	 'pdflink': u'http://arxiv.org/pdf/1202.3074',
	 'subjects': u'Computational Physics (physics.comp-ph)',
	 'title': u'\nConedy: a scientific tool to investigate Complex Network Dynamics',
	 'urllink': u'http://arxiv.org/abs/1202.3074'}
2015-03-23 21:58:37+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.4155> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 21:58:38+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.4155>
	{'abstract': u'We study randomized and quantum efficiency lower bounds in communication complexity. These arise from the study of zero-communication protocols in which players are allowed to abort. Our scenario is inspired by the physics setup of Bell experiments, where two players share a predefined entangled state but are not allowed to communicate. Each is given a measurement as input, which they perform on their share of the system. The outcomes of the measurements should follow a distribution predicted by quantum mechanics; however, in practice, the detectors may fail to produce an output in some of the runs. The efficiency of the experiment is the probability that the experiment succeeds (neither of the detectors fails). When the players share a quantum state, this gives rise to a new bound on quantum communication complexity (eff*) that subsumes the factorization norm. When players share randomness instead of a quantum state, the efficiency bound (eff), coincides with the partition bound of Jain and Klauck. This is one of the strongest lower bounds known for randomized communication complexity, which subsumes all the known combinatorial and algebraic methods including the rectangle (corruption) bound, the factorization norm, and discrepancy. The lower bound is formulated as a convex optimization problem. In practice, the dual form is more feasible to use, and we show that it amounts to constructing an explicit Bell inequality (for eff) or Tsirelson inequality (for eff*). We give an example of a quantum distribution where the violation can be exponentially bigger than the previously studied class of normalized Bell inequalities. For one-way communication, we show that the quantum one-way partition bound is tight for classical communication with shared entanglement up to arbitrarily small error.',
	 'authors': u'S. Laplante, V. Lerays, J. Roland,',
	 'category': u'Computer Science ',
	 'date': '2012-3-19',
	 'pdflink': u'http://arxiv.org/pdf/1203.4155',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nClassical and quantum partition bound and detector inefficiency',
	 'urllink': u'http://arxiv.org/abs/1203.4155'}
2015-03-23 21:59:02+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.5513> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 21:59:03+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.5513>
	{'abstract': u'Impulse cuts off entropy functional measure (EF) on Markov diffusion process trajectories-solutions of Ito controllable stochastic equation. Process additive functional defines EF reducing the functional on trajectories to a regular integral functional. Compared to Shannon entropy measure of random state, cutting process on separated states decreases quantity information concealed in the states correlation holding hidden process information. Multidimensional process cutoffs generate finite information measure integrated by information path functional (IPF) whose information approaches EF measure at infinite dimensions restricting maximal information of the Markov diffusion process. Delta impulse and discrete impulse deliver equivalent information at each cutoff. Finite restriction limits impulses discrete actions cutting the regular integral on EF increments between the cutoffs. Finite impulse step-up action transfers EF increment to following impulse whose step-down action cuts off information and step-up action starts imaginary impulse carrying entropy increment to next real cut. Step-down cut generates maximal information while the step-up action delivers minimal information from impulse cut to next impulse step-down action. Virtual impulse transfers conjugated entropy increments during microprocess ending with adjoining increment within actual step-down action at cutoff. Extracting maximum of minimal impulse information and transferring minimal entropy between impulses implement maxmin-minimax principle of converting process entropy to information. Macroprocess integrates imaginary entropy of microprocess and cutoff information of real impulses in IPF information physical process. EF cut measures Feller kernel information. Estimation extracting information confirms nonadditivity of EF measured process fractions.',
	 'authors': u'Vladimir S. Lerner,',
	 'category': u'Computer Science ',
	 'date': '2012-4-24',
	 'pdflink': u'http://arxiv.org/pdf/1204.5513',
	 'subjects': u'Adaptation and Self-Organizing Systems (nlin.AO)',
	 'title': u'\nEvaluation of cutting off entropy functional measure on trajectories of  Markov diffusion process and information path functional',
	 'urllink': u'http://arxiv.org/abs/1204.5513'}
2015-03-23 21:59:19+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0420> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 21:59:19+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0420>
	{'abstract': u'Wireless sensor networks sense and monitor real-time events. They supervise a geographic area where a phenomenon is to be monitored. The data in sensor networks have different levels of priority and hence their criticality differs. In order to keep up the real time commitment, the applications need higher transmission rates and reliability in information delivery. In this work we propose a multipath routing algorithm which enables the reliable delivery of data. By controlling the scheduling rate, it is possible to prevent congestion and packet loss in the network. The algorithm provides an efficient way to prevent the packet loss at each node. This results in congestion management in the sensor networks. This protocol prevents packet clustering and provides smoothness to the traffic. Through monitoring and controlling the scheduling rate the flow control and congestion control are managed.',
	 'authors': u'Mary Cherian, T. R. Gopalakrishnan Nair,',
	 'category': u'Computer Science ',
	 'date': '2012-6-3',
	 'pdflink': u'http://arxiv.org/pdf/1206.0420',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nMultipath Routing With Novel Packet Scheduling Approach In Wireless  Sensor Networks',
	 'urllink': u'http://arxiv.org/abs/1206.0420'}
2015-03-23 21:59:20+0000 [xxu46_4] INFO: Crawled 24 pages (at 3 pages/min), scraped 18 items (at 4 items/min)
2015-03-23 21:59:33+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.3062> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 21:59:33+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.3062>
	{'abstract': u'We investigate the communication sequences of millions of people through two different channels and analyze the fine grained temporal structure of correlated event trains induced by single individuals. By focusing on correlations between the heterogeneous dynamics and the topology of egocentric networks we find that the bursty trains usually evolve for pairs of individuals rather than for the ego and his/her several neighbors thus burstiness is a property of the links rather than of the nodes. We compare the directional balance of calls and short messages within bursty trains to the average on the actual link and show that for the trains of voice calls the imbalance is significantly enhanced, while for short messages the balance within the trains increases. These effects can be partly traced back to the technological constrains (for short messages) and partly to the human behavioral features (voice calls). We define a model that is able to reproduce the empirical results and may help us to understand better the mechanisms driving technology mediated human communication dynamics.',
	 'authors': u'M\xe1rton Karsai, Kimmo Kaski, J\xe1nos Kert\xe9sz,',
	 'category': u'Computer Science ',
	 'date': '2012-2-14',
	 'pdflink': u'http://arxiv.org/pdf/1202.3062',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nCorrelated dynamics in egocentric communication networks',
	 'urllink': u'http://arxiv.org/abs/1202.3062'}
2015-03-23 21:59:50+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.4134> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 21:59:50+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.4134>
	{'abstract': u'Chaotic cryptography describes the use of chaos theory (in particular physical dynamical systems working in chaotic regime as part of communication techniques and computation algorithms) to perform different cryptographic tasks in a cryptographic system. In the end, the question is, can chaotic systems provide alternative techniques able to enhance cryptographic algorithms?. This chapter can be a worthy material to guide the reader in order to answer himself this question. Thus, the objective of this chapter is to give a general vision of what chaotic cryptography is and a comprehensive example that illustrates the main techniques used in this field.',
	 'authors': u'Carmen Pellicer-Lostao, Ricardo Lopez-Ruiz,',
	 'category': u'Computer Science ',
	 'date': '2012-3-19',
	 'pdflink': u'http://arxiv.org/pdf/1203.4134',
	 'subjects': u'Chaotic Dynamics (nlin.CD)',
	 'title': u'\nNotions of Chaotic Cryptography: Sketch of a Chaos based Cryptosystem',
	 'urllink': u'http://arxiv.org/abs/1203.4134'}
2015-03-23 22:00:00+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.5490> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:00:00+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.5490>
	{'abstract': u"This paper solves a pursuit-evasion problem in which a prince must find a princess who is constrained to move on each day from one vertex of a finite graph to another. Unlike the related and much studied `Cops and Robbers Game', the prince has no knowledge of the position of the princess; he may, however, visit any single room he wishes on each day. We characterize the graphs for which the prince has a winning strategy, and determine, for each such graph, the minimum number of days the prince requires to guarantee to find the princess.",
	 'authors': u'John R. Britnell, Mark Wildon,',
	 'category': u'Computer Science ',
	 'date': '2012-4-24',
	 'pdflink': u'http://arxiv.org/pdf/1204.5490',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nFinding a princess in a palace: A pursuit-evasion problem',
	 'urllink': u'http://arxiv.org/abs/1204.5490'}
2015-03-23 22:00:14+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0419> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 22:00:14+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0419>
	{'abstract': u'One of the major challenges of cloud computing is the management of request-response coupling and optimal allocation strategies of computational resources for the various types of service requests. In the normal situations the intelligence required to classify the nature and order of the request using standard methods is insufficient because the arrival of request is at a random fashion and it is meant for multiple resources with different priority order and variety. Hence, it becomes absolutely essential that we identify the trends of different request streams in every category by auto classifications and organize preallocation strategies in a predictive way. It calls for designs of intelligent modes of interaction between the client request and cloud computing resource manager. This paper discusses about the corresponding scheme using Adaptive Resonance Theory-2.',
	 'authors': u'T. R. Gopalakrishnan Nair, P Jayarekha,',
	 'category': u'Computer Science ',
	 'date': '2012-6-3',
	 'pdflink': u'http://arxiv.org/pdf/1206.0419',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nPre-allocation Strategies of Computational Resources in Cloud Computing  using Adaptive Resonance Theory-2',
	 'urllink': u'http://arxiv.org/abs/1206.0419'}
2015-03-23 22:00:20+0000 [xxu46_4] INFO: Crawled 28 pages (at 4 pages/min), scraped 22 items (at 4 items/min)
2015-03-23 22:00:23+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6921> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-23 22:00:23+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6921>
	{'abstract': u"How to distribute welfare in a society is a key issue in the subject of distributional justice, which is deeply involved with notions of fairness. Following a thought experiment by Dworkin, this work considers a society of individuals with different preferences on the welfare distribution and an official to mediate the coordination among them. Based on a simple assumption that an individual's welfare is proportional to how her preference is fulfilled by the actual distribution, we show that an egalitarian preference is a strict Nash equilibrium and can be favorable even in certain inhomogeneous situations. These suggest how communication can encourage and secure a notion of fairness.",
	 'authors': u'Seung Ki Baek, Jung-Kyoo Choi, Beom Jun Kim,',
	 'category': u'Computer Science ',
	 'date': '2012-6-29',
	 'pdflink': u'http://arxiv.org/pdf/1206.6921',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u"\nDworkin's Paradox",
	 'urllink': u'http://arxiv.org/abs/1206.6921'}
2015-03-23 22:00:34+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.3059> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:00:34+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.3059>
	{'abstract': u'In this paper we study a model of synchronization process on scale free networks with degree-degree correlations. This model was already studied on this kind of networks without correlations by Pastore y Piontti , Phys. Rev. E , 046117 (2007). Here, we study the effects of the degree-degree correlation on the behavior of the load fluctuations in the steady state. We found that for assortative networks there exist a specific correlation where the system is optimal synchronized. In addition, we found that close to this optimally value the fluctuations does not depend on the system size and therefore the system becomes fully scalable. This result could be very important for some technological applications. On the other hand, far from the optimal correlation, scales logarithmically with the system size.',
	 'authors': u'Cristian E. La Rocca, Lidia A. Braunstein, Pablo A. Macri,',
	 'category': u'Computer Science ',
	 'date': '2012-2-14',
	 'pdflink': u'http://arxiv.org/pdf/1202.3059',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nSynchronization in Scale Free networks with degree correlation',
	 'urllink': u'http://arxiv.org/abs/1202.3059'}
2015-03-23 22:00:51+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.4084> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:00:51+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.4084>
	{'abstract': u'Proof nets provide abstract counterparts to sequent proofs modulo rule permutations; the idea being that if two proofs have the same underlying proof-net, they are in essence the same proof. Providing a convincing proof-net counterpart to proofs in the classical sequent calculus is thus an important step in understanding classical sequent calculus proofs. By convincing, we mean that (a) there should be a canonical function from sequent proofs to proof nets, (b) it should be possible to check the correctness of a net in polynomial time, (c) every correct net should be obtainable from a sequent calculus proof, and (d) there should be a cut-elimination procedure which preserves correctness. Previous attempts to give proof-net-like objects for propositional classical logic have failed at least one of the above conditions. In [23], the author presented a calculus of proof nets (expansion nets) satisfying (a) and (b); the paper defined a sequent calculus corresponding to expansion nets but gave no explicit demonstration of (c). That sequent calculus, called LK ast in this paper, is a novel one-sided sequent calculus with both additively and multiplicatively formulated disjunction rules. In this paper (a self-contained extended version of [23]), we give a full proof of (c) for expansion nets with respect to LK ast, and in addition give a cut-elimination procedure internal to expansion nets - this makes expansion nets the first notion of proof-net for classical logic satisfying all four criteria.',
	 'authors': u'Richard McKinley,',
	 'category': u'Computer Science ',
	 'date': '2012-3-19',
	 'pdflink': u'http://arxiv.org/pdf/1203.4084',
	 'subjects': u'Logic (math.LO)',
	 'title': u'\nCanonical Proof nets for Classical Logic',
	 'urllink': u'http://arxiv.org/abs/1203.4084'}
2015-03-23 22:01:05+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.5489> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:01:05+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.5489>
	{'abstract': u'Recently, Cygan, Kowalik, and Wykurz [IPL 2009] gave sub-exponential-time approximation algorithms for the Set-Cover problem with approximation ratios better than ln(n). In light of this result, it is natural to ask whether such improvements can be achieved using lift-and-project methods. We present a simpler combinatorial algorithm which has nearly the same time-approximation tradeoff as the algorithm of Cygan et al., and which lends itself naturally to a lift-and-project based approach. At a high level, our approach is similar to the recent work of Karlin, Mathieu, and Nguyen [IPCO 2011], who examined a known PTAS for Knapsack (similar to our combinatorial Set-Cover algorithm) and its connection to hierarchies of LP and SDP relaxations for Knapsack. For Set-Cover, we show that, indeed, using the trick of "lifting the objective function", we can match the performance of our combinatorial algorithm using the LP hierarchy of Lovasz and Schrijver. We also show that this trick is essential: even in the stronger LP hierarchy of Sherali and Adams, the integrality gap remains at least (1-eps) ln(n) at level Omega(n) (when the objective function is not lifted). As shown by Aleknovich, Arora, and Tourlakis [STOC 2005], Set-Cover relaxations stemming from SDP hierarchies (specifically, LS+) have similarly large integrality gaps. This stands in contrast to Knapsack, where Karlin et al. showed that the (much stronger) Lasserre SDP hierarchy reduces the integrality gap to (1+eps) at level O(1). For completeness, we show that LS+ also reduces the integrality gap for Knapsack to (1+eps). This result may be of independent interest, as our LS+ based rounding and analysis are rather different from those of Karlin et al., and to the best of our knowledge this is the first explicit demonstration of such a reduction in the integrality gap of LS+ relaxations after few rounds.',
	 'authors': u'Eden Chlamtac, Zac Friggstad, Konstantinos Georgiou,',
	 'category': u'Computer Science ',
	 'date': '2012-4-24',
	 'pdflink': u'http://arxiv.org/pdf/1204.5489',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nUnderstanding Set Cover: Sub-exponential Time Approximations and  Lift-and-Project Methods',
	 'urllink': u'http://arxiv.org/abs/1204.5489'}
2015-03-23 22:01:18+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0418> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 22:01:18+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0418>
	{'abstract': u"This paper presents an analysis of spinal codes, a class of rateless codes proposed recently. We prove that spinal codes achieve Shannon capacity for the binary symmetric channel (BSC) and the additive white Gaussian noise (AWGN) channel with an efficient polynomial-time encoder and decoder. They are the first rateless codes with proofs of these properties for BSC and AWGN. The key idea in the spinal code is the sequential application of a hash function over the message bits. The sequential structure of the code turns out to be crucial for efficient decoding. Moreover, counter to the wisdom of having an expander structure in good codes, we show that the spinal code, despite its sequential structure, achieves capacity. The pseudo-randomness provided by a hash function suffices for this purpose. Our proof introduces a variant of Gallager's result characterizing the error exponent of random codes for any memoryless channel. We present a novel application of these error-exponent results within the framework of an efficient sequential code. The application of a hash function over the message bits provides a methodical and effective way to de-randomize Shannon's random codebook construction.",
	 'authors': u'Hari Balakrishnan, Peter Iannucci, Jonathan Perry, Devavrat Shah,',
	 'category': u'Computer Science ',
	 'date': '2012-6-3',
	 'pdflink': u'http://arxiv.org/pdf/1206.0418',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nDe-randomizing Shannon: The Design and Analysis of a Capacity-Achieving  Rateless Code',
	 'urllink': u'http://arxiv.org/abs/1206.0418'}
2015-03-23 22:01:20+0000 [xxu46_4] INFO: Crawled 33 pages (at 5 pages/min), scraped 27 items (at 5 items/min)
2015-03-23 22:01:35+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6874> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-23 22:01:35+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6874>
	{'abstract': u'We introduce priors and algorithms to perform Bayesian inference in Gaussian models defined by acyclic directed mixed graphs. Such a class of graphs, composed of directed and bi-directed edges, is a representation of conditional independencies that is closed under marginalization and arises naturally from causal models which allow for unmeasured confounding. Monte Carlo methods and a variational approximation for such models are presented. Our algorithms for Bayesian inference allow the evaluation of posterior distributions for several quantities of interest, including causal effects that are not identifiable from data alone but could otherwise be inferred where informative prior knowledge about confounding is available.',
	 'authors': u'Ricardo Silva, Zoubin Ghahramani,',
	 'category': u'Computer Science ',
	 'date': '2012-6-27',
	 'pdflink': u'http://arxiv.org/pdf/1206.6874',
	 'subjects': u'Methodology (stat.ME)',
	 'title': u'\nBayesian Inference for Gaussian Mixed Graph Models',
	 'urllink': u'http://arxiv.org/abs/1206.6874'}
2015-03-23 22:01:51+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.3013> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:01:51+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.3013>
	{'abstract': u'A group is Markov if it admits a prefix-closed regular language of unique representatives with respect to some generating set, and strongly Markov if it admits such a language of unique minimal-length representatives over every generating set. This paper considers the natural generalizations of these concepts to semigroups and monoids. Two distinct potential generalizations to monoids are shown to be equivalent. Various interesting examples are presented, including an example of a non-Markov monoid that nevertheless admits a regular language of unique representatives over any generating set. It is shown that all finitely generated commutative semigroups are strongly Markov, but that finitely generated subsemigroups of virtually abelian or polycyclic groups need not be. Potential connections with word-hyperbolic semigroups are investigated. A study is made of the interaction of the classes of Markov and strongly Markov semigroups with direct products, free products, and finite-index subsemigroups and extensions. Several questions are posed.',
	 'authors': u'Alan J. Cain, Victor Maltcev,',
	 'category': u'Computer Science ',
	 'date': '2012-2-14',
	 'pdflink': u'http://arxiv.org/pdf/1202.3013',
	 'subjects': u'Group Theory (math.GR)',
	 'title': u'\nMarkov semigroups, monoids, and groups',
	 'urllink': u'http://arxiv.org/abs/1202.3013'}
2015-03-23 22:02:08+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.4069> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:02:08+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.4069>
	{'abstract': u'The problem of finding the largest connected subgraph of a given undirected host graph, subject to constraints on the maximum degree and the diameter , was introduced in cite, as a generalization of the Degree-Diameter Problem. A case of special interest is when the host graph is a common parallel architecture. Here we discuss the case when the host graph is a -dimensional mesh. We provide some general bounds for the order of the largest subgraph in arbitrary dimension , and for the particular cases of and , we give constructions that result in sharper lower bounds.',
	 'authors': u'Mirka Miller, Hebert Perez-Roses, Joe Ryan,',
	 'category': u'Computer Science ',
	 'date': '2012-3-19',
	 'pdflink': u'http://arxiv.org/pdf/1203.4069',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nThe Maximum Degree-and-Diameter-Bounded Subgraph in the Mesh',
	 'urllink': u'http://arxiv.org/abs/1203.4069'}
2015-03-23 22:02:20+0000 [xxu46_4] INFO: Crawled 36 pages (at 3 pages/min), scraped 30 items (at 3 items/min)
2015-03-23 22:02:22+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.3188> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:02:22+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.3188>
	{'abstract': u'Complex networks of real-world systems are believed to be controlled by common phenomena, producing structures far from regular or random. Clustering, community structure and assortative mixing by degree are perhaps among most prominent examples of the latter. Although generally accepted for social networks, these properties only partially explain the structure of other networks. We first show that degree-corrected clustering is in contrast to standard definition highly assortative. Yet interesting on its own, we further note that non-social networks contain connected regions with very low clustering. Hence, the structure of real-world networks is beyond communities. We here investigate the concept of functional modules---groups of regularly equivalent nodes---and show that such structures could explain for the properties observed in non-social networks. Real-world networks might be composed of functional modules that are overlaid by communities. We support the latter by proposing a simple network model that generates scale-free small-world networks with tunable clustering and degree mixing. Model has a natural interpretation in many real-world networks, while it also gives insights into an adequate community extraction framework. We also present an algorithm for detection of arbitrary structural modules without any prior knowledge. Algorithm is shown to be superior to state-of-the-art, while application to real-world networks reveals well supported composites of different structural modules that are consistent with the underlying systems. Clear functional modules are identified in all types of networks including social. Our findings thus expose functional modules as another key ingredient of complex real-world networks.',
	 'authors': u'Lovro \u0160ubelj, Marko Bajec,',
	 'category': u'Computer Science ',
	 'date': '2012-2-15',
	 'pdflink': u'http://arxiv.org/pdf/1202.3188',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nClustering assortativity, communities and functional modules in  real-world networks',
	 'urllink': u'http://arxiv.org/abs/1202.3188'}
2015-03-23 22:02:39+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.5548> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:02:39+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.5548>
	{'abstract': u"In this paper we are concerned with knight's tours on high-dimensional boards. Our main aim is to show that on the -dimensional board , with even, there is always a knight's tour provided that is sufficiently large. In fact, we give an exact classification of the grids in which there is a knight's tour. This answers questions of DeMaio, DeMaio and Mathew, and Watkins.",
	 'authors': u'Joshua Erde,',
	 'category': u'Computer Science ',
	 'date': '2012-2-24',
	 'pdflink': u'http://arxiv.org/pdf/1202.5548',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u"\nKnight's Tours in Higher Dimensions",
	 'urllink': u'http://arxiv.org/abs/1202.5548'}
2015-03-23 22:02:54+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.6345> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:02:54+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.6345>
	{'abstract': u'Non-communicable diseases like diabetes, obesity and certain forms of cancer have been increasing in many countries at alarming levels. A difficulty in the conception of policies to reverse these trends is the identification of the drivers behind the global epidemics. Here, we implement a spatial spreading analysis to investigate whether diabetes, obesity and cancer show spatial correlations revealing the effect of collective and global factors acting above individual choices. We adapt a theoretical framework for critical physical systems displaying collective behavior to decipher the laws of spatial spreading of diseases. We find a regularity in the spatial fluctuations of their prevalence revealed by a pattern of scale-free long-range correlations. The fluctuations are anomalous, deviating in a fundamental way from the weaker correlations found in the underlying population distribution. This collective behavior indicates that the spreading dynamics of obesity, diabetes and some forms of cancer like lung cancer are analogous to a critical point of fluctuations, just as a physical system in a second-order phase transition. According to this notion, individual interactions and habits may have negligible influence in shaping the global patterns of spreading. Thus, obesity turns out to be a global problem where local details are of little importance. Interestingly, we find the same critical fluctuations in obesity and diabetes, and in the activities of economic sectors associated with food production such as supermarkets, food and beverage stores--- which cluster in a different universality class than other generic sectors of the economy. These results motivate future interventions to investigate the causality of this relation providing guidance for the implementation of preventive health policies.',
	 'authors': u'Lazaros K. Gallos, Pablo Barttfeld, Shlomo Havlin, Mariano Sigman, Hern\xe1n A. Makse,',
	 'category': u'Computer Science ',
	 'date': '2012-2-28',
	 'pdflink': u'http://arxiv.org/pdf/1202.6345',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nCollective behavior and critical fluctuations in the spatial spreading  of obesity, diabetes and cancer',
	 'urllink': u'http://arxiv.org/abs/1202.6345'}
2015-03-23 22:03:07+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0747> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:03:07+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0747>
	{'abstract': u'We analyze the state of the art of content-based retrieval in Earth observation image archives focusing on complete systems showing promise for operational implementation. The different paradigms at the basis of the main system families are introduced. The approaches taken are analyzed, focusing in particular on the phases after primitive feature extraction. The solutions envisaged for the issues related to feature simplification and synthesis, indexing, semantic labeling are reviewed. The methodologies for query specification and execution are analyzed.',
	 'authors': u'Marco Quartulli, Igor G. Olaizola,',
	 'category': u'Computer Science ',
	 'date': '2012-3-4',
	 'pdflink': u'http://arxiv.org/pdf/1203.0747',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nA review of EO image information mining',
	 'urllink': u'http://arxiv.org/abs/1203.0747'}
2015-03-23 22:03:20+0000 [xxu46_4] INFO: Crawled 40 pages (at 4 pages/min), scraped 34 items (at 4 items/min)
2015-03-23 22:03:20+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0744> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:03:20+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0744>
	{'abstract': u'In practical applications, we often have to deal with high order data, such as a grayscale image and a video sequence are intrinsically 2nd-order tensor and 3rd-order tensor, respectively. For doing clustering or classification of these high order data, it is a conventional way to vectorize these data before hand, as PCA or FDA does, which often induce the curse of dimensionality problem. For this reason, experts have developed many methods to deal with the tensorial data, such as multilinear PCA, multilinear LDA, and so on. In this paper, we still address the problem of high order data representation and recognition, and propose to study the result of merging multilinear PCA and multilinear LDA into one scenario, we name it textbf for the abbreviation of Generalized Discriminant Analysis. To evaluate GDA, we perform a series of experiments, and the experimental results demonstrate our GDA outperforms a selection of competing methods such (2D)PCA, (2D)LDA, and MDA.',
	 'authors': u'Shu Kong, Donghui Wang,',
	 'category': u'Computer Science ',
	 'date': '2012-3-4',
	 'pdflink': u'http://arxiv.org/pdf/1203.0744',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nA Report on Multilinear PCA Plus Multilinear LDA to Deal with Tensorial  Data: Visual Classification as An Example',
	 'urllink': u'http://arxiv.org/abs/1203.0744'}
2015-03-23 22:03:37+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0740> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:03:37+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0740>
	{'abstract': u'Advance reservation is important to guarantee the quality of services of jobs by allowing exclusive access to resources over a defined time interval on resources. It is a challenge for the scheduler to organize available resources efficiently and to allocate them for parallel AR jobs with deadline constraint appropriately. This paper provides a slot-based data structure to organize available resources of multiprocessor systems in a way that enables efficient search and update operations, and formulates a suite of scheduling policies to allocate resources for dynamically arriving AR requests. The performance of the scheduling algorithms were investigated by simulations with different job sizes and durations, system loads and scheduling flexibilities. Simulation results show that job sizes and durations, system load and the flexibility of scheduling will impact the performance metrics of all the scheduling algorithms, and the PE-Worst-Fit algorithm becomes the best algorithm for the scheduler with the highest acceptance rate of AR requests, and the jobs with the First-Fit algorithm experience the lowest average slowdown. The data structure and scheduling policies can be used to organize and allocate resources for parallel AR jobs with deadline constraint in large-scale computing systems.',
	 'authors': u'Bo Li, Yijian Pei, Bin Shen, Hao Wu, Min He, Jundong Yang,',
	 'category': u'Computer Science ',
	 'date': '2012-3-4',
	 'pdflink': u'http://arxiv.org/pdf/1203.0740',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nResource Availability-Aware Advance Reservation for Parallel Jobs with  Deadlines',
	 'urllink': u'http://arxiv.org/abs/1203.0740'}
2015-03-23 22:03:52+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0732> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:03:52+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0732>
	{'abstract': u'Data aggregation in intermediate nodes (called aggregator nodes) is an effective approach for optimizing consumption of scarce resources like bandwidth and energy in Wireless Sensor Networks (WSNs). However, in-network processing poses a problem for the privacy of the sensor data since individual data of sensor nodes need to be known to the aggregator node before the aggregation process can be carried out. In applications of WSNs, privacy-preserving data aggregation has become an important requirement due to sensitive nature of the sensor data. Researchers have proposed a number of protocols and schemes for this purpose. He et al. (INFOCOM 2007) have proposed a protocol - called CPDA - for carrying out additive data aggregation in a privacy-preserving manner for application in WSNs. The scheme has been quite popular and well-known. In spite of the popularity of this protocol, it has been found that the protocol is vulnerable to attack and it is also not energy-efficient. In this paper, we first present a brief state of the art survey on the current privacy-preserving data aggregation protocols for WSNS. Then we describe the CPDA protocol and identify its security vulnerability. Finally, we demonstrate how the protocol can be made secure and energy efficient.',
	 'authors': u'Jaydip Sen,',
	 'category': u'Computer Science ',
	 'date': '2012-3-4',
	 'pdflink': u'http://arxiv.org/pdf/1203.0732',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nSecure and Energy-Efficient Data Aggregation in Wireless Sensor Networks',
	 'urllink': u'http://arxiv.org/abs/1203.0732'}
2015-03-23 22:04:08+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0731> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:04:08+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0731>
	{'abstract': u'In this paper, we study the problem of coordinating two nodes which can only exchange information via a relay at limited rates. The nodes are allowed to do a two-round interactive two-way communication with the relay, after which they should be able to generate i.i.d. copies of two random variables with a given joint distribution within a vanishing total variation distance. We prove inner and outer bounds on the coordination capacity region for this problem. Our inner bound is proved using the technique of "output statistics of random binning" that has recently been developed by Yassaee, et al.',
	 'authors': u'Farzin Haddadpour, Mohammad Hossein Yassaee, Amin Gohari, Mohammad Reza Aref,',
	 'category': u'Computer Science ',
	 'date': '2012-3-4',
	 'pdflink': u'http://arxiv.org/pdf/1203.0731',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nCoordination via a relay',
	 'urllink': u'http://arxiv.org/abs/1203.0731'}
2015-03-23 22:04:20+0000 [xxu46_4] INFO: Crawled 44 pages (at 4 pages/min), scraped 38 items (at 4 items/min)
2015-03-23 22:04:24+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0730> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:04:24+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0730>
	{'abstract': u'This paper introduces a new and ubiquitous framework for establishing achievability results in emph (NIT) problems. The framework uses random binning arguments and is based on a duality between channel and source coding problems. the framework uses pmf approximation arguments instead of counting and typicality. This allows for proving coordination and emph secrecy problems where certain statistical conditions on the distribution of random variables need to be satisfied. These statistical conditions include independence between messages and eavesdropper\'s observations in secrecy problems and closeness to a certain distribution (usually, i.i.d. distribution) in coordination problems. One important feature of the framework is to enable one add an eavesdropper and obtain a result on the secrecy rates "for free." We make a case for generality of the framework by studying examples in the variety of settings containing channel coding, lossy source coding, joint source-channel coding, coordination, strong secrecy, feedback and relaying. In particular, by investigating the framework for the lossy source coding problem over broadcast channel, it is shown that the new framework provides a simple alternative scheme to emph coding scheme. Also, new results on secrecy rate region (under strong secrecy criterion) of wiretap broadcast channel and wiretap relay channel are derived. In a set of accompanied papers, we have shown the usefulness of the framework to establish achievability results for coordination problems including interactive channel simulation, coordination via relay and channel simulation via another channel.',
	 'authors': u'Mohammad Hossein Yassaee, Mohammad Reza Aref, Amin Gohari,',
	 'category': u'Computer Science ',
	 'date': '2012-3-4',
	 'pdflink': u'http://arxiv.org/pdf/1203.0730',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nAchievability proof via output statistics of random binning',
	 'urllink': u'http://arxiv.org/abs/1203.0730'}
2015-03-23 22:04:41+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0728> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:04:41+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0728>
	{'abstract': u'Upper and lower bounds are derived for the quantity in the title, which is tabulated for modest values of and An application to graphs with many cycles is given.',
	 'authors': u'A. Alahmadi, R. E. L. Aldred, R. dela Cruz, P. Sol\xe9, C. Thomassen,',
	 'category': u'Computer Science ',
	 'date': '2012-3-4',
	 'pdflink': u'http://arxiv.org/pdf/1203.0728',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nThe maximum number of minimal codewords in an $[n,k]-$code',
	 'urllink': u'http://arxiv.org/abs/1203.0728'}
2015-03-23 22:04:56+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0714> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:04:56+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0714>
	{'abstract': u'Since the time when concept of e-maintenance was introduced, most of the works insisted on the relevance of the underlying Information and Communication Technologies infrastructure. Through a review of current e-maintenance conceptual approaches and realizations, this paper aims to reconsider the predominance of ICT within e-maintenance projects and literature. The review brings to light the importance of intelligence as a fundamental dimension of e-maintenance that is to be led in a holistic predefined manner rather than isolated efforts within ICT driven approaches. As a contribution towards an intelligence based e-maintenance conceptual framework, a proposal is outlined in this paper to model e-maintenance system as an intelligent system. The proposed frame is based on CogAff architecture for intelligent agents. Within the proposed frame, more importance was reserved to the environment that the system is to be continuously aware of: Plant Environment, Internal and External Enterprise Environment and Human Environment. In addition to the abilities required for internal coherent behavior of the system, requirements for maintenance activities support are also mapped within the same frame according to corresponding levels of management. A case study was detailed in this paper sustaining the applicability of the proposal in relation to the classification of existing e-maintenance platforms. However, more work is needed to enhance exhaustiveness of the frame to serve as a comparison tool of existing e-maintenance systems. At the conceptual level, our future work is to use the proposed frame in an e-maintenance project.',
	 'authors': u'Abdessamad Mouzoune,',
	 'category': u'Computer Science ',
	 'date': '2012-3-4',
	 'pdflink': u'http://arxiv.org/pdf/1203.0714',
	 'subjects': u'Multiagent Systems (cs.MA)',
	 'title': u'\nTowards an intelligence based conceptual framework for e-maintenance',
	 'urllink': u'http://arxiv.org/abs/1203.0714'}
2015-03-23 22:05:10+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0699> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:05:10+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0699>
	{'abstract': u"Standard models of multi-agent modal logic do not capture the fact that information is often ambiguous, and may be interpreted in different ways by different agents. We propose a framework that can model this, and consider different semantics that capture different assumptions about the agents' beliefs regarding whether or not there is ambiguity. We consider the impact of ambiguity on a seminal result in economics: Aumann's result saying that agents with a common prior cannot agree to disagree. This result is known not to hold if agents do not have a common prior; we show that it also does not hold in the presence of ambiguity. We then consider the tradeoff between assuming a common interpretation (i.e., no ambiguity) and a common prior (i.e., shared initial beliefs).",
	 'authors': u'Joseph Y. Halpern, Willemien Kets,',
	 'category': u'Computer Science ',
	 'date': '2012-3-4',
	 'pdflink': u'http://arxiv.org/pdf/1203.0699',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nAmbiguous Language and Differences in Beliefs',
	 'urllink': u'http://arxiv.org/abs/1203.0699'}
2015-03-23 22:05:20+0000 [xxu46_4] INFO: Crawled 48 pages (at 4 pages/min), scraped 42 items (at 4 items/min)
2015-03-23 22:05:25+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0695> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:05:25+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0695>
	{'abstract': u"We examine the benefits of user cooperation under compute-and-forward. Much like in network coding, receivers in a compute-and-forward network recover finite-field linear combinations of transmitters' messages. Recovery is enabled by linear codes: transmitters map messages to a linear codebook, and receivers attempt to decode the incoming superposition of signals to an integer combination of codewords. However, the achievable computation rates are low if channel gains do not correspond to a suitable linear combination. In response to this challenge, we propose a cooperative approach to compute-and-forward. We devise a lattice-coding approach to block Markov encoding with which we construct a decode-and-forward style computation strategy. Transmitters broadcast lattice codewords, decode each other's messages, and then cooperatively transmit resolution information to aid receivers in decoding the integer combinations. Using our strategy, we show that cooperation offers a significant improvement both in the achievable computation rate and in the diversity-multiplexing tradeoff.",
	 'authors': u'Matthew Nokleby, Behnaam Aazhang,',
	 'category': u'Computer Science ',
	 'date': '2012-3-3',
	 'pdflink': u'http://arxiv.org/pdf/1203.0695',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nCooperative Compute-and-Forward',
	 'urllink': u'http://arxiv.org/abs/1203.0695'}
2015-03-23 22:05:42+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0692> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:05:42+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0692>
	{'abstract': u'In our previous researches, a new digital watermarking scheme based on chaotic iterations has been introduced. This scheme was both stego-secure and topologically secure. The stego-security is to face an attacker in the "watermark only attack" category, whereas the topological security concerns other categories of attacks. Its Lyapunov exponent is evaluated here, to quantify the chaos generated by this scheme. Keywords : Lyapunov exponent; Information hiding; Security; Chaotic iterations; Digital Watermarking.',
	 'authors': u'Jacques M. Bahi, Nicolas Friot, Christophe Guyeux,',
	 'category': u'Computer Science ',
	 'date': '2012-3-3',
	 'pdflink': u'http://arxiv.org/pdf/1203.0692',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nLyapunov exponent evaluation of a digital watermarking scheme proven to  be secure',
	 'urllink': u'http://arxiv.org/abs/1203.0692'}
2015-03-23 22:05:59+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0683> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:05:59+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0683>
	{'abstract': u'Mixture models are a fundamental tool in applied statistics and machine learning for treating data taken from multiple subpopulations. The current practice for estimating the parameters of such models relies on local search heuristics (e.g., the EM algorithm) which are prone to failure, and existing consistent methods are unfavorable due to their high computational and sample complexity which typically scale exponentially with the number of mixture components. This work develops an efficient method of moments approach to parameter estimation for a broad class of high-dimensional mixture models with many components, including multi-view mixtures of Gaussians (such as mixtures of axis-aligned Gaussians) and hidden Markov models. The new method leads to rigorous unsupervised learning results for mixture models that were not achieved by previous works; and, because of its simplicity, it offers a viable alternative to EM for practical deployment.',
	 'authors': u'Animashree Anandkumar, Daniel Hsu, Sham M. Kakade,',
	 'category': u'Computer Science ',
	 'date': '2012-3-3',
	 'pdflink': u'http://arxiv.org/pdf/1203.0683',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nA Method of Moments for Mixture Models and Hidden Markov Models',
	 'urllink': u'http://arxiv.org/abs/1203.0683'}
2015-03-23 22:06:17+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0681> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:06:17+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0681>
	{'abstract': u'Developing an application with high performance through the code optimization places a greater responsibility on the programmers. While most of the existing compilers attempt to automatically optimize the program code, manual techniques remain the predominant method for performing optimization. Deciding where to try to optimize code is difficult, especially for large complex applications. For manual optimization, the programmers can use his experiences in writing the code, and then he can use a software profiler in order to collect and analyze the performance data from the code. In this work, we have gathered the most experiences which can be applied to improve the style of writing programs in C language as well as we present an implementation of the manual optimization of the codes using the Intel VTune profiler. The paper includes two case studies to illustrate our optimization on the Heap Sort and Factorial functions.',
	 'authors': u'Mohammed Fadle Abdulla,',
	 'category': u'Computer Science ',
	 'date': '2012-3-3',
	 'pdflink': u'http://arxiv.org/pdf/1203.0681',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nManual and Fast C Code Optimization',
	 'urllink': u'http://arxiv.org/abs/1203.0681'}
2015-03-23 22:06:20+0000 [xxu46_4] INFO: Crawled 52 pages (at 4 pages/min), scraped 46 items (at 4 items/min)
2015-03-23 22:06:28+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0670> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:06:28+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0670>
	{'abstract': u"Inspired by a recent graphical formalism for lambda-calculus based on linear logic technology, we introduce an untyped structural lambda-calculus, called lambda j, which combines actions at a distance with exponential rules decomposing the substitution by means of weakening, contraction and derelicition. First, we prove some fundamental properties of lambda j such as confluence and preservation of beta-strong normalisation. Second, we add a strong bisimulation to lambda j by means of an equational theory which captures in particular Regnier's sigma-equivalence. We then complete this bisimulation with two more equations for (de)composition of substitutions and we prove that the resulting calculus still preserves beta-strong normalization. Finally, we discuss some consequences of our results.",
	 'authors': u'Beniamino Accattoli, Delia Kesner,',
	 'category': u'Computer Science ',
	 'date': '2012-3-3',
	 'pdflink': u'http://arxiv.org/pdf/1203.0670',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nPreservation of Strong Normalisation modulo permutations for the  structural lambda-calculus',
	 'urllink': u'http://arxiv.org/abs/1203.0670'}
2015-03-23 22:06:40+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0666> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:06:40+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0666>
	{'abstract': u'Let be a graph with a threshold function such that for every vertex of , where is the degree of in . Suppose we are given a target set . The paper considers the following repetitive process on . At time step 0 the vertices of are colored black and the other vertices are colored white. After that, at each time step , the colors of white vertices (if any) are updated according to the following rule. All white vertices that have at least black neighbors at the time step are colored black, and the colors of the other vertices do not change. The process runs until no more white vertices can update colors from white to black. The following optimization problem is called Target Set Selection: Finding a target set of smallest possible size such that all vertices in are black at the end of the process. Such an is called an for under the threshold function . We are interested in finding an optimal target set for the well-known class of honeycomb networks under an important threshold function called , where for each vertex in . In a graph , a is a subset such that the subgraph induced by is cycle-free. In this paper we give exact value on the size of the optimal target set for various kinds of honeycomb networks under strict majority threshold, and as a by-product we also provide a minimum feedback vertex set for different kinds regular graphs in the class of honeycomb networks',
	 'authors': u'Chun-Ying Chiang, Liang-Hao Huang, Hong-Gwa Yeh,',
	 'category': u'Computer Science ',
	 'date': '2012-3-3',
	 'pdflink': u'http://arxiv.org/pdf/1203.0666',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nTarget set selection problem for honeycomb networks',
	 'urllink': u'http://arxiv.org/abs/1203.0666'}
2015-03-23 22:06:57+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0665> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:06:57+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0665>
	{'abstract': u'This article describes technology for diagnosing SoC HDL-models, based on transactional graph. Diagnosis method is focused to considerable decrease the time of fault detection and memory for storage of diagnosis matrix by means of forming ternary relations in the form of test, monitor, and functional component. The following problems are solved: creation of digital system model in the form of transaction graph and multi-tree of fault detection tables, as well as ternary matrices for activating functional components in tests, relative to the selected set of monitors; development of a method for analyzing the activation matrix to detect the faults with given depth and synthesizing logic functions for subsequent embedded hardware fault diagnosing.',
	 'authors': u'Vladimir Hahanov, Wajeb Gharibi, Eugenia Litvinova, Svetlana Chumachenko,',
	 'category': u'Computer Science ',
	 'date': '2012-3-3',
	 'pdflink': u'http://arxiv.org/pdf/1203.0665',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nVerification and Diagnosis Infrastructure of SoC HDL-model',
	 'urllink': u'http://arxiv.org/abs/1203.0665'}
2015-03-23 22:07:14+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0657> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:07:14+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0657>
	{'abstract': u'In this paper, we analyze the performance of cooperative content caching in vehicular ad hoc networks (VANETs). In particular, we characterize, using analysis and simulations, the behavior of the probability of outage (i.e. not finding a requested data chunk at a neighbor) under freeway vehicular mobility. First, we introduce a formal definition for the probability of outage in the context of cooperative content caching. Second, we characterize, analytically, the outage probability under vehicular and random mobility scenarios. Next, we verify the analytical results using simulations and compare the performance under a number of plausible mobility scenarios. This provides key insights into the problem and the involved trade-offs and enable us to assess the potential opportunity offered by the, somewhat structured, vehicular mobility that can be exploited by cooperative content caching schemes. The presented numerical results exhibit complete agreement between the analytical and simulation studies. Finally, we observe that vehicular mobility creates opportunities for enhanced outage performance under practically relevant scenarios.',
	 'authors': u'Osama Attia, Tamer ElBatt,',
	 'category': u'Computer Science ',
	 'date': '2012-3-3',
	 'pdflink': u'http://arxiv.org/pdf/1203.0657',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nOn the Role of Vehicular Mobility in Cooperative Content Caching',
	 'urllink': u'http://arxiv.org/abs/1203.0657'}
2015-03-23 22:07:20+0000 [xxu46_4] INFO: Crawled 56 pages (at 4 pages/min), scraped 50 items (at 4 items/min)
2015-03-23 22:07:24+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0656> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:07:24+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0656>
	{'abstract': u'The study is from a base of accident scenarii in rail transport (feedback) in order to develop a tool to share build and sustain knowledge and safety and secondly to exploit the knowledge stored to prevent the reproduction of accidents / incidents. This tool should ultimately lead to the proposal of prevention and protection measures to minimize the risk level of a new transport system and thus to improve safety. The approach to achieving this goal largely depends on the use of artificial intelligence techniques and rarely the use of a method of automatic learning in order to develop a feasibility model of a software tool based on case based reasoning (CBR) to exploit stored knowledge in order to create know-how that can help stimulate domain experts in the task of analysis, evaluation and certification of a new system.',
	 'authors': u'Ahmed Maalel, Habib Hadj-Mabrouk,',
	 'category': u'Computer Science ',
	 'date': '2012-3-3',
	 'pdflink': u'http://arxiv.org/pdf/1203.0656',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nContribution of Case Based Reasoning (CBR) in the Exploitation of Return  of Experience. Application to Accident Scenarii in Railroad Transport',
	 'urllink': u'http://arxiv.org/abs/1203.0656'}
2015-03-23 22:07:41+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0653> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:07:41+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0653>
	{'abstract': u'The set of all error--correcting block codes over a fixed alphabet with letters determines a recursively enumerable set of rational points in the unit square with coordinates := (relative transmission rate, relative minimal distance). Limit points of this set form a closed subset, defined by , where is a continuous decreasing function called asymptotic bound. Its existence was proved by the first--named author in 1981 ([Man1]), but no approaches to the computation of this function are known, and in [Man5] it was even suggested that this function might be uncomputable in the sense of constructive analysis. In this note we show that the asymptotic bound becomes computable with the assistance of an oracle producing codes in the order of their growing Kolmogorov complexity. Moreover, a natural partition function involving complexity allows us to interpret the asymptotic bound as a curve dividing two different thermodynamic phases of codes.',
	 'authors': u'Yuri I. Manin, Matilde Marcolli,',
	 'category': u'Computer Science ',
	 'date': '2012-3-3',
	 'pdflink': u'http://arxiv.org/pdf/1203.0653',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nKolmogorov complexity and the asymptotic bound for error-correcting  codes',
	 'urllink': u'http://arxiv.org/abs/1203.0653'}
2015-03-23 22:07:49+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0652> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:07:49+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0652>
	{'abstract': u'Online discussion threads are conversational cascades in the form of posted messages that can be generally found in social systems that comprise many-to-many interaction such as blogs, news aggregators or bulletin board systems. We propose a framework based on generative models of growing trees to analyse the structure and evolution of discussion threads. We consider the growth of a discussion to be determined by an interplay between popularity, novelty and a trend (or bias) to reply to the thread originator. The relevance of these features is estimated using a full likelihood approach and allows to characterize the habits and communication patterns of a given platform and/or community.',
	 'authors': u'Vicen\xe7 G\xf3mez, Hilbert J. Kappen, Nelly Litvak, Andreas Kaltenbrunner,',
	 'category': u'Computer Science ',
	 'date': '2012-3-3',
	 'pdflink': u'http://arxiv.org/pdf/1203.0652',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nA likelihood-based framework for the analysis of discussion threads',
	 'urllink': u'http://arxiv.org/abs/1203.0652'}
2015-03-23 22:08:03+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0651> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:08:03+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0651>
	{'abstract': u'In this paper, we propose an analytical method to model the dependency between configuration parameters and total execution time of Map-Reduce applications. Our approach has three key phases: profiling, modeling, and prediction. In profiling, an application is run several times with different sets of MapReduce configuration parameters to profile the execution time of the application on a given platform. Then in modeling, the relation between these parameters and total execution time is modeled by multivariate linear regression. Among the possible configuration parameters, two main parameters have been used in this study: the number of Mappers, and the number of Reducers. For evaluation, two standard applications (WordCount, and Exim Mainlog parsing) are utilized to evaluate our technique on a 4-node MapReduce platform.',
	 'authors': u'Nikzad Babaii Rizvandi, Albert Y. Zomaya, Ali Javadzadeh Boloori, Javid Taheri,',
	 'category': u'Computer Science ',
	 'date': '2012-3-3',
	 'pdflink': u'http://arxiv.org/pdf/1203.0651',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nOn Modeling Dependency between MapReduce Configuration Parameters and  Total Execution Time',
	 'urllink': u'http://arxiv.org/abs/1203.0651'}
2015-03-23 22:08:18+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0648> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:08:18+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0648>
	{'abstract': u"In the paper, frameworks for electronic shopping of composite (modular) products are described: (a) multicriteria selection (product is considered as a whole system, it is a traditional approach), (b) combinatorial synthesis (composition) of the product from its components, (c) aggregation of the product from several selected products/prototypes. The following product model is examined: (i) general tree-like structure, (ii) set of system parts/components (leaf nodes), (iii) design alternatives (DAs) for each component, (iv) ordinal priorities for DAs, and (v) estimates of compatibility between DAs for different components. The combinatorial synthesis is realized as morphological design of a composite (modular) product or an extended composite product (e.g., product and support services as financial instruments). Here the solving process is based on Hierarchical Morphological Multicriteria Design (HMMD): (i) multicriteria selection of alternatives for system parts, (ii) composing the selected alternatives into a resultant combination (while taking into account ordinal quality of the alternatives above and their compatibility). The aggregation framework is based on consideration of aggregation procedures, for example: (i) addition procedure: design of a products substructure or an extended substructure ('kernel') and addition of elements, and (ii) design procedure: design of the composite solution based on all elements of product superstructure. Applied numerical examples (e.g., composite product, extended composite product, product repair plan, and product trajectory) illustrate the proposed approaches.",
	 'authors': u'Mark Sh. Levin,',
	 'category': u'Computer Science ',
	 'date': '2012-3-3',
	 'pdflink': u'http://arxiv.org/pdf/1203.0648',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nTowards Electronic Shopping of Composite Product',
	 'urllink': u'http://arxiv.org/abs/1203.0648'}
2015-03-23 22:08:20+0000 [xxu46_4] INFO: Crawled 61 pages (at 5 pages/min), scraped 55 items (at 5 items/min)
2015-03-23 22:08:35+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0640> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:08:35+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0640>
	{'abstract': u'We proposed an authentication mechanism in the wireless sensor network. Sensor network uses the Kerberos authentication scheme for the authentication of bases station in the network. Kerberos provides a centralized authentication server whose function is to authenticate user by providing him the ticket to grant request to the base station. In this paper we have provided architecture for the authentication of base station in the wireless sensor network based on the Kerberos server authentication scheme.',
	 'authors': u'Qasim Siddique,',
	 'category': u'Computer Science ',
	 'date': '2012-3-3',
	 'pdflink': u'http://arxiv.org/pdf/1203.0640',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nKerberos Authentication in Wireless Sensor Networks',
	 'urllink': u'http://arxiv.org/abs/1203.0640'}
2015-03-23 22:08:52+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0631> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:08:52+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0631>
	{'abstract': u"A Boolean function is called read-once over a basis B if it can be expressed by a formula over B where no variable appears more than once. A checking test for a read-once function f over B depending on all its variables is a set of input vectors distinguishing f from all other read-once functions of the same variables. We show that every read-once function f over B has a checking test containing O(n^l) vectors, where n is the number of relevant variables of f and l is the largest arity of functions in B. For some functions, this bound cannot be improved by more than a constant factor. The employed technique involves reconstructing f from its l-variable projections and provides a stronger form of Kuznetsov's classic theorem on read-once representations.",
	 'authors': u'Dmitry V. Chistikov,',
	 'category': u'Computer Science ',
	 'date': '2012-3-3',
	 'pdflink': u'http://arxiv.org/pdf/1203.0631',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nChecking Tests for Read-Once Functions over Arbitrary Bases',
	 'urllink': u'http://arxiv.org/abs/1203.0631'}
2015-03-23 22:09:10+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0864> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:09:10+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0864>
	{'abstract': u'Recent improvements in positioning technology has led to a much wider availability of massive moving object data. A crucial task is to find the moving objects that travel together. Usually, these object sets are called spatio-temporal patterns. Due to the emergence of many different kinds of spatio-temporal patterns in recent years, different approaches have been proposed to extract them. However, each approach only focuses on mining a specific kind of pattern. In addition to being a painstaking task due to the large number of algorithms used to mine and manage patterns, it is also time consuming. Moreover, we have to execute these algorithms again whenever new data are added to the existing database. To address these issues, we ?first redefine spatio-temporal patterns in the itemset context. Secondly, we propose a unifying approach, named GeT_Move, which uses a frequent closed itemset-based spatio-temporal pattern-mining algorithm to mine and manage different spatio-temporal patterns. GeT_Move is implemented in two versions which are GeT_Move and Incremental GeT_Move. To optimize the efficiency and to free the parameters setting, we also propose a Parameter Free Incremental GeT_Move algorithm. Comprehensive experiments are performed on real datasets as well as large synthetic datasets to demonstrate the effectiveness and efficiency of our approaches.',
	 'authors': u'Phan Nhat Hai, Pascal Poncelet, Maguelonne Teisseire,',
	 'category': u'Computer Science ',
	 'date': '2012-4-4',
	 'pdflink': u'http://arxiv.org/pdf/1204.0864',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nGeT_Move: An Efficient and Unifying Spatio-Temporal Pattern Mining  Algorithm for Moving Objects',
	 'urllink': u'http://arxiv.org/abs/1204.0864'}
2015-03-23 22:09:20+0000 [xxu46_4] INFO: Crawled 64 pages (at 3 pages/min), scraped 58 items (at 3 items/min)
2015-03-23 22:09:27+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0617> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:09:27+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0617>
	{'abstract': u'Bayesian inference is an important technique throughout statistics. The essence of Beyesian inference is to derive the posterior belief updated from prior belief by the learned information, which is a set of differentially private answers under differential privacy. Although Bayesian inference can be used in a variety of applications, it becomes theoretically hard to solve when the number of differentially private answers is large. To facilitate Bayesian inference under differential privacy, this paper proposes a systematic mechanism. The key step of the mechanism is the implementation of Bayesian updating with the best linear unbiased estimator derived by Gauss-Markov theorem. In addition, we also apply the proposed inference mechanism into an online queryanswering system, the novelty of which is that the utility for users is guaranteed by Bayesian inference in the form of credible interval and confidence level. Theoretical and experimental analysis are shown to demonstrate the efficiency and effectiveness of both inference mechanism and online query-answering system.',
	 'authors': u'Yonghui Xiao, Li Xiong,',
	 'category': u'Computer Science ',
	 'date': '2012-3-3',
	 'pdflink': u'http://arxiv.org/pdf/1203.0617',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nBayesian inference under differential privacy',
	 'urllink': u'http://arxiv.org/abs/1203.0617'}
2015-03-23 22:09:45+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0856> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:09:45+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0856>
	{'abstract': u"The vern 'y conjecture ( vern 'y, 1964) states that each n-state san possess a sw of length . From the other side the best upper bound for the rl of n-state sa known so far is equal to (Pin, 1983) and so is cubic (a slightly better though still cubic upper bound has been claimed in Trahtman but the published proof of this result contains an unclear place) in . In the paper the vern 'y conjecture is reduced to a simpler conjecture. In particular, we prove vern 'y conjecture for one-cluster automata and quadratic upper bounds for automata closed to one-cluster automata. Our approach utilize theory of Markov chains and one simple fact from linear programming.",
	 'authors': u'Mikhail Berlinkov,',
	 'category': u'Computer Science ',
	 'date': '2012-4-4',
	 'pdflink': u'http://arxiv.org/e-print/1204.0856',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nThe Cerny Conjecture',
	 'urllink': u'http://arxiv.org/abs/1204.0856'}
2015-03-23 22:10:01+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0594> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:10:01+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0594>
	{'abstract': u'Since its introduction by Valiant in 1984, PAC learning of DNF expressions remains one of the central problems in learning theory. We consider this problem in the setting where the underlying distribution is uniform, or more generally, a product distribution. Kalai, Samorodnitsky and Teng (2009) showed that in this setting a DNF expression can be efficiently approximated from its "heavy" low-degree Fourier coefficients alone. This is in contrast to previous approaches where boosting was used and thus Fourier coefficients of the target function modified by various distributions were needed. This property is crucial for learning of DNF expressions over smoothed product distributions, a learning model introduced by Kalai et al. (2009) and inspired by the seminal smoothed analysis model of Spielman and Teng (2001). We introduce a new approach to learning (or approximating) a polynomial threshold functions which is based on creating a function with range [-1,1] that approximately agrees with the unknown function on low-degree Fourier coefficients. We then describe conditions under which this is sufficient for learning polynomial threshold functions. Our approach yields a new, simple algorithm for approximating any polynomial-size DNF expression from its "heavy" low-degree Fourier coefficients alone. Our algorithm greatly simplifies the proof of learnability of DNF expressions over smoothed product distributions. We also describe an application of our algorithm to learning monotone DNF expressions over product distributions. Building on the work of Servedio (2001), we give an algorithm that runs in time , where is the size of the target DNF expression and is the accuracy. This improves on bound of Servedio (2001).',
	 'authors': u'Vitaly Feldman,',
	 'category': u'Computer Science ',
	 'date': '2012-3-3',
	 'pdflink': u'http://arxiv.org/pdf/1203.0594',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nLearning DNF Expressions from Fourier Spectrum',
	 'urllink': u'http://arxiv.org/abs/1203.0594'}
2015-03-23 22:10:19+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0849> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:10:19+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0849>
	{'abstract': u'The problem of monotonicity testing over the hypergrid and its special case, the hypercube, is a classic, well-studied, yet unsolved question in property testing. We are given query access to (for some ordered range ). The hypergrid/cube has a natural partial order given by coordinate-wise ordering, denoted by . A function is emph if for all pairs , . The distance to monotonicity, , is the minimum fraction of values of that need to be changed to make monotone. For (the boolean hypercube), the usual tester is the emph, which checks monotonicity on adjacent pairs of domain points. It is known that the edge tester using samples can distinguish a monotone function from one where . On the other hand, the best lower bound for monotonicity testing over the hypercube is . This leaves a quadratic gap in our knowledge, since can be . We resolve this long standing open problem and prove that samples suffice for the edge tester. For hypergrids, known testers require samples, while the best known (non-adaptive) lower bound is . We give a (non-adaptive) monotonicity tester for hypergrids running in time. Our techniques lead to optimal property testers (with the same running time) for the natural emph on hypercubes and hypergrids. (A -Lipschitz function is one where .) In fact, we give a general unified proof for -query testers for a class of "bounded-derivative" properties, a class containing both monotonicity and Lipschitz.',
	 'authors': u'Deeparnab Chakrabarty, C. Seshadhri,',
	 'category': u'Computer Science ',
	 'date': '2012-4-4',
	 'pdflink': u'http://arxiv.org/pdf/1204.0849',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nOptimal bounds for monotonicity and Lipschitz testing over hypercubes  and hypergrids',
	 'urllink': u'http://arxiv.org/abs/1204.0849'}
2015-03-23 22:10:20+0000 [xxu46_4] INFO: Crawled 68 pages (at 4 pages/min), scraped 62 items (at 4 items/min)
2015-03-23 22:10:34+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0587> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:10:34+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0587>
	{'abstract': u'This paper introduces an extension of Answer Set Programming called Preference Set Constraint Programming which is a convenient and general formalism to reason with preferences. PSC programming extends Set Constraint Programming introduced by Marek and Remmel (Marek and Remmel 2004) by introducing two types of preference set constraint atoms, measure preference set constraint atoms and pre-ordered preference set constraint atoms, which are extensions of set constraint atoms. We show that the question of whether a PSC program has a preferred stable model is CoNP-complete. We give examples of the uses of the preference set constraint atoms and show that Answer Set Optimization (Brewka, Niemel "a, and Truszczynski 2003) and General Preference (Son and Pontelli 2006) can be expressed using preference set constraint atoms.',
	 'authors': u'Alex Brik, Jeffrey B. Remmel,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0587',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nExpressing Preferences using Preference Set Constraint Atoms',
	 'urllink': u'http://arxiv.org/abs/1203.0587'}
2015-03-23 22:10:45+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0844> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:10:45+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0844>
	{'abstract': u'Novel techniques based on signal-conditioning are presented to mitigate timing errors in time-interleaved ADCs. A theoretical bound on the achievable spurious signal content, on applying the techniques, is also derived. Behavioral simulations corroborating the same are presented.',
	 'authors': u'Abhishek Ghosh, Sudhakar Pamarti,',
	 'category': u'Computer Science ',
	 'date': '2012-4-4',
	 'pdflink': u'http://arxiv.org/pdf/1204.0844',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nMitigating Timing Errors in Time-Interleaved ADCs: a signal conditioning  approach',
	 'urllink': u'http://arxiv.org/abs/1204.0844'}
2015-03-23 22:10:54+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0550> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:10:54+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0550>
	{'abstract': u'This paper presents new and effective algorithms for learning kernels. In particular, as shown by our empirical results, these algorithms consistently outperform the so-called uniform combination solution that has proven to be difficult to improve upon in the past, as well as other algorithms for learning kernels based on convex combinations of base kernels in both classification and regression. Our algorithms are based on the notion of centered alignment which is used as a similarity measure between kernels or kernel matrices. We present a number of novel algorithmic, theoretical, and empirical results for learning kernels based on our notion of centered alignment. In particular, we describe efficient algorithms for learning a maximum alignment kernel by showing that the problem can be reduced to a simple QP and discuss a one-stage algorithm for learning both a kernel and a hypothesis based on that kernel using an alignment-based regularization. Our theoretical results include a novel concentration bound for centered alignment between kernel matrices, the proof of the existence of effective predictors for kernels with high alignment, both for classification and for regression, and the proof of stability-based generalization bounds for a broad family of algorithms for learning kernels based on centered alignment. We also report the results of experiments with our centered alignment-based algorithms in both classification and regression.',
	 'authors': u'Corinna Cortes, Mehryar Mohri, Afshin Rostamizadeh,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0550',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nAlgorithms for Learning Kernels Based on Centered Alignment',
	 'urllink': u'http://arxiv.org/abs/1203.0550'}
2015-03-23 22:11:12+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0839> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:11:12+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0839>
	{'abstract': u'This paper presents a significant modification to the Random Demodulator (RD) of Tropp et al. for sub-Nyquist sampling of frequency-sparse signals. The modification, termed constrained random demodulator, involves replacing the random waveform, essential to the operation of the RD, with a constrained random waveform that has limits on its switching rate because fast switching waveforms may be hard to generate cleanly. The result is a relaxation on the hardware requirements with a slight, but manageable, decrease in the recovery guarantees. The paper also establishes the importance of properly choosing the statistics of the constrained random waveform. If the power spectrum of the random waveform matches the distribution on the tones of the input signal (i.e., the distribution is proportional to the power spectrum), then recovery of the input signal tones is improved. The theoretical guarantees provided in the paper are validated through extensive numerical simulations and phase transition plots.',
	 'authors': u'Andrew Harms, Waheed U. Bajwa, Robert Calderbank,',
	 'category': u'Computer Science ',
	 'date': '2012-4-4',
	 'pdflink': u'http://arxiv.org/pdf/1204.0839',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nA Constrained Random Demodulator for Sub-Nyquist Sampling',
	 'urllink': u'http://arxiv.org/abs/1204.0839'}
2015-03-23 22:11:20+0000 [xxu46_4] INFO: Crawled 72 pages (at 4 pages/min), scraped 66 items (at 4 items/min)
2015-03-23 22:11:27+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0543> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:11:27+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0543>
	{'abstract': u'The growing amount of applications that generate vast amount of data in short time scales render the problem of partial monitoring, coupled with prediction, a rather fundamental one. We study the aforementioned canonical problem under the context of large-scale monitoring of communication networks. We consider the problem of selecting the "best" subset of links so as to optimally predict the quantity of interest at the remaining ones. This is a well know NP-hard problem, and algorithms seeking the exact solution are prohibitively expensive. We present a number of approximation algorithms that: 1) their computational complexity gains a significant improvement over existing greedy algorithms; 2) exploit the geometry of principal component analysis, which also helps us establish theoretical bounds on the prediction error; 3) are amenable for randomized implementation and execution in parallel or distributed fashion, a process that often yields the exact solution. The new algorithms are demonstrated and evaluated using real-world network data.',
	 'authors': u'Michalis Kallitsis, Stilian Stoev, George Michailidis,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/e-print/1203.0543',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nEfficient Approximation Algorithms for Optimal Large-scale Network  Monitoring',
	 'urllink': u'http://arxiv.org/abs/1203.0543'}
2015-03-23 22:11:43+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0833> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:11:43+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0833>
	{'abstract': u'We show that deterministic finite automata equipped with two-way heads are equivalent to deterministic machines with a single two-way input head and linearly bounded counters if the accepted language is strictly bounded, i.e., a subset of for a fixed sequence of symbols . Then we investigate linear speed-up for counter machines. Lower and upper time bounds for concrete recognition problems are shown, implying that in general linear speed-up does not hold for counter machines. For bounded languages we develop a technique for speeding up computations by any constant factor at the expense of adding a fixed number of counters.',
	 'authors': u'Holger Petersen,',
	 'category': u'Computer Science ',
	 'date': '2012-4-3',
	 'pdflink': u'http://arxiv.org/pdf/1204.0833',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nBounded Counter Languages',
	 'urllink': u'http://arxiv.org/abs/1204.0833'}
2015-03-23 22:12:00+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0541> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:12:00+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0541>
	{'abstract': u'Sensor networks aim at monitoring their surroundings for event detection and object tracking. But due to failure or death of sensors, false signal can be transmitted. In this paper, we consider the problem of fault detection in wireless sensor network (WSN), in particular, addressing both the noise-related measurement error and sensor fault simultaneously in fault detection. We assume that the sensors are placed at the center of a square (or hexagonal) cell in region of interest (ROI) and, if the event occurs, it occurs at a particular cell of the ROI. We propose fault detection schemes that take into account error probabilities into the optimal event detection process. We develop the schemes under the consideration of Neyman-Pearson test and Bayes test.',
	 'authors': u'Mrinal Nandi, Amiya Nayak, Bimal Roy, Santanu Sarkar,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0541',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nHypothesis Testing and Decision Theoretic Approach for Fault Detection  in Wireless Sensor Networks',
	 'urllink': u'http://arxiv.org/abs/1203.0541'}
2015-03-23 22:12:13+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0830> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:12:13+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0830>
	{'abstract': u'In this paper, numerical methods are suggested to compute the discrete and the continuous spectrum of a signal with respect to the Zakharov-Shabat system, a Lax operator underlying numerous integrable communication channels including the nonlinear Schr "odinger channel, modeling pulse propagation in optical fibers. These methods are subsequently tested and their ability to estimate the spectrum are compared against each other. These methods are used to compute the spectrum of various signals commonly used in the optical fiber communications. It is found that the layer-peeling and the spectral methods are suitable schemes to estimate the nonlinear spectra with good accuracy. To illustrate the structure of the spectrum, the locus of the eigenvalues is determined under amplitude and phase modulation in a number of examples. It is observed that in some cases, as signal parameters vary, eigenvalues collide and change their course of motion. The real axis is typically the place from which new eigenvalues originate or are absorbed into after traveling a trajectory in the complex plane.',
	 'authors': u'Mansoor I. Yousefi, Frank R. Kschischang,',
	 'category': u'Computer Science ',
	 'date': '2012-4-3',
	 'pdflink': u'http://arxiv.org/pdf/1204.0830',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nInformation Transmission using the Nonlinear Fourier Transform, Part II:  Numerical Methods',
	 'urllink': u'http://arxiv.org/abs/1204.0830'}
2015-03-23 22:12:20+0000 [xxu46_4] INFO: Crawled 76 pages (at 4 pages/min), scraped 70 items (at 4 items/min)
2015-03-23 22:12:30+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0536> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:12:30+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0536>
	{'abstract': u'In this paper we address two basic questions in wireless communication: First, how long does it take to schedule an arbitrary set of communication requests? Second, given a set of communication requests, how many of them can be scheduled concurrently? Our results are derived in an interference model with geometric path loss and consist of efficient algorithms that find a constant approximation for the second problem and a logarithmic approximation for the first problem. In addition, we analyze some important properties of the interference model and show that it is robust to various factors that can influence the signal attenuation. More specifically, we prove that as long as such influences on the signal attenuation are constant, they affect the capacity only by a constant factor.',
	 'authors': u'Olga Goussevskaia, Magn\xfas M. Halld\xf3rsson, Roger Wattenhofer,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0536',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nAlgorithms for Wireless Capacity',
	 'urllink': u'http://arxiv.org/abs/1203.0536'}
2015-03-23 22:12:47+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0824> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:12:47+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0824>
	{'abstract': u'Computing the coordinate-wise maxima of a planar point set is a classic and well-studied problem in computational geometry. We give an algorithm for this problem in the emph. We have (unknown) independent distributions of planar points. An input pointset is generated by taking an independent sample from each , so the input distribution is the product . A self-improving algorithm repeatedly gets input sets from the distribution (which is emph unknown) and tries to optimize its running time for . Our algorithm uses the first few inputs to learn salient features of the distribution, and then becomes an optimal algorithm for distribution . Let denote the expected depth of an emph linear comparison tree computing the maxima for distribution . Our algorithm eventually has an expected running time of , even though it did not know to begin with. Our result requires new tools to understand linear comparison trees for computing maxima. We show how to convert general linear comparison trees to very restricted versions, which can then be related to the running time of our algorithm. An interesting feature of our algorithm is an interleaved search, where the algorithm tries to determine the likeliest point to be maximal with minimal computation. This allows the running time to be truly optimal for the distribution .',
	 'authors': u'Kenneth L. Clarkson, Wolfgang Mulzer, C. Seshadhri,',
	 'category': u'Computer Science ',
	 'date': '2012-4-3',
	 'pdflink': u'http://arxiv.org/pdf/1204.0824',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nSelf-improving Algorithms for Coordinate-wise Maxima',
	 'urllink': u'http://arxiv.org/abs/1204.0824'}
2015-03-23 22:13:02+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0535> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:13:02+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0535>
	{'abstract': u'Pervasive socio-technical networks bring new conceptual and technological challenges to developers and users alike. A central research theme is evaluation of the intensity of relations linking users and how they facilitate communication and the spread of information. These aspects of human relationships have been studied extensively in the social sciences under the framework of the "strength of weak ties" theory proposed by Mark Granovetter.13 Some research has considered whether that theory can be extended to online social networks like Facebook, suggesting interaction data can be used to predict the strength of ties. The approaches being used require handling user-generated data that is often not publicly available due to privacy concerns. Here, we propose an alternative definition of weak and strong ties that requires knowledge of only the topology of the social network (such as who is a friend of whom on Facebook), relying on the fact that online social networks, or OSNs, tend to fragment into communities. We thus suggest classifying as weak ties those edges linking individuals belonging to different communities and strong ties as those connecting users in the same community. We tested this definition on a large network representing part of the Facebook social graph and studied how weak and strong ties affect the information-diffusion process. Our findings suggest individuals in OSNs self-organize to create well-connected communities, while weak ties yield cohesion and optimize the coverage of information spread.',
	 'authors': u'Pasquale De Meo, Emilio Ferrara, Giacomo Fiumara, Alessandro Provetti,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0535',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nOn Facebook, most ties are weak',
	 'urllink': u'http://arxiv.org/abs/1203.0535'}
2015-03-23 22:13:14+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0816> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:13:14+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0816>
	{'abstract': u'We prove that every YES instance of Balanced ST-Connectivity has a balanced path of polynomial length.',
	 'authors': u'Shiva Kintali, Asaf Shapira,',
	 'category': u'Computer Science ',
	 'date': '2012-4-3',
	 'pdflink': u'http://arxiv.org/pdf/1204.0816',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nA Note on the Balanced ST-Connectivity',
	 'urllink': u'http://arxiv.org/abs/1204.0816'}
2015-03-23 22:13:20+0000 [xxu46_4] INFO: Crawled 80 pages (at 4 pages/min), scraped 74 items (at 4 items/min)
2015-03-23 22:13:32+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0532> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:13:32+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0532>
	{'abstract': u'Classifying journals or publications into research areas is an essential element of many bibliometric analyses. Classification usually takes place at the level of journals, where the Web of Science subject categories are the most popular classification system. However, journal-level classification systems have two important limitations: They offer only a limited amount of detail, and they have difficulties with multidisciplinary journals. To avoid these limitations, we introduce a new methodology for constructing classification systems at the level of individual publications. In the proposed methodology, publications are clustered into research areas based on citation relations. The methodology is able to deal with very large numbers of publications. We present an application in which a classification system is produced that includes almost ten million publications. Based on an extensive analysis of this classification system, we discuss the strengths and the limitations of the proposed methodology. Important strengths are the transparency and relative simplicity of the methodology and its fairly modest computing and memory requirements. The main limitation of the methodology is its exclusive reliance on direct citation relations between publications. The accuracy of the methodology can probably be increased by also taking into account other types of relations, for instance based on bibliographic coupling.',
	 'authors': u'Ludo Waltman, Nees Jan van Eck,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0532',
	 'subjects': u'Digital Libraries (cs.DL)',
	 'title': u'\nA new methodology for constructing a publication-level classification  system of science',
	 'urllink': u'http://arxiv.org/abs/1203.0532'}
2015-03-23 22:13:43+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0803> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:13:43+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0803>
	{'abstract': u'We propose a new technique for adaptive identification of sparse systems based on the compressed sensing (CS) theory. We manipulate the transmitted pilot (input signal) and the received signal such that the weights of adaptive filter approach the compressed version of the sparse system instead of the original system. To this end, we use random filter structure at the transmitter to form the measurement matrix according to the CS framework. The original sparse system can be reconstructed by the conventional recovery algorithms. As a result, the denoising property of CS can be deployed in the proposed method at the recovery stage. The experiments indicate significant performance improvement of proposed method compared to the conventional LMS method which directly identifies the sparse system. Furthermore, at low levels of sparsity, our method outperforms a specialized identification algorithm that promotes sparsity.',
	 'authors': u'Seyed Hossein Hosseini, Mahrokh G. Shayesteh,',
	 'category': u'Computer Science ',
	 'date': '2012-4-3',
	 'pdflink': u'http://arxiv.org/pdf/1204.0803',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nCompressed Sensing for Denoising in Adaptive System Identification',
	 'urllink': u'http://arxiv.org/abs/1204.0803'}
2015-03-23 22:14:01+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0518> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:14:01+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0518>
	{'abstract': u'The second Information Retrieval Education through EXperimentation track (EIREX 2011) was run at the University Carlos III of Madrid, during the 2011 spring semester. EIREX 2011 is the second in a series of experiments designed to foster new Information Retrieval (IR) education methodologies and resources, with the specific goal of teaching undergraduate IR courses from an experimental perspective. For an introduction to the motivation behind the EIREX experiments, see the first sections of [Urbano et al., 2011a]. For information on other editions of EIREX and related data, see the website at this http URL The EIREX series have the following goals: a) to help students get a view of the Information Retrieval process as they would find it in a real-world scenario, either industrial or academic; b) to make students realize the importance of laboratory experiments in Computer Science and have them initiated in their execution and analysis; c) to create a public repository of resources to teach Information Retrieval courses; d) to seek the collaboration and active participation of other Universities in this endeavor. This overview paper summarizes the results of the EIREX 2011 track, focusing on the creation of the test collection and the analysis to assess its reliability.',
	 'authors': u'Juli\xe1n Urbano, Diego Mart\xedn, M\xf3nica Marrero, Jorge Morato,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0518',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nOverview of EIREX 2011: Crowdsourcing',
	 'urllink': u'http://arxiv.org/abs/1203.0518'}
2015-03-23 22:14:08+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0776> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:14:08+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0776>
	{'abstract': u'We consider a cognitive radio network with multiple primary users (PUs) and one secondary user (SU), where a spectrum server is utilized for spectrum sensing and scheduling the SU to transmit over one of the PU channels opportunistically. One practical yet challenging scenario is when textit the PU occupancy and the channel fading vary over time and exhibit temporal correlations. Little work has been done for exploiting such temporal memory in the channel fading and the PU occupancy simultaneously for opportunistic spectrum scheduling. A main goal of this work is to understand the intricate tradeoffs resulting from the interactions of the two sets of system states - the channel fading and the PU occupancy, by casting the problem as a partially observable Markov decision process. We first show that a simple greedy policy is optimal in some special cases. To build a clear understanding of the tradeoffs, we then introduce a full-observation genie-aided system, where the spectrum server collects channel fading states from all PU channels. The genie-aided system is used to decompose the tradeoffs in the original system into multiple tiers, which are examined progressively. Numerical examples indicate that the optimal scheduler in the original system, with observation on the scheduled channel only, achieves a performance very close to the genie-aided system. Further, as expected, the optimal policy in the original system significantly outperforms randomized scheduling, pointing to the merit of exploiting the temporal correlation structure in both channel fading and PU occupancy.',
	 'authors': u'Shanshan Wang, Sugumar Murugesan, Junshan Zhang,',
	 'category': u'Computer Science ',
	 'date': '2012-4-3',
	 'pdflink': u'http://arxiv.org/pdf/1204.0776',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nExploiting Channel Correlation and PU Traffic Memory for Opportunistic  Spectrum Scheduling',
	 'urllink': u'http://arxiv.org/abs/1204.0776'}
2015-03-23 22:14:17+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0516> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:14:17+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0516>
	{'abstract': u'Considered in this paper is the method of describingc of telecommunications systems providing VoD service using multi-layer graph. The paper describes the relations between the structural elements at each hierarchical level of the multi-layer graph. Transfer of video is a resource consuming task, and it requires an optimal configuration of the studied system. The usage of the multi-layer graph makes it possible to consider the telecommunication system as a whole and avoid falling in the local optimums when solving optimization problems.',
	 'authors': u'Dmitry Ageyev, Artem Ignatenko,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0516',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nDescribing and Modeling of Video-on-Demand Service with the Usage of  Multi-Layer Graph',
	 'urllink': u'http://arxiv.org/abs/1203.0516'}
2015-03-23 22:14:20+0000 [xxu46_4] INFO: Crawled 85 pages (at 5 pages/min), scraped 79 items (at 5 items/min)
2015-03-23 22:14:33+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0775> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:14:33+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0775>
	{'abstract': u'We study the complexity of the following "resolution width problem": Does a given 3-CNF have a resolution refutation of width k? We prove that the problem cannot be decided in time O(n^((k-3)/12)). This lower bound is unconditional and does not rely on any unproven complexity theoretic assumptions. The lower bound is matched by a trivial upper bound of n^O(k). We also prove that the resolution width problem is EXPTIME-complete (if k is part of the input). This confirms a conjecture by Vardi, who has first raised the question for the complexity of the resolution width problem. Furthermore, we prove that the variant of the resolution width problem for regular resolution is PSPACE-complete, confirming a conjecture by Urquhart.',
	 'authors': u'Christoph Berkholz,',
	 'category': u'Computer Science ',
	 'date': '2012-4-3',
	 'pdflink': u'http://arxiv.org/pdf/1204.0775',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nOn the Complexity of Finding Narrow Proofs',
	 'urllink': u'http://arxiv.org/abs/1204.0775'}
2015-03-23 22:14:48+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0512> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:14:48+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0512>
	{'abstract': u'In this paper, we claim that language is likely to have emerged as a mechanism for coordinating the solution of complex tasks. To confirm this thesis, computer simulations are performed based on the coordination task presented by Garrod &amp; Anderson (1987). The role of success in task-oriented dialogue is analytically evaluated with the help of performance measurements and a thorough lexical analysis of the emergent communication system. Simulation results confirm a strong effect of success mattering on both reliability and dispersion of linguistic conventions.',
	 'authors': u'Martin Bachwerk, Carl Vogel,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0512',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nEstablishing linguistic conventions in task-oriented primeval dialogue',
	 'urllink': u'http://arxiv.org/abs/1203.0512'}
2015-03-23 22:15:04+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0767> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:15:04+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0767>
	{'abstract': u'This paper focuses on fruit defect detection and glare removal using morphological operations, Glare removal can be considered as an important preprocessing step as uneven lighting may introduce it in images, which hamper the results produced through segmentation by Gabor filters .The problem of glare in images is very pronounced sometimes due to the unusual reflectance from the camera sensor or stray light entering, this method counteracts this problem and makes the defect detection much more pronounced. Anisotropic diffusion is used for further smoothening of the images and removing the high energy regions in an image for better defect detection and makes the defects more retrievable. Our algorithm is robust and scalable the employability of a particular mask for glare removal has been checked and proved useful for counteracting.this problem, anisotropic diffusion further enhances the defects with its use further Optimal Gabor filter at various orientations is used for defect detection.',
	 'authors': u'Vini Katyal, Deepesh Srivastava,',
	 'category': u'Computer Science ',
	 'date': '2012-4-3',
	 'pdflink': u'http://arxiv.org/e-print/1204.0767',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nEfficient Fruit Defect Detection and Glare removal Algorithm by  anisotropic diffusion and 2D Gabor filter',
	 'urllink': u'http://arxiv.org/abs/1204.0767'}
2015-03-23 22:15:18+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0511> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:15:18+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0511>
	{'abstract': u'This study is devoted to the problem of parametric synthesis of multi-service telecommunication sys-tems. The main characteristics of telecommunication systems, which are brought to account in an article, are multilayer structure formed by the overlayed networks and presence flows with self-similarity effect. For accounting these features of modern telecommunications systems is proposed to use a multi-layered graph for describing the system structure, and self-similar processes model for modeling flows in a network. Solution of parametric synthesis problem is reduced to a nonlinear programming problem which is solved by using gradient descent method.',
	 'authors': u'Dmitry Ageyev, Haidara Abdalla,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0511',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nMultiservice Telecommunication Systems Parametrical Synthesis by using  of Multilayer Graph Mathematical Model',
	 'urllink': u'http://arxiv.org/abs/1203.0511'}
2015-03-23 22:15:20+0000 [xxu46_4] INFO: Crawled 89 pages (at 4 pages/min), scraped 83 items (at 4 items/min)
2015-03-23 22:15:32+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0764> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:15:32+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0764>
	{'abstract': u'Cloud Computing holds the potential to eliminate the requirements for setting up of high-cost computing infrastructure for IT-based solutions and services that the industry uses. It promises to provide a flexible IT architecture, accessible through internet for lightweight portable devices. This would allow multi-fold increase in the capacity or capabilities of the existing and new software. In a cloud computing environment, the entire data reside over a set of networked resources, enabling the data to be accessed through virtual machines. Since these data-centers may lie in any corner of the world beyond the reach and control of users, there are multifarious security and privacy challenges that need to be understood and taken care of. Also, one can never deny the possibility of a server breakdown that has been witnessed, rather quite often in the recent times. There are various issues that need to be dealt with respect to security and privacy in a cloud computing scenario. This extensive survey paper aims to elaborate and analyze the numerous unresolved issues threatening the cloud computing adoption and diffusion affecting the various stake-holders linked to it.',
	 'authors': u'Rohit Bhadauria, Sugata Sanyal,',
	 'category': u'Computer Science ',
	 'date': '2012-4-3',
	 'pdflink': u'http://arxiv.org/pdf/1204.0764',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nSurvey on Security Issues in Cloud Computing and Associated Mitigation  Techniques',
	 'urllink': u'http://arxiv.org/abs/1204.0764'}
2015-03-23 22:15:50+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0504> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:15:50+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0504>
	{'abstract': u'Language evolution might have preferred certain prior social configurations over others. Experiments conducted with models of different social structures (varying subgroup interactions and the role of a dominant interlocutor) suggest that having isolated agent groups rather than an interconnected agent is more advantageous for the emergence of a social communication system. Distinctive groups that are closely connected by communication yield systems less like natural language than fully isolated groups inhabiting the same world. Furthermore, the addition of a dominant male who is asymmetrically favoured as a hearer, and equally likely to be a speaker has no positive influence on the disjoint groups.',
	 'authors': u'Martin Bachwerk, Carl Vogel,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0504',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nModelling Social Structures and Hierarchies in Language Evolution',
	 'urllink': u'http://arxiv.org/abs/1203.0504'}
2015-03-23 22:16:01+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0747> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:16:01+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0747>
	{'abstract': u'We define signed dual volumes at all dimensions for circumcentric dual meshes. We show that for pairwise Delaunay triangulations with mild boundary assumptions these signed dual volumes are positive. This allows the use of such Delaunay meshes for Discrete Exterior Calculus (DEC) because the discrete Hodge star operator can now be correctly defined for such meshes. This operator is crucial for DEC and is a diagonal matrix with the ratio of primal and dual volumes along the diagonal. A correct definition requires that all entries be positive. DEC is a framework for numerically solving differential equations on meshes and for geometry processing tasks and has had considerable impact in computer graphics and scientific computing. Our result allows the use of DEC with a much larger class of meshes than was previously considered possible.',
	 'authors': u'Anil N. Hirani, Kaushik Kalyanaraman, Evan B. VanderZee,',
	 'category': u'Computer Science ',
	 'date': '2012-4-3',
	 'pdflink': u'http://arxiv.org/pdf/1204.0747',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nDelaunay Hodge Star',
	 'urllink': u'http://arxiv.org/abs/1204.0747'}
2015-03-23 22:16:13+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0503> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:16:13+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0503>
	{'abstract': u'It is suggested to use multi-layer graphs as a mathematical model in the design of MPLS networks. The application of this model makes it possible to design multi-service telecommunication systems simultaneously at several levels and to reduce the problem to the search of the minimum weight graph.',
	 'authors': u'Haidara Abdalla, Dmitry Ageyev,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0503',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nApplication of Multi-layer Graphs In the Design of MPLS Networks',
	 'urllink': u'http://arxiv.org/abs/1203.0503'}
2015-03-23 22:16:20+0000 [xxu46_4] INFO: Crawled 93 pages (at 4 pages/min), scraped 87 items (at 4 items/min)
2015-03-23 22:16:29+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0746> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:16:29+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0746>
	{'abstract': u'We propose a new algorithm for recovery of sparse signals from their compressively sensed samples. The proposed algorithm benefits from the strategy of gradual movement to estimate the positions of non-zero samples of sparse signal. We decompose each sample of signal into two variables, namely "value" and "detector", by a weighted exponential function. We update these new variables using gradient descent method. Like the traditional compressed sensing algorithms, the first variable is used to solve the Least Absolute Shrinkage and Selection Operator (Lasso) problem. As a new strategy, the second variable participates in the regularization term of the Lasso (l1 norm) that gradually detects the non-zero elements. The presence of the second variable enables us to extend the corresponding vector of the first variable to matrix form. This makes possible use of the correlation matrix for a heuristic search in the case that there are correlations among the samples of signal. We compare the performance of the new algorithm with various algorithms for uncorrelated and correlated sparsity. The results indicate the efficiency of the proposed methods.',
	 'authors': u'Seyed Hossein Hosseini, Mahrokh G. Shayesteh,',
	 'category': u'Computer Science ',
	 'date': '2012-4-3',
	 'pdflink': u'http://arxiv.org/pdf/1204.0746',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nGradually Atom Pruning for Sparse Reconstruction and Extension to  Correlated Sparsity',
	 'urllink': u'http://arxiv.org/abs/1204.0746'}
2015-03-23 22:16:45+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0500> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:16:45+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0500>
	{'abstract': u'To give a georeference means to give a reference as existing in the physical space of Earth. This procedure is widely used for the location of archaeological, historical and other sites when geographic information systems (GIS) are used. Here we are proposing to georeference the lives of famous people (in the paper, Newton and Schiaparelli) for teaching purposes, to increase the appeal of some scientific disciplines.',
	 'authors': u'A.C. Sparavigna, R. Marazzato,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0500',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nGeoreferenced lives',
	 'urllink': u'http://arxiv.org/abs/1203.0500'}
2015-03-23 22:16:59+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0731> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:16:59+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0731>
	{'abstract': u'Some aspects of the result of applying unit resolution on a CNF formula can be formalized as functions with domain a set of partial truth assignments. We are interested in two ways for computing such functions, depending on whether the result is the production of the empty clause or the assignment of a variable with a given truth value. We show that these two models can compute the same functions with formulae of polynomially related sizes, and we explain how this result is related to the CNF encoding of Boolean constraints.',
	 'authors': u'Olivier Bailleux,',
	 'category': u'Computer Science ',
	 'date': '2012-4-3',
	 'pdflink': u'http://arxiv.org/pdf/1204.0731',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nUnit contradiction versus unit propagation',
	 'urllink': u'http://arxiv.org/abs/1204.0731'}
2015-03-23 22:17:15+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0494> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:17:15+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0494>
	{'abstract': u"This paper exposes a contradiction in the Zermelo-Fraenkel set theory with the axiom of choice (ZFC). While Godel's incompleteness theorems state that a consistent system cannot prove its consistency, they do not eliminate proofs using a stronger system or methods that are outside the scope of the system. The paper shows that the cardinalities of infinite sets are uncontrollable and contradictory. The paper then states that Peano arithmetic, or first-order arithmetic, is inconsistent if all of the axioms and axiom schema assumed in the ZFC system are taken as being true, showing that ZFC is inconsistent. The paper then exposes some consequences that are in the scope of the computational complexity theory.",
	 'authors': u'Minseong Kim,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0494',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nInconsistency of the Zermelo-Fraenkel set theory with the axiom of  choice and its effects on the computational complexity',
	 'urllink': u'http://arxiv.org/abs/1203.0494'}
2015-03-23 22:17:20+0000 [xxu46_4] INFO: Crawled 97 pages (at 4 pages/min), scraped 91 items (at 4 items/min)
2015-03-23 22:17:29+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0707> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:17:29+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0707>
	{'abstract': u'In an epsilon-Nash equilibrium, a player can gain at most epsilon by changing his behaviour. Recent work has addressed the question of how best to compute epsilon-Nash equilibria, and for what values of epsilon a polynomial-time algorithm exists. An epsilon-well-supported Nash equilibrium (epsilon-WSNE) has the additional requirement that any strategy that is used with non-zero probability by a player must have payoff at most epsilon less than the best response. A recent algorithm of Kontogiannis and Spirakis shows how to compute a 2/3-WSNE in polynomial time, for bimatrix games. Here we introduce a new technique that leads to an improvement to the worst-case approximation guarantee.',
	 'authors': u'John Fearnley, Paul W. Goldberg, Rahul Savani, Troels Bjerre S\xf8rensen,',
	 'category': u'Computer Science ',
	 'date': '2012-4-3',
	 'pdflink': u'http://arxiv.org/pdf/1204.0707',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nApproximate Well-supported Nash Equilibria below Two-thirds',
	 'urllink': u'http://arxiv.org/abs/1204.0707'}
2015-03-23 22:17:41+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0488> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:17:41+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0488>
	{'abstract': u'This paper introduces a simple but highly efficient ensemble for robust texture classification, which can effectively deal with translation, scale and changes of significant viewpoint problems. The proposed method first inherits the spirit of spatial pyramid matching model (SPM), which is popular for encoding spatial distribution of local features, but in a flexible way, partitioning the original image into different levels and incorporating different overlapping patterns of each level. This flexible setup helps capture the informative features and produces sufficient local feature codes by some well-chosen aggregation statistics or pooling operations within each partitioned region, even when only a few sample images are available for training. Then each texture image is represented by several orderless feature codes and thereby all the training data form a reliable feature pond. Finally, to take full advantage of this feature pond, we develop a collaborative representation-based strategy with locality constraint (LC-CRC) for the final classification, and experimental results on three well-known public texture datasets demonstrate the proposed approach is very competitive and even outperforms several state-of-the-art methods. Particularly, when only a few samples of each category are available for training, our approach still achieves very high classification performance.',
	 'authors': u'Shu Kong, Donghui Wang,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0488',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nMulti-Level Feature Descriptor for Robust Texture Classification via  Locality-Constrained Collaborative Strategy',
	 'urllink': u'http://arxiv.org/abs/1203.0488'}
2015-03-23 22:17:53+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0684> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:17:53+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0684>
	{'abstract': u'Linear principal component analysis (PCA) can be extended to a nonlinear PCA by using artificial neural networks. But the benefit of curved components requires a careful control of the model complexity. Moreover, standard techniques for model selection, including cross-validation and more generally the use of an independent test set, fail when applied to nonlinear PCA because of its inherent unsupervised characteristics. This paper presents a new approach for validating the complexity of nonlinear PCA models by using the error in missing data estimation as a criterion for model selection. It is motivated by the idea that only the model of optimal complexity is able to predict missing values with the highest accuracy. While standard test set validation usually favours over-fitted nonlinear PCA models, the proposed model validation approach correctly selects the optimal model complexity.',
	 'authors': u'Matthias Scholz,',
	 'category': u'Computer Science ',
	 'date': '2012-4-3',
	 'pdflink': u'http://arxiv.org/pdf/1204.0684',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nValidation of nonlinear PCA',
	 'urllink': u'http://arxiv.org/abs/1204.0684'}
2015-03-23 22:18:02+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0478> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:18:02+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0478>
	{'abstract': u"Approximating complex curves with simple parametric curves is widely used in CAGD, CG, and CNC. This paper presents an algorithm to compute a certified approximation to a given parametric space curve with cubic B-spline curves. By certified, we mean that the approximation can approximate the given curve to any given precision and preserve the geometric features of the given curve such as the topology, singular points, etc. The approximated curve is divided into segments called quasi-cubic B 'zier curve segments which have properties similar to a cubic rational B 'zier curve. And the approximate curve is naturally constructed as the associated cubic rational B 'zier curve of the control tetrahedron of a quasi-cubic curve. A novel optimization method is proposed to select proper weights in the cubic rational B 'zier curve to approximate the given curve. The error of the approximation is controlled by the size of its tetrahedron, which converges to zero by subdividing the curve segments. As an application, approximate implicit equations of the approximated curves can be computed. Experiments show that the method can approximate space curves of high degrees with high precision and very few cubic B 'zier curve segments.",
	 'authors': u'Liyong Shen, Chunming Yuan, Xiao-Shan Gao,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0478',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nCertified Approximation of Parametric Space Curves with Cubic B-spline  Curves',
	 'urllink': u'http://arxiv.org/abs/1203.0478'}
2015-03-23 22:18:13+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0660> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:18:13+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0660>
	{'abstract': u'We show that, if P not=NP, there is a constant c &gt; 1 such that there is no c-approximation algorithm for the crossing number, even when restricted to 3-regular graphs.',
	 'authors': u'Sergio Cabello,',
	 'category': u'Computer Science ',
	 'date': '2012-4-3',
	 'pdflink': u'http://arxiv.org/pdf/1204.0660',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nHardness of approximation for crossing number',
	 'urllink': u'http://arxiv.org/abs/1204.0660'}
2015-03-23 22:18:20+0000 [xxu46_4] INFO: Crawled 102 pages (at 5 pages/min), scraped 96 items (at 5 items/min)
2015-03-23 22:18:30+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0474> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:18:30+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0474>
	{'abstract': u'Orthogonal designs are fundamental mathematical notions used in the construction of space time block codes for wireless transmissions. Designs have two important parameters, the rate and the decoding delay; the main problem of the theory is to construct designs maximizing the rate and minimizing the decoding delay. All known constructions of CODs are inductive or algorithmic. In this paper, we present an explicit construction of optimal CODs. We do not apply recurrent procedures and do calculate the matrix elements directly. Our formula is based on a cubic function in two binary n-vectors. In our previous work (Comm. Math. Phys., 2010, and J. Pure and Appl. Algebra, 2011), we used this function to define a series of non-associative algebras generalizing the classical algebra of octonions and to obtain sum of squares identities of Hurwitz-Radon type.',
	 'authors': u'Sophie Morier-Genoud, Valentin Ovsienko,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0474',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOrthogonal Designs and a Cubic Binary Function',
	 'urllink': u'http://arxiv.org/abs/1203.0474'}
2015-03-23 22:18:43+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0643> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:18:43+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0643>
	{'abstract': u'Multi-user spatial multiplexing combined with packet aggregation can significantly increase the performance of Wireless Local Area Networks (WLANs). In this letter, we present and evaluate a simple technique to perform packet aggregation in IEEE 802.11ac MU-MIMO (Multi-user Multiple Input Multiple Output) WLANs. Results show that in non-saturation conditions both the number of active stations (STAs) and the queue size have a significant impact on the system performance. If the number of stations is excessively high, the heterogeneity of destinations in the packets contained in the queue makes it difficult to take full advantage of packet aggregation. This effect can be alleviated by increasing the queue size, which increases the chances to schedule a large number of packets at each transmission, hence improving the system throughput at the cost of a higher delay.',
	 'authors': u'Boris Bellalta, Jaume Barcelo, Dirk Staehle, Alexey Vinel, Miquel Oliver,',
	 'category': u'Computer Science ',
	 'date': '2012-4-3',
	 'pdflink': u'http://arxiv.org/pdf/1204.0643',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nOn the Performance of Packet Aggregation in IEEE 802.11ac MU-MIMO WLANs',
	 'urllink': u'http://arxiv.org/abs/1204.0643'}
2015-03-23 22:18:56+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0473> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:18:56+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0473>
	{'abstract': u'This paper shows that a finitely presented monoid with linear Dehn function need not have a regular cross-section, strengthening the previously-known result that such a monoid need not be presented by a finite complete string rewriting system, and contrasting the fact that finitely presented groups with linear Dehn function always have regular cross-sections.',
	 'authors': u'Alan J. Cain, Victor Maltcev,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0473',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nFinitely presented monoids with linear Dehn function need not have  regular cross-sections',
	 'urllink': u'http://arxiv.org/abs/1203.0473'}
2015-03-23 22:19:08+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0641> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:19:08+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0641>
	{'abstract': u'We study distributed computation in synchronous dynamic networks where an omniscient adversary controls the unidirectional communication links. Its behavior is modeled as a sequence of directed graphs representing the active (i.e. timely) communication links per round. We prove that consensus is impossible under some natural weak connectivity assumptions, and introduce vertex-stable root components as a means for circumventing this impossibility. Essentially, we assume that there is a short period of time during which an arbitrary part of the network remains strongly connected, while its interconnect topology may keep changing continuously. We present a consensus algorithm that works under this assumption, and prove its correctness. Our algorithm maintains a local estimate of the communication graphs, and applies techniques for detecting stable network properties and univalent system configurations. Our possibility results are complemented by several impossibility results and lower bounds for consensus and other distributed computing problems like leader election, revealing that our algorithm is asymptotically optimal.',
	 'authors': u'Martin Biely, Peter Robinson, Ulrich Schmid,',
	 'category': u'Computer Science ',
	 'date': '2012-4-3',
	 'pdflink': u'http://arxiv.org/pdf/1204.0641',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nAgreement in Directed Dynamic Networks',
	 'urllink': u'http://arxiv.org/abs/1204.0641'}
2015-03-23 22:19:20+0000 [xxu46_4] INFO: Crawled 106 pages (at 4 pages/min), scraped 100 items (at 4 items/min)
2015-03-23 22:19:21+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0443> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:19:21+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0443>
	{'abstract': u'A fundamental ambition of grid and distributed systems is to be capable of sustaining evolution and allowing for adaptability ((F. Losavio et al., 2002), (S. Radhakrishnan, 2005)). Furthermore, as the complexity and sophistication of theses structures increases, so does the need for adaptability of each component. One of the primary benefits of service oriented architecture (SOA) is the ability to compose applications, processes or more complex services from other services which increases the capacity for adaptation. This document proposes a novel infrastructure composition model that aims at increasing the adaptability of the capabilities exposed through it by dynamically managing their non functional requirements.',
	 'authors': u'Pierre de Leusse, Panos Periorellis, Paul Watson, Andreas Maierhofer,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0443',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nSecure & Rapid Composition of Infrastructure Services in the Cloud',
	 'urllink': u'http://arxiv.org/abs/1203.0443'}
2015-03-23 22:19:35+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0634> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:19:35+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0634>
	{'abstract': u'This paper deals with the specification and the implementation of multi-level agent-based models, using a formal model, IRM4MLS (an Influence Reaction Model for Multi-Level Simulation), based on the Influence Reaction principle. Proposed examples illustrate forms of top-down control in (multi-level) multi-agent based-simulations.',
	 'authors': u'Gildas Morvan, Daniel Jolly,',
	 'category': u'Computer Science ',
	 'date': '2012-4-3',
	 'pdflink': u'http://arxiv.org/pdf/1204.0634',
	 'subjects': u'Multiagent Systems (cs.MA)',
	 'title': u'\nMulti-level agent-based modeling with the Influence Reaction principle',
	 'urllink': u'http://arxiv.org/abs/1204.0634'}
2015-03-23 22:19:46+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0442> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:19:46+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0442>
	{'abstract': u'We present an approach of computing the intersection curve of two rational parametric surface and , one being projectable and hence can easily be implicitized. Plugging the parametric surface to the implicit surface yields a plane algebraic curve . By analyzing the topology graph of and the singular points on the intersection curve we associate a space topology graph to , which is homeomorphic to and therefore leads us to an approximation for in a given precision.',
	 'authors': u'Liyong shen, Jin-san Cheng, Xiaohong Jia,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0442',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nHomeomorphic approximation of the intersection curve of two rational  surfaces',
	 'urllink': u'http://arxiv.org/abs/1203.0442'}
2015-03-23 22:20:03+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0566> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:20:03+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0566>
	{'abstract': u'We present a novel approach for training kernel Support Vector Machines, establish learning runtime guarantees for our method that are better then those of any other known kernelized SVM optimization approach, and show that our method works well in practice compared to existing alternatives.',
	 'authors': u'Andrew Cotter, Shai Shalev-Shwartz, Nathan Srebro,',
	 'category': u'Computer Science ',
	 'date': '2012-4-3',
	 'pdflink': u'http://arxiv.org/pdf/1204.0566',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nThe Kernelized Stochastic Batch Perceptron',
	 'urllink': u'http://arxiv.org/abs/1204.0566'}
2015-03-23 22:20:18+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0440> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:20:18+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0440>
	{'abstract': u'Business requirements for rapid operational efficiency, customer responsiveness as well as rapid adaptability are actively driving the need for ever increasing communication and integration apabilities of software assets. In this context, security, although acknowledged as being a necessity, is often perceived as a hindrance. Indeed, dynamic environments require flexible and understandable security that can be customized, adapted and reconfigured dynamically to face changing requirements. In this paper, the authors propose SOA based security governance middleware that handles security requirements on behalf of a resource exposed through it. The middleware aims at providing different security settings through the use of managed compositions of security services called profiles. The main added value of this work compared to existing handlers or centralized approaches lies in its enhanced flexibility and transparency.',
	 'authors': u'Pierre de Leusse, Theo Dimitrakos,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0440',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nSOA-based security governance middleware',
	 'urllink': u'http://arxiv.org/abs/1203.0440'}
2015-03-23 22:20:20+0000 [xxu46_4] INFO: Crawled 111 pages (at 5 pages/min), scraped 105 items (at 5 items/min)
2015-03-23 22:20:31+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0562> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:20:31+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0562>
	{'abstract': u"Motivated by recent work on atomic norms in inverse problems, we propose a new approach to line spectral estimation that provides theoretical guarantees for the mean-squared-error (MSE) performance in the presence of noise and without knowledge of the model order. We propose an abstract theory of denoising with atomic norms and specialize this theory to provide a convex optimization problem for estimating the frequencies and phases of a mixture of complex exponentials. We show that the associated convex optimization problem can be solved in polynomial time via semidefinite programming (SDP). We also show that the SDP can be approximated by an l1-regularized least-squares problem that achieves nearly the same error rate as the SDP but can scale to much larger problems. We compare both SDP and l1-based approaches with classical line spectral analysis methods and demonstrate that the SDP outperforms the l1 optimization which outperforms MUSIC, Cadzow's, and Matrix Pencil approaches in terms of MSE over a wide range of signal-to-noise ratios.",
	 'authors': u'Badri Narayan Bhaskar, Gongguo Tang, Benjamin Recht,',
	 'category': u'Computer Science ',
	 'date': '2012-4-3',
	 'pdflink': u'http://arxiv.org/pdf/1204.0562',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nAtomic norm denoising with applications to line spectral estimation',
	 'urllink': u'http://arxiv.org/abs/1204.0562'}
2015-03-23 22:20:49+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0439> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:20:49+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0439>
	{'abstract': u'The Internet of Things and Services is a rapidly growing concept that illustrates that the ever increasing amount of physical items of our daily life which become addressable through a network could be made more easily manageable and usable through the use of Services. This surge of exposed resources along with the level of privacy and value of the information they hold, together with the increase of their usage make for an augmentation in the number of the security threats and violation attempts that existing security systems do not appear robust enough to address. In this paper, the authors underline this increase in risk and identify the requirements for resources to be more resilient in this type of environment while keeping an important level of flexibility. In addition, the authors propose an architectural model of Self Managed Security Cell, which leverages on current knowledge in large scale security systems, information management and autonomous systems.',
	 'authors': u'Pierre de Leusse, Panos Periorellis, Theo Dimitrakos, Srijith K. Nair,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0439',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nSelf Managed Security Cell, a security model for the Internet of Things  and Services',
	 'urllink': u'http://arxiv.org/abs/1203.0439'}
2015-03-23 22:21:03+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0556> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:21:03+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0556>
	{'abstract': u'When binary linear error-correcting codes are used over symmetric channels, a relaxed version of the maximum likelihood decoding problem can be stated as a linear program (LP). This LP decoder can be used to decode error-correcting codes at bit-error-rates comparable to state-of-the-art belief propagation (BP) decoders, but with significantly stronger theoretical guarantees. However, LP decoding when implemented with standard LP solvers does not easily scale to the block lengths of modern error correcting codes. In this paper we draw on decomposition methods from optimization theory, specifically the Alternating Directions Method of Multipliers (ADMM), to develop efficient distributed algorithms for LP decoding. The key enabling technical result is a "two-slice" characterization of the geometry of the parity polytope, which is the convex hull of all codewords of a single parity check code. This new characterization simplifies the representation of points in the polytope. Using this simplification, we develop an efficient algorithm for Euclidean norm projection onto the parity polytope. This projection is required by ADMM and allows us to use LP decoding, with all its theoretical guarantees, to decode large-scale error correcting codes efficiently. We present numerical results for LDPC codes of lengths more than 1000. The waterfall region of LP decoding is seen to initiate at a slightly higher signal-to-noise ratio than for sum-product BP, however an error floor is not observed for LP decoding, which is not the case for BP. Our implementation of LP decoding using ADMM executes as fast as our baseline sum-product BP decoder, is fully parallelizable, and can be seen to implement a type of message-passing with a particularly simple schedule.',
	 'authors': u'Siddharth Barman, Xishuo Liu, Stark C. Draper, Benjamin Recht,',
	 'category': u'Computer Science ',
	 'date': '2012-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1204.0556',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nDecomposition Methods for Large Scale LP Decoding',
	 'urllink': u'http://arxiv.org/abs/1204.0556'}
2015-03-23 22:21:17+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0436> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:21:17+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0436>
	{'abstract': u'Continuous logic extends the multi-valued Lukasiewicz logic by adding a halving operator on propositions. This extension is designed to give a more satisfactory model theory for continuous structures. The semantics of these logics can be given using specialisations of algebraic structures known as hoops. As part of an investigation into the metatheory of propositional continuous logic, we were indebted to Prover9 for finding a proof of an important algebraic law.',
	 'authors': u'Rob Arthan, Paulo Oliva,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0436',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\n(Dual) Hoops Have Unique Halving',
	 'urllink': u'http://arxiv.org/abs/1203.0436'}
2015-03-23 22:21:20+0000 [xxu46_4] INFO: Crawled 115 pages (at 4 pages/min), scraped 109 items (at 4 items/min)
2015-03-23 22:21:34+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0547> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:21:34+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0547>
	{'abstract': u'Given a set of points in the plane, a emph of with respect to a point (not in ) is a clockwise circular ordering of the elements in by angle around . If is two-colored, a emph is a radial ordering of in which only the colors of the points are considered. In this paper, we obtain bounds on the number of distinct non-colored and colored radial orderings of . We assume a strong general position on , not three points are collinear and not three lines---each passing through a pair of points in ---intersect in a point of . In the colored case, is a set of points partitioned into red and blue points, and is even. We prove that: the number of distinct radial orderings of is at most and at least ; the number of colored radial orderings of is at most and at least ; there exist sets of points with colored radial orderings and sets of points with only colored radial orderings.',
	 'authors': u'Jos\xe9 M. D\xedaz-Ba\xf1ez, Ruy Fabila-Monroy, Pablo P\xe9rez-Lantero,',
	 'category': u'Computer Science ',
	 'date': '2012-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1204.0547',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nOn the number of radial orderings of planar point sets',
	 'urllink': u'http://arxiv.org/abs/1204.0547'}
2015-03-23 22:21:45+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0435> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:21:45+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0435>
	{'abstract': u"The rule technological landscape is becoming ever more complex, with an extended number of specifications and products. It is therefore becoming increasingly difficult to integrate rule-driven components and manage interoperability in multi-rule engine environments. The described work presents the possibility to provide a common interface for rule-driven components in a distributed system. The authors' approach leverages on a set of discovery protocol, rule interchange and user interface to alleviate the environment's complexity.",
	 'authors': u'Pierre de Leusse, Bartosz Kwolek, Krzysztof Zielinski,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0435',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nA common interface for multi-rule-engine distributed systems',
	 'urllink': u'http://arxiv.org/abs/1203.0435'}
2015-03-23 22:21:59+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0535> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:21:59+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0535>
	{'abstract': u'Display advertisements on the web are sold via ad exchanges that use real time auction. We describe the challenges of designing a suitable auction, and present a simple auction called the Optional Second Price (OSP) auction that is currently used in Doubleclick Ad Exchange.',
	 'authors': u'Yishay Mansour, S. Muthukrishnan, Noam Nisan,',
	 'category': u'Computer Science ',
	 'date': '2012-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1204.0535',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nDoubleclick Ad Exchange Auction',
	 'urllink': u'http://arxiv.org/abs/1204.0535'}
2015-03-23 22:22:13+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0434> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:22:13+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0434>
	{'abstract': u'There is no doubt that Search Engines are playing a great role in Internet usage. But all the top search engines Google, Yahoo and Bing are having a critical flaw called "Openness of a Search Engine". An Internet user should be allowed to get the search results only when requested through Search engine\'s web page but the user must not be allowed to get the search results when requested through any web page that does not belong to the Search Engine. Only results of a search engine should be available to the Internet user but not the Search Engine. This paper explains the critical flaw called "Openness of Search Engine" with a case study on top 3 search engines \'Google\', \'Yahoo\' and \'Bing\'. This paper conducts an attack based test using J2EE framework and proves that \'Google\' passed the test and it strongly protects its Critical Search System, where \'Yahoo\' and \'Bing\' are failed to protect their Search Engines. But previously \'Google\' also had other high severity issues with the Openness of search engine; this paper reveals those issues also. Finally this paper appeals strongly to the all top Search Engines to fix their critical flaws of "Openness of Search Engine".',
	 'authors': u'Katuru SM Kalyana Chakravarthy,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0434',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\n"openness of search engine": A critical flaw in search systems; a case  study on google, yahoo and bing',
	 'urllink': u'http://arxiv.org/abs/1203.0434'}
2015-03-23 22:22:20+0000 [xxu46_4] INFO: Crawled 119 pages (at 4 pages/min), scraped 113 items (at 4 items/min)
2015-03-23 22:22:23+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0480> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:22:24+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0480>
	{'abstract': u'Guttman presented a model-theoretic approach to establishing security goals in the context of Strand Space theory. In his approach, a run of the Cryptographic Protocol Shapes Analyzer (CPSA) produces models that determine if a goal is satisfied. This paper presents a method for extracting a sentence that completely characterizes a run of CPSA. Logical deduction can then be used to determine if a goal is satisfied. This method has been implemented and is available to all.',
	 'authors': u'John D. Ramsdell,',
	 'category': u'Computer Science ',
	 'date': '2012-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1204.0480',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nDeducing Security Goals From Shape Analysis Sentences',
	 'urllink': u'http://arxiv.org/abs/1204.0480'}
2015-03-23 22:22:37+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0432> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:22:37+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0432>
	{'abstract': u'In this article, the authors introduce the main ideas around the governance of cross-Cloud application deployment and their related concepts. It is argued that, due to the increasing complexity and nature of the Cloud market, an intermediary specialized in brokering the deployment of different components of a same application onto different Cloud products could both facilitate said deployment and in some cases improve its quality in terms of cost, security &amp; reliability and QoS. In order to fulfill these objectives, the authors propose a high level architecture that relies on their previous work on governance of policy &amp; rule driven distributed systems. This architecture aims at supplying five main functions of 1) translation of Service Level Agreements (SLAs) and pricing into a common shared DSL, 2) correlation of analytical data (e.g. monitoring, metering), 3) combination of Cloud products, 4) information from third parties regarding different aspects of Quality of Service (QoS) and 5) cross-Cloud application deployment specification and governance.',
	 'authors': u'Pierre de Leusse, Krzysztof Zielinski,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0432',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nToward Governance of Cross-Cloud Application Deployment',
	 'urllink': u'http://arxiv.org/abs/1203.0432'}
2015-03-23 22:22:51+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0479> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:22:51+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0479>
	{'abstract': u'The paper presents an ant colony optimization metaheuristic for collaborative planning. Collaborative planning is used to coordinate individual plans of self-interested decision makers with private information in order to increase the overall benefit of the coalition. The method consists of a new search graph based on encoded solutions. Distributed and private information is integrated via voting mechanisms and via a simple but effective collaborative local search procedure. The approach is applied to a distributed variant of the multi-level lot-sizing problem and evaluated by means of 352 benchmark instances from the literature. The proposed approach clearly outperforms existing approaches on the sets of medium and large sized instances. While the best method in the literature so far achieves an average deviation from the best known non-distributed solutions of 46 percent for the set of the largest instances, for example, the presented approach reduces the average deviation to only 5 percent.',
	 'authors': u'Tobias Buer, J\xf6rg Homberger, Hermann Gehring,',
	 'category': u'Computer Science ',
	 'date': '2012-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1204.0479',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nA collaborative ant colony metaheuristic for distributed multi-level  lot-sizing',
	 'urllink': u'http://arxiv.org/abs/1204.0479'}
2015-03-23 22:23:05+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0429> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:23:05+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0429>
	{'abstract': u'Service-oriented infrastructures pose new challenges in a number of areas, notably with regard to security and dependability. BT has developed a combination of innovative security solutions and governance frameworks that can address these challenges. They include advances in identity federation; distributed usage and access management; context-aware secure messaging, routing and transformation; and (security) policy governance for service-oriented architectures. This paper discusses these developments and the steps being taken to validate their functionality and performance.',
	 'authors': u'Theo Dimitrakos, David Brossard, Pierre de Leusse,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0429',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nSecuring business operations in an SOA',
	 'urllink': u'http://arxiv.org/abs/1203.0429'}
2015-03-23 22:23:14+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0469> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:23:14+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0469>
	{'abstract': u'While model checking PCTL for Markov chains is decidable in polynomial-time, the decidability of PCTL satisfiability, as well as its finite model property, are long standing open problems. While general satisfiability is an intriguing challenge from a purely theoretical point of view, we argue that general solutions would not be of interest to practitioners: such solutions could be too big to be implementable or even infinite. Inspired by bounded synthesis techniques, we turn to the more applied problem of seeking models of a bounded size: we restrict our search to implementable -- and therefore reasonably simple -- models. We propose a procedure to decide whether or not a given PCTL formula has an implementable model by reducing it to an SMT problem. We have implemented our techniques and found that they can be applied to the practical problem of sanity checking -- a procedure that allows a system designer to check whether their formula has an unexpectedly small model.',
	 'authors': u'Nathalie Bertrand, John Fearnley, Sven Schewe,',
	 'category': u'Computer Science ',
	 'date': '2012-3-30',
	 'pdflink': u'http://arxiv.org/pdf/1204.0469',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nBounded Satisfiability for PCTL',
	 'urllink': u'http://arxiv.org/abs/1204.0469'}
2015-03-23 22:23:20+0000 [xxu46_4] INFO: Crawled 124 pages (at 5 pages/min), scraped 118 items (at 5 items/min)
2015-03-23 22:23:32+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0415> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:23:32+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0415>
	{'abstract': u'We present a framework to formally describe probabilistic system behavior and symbolically reason about it. In particular we aim at reasoning about possible failures and fault tolerance. We regard systems which are composed of different units: sensors, computational parts and actuators. Considering worst-case failure behavior of system components, our framework is most suited to derive reliability guarantees for composed systems. The behavior of system components is modeled using monad like constructs that serve as an abstract representation for system behavior. We introduce rules to reason about these representations and derive results like guaranteed upper bounds for system failure. Our approach is characterized by the fact that we do not just map a certain component to a failure probability, but regard distributions of error behavior and their evolvement over system runs. This serves as basis for deriving probabilities of events, in particular failure probabilities. The work presented in this paper slightly extends a complete framework and a case study which has been previously published. One focus of this report is a more detailed explanation of definitions and a more comprehensive description of examples.',
	 'authors': u'Jan Olaf Blech,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0415',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nOn Compositional Reasoning for Guaranteeing Probabilistic Properties',
	 'urllink': u'http://arxiv.org/abs/1203.0415'}
2015-03-23 22:23:48+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0462> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:23:48+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0462>
	{'abstract': u'A novel time synchronization attack (TSA) on wide area monitoring systems in smart grid has been identified in the first part of this paper. A cross layer detection mechanism is proposed to combat TSA in part II of this paper. In the physical layer, we propose a GPS carrier signal noise ratio (C/No) based spoofing detection technique. In addition, a patch-monopole hybrid antenna is applied to receive GPS signal. By computing the standard deviation of the C/No difference from two GPS receivers, a priori probability of spoofing detection is fed to the upper layer, where power system state is estimated and controlled. A trustworthiness based evaluation method is applied to identify the PMU being under TSA. Both the physical layer and upper layer algorithms are integrated to detect the TSA, thus forming a cross layer mechanism. Experiment is carried out to verify the effectiveness of the proposed TSA detection algorithm.',
	 'authors': u'Zhenghao Zhang, Matthew Trinkle, Aleksandar D. Dimitrovski, Husheng Li,',
	 'category': u'Computer Science ',
	 'date': '2012-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1204.0462',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nTime Synchronization Attack in Smart Grid-Part II: Cross Layer Detection  Mechanism',
	 'urllink': u'http://arxiv.org/abs/1204.0462'}
2015-03-23 22:23:55+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0411> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:23:55+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0411>
	{'abstract': u"Previous work on voter control, which refers to situations where a chair seeks to change the outcome of an election by deleting, adding, or partitioning voters, takes for granted that the chair knows all the voters' preferences and that all votes are cast simultaneously. However, elections are often held sequentially and the chair thus knows only the previously cast votes and not the future ones, yet needs to decide instantaneously which control action to take. We introduce a framework that models emph. We show that the related problems can be much harder than in the standard (non-online) case: For certain election systems, even with efficient winner problems, online control by deleting, adding, or partitioning voters is PSPACE-complete, even if there are only two candidates. In addition, we obtain completeness for coNP in the deleting/adding cases with a bounded deletion/addition limit, and for NP in the partition cases with only one candidate. Finally, we show that for plurality, online control by deleting or adding voters is in P, and for partitioning voters is coNP-hard.",
	 'authors': u'Edith Hemaspaandra, Lane A. Hemaspaandra, Joerg Rothe,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0411',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nOnline Voter Control in Sequential Elections',
	 'urllink': u'http://arxiv.org/abs/1203.0411'}
2015-03-23 22:24:09+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0459> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:24:09+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0459>
	{'abstract': u'Many operations in power grids, such as fault detection and event location estimation, depend on precise timing information. In this paper, a novel Time Synchronization Attack (TSA) is proposed to attack the timing information in smart grid. Since many applications in smart grid utilize synchronous measurements and most of the measurement devices are equipped with global positioning system (GPS) for precise timing, it is highly probable to attack the measurement system by spoofing the GPS. The effectiveness of TSA is demonstrated for three applications of phasor measurement unit (PMU) in smart grid, namely transmission line fault detection, voltage stability monitoring and event locationing. The validity of TSA is demonstrated by numerical simulations.',
	 'authors': u'Zhenghao Zhang, Shuping Gong, Aleksandar D. Dimitrovski, Husheng Li,',
	 'category': u'Computer Science ',
	 'date': '2012-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1204.0459',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nTime Synchronization Attack in Smart Grid-Part I: Impact and Analysis',
	 'urllink': u'http://arxiv.org/abs/1204.0459'}
2015-03-23 22:24:20+0000 [xxu46_4] INFO: Crawled 128 pages (at 4 pages/min), scraped 122 items (at 4 items/min)
2015-03-23 22:24:26+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0400> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:24:26+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0400>
	{'abstract': u'Many companies include in their Information Systems (IS) several communicating heterogeneous middleware according to their technical needs. The need is the same when IS requires using context aware platforms for different aims. Moreover, users may be mobile and want to receive and send services with their PDA that more often supports Android based Human Man Interface. In this paper, we show how we extend Android to make it adaptable and open. We also present how we communicate between different heterogeneous context aware platforms as WComp and OpenORB by using Android and Web Services. We introduce a concrete case study to explain our approach.',
	 'authors': u'Valerie Monfort, Sihem Cherif,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0400',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nBridging the Gap between Technical Heterogeneity of Context-Aware  Platforms: Experimenting a Service Based Connectivity between Adaptable  Android, WComp and OpenORB',
	 'urllink': u'http://arxiv.org/abs/1203.0400'}
2015-03-23 22:24:35+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0448> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:24:35+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0448>
	{'abstract': u"In this paper we investigate the problem of gathering the data in wireless sensor network using a single Mobile Element. In particular we consider the case where the data are produced by measurements and they need to be delivered to a predefined sink within a given time interval from the time the measurement takes place. A mobile element travels the network in predefined paths, collect the data from the nodes, and deliver them to the sink by a single long-distance transmission. In this problem, the length of the mobile element path is bounded by pre-determined length. This path will visit a subset of the nodes. These selected nodes will work as caching points and will aggregate the other nodes' data. The caching point nodes are selected with the aim of reducing the energy expenditures due to multi-hop forwarding. We provide a heuristic-based solution for this problem. We evaluate the performance of our algorithm by comparing it to the best well-known algorithms from the literature.",
	 'authors': u"Bassam Alqaralleh, K. Almi'ani,",
	 'category': u'Computer Science ',
	 'date': '2012-4-2',
	 'pdflink': u'http://arxiv.org/e-print/1204.0448',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nData Gathering Scheme for Wireless SensorNetworks Using a Single Mobile  Element',
	 'urllink': u'http://arxiv.org/abs/1204.0448'}
2015-03-23 22:24:53+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0369> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:24:53+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0369>
	{'abstract': u'This paper proposes to put forward an innovative algorithm for symmetric key block cipher named as "Triple Prime Symmetric Key Block Cipher with Variable Key-Spaces (TPSKBCVK)" that employs triple prime integers as private key-spaces of varying lengths to encrypt data files. Principles of modular arithmetic have been elegantly used in the proposed idea of the cipher. Depending on observations of the results of implementation of the proposed cipher on a set of real data files of several types, all results are registered and analyzed. The strength of the underlying design of the cipher and the liberty of using a long key-space expectedly makes it reasonably non-susceptible against possible cryptanalytic intrusions. As a future scope of the work, it is intended to formulate and employ an improved scheme that will use a carrier media (image or multimedia data file) for a secure transmission of the private keys.',
	 'authors': u'Abhijit Chowdhury, Angshu Kumar Sinha, Saurabh Dutta,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0369',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nIntroduction of a Triple Prime Symmetric Key Block Cipher',
	 'urllink': u'http://arxiv.org/abs/1203.0369'}
2015-03-23 22:25:02+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0447> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:25:02+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0447>
	{'abstract': u"Not only the free web is victim to China's excessive censorship, but also the Tor anonymity network: the Great Firewall of China prevents thousands of potential Tor users from accessing the network. In this paper, we investigate how the blocking mechanism is implemented, we conjecture how China's Tor blocking infrastructure is designed and we propose countermeasures. Our work bolsters the understanding of China's censorship capabilities and thus paves the way towards more effective evasion techniques.",
	 'authors': u'Philipp Winter, Stefan Lindskog,',
	 'category': u'Computer Science ',
	 'date': '2012-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1204.0447',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nHow China Is Blocking Tor',
	 'urllink': u'http://arxiv.org/abs/1204.0447'}
2015-03-23 22:25:15+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0353> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:25:15+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0353>
	{'abstract': u'We consider the problem of conducting a survey with the goal of obtaining an unbiased estimator of some population statistic when individuals have unknown costs (drawn from a known prior) for participating in the survey. Individuals must be compensated for their participation and are strategic agents, and so the payment scheme must incentivize truthful behavior. We derive optimal truthful mechanisms for this problem for the two goals of minimizing the variance of the estimator given a fixed budget, and minimizing the expected cost of the survey given a fixed variance goal.',
	 'authors': u'Aaron Roth, Grant Schoenebeck,',
	 'category': u'Computer Science ',
	 'date': '2012-3-2',
	 'pdflink': u'http://arxiv.org/pdf/1203.0353',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nConducting Truthful Surveys, Cheaply',
	 'urllink': u'http://arxiv.org/abs/1203.0353'}
2015-03-23 22:25:20+0000 [xxu46_4] INFO: Crawled 133 pages (at 5 pages/min), scraped 127 items (at 5 items/min)
2015-03-23 22:25:29+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0431> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:25:29+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0431>
	{'abstract': u"In this paper, we study the finite blocklength limits of state-dependent discrete memoryless channels where the discrete memoryless state is known noncausally at the encoder. For the point-to-point case, this is known as the Gel'fand-Pinsker channel model. We define the (n, epsilon)-capacity of the Gel'fand-Pinsker channel as the maximal rate of transmission of a message subject to the condition that the length of the block-code is n and the average error probability is no larger than epsilon. This paper provides a lower bound for the (n, epsilon)-capacity of the Gel'fand-Pinsker channel model, and hence an upper bound on the dispersion, a fundamental second-order quantity in the study of the performance limits of discrete memoryless channels. In addition, we extend the work of Y. Steinberg (2005), in which the (degraded) broadcast channel extension of the Gel'fand-Pinsker model was studied. We provide and inner bound to the (n, epsilon)-capacity region for this broadcast channel model using a combination of ideas of Gel'fand-Pinsker coding, superposition coding and dispersion (finite blocklength) analysis.",
	 'authors': u'Vincent Y. F. Tan,',
	 'category': u'Computer Science ',
	 'date': '2012-4-2',
	 'pdflink': u'http://arxiv.org/e-print/1204.0431',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOn Dispersions of Discrete Memoryless Channels with Noncausal State  Information at the Encoder',
	 'urllink': u'http://arxiv.org/abs/1204.0431'}
2015-03-23 22:25:38+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0333> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:25:38+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0333>
	{'abstract': u'Biometric authentication systems are presented as the best way to reach high security levels in controlling access to IT systems or sensitive infrastructures. But several issues are often not taken properly into account. In order for the implementation of those systems to be successful, the hidden risks and the related liabilities have to be carefully analyzed before biometrics can be used on a large scale for sensitive applications.',
	 'authors': u'Alfredo Esposito,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0333',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nDebunking some myths about biometric authentication',
	 'urllink': u'http://arxiv.org/abs/1203.0333'}
2015-03-23 22:25:46+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0429> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:25:46+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0429>
	{'abstract': u'In this work we analyze principle component analysis (PCA) as a deterministic input-output system. We show that the relative information loss induced by reducing the dimensionality of the data after performing the PCA is the same as in dimensionality reduction without PCA. Finally, we analyze the case where the PCA uses the sample covariance matrix to compute the rotation. If the rotation matrix is not available at the output, we show that an infinite amount of information is lost. The relative information loss is shown to decrease with increasing sample size.',
	 'authors': u'Bernhard C. Geiger, Gernot Kubin,',
	 'category': u'Computer Science ',
	 'date': '2012-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1204.0429',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nRelative Information Loss in the PCA',
	 'urllink': u'http://arxiv.org/abs/1204.0429'}
2015-03-23 22:26:02+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0332> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:26:02+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0332>
	{'abstract': u'Tagging activity has been recently identified as a potential source of knowledge about personal interests, preferences, goals, and other attributes known from user models. Tags themselves can be therefore used for finding personalized recommendations of items. In this paper, we present a tag-based recommender system which suggests similar Web pages based on the similarity of their tags from a Web 2.0 tagging application. The proposed approach extends the basic similarity calculus with external factors such as tag popularity, tag representativeness and the affinity between user and tag. In order to study and evaluate the recommender system, we have conducted an experiment involving 38 people from 12 countries using data from Del.icio.us, a social bookmarking web system on which users can share their personal bookmarks.',
	 'authors': u'Frederico Durao, Peter Dolog,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0332',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nA Personalized Tag-Based Recommendation in Social Web Systems',
	 'urllink': u'http://arxiv.org/abs/1203.0332'}
2015-03-23 22:26:20+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0423> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:26:20+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0423>
	{'abstract': u'This is a report, where preliminary work regarding the topic of voting intention inference from Social Media - such as Twitter - is presented. Our case study is the UK 2010 General Election and we are focusing on predicting the percentages of voting intention polls (conducted by YouGov) for the three major political parties - Conservatives, Labours and Liberal Democrats - during a 5-month period before the election date (May 6, 2010). We form three methodologies for extracting positive or negative sentiment from tweets, which build on each other, and then propose two supervised models for turning sentiment into voting intention percentages. Interestingly, when the content of tweets is enriched by attaching synonymous words, a significant improvement on inference performance is achieved reaching a mean absolute error of 4.34% +/- 2.13%; in that case, the predictions are also shown to be statistically significant. The presented methods should be considered as work-in-progress; limitations and suggestions for future work appear in the final section of this script.',
	 'authors': u'Vasileios Lampos,',
	 'category': u'Computer Science ',
	 'date': '2012-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1204.0423',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nOn voting intentions inference from Twitter content: a case study on UK  2010 General Election',
	 'urllink': u'http://arxiv.org/abs/1204.0423'}
2015-03-23 22:26:20+0000 [xxu46_4] INFO: Crawled 138 pages (at 5 pages/min), scraped 132 items (at 5 items/min)
2015-03-23 22:26:33+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0321> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:26:33+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0321>
	{'abstract': u'High-performance scientific applications require more and more compute power. The concurrent use of multiple distributed compute resources is vital for making scientific progress. The resulting distributed system, a so-called Jungle Computing System, is both highly heterogeneous and hierarchical, potentially consisting of grids, clouds, stand-alone machines, clusters, desktop grids, mobile devices, and supercomputers, possibly with accelerators such as GPUs. One striking example of applications that can benefit greatly of Jungle Computing Systems are Multi-Model / Multi-Kernel simulations. In these simulations, multiple models, possibly implemented using different techniques and programming models, are coupled into a single simulation of a physical system. Examples include the domain of computational astrophysics and climate modeling. In this paper we investigate the use of Jungle Computing Systems for such Multi-Model / Multi-Kernel simulations. We make use of the software developed in the Ibis project, which addresses many of the problems faced when running applications on Jungle Computing Systems. We create a prototype Jungle-aware version of AMUSE, an astrophysical simulation framework. We show preliminary experiments with the resulting system, using clusters, grids, stand-alone machines, and GPUs.',
	 'authors': u'Niels Drost, Jason Maassen, Maarten A.J. van Meersbergen, Henri E. Bal, F. Inti Pelupessy, Simon Portegies Zwart, Michael Kliphuis, Henk A. Dijkstra, Frank J. Seinstra,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0321',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nHigh-Performance Distributed Multi-Model / Multi-Kernel Simulations: A  Case-Study in Jungle Computing',
	 'urllink': u'http://arxiv.org/abs/1203.0321'}
2015-03-23 22:26:48+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0416> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:26:48+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0416>
	{'abstract': u'We consider Content Centric Network (CCN) interest forwarding problem as a Multi-Armed Bandit (MAB) problem with delays. We investigate the transient behaviour of the -greedy, tuned -greedy and Upper Confidence Bound (UCB) interest forwarding policies. Surprisingly, for all the three policies very short initial exploratory phase is needed. We demonstrate that the tuned -greedy algorithm is nearly as good as the UCB algorithm, the best currently available algorithm. We prove the uniform logarithmic bound for the tuned -greedy algorithm. In addition to its immediate application to CCN interest forwarding, the new theoretical results for MAB problem with delays represent significant theoretical advances in machine learning discipline.',
	 'authors': u'Konstantin Avrachenkov, Peter Jacko,',
	 'category': u'Computer Science ',
	 'date': '2012-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1204.0416',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nCCN Interest Forwarding Strategy as Multi-Armed Bandit Model with Delays',
	 'urllink': u'http://arxiv.org/abs/1204.0416'}
2015-03-23 22:27:01+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0298> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:27:01+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0298>
	{'abstract': u'In this paper, we study the application of GIST SVM in disease prediction (detection of cancer). Pattern classification problems can be effectively solved by Support vector machines. Here we propose a classifier which can differentiate patients having benign and malignant cancer cells. To improve the accuracy of classification, we propose to determine the optimal size of the training set and perform feature selection. To find the optimal size of the training set, different sizes of training sets are experimented and the one with highest classification rate is selected. The optimal features are selected through their F-Scores.',
	 'authors': u'S. Aruna, S. P. Rajagopalan, L. V. Nandakishore,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0298',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nApplication of Gist SVM in Cancer Detection',
	 'urllink': u'http://arxiv.org/abs/1203.0298'}
2015-03-23 22:27:18+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0414> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:27:18+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0414>
	{'abstract': u'State-space reduction techniques, used primarily in model-checkers, all rely on the idea that some actions are independent, hence could be taken in any (respective) order while put in parallel, without changing the semantics. It is thus not necessary to consider all execution paths in the interleaving semantics of a concurrent program, but rather some equivalence classes. The purpose of this paper is to describe a new algorithm to compute such equivalence classes, and a representative per class, which is based on ideas originating in algebraic topology. We introduce a geometric semantics of concurrent languages, where programs are interpreted as directed topological spaces, and study its properties in order to devise an algorithm for computing dihomotopy classes of execution paths. In particular, our algorithm is able to compute a control-flow graph for concurrent programs, possibly containing loops, which is "as reduced as possible" in the sense that it generates traces modulo equivalence. A preliminary implementation was achieved, showing promising results towards efficient methods to analyze concurrent programs, with very promising results compared to partial-order reduction techniques.',
	 'authors': u'Lisbeth Fajstrup, Eric Goubault, Emmanuel Haucourt, Samuel Mimram, Martin Raussen,',
	 'category': u'Computer Science ',
	 'date': '2012-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1204.0414',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nTrace Spaces: an Efficient New Technique for State-Space Reduction',
	 'urllink': u'http://arxiv.org/abs/1204.0414'}
2015-03-23 22:27:20+0000 [xxu46_4] INFO: Crawled 142 pages (at 4 pages/min), scraped 136 items (at 4 items/min)
2015-03-23 22:27:27+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0290> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:27:27+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0290>
	{'abstract': u'In this paper we consider the problem of determining the weight spectrum of q-ary codes C(3,m) associated with Grassmann varieties G(3,m). For m=6 this was done by Nogin. We derive a formula for the weight of a codeword of C(3,m), in terms of certain varieties associated with alternating trilinear forms on (F_q)^m. The classification of such forms under the action of the general linear group GL(m,F_q) is the other component that is required to calculate the spectrum of C(3,m). For m=7, we explicitly determine the varieties mentioned above. The classification problem for alternating 3-forms on (F_q)^7 was solved by Cohen and Helminck, which we then use to determine the spectrum of C(3,7).',
	 'authors': u'K. V. Kaipa, H. Pillai,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0290',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nWeight spectrum of codes associated with the Grassmannian G(3,7)',
	 'urllink': u'http://arxiv.org/abs/1203.0290'}
2015-03-23 22:27:44+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0375> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:27:44+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0375>
	{'abstract': u'In this paper, we investigate the implementation of a Python code for a Kalman Filter using the Numpy package. A Kalman Filtering is carried out in two steps: Prediction and Update. Each step is investigated and coded as a function with matrix input and output. These different functions are explained and an example of a Kalman Filter application for the localization of mobile in wireless networks is given.',
	 'authors': u'Mohamed Laaraiedh,',
	 'category': u'Computer Science ',
	 'date': '2012-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1204.0375',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nImplementation of Kalman Filter with Python Language',
	 'urllink': u'http://arxiv.org/abs/1204.0375'}
2015-03-23 22:27:59+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0289> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:27:59+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0289>
	{'abstract': u'We describe scalable algorithms for secure multiparty computation (SMPC). We assume a synchronous message passing communication model, but unlike most related work, we do not assume the existence of a broadcast channel. Our main result holds for the case where there are n players, of which a (1/3- epsilon)-fraction are controlled by an adversary, for epsilon, any positive constant. We describe a SMPC algorithm for this model that requires each player to send O((n+m)/n + sqrt) (where the O notation hides polylogarithmic factors) messages and perform O((n+m)/n + sqrt) computations to compute any function f, where m is the size of a circuit to compute f. We also consider a model where all players are selfish but rational. In this model, we describe a Nash equilibrium protocol that solve SMPC and requires each player to send O((n+m)/n) messages and perform O((n+m)/n) computations. These results significantly improve over past results for SMPC which require each player to send a number of bits and perform a number of computations that is theta(nm).',
	 'authors': u'Varsha Dani, Valerie King, Mahnush Movahedi, Jared Saia,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0289',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nBreaking the O(nm) Bit Barrier: Secure Multiparty Computation with a  Static Adversary',
	 'urllink': u'http://arxiv.org/abs/1203.0289'}
2015-03-23 22:28:15+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0368> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:28:15+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0368>
	{'abstract': u'In dynamic and turbulent business environment, the need for success and survival of any organization is the ability of adapting to changes efficiently and cost-effectively. So, for developing software applications, one of the methods is Service Oriented Architecture (SOA) methodology and other is Agile Methodology. Since embracing changes is the indispensable concept of SOA development as well as Agile Development, using an appropriate SOA methodology able to adapt changes even during system development with the preservation of software quality is necessary. In this paper, a new approach consisted of five steps is presented to add agility to SOA methodologies. This approach, before any SOA-based development, helps architect(s) to determine Core Business Processes (CBPs) by using agile principals for establishing Core Architecture. The most important advantage of this approach according to the results of case study is possibility of embracing changes with the preservation of software quality in SOA developments.',
	 'authors': u'Majlesi Shahrbanoo, Mehrpour Ali, Mohsenzadeh Mehran,',
	 'category': u'Computer Science ',
	 'date': '2012-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1204.0368',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nAn Approach for Agile SOA Development using Agile Principals',
	 'urllink': u'http://arxiv.org/abs/1204.0368'}
2015-03-23 22:28:20+0000 [xxu46_4] INFO: Crawled 146 pages (at 4 pages/min), scraped 140 items (at 4 items/min)
2015-03-23 22:28:29+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0265> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:28:29+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0265>
	{'abstract': u'This paper presents the Discrete Wavelet based fusion techniques for combining perceptually important image features. SPIHT (Set Partitioning in Hierarchical Trees) algorithm is an efficient method for lossy and lossless coding of fused image. This paper presents some modifications on the SPIHT algorithm. It is based on the idea of insignificant correlation of wavelet coefficient among the medium and high frequency sub bands. In RE-MSPIHT algorithm, wavelet coefficients are scaled prior to SPIHT coding based on the sub band importance, with the goal of minimizing the MSE.',
	 'authors': u'S. Chitra, J. B. Bhattacharjee, B. Thilakavathi,',
	 'category': u'Computer Science ',
	 'date': '2012-2-29',
	 'pdflink': u'http://arxiv.org/pdf/1203.0265',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nImage Fusion and Re-Modified SPIHT for Fused Image',
	 'urllink': u'http://arxiv.org/abs/1203.0265'}
2015-03-23 22:28:43+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0357> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:28:43+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0357>
	{'abstract': u'Skull-stripping separates the skull region of the head from the soft brain tissues. In many cases of brain image analysis, this is an essential preprocessing step in order to improve the final result. This is true for both registration and segmentation tasks. In fact, skull-stripping of magnetic resonance images (MRI) is a well-studied problem with numerous publications in recent years. Many different algorithms have been proposed, a summary and comparison of which can be found in [Fennema-Notestine, 2006]. Despite the abundance of approaches, we discovered that the algorithms which had been suggested so far, perform poorly when dealing with tumor-bearing brain images. This is mostly due to additional difficulties in separating the brain from the skull in this case, especially when the lesion is located very close to the skull border. Additionally, images acquired according to standard clinical protocols, often exhibit anisotropic resolution and only partial coverage, which further complicates the task. Therefore, we developed a method which is dedicated to skull-stripping for clinically acquired tumor-bearing brain images.',
	 'authors': u'Stefan Bauer, Lutz-P. Nolte, Mauricio Reyes,',
	 'category': u'Computer Science ',
	 'date': '2012-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1204.0357',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nSkull-stripping for Tumor-bearing Brain Images',
	 'urllink': u'http://arxiv.org/abs/1204.0357'}
2015-03-23 22:28:58+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0259> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:28:58+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0259>
	{'abstract': u'Link-based data structures, such as linked lists and binary search trees, have many well-known rearrangement steps allowing for efficient implementations of insertion, deletion, and other operations. We describe a rearrangement primitive designed for link-based, heap-ordered priority queues in the comparison model, such as those similar to Fibonacci heaps or binomial heaps. In its most basic form, the primitive rearranges a collection of heap-ordered perfect binary trees. Doing so offers a data structure control on the number of trees involved in such a collection, in particular keeping this number logarithmic in the number of elements. The rearrangement step is free from an amortized complexity standpoint (using an appropriate potential function).',
	 'authors': u'Boris Alexeev, M. Brian Jacokes,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0259',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nA rearrangement step with potential uses in priority queues',
	 'urllink': u'http://arxiv.org/abs/1203.0259'}
2015-03-23 22:29:09+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0354> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:29:09+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0354>
	{'abstract': u'Identifying the infection sources in a network, including the index cases that introduce a contagious disease into a population network, the servers that inject a computer virus into a computer network, or the individuals who started a rumor in a social network, plays a critical role in limiting the damage caused by the infection through timely quarantine of the sources. We consider the problem of estimating the infection sources and the infection regions (subsets of nodes infected by each source) in a network, based only on knowledge of which nodes are infected and their connections, and when the number of sources is unknown a priori. We derive estimators for the infection sources and their infection regions based on approximations of the infection sequences count. We prove that if there are at most two infection sources in a geometric tree, our estimator identifies the true source or sources with probability going to one as the number of infected nodes increases. When there are more than two infection sources, and when the maximum possible number of infection sources is known, we propose an algorithm with quadratic complexity to estimate the actual number and identities of the infection sources. Simulations on various kinds of networks, including tree networks, small-world networks and real world power grid networks, and tests on two real data sets are provided to verify the performance of our estimators.',
	 'authors': u'Wuqiong Luo, Wee Peng Tay, Mei Leng,',
	 'category': u'Computer Science ',
	 'date': '2012-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1204.0354',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nIdentifying Infection Sources and Regions in Large Networks',
	 'urllink': u'http://arxiv.org/abs/1204.0354'}
2015-03-23 22:29:20+0000 [xxu46_4] INFO: Crawled 150 pages (at 4 pages/min), scraped 144 items (at 4 items/min)
2015-03-23 22:29:25+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0240> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:29:25+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0240>
	{'abstract': u'Security of Wireless sensor network (WSN) becomes a very important issue with the rapid development of WSN that is vulnerable to a wide range of attacks due to deployment in the hostile environment and having limited resources. Intrusion detection system is one of the major and efficient defensive methods against attacks in WSN. A particularly devastating attack is the sleep deprivation attack, where a malicious node forces legitimate nodes to waste their energy by resisting the sensor nodes from going into low power sleep mode. The goal of this attack is to maximize the power consumption of the target node, thereby decreasing its battery life. Existing works on sleep deprivation attack have mainly focused on mitigation using MAC based protocols, such as S-MAC, T-MAC, B-MAC, etc. In this article, a brief review of some of the recent intrusion detection systems in wireless sensor network environment is presented. Finally, we propose a framework of cluster based layered countermeasure that can efficiently mitigate sleep deprivation attack in WSN. Simulation results on MATLAB exhibit the effectiveness of the proposed model in detecting sleep-deprivation attacks.',
	 'authors': u'Tapalina Bhattasali, Rituparna Chaki,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0240',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nA Survey of Recent Intrusion Detection Systems for Wireless Sensor  Network',
	 'urllink': u'http://arxiv.org/abs/1203.0240'}
2015-03-23 22:29:39+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0347> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:29:39+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0347>
	{'abstract': u'Calculi with control operators have been studied as extensions of simple type theory. Real programming languages contain datatypes, so to really understand control operators, one should also include these in the calculus. As a first step in that direction, we introduce lambda-mu-T, a combination of Parigot\'s lambda-mu-calculus and G "odel\'s T, to extend a calculus with control operators with a datatype of natural numbers with a primitive recursor. We consider the problem of confluence on raw terms, and that of strong normalization for the well-typed terms. Observing some problems with extending the proofs of Baba at al. and Parigot\'s original confluence proof, we provide new, and improved, proofs of confluence (by complete developments) and strong normalization (by reducibility and a postponement argument) for our system. We conclude with some remarks about extensions, choices, and prospects for an improved presentation.',
	 'authors': u'Herman Geuvers, Robbert Krebbers, James McKinna,',
	 'category': u'Computer Science ',
	 'date': '2012-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1204.0347',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nThe lambda-mu-T-calculus',
	 'urllink': u'http://arxiv.org/abs/1204.0347'}
2015-03-23 22:29:56+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0231> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:29:56+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0231>
	{'abstract': u'Deployment of sensor network in hostile environment makes it mainly vulnerable to battery drainage attacks because it is impossible to recharge or replace the battery power of sensor nodes. Among different types of security threats, low power sensor nodes are immensely affected by the attacks which cause random drainage of the energy level of sensors, leading to death of the nodes. The most dangerous type of attack in this category is sleep deprivation, where target of the intruder is to maximize the power consumption of sensor nodes, so that their lifetime is minimized. Most of the existing works on sleep deprivation attack detection involve a lot of overhead, leading to poor throughput. The need of the day is to design a model for detecting intrusions accurately in an energy efficient manner. This paper proposes a hierarchical framework based on distributed collaborative mechanism for detecting sleep deprivation torture in wireless sensor network efficiently. Proposed model uses anomaly detection technique in two steps to reduce the probability of false intrusion.',
	 'authors': u'Tapalina Bhattasali, Rituparna Chaki, Sugata Sanyal,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0231',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nSleep Deprivation Attack Detection in Wireless Sensor Network',
	 'urllink': u'http://arxiv.org/abs/1203.0231'}
2015-03-23 22:30:13+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0343> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:30:13+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0343>
	{'abstract': u"A recent paper [1] (El Aroudi, 2012) misapplied a critical condition (Fang and Abed, 2001) to a well-known example. Even if the mistake is corrected, the results in [1] are applicable only to buck converters and period-doubling bifurcation. Actually, these results are known in Fang's works a decade ago which have broader critical conditions applicable to other converters and bifurcations. The flaws in [1] are identified.",
	 'authors': u'Chung-Chieh Fang,',
	 'category': u'Computer Science ',
	 'date': '2012-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1204.0343',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nComments on "Prediction of Subharmonic Oscillation in Switching  Converters Under Different Control Strategies"',
	 'urllink': u'http://arxiv.org/abs/1204.0343'}
2015-03-23 22:30:20+0000 [xxu46_4] INFO: Crawled 154 pages (at 4 pages/min), scraped 148 items (at 4 items/min)
2015-03-23 22:30:29+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0224> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:30:29+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0224>
	{'abstract': u'We study the well-known Label Cover problem under the additional requirement that problem instances have large girth. We show that if the girth is some , the problem is roughly hard to approximate for all constant . A similar theorem was claimed by Elkin and Peleg [ICALP 2000], but their proof was later found to have a fundamental error. We use the new proof to show inapproximability for the basic -spanner problem, which is both the simplest problem in graph spanners and one of the few for which super-logarithmic hardness was not known. Assuming , we show that for every and every constant it is hard to approximate the basic -spanner problem within a factor better than (for large enough ). A similar hardness for basic -spanner was claimed by Elkin and Peleg [ICALP 2000], but the error in their analysis of Label Cover made this proof fail as well. Thus for the problem of Label Cover with large girth we give the first non-trivial lower bound. For the basic -spanner problem we improve the previous best lower bound of by Kortsarz [Algorithmica 1998]. Our main technique is subsampling the edges of 2-query PCPs, which allows us to reduce the degree of a PCP to be essentially equal to the soundness desired. This turns out to be enough to essentially guarantee large girth.',
	 'authors': u'Michael Dinitz, Guy Kortsarz, Ran Raz,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0224',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nLabel Cover instances with large girth and the hardness of approximating  basic k-spanner',
	 'urllink': u'http://arxiv.org/abs/1203.0224'}
2015-03-23 22:30:44+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0334> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:30:44+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0334>
	{'abstract': u'With the use of belief propagation (BP) decoding algorithm, low-density parity-check (LDPC) codes can achieve near-Shannon limit performance. In order to evaluate the error performance of LDPC codes, simulators running on CPUs are commonly used. However, the time taken to evaluate LDPC codes with very good error performance is excessive. In this paper, efficient LDPC block-code decoders/simulators which run on graphics processing units (GPUs) are proposed. We also implement the decoder for the LDPC convolutional code (LDPCCC). The LDPCCC is derived from a pre-designed quasi-cyclic LDPC block code with good error performance. Compared to the decoder based on the randomly constructed LDPCCC code, the complexity of the proposed LDPCCC decoder is reduced due to the periodicity of the derived LDPCCC and the properties of the quasi-cyclic structure. In our proposed decoder architecture, (a multiple of a warp) codewords are decoded together and hence the messages of codewords are also processed together. Since all the codewords share the same Tanner graph, messages of the distinct codewords corresponding to the same edge can be grouped into one package and stored linearly. By optimizing the data structures of the messages used in the decoding process, both the read and write processes can be performed in a highly parallel manner by the GPUs. In addition, a thread hierarchy minimizing the divergence of the threads is deployed, and it can maximize the efficiency of the parallel execution. With the use of a large number of cores in the GPU to perform the simple computations simultaneously, our GPU-based LDPC decoder can obtain hundreds of times speedup compared with a serial CPU-based simulator and over 40 times speedup compared with an 8-thread CPU-based simulator.',
	 'authors': u'Yue Zhao, Francis C. M. Lau,',
	 'category': u'Computer Science ',
	 'date': '2012-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1204.0334',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nImplementation Of Decoders for LDPC Block Codes and LDPC Convolutional  Codes Based on GPUs',
	 'urllink': u'http://arxiv.org/abs/1204.0334'}
2015-03-23 22:31:00+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0220> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:31:00+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0220>
	{'abstract': u'We introduce a family of new equational semantics for argumentation networks which can handle odd and even loops in a uniform manner. We offer one version of equational semantics which is equivalent to CF2 semantics, and a better version which gives the same results as traditional Dung semantics for even loops but can still handle odd loops.',
	 'authors': u'Dov M. Gabbay,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0220',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nThe Equational Approach to CF2 Semantics',
	 'urllink': u'http://arxiv.org/abs/1203.0220'}
2015-03-23 22:31:18+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0309> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:31:18+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0309>
	{'abstract': u"The World Wide Web caters to the needs of billions of users in heterogeneous groups. Each user accessing the World Wide Web might have his / her own specific interest and would expect the web to respond to the specific requirements. The process of making the web to react in a customized manner is achieved through personalization. This paper proposes a novel model for extracting keywords from a web page with personalization being incorporated into it. The keyword extraction problem is approached with the help of web page segmentation which facilitates in making the problem simpler and solving it effectively. The proposed model is implemented as a prototype and the experiments conducted on it empirically validate the model's efficiency.",
	 'authors': u'K. S. Kuppusamy, G. Aghila,',
	 'category': u'Computer Science ',
	 'date': '2012-4-2',
	 'pdflink': u'http://arxiv.org/pdf/1204.0309',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nA Model for Personalized Keyword Extraction from Web Pages using  Segmentation',
	 'urllink': u'http://arxiv.org/abs/1204.0309'}
2015-03-23 22:31:20+0000 [xxu46_4] INFO: Crawled 158 pages (at 4 pages/min), scraped 152 items (at 4 items/min)
2015-03-23 22:31:34+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0203> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:31:34+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0203>
	{'abstract': u"The use of Reinforcement Learning in real-world scenarios is strongly limited by issues of scale. Most RL learning algorithms are unable to deal with problems composed of hundreds or sometimes even dozens of possible actions, and therefore cannot be applied to many real-world problems. We consider the RL problem in the supervised classification framework where the optimal policy is obtained through a multiclass classifier, the set of classes being the set of actions of the problem. We introduce error-correcting output codes (ECOCs) in this setting and propose two new methods for reducing complexity when using rollouts-based approaches. The first method consists in using an ECOC-based classifier as the multiclass classifier, reducing the learning complexity from O(A2) to O(Alog(A)). We then propose a novel method that profits from the ECOC's coding dictionary to split the initial MDP into O(log(A)) seperate two-action MDPs. This second method reduces learning complexity even further, from O(A2) to O(log(A)), thus rendering problems with large action sets tractable. We finish by experimentally demonstrating the advantages of our approach on a set of benchmark problems, both in speed and performance.",
	 'authors': u'Gabriel Dulac-Arnold, Ludovic Denoyer, Philippe Preux, Patrick Gallinari,',
	 'category': u'Computer Science ',
	 'date': '2012-2-29',
	 'pdflink': u'http://arxiv.org/pdf/1203.0203',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nFast Reinforcement Learning with Large Action Sets using  Error-Correcting Output Codes for MDP Factorization',
	 'urllink': u'http://arxiv.org/abs/1203.0203'}
2015-03-23 22:31:52+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0281> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:31:52+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0281>
	{'abstract': u'Let be given. As we know the, amount of bits needed to binary code with given accuracy () is approximately We consider the problem where we should translate the origin so that the mean amount of bits needed to code randomly chosen element from a realization of a random variable is minimal. In other words, we want to find such that R ni a to mathrm ( m_ (X-a)) attains minimum.',
	 'authors': u'Przemys\u0142aw Spurek, Jacek Tabor,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0281',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nThe memory centre',
	 'urllink': u'http://arxiv.org/abs/1204.0281'}
2015-03-23 22:32:05+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0200> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:32:05+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0200>
	{'abstract': u'SOA brought new opportunities for the long expected agility, reuse and the adaptive capability of information technology to the ever changing business requirements and environments. The purpose of this paper is to describe the implementation of Medical Insurance Claim Process Model using SOA. We adopt Service Oriented Architecture (SOA) to reduce the complexity among systems and solve data consistency problems among services. We choose n-tier and Service-Oriented Architecture (SOA) as our system environment. This model can also establish a potentially new innovative market branch for the insurance industry.',
	 'authors': u'S. Nirmala Sugirtha Rajini, T. Bhuvaneswari,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0200',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nAn Interface using SOA Framework For Mediclaim Provider',
	 'urllink': u'http://arxiv.org/abs/1203.0200'}
2015-03-23 22:32:20+0000 [xxu46_4] INFO: Crawled 161 pages (at 3 pages/min), scraped 155 items (at 3 items/min)
2015-03-23 22:32:22+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0280> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:32:22+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0280>
	{'abstract': u'As general purpose robots become more capable, pre-programming of all tasks at the factory will become less practical. We would like for non-technical human owners to be able to communicate, through interaction with their robot, the details of a new task; we call this interaction "task communication". During task communication the robot must infer the details of the task from unstructured human signals and it must choose actions that facilitate this inference. In this paper we propose the use of a partially observable Markov decision process (POMDP) for representing the task communication problem; with the unobservable task details and unobservable intentions of the human teacher captured in the state, with all signals from the human represented as observations, and with the cost function chosen to penalize uncertainty. We work through an example representation of task communication as a POMDP, and present results from a user experiment on an interactive virtual robot, compared with a human controlled virtual robot, for a task involving a single object movement and binary approval input from the teacher. The results suggest that the proposed POMDP representation produces robots that are robust to teacher error, that can accurately infer task details, and that are perceived to be intelligent.',
	 'authors': u'Mark P. Woodward, Robert J. Wood,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0280',
	 'subjects': u'Robotics (cs.RO)',
	 'title': u'\nFraming Human-Robot Task Communication as a POMDP',
	 'urllink': u'http://arxiv.org/abs/1204.0280'}
2015-03-23 22:32:35+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0197> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:32:35+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0197>
	{'abstract': u'Applications of ACO algorithms to obtain better solutions for combinatorial optimization problems have become very popular in recent years. In ACO algorithms, group of agents repeatedly perform well defined actions and collaborate with other ants in order to accomplish the defined task. In this paper, we introduce new mechanisms for selecting the Elite ants dynamically based on simple statistical tools. We also investigate the performance of newly proposed mechanisms.',
	 'authors': u'G. S. Raghavendra, N. Prasanna Kumar,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0197',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nStatistical Approach for Selecting Elite Ants',
	 'urllink': u'http://arxiv.org/abs/1203.0197'}
2015-03-23 22:32:50+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0274> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:32:50+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0274>
	{'abstract': u"The interactive partially observable Markov decision process (I-POMDP) is a recently developed framework which extends the POMDP to the multi-agent setting by including agent models in the state space. This paper argues for formulating the problem of an agent learning interactively from a human teacher as an I-POMDP, where the agent emph to be learned is captured by random variables in the agent's state space, all emph from the human teacher are treated as observed random variables, and the human teacher, modeled as a distinct agent, is explicitly represented in the agent's state space. The main benefits of this approach are: i. a principled action selection mechanism, ii. a principled belief update mechanism, iii. support for the most common teacher emph, and iv. the anticipated production of complex beneficial interactions. The proposed formulation, its benefits, and several open questions are presented.",
	 'authors': u'Mark P. Woodward, Robert J. Wood,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0274',
	 'subjects': u'Robotics (cs.RO)',
	 'title': u'\nLearning from Humans as an I-POMDP',
	 'urllink': u'http://arxiv.org/abs/1204.0274'}
2015-03-23 22:32:58+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0160> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:32:58+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0160>
	{'abstract': u'In this paper, we present the case for a declarative foundation for data-intensive machine learning systems. Instead of creating a new system for each specific flavor of machine learning task, or hardcoding new optimizations, we argue for the use of recursive queries to program a variety of machine learning systems. By taking this approach, database query optimization techniques can be utilized to identify effective execution plans, and the resulting runtime plans can be executed on a single unified data-parallel query processing engine. As a proof of concept, we consider two programming models--Pregel and Iterative Map-Reduce-Update---from the machine learning domain, and show how they can be captured in Datalog, tuned for a specific task, and then compiled into an optimized physical plan. Experiments performed on a large computing cluster with real data demonstrate that this declarative approach can provide very good performance while offering both increased generality and programming ease.',
	 'authors': u'Yingyi Bu, Vinayak Borkar, Michael J. Carey, Joshua Rosen, Neoklis Polyzotis, Tyson Condie, Markus Weimer, Raghu Ramakrishnan,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0160',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nScaling Datalog for Machine Learning on Big Data',
	 'urllink': u'http://arxiv.org/abs/1203.0160'}
2015-03-23 22:33:14+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0267> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:33:14+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0267>
	{'abstract': u'We present two open-source (BSD) implementations of ellipsoidal harmonic expansions for solving problems of potential theory using separation of variables. Ellipsoidal harmonics are used surprisingly infrequently, considering their substantial value for problems ranging in scale from molecules to the entire solar system. In this article, we suggest two possible reasons for the paucity relative to spherical harmonics. The first is essentially historical---ellipsoidal harmonics developed during the late 19th century and early 20th, when it was found that only the lowest-order harmonics are expressible in closed form. Each higher-order term requires the solution of an eigenvalue problem, and tedious manual computation seems to have discouraged applications and theoretical studies. The second explanation is practical: even with modern computers and accurate eigenvalue algorithms, expansions in ellipsoidal harmonics are significantly more challenging to compute than those in Cartesian or spherical coordinates. The present implementations reduce the "barrier to entry" by providing an easy and free way for the community to begin using ellipsoidal harmonics in actual research. We demonstrate our implementation using the specific and physiologically crucial problem of how charged proteins interact with their environment, and ask: what other analytical tools await re-discovery in an era of inexpensive computation?',
	 'authors': u'Jaydeep P. Bardhan, Matthew G. Knepley,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0267',
	 'subjects': u'Computational Engineering, Finance, and Science (cs.CE)',
	 'title': u'\nComputational science and re-discovery: open-source implementations of  ellipsoidal harmonics for problems in potential theory',
	 'urllink': u'http://arxiv.org/abs/1204.0267'}
2015-03-23 22:33:20+0000 [xxu46_4] INFO: Crawled 166 pages (at 5 pages/min), scraped 160 items (at 5 items/min)
2015-03-23 22:33:26+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0145> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:33:26+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0145>
	{'abstract': u"I pinpoint an interesting similarity between a recent account to rational parsing and the treatment of sequential decisions problems in a dynamical systems approach. I argue that expectation-driven search heuristics aiming at fast computation resembles a high-risk decision strategy in favor of large transition velocities. Hale's rational parser, combining generalized left-corner parsing with informed search to resolve processing conflicts, explains gardenpath effects in natural sentence processing by misleading estimates of future processing costs that are to be minimized. On the other hand, minimizing the duration of cognitive computations in time-continuous dynamical systems can be described by combining vector space representations of cognitive states by means of filler/role decompositions and subsequent tensor product representations with the paradigm of stable heteroclinic sequences. Maximizing transition velocities according to a high-risk decision strategy could account for a fast race even between states that are apparently remote in representation space.",
	 'authors': u'Peter beim Graben,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/e-print/1203.0145',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nThe Horse Raced Past: Gardenpath Processing in Dynamical Systems',
	 'urllink': u'http://arxiv.org/abs/1203.0145'}
2015-03-23 22:33:42+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0262> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:33:42+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0262>
	{'abstract': u'Today, a wide variety of probabilistic and expert AI systems used to analyze real world inputs such as unstructured text, sounds, images, and statistical data. However, all these systems exist on different platforms, with different implementations, and with very different, often very specific goals in mind. This paper introduces a concept for a mediator framework for such systems and seeks to show several architectures which would support it, potential benefits in combining the signals of disparate networks for formalized, high level logic and signal processing, and its possible academic and industrial uses.',
	 'authors': u'Greg Fish,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0262',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nManaging contextual artificial neural networks with a service-based  mediator',
	 'urllink': u'http://arxiv.org/abs/1204.0262'}
2015-03-23 22:33:59+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0837> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:33:59+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0837>
	{'abstract': u'We consider the recently introduced monochromatic reverse top-k queries which ask for, given a new tuple q and a dataset D, all possible top-k queries on D union for which q is in the result. Towards this problem, we focus on designing indexes in two dimensions for repeated (or batch) querying, a novel but practical consideration. We present the insight that by representing the dataset as an arrangement of lines, a critical k-polygon can be identified and used exclusively to respond to reverse top-k queries. We construct an index based on this observation which has guaranteed worst-case query cost that is logarithmic in the size of the k-polygon. We implement our work and compare it to related approaches, demonstrating that our index is fast in practice. Furthermore, we demonstrate through our experiments that a k-polygon is comprised of a small proportion of the original data, so our index structure consumes little disk space.',
	 'authors': u'Sean Chester, Alex Thomo, S. Venkatesh, Sue Whitesides,',
	 'category': u'Computer Science ',
	 'date': '2012-5-4',
	 'pdflink': u'http://arxiv.org/pdf/1205.0837',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nIndexing Reverse Top-k Queries',
	 'urllink': u'http://arxiv.org/abs/1205.0837'}
2015-03-23 22:34:13+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0135> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:34:13+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0135>
	{'abstract': u'We consider the problem of devising incentive strategies for viral marketing of a product. In particular, we assume that the seller can influence penetration of the product by offering two incentive programs: a) direct incentives to potential buyers (influence) and b) referral rewards for customers who influence potential buyers to make the purchase (exploit connections). The problem is to determine the optimal timing of these programs over a finite time horizon. In contrast to algorithmic perspective popular in the literature, we take a mean-field approach and formulate the problem as a continuous-time deterministic optimal control problem. We show that the optimal strategy for the seller has a simple structure and can take both forms, namely, influence-and-exploit and exploit-and-influence. We also show that in some cases it may optimal for the seller to deploy incentive programs mostly for low degree nodes. We support our theoretical results through numerical studies and provide practical insights by analyzing various scenarios.',
	 'authors': u'Pankaj Dayama, Aditya Karnik, Y. Narahari,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0135',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nOptimal Mix of Incentive Strategies for Product Marketing on Social  Networks',
	 'urllink': u'http://arxiv.org/abs/1203.0135'}
2015-03-23 22:34:20+0000 [xxu46_4] INFO: Crawled 170 pages (at 4 pages/min), scraped 164 items (at 4 items/min)
2015-03-23 22:34:20+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0258> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:34:20+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0258>
	{'abstract': u"This paper presents the steps involved in creating an electronic lexical knowledge base from the 1987 Penguin edition of Roget's Thesaurus. Semantic relations are labelled with the help of WordNet. The two resources are compared in a qualitative and quantitative manner. Differences in the organization of the lexical material are discussed, as well as the possibility of merging both resources.",
	 'authors': u'Mario Jarmasz, Stan Szpakowicz,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0258',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u"\nRoget's Thesaurus: a Lexical Resource to Treasure",
	 'urllink': u'http://arxiv.org/abs/1204.0258'}
2015-03-23 22:34:37+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0835> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:34:37+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0835>
	{'abstract': u'We consider the problem of optimal distributed beamforming in a sensor network where the sensors observe a dynamic parameter in noise and coherently amplify and forward their observations to a fusion center (FC). The FC uses a Kalman filter to track the parameter using the observations from the sensors, and we show how to find the optimal gain and phase of the sensor transmissions under both global and individual power constraints in order to minimize the mean squared error (MSE) of the parameter estimate. For the case of a global power constraint, a closed-form solution can be obtained. A numerical optimization is required for individual power constraints, but the problem can be relaxed to a semidefinite programming problem (SDP), and we show how the optimal solution can be constructed from the solution to the SDP. Simulation results show that compared with equal power transmission, the use of optimized power control can significantly reduce the MSE.',
	 'authors': u'Feng Jiang, Jie Chen, A. Lee Swindlehurst,',
	 'category': u'Computer Science ',
	 'date': '2012-5-3',
	 'pdflink': u'http://arxiv.org/pdf/1205.0835',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nParameter Tracking via Optimal Distributed Beamforming in an Analog  Sensor Network',
	 'urllink': u'http://arxiv.org/abs/1205.0835'}
2015-03-23 22:34:55+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0120> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:34:55+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0120>
	{'abstract': u'The present paper examines the behavior of Shift-insertion sort (insertion sort with shifting) for normal distribution inputs and is in continuation of our earlier work on this new algorithm for discrete distribution inputs, namely, negative binomial. Shift insertion sort is found more sensitive for main effects but not for all interaction effects compared to conventional insertion sort.',
	 'authors': u'Mita Pal, Soubhik Chakraborty, N.C. Mahanti,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0120',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nHow does the Shift-insertion sort behave when the sorting elements  follow a Normal distribution?',
	 'urllink': u'http://arxiv.org/abs/1203.0120'}
2015-03-23 22:35:08+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0257> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:35:08+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0257>
	{'abstract': u"Morris and Hirst present a method of linking significant words that are about the same topic. The resulting lexical chains are a means of identifying cohesive regions in a text, with applications in many natural language processing tasks, including text summarization. The first lexical chains were constructed manually using Roget's International Thesaurus. Morris and Hirst wrote that automation would be straightforward given an electronic thesaurus. All applications so far have used WordNet to produce lexical chains, perhaps because adequate electronic versions of Roget's were not available until recently. We discuss the building of lexical chains using an electronic version of Roget's Thesaurus. We implement a variant of the original algorithm, and explain the necessary design decisions. We include a comparison with other implementations.",
	 'authors': u'Mario Jarmasz, Stan Szpakowicz,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0257',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u"\nNot As Easy As It Seems: Automating the Construction of Lexical Chains  Using Roget's Thesaurus",
	 'urllink': u'http://arxiv.org/abs/1204.0257'}
2015-03-23 22:35:20+0000 [xxu46_4] INFO: Crawled 174 pages (at 4 pages/min), scraped 168 items (at 4 items/min)
2015-03-23 22:35:21+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0831> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:35:21+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0831>
	{'abstract': u'World Health Organization reports that African Trypanosomiasis affects mostly poor populations living in remote rural areas of Africa that can be fatal if properly not treated. This paper presents Dempster-Shafer Theory for the detection of African trypanosomiasis. Sustainable elimination of African trypanosomiasis as a public-health problem is feasible and requires continuous efforts and innovative approaches. In this research, we implement Dempster-Shafer theory for detecting African trypanosomiasis and displaying the result of detection process. We describe eleven symptoms as major symptoms which include fever, red urine, skin rash, paralysis, headache, bleeding around the bite, joint the paint, swollen lymph nodes, sleep disturbances, meningitis and arthritis. Dempster-Shafer theory to quantify the degree of belief, our approach uses Dempster-Shafer theory to combine beliefs under conditions of uncertainty and ignorance, and allows quantitative measurement of the belief and plausibility in our identification result.',
	 'authors': u'Andino Maseleno, Md. Mahmud Hasan,',
	 'category': u'Computer Science ',
	 'date': '2012-5-3',
	 'pdflink': u'http://arxiv.org/pdf/1205.0831',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nAfrican Trypanosomiasis Detection using Dempster-Shafer Theory',
	 'urllink': u'http://arxiv.org/abs/1205.0831'}
2015-03-23 22:35:34+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0115> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:35:34+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0115>
	{'abstract': u"Let T be Goedel's system of primitive recursive functionals of finite type in the lambda formulation. We define by constructive means using recursion on nested multisets a multivalued function I from the set of terms of T into the set of natural numbers such that if a term a reduces to a term b and if a natural number I(a) is assigned to a then a natural number I(b) can be assigned to b such that I(a) is greater than I(b). The construction of I is based on Howard's 1970 ordinal assignment for T and Weiermann's 1996 treatment of T in the combinatory logic version. As a corollary we obtain an optimal derivation length classification for the lambda formulation of T and its fragments. Compared with Weiermann's 1996 exposition this article yields solutions to several non-trivial problems arising from dealing with lambda terms instead of combinatory logic terms. It is expected that the methods developed here can be applied to other higher order rewrite systems resulting in new powerful termination orderings since T is a paradigm for such systems.",
	 'authors': u'Gunnar Wilken, Andreas Weiermann,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0115',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u"\nDerivation Lengths Classification of G\xf6del's T Extending Howard's  Assignment",
	 'urllink': u'http://arxiv.org/abs/1203.0115'}
2015-03-23 22:35:44+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0255> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:35:44+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0255>
	{'abstract': u'This paper proposes some modest improvements to Extractor, a state-of-the-art keyphrase extraction system, by using a terabyte-sized corpus to estimate the informativeness and semantic similarity of keyphrases. We present two techniques to improve the organization and remove outliers of lists of keyphrases. The first is a simple ordering according to their occurrences in the corpus; the second is clustering according to semantic similarity. Evaluation issues are discussed. We present a novel technique of comparing extracted keyphrases to a gold standard which relies on semantic similarity rather than string matching or an evaluation involving human judges.',
	 'authors': u'Mario Jarmasz, Caroline Barri\xe8re,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0255',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nKeyphrase Extraction : Enhancing Lists',
	 'urllink': u'http://arxiv.org/abs/1204.0255'}
2015-03-23 22:36:00+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0820> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:36:00+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0820>
	{'abstract': u'Multihomed services can load-balance their incoming connection requests using DNS, resolving the name of the server with different addresses depending on the link load that corresponds to each address. Previous work has studied a number of problems with this approach, e.g., due to Time-to-Live duration violations and client proximity to local DNS servers. In this paper, we experimentally evaluate a DNS-based ingress traffic engineering system that we deployed at Georgia Tech. Our objective is to understand whether simple and robust load balancing algorithms can be accurate in practice, despite aforementioned problems with DNS-based load balancing methods. In particular, we examine the impact of various system parameters and of the main workload characteristics. We show that a window-based measurement scheme can be fairly accurate in practice, as long as its window duration has been appropriately configured.',
	 'authors': u'Partha Kanuparthy, Warren Matthews, Constantine Dovrolis,',
	 'category': u'Computer Science ',
	 'date': '2012-5-3',
	 'pdflink': u'http://arxiv.org/pdf/1205.0820',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nDNS-based Ingress Load Balancing: An Experimental Evaluation',
	 'urllink': u'http://arxiv.org/abs/1205.0820'}
2015-03-23 22:36:17+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0113> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:36:17+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0113>
	{'abstract': u'In this paper, we study some decision problems both for and . We first show that given a -letter quantum finite automaton and a -letter quantum finite automaton over the same input alphabet , they are equivalent if and only if they are -equivalent where , , are the number of states in respectively, and . By applying a method, due to the author, used to deal with the equivalence problem of , we also show that a -letter measure many quantum finite automaton and a -letter measure many quantum finite automaton are equivalent if and only if they are -equivalent where , , are the number of states in respectively, and . Next, we study the emptiness problem of those two kinds of quantum finite automata. We show that whether the language recognized by a -letter quantum finite automaton with non-strict cut-point is empty is undecidable, but we leave open the emptiness of language reorganized by a -letter quantum finite automaton with strict cutpoint. We also show that whether the languages recognized by a -letter measure many quantum finite automaton with both nonstrict and strict cutpoints are undecidable. And the direct consequences of the above outcomes are summarized in the paper.',
	 'authors': u'Tianrong Lin,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0113',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nOn equivalence and emptiness problems of multi-letter (measure many)  quantum finite automata',
	 'urllink': u'http://arxiv.org/abs/1203.0113'}
2015-03-23 22:36:20+0000 [xxu46_4] INFO: Crawled 179 pages (at 5 pages/min), scraped 173 items (at 5 items/min)
2015-03-23 22:36:35+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0245> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:36:35+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0245>
	{'abstract': u"We have implemented a system that measures semantic similarity using a computerized 1987 Roget's Thesaurus, and evaluated it by performing a few typical tests. We compare the results of these tests with those produced by WordNet-based similarity measures. One of the benchmarks is Miller and Charles' list of 30 noun pairs to which human judges had assigned similarity measures. We correlate these measures with those computed by several NLP systems. The 30 pairs can be traced back to Rubenstein and Goodenough's 65 pairs, which we have also studied. Our Roget's-based system gets correlations of .878 for the smaller and .818 for the larger list of noun pairs; this is quite close to the .885 that Resnik obtained when he employed humans to replicate the Miller and Charles experiment. We further evaluate our measure by using Roget's and WordNet to answer 80 TOEFL, 50 ESL and 300 Reader's Digest questions: the correct synonym must be selected amongst a group of four words. Our system gets 78.75%, 82.00% and 74.33% of the questions respectively.",
	 'authors': u'Mario Jarmasz, Stan Szpakowicz,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0245',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u"\nRoget's Thesaurus and Semantic Similarity",
	 'urllink': u'http://arxiv.org/abs/1204.0245'}
2015-03-23 22:36:46+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0792> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:36:46+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0792>
	{'abstract': u'We develop an exact wavelet transform on the three-dimensional ball (i.e. on the solid sphere), which we name the flaglet transform. For this purpose we first construct an exact transform on the radial half-line using damped Laguerre polynomials and develop a corresponding quadrature rule. Combined with the spherical harmonic transform, this approach leads to a sampling theorem on the ball and a novel three-dimensional decomposition which we call the Fourier-Laguerre transform. We relate this new transform to the well-known Fourier-Bessel decomposition and show that band-limitedness in the Fourier-Laguerre basis is a sufficient condition to compute the Fourier-Bessel decomposition exactly. We then construct the flaglet transform on the ball through a harmonic tiling, which is exact thanks to the exactness of the Fourier-Laguerre transform (from which the name flaglets is coined). The corresponding wavelet kernels are well localised in real and Fourier-Laguerre spaces and their angular aperture is invariant under radial translation. We introduce a multiresolution algorithm to perform the flaglet transform rapidly, while capturing all information at each wavelet scale in the minimal number of samples on the ball. Our implementation of these new tools achieves floating-point precision and is made publicly available. We perform numerical experiments demonstrating the speed and accuracy of these libraries and illustrate their capabilities on a simple denoising example.',
	 'authors': u'B. Leistedt, J. D. McEwen,',
	 'category': u'Computer Science ',
	 'date': '2012-5-3',
	 'pdflink': u'http://arxiv.org/pdf/1205.0792',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nExact Wavelets on the Ball',
	 'urllink': u'http://arxiv.org/abs/1205.0792'}
2015-03-23 22:37:03+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0103> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:37:03+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0103>
	{'abstract': u'Computability logic (see this http URL ) is a long-term project for redeveloping logic on the basis of a constructive game semantics, with games seen as abstract models of interactive computational problems. Among the fragments of this logic successfully axiomatized so far is CL12 --- a conservative extension of classical first-order logic, whose language augments that of classical logic with the so called choice sorts of quantifiers and connectives. This system has already found fruitful applications as a logical basis for constructive and complexity-oriented versions of Peano arithmetic, such as arithmetics for polynomial time computability, polynomial space computability, and beyond. The present paper introduces a third, indispensable complexity measure for interactive computations termed amplitude complexity, and establishes the adequacy of CL12 with respect to A-amplitude, S-space and T-time computability under certain minimal conditions on the triples (A,S,T) of function classes. This result very substantially broadens the potential application areas of CL12. The paper is self-contained, and targets readers with no prior familiarity with the subject.',
	 'authors': u'Giorgi Japaridze,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0103',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nOn the system CL12 of computability logic',
	 'urllink': u'http://arxiv.org/abs/1203.0103'}
2015-03-23 22:37:20+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0240> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:37:20+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0240>
	{'abstract': u"Actually Information security becomes a very important part for the organization's intangible assets, so level of confidence and stakeholder trusted are performance indicator as successes organization. Since information security has a very important role in supporting the activities of the organization, we need a standard or benchmark which regulates governance over information security. The main objective of this paper is to implement a novel practical approach framework to the development of information security management system (ISMS) assessment and monitoring software, called by I-SolFramework. System / software is expected to assist stakeholders in assessing the level of their ISO27001 compliance readiness, the software could help stakeholders understood security control or called by compliance parameters, being shorter and more structured. The case study illustrated provided to the reader with a set of guidelines, that aims easy understood and applicable as measuring tools for ISMS standards (ISO27001) compliance.",
	 'authors': u'Heru Susanto, Mohammad Nabil Almunawar, Yong Chee Tuan, Mehmet Sabih Aksoy, Wahyudin P Syam,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0240',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nIntegrated Solution Modeling Software: A New Paradigm on Information  Security Review',
	 'urllink': u'http://arxiv.org/abs/1204.0240'}
2015-03-23 22:37:20+0000 [xxu46_4] INFO: Crawled 183 pages (at 4 pages/min), scraped 177 items (at 4 items/min)
2015-03-23 22:37:36+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0790> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:37:36+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0790>
	{'abstract': u'An approach for incorporating embedded simulation and analysis capabilities in complex simulation codes through template-based generic programming is presented. This approach relies on templating and operator overloading within the C++ language to transform a given calculation into one that can compute a variety of additional quantities that are necessary for many state-of-the-art simulation and analysis algorithms. An approach for incorporating these ideas into complex simulation codes through general graph-based assembly is also presented. These ideas have been implemented within a set of packages in the Trilinos framework and are demonstrated on a simple problem from chemical engineering.',
	 'authors': u'Roger P. Pawlowski, Eric T. Phipps, Andrew G. Salinger,',
	 'category': u'Computer Science ',
	 'date': '2012-5-3',
	 'pdflink': u'http://arxiv.org/pdf/1205.0790',
	 'subjects': u'Mathematical Software (cs.MS)',
	 'title': u'\nAutomating embedded analysis capabilities and managing software  complexity in multiphysics simulation part I: template-based generic  programming',
	 'urllink': u'http://arxiv.org/abs/1205.0790'}
2015-03-23 22:37:45+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0100> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:37:45+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0100>
	{'abstract': u'We examine the history of cake cutting mechanisms and discuss the efficiency of their allocations. In the case of piecewise uniform preferences, we define a game that in the presence of strategic agents has equilibria that are not dominated by the allocations of any mechanism. We identify that the equilibria of this game coincide with the allocations of an existing cake cutting mechanism.',
	 'authors': u'Egor Ianovski,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0100',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nCake Cutting Mechanisms',
	 'urllink': u'http://arxiv.org/abs/1203.0100'}
2015-03-23 22:37:58+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0232> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:37:58+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0232>
	{'abstract': u"Today's PCs can directly manipulate numbers not longer than 64 bits because the size of the CPU registers and the data-path are limited. Consequently, arithmetic operations such as addition, can only be performed on numbers of that length. To solve the problem of computation on big-integer numbers, different algorithms were developed. However, these algorithms are considerably slow because they operate on individual bits; and are only designed to run over single-processor computers. In this paper, two algorithms for handling arithmetic addition on big-integer numbers are presented. The first algorithm is sequential while the second is parallel. Both algorithms, unlike existing ones, perform addition on blocks or tokens of 60 bits (18 digits), and thus boosting the execution time by a factor of 60.",
	 'authors': u'Youssef Bassil, Aziz Barbar,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0232',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nSequential and Parallel Algorithms for the Addition of Big-Integer  Numbers',
	 'urllink': u'http://arxiv.org/abs/1204.0232'}
2015-03-23 22:38:06+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0751> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:38:06+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0751>
	{'abstract': u"The current software development tools show the same form of interaction as when they started back, in the mid 70's. However, since the appearance of visual languages and due to their own nature, they can be handled by tools which have different input methods to conventional ones. By incorporating new motion detection technology, it is intended that new forms of interaction are established. Interactions which respond to the free movement of hands, therefore the software's developer will have a substantial improvement in the user experience.",
	 'authors': u'Carlos Alberto Fernandez-y-Fernandez, Jose Angel Quintanar,',
	 'category': u'Computer Science ',
	 'date': '2012-5-3',
	 'pdflink': u'http://arxiv.org/pdf/1205.0751',
	 'subjects': u'Human-Computer Interaction (cs.HC)',
	 'title': u'\nIntegrated Development Environment Gesture for modeling workflow  diagrams',
	 'urllink': u'http://arxiv.org/abs/1205.0751'}
2015-03-23 22:38:20+0000 [xxu46_4] INFO: Crawled 187 pages (at 4 pages/min), scraped 181 items (at 4 items/min)
2015-03-23 22:38:21+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0096> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:38:21+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0096>
	{'abstract': u'We propose a novel technique for joint estimation of angle and delay of radio wave arrival in a multipath mobile communication channel using knowledge of the transmitted pulse shape function. Employing an array of sensors to sample the radio received signal, and subsequent array signal processing can provide the characterization of a high-rank channel in terms of the multipath angles of arrival and time delays. Although several works have been reported in the literature for estimation of the high-rank channel parameters, we are not aware of any work that deals with the problem of estimation in a fading channel, which essentially leads to a multiplicative noise environment.',
	 'authors': u'Pradip Sircar,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0096',
	 'subjects': u'Computational Engineering, Finance, and Science (cs.CE)',
	 'title': u'\nJoint Estimation of Angle and Delay of Radio Wave Arrival under  Multiplicative Noise Environment',
	 'urllink': u'http://arxiv.org/abs/1203.0096'}
2015-03-23 22:38:38+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0225> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:38:38+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0225>
	{'abstract': u"The paper presents a simulation on automotive inventory and stock issue, followed by evaluated performance of automotif Sector Company, focused on getting optimum profit from supply and demand balancing. Starting by evaluating and verification of customer's document until car delivered to customer. Simulation method of performance is used to evaluate company activity. excess demand of car by customer, not eligible customer to rented a car, number of customer who served and number of customer who served including the driver, the last result is number of optimum demand that match with the stock or supply of car by the company. Finally, board of management should be making decision; the first decision is buy the new car for meet with the demand or second decision is recruit new staff for increasing customer service or customer care.",
	 'authors': u'Heru Susanto, Mohammad Nabil Almunawar, Mehmet Sabih Aksoy, Yong Chee Tuan,',
	 'category': u'Computer Science ',
	 'date': '2012-3-28',
	 'pdflink': u'http://arxiv.org/pdf/1204.0225',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nA Simulation Approach Paradigm: An Optimization and Inventory Challenge  Case Study',
	 'urllink': u'http://arxiv.org/abs/1204.0225'}
2015-03-23 22:38:53+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0750> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:38:53+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0750>
	{'abstract': u'This paper presents our proposal for the evolution of the metamodel for the Task Algebra in the Task Flow model for the Discovery Method. The original Task Algebra is based on simple and compound tasks structured using operators such as sequence, selection, and parallel composition. Recursion and encapsulation were also considered. We propose additional characteristics to improve the capabilities of the metamodel to represent accurately the Task Flow Model.',
	 'authors': u'Carlos Alberto Fernandez-y-Fernandez,',
	 'category': u'Computer Science ',
	 'date': '2012-5-3',
	 'pdflink': u'http://arxiv.org/pdf/1205.0750',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nTowards a new metamodel for the Task Flow Model of the Discovery Method',
	 'urllink': u'http://arxiv.org/abs/1205.0750'}
2015-03-23 22:39:02+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0088> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:39:02+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0088>
	{'abstract': u'There is a vast supply of prior art that study models for mental processes. Some studies in psychology and philosophy approach it from an inner perspective in terms of experiences and percepts. Others such as neurobiology or connectionist-machines approach it externally by viewing the mind as complex circuit of neurons where each neuron is a primitive binary circuit. In this paper, we also model the mind as a place where a circuit grows, starting as a collection of primitive components at birth and then builds up incrementally in a bottom up fashion. A new node is formed by a simple composition of prior nodes when we undergo a repeated experience that can be described by that composition. Unlike neural networks, however, these circuits take "concepts" or "percepts" as inputs and outputs. Thus the growing circuits can be likened to a growing collection of lambda expressions that are built on top of one another in an attempt to compress the sensory input as a heuristic to bound its Kolmogorov Complexity.',
	 'authors': u'Rina Panigrahy, Li Zhang,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0088',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nThe Mind Grows Circuits',
	 'urllink': u'http://arxiv.org/abs/1203.0088'}
2015-03-23 22:39:14+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0221> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:39:14+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0221>
	{'abstract': u'Modern computer programming languages are governed by complex syntactic rules. They are unlike natural languages; they require extensive manual work and a significant amount of learning and practicing for an individual to become skilled at and to write correct programs. Computer programming is a difficult, complicated, unfamiliar, non-automated, and a challenging discipline for everyone; especially, for students, new programmers and end-users. This paper proposes a new programming language and an environment for writing computer applications based on source-code generation. It is mainly a template-driven automatic natural imperative programming language called MyProLang. It harnesses GUI templates to generate proprietary natural language source-code, instead of having computer programmers write the code manually. MyProLang is a blend of five elements. A proprietary natural programming language with unsophisticated grammatical rules and expressive syntax; automation templates that automate the generation of instructions and thereby minimizing the learning and training time; an NLG engine to generate natural instructions; a source-to-source compiler that analyzes, parses, and build executables; and an ergonomic IDE that houses diverse functions whose role is to simplify the software development process. MyProLang is expected to make programming open to everyone including students, programmers and end-users. In that sense, anyone can start programming systematically, in an automated manner and in natural language; without wasting time in learning how to formulate instructions and arrange expressions, without putting up with unfamiliar structures and symbols, and without being annoyed by syntax errors. In the long run, this increases the productivity, quality and time-to-market in software development.',
	 'authors': u'Youssef Bassil, Aziz Barbar,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0221',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nMyProLang - My Programming Language: A Template-Driven Automatic Natural  Programming Language',
	 'urllink': u'http://arxiv.org/abs/1204.0221'}
2015-03-23 22:39:20+0000 [xxu46_4] INFO: Crawled 192 pages (at 5 pages/min), scraped 186 items (at 5 items/min)
2015-03-23 22:39:24+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0732> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:39:24+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0732>
	{'abstract': u'The capability of discretization of matrix elements in the problem of quadratic functional minimization with linear member built on matrix in N-dimensional configuration space with discrete coordinates is researched. It is shown, that optimal procedure of replacement matrix elements by the integer quantities with the limited number of gradations exist, and the efficient of minimization does not reduce. Parameter depends on matrix properties, which allows estimate the capability of using described procedure for given type of matrix, is found. Computational complexities of algorithm and RAM requirements are reduced by 16 times, correct using of integer elements allows increase minimization algorithm speed by the orders.',
	 'authors': u'Boris Kryzhanovsky, Mikhail Kryzhanovsky, Magomed Malsagov,',
	 'category': u'Computer Science ',
	 'date': '2012-5-3',
	 'pdflink': u'http://arxiv.org/pdf/1205.0732',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nDiscretization of a matrix in the problem of quadratic functional binary  minimization',
	 'urllink': u'http://arxiv.org/abs/1205.0732'}
2015-03-23 22:39:41+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0077> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:39:41+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0077>
	{'abstract': u'A well-established and fundamental insight in database theory is that negation (also known as complementation) tends to make queries difficult to process and difficult to reason about. Many basic problems are decidable and admit practical algorithms in the case of unions of conjunctive queries, but become difficult or even undecidable when queries are allowed to contain negation. Inspired by recent results in finite model theory, we consider a restricted form of negation, guarded negation. We introduce a fragment of SQL, called GN-SQL, as well as a fragment of Datalog with stratified negation, called GN-Datalog, that allow only guarded negation, and we show that these query languages are computationally well behaved, in terms of testing query containment, query evaluation, open-world query answering, and boundedness. GN-SQL and GN-Datalog subsume a number of well known query languages and constraint languages, such as unions of conjunctive queries, monadic Datalog, and frontier-guarded tgds. In addition, an analysis of standard benchmark workloads shows that most usage of negation in SQL in practice is guarded negation.',
	 'authors': u'Vince Barany, Balder ten Cate, Martin Otto,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0077',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nQueries with Guarded Negation (full version)',
	 'urllink': u'http://arxiv.org/abs/1203.0077'}
2015-03-23 22:39:58+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0220> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:39:58+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0220>
	{'abstract': u'Many emerging computer applications require the processing of large numbers, larger than what a CPU can handle. In fact, the top of the line PCs can only manipulate numbers not longer than 32 bits or 64 bits. This is due to the size of the registers and the data-path inside the CPU. As a result, performing arithmetic operations such as subtraction on big-integer numbers is to some extend limited. Different algorithms were designed in an attempt to solve this problem; they all operate on big-integer numbers by first converting them into a binary representation then performing bitwise operations on single bits. Such algorithms are of complexity O(n) where n is the total number of bits in each operand. This paper proposes two new algorithms for performing arithmetic subtraction on big-integer numbers. The two algorithms are different in that one is sequential while the other is parallel. The similarity between them is that both follow the same concept of dividing the big-integer inputs into several blocks or tokens of 60 bits (18 digits) each; thus reducing the input size n in O(n) by a factor of 60. Subtraction of corresponding tokens, one from each operand, is performed as humans perform subtraction, using a pencil and a paper in the decimal system. Both algorithms are to be implemented using MS C#.NET 2005 and tested over a multiple processor system. Further studies can be done on other arithmetic operations such as addition and multiplication.',
	 'authors': u'Youssef Bassil, Aziz Barbar,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0220',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nSequential & Parallel Algorithms for Big-Integer Numbers Subtraction',
	 'urllink': u'http://arxiv.org/abs/1204.0220'}
2015-03-23 22:40:16+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0731> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:40:16+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0731>
	{'abstract': u"In 1998, Reed conjectured that for any graph , , where , , and respectively denote the chromatic number, the clique number and the maximum degree of . In this paper, we study this conjecture for some expansions of graphs, that is graphs obtained with the well known operation composition of graphs. We prove that Reed's Conjecture holds for expansions of bipartite graphs, for expansions of odd holes where the minimum chromatic number of the components is even, when some component of the expansion has chromatic number 1 or when a component induces a bipartite graph. Moreover, Reed's Conjecture holds if all components have the same chromatic number, if the components have chromatic number at most 4 and when the odd hole has length 5. Finally, when is an odd hole expansion, we prove .",
	 'authors': u'Jean-Luc Fouquet, Jean-Marie Vanherpe,',
	 'category': u'Computer Science ',
	 'date': '2012-5-3',
	 'pdflink': u'http://arxiv.org/pdf/1205.0731',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u"\nReed's Conjecture on hole expansions",
	 'urllink': u'http://arxiv.org/abs/1205.0731'}
2015-03-23 22:40:20+0000 [xxu46_4] INFO: Crawled 196 pages (at 4 pages/min), scraped 190 items (at 4 items/min)
2015-03-23 22:40:33+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0076> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:40:33+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0076>
	{'abstract': u'3D motion tracking is a critical task in many computer vision applications. Unsupervised markerless 3D motion tracking systems determine the most relevant object in the screen and then track it by continuously estimating its projection features (center and area) from the edge image and a point inside the relevant object projection (namely, inner point), until the tracking fails. Existing reliable object projection feature estimation techniques are based on ray-casting or grid-filling from the inner point. These techniques assume the edge image to be accurate. However, in real case scenarios, edge miscalculations may arise from low contrast between the target object and its surroundings or motion blur caused by low frame rates or fast moving target objects. In this paper, we propose a barrier extension to casting-based techniques that mitigates the effect of edge miscalculations.',
	 'authors': u'Luis Quesada,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0076',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nUsing Barriers to Reduce the Sensitivity to Edge Miscalculations of  Casting-Based Object Projection Feature Estimation',
	 'urllink': u'http://arxiv.org/abs/1203.0076'}
2015-03-23 22:40:51+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0219> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:40:51+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0219>
	{'abstract': u"An instance of the maximum mixed graph orientation problem consists of a mixed graph and a collection of source-target vertex pairs. The objective is to orient the undirected edges of the graph so as to maximize the number of pairs that admit a directed source-target path. This problem has recently arisen in the study of biological networks, and it also has applications in communication networks. In this paper, we identify an interesting local-to-global orientation property. This property enables us to modify the best known algorithms for maximum mixed graph orientation and some of its special structured instances, due to Elberfeld et al. (CPM '11), and obtain improved approximation ratios. We further proceed by developing an algorithm that achieves an even better approximation guarantee for the general setting of the problem. Finally, we study several well-motivated variants of this orientation problem.",
	 'authors': u'Iftah Gamzu, Moti Medina,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0219',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nImproved Approximation for Orienting Mixed Graphs',
	 'urllink': u'http://arxiv.org/abs/1204.0219'}
2015-03-23 22:41:06+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0730> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:41:06+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0730>
	{'abstract': u'Reed conjectured that for any graph , , where , , and respectively denote the chromatic number, the clique number and the maximum degree of . In this paper, we verify this conjecture for some special classes of graphs, in particular for subclasses of -free graphs or -free graphs.',
	 'authors': u'Jean-Luc Fouquet, Jean-Marie Vanherpe,',
	 'category': u'Computer Science ',
	 'date': '2012-5-3',
	 'pdflink': u'http://arxiv.org/pdf/1205.0730',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u"\nReed's conjecture on some special classes of graphs",
	 'urllink': u'http://arxiv.org/abs/1205.0730'}
2015-03-23 22:41:20+0000 [xxu46_4] INFO: Crawled 199 pages (at 3 pages/min), scraped 193 items (at 3 items/min)
2015-03-23 22:41:22+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0061> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:41:22+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0061>
	{'abstract': u'Analyzing large scale data has emerged as an important activity for many organizations in the past few years. This large scale data analysis is facilitated by the MapReduce programming and execution model and its implementations, most notably Hadoop. Users of MapReduce often have analysis tasks that are too complex to express as individual MapReduce jobs. Instead, they use high-level query languages such as Pig, Hive, or Jaql to express their complex tasks. The compilers of these languages translate queries into workflows of MapReduce jobs. Each job in these workflows reads its input from the distributed file system used by the MapReduce system and produces output that is stored in this distributed file system and read as input by the next job in the workflow. The current practice is to delete these intermediate results from the distributed file system at the end of executing the workflow. One way to improve the performance of workflows of MapReduce jobs is to keep these intermediate results and reuse them for future workflows submitted to the system. In this paper, we present ReStore, a system that manages the storage and reuse of such intermediate results. ReStore can reuse the output of whole MapReduce jobs that are part of a workflow, and it can also create additional reuse opportunities by materializing and storing the output of query execution operators that are executed within a MapReduce job. We have implemented ReStore as an extension to the Pig dataflow system on top of Hadoop, and we experimentally demonstrate significant speedups on queries from the PigMix benchmark.',
	 'authors': u'Iman Elghandour, Ashraf Aboulnaga,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0061',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nReStore: Reusing Results of MapReduce Jobs',
	 'urllink': u'http://arxiv.org/abs/1203.0061'}
2015-03-23 22:41:36+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0199> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:41:36+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0199>
	{'abstract': u'In this paper, we propose a two-timescale delay-optimal base station Discontinuous Transmission (BS-DTX) control and user scheduling for downlink coordinated MIMO systems with energy harvesting capability. To reduce the complexity and signaling overhead in practical systems, the BS-DTX control is adaptive to both the energy state information (ESI) and the data queue state information (QSI) over a longer timescale. The user scheduling is adaptive to the ESI, the QSI and the channel state information (CSI) over a shorter timescale. We show that the two-timescale delay-optimal control problem can be modeled as an infinite horizon average cost Partially Observed Markov Decision Problem (POMDP), which is well-known to be a difficult problem in general. By using sample-path analysis and exploiting specific problem structure, we first obtain some structural results on the optimal control policy and derive an equivalent Bellman equation with reduced state space. To reduce the complexity and facilitate distributed implementation, we obtain a delay-aware distributed solution with the BS-DTX control at the BS controller (BSC) and the user scheduling at each cluster manager (CM) using approximate dynamic programming and distributed stochastic learning. We show that the proposed distributed two-timescale algorithm converges almost surely. Furthermore, using queueing theory, stochastic geometry and optimization techniques, we derive sufficient conditions for the data queues to be stable in the coordinated MIMO network and discuss various design insights.',
	 'authors': u'Ying Cui, Vincent K. N. Lau, Yueping Wu,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0199',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nDelay-aware BS Discontinuous Transmission Control and User Scheduling  for Energy Harvesting Downlink Coordinated MIMO Systems',
	 'urllink': u'http://arxiv.org/abs/1204.0199'}
2015-03-23 22:41:52+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0724> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:41:52+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0724>
	{'abstract': u"The data warehousing is becoming increasingly important in terms of strategic decision making through their capacity to integrate heterogeneous data from multiple information sources in a common storage space, for querying and analysis. So it can evolve into a multi-tier structure where parts of the organization take information from the main data warehouse into their own systems. These may include analysis databases or dependent data marts. As the data warehouse evolves and the organization gets better at capturing information on all interactions with the customer. Data warehouse can track customer interactions over the whole of the customer's lifetime.",
	 'authors': u'Phuc V. Nguyen,',
	 'category': u'Computer Science ',
	 'date': '2011-12-14',
	 'pdflink': u'http://arxiv.org/pdf/1205.0724',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nUsing Data Warehouse to Support Building Strategy or Forecast Business  Tend',
	 'urllink': u'http://arxiv.org/abs/1205.0724'}
2015-03-23 22:42:03+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0060> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:42:03+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0060>
	{'abstract': u'Recent years have witnessed an unprecedented proliferation of social media. People around the globe author, every day, millions of blog posts, social network status updates, etc. This rich stream of information can be used to identify, on an ongoing basis, emerging stories, and events that capture popular attention. Stories can be identified via groups of tightly-coupled real-world entities, namely the people, locations, products, etc., that are involved in the story. The sheer scale, and rapid evolution of the data involved necessitate highly efficient techniques for identifying important stories at every point of time. The main challenge in real-time story identification is the maintenance of dense subgraphs (corresponding to groups of tightly-coupled entities) under streaming edge weight updates (resulting from a stream of user-generated content). This is the first work to study the efficient maintenance of dense subgraphs under such streaming edge weight updates. For a wide range of definitions of density, we derive theoretical results regarding the magnitude of change that a single edge weight update can cause. Based on these, we propose a novel algorithm, DYNDENS, which outperforms adaptations of existing techniques to this setting, and yields meaningful results. Our approach is validated by a thorough experimental evaluation on large-scale real and synthetic datasets.',
	 'authors': u'Albert Angel, Nick Koudas, Nikos Sarkas, Divesh Srivastava,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0060',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nDense Subgraph Maintenance under Streaming Edge Weight Updates for  Real-time Story Identification',
	 'urllink': u'http://arxiv.org/abs/1203.0060'}
2015-03-23 22:42:19+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0197> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:42:19+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0197>
	{'abstract': u'Operating systems are vital system software that, without them, humans would not be able to manage and use computer systems. In essence, an operating system is a collection of software programs whose role is to manage computer resources and provide an interface for client applications to interact with the different computer hardware. Most of the commercial operating systems available today on the market have buggy code and they exhibit security flaws and vulnerabilities. In effect, building a trusted operating system that can mostly resist attacks and provide a secure computing environment to protect the important assets of a computer is the goal of every operating system manufacturer. This paper deeply investigates the various security features of the two most widespread and successful operating systems, Microsoft Windows and Linux. The different security features, designs, and components of the two systems are to be covered elaborately, pin-pointing the key similarities and differences between them. In due course, a head-to-head comparison is to be drawn for each security aspect, exposing the advantage of one system over the other.',
	 'authors': u'Youssef Bassil,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0197',
	 'subjects': u'Operating Systems (cs.OS)',
	 'title': u'\nWindows And Linux Operating Systems From A Security Perspective',
	 'urllink': u'http://arxiv.org/abs/1204.0197'}
2015-03-23 22:42:20+0000 [xxu46_4] INFO: Crawled 204 pages (at 5 pages/min), scraped 198 items (at 5 items/min)
2015-03-23 22:42:36+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0722> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:42:36+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0722>
	{'abstract': u"The subsumption problem with respect to terminologies in the description logic ALC is EXPTIME-complete. We investigate the computational complexity of fragments of this problem by means of allowed Boolean operators. Hereto we make use of the notion of clones in the context of Post's lattice. Furthermore we consider all four possible quantifier combinations for each fragment parameterized by a clone. We will see that depending on what quantifiers are available the classification will be either tripartite or a quartering.",
	 'authors': u'Arne Meier,',
	 'category': u'Computer Science ',
	 'date': '2012-5-3',
	 'pdflink': u'http://arxiv.org/pdf/1205.0722',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nGeneralized Complexity of ALC Subsumption',
	 'urllink': u'http://arxiv.org/abs/1205.0722'}
2015-03-23 22:42:48+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0059> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:42:48+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0059>
	{'abstract': u'Data-management-as-a-service systems are increasingly being used in collaborative settings, where multiple users access common datasets. Cloud providers have the choice to implement various optimizations, such as indexing or materialized views, to accelerate queries over these datasets. Each optimization carries a cost and may benefit multiple users. This creates a major challenge: how to select which optimizations to perform and how to share their cost among users. The problem is especially challenging when users are selfish and will only report their true values for different optimizations if doing so maximizes their utility. In this paper, we present a new approach for selecting and pricing shared optimizations by using Mechanism Design. We first show how to apply the Shapley Value Mechanism to the simple case of selecting and pricing additive optimizations, assuming an offline game where all users access the service for the same time-period. Second, we extend the approach to online scenarios where users come and go. Finally, we consider the case of substitutive optimizations. We show analytically that our mechanisms induce truth- fulness and recover the optimization costs. We also show experimentally that our mechanisms yield higher utility than the state-of-the-art approach based on regret accumulation.',
	 'authors': u'Prasang Upadhyaya, Magdalena Balazinska, Dan Suciu,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0059',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nHow to Price Shared Optimizations in the Cloud',
	 'urllink': u'http://arxiv.org/abs/1203.0059'}
2015-03-23 22:42:55+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0195> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:42:55+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0195>
	{'abstract': u"This paper defines the specifications of a management language intended to automate the control and administration of various service components connected to a digital ecosystem. It is called EML short for Ecosystem Management Language and it is based on proprietary syntax and notation and contains a set of managerial commands issued by the system's administrator via a command console. Additionally, EML is shipped with a collection of self-adaptation procedures called SAP. Their purpose is to provide self-adaptation properties to the ecosystem allowing it to self-optimize itself based on the state of its execution environment. On top of that, there exists the EMU short for Ecosystem Management Unit which interprets, validates, parses, and executes EML commands and SAP procedures. Future research can improve upon EML so much so that it can be extended to support a larger set of commands in addition to a larger set of SAP procedures.",
	 'authors': u'Youssef Bassil,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0195',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nManagement Language Specifications For Digital Ecosystems',
	 'urllink': u'http://arxiv.org/abs/1204.0195'}
2015-03-23 22:43:09+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0703> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:43:09+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0703>
	{'abstract': u'Design methods for paraunitary matrices from complete orthogonal sets of idempotents and related matrix structures are presented. These include techniques for designing non-separable multidimensional paraunitary matrices. Properties of the structures are obtained and proofs given. Paraunitary matrices play a central role in signal processing, in particular in the areas of filterbanks and wavelets.',
	 'authors': u'Barry Hurley, Ted Hurley,',
	 'category': u'Computer Science ',
	 'date': '2012-5-3',
	 'pdflink': u'http://arxiv.org/pdf/1205.0703',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nParaunitary Matrices',
	 'urllink': u'http://arxiv.org/abs/1205.0703'}
2015-03-23 22:43:20+0000 [xxu46_4] INFO: Crawled 208 pages (at 4 pages/min), scraped 202 items (at 4 items/min)
2015-03-23 22:43:24+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0058> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:43:24+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0058>
	{'abstract': u'In practical data integration systems, it is common for the data sources being integrated to provide conflicting information about the same entity. Consequently, a major challenge for data integration is to derive the most complete and accurate integrated records from diverse and sometimes conflicting sources. We term this challenge the truth finding problem. We observe that some sources are generally more reliable than others, and therefore a good model of source quality is the key to solving the truth finding problem. In this work, we propose a probabilistic graphical model that can automatically infer true records and source quality without any supervision. In contrast to previous methods, our principled approach leverages a generative process of two types of errors (false positive and false negative) by modeling two different aspects of source quality. In so doing, ours is also the first approach designed to merge multi-valued attribute types. Our method is scalable, due to an efficient sampling-based inference algorithm that needs very few iterations in practice and enjoys linear time complexity, with an even faster incremental variant. Experiments on two real world datasets show that our new method outperforms existing state-of-the-art approaches to the truth finding problem.',
	 'authors': u'Bo Zhao, Benjamin I. P. Rubinstein, Jim Gemmell, Jiawei Han,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0058',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nA Bayesian Approach to Discovering Truth from Conflicting Sources for  Data Integration',
	 'urllink': u'http://arxiv.org/abs/1203.0058'}
2015-03-23 22:43:39+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0193> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:43:39+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0193>
	{'abstract': u"Service-based IT infrastructures are today's trend and the future for every enterprise willing to support dynamic and agile business to contend with the ever changing e-demands and requirements. A digital ecosystem is an emerging business IT model for developing agile e-enterprises made out of self-adaptable, self-manageable, self-organizing, and sustainable service components. This paper defines the specifications of a communication language for exchanging data between connecting entities in digital ecosystems. It is called ECL short for Ecosystem Communication Language and is based on XML to format its request and response messages. An ECU short for Ecosystem Communication Unit is also presented which interprets, validates, parses ECL messages and routes them to their destination entities. ECL is open and provides transparent, portable, and interoperable communication between the different heterogeneous distributed components to send requests, and receive responses from each other, regardless of their incompatible protocols, standards, and technologies. As future research, digital signature for ECL is to be investigated so as to deliver data integrity as well as message authenticity for the digital ecosystem.",
	 'authors': u'Youssef Bassil,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0193',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nCommunication Language Specifications For Digital Ecosystems',
	 'urllink': u'http://arxiv.org/abs/1204.0193'}
2015-03-23 22:43:52+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0699> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:43:52+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0699>
	{'abstract': u'Multiple antenna (MIMO) devices are widely used to increase reliability and information bit rate. Optimal error rate performance (full diversity and large coding gain), for unknown channel state information at the transmitter and for maximal rate, can be achieved by approximately universal space-time codes, but comes at a price of large detection complexity, infeasible for most practical systems. We propose a new coded modulation paradigm: error-correction outer code with space-only but time-varying precoder (as inner code). We refer to the latter as Ergodic Mutual Information (EMI) code. The EMI code achieves the maximal multiplexing gain and full diversity is proved in terms of the outage probability. Contrary to most of the literature, our work is not based on the elegant but difficult classical algebraic MIMO theory. Instead, the relation between MIMO and parallel channels is exploited. The theoretical proof of full diversity is corroborated by means of numerical simulations for many MIMO scenarios, in terms of outage probability and word error rate of LDPC coded systems. The full-diversity and full-rate at low detection complexity comes at a price of a small coding gain loss for outer coding rates close to one, but this loss vanishes with decreasing coding rate.',
	 'authors': u'Dieter Duyck, Sheng Yang, Fambirai Takawira, Joseph J. Boutros, Marc Moeneclaey,',
	 'category': u'Computer Science ',
	 'date': '2012-5-3',
	 'pdflink': u'http://arxiv.org/pdf/1205.0699',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nTime-Varying Space-Only Codes for Coded MIMO',
	 'urllink': u'http://arxiv.org/abs/1205.0699'}
2015-03-23 22:44:03+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0057> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:44:03+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0057>
	{'abstract': u'By incorporating human workers into the query execution process crowd-enabled databases facilitate intelligent, social capabilities like completing missing data at query time or performing cognitive operators. But despite all their flexibility, crowd-enabled databases still maintain rigid schemas. In this paper, we extend crowd-enabled databases by flexible query-driven schema expansion, allowing the addition of new attributes to the database at query time. However, the number of crowd-sourced mini-tasks to fill in missing values may often be prohibitively large and the resulting data quality is doubtful. Instead of simple crowd-sourcing to obtain all values individually, we leverage the user-generated data found in the Social Web: By exploiting user ratings we build perceptual spaces, i.e., highly-compressed representations of opinions, impressions, and perceptions of large numbers of users. Using few training samples obtained by expert crowd sourcing, we then can extract all missing data automatically from the perceptual space with high quality and at low costs. Extensive experiments show that our approach can boost both performance and quality of crowd-enabled databases, while also providing the flexibility to expand schemas in a query-driven fashion.',
	 'authors': u'Joachim Selke, Christoph Lofi, Wolf-Tilo Balke,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0057',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nPushing the Boundaries of Crowd-enabled Databases with Query-driven  Schema Expansion',
	 'urllink': u'http://arxiv.org/abs/1203.0057'}
2015-03-23 22:44:16+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0191> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:44:16+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0191>
	{'abstract': u"With the advent of digital optical scanners, a lot of paper-based books, textbooks, magazines, articles, and documents are being transformed into an electronic version that can be manipulated by a computer. For this purpose, OCR, short for Optical Character Recognition was developed to translate scanned graphical text into editable computer text. Unfortunately, OCR is still imperfect as it occasionally mis-recognizes letters and falsely identifies scanned text, leading to misspellings and linguistics errors in the OCR output text. This paper proposes a post-processing context-based error correction algorithm for detecting and correcting OCR non-word and real-word errors. The proposed algorithm is based on Google's online spelling suggestion which harnesses an internal database containing a huge collection of terms and word sequences gathered from all over the web, convenient to suggest possible replacements for words that have been misspelled during the OCR process. Experiments carried out revealed a significant improvement in OCR error correction rate. Future research can improve upon the proposed algorithm so much so that it can be parallelized and executed over multiprocessing platforms.",
	 'authors': u'Youssef Bassil, Mohammad Alwani,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0191',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nOCR Post-Processing Error Correction Algorithm using Google Online  Spelling Suggestion',
	 'urllink': u'http://arxiv.org/abs/1204.0191'}
2015-03-23 22:44:20+0000 [xxu46_4] INFO: Crawled 213 pages (at 5 pages/min), scraped 207 items (at 5 items/min)
2015-03-23 22:44:27+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0680> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:44:27+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0680>
	{'abstract': u'Using the InCites tool of Thomson Reuters, this study compares normalized citation impact values calculated for China, Japan, France, Germany, United States, and the UK throughout the time period from 1981 to 2010. The citation impact values are normalized to four subject areas: natural sciences; engineering and technology; medical and health sciences; and agricultural sciences. The results show an increasing trend in citation impact values for France, the UK and especially for Germany across the last thirty years in all subject areas. The citation impact of papers from China is still at a relatively low level (mostly below the world average), but the country follows an increasing trend line. The USA exhibits a relatively stable pattern of high citation impact values across the years. With small impact differences between the publication years, the US trend is increasing in engineering and technology but decreasing in medical and health sciences as well as in agricultural sciences. Similar to the USA, Japan follows increasing as well as decreasing trends in different subject areas, but the variability across the years is small. In most of the years, papers from Japan perform below or approximately at the world average in each subject area.',
	 'authors': u'Lutz Bornmann, Loet Leydesdorff,',
	 'category': u'Computer Science ',
	 'date': '2012-5-3',
	 'pdflink': u'http://arxiv.org/pdf/1205.0680',
	 'subjects': u'Digital Libraries (cs.DL)',
	 'title': u'\nCitation impact of papers published from six prolific countries: A  national comparison based on InCites data',
	 'urllink': u'http://arxiv.org/abs/1205.0680'}
2015-03-23 22:44:38+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0056> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:44:38+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0056>
	{'abstract': u'Traditional database systems are built around the query-at-a-time model. This approach tries to optimize performance in a best-effort way. Unfortunately, best effort is not good enough for many modern applications. These applications require response time guarantees in high load situations. This paper describes the design of a new database architecture that is based on batching queries and shared computation across possibly hundreds of concurrent queries and updates. Performance experiments with the TPC-W benchmark show that the performance of our implementation, SharedDB, is indeed robust across a wide range of dynamic workloads.',
	 'authors': u'Georgios Giannikis, Gustavo Alonso, Donald Kossmann,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0056',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nSharedDB: Killing One Thousand Queries With One Stone',
	 'urllink': u'http://arxiv.org/abs/1203.0056'}
2015-03-23 22:44:49+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0188> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:44:49+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0188>
	{'abstract': u'Since the dawn of the computing era, information has been represented digitally so that it can be processed by electronic computers. Paper books and documents were abundant and widely being published at that time; and hence, there was a need to convert them into digital format. OCR, short for Optical Character Recognition was conceived to translate paper-based books into digital e-books. Regrettably, OCR systems are still erroneous and inaccurate as they produce misspellings in the recognized text, especially when the source document is of low printing quality. This paper proposes a post-processing OCR context-sensitive error correction method for detecting and correcting non-word and real-word OCR errors. The cornerstone of this proposed approach is the use of Google Web 1T 5-gram data set as a dictionary of words to spell-check OCR text. The Google data set incorporates a very large vocabulary and word statistics entirely reaped from the Internet, making it a reliable source to perform dictionary-based error correction. The core of the proposed solution is a combination of three algorithms: The error detection, candidate spellings generator, and error correction algorithms, which all exploit information extracted from Google Web 1T 5-gram data set. Experiments conducted on scanned images written in different languages showed a substantial improvement in the OCR error correction rate. As future developments, the proposed algorithm is to be parallelised so as to support parallel and distributed computing architectures.',
	 'authors': u'Youssef Bassil, Mohammad Alwani,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0188',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nOCR Context-Sensitive Error Correction Based on Google Web 1T 5-Gram  Data Set',
	 'urllink': u'http://arxiv.org/abs/1204.0188'}
2015-03-23 22:45:01+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0679> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:45:01+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0679>
	{'abstract': u'The existential k-pebble game characterizes the expressive power of the existential-positive k-variable fragment of first-order logic on finite structures. The winner of the existential k-pebble game on two given finite structures can be determined in time O(n2k) by dynamic programming on the graph of game configurations. We show that there is no O(n(k-3)/12)-time algorithm that decides which player can win the existential k-pebble game on two given structures. This lower bound is unconditional and does not rely on any complexity-theoretic assumptions. Establishing strong k-consistency is a well-known heuristic for solving the constraint satisfaction problem (CSP). By the game characterization of Kolaitis and Vardi our result implies that there is no O(n(k-3)/12)-time algorithm that decides if strong k-consistency can be established for a given CSP-instance.',
	 'authors': u'Christoph Berkholz,',
	 'category': u'Computer Science ',
	 'date': '2012-5-3',
	 'pdflink': u'http://arxiv.org/pdf/1205.0679',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nLower Bounds for Existential Pebble Games and k-Consistency Tests',
	 'urllink': u'http://arxiv.org/abs/1205.0679'}
2015-03-23 22:45:15+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0055> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:45:15+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0055>
	{'abstract': u"Modern business applications and scientific databases call for inherently dynamic data storage environments. Such environments are characterized by two challenging features: (a) they have little idle system time to devote on physical design; and (b) there is little, if any, a priori workload knowledge, while the query and data workload keeps changing dynamically. In such environments, traditional approaches to index building and maintenance cannot apply. Database cracking has been proposed as a solution that allows on-the-fly physical data reorganization, as a collateral effect of query processing. Cracking aims to continuously and automatically adapt indexes to the workload at hand, without human intervention. Indexes are built incrementally, adaptively, and on demand. Nevertheless, as we show, existing adaptive indexing methods fail to deliver workload-robustness; they perform much better with random workloads than with others. This frailty derives from the inelasticity with which these approaches interpret each query as a hint on how data should be stored. Current cracking schemes blindly reorganize the data within each query's range, even if that results into successive expensive operations with minimal indexing benefit. In this paper, we introduce stochastic cracking, a significantly more resilient approach to adaptive indexing. Stochastic cracking also uses each query as a hint on how to reorganize data, but not blindly so; it gains resilience and avoids performance bottlenecks by deliberately applying certain arbitrary choices in its decision-making. Thereby, we bring adaptive indexing forward to a mature formulation that confers the workload-robustness previous approaches lacked. Our extensive experimental study verifies that stochastic cracking maintains the desired properties of original database cracking while at the same time it performs well with diverse realistic workloads.",
	 'authors': u'Felix Halim, Stratos Idreos, Panagiotis Karras, Roland H. C. Yap,',
	 'category': u'Computer Science ',
	 'date': '2012-3-1',
	 'pdflink': u'http://arxiv.org/pdf/1203.0055',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nStochastic Database Cracking: Towards Robust Adaptive Indexing in  Main-Memory Column-Stores',
	 'urllink': u'http://arxiv.org/abs/1203.0055'}
2015-03-23 22:45:20+0000 [xxu46_4] INFO: Crawled 218 pages (at 5 pages/min), scraped 212 items (at 5 items/min)
2015-03-23 22:45:30+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0186> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:45:30+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0186>
	{'abstract': u'With the advent of the Internet, a new era of digital information exchange has begun. Currently, the Internet encompasses more than five billion online sites and this number is exponentially increasing every day. Fundamentally, Information Retrieval (IR) is the science and practice of storing documents and retrieving information from within these documents. Mathematically, IR systems are at the core based on a feature vector model coupled with a term weighting scheme that weights terms in a document according to their significance with respect to the context in which they appear. Practically, Vector Space Model (VSM), Term Frequency (TF), and Inverse Term Frequency (IDF) are among other long-established techniques employed in mainstream IR systems. However, present IR models only target generic-type text documents, in that, they do not consider specific formats of files such as HTML web documents. This paper proposes a new semantic-sensitive web information retrieval model for HTML documents. It consists of a vector model called SWVM and a weighting scheme called BTF-IDF, particularly designed to support the indexing and retrieval of HTML web documents. The chief advantage of the proposed model is that it assigns extra weights for terms that appear in certain pre-specified HTML tags that are correlated to the semantics of the document. Additionally, the model is semantic-sensitive as it generates synonyms for every term being indexed and later weights them appropriately to increase the likelihood of retrieving documents with similar context but different vocabulary terms. Experiments conducted, revealed a momentous enhancement in the precision of web IR systems and a radical increase in the number of relevant documents being retrieved. As further research, the proposed model is to be upgraded so as to support the indexing and retrieval of web images in multimedia-rich web documents.',
	 'authors': u'Youssef Bassil, Paul Semaan,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0186',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nSemantic-Sensitive Web Information Retrieval Model for HTML Documents',
	 'urllink': u'http://arxiv.org/abs/1204.0186'}
2015-03-23 22:45:46+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0668> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:45:46+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0668>
	{'abstract': u'Using the CD-ROM version of the Science Citation Index 2010 (N = 3,705 journals), we study the (combined) effects of (i) fractional counting on the impact factor (IF) and (ii) transformation of the skewed citation distributions into a distribution of 100 percentiles and six percentile rank classes (top-1%, top-5%, etc.). Do these approaches lead to field-normalized impact measures for journals? In addition to the two-year IF (IF2), we consider the five-year IF (IF5), the respective numerators of these IFs, and the number of Total Cites, counted both as integers and fractionally. These various indicators are tested against the hypothesis that the classification of journals into 11 broad fields by PatentBoard/National Science Foundation provides statistically significant between-field effects. Using fractional counting the between-field variance is reduced by 91.7% in the case of IF5, and by 79.2% in the case of IF2. However, the differences in citation counts are not significantly affected by fractional counting. These results accord with previous studies, but the longer citation window of a fractionally counted IF5 can lead to significant improvement in the normalization across fields.',
	 'authors': u'Loet Leydesdorff, Ping Zhou, Lutz Bornmann,',
	 'category': u'Computer Science ',
	 'date': '2012-5-3',
	 'pdflink': u'http://arxiv.org/pdf/1205.0668',
	 'subjects': u'Digital Libraries (cs.DL)',
	 'title': u'\nHow Can Journal Impact Factors be Normalized across Fields of Science?  An Assessment in terms of Percentile Ranks and Fractional Counts',
	 'urllink': u'http://arxiv.org/abs/1205.0668'}
2015-03-23 22:46:01+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0050> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:46:01+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0050>
	{'abstract': u'We present a new class of vertex cover and set cover games. The price of anarchy bounds match the best known constant factor approximation guarantees for the centralized optimization problems for linear and also for submodular costs -- in contrast to all previously studied covering games, where the price of anarchy cannot be bounded by a constant (e.g. [6, 7, 11, 5, 2]). In particular, we describe a vertex cover game with a price of anarchy of 2. The rules of the games capture the structure of the linear programming relaxations of the underlying optimization problems, and our bounds are established by analyzing these relaxations. Furthermore, for linear costs we exhibit linear time best response dynamics that converge to these almost optimal Nash equilibria. These dynamics mimic the classical greedy approximation algorithm of Bar-Yehuda and Even [3].',
	 'authors': u'Georgios Piliouras, Tomas Valla, Laszlo A. Vegh,',
	 'category': u'Computer Science ',
	 'date': '2012-2-29',
	 'pdflink': u'http://arxiv.org/pdf/1203.0050',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nLP-based Covering Games with Low Price of Anarchy',
	 'urllink': u'http://arxiv.org/abs/1203.0050'}
2015-03-23 22:46:17+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0185> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:46:17+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0185>
	{'abstract': u"Currently, industrial sectors are transforming their business processes into e-services and component-based architectures to build flexible, robust, and scalable systems, and reduce integration-related maintenance and development costs. Robotics is yet another promising and fast-growing industry that deals with the creation of machines that operate in an autonomous fashion and serve for various applications including space exploration, weaponry, laboratory research, and manufacturing. It is in space exploration that the most common type of robots is the planetary rover which moves across the surface of a planet and conducts a thorough geological study of the celestial surface. This type of rover system is still ad-hoc in that it incorporates its software into its core hardware making the whole system cohesive, tightly-coupled, more susceptible to shortcomings, less flexible, hard to be scaled and maintained, and impossible to be adapted to other purposes. This paper proposes a service-oriented architecture for space exploration robotic rover systems made out of loosely-coupled and distributed web services. The proposed architecture consists of three elementary tiers: the client tier that corresponds to the actual rover; the server tier that corresponds to the web services; and the middleware tier that corresponds to an Enterprise Service Bus which promotes interoperability between the interconnected entities. The niche of this architecture is that rover's software components are decoupled and isolated from the rover's body and possibly deployed at a distant location. A service-oriented architecture promotes integrate-ability, scalability, reusability, maintainability, and interoperability for client-to-server communication.",
	 'authors': u'Youssef Bassil,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0185',
	 'subjects': u'Robotics (cs.RO)',
	 'title': u'\nService-Oriented Architecture for Space Exploration Robotic Rover  Systems',
	 'urllink': u'http://arxiv.org/abs/1204.0185'}
2015-03-23 22:46:20+0000 [xxu46_4] INFO: Crawled 222 pages (at 4 pages/min), scraped 216 items (at 4 items/min)
2015-03-23 22:46:33+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0652> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:46:33+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0652>
	{'abstract': u'Performance of data forwarding in Delay Tolerant Networks (DTNs) benefits considerably if one can make use of human mobility in terms of social structures. However, it is difficult and time-consuming to calculate the centrality and similarity of nodes by using solutions for traditional social networks, this is mainly because of the transient node contact and the intermittently connected environment. In this work, we are interested in the following question: Can we explore some other stable social attributes to quantify the centrality and similarity of nodes? Taking GPS traces of human walks from the real world, we find that there exist two known phenomena. One is public hotspot, the other is personal hotspot. Motivated by this observation, we present Hoten (hotspot and entropy), a novel routing metric to improve routing performance in DTNs. First, we use the relative entropy between the public hotspots and the personal hotspots to compute the centrality of nodes. Then we utilize the inverse symmetrized entropy of the personal hotspots between two nodes to compute the similarity between them. Third, we exploit the entropy of personal hotspots of a node to estimate its personality. Besides, we propose a method to ascertain the optimized size of hotspot. Finally, we compare our routing strategy with other state-of-the-art routing schemes through extensive trace-driven simulations, the results show that Hoten largely outperforms other solutions, especially in terms of combined overhead/packet delivery ratio and the average number of hops per message.',
	 'authors': u'Peiyan Yuan, Huadong Ma, Shaojie Tang,',
	 'category': u'Computer Science ',
	 'date': '2012-5-3',
	 'pdflink': u'http://arxiv.org/e-print/1205.0652',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nOn Exploiting Hotspot and Entropy for Data Forwarding in Delay Tolerant  Networks',
	 'urllink': u'http://arxiv.org/abs/1205.0652'}
2015-03-23 22:46:51+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0044> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:46:51+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0044>
	{'abstract': u'In this paper, we study the connectivity in one-dimensional ad hoc wireless networks with an fixed access point. In recent years, various closed expressions for the probability of connectivity on one-dimensional networks (interval graphs) have been derived by many researchers. We will provide some numerical validation for them by means of extensive simulations.',
	 'authors': u'Junshan Li,',
	 'category': u'Computer Science ',
	 'date': '2012-2-29',
	 'pdflink': u'http://arxiv.org/pdf/1203.0044',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nConnectivity in one-dimensional ad hoc networks with an access point',
	 'urllink': u'http://arxiv.org/abs/1203.0044'}
2015-03-23 22:47:04+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0184> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:47:04+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0184>
	{'abstract': u'Spell-checking is the process of detecting and sometimes providing suggestions for incorrectly spelled words in a text. Basically, the larger the dictionary of a spell-checker is, the higher is the error detection rate; otherwise, misspellings would pass undetected. Unfortunately, traditional dictionaries suffer from out-of-vocabulary and data sparseness problems as they do not encompass large vocabulary of words indispensable to cover proper names, domain-specific terms, technical jargons, special acronyms, and terminologies. As a result, spell-checkers will incur low error detection and correction rate and will fail to flag all errors in the text. This paper proposes a new parallel shared-memory spell-checking algorithm that uses rich real-world word statistics from Yahoo! N-Grams Dataset to correct non-word and real-word errors in computer text. Essentially, the proposed algorithm can be divided into three sub-algorithms that run in a parallel fashion: The error detection algorithm that detects misspellings, the candidates generation algorithm that generates correction suggestions, and the error correction algorithm that performs contextual error correction. Experiments conducted on a set of text articles containing misspellings, showed a remarkable spelling error correction rate that resulted in a radical reduction of both non-word and real-word errors in electronic text. In a further study, the proposed algorithm is to be optimized for message-passing systems so as to become more flexible and less costly to scale over distributed machines.',
	 'authors': u'Youssef Bassil,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0184',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nParallel Spell-Checking Algorithm Based on Yahoo! N-Grams Dataset',
	 'urllink': u'http://arxiv.org/abs/1204.0184'}
2015-03-23 22:47:18+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0651> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:47:18+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0651>
	{'abstract': u"Maximum entropy approach to classification is very well studied in applied statistics and machine learning and almost all the methods that exists in literature are discriminative in nature. In this paper, we introduce a maximum entropy classification method with feature selection for large dimensional data such as text datasets that is generative in nature. To tackle the curse of dimensionality of large data sets, we employ conditional independence assumption (Naive Bayes) and we perform feature selection simultaneously, by enforcing a `maximum discrimination' between estimated class conditional densities. For two class problems, in the proposed method, we use Jeffreys () divergence to discriminate the class conditional densities. To extend our method to the multi-class case, we propose a completely new approach by considering a multi-distribution divergence: we replace Jeffreys divergence by Jensen-Shannon () divergence to discriminate conditional densities of multiple classes. In order to reduce computational complexity, we employ a modified Jensen-Shannon divergence (), based on AM-GM inequality. We show that the resulting divergence is a natural generalization of Jeffreys divergence to a multiple distributions case. As far as the theoretical justifications are concerned we show that when one intends to select the best features in a generative maximum entropy approach, maximum discrimination using divergence emerges naturally in binary classification. Performance and comparative study of the proposed algorithms have been demonstrated on large dimensional text and gene expression datasets that show our methods scale up very well with large dimensional datasets.",
	 'authors': u'Ambedkar Dukkipati, Gaurav Pandey, Debarghya Ghoshdastidar, Paramita Koley, D. M. V. Satya Sriram,',
	 'category': u'Computer Science ',
	 'date': '2012-5-3',
	 'pdflink': u'http://arxiv.org/pdf/1205.0651',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nGenerative Maximum Entropy Learning for Multiclass Classification',
	 'urllink': u'http://arxiv.org/abs/1205.0651'}
2015-03-23 22:47:20+0000 [xxu46_4] INFO: Crawled 226 pages (at 4 pages/min), scraped 220 items (at 4 items/min)
2015-03-23 22:47:35+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0030> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:47:35+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0030>
	{'abstract': u'For a closed-loop system, which has a contention-based multiple access network on its sensor link, the Medium Access Controller (MAC) may discard some packets when the traffic on the link is high. We use a local state-based scheduler to select a few critical data packets to send to the MAC. In this paper, we analyze the impact of such a scheduler on the closed-loop system in the presence of traffic, and show that there is a dual effect with state-based scheduling. In general, this makes the optimal scheduler and controller hard to find. However, by removing past controls from the scheduling criterion, we find that certainty equivalence holds. This condition is related to the classical result of Bar-Shalom and Tse, and it leads to the design of a scheduler with a certainty equivalent controller. This design, however, does not result in an equivalent system to the original problem, in the sense of Witsenhausen. Computing the estimate is difficult, but can be simplified by introducing a symmetry constraint on the scheduler. Based on these findings, we propose a dual predictor architecture for the closed-loop system, which ensures separation between scheduler, observer and controller. We present an example of this architecture, which illustrates a network-aware event-triggering mechanism.',
	 'authors': u'Chithrupa Ramesh, Henrik Sandberg, Karl H. Johansson,',
	 'category': u'Computer Science ',
	 'date': '2012-2-29',
	 'pdflink': u'http://arxiv.org/pdf/1203.0030',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nDesign of State-based Schedulers for a Network of Control Loops',
	 'urllink': u'http://arxiv.org/abs/1203.0030'}
2015-03-23 22:47:52+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0183> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:47:52+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0183>
	{'abstract': u"Today, robotics is an auspicious and fast-growing branch of technology that involves the manufacturing, design, and maintenance of robot machines that can operate in an autonomous fashion and can be used in a wide variety of applications including space exploration, weaponry, household, and transportation. More particularly, in space applications, a common type of robots has been of widespread use in the recent years. It is called planetary rover which is a robot vehicle that moves across the surface of a planet and conducts detailed geological studies pertaining to the properties of the landing cosmic environment. However, rovers are always impeded by obstacles along the traveling path which can destabilize the rover's body and prevent it from reaching its goal destination. This paper proposes an ANN model that allows rover systems to carry out autonomous path-planning to successfully navigate through challenging planetary terrains and follow their goal location while avoiding dangerous obstacles. The proposed ANN is a multilayer network made out of three layers: an input, a hidden, and an output layer. The network is trained in offline mode using back-propagation supervised learning algorithm. A software-simulated rover was experimented and it revealed that it was able to follow the safest trajectory despite existing obstacles. As future work, the proposed ANN is to be parallelized so as to speed-up the execution time of the training process.",
	 'authors': u'Youssef Bassil,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0183',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nNeural Network Model for Path-Planning of Robotic Rover Systems',
	 'urllink': u'http://arxiv.org/abs/1204.0183'}
2015-03-23 22:48:09+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0646> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:48:09+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0646>
	{'abstract': u'A percentile-based bibliometric indicator is an indicator that values publications based on their position within the citation distribution of their field. The most straightforward percentile-based indicator is the proportion of frequently cited publications, for instance the proportion of publications that belong to the top 10% most frequently cited of their field. Recently, more complex percentile-based indicators were proposed. A difficulty in the calculation of percentile-based indicators is caused by the discrete nature of citation distributions combined with the presence of many publications with the same number of citations. We introduce an approach to calculating percentile-based indicators that deals with this difficulty in a more satisfactory way than earlier approaches suggested in the literature. We show in a formal mathematical framework that our approach leads to indicators that do not suffer from biases in favor of or against particular fields of science.',
	 'authors': u'Ludo Waltman, Michael Schreiber,',
	 'category': u'Computer Science ',
	 'date': '2012-5-3',
	 'pdflink': u'http://arxiv.org/pdf/1205.0646',
	 'subjects': u'Digital Libraries (cs.DL)',
	 'title': u'\nOn the calculation of percentile-based bibliometric indicators',
	 'urllink': u'http://arxiv.org/abs/1205.0646'}
2015-03-23 22:48:20+0000 [xxu46_4] INFO: Crawled 229 pages (at 3 pages/min), scraped 223 items (at 3 items/min)
2015-03-23 22:48:24+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.0024> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:48:24+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.0024>
	{'abstract': u'Data-centric dynamic systems are systems where both the process controlling the dynamics and the manipulation of data are equally central. In this paper we study verification of (first-order) mu-calculus variants over relational data-centric dynamic systems, where data are represented by a full-fledged relational database, and the process is described in terms of atomic actions that evolve the database. The execution of such actions may involve calls to external services, providing fresh data inserted into the system. As a result such systems are typically infinite-state. We show that verification is undecidable in general, and we isolate notable cases, where decidability is achieved. Specifically we start by considering service calls that return values deterministically (depending only on passed parameters). We show that in a mu-calculus variant that preserves knowledge of objects appeared along a run we get decidability under the assumption that the fresh data introduced along a run are bounded, though they might not be bounded in the overall system. In fact we tie such a result to a notion related to weak acyclicity studied in data exchange. Then, we move to nondeterministic services where the assumption of data bounded run would result in a bound on the service calls that can be invoked during the execution and hence would be too restrictive. So we investigate decidability under the assumption that knowledge of objects is preserved only if they are continuously present. We show that if infinitely many values occur in a run but do not accumulate in the same state, then we get again decidability. We give syntactic conditions to avoid this accumulation through the novel notion of "generate-recall acyclicity", which takes into consideration that every service call activation generates new values that cannot be accumulated indefinitely.',
	 'authors': u'Babak Bagheri Hariri, Diego Calvanese, Giuseppe De Giacomo, Alin Deutsch, Marco Montali,',
	 'category': u'Computer Science ',
	 'date': '2012-2-29',
	 'pdflink': u'http://arxiv.org/pdf/1203.0024',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nVerification of Relational Data-Centric Dynamic Systems with External  Services',
	 'urllink': u'http://arxiv.org/abs/1203.0024'}
2015-03-23 22:48:40+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0182> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:48:40+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0182>
	{'abstract': u"The Bing Bang of the Internet in the early 90's increased dramatically the number of images being distributed and shared over the web. As a result, image information retrieval systems were developed to index and retrieve image files spread over the Internet. Most of these systems are keyword-based which search for images based on their textual metadata; and thus, they are imprecise as it is vague to describe an image with a human language. Besides, there exist the content-based image retrieval systems which search for images based on their visual information. However, content-based type systems are still immature and not that effective as they suffer from low retrieval recall/precision rate. This paper proposes a new hybrid image information retrieval model for indexing and retrieving web images published in HTML documents. The distinguishing mark of the proposed model is that it is based on both graphical content and textual metadata. The graphical content is denoted by color features and color histogram of the image; while textual metadata are denoted by the terms that surround the image in the HTML document, more particularly, the terms that appear in the tags p, h1, and h2, in addition to the terms that appear in the image's alt attribute, filename, and class-label. Moreover, this paper presents a new term weighting scheme called VTF-IDF short for Variable Term Frequency-Inverse Document Frequency which unlike traditional schemes, it exploits the HTML tag structure and assigns an extra bonus weight for terms that appear within certain particular HTML tags that are correlated to the semantics of the image. Experiments conducted to evaluate the proposed IR model showed a high retrieval precision rate that outpaced other current models.",
	 'authors': u'Youssef Bassil,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0182',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nHybrid Information Retrieval Model For Web Images',
	 'urllink': u'http://arxiv.org/abs/1204.0182'}
2015-03-23 22:48:54+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0642> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:48:55+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0642>
	{'abstract': u'We consider the group isomorphism problem: given two finite groups G and H specified by their multiplication tables, decide if G and H are isomorphic. The n^(log n) barrier for group isomorphism has withstood all attacks --- even for the special cases of p-groups and solvable groups --- ever since the n^(log n + O(1)) generator-enumeration algorithm. In this work, we present the first significant improvement over n^(log n) by showing that group isomorphism is n^((1 / 2) log_p n + O(1)) Turing reducible to composition-series isomorphism where p is the smallest prime dividing the order of the group. Combining our reduction with an n^(O(p / log p)) algorithm for p-group composition-series isomorphism, we obtain an n^((1 / 2) log n + O(1)) algorithm for p-group isomorphism. We then generalize our techniques from p-groups using Sylow bases to derive an n^((1 / 2) log n + O(log n / log log n)) algorithm for solvable-group isomorphism. Finally, we relate group isomorphism to the collision problem which allows us replace the 1 / 2 in the exponents with 1 / 4 using randomized algorithms and 1 / 6 using quantum algorithms.',
	 'authors': u'David Rosenbaum,',
	 'category': u'Computer Science ',
	 'date': '2012-5-3',
	 'pdflink': u'http://arxiv.org/pdf/1205.0642',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nBreaking the n^(log n) Barrier for Solvable-Group Isomorphism',
	 'urllink': u'http://arxiv.org/abs/1205.0642'}
2015-03-23 22:49:08+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0181> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:49:08+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0181>
	{'abstract': u'Expert systems use human knowledge often stored as rules within the computer to solve problems that generally would entail human intelligence. Today, with information systems turning out to be more pervasive and with the myriad advances in information technologies, automating computer fault diagnosis is becoming so fundamental that soon every enterprise has to endorse it. This paper proposes an expert system called Expert PC Troubleshooter for diagnosing computer problems. The system is composed of a user interface, a rule-base, an inference engine, and an expert interface. Additionally, the system features a fuzzy-logic module to troubleshoot POST beep errors, and an intelligent agent that assists in the knowledge acquisition process. The proposed system is meant to automate the maintenance, repair, and operations (MRO) process, and free-up human technicians from manually performing routine, laborious, and timeconsuming maintenance tasks. As future work, the proposed system is to be parallelized so as to boost its performance and speed-up its various operations.',
	 'authors': u'Youssef Bassil,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0181',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nExpert PC Troubleshooter With Fuzzy-Logic And Self-Learning Support',
	 'urllink': u'http://arxiv.org/abs/1204.0181'}
2015-03-23 22:49:20+0000 [xxu46_4] INFO: Crawled 233 pages (at 4 pages/min), scraped 227 items (at 4 items/min)
2015-03-23 22:49:26+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0627> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:49:26+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0627>
	{'abstract': u'Two formalisms, both based on context-free grammars, have recently been proposed as a basis for a non-uniform random generation of combinatorial objects. The former, introduced by Denise et al, associates weights with letters, while the latter, recently explored by Weinberg et al in the context of random generation, associates weights to transitions. In this short note, we use a simple modification of the Greibach Normal Form transformation algorithm, due to Blum and Koch, to show the equivalent expressivities, in term of their induced distributions, of these two formalisms.',
	 'authors': u'Yann Ponty,',
	 'category': u'Computer Science ',
	 'date': '2012-5-3',
	 'pdflink': u'http://arxiv.org/pdf/1205.0627',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nRule-weighted and terminal-weighted context-free grammars have identical  expressivity',
	 'urllink': u'http://arxiv.org/abs/1205.0627'}
2015-03-23 22:49:41+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0179> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:49:41+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0179>
	{'abstract': u'Military is one of many industries that is more computer-dependent than ever before, from soldiers with computerized weapons, and tactical wireless devices, to commanders with advanced battle management, command and control systems. Fundamentally, command and control is the process of planning, monitoring, and commanding military personnel, weaponry equipment, and combating vehicles to execute military missions. In fact, command and control systems are revolutionizing as war fighting is changing into cyber, technology, information, and unmanned warfare. As a result, a new design model that supports scalability, reusability, maintainability, survivability, and interoperability is needed to allow commanders, hundreds of miles away from the battlefield, to plan, monitor, evaluate, and control the war events in a dynamic, robust, agile, and reliable manner. This paper proposes a service-oriented architecture for weaponry and battle command and control systems, made out of loosely-coupled and distributed web services. The proposed architecture consists of three elementary tiers: the client tier that corresponds to any computing military equipment; the server tier that corresponds to the web services that deliver the basic functionalities for the client tier; and the middleware tier that corresponds to an enterprise service bus that promotes interoperability between all the interconnected entities. A command and control system was simulated and experimented and it successfully exhibited the desired features of SOA. Future research can improve upon the proposed architecture so much so that it supports encryption for securing the exchange of data between the various communicating entities of the system.',
	 'authors': u'Youssef Bassil,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0179',
	 'subjects': u'Robotics (cs.RO)',
	 'title': u'\nService-Oriented Architecture for Weaponry and Battle Command and  Control Systems in Warfighting',
	 'urllink': u'http://arxiv.org/abs/1204.0179'}
2015-03-23 22:49:55+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0622> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:49:55+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0622>
	{'abstract': u"Counterfactual Regret Minimization (CFR) is an efficient no-regret learning algorithm for decision problems modeled as extensive games. CFR's regret bounds depend on the requirement of perfect recall: players always remember information that was revealed to them and the order in which it was revealed. In games without perfect recall, however, CFR's guarantees do not apply. In this paper, we present the first regret bound for CFR when applied to a general class of games with imperfect recall. In addition, we show that CFR applied to any abstraction belonging to our general class results in a regret bound not just for the abstract game, but for the full game as well. We verify our theory and show how imperfect recall can be used to trade a small increase in regret for a significant reduction in memory in three domains: die-roll poker, phantom tic-tac-toe, and Bluff.",
	 'authors': u'Marc Lanctot, Richard Gibson, Neil Burch, Martin Zinkevich, Michael Bowling,',
	 'category': u'Computer Science ',
	 'date': '2012-5-3',
	 'pdflink': u'http://arxiv.org/pdf/1205.0622',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nNo-Regret Learning in Extensive-Form Games with Imperfect Recall',
	 'urllink': u'http://arxiv.org/abs/1205.0622'}
2015-03-23 22:50:09+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0176> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:50:09+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0176>
	{'abstract': u'A new approach, to measure normalization completeness for conceptual model, is introduced using quantitative fuzzy functionality in this paper. We measure the normalization completeness of the conceptual model in two steps. In the first step, different normalization techniques are analyzed up to Boyce Codd Normal Form (BCNF) to find the current normal form of the relation. In the second step, fuzzy membership values are used to scale the normal form between 0 and 1. Case studies to explain schema transformation rules and measurements. Normalization completeness is measured by considering completeness attributes, preventing attributes of the functional dependencies and total number of attributes such as if the functional dependency is non-preventing then the attributes of that functional dependency are completeness attributes. The attributes of functional dependency which prevent to go to the next normal form are called preventing attributes.',
	 'authors': u'M. Rizwan Jameel Qureshi, Mehboob Sharif, Nayyar Iqbal,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0176',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nUsing Fuzzy Logic to Evaluate Normalization Completeness for An Improved  Database Design',
	 'urllink': u'http://arxiv.org/abs/1204.0176'}
2015-03-23 22:50:20+0000 [xxu46_4] INFO: Crawled 237 pages (at 4 pages/min), scraped 231 items (at 4 items/min)
2015-03-23 22:50:26+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0618> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:50:26+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0618>
	{'abstract': u'Simultaneous information and power transfer over the wireless channels potentially offers great convenience to mobile users. Yet practical receiver designs impose technical constraints on its hardware realization, as practical circuits for harvesting energy from radio signals are not yet able to decode the carried information directly. To make theoretical progress, we propose a general receiver operation, namely, dynamic power splitting (DPS), which splits the received signal with adjustable power ratio for energy harvesting and information decoding, separately. Three special cases of DPS, namely, time switching (TS), static power splitting (SPS) and on-off power splitting (OPS) are investigated. The TS and SPS schemes can be treated as special cases of OPS. Moreover, we propose two types of practical receiver architectures, namely, separated versus integrated information and energy receivers. The integrated receiver integrates the front-end components of the separated receiver, thus achieving a smaller form factor. The rate-energy tradeoff for the two architectures are characterized by a so-called rate-energy (R-E) region. The optimal transmission strategy is derived to achieve different rate-energy tradeoffs. With receiver circuit power consumption taken into account, it is shown that the OPS scheme is optimal for both receivers. For the ideal case when the receiver circuit does not consume power, the SPS scheme is optimal for both receivers. In addition, we study the performance for the two types of receivers under a realistic system setup that employs practical modulation. Our results provide useful insights to the optimal practical receiver design for simultaneous wireless information and power transfer (SWIPT).',
	 'authors': u'Xun Zhou, Rui Zhang, Chin Keong Ho,',
	 'category': u'Computer Science ',
	 'date': '2012-5-3',
	 'pdflink': u'http://arxiv.org/pdf/1205.0618',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nWireless Information and Power Transfer: Architecture Design and  Rate-Energy Tradeoff',
	 'urllink': u'http://arxiv.org/abs/1205.0618'}
2015-03-23 22:50:39+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.1928> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:50:39+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.1928>
	{'abstract': u'We consider the problem of providing optimal uncertainty quantification (UQ) --- and hence rigorous certification --- for partially-observed functions. We present a UQ framework within which the observations may be small or large in number, and need not carry information about the probability distribution of the system in operation. The UQ objectives are posed as optimization problems, the solutions of which are optimal bounds on the quantities of interest; we consider two typical settings, namely parameter sensitivities (McDiarmid diameters) and output deviation (or failure) probabilities. The solutions of these optimization problems depend non-trivially (even non-monotonically and discontinuously) upon the specified legacy data. Furthermore, the extreme values are often determined by only a few members of the data set; in our principal physically-motivated example, the bounds are determined by just 2 out of 32 data points, and the remainder carry no information and could be neglected without changing the final answer. We propose an analogue of the simplex algorithm from linear programming that uses these observations to offer efficient and rigorous UQ for high-dimensional systems with high-cardinality legacy data. These findings suggest natural methods for selecting optimal (maximally informative) next experiments.',
	 'authors': u'T. J. Sullivan, M. McKerns, D. Meyer, F. Theil, H. Owhadi, M. Ortiz,',
	 'category': u'Computer Science ',
	 'date': '2012-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1202.1928',
	 'subjects': u'Probability (math.PR)',
	 'title': u'\nOptimal uncertainty quantification for legacy data observations of  Lipschitz functions',
	 'urllink': u'http://arxiv.org/abs/1202.1928'}
2015-03-23 22:50:51+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0173> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:50:51+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0173>
	{'abstract': u'A new applicable wiretap channel with separated side information is considered here which consist of a sender, a legitimate receiver and a wiretapper. In the considered scenario, the links from the transmitter to the legitimate receiver and the eavesdropper experience different conditions or channel states. So, the legitimate receiver and the wiretapper listen to the transmitted signal through the channels with different channel states which may have some correlation to each other. It is assumed that the transmitter knows the state of the main channel non-causally and uses this knowledge to encode its message. The state of the wiretap channel is not known anywhere. An achievable equivocation rate region is derived for this model and is compared to the existing works. In some special cases, the results are extended to the Gaussian wiretap channel.',
	 'authors': u'Hamid G. Bafghi, Babak Seyfe, Mahtab Mirmohseni, M. Reza Aref,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0173',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOn The Achievable Rate Region of a New Wiretap Channel With Side  Information',
	 'urllink': u'http://arxiv.org/abs/1204.0173'}
2015-03-23 22:51:06+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0610> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:51:06+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0610>
	{'abstract': u'Multiple instance learning (MIL) has attracted great attention recently in machine learning community. However, most MIL algorithms are very slow and cannot be applied to large datasets. In this paper, we propose a greedy strategy to speed up the multiple instance learning process. Our contribution is two fold. First, we propose a density ratio model, and show that maximizing a density ratio function is the low bound of the DD model under certain conditions. Secondly, we make use of a histogram ratio between positive bags and negative bags to represent the density ratio function and find codebooks separately for positive bags and negative bags by a greedy strategy. For testing, we make use of a nearest neighbor strategy to classify new bags. We test our method on both small benchmark datasets and the large TRECVID MED11 dataset. The experimental results show that our method yields comparable accuracy to the current state of the art, while being up to at least one order of magnitude faster.',
	 'authors': u'Gang Chen, Jason Corso,',
	 'category': u'Computer Science ',
	 'date': '2012-5-3',
	 'pdflink': u'http://arxiv.org/pdf/1205.0610',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nGreedy Multiple Instance Learning via Codebook Learning and Nearest  Neighbor Voting',
	 'urllink': u'http://arxiv.org/abs/1205.0610'}
2015-03-23 22:51:20+0000 [xxu46_4] INFO: Crawled 241 pages (at 4 pages/min), scraped 235 items (at 4 items/min)
2015-03-23 22:51:21+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0606> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:51:21+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0606>
	{'abstract': u'Stencil computations on low dimensional grids are kernels of many scientific applications including finite difference methods used to solve partial differential equations. On typical modern computer architectures, such stencil computations are limited by the performance of the memory subsystem, namely by the bandwidth between main memory and the cache. This work considers the computation of star stencils, like the 5-point and 7-point stencil, in the external memory model and parallel external memory model and analyses the constant of the leading term of the non-compulsory I/Os. While optimizing stencil computations is an active field of research, there has been a significant gap between the lower bounds and the performance of the algorithms so far. In two dimensions, this work provides matching constants for lower and upper bounds closing a multiplicative gap of 4. In three dimensions, the bounds match up to a factor of improving the known results by a factor of , where is the block (cache line) size of the external memory model. For dimensions , the lower bound is improved between a factor of and . For arbitrary dimension~, the first analysis of the constant of the leading term of the non-compulsory I/Os is presented. For the lower and upper bound match up to a factor of .',
	 'authors': u'Philipp Hupp, Riko Jacob,',
	 'category': u'Computer Science ',
	 'date': '2012-5-3',
	 'pdflink': u'http://arxiv.org/pdf/1205.0606',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nTight Bounds for Low Dimensional Star Stencils in the Parallel External  Memory Model',
	 'urllink': u'http://arxiv.org/abs/1205.0606'}
2015-03-23 22:51:32+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.0946> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:51:32+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.0946>
	{'abstract': u'This paper extends the energy-based version of the stochastic linearization method, known for classical nonlinear systems, to open quantum systems with canonically commuting dynamic variables governed by quantum stochastic differential equations with non-quadratic Hamiltonians. The linearization proceeds by approximating the actual Hamiltonian of the quantum system by a quadratic function of its observables which corresponds to the Hamiltonian of a quantum harmonic oscillator. This approximation is carried out in a mean square optimal sense with respect to a Gaussian reference quantum state and leads to a self-consistent linearization procedure where the mean vector and quantum covariance matrix of the system observables evolve in time according to the effective linear dynamics. We demonstrate the proposed Hamiltonian-based Gaussian linearization for the quantum Duffing oscillator whose Hamiltonian is a quadro-quartic polynomial of the momentum and position operators. The results of the paper are applicable to the design of suboptimal controllers and filters for nonlinear quantum systems.',
	 'authors': u'Igor G. Vladimirov, Ian R. Petersen,',
	 'category': u'Computer Science ',
	 'date': '2012-2-5',
	 'pdflink': u'http://arxiv.org/pdf/1202.0946',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nGaussian Stochastic Linearization for Open Quantum Systems Using  Quadratic Approximation of Hamiltonians',
	 'urllink': u'http://arxiv.org/abs/1202.0946'}
2015-03-23 22:51:47+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0170> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:51:47+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0170>
	{'abstract': u'Latent Dirichlet allocation (LDA) is a widely-used probabilistic topic modeling paradigm, and recently finds many applications in computer vision and computational biology. In this paper, we propose a fast and accurate batch algorithm, active belief propagation (ABP), for training LDA. Usually batch LDA algorithms require repeated scanning of the entire corpus and searching the complete topic space. To process massive corpora having a large number of topics, the training iteration of batch LDA algorithms is often inefficient and time-consuming. To accelerate the training speed, ABP actively scans the subset of corpus and searches the subset of topic space for topic modeling, therefore saves enormous training time in each iteration. To ensure accuracy, ABP selects only those documents and topics that contribute to the largest residuals within the residual belief propagation (RBP) framework. On four real-world corpora, ABP performs around to times faster than state-of-the-art batch LDA algorithms with a comparable topic modeling accuracy.',
	 'authors': u'Jia Zeng, Zhi-Qiang Liu, Xiao-Qin Cao,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0170',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nA New Approach to Speeding Up Topic Modeling',
	 'urllink': u'http://arxiv.org/abs/1204.0170'}
2015-03-23 22:51:58+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0596> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:51:58+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0596>
	{'abstract': u"Complex networks are all around us, and they can be generated by simple mechanisms. Understanding what kinds of networks can be produced by following simple rules is therefore of great importance. We investigate this issue by studying the dynamics of extremely simple systems where are `writer' moves around a network, and modifies it in a way that depends upon the writer's surroundings. Each vertex in the network has three edges incident upon it, which are colored red, blue and green. This edge coloring is done to provide a way for the writer to orient its movement. We explore the dynamics of a space of 3888 of these `colored trinet automata' systems. We find a large variety of behaviour, ranging from the very simple to the very complex. We also discover simple rules that generate forms which are remarkably similar to a wide range of natural objects. We study our systems using simulations (with appropriate visualization techniques) and analyze selected rules mathematically. We arrive at an empirical classification scheme which reveals a lot about the kinds of dynamics and networks that can be generated by these systems.",
	 'authors': u'Richard Southwell, Jianwei Huang, Chris Cannings,',
	 'category': u'Computer Science ',
	 'date': '2012-5-3',
	 'pdflink': u'http://arxiv.org/pdf/1205.0596',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nComplex Networks from Simple Rewrite Systems',
	 'urllink': u'http://arxiv.org/abs/1205.0596'}
2015-03-23 22:52:12+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.4303> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:52:12+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.4303>
	{'abstract': u'A big class of Feynman integrals, in particular, the coefficients of their Laurent series expansion w.r.t. the dimension parameter can be transformed to multi-sums over hypergeometric terms and harmonic sums. In this article, we present a general summation method based on difference fields that simplifies these multi--sums by transforming them from inside to outside to representations in terms of indefinite nested sums and products. In particular, we present techniques that assist in the task to simplify huge expressions of such multi-sums in a completely automatic fashion. The ideas are illustrated on new calculations coming from 3-loop topologies of gluonic massive operator matrix elements containing two fermion lines, which contribute to the transition matrix elements in the variable flavor scheme.',
	 'authors': u'J. Bl\xfcmlein, A. Hasselhuhn, C. Schneider,',
	 'category': u'Computer Science ',
	 'date': '2012-2-20',
	 'pdflink': u'http://arxiv.org/pdf/1202.4303',
	 'subjects': u'Mathematical Physics (math-ph)',
	 'title': u'\nEvaluation of Multi-Sums for Large Scale Problems',
	 'urllink': u'http://arxiv.org/abs/1202.4303'}
2015-03-23 22:52:20+0000 [xxu46_4] INFO: Crawled 246 pages (at 5 pages/min), scraped 240 items (at 5 items/min)
2015-03-23 22:52:25+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0166> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:52:25+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0166>
	{'abstract': u'This paper studies a downlink multiuser transmit beamforming design under spherical channel uncertainties, using a worst-case robust formulation. This robust design problem is nonconvex. Recently, a convex approximation formulation based on semidefinite relaxation (SDR) has been proposed to handle the problem. Curiously, simulation results have consistently indicated that SDR can attain the global optimum of the robust design problem. This paper intends to provide some theoretical insights into this important empirical finding. Our main result is a dual representation of the SDR formulation, which reveals an interesting linkage to a different robust design problem, and the possibility of SDR optimality.',
	 'authors': u'Tsung-Hui Chang, Wing-Kin Ma, Chong-Yung Chi,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0166',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nWorst-Case Robust Multiuser Transmit Beamforming Using Semidefinite  Relaxation: Duality and Implications',
	 'urllink': u'http://arxiv.org/abs/1204.0166'}
2015-03-23 22:52:41+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0591> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:52:41+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0591>
	{'abstract': u'Personalized article recommendation is important to improve user engagement on news sites. Existing work quantifies engagement primarily through click rates. We argue that quality of recommendations can be improved by incorporating different types of "post-read" engagement signals like sharing, commenting, printing and e-mailing article links. More specifically, we propose a multi-faceted ranking problem for recommending news articles where each facet corresponds to a ranking problem to maximize actions of a post-read action type. The key technical challenge is to estimate the rates of post-read action types by mitigating the impact of enormous data sparsity, we do so through several variations of factor models. To exploit correlations among post-read action types we also introduce a novel variant called locally augmented tensor (LAT) model. Through data obtained from a major news site in the US, we show that factor models significantly outperform a few baseline IR models and the LAT model significantly outperforms several other variations of factor models. Our findings show that it is possible to incorporate post-read signals that are commonly available on online news sites to improve quality of recommendations.',
	 'authors': u'Deepak Agarwal, Bee-Chung Chen, Xuanhui Wang,',
	 'category': u'Computer Science ',
	 'date': '2012-5-3',
	 'pdflink': u'http://arxiv.org/pdf/1205.0591',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nMulti-Faceted Ranking of News Articles using Post-Read Actions',
	 'urllink': u'http://arxiv.org/abs/1205.0591'}
2015-03-23 22:52:56+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.6522> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:52:56+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.6522>
	{'abstract': u'In this paper, we report on very efficient algorithms for the spherical harmonic transform (SHT). Explicitly vectorized variations of the algorithm based on the Gauss-Legendre quadrature are discussed and implemented in the SHTns library which includes scalar and vector transforms. The main breakthrough is to achieve very efficient on-the-fly computations of the Legendre associated functions, even for very high resolutions, by taking advantage of the specific properties of the SHT and the advanced capabilities of current and future computers. This allows us to simultaneously and significantly reduce memory usage and computation time of the SHT. We measure the performance and accuracy of our algorithms. Even though the complexity of the algorithms implemented in SHTns are in (where N is the maximum harmonic degree of the transform), they perform much better than any third party implementation, including lower complexity algorithms, even for truncations as high as N=1023. SHTns is available at this https URL as open source software.',
	 'authors': u'Nathana\xebl Schaeffer,',
	 'category': u'Computer Science ',
	 'date': '2012-2-29',
	 'pdflink': u'http://arxiv.org/pdf/1202.6522',
	 'subjects': u'Computational Physics (physics.comp-ph)',
	 'title': u'\nEfficient Spherical Harmonic Transforms aimed at pseudo-spectral  numerical simulations',
	 'urllink': u'http://arxiv.org/abs/1202.6522'}
2015-03-23 22:53:11+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0165> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:53:11+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0165>
	{'abstract': u"The topological structure of the power grid plays a key role in the reliable delivery of electricity and price settlement in the electricity market. Incorporation of new energy sources and loads into the grid over time has led to its structural and geographical expansion and can affect its stable operation. This paper presents an intuitive analytical model for the temporal evolution of large grids and uses it to understand common structural features observed in grids across America. In particular, key graph parameters like degree distribution, graph diameter, betweenness centralities, eigen-spread and clustering coefficients, as well as graph processes like infection propagation are used to quantify the model's benefits through comparison with the Western US and ERCOT power grids. The most significant contribution of the developed model is its analytical tractability, that provides a closed form expression for the nodal degree distribution observed in large grids. The discussed model can be used to generate realistic test cases to analyze topological effects on grid functioning and new grid technologies.",
	 'authors': u'Deepjyoti Deka, Sriram Vishwanath,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0165',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nAnalytical Models for Power Networks: The case of the Western US and  ERCOT grids',
	 'urllink': u'http://arxiv.org/abs/1204.0165'}
2015-03-23 22:53:20+0000 [xxu46_4] INFO: Crawled 250 pages (at 4 pages/min), scraped 244 items (at 4 items/min)
2015-03-23 22:53:28+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0586> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:53:28+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0586>
	{'abstract': u'Error control is significant to network coding, since when unchecked, errors greatly deteriorate the throughput gains of network coding and seriously undermine both reliability and security of data. Two families of codes, subspace and rank metric codes, have been used to provide error control for random linear network coding. In this paper, we enhance the error correction capability of these two families of codes by using a novel two-tier decoding scheme. While the decoding of subspace and rank metric codes serves a second-tier decoding, we propose to perform a first-tier decoding on the packet level by taking advantage of Hamming distance properties of subspace and rank metric codes. This packet-level decoding can also be implemented by intermediate nodes to reduce error propagation. To support the first-tier decoding, we also investigate Hamming distance properties of three important families of subspace and rank metric codes, Gabidulin codes, Kotter--Kschischang codes, and Mahdavifar--Vardy codes. Both the two-tier decoding scheme and the Hamming distance properties of these codes are novel to the best of our knowledge.',
	 'authors': u'Zhiyuan Yan, Hongmei Xie,',
	 'category': u'Computer Science ',
	 'date': '2012-5-3',
	 'pdflink': u'http://arxiv.org/pdf/1205.0586',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nEnhanced Algebraic Error Control for Random Linear Network Coding',
	 'urllink': u'http://arxiv.org/abs/1205.0586'}
2015-03-23 22:53:45+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.6666> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:53:45+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.6666>
	{'abstract': u'The original contributions of this paper are twofold: a new understanding of the influence of noise on the eigenvectors of the graph Laplacian of a set of image patches, and an algorithm to estimate a denoised set of patches from a noisy image. The algorithm relies on the following two observations: (1) the low-index eigenvectors of the diffusion, or graph Laplacian, operators are very robust to random perturbations of the weights and random changes in the connections of the patch-graph; and (2) patches extracted from smooth regions of the image are organized along smooth low-dimensional structures in the patch-set, and therefore can be reconstructed with few eigenvectors. Experiments demonstrate that our denoising algorithm outperforms the denoising gold-standards.',
	 'authors': u'Francois G. Meyer, Xilin Shen,',
	 'category': u'Computer Science ',
	 'date': '2012-2-29',
	 'pdflink': u'http://arxiv.org/pdf/1202.6666',
	 'subjects': u'Data Analysis, Statistics and Probability (physics.data-an)',
	 'title': u'\nPerturbation of the Eigenvectors of the Graph Laplacian: Application to  Image Denoising',
	 'urllink': u'http://arxiv.org/abs/1202.6666'}
2015-03-23 22:53:59+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0163> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:53:59+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0163>
	{'abstract': u"Fashion plays such a crucial rule in the evolution of culture and society that it is regarded as a second nature to the human being. Also, its impact on economy is quite nontrivial. On what is fashionable, interestingly, there are two viewpoints that are both extremely widespread but almost opposite: conformists think that what is popular is fashionable, while rebels believe that being different is the essence. Fashion color is fashionable in the first sense, and Lady Gaga in the second. We investigate a model where the population consists of the afore-mentioned two groups of people that are located on social networks (a spatial cellular automata network and small-world networks). This model captures two fundamental kinds of social interactions (coordination and anti-coordination) simultaneously, and also has its own interest to game theory: it is a hybrid model of pure competition and pure cooperation. This is true because when a conformist meets a rebel, they play the zero sum matching pennies game, which is pure competition. When two conformists (rebels) meet, they play the (anti-) coordination game, which is pure cooperation. Simulation shows that simple social interactions greatly promote cooperation: in most cases people can reach an extraordinarily high level of cooperation, through a selfish, myopic, naive, and local interacting dynamic (the best response dynamic). We find that degree of synchronization also plays a critical role, but mostly on the negative side. Four indices, namely cooperation degree, average satisfaction degree, equilibrium ratio and complete ratio, are defined and applied to measure people's cooperation levels from various angles. Phase transition, as well as emergence of many interesting geographic patterns in the cellular automata network, is also observed.",
	 'authors': u'Zhigang Cao, Haoyu Gao, Xinglong Qu, Mingmin Yang, Xiaoguang Yang,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0163',
	 'subjects': u'Multiagent Systems (cs.MA)',
	 'title': u'\nFashion, Cooperation, and Social Interactions',
	 'urllink': u'http://arxiv.org/abs/1204.0163'}
2015-03-23 22:54:16+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0581> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:54:16+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0581>
	{'abstract': u'We consider the classical secret sharing problem in the case where all agents are selfish but rational. In recent work, Kol and Naor show that, when there are two players, in the non-simultaneous communication model, i.e. when rushing is possible, there is no Nash equilibrium that ensures both players learn the secret. However, they describe a mechanism for this problem, for any number of players, that is an epsilon-Nash equilibrium, in that no player can gain more than epsilon utility by deviating from it. Unfortunately, the Kol and Naor mechanism, and, to the best of our knowledge, all previous mechanisms for this problem require each agent to send O(n) messages in expectation, where n is the number of agents. This may be problematic for some applications of rational secret sharing such as secure multi-party computation and simulation of a mediator. We address this issue by describing mechanisms for rational secret sharing that are designed for large n. Both of our results hold for n &gt; 2, and are Nash equilbria, rather than just epsilon-Nash equilbria. Our first result is a mechanism for n-out-of-n rational secret sharing that is scalable in the sense that it requires each agent to send only an expected O(log n) bits. Moreover, the latency of this mechanism is O(log n) in expectation, compared to O(n) expected latency for the Kol and Naor result. Our second result is a mechanism for a relaxed variant of rational m-out-of-n secret sharing where m = Theta(n). It requires each processor to send O(log n) bits and has O(log n) latency. Both of our mechanisms are non-cryptographic, and are not susceptible to backwards induction.',
	 'authors': u'Varsha Dani, Mahnush Movahedi, Jared Saia,',
	 'category': u'Computer Science ',
	 'date': '2012-5-2',
	 'pdflink': u'http://arxiv.org/pdf/1205.0581',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nScalable Mechanisms for Rational Secret Sharing',
	 'urllink': u'http://arxiv.org/abs/1205.0581'}
2015-03-23 22:54:20+0000 [xxu46_4] INFO: Crawled 254 pages (at 4 pages/min), scraped 248 items (at 4 items/min)
2015-03-23 22:54:34+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.6645> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:54:34+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.6645>
	{'abstract': u"Kaplanski's Zero Divisor Conjecture envisions that for a torsion-free group G and an integral domain R, the group ring R[G] does not contain non-trivial zero divisors. We define the length of an element a in R[G] as the minimal non-negative integer k for which there are ring elements r_1,...,r_k in R and group elements g_1,...,g_k in G such that a = r_1 g_1+...+r_k g_k. We investigate the conjecture when R is the field of rational numbers. By a reduction to the finite field with two elements, we show that if ab = 0 for non-trivial elements in the group ring of a torsion-free group over the rationals, then the lengths of a and b cannot be among certain combinations. More precisely, we show for various pairs of integers (i,j) that if one of the lengths is at most i then the other length must exceed j. Using combinatorial arguments we show this for the pairs (3,6) and (4,4). With a computer-assisted approach we strengthen this to show the statement holds for the pairs (3,16) and (4,7). As part of our method, we describe a combinatorial structure, which we call matched rectangles, and show that for these a canonical labeling can be computed in quadratic time. Each matched rectangle gives rise to a presentation of a group. These associated groups are universal in the sense that there is no counterexample to the conjecture among them if and only if the conjecture is true over the rationals.",
	 'authors': u'Pascal Schweitzer,',
	 'category': u'Computer Science ',
	 'date': '2012-2-29',
	 'pdflink': u'http://arxiv.org/pdf/1202.6645',
	 'subjects': u'Rings and Algebras (math.RA)',
	 'title': u'\nOn Zero Divisors with Small Support in Group Rings of Torsion-Free  Groups',
	 'urllink': u'http://arxiv.org/abs/1202.6645'}
2015-03-23 22:54:51+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0161> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:54:51+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0161>
	{'abstract': u"We study an extension of the DeGroot model where part of the players may be rebels. The updating rule for rebels is quite different with that of normal players (which are referred to as conformists): at each step a rebel first takes the opposite value of the weighted average of her neighbors' opinions, i.e. 1 minus that average (the opinion space is assumed to be [0,1] as usual), and then updates her opinion by taking another weighted average between that value and her own opinion in the last round. We find that the effect of rebels is rather significant: as long as there is at least one rebel in every closed and strongly connected group, under very weak conditions, the opinion of each player in the whole society will eventually tend to 0.5.",
	 'authors': u'Zhigang Cao, Mingmin Yang, Xinglong Qu, Xiaoguang Yang,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0161',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nRebels Lead to the Doctrine of the Mean: Opinion Dynamic in a  Heterogeneous DeGroot Model',
	 'urllink': u'http://arxiv.org/abs/1204.0161'}
2015-03-23 22:55:04+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0561> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:55:04+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0561>
	{'abstract': u'During last decade, multi-level agent-based modeling has received significant and dramatically increasing interest. In this article we present a comprehensive and structured review of literature on the subject. We present the main theoretical contributions and application domains of this concept, with an emphasis on social, flow, biological and biomedical models.',
	 'authors': u'Gildas Morvan,',
	 'category': u'Computer Science ',
	 'date': '2012-5-2',
	 'pdflink': u'http://arxiv.org/pdf/1205.0561',
	 'subjects': u'Multiagent Systems (cs.MA)',
	 'title': u'\nMulti-level agent-based modeling - A literature survey',
	 'urllink': u'http://arxiv.org/abs/1205.0561'}
2015-03-23 22:55:20+0000 [xxu46_4] INFO: Crawled 257 pages (at 3 pages/min), scraped 251 items (at 3 items/min)
2015-03-23 22:55:20+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.6530> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:55:20+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.6530>
	{'abstract': u'We define a subclass of quantum Turing machine (QTM) named SR-QTM, which halts deterministically and has deterministic tape head position. A quantum state transition diagram (QSTD) is proposed to describe SR-QTM. With the help of QSTD, we construct a SR-QTM which is universal for all near-trivial transformations. This means there exists a QTM which is universal for the above subclass. Finally we prove that SR-QTM is computational equivalent with ordinary QTM in the bounded error setting. It can be seen that, because SR-QTM has the same time steps for different branches of computation, the halting scheme problem will not exist when considering SR-QTM as a model of quantum computing.',
	 'authors': u'Min Liang, Li Yang,',
	 'category': u'Computer Science ',
	 'date': '2012-2-29',
	 'pdflink': u'http://arxiv.org/pdf/1202.6530',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nOn Quantum Turing Machine Halting Deterministically',
	 'urllink': u'http://arxiv.org/abs/1202.6530'}
2015-03-23 22:55:36+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0156> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:55:36+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0156>
	{'abstract': u'The increasing popularity of Twitter and other microblogs makes improved trustworthiness and relevance assessment of microblogs evermore important. We propose a method of ranking of tweets considering trustworthiness and content based popularity. The analysis of trustworthiness and popularity exploits the implicit relationships between the tweets. We model microblog ecosystem as a three-layer graph consisting of : (i) users (ii) tweets and (iii) web pages. We propose to derive trust and popularity scores of entities in these three layers, and propagate the scores to tweets considering the inter-layer relations. Our preliminary evaluations show improvement in precision and trustworthiness over the baseline methods and acceptable computation timings.',
	 'authors': u'Srijith Ravikumar, Raju Balakrishnan, Subbarao Kambhampati,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0156',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nRanking Tweets Considering Trust and Relevance',
	 'urllink': u'http://arxiv.org/abs/1204.0156'}
2015-03-23 22:55:54+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0483> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:55:54+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0483>
	{'abstract': u'High availability has always been one of the main problems for a data center. Till now high availability was achieved by host per host redundancy, a highly expensive method in terms of hardware and human costs. A new approach to the problem can be offered by virtualization. Using virtualization, it is possible to achieve a redundancy system for all the services running on a data center. This new approach to high availability allows the running virtual machines to be distributed over a small number of servers, by exploiting the features of the virtualization layer: start, stop and move virtual machines between physical hosts. The 3RC system is based on a finite state machine, providing the possibility to restart each virtual machine over any physical host, or reinstall it from scratch. A complete infrastructure has been developed to install operating system and middleware in a few minutes. To virtualize the main servers of a data center, a new procedure has been developed to migrate physical to virtual hosts. The whole Grid data center SNS-PISA is running at the moment in virtual environment under the high availability system.',
	 'authors': u'Federico Calzolari, Silvia Arezzini, Alberto Ciampa, Enrico Mazzoni, Andrea Domenici, Gigliola Vaglini,',
	 'category': u'Computer Science ',
	 'date': '2012-5-2',
	 'pdflink': u'http://arxiv.org/pdf/1205.0483',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nHigh availability using virtualization - 3RC',
	 'urllink': u'http://arxiv.org/abs/1205.0483'}
2015-03-23 22:56:10+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.6513> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:56:10+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.6513>
	{'abstract': u'We develop the Mechanic package, which is a new numerical framework for dynamical astronomy. The aim of our software is to help in massive numerical simulations by efficient task management and unified data storage. The code is built on top of the Message Passing Interface (MPI) and Hierarchical Data Format (HDF5) standards and uses the Task Farm approach to manage numerical tasks. It relies on the core-module approach. The numerical problem implemented in the user-supplied module is separated from the host code (core). The core is designed to handle basic setup, data storage and communication between nodes in a computing pool. It has been tested on large CPU-clusters, as well as desktop computers. The Mechanic may be used in computing dynamical maps, data optimization or numerical integration. The code and sample modules are freely available at this http URL',
	 'authors': u'Mariusz Slonina, Krzysztof Gozdziewski, Cezary Migaszewski,',
	 'category': u'Computer Science ',
	 'date': '2012-2-29',
	 'pdflink': u'http://arxiv.org/pdf/1202.6513',
	 'subjects': u'Instrumentation and Methods for Astrophysics (astro-ph.IM)',
	 'title': u'\nMechanic: a new numerical MPI framework for the dynamical astronomy',
	 'urllink': u'http://arxiv.org/abs/1202.6513'}
2015-03-23 22:56:20+0000 [xxu46_4] INFO: Crawled 261 pages (at 4 pages/min), scraped 255 items (at 4 items/min)
2015-03-23 22:56:23+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0153> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:56:23+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0153>
	{'abstract': u"This paper considers the problem of end-end security enhancement by resorting to deliberate noise injected in ciphertexts. The main goal is to generate a degraded wiretap channel in application layer over which Wyner-type secrecy encoding is invoked to deliver additional secure information. More specifically, we study secrecy enhancement of DES block cipher working in cipher feedback model (CFB) when adjustable and intentional noise is introduced into encrypted data in application layer. A verification strategy in exhaustive search step of linear attack is designed to allow Eve to mount a successful attack in the noisy environment. Thus, a controllable wiretap channel is created over multiple frames by taking advantage of errors in Eve's cryptanalysis, whose secrecy capacity is found for the case of known channel states at receivers. As a result, additional secure information can be delivered by performing Wyner type secrecy encoding over super-frames ahead of encryption, namely, our proposed secrecy encoding-then-encryption scheme. These secrecy bits could be taken as symmetric keys for upcoming frames. Numerical results indicate that a sufficiently large secrecy rate can be achieved by selective noise addition.",
	 'authors': u'Yahya S. Khiabani, Shuangqing Wei, Jian Yuan, Jian Wang,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0153',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nEnhancement of Secrecy of Block Ciphered Systems by Deliberate Noise',
	 'urllink': u'http://arxiv.org/abs/1204.0153'}
2015-03-23 22:56:30+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0480> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:56:30+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0480>
	{'abstract': u'In recent years, Session Initiation Protocol (SIP) has become widely used in current internet protocols. It is a text-based protocol much like Hyper Text Transport Protocol (HTTP) and Simple Mail Transport Protocol (SMTP). SIP is a strong enough signaling protocol on the internet for establishing, maintaining, and terminating session. In this paper the areas of security and attacks in SIP are discussed. We consider attacks from diverse related perspectives. The authentication schemes are compared, the representative existing solutions are highlighted, and several remaining research challenges are identified. Finally, the taxonomy of SIP threat will be presented.',
	 'authors': u'Hassan Keshavarz, Mohammad Reza Jabbarpour Sattari, Rafidah Md Noor,',
	 'category': u'Computer Science ',
	 'date': '2012-5-2',
	 'pdflink': u'http://arxiv.org/pdf/1205.0480',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nSession Initiation Protocol Attacks and Challenges',
	 'urllink': u'http://arxiv.org/abs/1205.0480'}
2015-03-23 22:56:45+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.6504> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:56:45+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.6504>
	{'abstract': u'This paper presents a kernel-based discriminative learning framework on probability measures. Rather than relying on large collections of vectorial training examples, our framework learns using a collection of probability distributions that have been constructed to meaningfully represent training data. By representing these probability distributions as mean embeddings in the reproducing kernel Hilbert space (RKHS), we are able to apply many standard kernel-based learning techniques in straightforward fashion. To accomplish this, we construct a generalization of the support vector machine (SVM) called a support measure machine (SMM). Our analyses of SMMs provides several insights into their relationship to traditional SVMs. Based on such insights, we propose a flexible SVM (Flex-SVM) that places different kernel functions on each training example. Experimental results on both synthetic and real-world data demonstrate the effectiveness of our proposed framework.',
	 'authors': u'Krikamol Muandet, Kenji Fukumizu, Francesco Dinuzzo, Bernhard Sch\xf6lkopf,',
	 'category': u'Computer Science ',
	 'date': '2012-2-29',
	 'pdflink': u'http://arxiv.org/pdf/1202.6504',
	 'subjects': u'Machine Learning (stat.ML)',
	 'title': u'\nLearning from Distributions via Support Measure Machines',
	 'urllink': u'http://arxiv.org/abs/1202.6504'}
2015-03-23 22:56:57+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0147> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:56:57+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0147>
	{'abstract': u'In this paper we study the covering numbers of the space of convex and uniformly bounded functions in multi-dimension. We find optimal upper and lower bounds for the -covering number of , in the -metric, , in terms of the relevant constants, where , , , and denotes the set of all convex functions on that are uniformly bounded by . We summarize previously known results on covering numbers for convex functions and also provide alternate proofs of some known results. Our results have direct implications in the study of rates of convergence of empirical minimization procedures as well as optimal convergence rates in the numerous convexity constrained function estimation problems.',
	 'authors': u'Adityanand Guntuboyina, Bodhisattva Sen,',
	 'category': u'Computer Science ',
	 'date': '2012-3-31',
	 'pdflink': u'http://arxiv.org/pdf/1204.0147',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nCovering Numbers for Convex Functions',
	 'urllink': u'http://arxiv.org/abs/1204.0147'}
2015-03-23 22:57:12+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0477> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:57:12+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0477>
	{'abstract': u'Renaming is a fundamental problem in distributed computing, which consists of a set of processes picking distinct names from a given namespace. The paper presents algorithms that solve order-preserving renaming in synchronous message passing systems with Byzantine processes. To the best of our knowledge, this work is the first to address order-preserving renaming in the given model. Although this problem can be solved by using consensus, it is known that renaming is "weaker" than consensus, therefore we are mainly concerned with the efficiency of performing renaming and make three contributions in this direction. We present an order-preserving renaming algorithm for with target namespace of size and logarithmic step complexity (where is the number of processes and is an upper bound on the number of faults). Similarly to the existing crash-tolerant solution, our algorithm employs the ideas from the approximate agreement problem. We show that our algorithm has constant step complexity if and achieves tight namespace of size . Finally, we present an algorithm that solves order-preserving renaming in just 2 communication steps, if .',
	 'authors': u'Oksana Denysyuk, Luis Rodrigues,',
	 'category': u'Computer Science ',
	 'date': '2012-5-2',
	 'pdflink': u'http://arxiv.org/pdf/1205.0477',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nOrder-preserving Renaming in Synchronous Message Passing Systems with  Byzantine Faults',
	 'urllink': u'http://arxiv.org/abs/1205.0477'}
2015-03-23 22:57:20+0000 [xxu46_4] INFO: Crawled 266 pages (at 5 pages/min), scraped 260 items (at 5 items/min)
2015-03-23 22:57:29+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.6389> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:57:29+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.6389>
	{'abstract': u"Distributed consensus and other linear systems with system stochastic matrices emerge in various settings, like opinion formation in social networks, rendezvous of robots, and distributed inference in sensor networks. The matrices are often random, due to, e.g., random packet dropouts in wireless sensor networks. Key in analyzing the performance of such systems is studying convergence of matrix products . In this paper, we find the exact exponential rate for the convergence in probability of the product of such matrices when time grows large, under the assumption that the 's are symmetric and independent identically distributed in time. Further, for commonly used random models like with gossip and link failure, we show that the rate is found by solving a min-cut problem and, hence, easily computable. Finally, we apply our results to optimally allocate the sensors' transmission power in consensus+innovations distributed detection.",
	 'authors': u'Dragana Bajovic, Joao Xavier, Jose M. F. Moura, Bruno Sinopoli,',
	 'category': u'Computer Science ',
	 'date': '2012-2-28',
	 'pdflink': u'http://arxiv.org/pdf/1202.6389',
	 'subjects': u'Probability (math.PR)',
	 'title': u'\nConsensus and Products of Random Stochastic Matrices: Exact Rate for  Convergence in Probability',
	 'urllink': u'http://arxiv.org/abs/1202.6389'}
2015-03-23 22:57:40+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0140> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:57:40+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0140>
	{'abstract': u"WordNet proved that it is possible to construct a large-scale electronic lexical database on the principles of lexical semantics. It has been accepted and used extensively by computational linguists ever since it was released. Inspired by WordNet's success, we propose as an alternative a similar resource, based on the 1987 Penguin edition of Roget's Thesaurus of English Words and Phrases. Peter Mark Roget published his first Thesaurus over 150 years ago. Countless writers, orators and students of the English language have used it. Computational linguists have employed Roget's for almost 50 years in Natural Language Processing, however hesitated in accepting Roget's Thesaurus because a proper machine tractable version was not available. This dissertation presents an implementation of a machine-tractable version of the 1987 Penguin edition of Roget's Thesaurus - the first implementation of its kind to use an entire current edition. It explains the steps necessary for taking a machine-readable file and transforming it into a tractable system. This involves converting the lexical material into a format that can be more easily exploited, identifying data structures and designing classes to computerize the Thesaurus. Roget's organization is studied in detail and contrasted with WordNet's. We show two applications of the computerized Thesaurus: computing semantic similarity between words and phrases, and building lexical chains in a text. The experiments are performed using well-known benchmarks and the results are compared to those of other systems that use Roget's, WordNet and statistical techniques. Roget's has turned out to be an excellent resource for measuring semantic similarity; lexical chains are easily built but more difficult to evaluate. We also explain ways in which Roget's Thesaurus and WordNet can be combined.",
	 'authors': u'Mario Jarmasz,',
	 'category': u'Computer Science ',
	 'date': '2012-3-31',
	 'pdflink': u'http://arxiv.org/pdf/1204.0140',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u"\nRoget's Thesaurus as a Lexical Resource for Natural Language Processing",
	 'urllink': u'http://arxiv.org/abs/1204.0140'}
2015-03-23 22:57:56+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0458> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:57:56+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0458>
	{'abstract': u'Recently Raghavendra and Tan (SODA 2012) gave a 0.85-approximation algorithm for the Max Bisection problem. We improve their algorithm to a 0.8776-approximation. As Max Bisection is hard to approximate within under the Unique Games Conjecture (UGC), our algorithm is nearly optimal. We conjecture that Max Bisection is approximable within , i.e., the bisection constraint (essentially) does not make Max Cut harder. We also obtain an optimal algorithm (assuming the UGC) for the analogous variant of Max 2-Sat. Our approximation ratio for this problem exactly matches the optimal approximation ratio for Max 2-Sat, i.e., , showing that the bisection constraint does not make Max 2-Sat harder. This improves on a 0.93-approximation for this problem due to Raghavendra and Tan.',
	 'authors': u'Per Austrin, Siavosh Benabbas, Konstantinos Georgiou,',
	 'category': u'Computer Science ',
	 'date': '2012-5-2',
	 'pdflink': u'http://arxiv.org/pdf/1205.0458',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nBetter Balance by Being Biased: A 0.8776-Approximation for Max Bisection',
	 'urllink': u'http://arxiv.org/abs/1205.0458'}
2015-03-23 22:58:08+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.6388> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:58:08+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.6388>
	{'abstract': u'Cognitive dissonance is the stress that comes from holding two conflicting thoughts simultaneously in the mind, usually arising when people are asked to choose between two detrimental or two beneficial options. In view of the well-established role of emotions in decision making, here we investigate whether the conventional structural models used to represent the relationships among basic emotions, such as the Circumplex model of affect, can describe the emotions of cognitive dissonance as well. We presented a questionnaire to 34 anonymous participants, where each question described a decision to be made among two conflicting motivations and asked the participants to rate analogically the pleasantness and the intensity of the experienced emotion. We found that the results were compatible with the predictions of the Circumplex model for basic emotions.',
	 'authors': u'Jose F. Fontanari, Marie-Claude Bonniot-Cabanac, Michel Cabanac, Leonid I. Perlovsky,',
	 'category': u'Computer Science ',
	 'date': '2012-2-28',
	 'pdflink': u'http://arxiv.org/pdf/1202.6388',
	 'subjects': u'Neurons and Cognition (q-bio.NC)',
	 'title': u'\nA structural model of emotions of cognitive dissonances',
	 'urllink': u'http://arxiv.org/abs/1202.6388'}
2015-03-23 22:58:20+0000 [xxu46_4] INFO: Crawled 270 pages (at 4 pages/min), scraped 264 items (at 4 items/min)
2015-03-23 22:58:24+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0136> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:58:24+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0136>
	{'abstract': u'In several online prediction problems of recent interest the comparison class is composed of matrices with bounded entries. For example, in the online max-cut problem, the comparison class is matrices which represent cuts of a given graph and in online gambling the comparison class is matrices which represent permutations over n teams. Another important example is online collaborative filtering in which a widely used comparison class is the set of matrices with a small trace norm. In this paper we isolate a property of matrices, which we call (beta,tau)-decomposability, and derive an efficient online learning algorithm, that enjoys a regret bound of O*(sqrt(beta tau T)) for all problems in which the comparison class is composed of (beta,tau)-decomposable matrices. By analyzing the decomposability of cut matrices, triangular matrices, and low trace-norm matrices, we derive near optimal regret bounds for online max-cut, online gambling, and online collaborative filtering. In particular, this resolves (in the affirmative) an open problem posed by Abernethy (2010); Kleinberg et al (2010). Finally, we derive lower bounds for the three problems and show that our upper bounds are optimal up to logarithmic factors. In particular, our lower bound for the online collaborative filtering problem resolves another open problem posed by Shamir and Srebro (2011).',
	 'authors': u'Elad Hazan, Satyen Kale, Shai Shalev-Shwartz,',
	 'category': u'Computer Science ',
	 'date': '2012-3-31',
	 'pdflink': u'http://arxiv.org/pdf/1204.0136',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nNear-Optimal Algorithms for Online Matrix Prediction',
	 'urllink': u'http://arxiv.org/abs/1204.0136'}
2015-03-23 22:58:42+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0456> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:58:42+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0456>
	{'abstract': u'Borel-fixed ideals play a key role in the study of Hilbert schemes. Indeed each component and each intersection of components of a Hilbert scheme contains at least one Borel-fixed point, i.e. a point corresponding to a subscheme defined by a Borel-fixed ideal. Moreover Borel-fixed ideals have good combinatorial properties, which make them very interesting in an algorithmic perspective. In this paper, we propose an implementation of the algorithm computing all the saturated Borel-fixed ideals with number of variables and Hilbert polynomial assigned, introduced from a theoretical point of view in the paper "Segment ideals and Hilbert schemes of points", Discrete Mathematics 311 (2011).',
	 'authors': u'Paolo Lella,',
	 'category': u'Computer Science ',
	 'date': '2012-5-2',
	 'pdflink': u'http://arxiv.org/pdf/1205.0456',
	 'subjects': u'Symbolic Computation (cs.SC)',
	 'title': u'\nAn efficient implementation of the algorithm computing the Borel-fixed  points of a Hilbert scheme',
	 'urllink': u'http://arxiv.org/abs/1205.0456'}
2015-03-23 22:58:56+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.1204> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 22:58:56+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.1204>
	{'abstract': u'Due to the inherent aleatory uncertainties in renewable generators, the reliability/adequacy assessments of distributed generation (DG) systems have been particularly focused on the probabilistic modeling of random behaviors, given sufficient informative data. However, another type of uncertainty (epistemic uncertainty) must be accounted for in the modeling, due to incomplete knowledge of the phenomena and imprecise evaluation of the related characteristic parameters. In circumstances of few informative data, this type of uncertainty calls for alternative methods of representation, propagation, analysis and interpretation. In this study, we make a first attempt to identify, model, and jointly propagate aleatory and epistemic uncertainties in the context of DG systems modeling for adequacy assessment. Probability and possibility distributions are used to model the aleatory and epistemic uncertainties, respectively. Evidence theory is used to incorporate the two uncertainties under a single framework. Based on the plausibility and belief functions of evidence theory, the hybrid propagation approach is introduced. A demonstration is given on a DG system adapted from the IEEE 34 nodes distribution test feeder. Compared to the pure probabilistic approach, it is shown that the hybrid propagation is capable of explicitly expressing the imprecision in the knowledge on the DG parameters into the final adequacy values assessed. It also effectively captures the growth of uncertainties with higher DG penetration levels.',
	 'authors': u'Yanfu Li, Enrico Zio,',
	 'category': u'Computer Science ',
	 'date': '2012-6-6',
	 'pdflink': u'http://arxiv.org/pdf/1206.1204',
	 'subjects': u'Performance (cs.PF)',
	 'title': u'\nUncertainty Analysis of the Adequacy Assessment Model of a Distributed  Generation System',
	 'urllink': u'http://arxiv.org/abs/1206.1204'}
2015-03-23 22:59:14+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.6350> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 22:59:14+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.6350>
	{'abstract': u'We introduce a class of finite tight frames called prime tight frames and prove some of their elementary properties. In particular, we show that any finite tight frame can be written as a union of prime tight frames. We then characterize all prime harmonic tight frames and use this characterization to suggest effective analysis and synthesis computation strategies for such frames. Finally, we describe all prime frames constructed from the spectral tetris method, and, as a byproduct, we obtain a characterization of when the spectral tetris construction works for redundancies below two.',
	 'authors': u'Jakob Lemvig, Christopher Miller, Kasso A. Okoudjou,',
	 'category': u'Computer Science ',
	 'date': '2012-2-28',
	 'pdflink': u'http://arxiv.org/pdf/1202.6350',
	 'subjects': u'Functional Analysis (math.FA)',
	 'title': u'\nPrime tight frames',
	 'urllink': u'http://arxiv.org/abs/1202.6350'}
2015-03-23 22:59:20+0000 [xxu46_4] INFO: Crawled 274 pages (at 4 pages/min), scraped 268 items (at 4 items/min)
2015-03-23 22:59:31+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0133> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 22:59:31+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0133>
	{'abstract': u'In this paper, we propose a progressive Bayesian procedure, where the measurement information is continuously included into the given prior estimate (although we perform observations at discrete time steps). The key idea is to derive a system of ordinary first-order differential equations (ODE) by employing a new coupled density representation comprising a Gaussian density and its Dirac Mixture approximation. The ODE is used for continuously tracking the true non-Gaussian posterior by its best matching Gaussian approximation. The performance of the new filter is evaluated in comparison with state-of-the-art filters by means of a canonical benchmark example, the discrete-time cubic sensor problem.',
	 'authors': u'Uwe D. Hanebeck, Jannik Steinbring,',
	 'category': u'Computer Science ',
	 'date': '2012-3-31',
	 'pdflink': u'http://arxiv.org/pdf/1204.0133',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nProgressive Gaussian Filtering',
	 'urllink': u'http://arxiv.org/abs/1204.0133'}
2015-03-23 22:59:42+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0451> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 22:59:42+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0451>
	{'abstract': u"Smartphones have recently gained significant popularity in heavy mobile processing while users are increasing their expectations toward rich computing experience. However, resource limitations and current mobile computing advancements hinder this vision. Therefore, resource-intensive application execution remains a challenging task in mobile computing that necessitates device augmentation. In this article, smartphone augmentation approaches are reviewed and classified in two main groups, namely hardware and software. Generating high-end hardware is a subset of hardware augmentation approaches, whereas conserving local resource and reducing resource requirements approaches are grouped under software augmentation methods. Our study advocates that consreving smartphones' native resources, which is mainly done via task offloading, is more appropriate for already-developed applications than new ones, due to costly re-development process. Cloud computing has recently obtained momentous ground as one of the major cornerstone technologies in augmenting smartphones. We present sample execution model for intensive mobile applications and devised taxonomy of augmentation approaches. For better comprehension, the results of this study are summarized in a table.",
	 'authors': u'Saeid Abolfazli, Zohreh Sanaei, Abdullah Gani,',
	 'category': u'Computer Science ',
	 'date': '2012-5-2',
	 'pdflink': u'http://arxiv.org/pdf/1205.0451',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nMobile Cloud Computing: A Review on Smartphone Augmentation Approaches',
	 'urllink': u'http://arxiv.org/abs/1205.0451'}
2015-03-23 22:59:58+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.1188> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 22:59:58+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.1188>
	{'abstract': u"The Maskin's theorem is a fundamental work in the theory of mechanism design. In this paper, we propose that if agents report messages to the designer through channels (e.g., Internet), agents can construct a self-enforcing agreement such that any Pareto-inefficient social choice rule satisfying monotonicity and no-veto will not be Nash implementable when an additional condition is satisfied. The key points are: 1) The agreement is unobservable to the designer, and the designer cannot prevent the agents from constructing such agreement; 2) The agents act non-cooperatively, and the Maskin mechanism remain unchanged from the designer's perspective.",
	 'authors': u'Haoyang Wu,',
	 'category': u'Computer Science ',
	 'date': '2012-6-6',
	 'pdflink': u'http://arxiv.org/pdf/1206.1188',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nTraditional sufficient conditions for Nash implementation may fail on  Internet',
	 'urllink': u'http://arxiv.org/abs/1206.1188'}
2015-03-23 23:00:12+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0131> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:00:12+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0131>
	{'abstract': u'We introduce a new symbolic representation based on an original generalization of counter abstraction. Unlike classical counter abstraction (used in the analysis of parameterized systems with unordered or unstructured topologies) the new representation is tailored for proving properties of linearly ordered parameterized systems, i.e., systems with arbitrary many finite processes placed in an array. The relative positions in the array capture the relative priorities of the processes. Configurations of such systems are finite words of arbitrary lengths. The processes communicate using global transitions constrained by their relative priorities. Intuitively, an element of the symbolic representation has a base and a set of counters. It denotes configurations that respect the constraints imposed by the counters and that have the base as a sub word. We use the new representation in a uniform and automatic Counter Example Guided Refinement scheme. We introduce a relaxation operator that allows a well quasi ordering argument for the termination of each iteration of the refinement loop. We explain how to refine the relaxation to systematically prune out false positives. We implemented a tool to illustrate the approach on a number of parameterized systems.',
	 'authors': u'Ahmed Rezine,',
	 'category': u'Computer Science ',
	 'date': '2012-3-31',
	 'pdflink': u'http://arxiv.org/pdf/1204.0131',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nOrdered Counter-Abstraction',
	 'urllink': u'http://arxiv.org/abs/1204.0131'}
2015-03-23 23:00:20+0000 [xxu46_4] INFO: Crawled 278 pages (at 4 pages/min), scraped 272 items (at 4 items/min)
2015-03-23 23:00:26+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0439> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:00:26+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0439>
	{'abstract': u"In today's world of computers, dealing with huge amounts of data is not unusual. The need to distribute this data in order to increase its availability and increase the performance of accessing it is more urgent than ever. For these reasons it is necessary to develop scalable distributed data structures. In this paper we propose a TH* distributed variant of the Trie Hashing data structure. First we propose Thsw new version of TH without node Nil in digital tree (trie), then this version will be adapted to multicomputer environment. The simulation results reveal that TH* is scalable in the sense that it grows gracefully, one bucket at a time, to a large number of servers, also TH* offers a good storage space utilization and high query efficiency special for ordering operations.",
	 'authors': u'Aridj Mohamed, Zegour Djamel Eddine,',
	 'category': u'Computer Science ',
	 'date': '2012-5-2',
	 'pdflink': u'http://arxiv.org/pdf/1205.0439',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nTH*:Scalable Distributed Trie Hashing',
	 'urllink': u'http://arxiv.org/abs/1205.0439'}
2015-03-23 23:00:43+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.1187> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:00:43+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.1187>
	{'abstract': u"Pseudorandom number generators are required for many computational tasks, such as stochastic modelling and simulation. This paper investigates the serial CPU and parallel GPU implementation of a Linear Congruential Generator based on the binary representation of the normal number . We adapted two methods of modular reduction which allowed us to perform most operations in 64-bit integer arithmetic, improving on the original implementation based on 106-bit double-double operations. We found that our implementation is faster than existing methods in literature, and our generation rate is close to the limiting rate imposed by the efficiency of writing to a GPU's global memory.",
	 'authors': u'Gleb Beliakov, Michael Johnstone, Doug Creighton, Tim Wilkin,',
	 'category': u'Computer Science ',
	 'date': '2012-6-6',
	 'pdflink': u'http://arxiv.org/pdf/1206.1187',
	 'subjects': u'Mathematical Software (cs.MS)',
	 'title': u'\nParallel random variates generator for GPUs based on normal numbers',
	 'urllink': u'http://arxiv.org/abs/1206.1187'}
2015-03-23 23:01:00+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.6344> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:01:00+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.6344>
	{'abstract': u'This paper focuses on effectivity aspects of the L "uroth\'s theorem in differential fields. Let be an ordinary differential field of characteristic 0 and be the field of differential rational functions generated by a single indeterminate . Let be given non constant rational functions generating a differential subfield . The differential L "uroth\'s theorem proved by Ritt in 1932 states that there exists such that . Here we prove that the total order and degree of a generator are bounded by and , respectively, where and . As a byproduct, our techniques enable us to compute a L "uroth generator by dealing with a polynomial ideal in a polynomial ring in finitely many variables.',
	 'authors': u"Lisi D'Alfonso, Gabriela Jeronimo, Pablo Solern\xf3,",
	 'category': u'Computer Science ',
	 'date': '2012-2-28',
	 'pdflink': u'http://arxiv.org/pdf/1202.6344',
	 'subjects': u'Commutative Algebra (math.AC)',
	 'title': u"\nEffective Differential L\xfcroth's Theorem",
	 'urllink': u'http://arxiv.org/abs/1202.6344'}
2015-03-23 23:01:14+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0128> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:01:14+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0128>
	{'abstract': u'We present an analysis of user conversations in on-line social media and their evolution over time. We propose a dynamic model that accurately predicts the growth dynamics and structural properties of conversation threads. The model successfully reconciles the differing observations that have been reported in existing studies. By separating artificial factors from user behaviors, we show that there are actually underlying rules in common for on-line conversations in different social media websites. Results of our model are supported by empirical measurements throughout a number of different social media websites.',
	 'authors': u'Chunyan Wang, Mao Ye, Bernardo A. Huberman,',
	 'category': u'Computer Science ',
	 'date': '2012-3-31',
	 'pdflink': u'http://arxiv.org/pdf/1204.0128',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nFrom User Comments to On-line Conversations',
	 'urllink': u'http://arxiv.org/abs/1204.0128'}
2015-03-23 23:01:20+0000 [xxu46_4] INFO: Crawled 282 pages (at 4 pages/min), scraped 276 items (at 4 items/min)
2015-03-23 23:01:29+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0435> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:01:29+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0435>
	{'abstract': u'Social coordination allows users to move beyond awareness of their friends to efficiently coordinating physical activities with others. While specific forms of social coordination can be seen in tools such as Evite, Meetup and Groupon, we introduce a more general model using what we call enmeshed queries. An enmeshed query allows users to declaratively specify an intent to coordinate by specifying social attributes such as the desired group size and who/what/when, and the database returns matching queries. Enmeshed queries are continuous, but new queries (and not data) answer older queries; the variable group size also makes enmeshed queries different from entangled queries, publish-subscribe systems, and dating services. We show that even offline group coordination using enmeshed queries is NP-hard. We then introduce efficient heuristics that use selective indices such as location and time to reduce the space of possible matches; we also add refinements such as delayed evaluation and using the relative matchability of users to determine search order. We describe a centralized implementation and evaluate its performance against an optimal algorithm. We show that the combination of not stopping prematurely (after finding a match) and delayed evaluation results in an algorithm that finds 86% of the matches found by an optimal algorithm, and takes an average of 40 usec per query using 1 core of a 2.5 Ghz server machine. Further, the algorithm has good latency, is reasonably fair to large group size requests, and can be scaled to global workloads using multiple cores and multiple servers. We conclude by describing potential generalizations that add prices, recommendations, and data mining to basic enmeshed queries.',
	 'authors': u'Jianjun Chen, Ashwin Machanavajjhala, George Varghese,',
	 'category': u'Computer Science ',
	 'date': '2012-5-2',
	 'pdflink': u'http://arxiv.org/pdf/1205.0435',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nScalable Social Coordination using Enmeshed Queries',
	 'urllink': u'http://arxiv.org/abs/1205.0435'}
2015-03-23 23:01:45+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.1148> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:01:45+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.1148>
	{'abstract': u'In this paper, we first give a high-level overview of medical visualization development over the past 30 years, focusing on key developments and the trends that they represent. During this discussion, we will refer to a number of key papers that we have also arranged on the medical visualization research timeline. Based on the overview and our observations of the field, we then identify and discuss the medical visualization research challenges that we foresee for the coming decade.',
	 'authors': u'Charl P. Botha, Bernhard Preim, Arie Kaufman, Shigeo Takahashi, Anders Ynnerman,',
	 'category': u'Computer Science ',
	 'date': '2012-6-6',
	 'pdflink': u'http://arxiv.org/pdf/1206.1148',
	 'subjects': u'Graphics (cs.GR)',
	 'title': u'\nFrom individual to population: Challenges in Medical Visualization',
	 'urllink': u'http://arxiv.org/abs/1206.1148'}
2015-03-23 23:01:59+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.6321> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:01:59+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.6321>
	{'abstract': u'We prove that the spectral gap of the Swendsen-Wang dynamics for the random-cluster model on arbitrary graphs with m edges is bounded above by 16 m log m times the spectral gap of the single-bond (or heat-bath) dynamics. This and the corresponding lower bound imply that rapid mixing of these two dynamics is equivalent. Using the known lower bound on the spectral gap of the Swendsen-Wang dynamics for the two dimensional square lattice of side length L at high temperatures and a result for the single-bond dynamics on dual graphs, we obtain rapid mixing of both dynamics on at all non-critical temperatures. In particular this implies, as far as we know, the first proof of rapid mixing of a classical Markov chain for the Ising model on at all temperatures.',
	 'authors': u'Mario Ullrich,',
	 'category': u'Computer Science ',
	 'date': '2012-2-28',
	 'pdflink': u'http://arxiv.org/pdf/1202.6321',
	 'subjects': u'Probability (math.PR)',
	 'title': u'\nRapid mixing of Swendsen-Wang and single-bond dynamics in two dimensions',
	 'urllink': u'http://arxiv.org/abs/1202.6321'}
2015-03-23 23:02:16+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0111> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:02:16+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0111>
	{'abstract': u'A parallelization of a sweeping preconditioner for 3D Helmholtz equations without large cavities is introduced and benchmarked for several challenging velocity models. The setup and application costs of the sequential preconditioner are shown to be O(^2 N^) and O( N log N), where () denotes the modestly frequency-dependent number of grid points per Perfectly Matched Layer. Several computational and memory improvements are introduced relative to using black-box sparse-direct solvers for the auxiliary problems, and competitive runtimes and iteration counts are reported for high-frequency problems distributed over thousands of cores. Two open-source packages are released along with this paper: "Parallel Sweeping Preconditioner (PSP)" and the underlying distributed multifrontal solver, "Clique".',
	 'authors': u'Jack Poulson, Bj\xf6rn Engquist, Siwei Li, Lexing Ying,',
	 'category': u'Computer Science ',
	 'date': '2012-3-31',
	 'pdflink': u'http://arxiv.org/pdf/1204.0111',
	 'subjects': u'Numerical Analysis (cs.NA)',
	 'title': u'\nA parallel sweeping preconditioner for heterogeneous 3D Helmholtz  equations',
	 'urllink': u'http://arxiv.org/abs/1204.0111'}
2015-03-23 23:02:20+0000 [xxu46_4] INFO: Crawled 286 pages (at 4 pages/min), scraped 280 items (at 4 items/min)
2015-03-23 23:02:28+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0411> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:02:28+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0411>
	{'abstract': u'We provide a unifying framework linking two classes of statistics used in two-sample and independence testing: on the one hand, the energy distances and distance covariances from the statistics literature; on the other, distances between embeddings of distributions to reproducing kernel Hilbert spaces (RKHS), as established in machine learning. The equivalence holds when energy distances are computed with semimetrics of negative type, in which case a kernel may be defined such that the RKHS distance between distributions corresponds exactly to the energy distance. We determine the class of probability distributions for which kernels induced by semimetrics are characteristic (that is, for which embeddings of the distributions to an RKHS are injective). Finally, we investigate the performance of this family of kernels in two-sample and independence tests: we show in particular that the energy distance most commonly employed in statistics is just one member of a parametric family of kernels, and that other choices from this family can yield more powerful tests.',
	 'authors': u'Dino Sejdinovic, Arthur Gretton, Bharath Sriperumbudur, Kenji Fukumizu,',
	 'category': u'Computer Science ',
	 'date': '2012-5-2',
	 'pdflink': u'http://arxiv.org/pdf/1205.0411',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nHypothesis testing using pairwise distances and associated kernels (with  Appendix)',
	 'urllink': u'http://arxiv.org/abs/1205.0411'}
2015-03-23 23:02:44+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.1147> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:02:44+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.1147>
	{'abstract': u'As one of the simplest probabilistic topic modeling techniques, latent Dirichlet allocation (LDA) has found many important applications in text mining, computer vision and computational biology. Recent training algorithms for LDA can be interpreted within a unified message passing framework. However, message passing requires storing previous messages with a large amount of memory space, increasing linearly with the number of documents or the number of topics. Therefore, the high memory usage is often a major problem for topic modeling of massive corpora containing a large number of topics. To reduce the space complexity, we propose a novel algorithm without storing previous messages for training LDA: tiny belief propagation (TBP). The basic idea of TBP relates the message passing algorithms with the non-negative matrix factorization (NMF) algorithms, which absorb the message updating into the message passing process, and thus avoid storing previous messages. Experimental results on four large data sets confirm that TBP performs comparably well or even better than current state-of-the-art training algorithms for LDA but with a much less memory consumption. TBP can do topic modeling when massive corpora cannot fit in the computer memory, for example, extracting thematic topics from 7 GB PUBMED corpora on a common desktop computer with 2GB memory.',
	 'authors': u'Jia Zeng, Zhi-Qiang Liu, Xiao-Qin Cao,',
	 'category': u'Computer Science ',
	 'date': '2012-6-6',
	 'pdflink': u'http://arxiv.org/pdf/1206.1147',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nMemory-Efficient Topic Modeling',
	 'urllink': u'http://arxiv.org/abs/1206.1147'}
2015-03-23 23:03:01+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.6258> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:03:01+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.6258>
	{'abstract': u'We propose a new stochastic gradient method for optimizing the sum of a finite set of smooth functions, where the sum is strongly convex. While standard stochastic gradient methods converge at sublinear rates for this problem, the proposed method incorporates a memory of previous gradient values in order to achieve a linear convergence rate. In a machine learning context, numerical experiments indicate that the new algorithm can dramatically outperform standard algorithms, both in terms of optimizing the training error and reducing the test error quickly.',
	 'authors': u'Nicolas Le Roux, Mark Schmidt, Francis Bach,',
	 'category': u'Computer Science ',
	 'date': '2012-2-28',
	 'pdflink': u'http://arxiv.org/pdf/1202.6258',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nA Stochastic Gradient Method with an Exponential Convergence Rate for  Finite Training Sets',
	 'urllink': u'http://arxiv.org/abs/1202.6258'}
2015-03-23 23:03:16+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0094> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:03:16+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0094>
	{'abstract': u'We propose to demonstrate a mobile server assisted P2P system for on-demand video streaming. Our proposed solution uses a combination of 3G and ad-hoc Wi-Fi connections, to enable mobile devices to download content from a centralised server in a way that minimises the 3G bandwidth use and cost. On the customised GUI, we show the corresponding reduction in 3G bandwidth achieved by increasing the number of participating mobile devices in the combined P2P and ad-hoc Wi- Fi network, while demonstrating the good video playout quality on each of the mobiles. We also demonstrate the implemented trust mechanism which enables mobiles to only use trusted adhoc connections. The system has been implemented on Android based smartphones.',
	 'authors': u'Thava Iyer, Robert Hsieh, Nikzad Babaii Rizvandi, Benoy Varghese, Roksana Boreli,',
	 'category': u'Computer Science ',
	 'date': '2012-3-31',
	 'pdflink': u'http://arxiv.org/pdf/1204.0094',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nMobile P2P Trusted On-Demand Video Streaming',
	 'urllink': u'http://arxiv.org/abs/1204.0094'}
2015-03-23 23:03:20+0000 [xxu46_4] INFO: Crawled 290 pages (at 4 pages/min), scraped 284 items (at 4 items/min)
2015-03-23 23:03:34+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0406> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:03:34+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0406>
	{'abstract': u'Many studies on the cost-sensitive learning assumed that a unique cost matrix is known for a problem. However, this assumption may not hold for many real-world problems. For example, a classifier might need to be applied in several circumstances, each of which associates with a different cost matrix. Or, different human experts have different opinions about the costs for a given problem. Motivated by these facts, this study aims to seek the minimax classifier over multiple cost matrices. In summary, we theoretically proved that, no matter how many cost matrices are involved, the minimax problem can be tackled by solving a number of standard cost-sensitive problems and sub-problems that involve only two cost matrices. As a result, a general framework for achieving minimax classifier over multiple cost matrices is suggested and justified by preliminary empirical studies.',
	 'authors': u'Rui Wang, Ke Tang,',
	 'category': u'Computer Science ',
	 'date': '2012-5-2',
	 'pdflink': u'http://arxiv.org/pdf/1205.0406',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nMinimax Classifier for Uncertain Costs',
	 'urllink': u'http://arxiv.org/abs/1205.0406'}
2015-03-23 23:03:51+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.1145> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:03:51+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.1145>
	{'abstract': u"The goal of this paper is to critically evaluate a heuristic algorithm for the Inverse Banzhaf Index problem by Laruelle and Widgr 'en. Few qualitative results are known about the approximation quality of the heuristics for this problem. The intuition behind the operation of this approximation algorithm is analysed and evaluated. We found that the algorithm can not handle general inputs well, and often fails to improve inputs. It is also shown to diverge after only tens of iterations. We present three alternative extensions of the algorithm that do not alter the complexity but can result in up to a factor 6.5 improvement in solution quality.",
	 'authors': u'Frits de Nijs, Daan Wilmer,',
	 'category': u'Computer Science ',
	 'date': '2012-6-6',
	 'pdflink': u'http://arxiv.org/pdf/1206.1145',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nEvaluation and Improvement of Laruelle-Widgr\xe9n Inverse Banzhaf  Approximation',
	 'urllink': u'http://arxiv.org/abs/1206.1145'}
2015-03-23 23:04:02+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.6228> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:04:02+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.6228>
	{'abstract': u'In this work, we propose a PAC-Bayes bound for the generalization risk of the Gibbs classifier in the multi-class classification framework. The novelty of our work is the critical use of the confusion matrix of a classifier as an error measure; this puts our contribution in the line of work aiming at dealing with performance measure that are richer than mere scalar criterion such as the misclassification rate. Thanks to very recent and beautiful results on matrix concentration inequalities, we derive two bounds showing that the true confusion risk of the Gibbs classifier is upper-bounded by its empirical risk plus a term depending on the number of training examples in each class. To the best of our knowledge, this is the first PAC-Bayes bounds based on confusion matrices.',
	 'authors': u'Emilie Morvant, Sokol Ko\xe7o, Liva Ralaivola,',
	 'category': u'Computer Science ',
	 'date': '2012-2-28',
	 'pdflink': u'http://arxiv.org/pdf/1202.6228',
	 'subjects': u'Machine Learning (stat.ML)',
	 'title': u'\nPAC-Bayesian Generalization Bound on Confusion Matrix for Multi-Class  Classification',
	 'urllink': u'http://arxiv.org/abs/1202.6228'}
2015-03-23 23:04:16+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0078> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:04:16+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0078>
	{'abstract': u'We consider the computational aspects of lossy data compression problem, where the compression error is determined by a cover of the data space. We propose an algorithm which reduces the number of partitions needed to find the entropy with respect to the compression error. In particular, we show that, in the case of finite cover, the entropy is attained on some partition. We give an algorithmic construction of such partition.',
	 'authors': u'Marek \u015amieja, Jacek Tabor,',
	 'category': u'Computer Science ',
	 'date': '2012-3-31',
	 'pdflink': u'http://arxiv.org/pdf/1204.0078',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nPartition Reduction for Lossy Data Compression Problem',
	 'urllink': u'http://arxiv.org/abs/1204.0078'}
2015-03-23 23:04:20+0000 [xxu46_4] INFO: Crawled 294 pages (at 4 pages/min), scraped 288 items (at 4 items/min)
2015-03-23 23:04:33+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0376> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:04:33+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0376>
	{'abstract': u'Deciding in an efficient way weak probabilistic bisimulation in the context of Probabilistic Automata is an open problem for about a decade. In this work we close this problem by proposing a procedure that checks in polynomial time the existence of a weak combined transition satisfying the step condition of the bisimulation. We also present several extensions of weak combined transitions, such as hyper-transitions and the new concepts of allowed weak combined and hyper-transitions and of equivalence matching, that turn out to be verifiable in polynomial time as well. These results set the ground for the development of more effective compositional analysis algorithms for probabilistic systems.',
	 'authors': u'Holger Hermanns, Andrea Turrini,',
	 'category': u'Computer Science ',
	 'date': '2012-5-2',
	 'pdflink': u'http://arxiv.org/pdf/1205.0376',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nDeciding Probabilistic Automata Weak Bisimulation in Polynomial Time',
	 'urllink': u'http://arxiv.org/abs/1205.0376'}
2015-03-23 23:04:44+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.1134> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:04:44+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.1134>
	{'abstract': u'We consider the problem of answering point-to-point shortest path queries on massive social networks. The goal is to answer queries within tens of milliseconds while minimizing the memory requirements. We present a technique that achieves this goal for an extremely large fraction of path queries by exploiting the structure of the social networks. Using evaluations on real-world datasets, we argue that our technique offers a unique trade-off between latency, memory and accuracy. For instance, for the LiveJournal social network (roughly 5 million nodes and 69 million edges), our technique can answer 99.9% of the queries in less than a millisecond. In comparison to storing all pair shortest paths, our technique requires at least 550x less memory; the average query time is roughly 365 microseconds --- 430x faster than the state-of-the-art shortest path algorithm. Furthermore, the relative performance of our technique improves with the size (and density) of the network. For the Orkut social network (3 million nodes and 220 million edges), for instance, our technique is roughly 2588x faster than the state-of-the-art algorithm for computing shortest paths.',
	 'authors': u'Rachit Agarwal, Matthew Caesar, P. Brighten Godfrey, Ben Y. Zhao,',
	 'category': u'Computer Science ',
	 'date': '2012-6-6',
	 'pdflink': u'http://arxiv.org/pdf/1206.1134',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nShortest Paths in Less Than a Millisecond',
	 'urllink': u'http://arxiv.org/abs/1206.1134'}
2015-03-23 23:05:00+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.6219> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:05:00+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.6219>
	{'abstract': u'A long-standing conjecture of Kelly states that every regular tournament on n vertices can be decomposed into (n-1)/2 edge-disjoint Hamilton cycles. We prove this conjecture for large n. In fact, we prove a far more general result, based on our recent concept of robust expansion and a new method for decomposing graphs. We show that every sufficiently large regular digraph G on n vertices whose degree is linear in n and which is a robust outexpander has a decomposition into edge-disjoint Hamilton cycles. This enables us to obtain numerous further results, e.g. as a special case we confirm a conjecture of Erdos on packing Hamilton cycles in random tournaments. As corollaries to the main result, we also obtain several results on packing Hamilton cycles in undirected graphs, giving e.g. the best known result on a conjecture of Nash-Williams. We also apply our result to solve a problem on the domination ratio of the Asymmetric Travelling Salesman problem, which was raised e.g. by Glover and Punnen as well as Alon, Gutin and Krivelevich.',
	 'authors': u'Daniela K\xfchn, Deryk Osthus,',
	 'category': u'Computer Science ',
	 'date': '2012-2-28',
	 'pdflink': u'http://arxiv.org/pdf/1202.6219',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u"\nHamilton decompositions of regular expanders: a proof of Kelly's  conjecture for large tournaments",
	 'urllink': u'http://arxiv.org/abs/1202.6219'}
2015-03-23 23:05:14+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0077> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:05:14+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0077>
	{'abstract': u'We consider the task of controlling in a distributed way a Zielonka asynchronous automaton. Every process of a controller has access to its causal past to determine the next set of actions it proposes to play. An action can be played only if every process controlling this action proposes to play it. We consider reachability objectives: every process should reach its set of final states. We show that this control problem is decidable for tree architectures, where every process can communicate with its parent, its children, and with the environment. The complexity of our algorithm is l-fold exponential with l being the height of the tree representing the architecture. We show that this is unavoidable by showing that even for three processes the problem is EXPTIME-complete, and that it is non-elementary in general.',
	 'authors': u'Blaise Genest, Hugo Gimbert, Anca Muscholl, Igor Walukiewicz,',
	 'category': u'Computer Science ',
	 'date': '2012-3-31',
	 'pdflink': u'http://arxiv.org/pdf/1204.0077',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nAsynchronous Games over Tree Architectures',
	 'urllink': u'http://arxiv.org/abs/1204.0077'}
2015-03-23 23:05:20+0000 [xxu46_4] INFO: Crawled 298 pages (at 4 pages/min), scraped 292 items (at 4 items/min)
2015-03-23 23:05:31+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0357> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:05:31+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0357>
	{'abstract': u'Term graph rewriting provides a simple mechanism to finitely represent restricted forms of infinitary term rewriting. The correspondence between infinitary term rewriting and term graph rewriting has been studied to some extent. However, this endeavour is impaired by the lack of an appropriate counterpart of infinitary rewriting on the side of term graphs. We aim to fill this gap by devising two modes of convergence based on a partial order respectively a metric on term graphs. The thus obtained structures generalise corresponding modes of convergence that are usually studied in infinitary term rewriting. We argue that this yields a common framework in which both term rewriting and term graph rewriting can be studied. In order to substantiate our claim, we compare convergence on term graphs and on terms. In particular, we show that the modes of convergence on term graphs are conservative extensions of the corresponding modes of convergence on terms and are preserved under unravelling term graphs to terms. Moreover, we show that many of the properties known from infinitary term rewriting are preserved. This includes the intrinsic completeness of both modes of convergence and the fact that convergence via the partial order is a conservative extension of the metric convergence.',
	 'authors': u'Patrick Bahr,',
	 'category': u'Computer Science ',
	 'date': '2012-5-2',
	 'pdflink': u'http://arxiv.org/pdf/1205.0357',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nModes of Convergence for Term Graph Rewriting',
	 'urllink': u'http://arxiv.org/abs/1205.0357'}
2015-03-23 23:05:49+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.6168> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:05:49+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.6168>
	{'abstract': u'The aim of this paper is to present a first evaluation of the potential of an asynchronous distributed computation associated to the recently proposed approach, D-iteration: the D-iteration is a fluid diffusion based iterative method, which has the advantage of being natively distributive. It exploits a simple intuitive decomposition of the matrix-vector product as elementary operations of fluid diffusion associated to a new algebraic representation. We show through experiments on real datasets how much this approach can improve the computation efficiency when the parallelism is applied: with the proposed solution, when the computation is distributed over virtual machines (PIDs), the memory size to be handled by each virtual machine decreases linearly with and the computation speed increases almost linearly with with a slope becoming closer to one when the number of linear equations to be solved increases.',
	 'authors': u'Dohy Hong,',
	 'category': u'Computer Science ',
	 'date': '2012-2-28',
	 'pdflink': u'http://arxiv.org/pdf/1202.6168',
	 'subjects': u'Numerical Analysis (math.NA)',
	 'title': u'\nD-iteration: Evaluation of the Asynchronous Distributed Computation',
	 'urllink': u'http://arxiv.org/abs/1202.6168'}
2015-03-23 23:06:06+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0075> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:06:06+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0075>
	{'abstract': u"R 'enyi entropy of order alpha is a general measure of entropy. In this paper we derive estimations for the R 'enyi entropy of the mixture of sources in terms of the entropy of the single sources. These relations allow to compute the R 'enyi entropy dimension of arbitrary order of a mixture of measures. The key for obtaining these results is our new definition of the weighted R 'enyi entropy. It is shown that weighted entropy is equal to the classical R 'enyi entropy.",
	 'authors': u'Marek \u015amieja, Jacek Tabor,',
	 'category': u'Computer Science ',
	 'date': '2012-3-31',
	 'pdflink': u'http://arxiv.org/pdf/1204.0075',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nWeighted Approach to R\xe9nyi Entropy',
	 'urllink': u'http://arxiv.org/abs/1204.0075'}
2015-03-23 23:06:20+0000 [xxu46_4] INFO: Crawled 301 pages (at 3 pages/min), scraped 295 items (at 3 items/min)
2015-03-23 23:06:24+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0345> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:06:24+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0345>
	{'abstract': u'An open question about Gabidulin codes is whether polynomial-time list decoding beyond half the minimum distance is possible or not. In this contribution, we give a lower and an upper bound on the list size, i.e., the number of codewords in a ball around the received word. The lower bound shows that if the radius of this ball is greater than the Johnson radius, this list size can be exponential and hence, no polynomial-time list decoding is possible. The upper bound on the list size uses subspace properties.',
	 'authors': u'Antonia Wachter-Zeh,',
	 'category': u'Computer Science ',
	 'date': '2012-5-2',
	 'pdflink': u'http://arxiv.org/pdf/1205.0345',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nBounds on List Decoding Gabidulin Codes',
	 'urllink': u'http://arxiv.org/abs/1205.0345'}
2015-03-23 23:06:41+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.1118> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:06:41+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.1118>
	{'abstract': u'Mobile Cloud Computing (MCC) which combines mobile computing and cloud computing, has become one of the industry buzz words and a major discussion thread in the IT world since 2009. As MCC is still at the early stage of development, it is necessary to grasp a thorough understanding of the technology in order to point out the direction of future research. With the latter aim, this paper presents a review on the background and principle of MCC, characteristics, recent research work, and future research trends. A brief account on the background of MCC: from mobile computing to cloud computing is presented and then followed with a discussion on characteristics and recent research work. It then analyses the features and infrastructure of mobile cloud computing. The rest of the paper analyses the challenges of mobile cloud computing, summary of some research projects related to this area, and points out promising future research directions.',
	 'authors': u'Han Qi, Abdullah Gani,',
	 'category': u'Computer Science ',
	 'date': '2012-6-6',
	 'pdflink': u'http://arxiv.org/pdf/1206.1118',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nResearch On Mobile Cloud Computing: Review, Trend, And Perspectives',
	 'urllink': u'http://arxiv.org/abs/1206.1118'}
2015-03-23 23:06:59+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.6163> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:06:59+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.6163>
	{'abstract': u'We consider deployment of the particle filter on modern massively parallel hardware architectures, such as Graphics Processing Units (GPUs), with a focus on the resampling stage. While standard multinomial and stratified resamplers require a sum of importance weights computed collectively between threads, a Metropolis resampler favourably requires only pair-wise ratios between weights, computed independently by threads, and can be further tuned for performance by adjusting its number of iterations. While achieving respectable results for the stratified and multinomial resamplers, we demonstrate that a Metropolis resampler can be faster where the variance in importance weights is modest, and so is worth considering in a performance-critical context, such as particle Markov chain Monte Carlo and real-time applications.',
	 'authors': u'Lawrence Murray,',
	 'category': u'Computer Science ',
	 'date': '2012-2-28',
	 'pdflink': u'http://arxiv.org/pdf/1202.6163',
	 'subjects': u'Computation (stat.CO)',
	 'title': u'\nGPU acceleration of the particle filter: the Metropolis resampler',
	 'urllink': u'http://arxiv.org/abs/1202.6163'}
2015-03-23 23:07:14+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0072> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:07:14+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0072>
	{'abstract': u'This paper further studies the fuzzy rough sets based on fuzzy coverings. We first present the notions of the lower and upper approximation operators based on fuzzy coverings and derive their basic properties. To facilitate the computation of fuzzy coverings for fuzzy covering rough sets, the concepts of fuzzy subcoverings, the reducible and intersectional elements, the union and intersection operations are provided and their properties are discussed in detail. Afterwards, we introduce the concepts of consistent functions and fuzzy covering mappings and provide a basic theoretical foundation for the communication between fuzzy covering information systems. In addition, the notion of homomorphisms is proposed to reveal the relationship between fuzzy covering information systems. We show how large-scale fuzzy covering information systems and dynamic fuzzy covering information systems can be converted into small-scale ones by means of homomorphisms. Finally, an illustrative example is employed to show that the attribute reduction can be simplified significantly by our proposed approach.',
	 'authors': u'Guangming Lang, Qingguo Li, Lankun Guo,',
	 'category': u'Computer Science ',
	 'date': '2012-3-31',
	 'pdflink': u'http://arxiv.org/pdf/1204.0072',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nGeneralized fuzzy rough sets based on fuzzy coverings',
	 'urllink': u'http://arxiv.org/abs/1204.0072'}
2015-03-23 23:07:20+0000 [xxu46_4] INFO: Crawled 305 pages (at 4 pages/min), scraped 299 items (at 4 items/min)
2015-03-23 23:07:32+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0343> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:07:32+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0343>
	{'abstract': u'In this paper we determine the exact values of the signed domination number, signed total domination number, and minus domination number of complete multipartite graphs, which substantially generalizes some previous results obtained for special subclasses of complete multipartite graphs such as cliques and complete bipartite graphs.',
	 'authors': u'Hongyu Liang,',
	 'category': u'Computer Science ',
	 'date': '2012-5-2',
	 'pdflink': u'http://arxiv.org/pdf/1205.0343',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nSigned and Minus Domination in Complete Multipartite Graphs',
	 'urllink': u'http://arxiv.org/abs/1205.0343'}
2015-03-23 23:07:44+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.1116> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:07:44+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.1116>
	{'abstract': u'In this paper, we design interference free transceivers for multi-user two-way relay systems, where a multi-antenna base station (BS) simultaneously exchanges information with multiple single-antenna users via a multi-antenna amplify-and-forward relay station (RS). To offer a performance benchmark and provide useful insight into the transceiver structure, we employ alternating optimization to find optimal transceivers at the BS and RS that maximizes the bidirectional sum rate. We then propose a low complexity scheme, where the BS transceiver is the zero-forcing precoder and detector, and the RS transceiver is designed to balance the uplink and downlink sum rates. Simulation results demonstrate that the proposed scheme is superior to the existing zero forcing and signal alignment schemes, and the performance gap between the proposed scheme and the alternating optimization is minor.',
	 'authors': u'Can Sun, Chenyang Yang, Yonghui Li, Branka Vucetic,',
	 'category': u'Computer Science ',
	 'date': '2012-6-6',
	 'pdflink': u'http://arxiv.org/pdf/1206.1116',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nTransceiver Design for Multi-user Multi-antenna Two-way Relay Cellular  Systems',
	 'urllink': u'http://arxiv.org/abs/1206.1116'}
2015-03-23 23:07:52+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.6144> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:07:52+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.6144>
	{'abstract': u'Cyber-physical systems integrate computation, communication, and physical capabilities to interact with the physical world and humans. Besides failures of components, cyber-physical systems are prone to malignant attacks, and specific analysis tools as well as monitoring mechanisms need to be developed to enforce system security and reliability. This paper proposes a unified framework to analyze the resilience of cyber-physical systems against attacks cast by an omniscient adversary. We model cyber-physical systems as linear descriptor systems, and attacks as exogenous unknown inputs. Despite its simplicity, our model captures various real-world cyber-physical systems, and it includes and generalizes many prototypical attacks, including stealth, (dynamic) false-data injection and replay attacks. First, we characterize fundamental limitations of static, dynamic, and active monitors for attack detection and identification. Second, we provide constructive algebraic conditions to cast undetectable and unidentifiable attacks. Third, by using the system interconnection structure, we describe graph-theoretic conditions for the existence of undetectable and unidentifiable attacks. Finally, we validate our findings through some illustrative examples with different cyber-physical systems, such as a municipal water supply network and two electrical power grids.',
	 'authors': u'Fabio Pasqualetti, Florian D\xf6rfler, Francesco Bullo,',
	 'category': u'Computer Science ',
	 'date': '2012-2-28',
	 'pdflink': u'http://arxiv.org/pdf/1202.6144',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nAttack Detection and Identification in Cyber-Physical Systems -- Part I:  Models and Fundamental Limitations',
	 'urllink': u'http://arxiv.org/abs/1202.6144'}
2015-03-23 23:08:05+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0067> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:08:05+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0067>
	{'abstract': u'We address the problem of estimating a rigid transformation between two point sets, which is a key module for target tracking system using Light Detection And Ranging (LiDAR). A fast implementation of Expectation-maximization (EM) algorithm is presented whose complexity is O(N) with the number of scan points.',
	 'authors': u'Shuqing Zeng,',
	 'category': u'Computer Science ',
	 'date': '2012-3-31',
	 'pdflink': u'http://arxiv.org/pdf/1204.0067',
	 'subjects': u'Robotics (cs.RO)',
	 'title': u'\nEstimating Rigid Transformation Between Two Range Maps Using Expectation  Maximization Algorithm',
	 'urllink': u'http://arxiv.org/abs/1204.0067'}
2015-03-23 23:08:20+0000 [xxu46_4] INFO: Crawled 309 pages (at 4 pages/min), scraped 303 items (at 4 items/min)
2015-03-23 23:08:23+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0337> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:08:23+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0337>
	{'abstract': u"From the viewpoint of service operators the Total Cost of Ownership (TCO) for developing a communication service comprises from two parts; CAPital EXpenditure (CAPEX) and OPerational EXpenditure (OPEX). These two types of costs are interrelated and affect any service provider's deployment strategy. In many traditional methods, selection of critical elements of a new service is performed in a heuristic manner aimed at reducing only the OPEX part of the TCO which is not necessarily optimal. Furthermore, exact cost modeling for such services is not always possible and contains some uncertainties. In the current work, after cost modeling of each video streaming element by capturing the effect of the model uncertainties, the TCO optimization problem for video streaming over IP networks is formulated as a stochastic optimization problem. The solution of the proposed optimization problem can cope with the cost modeling uncertainties and track the dynamism in the TCO and lead to a time-varying optimal solution. Numerical analysis results verify the developed method.",
	 'authors': u'Pejman Goudarzi,',
	 'category': u'Computer Science ',
	 'date': '2012-5-2',
	 'pdflink': u'http://arxiv.org/pdf/1205.0337',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nStochastic TCO minimization for Video Transmission over IP Networks',
	 'urllink': u'http://arxiv.org/abs/1205.0337'}
2015-03-23 23:08:39+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.1113> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:08:39+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.1113>
	{'abstract': u'A fundamental problem in wireless networks is the emph (MST) problem: given a set of wireless nodes, compute a spanning tree , so that the total cost of is minimized. In recent years, there has been a lot of interest in the physical interference model based on SINR constraints. Distributed algorithms are especially challenging in the SINR model, because of the non-locality of the model. In this paper, we develop a fast distributed approximation algorithm for MST construction in an SINR based distributed computing model. For an -node network, our algorithm\'s running time is and produces a spanning tree whose cost is within times the optimal (MST cost), where denotes the diameter of the disk graph obtained by using the maximum possible transmission range, and denotes the "distance diversity" w.r.t. the largest and smallest distances between two nodes. (When is -polynomial, .) Our algorithm\'s running time is essentially optimal (upto a logarithmic factor), since computing spanning tree takes time; thus our algorithm produces a low cost spanning tree in time only a logarithmic factor more than the time to compute a spanning tree. The distributed scheduling complexity of the spanning tree resulted from our algorithm is . Our algorithmic design techniques can be useful in designing efficient distributed algorithms for related "global" problems in wireless networks in the SINR model.',
	 'authors': u'Maleq Khan, V.S. Anil Kumar, Gopal Pandurangan, Guanhong Pei,',
	 'category': u'Computer Science ',
	 'date': '2012-6-6',
	 'pdflink': u'http://arxiv.org/pdf/1206.1113',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nA Fast Distributed Approximation Algorithm for Minimum Spanning Trees in  the SINR Model',
	 'urllink': u'http://arxiv.org/abs/1206.1113'}
2015-03-23 23:08:57+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.6129> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:08:57+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.6129>
	{'abstract': u'A proper edge coloring of a graph is called acyclic if there is no bichromatic cycle in . The acyclic chromatic index of , denoted by , is the least number of colors such that has an acyclic edge -coloring. The maximum average degree of a graph , denoted by , is the maximum of the average degree of all subgraphs of . In this paper, it is proved that if , then ; if , then . This implies that every triangle-free planar graph is acyclically edge -colorable.',
	 'authors': u'Jianfeng Hou,',
	 'category': u'Computer Science ',
	 'date': '2012-2-28',
	 'pdflink': u'http://arxiv.org/pdf/1202.6129',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nAcyclic edge coloring of sparse graphs',
	 'urllink': u'http://arxiv.org/abs/1202.6129'}
2015-03-23 23:09:14+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0065> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:09:14+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0065>
	{'abstract': u'MIMO Z Channel is investigated in this paper. We focus on how to tackle the interference when different users try to send their codewords to their corresponding receivers while only one user will cause interference to the other. We assume there are two transmitters and two receivers each with two antennas. We propose a strategy to remove the interference while allowing different users transmit at the same time. Our strategy is low-complexity while the performance is good. Mathematical analysis is provided and simulations are given based on our system.',
	 'authors': u'Ian Lim,',
	 'category': u'Computer Science ',
	 'date': '2012-3-31',
	 'pdflink': u'http://arxiv.org/pdf/1204.0065',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nMIMO Z Channel Interference Management',
	 'urllink': u'http://arxiv.org/abs/1204.0065'}
2015-03-23 23:09:20+0000 [xxu46_4] INFO: Crawled 313 pages (at 4 pages/min), scraped 307 items (at 4 items/min)
2015-03-23 23:09:26+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0329> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:09:26+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0329>
	{'abstract': u'A low complexity, essentially-ML decoding technique for the Golden code and the 3 antenna Perfect code was introduced by Sirianunpiboon, Howard and Calderbank. Though no theoretical analysis of the decoder was given, the simulations showed that this decoding technique has almost maximum-likelihood (ML) performance. Inspired by this technique, in this paper we introduce two new low complexity decoders for Space-Time Block Codes (STBCs) - the Adaptive Conditional Zero-Forcing (ACZF) decoder and the ACZF decoder with successive interference cancellation (ACZF-SIC), which include as a special case the decoding technique of Sirianunpiboon et al. We show that both ACZF and ACZF-SIC decoders are capable of achieving full-diversity, and we give sufficient conditions for an STBC to give full-diversity with these decoders. We then show that the Golden code, the 3 and 4 antenna Perfect codes, the 3 antenna Threaded Algebraic Space-Time code and the 4 antenna rate 2 code of Srinath and Rajan are all full-diversity ACZF/ACZF-SIC decodable with complexity strictly less than that of their ML decoders. Simulations show that the proposed decoding method performs identical to ML decoding for all these five codes. These STBCs along with the proposed decoding algorithm outperform all known codes in terms of decoding complexity and error performance for 2,3 and 4 transmit antennas. We further provide a lower bound on the complexity of full-diversity ACZF/ACZF-SIC decoding. All the five codes listed above achieve this lower bound and hence are optimal in terms of minimizing the ACZF/ACZF-SIC decoding complexity. Both ACZF and ACZF-SIC decoders are amenable to sphere decoding implementation.',
	 'authors': u'Lakshmi Prasad Natarajan, B. Sundar Rajan,',
	 'category': u'Computer Science ',
	 'date': '2012-5-2',
	 'pdflink': u'http://arxiv.org/pdf/1205.0329',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nAn Adaptive Conditional Zero-Forcing Decoder with Full-diversity, Least  Complexity and Essentially-ML Performance for STBCs',
	 'urllink': u'http://arxiv.org/abs/1205.0329'}
2015-03-23 23:09:39+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.1105> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:09:39+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.1105>
	{'abstract': u"Understanding the behaviors of information propagation is essential for the effective exploitation of social influence in social networks. However, few existing influence models are both tractable and efficient for describing the information propagation process and quantitatively measuring social influence. To this end, in this paper, we develop a linear social influence model, named Circuit due to its close relation to the circuit network. Based on the predefined four axioms of social influence, we first demonstrate that our model can efficiently measure the influence strength between any pair of nodes. Along this line, an upper bound of the node(s)' influence is identified for potential use, e.g., reducing the search space. Furthermore, we provide the physical implication of the Circuit model and also a deep analysis of its relationships with the existing methods, such as PageRank. Then, we propose that the Circuit model provides a natural solution to the problems of computing each single node's authority and finding a set of nodes for social influence maximization. At last, the effectiveness of the proposed model is evaluated on the real-world data. The extensive experimental results demonstrate that Circuit model consistently outperforms the state-of-the-art methods and can greatly alleviate the computation burden of the influence maximization problem.",
	 'authors': u'Biao Xiang, Enhong Chen, Qi Liu, Hui Xiong,',
	 'category': u'Computer Science ',
	 'date': '2012-6-6',
	 'pdflink': u'http://arxiv.org/pdf/1206.1105',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nA Linear Circuit Model For Social Influence Analysis',
	 'urllink': u'http://arxiv.org/abs/1206.1105'}
2015-03-23 23:09:55+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.6103> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:09:55+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.6103>
	{'abstract': u'We present a technique for spatiotemporal data analysis called nonlinear Laplacian spectral analysis (NLSA), which generalizes singular spectrum analysis (SSA) to take into account the nonlinear manifold structure of complex data sets. The key principle underlying NLSA is that the functions used to represent temporal patterns should exhibit a degree of smoothness on the nonlinear data manifold M; a constraint absent from classical SSA. NLSA enforces such a notion of smoothness by requiring that temporal patterns belong in low-dimensional Hilbert spaces V_l spanned by the leading l Laplace-Beltrami eigenfunctions on M. These eigenfunctions can be evaluated efficiently in high ambient-space dimensions using sparse graph-theoretic algorithms. Moreover, they provide orthonormal bases to expand a family of linear maps, whose singular value decomposition leads to sets of spatiotemporal patterns at progressively finer resolution on the data manifold. The Riemannian measure of M and an adaptive graph kernel width enhances the capability of NLSA to detect important nonlinear processes, including intermittency and rare events. The minimum dimension of V_l required to capture these features while avoiding overfitting is estimated here using spectral entropy criteria.',
	 'authors': u'Dimitrios Giannakis, Andrew J. Majda,',
	 'category': u'Computer Science ',
	 'date': '2012-2-28',
	 'pdflink': u'http://arxiv.org/pdf/1202.6103',
	 'subjects': u'Data Analysis, Statistics and Probability (physics.data-an)',
	 'title': u'\nNonlinear Laplacian spectral analysis: Capturing intermittent and  low-frequency spatiotemporal patterns in high-dimensional data',
	 'urllink': u'http://arxiv.org/abs/1202.6103'}
2015-03-23 23:10:04+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0062> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:10:04+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0062>
	{'abstract': u'Several recent randomized linear algebra algorithms rely upon fast dimension reduction methods. A popular choice is the Subsampled Randomized Hadamard Transform (SRHT). In this article, we address the efficacy, in the Frobenius and spectral norms, of an SRHT-based low-rank matrix approximation technique introduced by Woolfe, Liberty, Rohklin, and Tygert. We establish a slightly better Frobenius norm error bound than currently available, and a much sharper spectral norm error bound (in the presence of reasonable decay of the singular values). Along the way, we produce several results on matrix operations with SRHTs (such as approximate matrix multiplication) that may be of independent interest. Our approach builds upon Tropp\'s in "Improved analysis of the Subsampled Randomized Hadamard Transform".',
	 'authors': u'Christos Boutsidis, Alex Gittens,',
	 'category': u'Computer Science ',
	 'date': '2012-3-31',
	 'pdflink': u'http://arxiv.org/pdf/1204.0062',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nImproved matrix algorithms via the Subsampled Randomized Hadamard  Transform',
	 'urllink': u'http://arxiv.org/abs/1204.0062'}
2015-03-23 23:10:20+0000 [xxu46_4] INFO: Crawled 317 pages (at 4 pages/min), scraped 311 items (at 4 items/min)
2015-03-23 23:10:21+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0326> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:10:21+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0326>
	{'abstract': u'Decode-and-forward (DF) cooperative communication based on free space optical (FSO) links is studied in this letter. We analyze performance of the DF protocol in the FSO links following the Gamma-Gamma distribution. The cumulative distribution function (CDF) and probability density function (PDF) of a random variable containing mixture of the Gamma- Gamma and Gaussian random variables is derived. By using the derived CDF and PDF, average bit error rate of the DF relaying is obtained.',
	 'authors': u'Manav R. Bhatnagar,',
	 'category': u'Computer Science ',
	 'date': '2012-5-2',
	 'pdflink': u'http://arxiv.org/pdf/1205.0326',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nPerformance Analysis of Decode-and-Forward Relaying in Gamma-Gamma  Fading Channels',
	 'urllink': u'http://arxiv.org/abs/1205.0326'}
2015-03-23 23:10:38+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.1099> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:10:38+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.1099>
	{'abstract': u"We consider power line outages in the transmission system of the power grid, and specifically those caused by a natural disaster or a large scale physical attack. In the transmission system, an outage of a line may lead to overload on other lines, thereby eventually leading to their outage. While such cascading failures have been studied before, our focus is on cascading failures that follow an outage of several lines in the same geographical area. We provide an analytical model of such failures, investigate the model's properties, and show that it differs from other models used to analyze cascades in the power grid (e.g., epidemic/percolation-based models). We then show how to identify the most vulnerable locations in the grid and perform extensive numerical experiments with real grid data to investigate the various effects of geographically correlated outages and the resulting cascades. These results allow us to gain insights into the relationships between various parameters and performance metrics, such as the size of the original event, the final number of connected components, and the fraction of demand (load) satisfied after the cascade. In particular, we focus on the timing and nature of optimal control actions used to reduce the impact of a cascade, in real time. We also compare results obtained by our model to the results of a real cascade that occurred during a major blackout in the San Diego area on Sept. 2011. The analysis and results presented in this paper will have implications both on the design of new power grids and on identifying the locations for shielding, strengthening, and monitoring efforts in grid upgrades.",
	 'authors': u'Andrey Bernstein, Daniel Bienstock, David Hay, Meric Uzunoglu, Gil Zussman,',
	 'category': u'Computer Science ',
	 'date': '2012-6-6',
	 'pdflink': u'http://arxiv.org/pdf/1206.1099',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nPower Grid Vulnerability to Geographically Correlated Failures -  Analysis and Control Implications',
	 'urllink': u'http://arxiv.org/abs/1206.1099'}
2015-03-23 23:10:54+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.6078> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:10:54+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.6078>
	{'abstract': u'We consider the problem of learning classifiers for labeled data that has been distributed across several nodes. Our goal is to find a single classifier, with small approximation error, across all datasets while minimizing the communication between nodes. This setting models real-world communication bottlenecks in the processing of massive distributed datasets. We present several very general sampling-based solutions as well as some two-way protocols which have a provable exponential speed-up over any one-way protocol. We focus on core problems for noiseless data distributed across two or more nodes. The techniques we introduce are reminiscent of active learning, but rather than actively probing labels, nodes actively communicate with each other, each node simultaneously learning the important data from another node.',
	 'authors': u'Hal Daume III, Jeff M. Phillips, Avishek Saha, Suresh Venkatasubramanian,',
	 'category': u'Computer Science ',
	 'date': '2012-2-27',
	 'pdflink': u'http://arxiv.org/pdf/1202.6078',
	 'subjects': u'Machine Learning (stat.ML)',
	 'title': u'\nProtocols for Learning Classifiers on Distributed Data',
	 'urllink': u'http://arxiv.org/abs/1202.6078'}
2015-03-23 23:11:09+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0056> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:11:09+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0056>
	{'abstract': u"Multimedia Information security becomes a important part for the organization's intangible assets. Level of confidence and stakeholder trusted are performance indicator as successes organization, it is imperative for organizations to use Information Security Management System (ISMS) to effectively manage their multimedia information assets. The main objective of this paper is to Provide a novel practical framework approach to the development of ISMS, Called by the I-SolFramework, implemented in multimedia information security architecture (MISA), it divides a problem into six object domains or six layers, namely organization,stakeholders, tool &amp; technology, policy, knowledge, and culture. In addition, this framework also introduced novelty algorithm and mathematic models as measurement and assessment tools of MISA parameters.",
	 'authors': u'Heru Susanto, Mohammad Nabil Almunawar, Yong Chee Tuan, Mehmet Sabih Aksoy,',
	 'category': u'Computer Science ',
	 'date': '2012-3-31',
	 'pdflink': u'http://arxiv.org/pdf/1204.0056',
	 'subjects': u'Multimedia (cs.MM)',
	 'title': u'\nI-SolFramework: An Integrated Solution Framework Six Layers Assessment  on Multimedia Information Security Architecture Policy Compliance',
	 'urllink': u'http://arxiv.org/abs/1204.0056'}
2015-03-23 23:11:20+0000 [xxu46_4] INFO: Crawled 321 pages (at 4 pages/min), scraped 315 items (at 4 items/min)
2015-03-23 23:11:20+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0325> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:11:20+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0325>
	{'abstract': u"In this work we study energy-efficient transmission for Cognitive Radio (CR) which opportunistically operates on Primary User's (PU's) channel through spectrum sensing. Spectrum sensing and compulsory idling (for incumbent protection) introduce energy-overheads for Secondary User's (SU's) operations, and thus an appropriate balance between energy consumption in data transmission and energy-overheads is required. We formulate this problem as a discrete-time Markov Decision Process (MDP) in which the SU aims at minimizing its average cost (including both energy consumption and delay cost) to finish a target traffic payload through an appropriate rate allocation. Based on Certainty Equivalent Control, we propose a low-complexity rate-adaptation policy that achieves comparable performance as the optimal policy. With the low-complexity policy, we quantify the impact of energy-overheads (including the power consumption for spectrum sensing and compulsory idling) on the SU transmission strategy. Specifically, the SU rate increases with the increase of energy-overheads, whose marginal impact, however, diminishes. Moreover, the marginal impact of energy-overheads is more significant for delay-insensitive traffic compared to that for delay-sensitive traffic. To mitigate the loss due to imperfect spectrum sensing, we quantify that the SU decreases (increases) its rate with a larger mis-detection probability (false alarm probability).",
	 'authors': u'Yuan Wu, Vincent K. N. Lau, Danny H. K. Tsang, Liping Qian,',
	 'category': u'Computer Science ',
	 'date': '2012-5-2',
	 'pdflink': u'http://arxiv.org/e-print/1205.0325',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nEnergy-Efficient Delay-Constrained Transmission and Sensing for  Cognitive Radio Systems',
	 'urllink': u'http://arxiv.org/abs/1205.0325'}
2015-03-23 23:11:36+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.1090> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:11:36+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.1090>
	{'abstract': u'In this paper, we present a new semantics to check file safety of multithreaded programs. A file-safe program is one that reaches a final configuration under the proposed semantics. We extend the While language with file operations and multi-threading commands, and call the new language whilef. This paper shows that the file safety is an un-decidable property for whilef. The file safety becomes a decidable property in a special case shown in this paper. The case happens when users provide pointer information. If the file is safe we call it a strongly safe file program. We modify the syntax and the semantic of the language and called it SafeWhilef.',
	 'authors': u'Mohamed A. El-Zawawy, Nagwan M. Daoud,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.1090',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nDynamic Verification for File Safety of Multithreaded Programs',
	 'urllink': u'http://arxiv.org/abs/1206.1090'}
2015-03-23 23:11:54+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.6049> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:11:54+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.6049>
	{'abstract': u'Cyber-physical systems integrate computation, communication, and physical capabilities to interact with the physical world and humans. Besides failures of components, cyber-physical systems are prone to malicious attacks so that specific analysis tools and monitoring mechanisms need to be developed to enforce system security and reliability. This paper builds upon the results presented in our companion paper [1] and proposes centralized and distributed monitors for attack detection and identification. First, we design optimal centralized attack detection and identification monitors. Optimality refers to the ability of detecting (respectively identifying) every detectable (respectively identifiable) attack. Second, we design an optimal distributed attack detection filter based upon a waveform relaxation technique. Third, we show that the attack identification problem is computationally hard, and we design a sub-optimal distributed attack identification procedure with performance guarantees. Finally, we illustrate the robustness of our monitors to system noise and unmodeled dynamics through a simulation study.',
	 'authors': u'Fabio Pasqualetti, Florian D\xf6rfler, Francesco Bullo,',
	 'category': u'Computer Science ',
	 'date': '2012-2-27',
	 'pdflink': u'http://arxiv.org/pdf/1202.6049',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nAttack Detection and Identification in Cyber-Physical Systems -- Part  II: Centralized and Distributed Monitor Design',
	 'urllink': u'http://arxiv.org/abs/1202.6049'}
2015-03-23 23:12:10+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0053> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:12:10+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0053>
	{'abstract': u'We motivate and give semantics to theory presentation combinators as the foundational building blocks for a scalable library of theories. The key observation is that the category of contexts and fibered categories are the ideal theoretical tools for this purpose.',
	 'authors': u"Jacques Carette, Russell O'Connor,",
	 'category': u'Computer Science ',
	 'date': '2012-3-31',
	 'pdflink': u'http://arxiv.org/pdf/1204.0053',
	 'subjects': u'Mathematical Software (cs.MS)',
	 'title': u'\nTheory Presentation Combinators',
	 'urllink': u'http://arxiv.org/abs/1204.0053'}
2015-03-23 23:12:20+0000 [xxu46_4] INFO: Crawled 325 pages (at 4 pages/min), scraped 319 items (at 4 items/min)
2015-03-23 23:12:27+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0314> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:12:27+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0314>
	{'abstract': u"Scribe notes from the 2012 Barbados Workshop on Computational Complexity. A series of lectures on Analysis of Boolean Functions by Ryan O'Donnell, with a guest lecture by Per Austrin.",
	 'authors': u'Li-Yang Tan,',
	 'category': u'Computer Science ',
	 'date': '2012-5-2',
	 'pdflink': u'http://arxiv.org/pdf/1205.0314',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nAnalysis of Boolean Functions',
	 'urllink': u'http://arxiv.org/abs/1205.0314'}
2015-03-23 23:12:40+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.1078> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:12:40+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.1078>
	{'abstract': u'Englisch: In this paper we study the paillier cryptosystem and derive form it to new schemes. First we transform the signature of paillier in a Blind signature. Secondly we propose a three-pass protocol wich use the homomorphic property instead of the commutativity as the Shamir protocol does. German: Basierend auf dem Kryptosystem von Paillier und dem damit eingef "uhrten Problem der zusammengesetzten Residuenklasse werden in diesem Artikel zwei kryptographische Verfahren vorgeschlagen. Zun "achst wird die Signatur von Paillier in ein blindes Signaturverfahren umgewandelt. Des Weiteren wird mit der homomorphen Eigenschaft des Kryptosystems von Paillier ein sogenanntes Three-Pass-Protocol - auch No-Key-Protocol genannt - entwickelt.',
	 'authors': u'Tueno Anselme,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.1078',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nZwei Anwendungen des Paillier-Kryptosystems: Blinde Signatur und  Three-Pass-Protocol',
	 'urllink': u'http://arxiv.org/abs/1206.1078'}
2015-03-23 23:12:55+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.6001> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:12:55+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.6001>
	{'abstract': u'We introduce a novel and efficient sampling algorithm for the Multiplicative Attribute Graph Model (MAGM - Kim and Leskovec (2010)). Our algorithm is emph more efficient than the algorithm proposed by Yun and Vishwanathan (2012), in the sense that our method extends the emph time complexity guarantee of their algorithm to a larger fraction of parameter space. Both in theory and in empirical evaluation on sparse graphs, our new algorithm outperforms the previous one. To design our algorithm, we first define a stochastic emph (BDP). Although a special case of this process was introduced as an efficient approximate sampling algorithm for the Kronecker Product Graph Model (KPGM - Leskovec et al. (2010)), neither emph such an approximation works nor emph is the actual distribution this process is sampling from has been addressed so far to the best of our knowledge. Our rigorous treatment of the BDP enables us to clarify the rational behind a BDP approximation of KPGM, and design an efficient sampling algorithm for the MAGM.',
	 'authors': u'Hyokun Yun, S. V. N. Vishwanathan,',
	 'category': u'Computer Science ',
	 'date': '2012-2-27',
	 'pdflink': u'http://arxiv.org/pdf/1202.6001',
	 'subjects': u'Machine Learning (stat.ML)',
	 'title': u'\nEfficiently Sampling Multiplicative Attribute Graphs Using a  Ball-Dropping Process',
	 'urllink': u'http://arxiv.org/abs/1202.6001'}
2015-03-23 23:13:09+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0052> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:13:09+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0052>
	{'abstract': u'We reformulate a recently introduced interpolation-based unique decoding algorithm of algebraic geometry codes using the theory of Gr "obner bases of modules on the coordinate ring of the base curve. With the same decoding performance, the new algorithm has a more conceptual description that lets us better understand the majority voting procedure central in the interpolation-based unique decoding.',
	 'authors': u'Kwankyu Lee,',
	 'category': u'Computer Science ',
	 'date': '2012-3-31',
	 'pdflink': u'http://arxiv.org/pdf/1204.0052',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nUnique Decoding of Plane AG Codes Revisited',
	 'urllink': u'http://arxiv.org/abs/1204.0052'}
2015-03-23 23:13:20+0000 [xxu46_4] INFO: Crawled 329 pages (at 4 pages/min), scraped 323 items (at 4 items/min)
2015-03-23 23:13:22+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0312> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:13:22+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0312>
	{'abstract': u'We proposed a Least Information theory (LIT) to quantify meaning of information in probability distribution changes, from which a new information retrieval model was developed. We observed several important characteristics of the proposed theory and derived two quantities in the IR context for document representation. Given probability distributions in a collection as prior knowledge, LI Binary (LIB) quantifies least information due to the binary occurrence of a term in a document whereas LI Frequency (LIF) measures least information based on the probability of drawing a term from a bag of words. Three fusion methods were also developed to combine LIB and LIF quantities for term weighting and document ranking. Experiments on four benchmark TREC collections for ad hoc retrieval showed that LIT-based methods demonstrated very strong performances compared to classic TF*IDF and BM25, especially for verbose queries and hard search topics. The least information theory offers a new approach to measuring semantic quantities of information and provides valuable insight into the development of new IR models.',
	 'authors': u'Weimao Ke,',
	 'category': u'Computer Science ',
	 'date': '2012-5-2',
	 'pdflink': u'http://arxiv.org/pdf/1205.0312',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nLeast Information Modeling for Information Retrieval',
	 'urllink': u'http://arxiv.org/abs/1205.0312'}
2015-03-23 23:13:39+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.1077> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:13:39+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.1077>
	{'abstract': u"Bergman's Ring , parameterized by a prime number , is a ring with elements that cannot be embedded in a ring of matrices over any commutative ring. This ring was discovered in 1974. In 2011, Climent, Navarro and Tortosa described an efficient implementation of using simple modular arithmetic, and suggested that this ring may be a useful source for intractable cryptographic problems. We present a deterministic polynomial time reduction of the Discrete Logarithm Problem in to the classical Discrete Logarithm Problem in , the -element field. In particular, the Discrete Logarithm Problem in can be solved, by conventional computers, in sub-exponential time.",
	 'authors': u'Matan Banin, Boaz Tsaban,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.1077',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u"\nThe Discrete Logarithm Problem in Bergman's non-representable ring",
	 'urllink': u'http://arxiv.org/abs/1206.1077'}
2015-03-23 23:13:54+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.5961> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:13:54+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.5961>
	{'abstract': u'We show that for finite n at least 3, every first-order axiomatisation of the varieties of representable n-dimensional cylindric algebras, diagonal-free cylindric algebras, polyadic algebras, and polyadic equality algebras contains an infinite number of non-canonical formulas. We also show that the class of structures for each of these varieties is non-elementary. The proofs employ algebras derived from random graphs.',
	 'authors': u'Jannis Bulian, Ian Hodkinson,',
	 'category': u'Computer Science ',
	 'date': '2012-2-27',
	 'pdflink': u'http://arxiv.org/pdf/1202.5961',
	 'subjects': u'Logic (math.LO)',
	 'title': u'\nBare canonicity of representable cylindric and polyadic algebras',
	 'urllink': u'http://arxiv.org/abs/1202.5961'}
2015-03-23 23:14:06+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0047> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:14:06+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0047>
	{'abstract': u'The problem of optimizing unknown costly-to-evaluate functions has been studied for a long time in the context of Bayesian Optimization. Algorithms in this field aim to find the optimizer of the function by asking only a few function evaluations at locations carefully selected based on a posterior model. In this paper, we assume the unknown function is Lipschitz continuous. Leveraging the Lipschitz property, we propose an algorithm with a distinct exploration phase followed by an exploitation phase. The exploration phase aims to select samples that shrink the search space as much as possible. The exploitation phase then focuses on the reduced search space and selects samples closest to the optimizer. Considering the Expected Improvement (EI) as a baseline, we empirically show that the proposed algorithm significantly outperforms EI.',
	 'authors': u'Ali Jalali, Javad Azimi, Xiaoli Fern, Ruofei Zhang,',
	 'category': u'Computer Science ',
	 'date': '2012-3-30',
	 'pdflink': u'http://arxiv.org/pdf/1204.0047',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nA Lipschitz Exploration-Exploitation Scheme for Bayesian Optimization',
	 'urllink': u'http://arxiv.org/abs/1204.0047'}
2015-03-23 23:14:20+0000 [xxu46_4] INFO: Crawled 333 pages (at 4 pages/min), scraped 327 items (at 4 items/min)
2015-03-23 23:14:23+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0288> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:14:23+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0288>
	{'abstract': u'We consider the problem of simultaneously learning to linearly combine a very large number of kernels and learn a good predictor based on the learnt kernel. When the number of kernels to be combined is very large, multiple kernel learning methods whose computational cost scales linearly in are intractable. We propose a randomized version of the mirror descent algorithm to overcome this issue, under the objective of minimizing the group -norm penalized empirical risk. The key to achieve the required exponential speed-up is the computationally efficient construction of low-variance estimates of the gradient. We propose importance sampling based estimates, and find that the ideal distribution samples a coordinate with a probability proportional to the magnitude of the corresponding gradient. We show the surprising result that in the case of learning the coefficients of a polynomial kernel, the combinatorial structure of the base kernels to be combined allows the implementation of sampling from this distribution to run in time, making the total computational cost of the method to achieve an -optimal solution to be , thereby allowing our method to operate for very large values of . Experiments with simulated and real data confirm that the new algorithm is computationally more efficient than its state-of-the-art alternatives.',
	 'authors': u'Arash Afkanpour, Andr\xe1s Gy\xf6rgy, Csaba Szepesv\xe1ri, Michael Bowling,',
	 'category': u'Computer Science ',
	 'date': '2012-5-1',
	 'pdflink': u'http://arxiv.org/pdf/1205.0288',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nA Randomized Mirror Descent Algorithm for Large Scale Multiple Kernel  Learning',
	 'urllink': u'http://arxiv.org/abs/1205.0288'}
2015-03-23 23:14:39+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.1074> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:14:39+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.1074>
	{'abstract': u'Memetic computation (MC) has emerged recently as a new paradigm of efficient algorithms for solving the hardest optimization problems. On the other hand, artificial bees colony (ABC) algorithms demonstrate good performances when solving continuous and combinatorial optimization problems. This study tries to use these technologies under the same roof. As a result, a memetic ABC (MABC) algorithm has been developed that is hybridized with two local search heuristics: the Nelder-Mead algorithm (NMA) and the random walk with direction exploitation (RWDE). The former is attended more towards exploration, while the latter more towards exploitation of the search space. The stochastic adaptation rule was employed in order to control the balancing between exploration and exploitation. This MABC algorithm was applied to a Special suite on Large Scale Continuous Global Optimization at the 2012 IEEE Congress on Evolutionary Computation. The obtained results the MABC are comparable with the results of DECC-G, DECC-G*, and MLCC.',
	 'authors': u'Iztok Fister, Iztok Fister Jr., Janez Brest, Viljem \u017dumer,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.1074',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nMemetic Artificial Bee Colony Algorithm for Large-Scale Global  Optimization',
	 'urllink': u'http://arxiv.org/abs/1206.1074'}
2015-03-23 23:14:55+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.5913> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:14:55+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.5913>
	{'abstract': u"Precopulatory courtship is a high-cost, non-well understood animal world mystery. Drosophila's (=D.'s) precopulatory courtship not only shows marked structural similarities with mammalian courtship, but also with human spoken language. This suggests the study of purpose, modalities and in particular of the power of this language and to compare it to human language. Following a mathematical symbolic dynamics approach, we translate courtship videos of D.'s body language into a formal language. This approach made it possible to show that D. may use its body language to express individual information - information that may be important for evolutionary optimization, on top of the sexual group membership. Here, we use Chomsky's hierarchical language classification to characterize the power of D.'s body language, and then compare it with the power of languages spoken by humans. We find that from a formal language point of view, D.'s body language is at least as powerful as the languages spoken by humans. From this we conclude that human intellect cannot be the direct consequence of the formal grammar complexity of human language.",
	 'authors': u'Ruedi Stoop, Patrick N\xfcesch, Ralph Lukas Stoop, Leonid Bunimovich,',
	 'category': u'Computer Science ',
	 'date': '2012-2-27',
	 'pdflink': u'http://arxiv.org/pdf/1202.5913',
	 'subjects': u'Populations and Evolution (q-bio.PE)',
	 'title': u'\nFly out-smarts man',
	 'urllink': u'http://arxiv.org/abs/1202.5913'}
2015-03-23 23:15:08+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0034> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:15:08+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0034>
	{'abstract': u"A characterization of systematic network coding over multi-hop wireless networks is key towards understanding the trade-off between complexity and delay performance of networks that preserve the systematic structure. This paper studies the case of a relay channel, where the source's objective is to deliver a given number of data packets to a receiver with the aid of a relay. The source broadcasts to both the receiver and the relay using one frequency, while the relay uses another frequency for transmissions to the receiver, allowing for a full-duplex operation of the relay. We analyze the decoding complexity and delay performance of two types of relays: one that preserves the systematic structure of the code from the source; another that does not. A systematic relay forwards uncoded packets upon reception, but transmits coded packets to the receiver after receiving the first coded packet from the source. On the other hand, a non-systematic relay always transmits linear combinations of previously received packets. We compare the performance of these two alternatives by analytically characterizing the expected transmission completion time as well as the number of uncoded packets forwarded by the relay. Our numerical results show that, for a poor channel between the source and the receiver, preserving the systematic structure at the relay (i) allows a significant increase in the number of uncoded packets received by the receiver, thus reducing the decoding complexity, and (ii) preserves close to optimal delay performance.",
	 'authors': u'Giuliano Giacaglia, Xiaomeng Shi, MinJi Kim, Daniel E. Lucani, Muriel Medard,',
	 'category': u'Computer Science ',
	 'date': '2012-3-30',
	 'pdflink': u'http://arxiv.org/pdf/1204.0034',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nSystematic Network Coding with the Aid of a Full-Duplex Relay',
	 'urllink': u'http://arxiv.org/abs/1204.0034'}
2015-03-23 23:15:17+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0281> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:15:17+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0281>
	{'abstract': u"This paper studies the achievable rate region of the two-user single-input-single-output (SISO) Gaussian interference channel, when the improper Gaussian signaling is applied. Under the assumption that the interference is treated as additive Gaussian noise, we show that the user's achievable rate can be expressed as a summation of the rate achievable by the conventional proper Gaussian signaling, which depends on the users' input covariances only, and an additional term, which is a function of both the users' covariances and pseudo-covariances. The additional degree of freedom given by the pseudo-covariance, which is conventionally set to be zero for the case of proper Gaussian signaling, provides an opportunity to improve the achievable rate by employing the improper Gaussian signaling. Since finding the optimal solution for the joint covariance and pseudo-covariance optimization is difficult, we propose a sub-optimal but efficient algorithm by separately optimizing these two sets of parameters. Numerical results show that the proposed algorithm provides a close-to-optimal performance as compared to the exhaustive search method, and significantly outperforms the optimal proper Gaussian signaling and other existing improper Gaussian signaling schemes.",
	 'authors': u'Yong Zeng, Cenk M. Yetis, Erry Gunawan, Yong Liang Guan, Rui Zhang,',
	 'category': u'Computer Science ',
	 'date': '2012-5-1',
	 'pdflink': u'http://arxiv.org/pdf/1205.0281',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nImproving Achievable Rate for the Two-User SISO Interference Channel  with Improper Gaussian Signaling',
	 'urllink': u'http://arxiv.org/abs/1205.0281'}
2015-03-23 23:15:20+0000 [xxu46_4] INFO: Crawled 338 pages (at 5 pages/min), scraped 332 items (at 5 items/min)
2015-03-23 23:15:31+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.1069> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:15:31+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.1069>
	{'abstract': u'We analyze different aspects of our quantum modeling approach of human concepts, and more specifically focus on the quantum effects of contextuality, interference, entanglement and emergence, illustrating how each of them makes its appearance in specific situations of the dynamics of human concepts and their combinations. We point out the relation of our approach, which is based on an ontology of a concept as an entity in a state changing under influence of a context, with the main traditional concept theories, i.e. prototype theory, exemplar theory and theory theory. We ponder about the question why quantum theory performs so well in its modeling of human concepts, and shed light on this question by analyzing the role of complex amplitudes, showing how they allow to describe interference in the statistics of measurement outcomes, while in the traditional theories statistics of outcomes originates in classical probability weights, without the possibility of interference. The relevance of complex numbers, the appearance of entanglement, and the role of Fock space in explaining contextual emergence, all as unique features of the quantum modeling, are explicitly revealed in this paper by analyzing human concepts and their dynamics.',
	 'authors': u'Diederik Aerts, Liane Gabora, Sandro Sozzo,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.1069',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nConcepts and Their Dynamics: A Quantum-Theoretic Modeling of Human  Thought',
	 'urllink': u'http://arxiv.org/abs/1206.1069'}
2015-03-23 23:15:49+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.5909> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:15:49+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.5909>
	{'abstract': u'Characterizing the community structure of complex networks is a key challenge in many scientific fields. Very diverse algorithms and methods have been proposed to this end, many working reasonably well in specific situations. However, no consensus has emerged on which of these methods is the best to use in practice. In part, this is due to the fact that testing their performance requires the generation of a comprehensive, standard set of synthetic benchmarks, a goal not yet fully achieved. Here, we present a type of benchmark that we call "closed", in which an initial network of known community structure is progressively converted into a second network whose communities are also known. This approach differs from all previously published ones, in which networks evolve toward randomness. The use of this type of benchmark allows us to monitor the transformation of the community structure of a network. Moreover, we can predict the optimal behavior of the variation of information, a measure of the quality of the partitions obtained, at any moment of the process. This enables us in many cases to determine the best partition among those suggested by different algorithms. Also, since any network can be used as a starting point, extensive studies and comparisons can be performed using a heterogeneous set of structures, including random ones. These properties make our benchmarks a general standard for comparing community detection algorithms.',
	 'authors': u'Rodrigo Aldecoa, Ignacio Mar\xedn,',
	 'category': u'Computer Science ',
	 'date': '2012-2-27',
	 'pdflink': u'http://arxiv.org/pdf/1202.5909',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nClosed benchmarks for network community structure characterization',
	 'urllink': u'http://arxiv.org/abs/1202.5909'}
2015-03-23 23:16:06+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0029> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:16:06+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0029>
	{'abstract': u'Blind Null Space Learning (BNSL) has recently been proposed for fast and accurate learning of the null-space associated with the channel matrix between a secondary transmitter and a primary receiver. In this paper we propose a channel tracking enhancement of the algorithm, namely the Blind Null Space Tracking (BNST) algorithm that allows transmission of information to the Secondary Receiver (SR) while simultaneously learning the null-space of the time-varying target channel. Specifically, the enhanced algorithm initially performs a BNSL sweep in order to acquire the null space. Then, it performs modified Jacobi rotations such that the induced interference to the primary receiver is kept lower than a given threshold with probability while information is transmitted to the SR simultaneously. We present simulation results indicating that the proposed approach has strictly better performance over the BNSL algorithm for channels with independent Rayleigh fading with a small Doppler frequency.',
	 'authors': u'Alexandros Manolakos, Yair Noam, Andrea J. Goldsmith,',
	 'category': u'Computer Science ',
	 'date': '2012-3-30',
	 'pdflink': u'http://arxiv.org/pdf/1204.0029',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nBlind Null-space Tracking for MIMO Underlay Cognitive Radio Networks',
	 'urllink': u'http://arxiv.org/abs/1204.0029'}
2015-03-23 23:16:20+0000 [xxu46_4] INFO: Crawled 341 pages (at 3 pages/min), scraped 335 items (at 3 items/min)
2015-03-23 23:16:25+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0273> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:16:25+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0273>
	{'abstract': u'We study computing geometric problems on uncertain points. An uncertain point is a point that does not have a fixed location, but rather is described by a probability distribution. When these probability distributions are restricted to a finite number of locations, the points are called indecisive points. In particular, we focus on geometric shape-fitting problems and on building compact distributions to describe how the solutions to these problems vary with respect to the uncertainty in the points. Our main results are: (1) a simple and efficient randomized approximation algorithm for calculating the distribution of any statistic on uncertain data sets; (2) a polynomial, deterministic and exact algorithm for computing the distribution of answers for any LP-type problem on an indecisive point set; and (3) the development of shape inclusion probability (SIP) functions which captures the ambient distribution of shapes fit to uncertain or indecisive point sets and are admissible to the two algorithmic constructions.',
	 'authors': u'Allan Jorgensen, Maarten L\xf6ffler, Jeff M. Phillips,',
	 'category': u'Computer Science ',
	 'date': '2012-5-1',
	 'pdflink': u'http://arxiv.org/pdf/1205.0273',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nGeometric Computations on Indecisive and Uncertain Points',
	 'urllink': u'http://arxiv.org/abs/1205.0273'}
2015-03-23 23:16:42+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.1066> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:16:42+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.1066>
	{'abstract': u'Understanding the ways in which participants in public discussions frame their arguments is important in understanding how public opinion is formed. In this paper, we adopt the position that it is time for more computationally-oriented research on problems involving framing. In the interests of furthering that goal, we propose the following specific, interesting and, we believe, relatively accessible question: In the controversy regarding the use of genetically-modified organisms (GMOs) in agriculture, do pro- and anti-GMO articles differ in whether they choose to adopt a "scientific" tone? Prior work on the rhetoric and sociology of science suggests that hedging may distinguish popular-science text from text written by professional scientists for their colleagues. We propose a detailed approach to studying whether hedge detection can be used to understanding scientific framing in the GMO debates, and provide corpora to facilitate this study. Some of our preliminary analyses suggest that hedges occur less frequently in scientific discourse than in popular text, a finding that contradicts prior assertions in the literature. We hope that our initial work and data will encourage others to pursue this promising line of inquiry.',
	 'authors': u'Eunsol Choi, Chenhao Tan, Lillian Lee, Cristian Danescu-Niculescu-Mizil, Jennifer Spindel,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.1066',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nHedge detection as a lens on framing in the GMO debates: A position  paper',
	 'urllink': u'http://arxiv.org/abs/1206.1066'}
2015-03-23 23:16:58+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.5895> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:16:58+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.5895>
	{'abstract': u'Both small world models of random networks with occasional long range connections and gossip processes with occasional long range transmission of information have similar characteristic behaviour. The long range elements appreciably reduce the effective distances, measured in space or in time, between pairs of typical points. In this paper, we show that their common behaviour can be interpreted as a product of the locally branching nature of the models. In particular, it is shown that both typical distances between points and the proportion of space that can be reached within a given distance or time can be approximated by formulae involving the limit random variable of the branching process.',
	 'authors': u'A. D. Barbour, G. Reinert,',
	 'category': u'Computer Science ',
	 'date': '2012-2-27',
	 'pdflink': u'http://arxiv.org/pdf/1202.5895',
	 'subjects': u'Probability (math.PR)',
	 'title': u'\nAsymptotic behaviour of gossip processes and small world networks',
	 'urllink': u'http://arxiv.org/abs/1202.5895'}
2015-03-23 23:17:15+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0011> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:17:15+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0011>
	{'abstract': u'Cooperation is viewed as a key ingredient for interference management in wireless systems. This paper shows that cooperation has fundamental limitations. The main result is that even full cooperation between transmitters cannot in general change an interference-limited network to a noise-limited network. The key idea is that there exists a spectral efficiency upper bound that is independent of the transmit power. First, a spectral efficiency upper bound is established for systems that rely on pilot-assisted channel estimation; in this framework, cooperation is shown to be possible only within clusters of limited size, which are subject to out-of-cluster interference whose power scales with that of the in-cluster signals. Second, an upper bound is also shown to exist when cooperation is through noncoherent communication; thus, the spectral efficiency limitation is not a by-product of the reliance on pilot-assisted channel estimation. Consequently, existing literature that routinely assumes the high-power spectral efficiency scales with the log of the transmit power provides only a partial characterization. The complete characterization proposed in this paper subdivides the high-power regime into a degrees-of-freedom regime, where the scaling with the log of the transmit power holds approximately, and a saturation regime, where the spectral efficiency hits a ceiling that is independent of the power. Using a cellular system as an example, it is demonstrated that the spectral efficiency saturates at power levels of operational relevance.',
	 'authors': u'Angel Lozano, Robert W. Heath Jr., Jeffrey G. Andrews,',
	 'category': u'Computer Science ',
	 'date': '2012-3-30',
	 'pdflink': u'http://arxiv.org/pdf/1204.0011',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nFundamental Limits of Cooperation',
	 'urllink': u'http://arxiv.org/abs/1204.0011'}
2015-03-23 23:17:20+0000 [xxu46_4] INFO: Crawled 345 pages (at 4 pages/min), scraped 339 items (at 4 items/min)
2015-03-23 23:17:27+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0263> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:17:27+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0263>
	{'abstract': u"Chang's lemma is a useful tool in additive combinatorics and the analysis of Boolean functions. Here we give an elementary proof using entropy. The constant we obtain is tight, and we give a slight improvement in the case where the variables are highly biased.",
	 'authors': u'Russell Impagliazzo, Cristopher Moore, Alexander Russell,',
	 'category': u'Computer Science ',
	 'date': '2012-5-1',
	 'pdflink': u'http://arxiv.org/pdf/1205.0263',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u"\nAn Entropic Proof of Chang's Inequality",
	 'urllink': u'http://arxiv.org/abs/1205.0263'}
2015-03-23 23:17:45+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.1065> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:17:45+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.1065>
	{'abstract': u'We consider the problem of carrier-phase differential GPS positioning for an land vehicle navigation system (LVNS), tightly coupled with an inertial measurement unit (IMU) and a speedometer. The primary focus is to apply Bayesian network to an IMU-aided GPS positioning system based on carrier-phase differential GPS. We describe the implementation details of the positioning system that integrates GPS measurements (i.e., pseudo-range, carrier-phase and doppler), IMU measurements, and speedometer measurements. We derive the linearized state process equation and the measurement equation for GPS and speedometer. To account for constraints of land vehicle, we add two more pseudo measurements to ensure the perpendicular velocities close to zero.',
	 'authors': u'Shuqing Zeng,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.1065',
	 'subjects': u'Robotics (cs.RO)',
	 'title': u'\nAn IMU-Aided Carrier-Phase Differential GPS Positioning System',
	 'urllink': u'http://arxiv.org/abs/1206.1065'}
2015-03-23 23:17:58+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.5810> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:17:58+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.5810>
	{'abstract': u'A univariate polynomial f over a field is decomposable if f = g o h = g(h) for nonlinear polynomials g and h. In order to count the decomposables, one wants to know, under a suitable normalization, the number of equal-degree collisions of the form f = g o h = g^* o h^* with (g, h) = (g^*, h^*) and deg g = deg g^*. Such collisions only occur in the wild case, where the field characteristic p divides deg f. Reasonable bounds on the number of decomposables over a finite field are known, but they are less sharp in the wild case, in particular for degree p^2. We provide a classification of all polynomials of degree p^2 with a collision. It yields the exact number of decomposable polynomials of degree p^2 over a finite field of characteristic p. We also present an efficient algorithm that determines whether a given polynomial of degree p^2 has a collision or not.',
	 'authors': u'Raoul Blankertz, Joachim von zur Gathen, Konstantin Ziegler,',
	 'category': u'Computer Science ',
	 'date': '2012-2-27',
	 'pdflink': u'http://arxiv.org/pdf/1202.5810',
	 'subjects': u'Commutative Algebra (math.AC)',
	 'title': u'\nCompositions and collisions at degree p^2',
	 'urllink': u'http://arxiv.org/abs/1202.5810'}
2015-03-23 23:18:08+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0243> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:18:08+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0243>
	{'abstract': u'Based on World Health Organization (WHO) fact sheet in the 2011, outbreaks of poultry diseases especially Avian Influenza in poultry may raise global public health concerns due to their effect on poultry populations, their potential to cause serious disease in people, and their pandemic potential. In this research, we built a Poultry Diseases Expert System using Dempster-Shafer Theory. In this Poultry Diseases Expert System We describe five symptoms which include depression, combs, wattle, bluish face region, swollen face region, narrowness of eyes, and balance disorders. The result of the research is that Poultry Diseases Expert System has been successfully identifying poultry diseases.',
	 'authors': u'Andino Maseleno, Md. Mahmud Hasan,',
	 'category': u'Computer Science ',
	 'date': '2012-5-1',
	 'pdflink': u'http://arxiv.org/e-print/1205.0243',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nPoultry Diseases Expert System using Dempster-Shafer Theory',
	 'urllink': u'http://arxiv.org/abs/1205.0243'}
2015-03-23 23:18:20+0000 [xxu46_4] INFO: Crawled 349 pages (at 4 pages/min), scraped 343 items (at 4 items/min)
2015-03-23 23:18:26+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.1061> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:18:26+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.1061>
	{'abstract': u'The main objective of this paper is to develop a new semantic Network structure, based on the fuzzy sets theory, used in Artificial Intelligent system in order to provide effective on-line assistance to users of new technological systems. This Semantic Networks is used to describe the knowledge of an "ideal" expert while fuzzy sets are used both to describe the approximate and uncertain knowledge of novice users who intervene to match fuzzy labels of a query with categories from an "ideal" expert. The technical system we consider is a word processor software, with Objects such as "Word" and Goals such as "Cut" or "Copy". We suggest to consider the set of the system\'s Goals as a set of linguistic variables to which corresponds a set of possible linguistic values based on the fuzzy set. We consider, therefore, a set of interpretation\'s levels for these possible values to which corresponds a set of membership functions. We also propose a method to measure the similarity degree between different fuzzy linguistic variables for the partition of the semantic network in class of similar objects to make easy the diagnosis of the user\'s fuzzy queries.',
	 'authors': u'Mohamed Nazih Omri, Mohamed Ali Mahjoub,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.1061',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nUse of Fuzzy Sets in Semantic Nets for Providing On-Line Assistance to  User of Technological Systems',
	 'urllink': u'http://arxiv.org/abs/1206.1061'}
2015-03-23 23:18:42+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.5762> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:18:42+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.5762>
	{'abstract': u"Coloring games are combinatorial games where the players alternate painting uncolored vertices of a graph one of colors. Each different ruleset specifies that game's coloring constraints. This paper investigates six impartial rulesets (five new), derived from previously-studied graph coloring schemes, including proper map coloring, oriented coloring, 2-distance coloring, weak coloring, and sequential coloring. For each, we study the outcome classes for special cases and general computational complexity. In some cases we pay special attention to the Grundy function.",
	 'authors': u'Gabriel Beaulieu, Kyle Burke, Eric Duch\xeane,',
	 'category': u'Computer Science ',
	 'date': '2012-2-26',
	 'pdflink': u'http://arxiv.org/pdf/1202.5762',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nImpartial coloring games',
	 'urllink': u'http://arxiv.org/abs/1202.5762'}
2015-03-23 23:18:59+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0207> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:18:59+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0207>
	{'abstract': u'For the task of moving a group of indistinguishable agents on a connected graph with unit edge lengths into an arbitrary goal formation, it was previously shown that distance optimal paths can be scheduled to complete with a tight convergence time guarantee, using a fully centralized algorithm. In this study, we show that the problem formulation in fact induces a more fundamental ordering of the vertices on the underlying graph network, which directly leads to a more intuitive scheduling algorithm that assures the same convergence time and runs faster. More importantly, this structure enables a distributed scheduling algorithm once individual paths are assigned to the agents, which was not possible before. The vertex ordering also readily extends to more general graphs - those with non-unit capacities and edge lengths - for which we again guarantee the convergence time until the desired formation is achieved.',
	 'authors': u'Jingjin Yu,',
	 'category': u'Computer Science ',
	 'date': '2012-5-1',
	 'pdflink': u'http://arxiv.org/pdf/1205.0207',
	 'subjects': u'Robotics (cs.RO)',
	 'title': u'\nShortest Path Set Induced Vertex Ordering and its Application to  Distributed Distance Optimal Multi-agent Formation Path Planning',
	 'urllink': u'http://arxiv.org/abs/1205.0207'}
2015-03-23 23:19:13+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.1042> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:19:13+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.1042>
	{'abstract': u"In this paper we present a short survey of fuzzy and Semantic approaches to Knowledge Extraction. The goal of such approaches is to define flexible Knowledge Extraction Systems able to deal with the inherent vagueness and uncertainty of the Extraction process. It has long been recognised that interactivity improves the effectiveness of Knowledge Extraction systems. Novice user's queries is the most natural and interactive medium of communication and recent progress in recognition is making it possible to build systems that interact with the user. However, given the typical novice user's queries submitted to Knowledge Extraction systems, it is easy to imagine that the effects of goal recognition errors in novice user's queries must be severely destructive on the system's effectiveness. The experimental work reported in this paper shows that the use of classical Knowledge Extraction techniques for novice user's query processing is robust to considerably high levels of goal recognition errors. Moreover, both standard relevance feedback and pseudo relevance feedback can be effectively employed to improve the effectiveness of novice user's query processing.",
	 'authors': u'Mohamed Nazih Omri,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.1042',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u"\nRelevance Feedback for Goal's Extraction from Fuzzy Semantic Networks",
	 'urllink': u'http://arxiv.org/abs/1206.1042'}
2015-03-23 23:19:20+0000 [xxu46_4] INFO: Crawled 353 pages (at 4 pages/min), scraped 347 items (at 4 items/min)
2015-03-23 23:19:29+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.5718> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:19:29+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.5718>
	{'abstract': u'Suppose that D is an acyclic orientation of a graph G. An arc of D is called dependent if its reversal creates a directed cycle. Let m and M denote the minimum and the maximum of the number of dependent arcs over all acyclic orientations of G. We call G fully orientable if G has an acyclic orientation with exactly d dependent arcs for every d satisfying m &lt;= d &lt;= M. A graph G is called chordal if every cycle in G of length at least four has a chord. We show that all chordal graphs are fully orientable.',
	 'authors': u'Hsin-Hao Lai, Ko-Wei Lih,',
	 'category': u'Computer Science ',
	 'date': '2012-2-26',
	 'pdflink': u'http://arxiv.org/pdf/1202.5718',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nChordal Graphs are Fully Orientable',
	 'urllink': u'http://arxiv.org/abs/1202.5718'}
2015-03-23 23:19:47+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0193> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:19:47+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0193>
	{'abstract': u'For an undirected, simple, finite, connected graph , we denote by and the sets of its vertices and edges, respectively. A function is called a proper edge -coloring of a graph if adjacent edges are colored differently and each of colors is used. An arbitrary nonempty subset of consecutive integers is called an interval. If is a proper edge -coloring of a graph and , then denotes the set of colors of edges of which are incident with . A proper edge -coloring of a graph is called a cyclically-interval -coloring if for any at least one of the following two conditions holds: a) is an interval, b) is an interval. For any , let be the set of graphs for which there exists a cyclically-interval -coloring, and let mathfrak equiv bigcup_ mathfrak_t. For an arbitrary tree , it is proved that and all possible values of are found for which',
	 'authors': u'R.R. Kamalian,',
	 'category': u'Computer Science ',
	 'date': '2012-5-1',
	 'pdflink': u'http://arxiv.org/pdf/1205.0193',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nOn cyclically-interval edge colorings of trees',
	 'urllink': u'http://arxiv.org/abs/1205.0193'}
2015-03-23 23:20:02+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.1032> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:20:02+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.1032>
	{'abstract': u'Mining frequent itemsets through static Databases has been extensively studied and used and is always considered a highly challenging task. For this reason it is interesting to extend it to data streams field. In the streaming case, the frequent patterns\' mining has much more information to track and much greater complexity to manage. Infrequent items can become frequent later on and hence cannot be ignored. The output structure needs to be dynamically incremented to reflect the evolution of itemset frequencies over time. In this paper, we study this problem and specifically the methodology of mining time-sensitive data streams. We tried to improve an existing algorithm by increasing the temporal accuracy and discarding the out-of-date data by adding a new concept called the "Shaking Point". We presented as well some experiments illustrating the time and space required.',
	 'authors': u'Manel Zarrouk, Med Salah Gouider,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.1032',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nFrequent Patterns mining in time-sensitive Data Stream',
	 'urllink': u'http://arxiv.org/abs/1206.1032'}
2015-03-23 23:20:20+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.5710> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:20:20+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.5710>
	{'abstract': u"We examine sparse grid quadrature on weighted tensor products (WTP) of reproducing kernel Hilbert spaces on products of the unit sphere, in the case of worst case quadrature error for rules with arbitrary quadrature weights. We describe a dimension adaptive quadrature algorithm based on an algorithm of Hegland (2003), and also formulate a version of Wasilkowski and Wozniakowski's WTP algorithm (1999), here called the WW algorithm. We prove that the dimension adaptive algorithm is optimal in the sense of Dantzig (1957) and therefore no greater in cost than the WW algorithm. Both algorithms therefore have the optimal asymptotic rate of convergence given by Theorem 3 of Wasilkowski and Wozniakowski (1999). A numerical example shows that, even though the asymptotic convergence rate is optimal, if the dimension weights decay slowly enough, and the dimensionality of the problem is large enough, the initial convergence of the dimension adaptive algorithm can be slow.",
	 'authors': u'Markus Hegland, Paul Leopardi,',
	 'category': u'Computer Science ',
	 'date': '2012-2-26',
	 'pdflink': u'http://arxiv.org/pdf/1202.5710',
	 'subjects': u'Numerical Analysis (math.NA)',
	 'title': u'\nSparse grid quadrature on products of spheres',
	 'urllink': u'http://arxiv.org/abs/1202.5710'}
2015-03-23 23:20:20+0000 [xxu46_4] INFO: Crawled 357 pages (at 4 pages/min), scraped 351 items (at 4 items/min)
2015-03-23 23:20:36+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.6795> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:20:36+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.6795>
	{'abstract': u'We investigate subshifts with a general algebraic structure and cellular automata on them, with an emphasis on (order-theoretic) lattices. Our main results concern the characterization of Boolean algebraic subshifts, conditions for algebraic subshifts to be recoded into cellwise algebras and the limit dynamics of homomorphic cellular automata on lattice subshifts.',
	 'authors': u'Ville Salo, Ilkka T\xf6rm\xe4,',
	 'category': u'Computer Science ',
	 'date': '2012-3-30',
	 'pdflink': u'http://arxiv.org/pdf/1203.6795',
	 'subjects': u'Dynamical Systems (math.DS)',
	 'title': u'\nOn Shift Spaces with Algebraic Structure',
	 'urllink': u'http://arxiv.org/abs/1203.6795'}
2015-03-23 23:20:54+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0192> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:20:54+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0192>
	{'abstract': u"Motivation The Burrows-Wheeler transform (BWT) is the foundation of many algorithms for compression and indexing of text data, but the cost of computing the BWT of very large string collections has prevented these techniques from being widely applied to the large sets of sequences often encountered as the outcome of DNA sequencing experiments. In previous work, we presented a novel algorithm that allows the BWT of human genome scale data to be computed on very moderate hardware, thus enabling us to investigate the BWT as a tool for the compression of such datasets. Results We first used simulated reads to explore the relationship between the level of compression and the error rate, the length of the reads and the level of sampling of the underlying genome and compare choices of second-stage compression algorithm. We demonstrate that compression may be greatly improved by a particular reordering of the sequences in the collection and give a novel `implicit sorting' strategy that enables these benefits to be realised without the overhead of sorting the reads. With these techniques, a 45x coverage of real human genome sequence data compresses losslessly to under 0.5 bits per base, allowing the 135.3Gbp of sequence to fit into only 8.2Gbytes of space (trimming a small proportion of low-quality bases from the reads improves the compression still further). This is more than 4 times smaller than the size achieved by a standard BWT-based compressor (bzip2) on the untrimmed reads, but an important further advantage of our approach is that it facilitates the building of compressed full text indexes such as the FM-index on large-scale DNA sequence collections.",
	 'authors': u'Anthony J. Cox, Markus J. Bauer, Tobias Jakobi, Giovanna Rosone,',
	 'category': u'Computer Science ',
	 'date': '2012-5-1',
	 'pdflink': u'http://arxiv.org/pdf/1205.0192',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nLarge-scale compression of genomic sequence databases with the  Burrows-Wheeler transform',
	 'urllink': u'http://arxiv.org/abs/1205.0192'}
2015-03-23 23:21:08+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.1012> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:21:08+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.1012>
	{'abstract': u'The Artificial Bee Colony (ABC) is the name of an optimization algorithm that was inspired by the intelligent behavior of a honey bee swarm. It is widely recognized as a quick, reliable, and efficient methods for solving optimization problems. This paper proposes a hybrid ABC (HABC) algorithm for graph 3-coloring, which is a well-known discrete optimization problem. The results of HABC are compared with results of the well-known graph coloring algorithms of today, i.e. the Tabucol and Hybrid Evolutionary algorithm (HEA) and results of the traditional evolutionary algorithm with SAW method (EA-SAW). Extensive experimentations has shown that the HABC matched the competitive results of the best graph coloring algorithms, and did better than the traditional heuristics EA-SAW when solving equi-partite, flat, and random generated medium-sized graphs.',
	 'authors': u'Iztok Fister Jr., Iztok Fister, Janez Brest,',
	 'category': u'Computer Science ',
	 'date': '2012-5-6',
	 'pdflink': u'http://arxiv.org/pdf/1206.1012',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nA Hybrid Artificial Bee Colony Algorithm for Graph 3-Coloring',
	 'urllink': u'http://arxiv.org/abs/1206.1012'}
2015-03-23 23:21:20+0000 [xxu46_4] INFO: Crawled 360 pages (at 3 pages/min), scraped 354 items (at 3 items/min)
2015-03-23 23:21:25+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.5657> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:21:25+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.5657>
	{'abstract': u'Phase shaping using fractional order (FO) phase shapers has been proposed by many contemporary researchers as a means of producing systems with iso-damped closed loop response due to a stepped variation in input. Such systems, with the closed loop damping remaining invariant to gain changes can be used to produce dead-beat step response with only rise time varying with gain. This technique is used to achieve an active step-back in a Pressurized Heavy Water Reactor (PHWR) where it is desired to change the reactor power to a pre-determined value within a short interval keeping the power undershoot as low as possible. This paper puts forward an approach as an alternative for the present day practice of a passive step-back mechanism where the control rods are allowed to drop during a step-back action by gravity, with release of electromagnetic clutches. The reactor under a step-back condition is identified as a system using practical test data and a suitable Proportional plus Integral plus Derivative (PID) controller is designed for it. Then the combined plant is augmented with a phase shaper to achieve a dead-beat response in terms of power drop. The fact that the identified static gain of the system depends on the initial power level at which a step-back is initiated, makes this application particularly suited for using a FO phase shaper. In this paper, a model of a nuclear reactor is developed for a control rod drop scenario involving rapid power reduction in a 500MWe Canadian Deuterium Uranium (CANDU) reactor using AutoRegressive Exogenous (ARX) algorithm. The system identification and reduced order modeling are developed from practical test data. For closed loop active control of the identified reactor model, the fractional order phase shaper along with a PID controller is shown to perform better than the present Reactor Regulating System (RRS) due to its iso-damped nature.',
	 'authors': u'Suman Saha, Saptarshi Das, Ratna Ghosh, Bhaswati Goswami, R. Balasubramanian, A.K. Chandra, Shantanu Das, Amitava Gupta,',
	 'category': u'Computer Science ',
	 'date': '2012-2-25',
	 'pdflink': u'http://arxiv.org/pdf/1202.5657',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nDesign of a Fractional Order Phase Shaper for Iso-damped Control of a  PHWR under Step-back Condition',
	 'urllink': u'http://arxiv.org/abs/1202.5657'}
2015-03-23 23:21:41+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.6880> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:21:41+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.6880>
	{'abstract': u'We study three mixing properties of a graph: large algebraic connectivity, large Cheeger constant (isoperimetric number) and large spectral gap from 1 for the second largest eigenvalue of the transition probability matrix of the random walk on the graph. We prove equivalence of this properties (in some sense). We give estimates for the probability for a random graph to satisfy these properties. In addition, we present asymptotic formulas for the numbers of Eulerian orientations and Eulerian circuits in an undirected simple graph.',
	 'authors': u'Mikhail Isaev, K.V Isaeva,',
	 'category': u'Computer Science ',
	 'date': '2012-3-30',
	 'pdflink': u'http://arxiv.org/pdf/1203.6880',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nOn the class of graphs with strong mixing properties',
	 'urllink': u'http://arxiv.org/abs/1203.6880'}
2015-03-23 23:21:56+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0181> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:21:57+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0181>
	{'abstract': u"In a heterogeneous wireless cellular network, each user may be covered by multiple access points such as macro/pico/relay/femto base stations (BS). An effective approach to maximize the sum utility (e.g., system throughput) in such a network is to jointly optimize users' linear procoders as well as their base station associations. In this paper we first show that this joint optimization problem is NP-hard and thus is difficult to solve to global optimality. To find a locally optimal solution, we formulate the problem as a noncooperative game in which the users and the BSs both act as players. We introduce a set of new utility functions for the players and show that every Nash equilibrium (NE) of the resulting game is a stationary solution of the original sum utility maximization problem. Moreover, we develop a best-response type algorithm that allows the players to distributedly reach a NE of the game. Simulation results show that the proposed distributed algorithm can effectively relieve local BS congestion and simultaneously achieve high throughput and load balancing in a heterogeneous network.",
	 'authors': u'Mingyi Hong, Zhi-Quan Luo,',
	 'category': u'Computer Science ',
	 'date': '2012-5-1',
	 'pdflink': u'http://arxiv.org/pdf/1205.0181',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nDistributed Linear Precoder Optimization and Base Station Selection for  an Uplink Heterogeneous Network',
	 'urllink': u'http://arxiv.org/abs/1205.0181'}
2015-03-23 23:22:09+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.1011> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:22:09+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.1011>
	{'abstract': u'Opinion mining aims at extracting useful subjective information from reliable amounts of text. Opinion mining holder recognition is a task that has not been considered yet in Arabic Language. This task essentially requires deep understanding of clauses structures. Unfortunately, the lack of a robust, publicly available, Arabic parser further complicates the research. This paper presents a leading research for the opinion holder extraction in Arabic news independent from any lexical parsers. We investigate constructing a comprehensive feature set to compensate the lack of parsing structural outcomes. The proposed feature set is tuned from English previous works coupled with our proposed semantic field and named entities features. Our feature analysis is based on Conditional Random Fields (CRF) and semi-supervised pattern recognition techniques. Different research models are evaluated via cross-validation experiments achieving 54.03 F-measure. We publicly release our own research outcome corpus and lexicon for opinion mining community to encourage further research.',
	 'authors': u'Mohamed Elarnaoty, Samir AbdelRahman, Aly Fahmy,',
	 'category': u'Computer Science ',
	 'date': '2012-4-6',
	 'pdflink': u'http://arxiv.org/pdf/1206.1011',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nA Machine Learning Approach For Opinion Holder Extraction In Arabic  Language',
	 'urllink': u'http://arxiv.org/abs/1206.1011'}
2015-03-23 23:22:20+0000 [xxu46_4] INFO: Crawled 364 pages (at 4 pages/min), scraped 358 items (at 4 items/min)
2015-03-23 23:22:24+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.5569> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:22:24+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.5569>
	{'abstract': u'A simple random walk on a graph is a sequence of movements from one vertex to another where at each step an edge is chosen uniformly at random from the set of edges incident on the current vertex, and then transitioned to next vertex. Central to this thesis is the cover time of the walk, that is, the expectation of the number of steps required to visit every vertex, maximised over all starting vertices. In our first contribution, we establish a relation between the cover times of a pair of graphs, and the cover time of their Cartesian product. This extends previous work on special cases of the Cartesian product, in particular, the square of a graph. We show that when one of the factors is in some sense larger than the other, its cover time dominates, and can become within a logarithmic factor of the cover time of the product as a whole. Our main theorem effectively gives conditions for when this holds. The techniques and lemmas we introduce may be of independent interest. In our second contribution, we determine the precise asymptotic value of the cover time of a random graph with given degree sequence. This is a graph picked uniformly at random from all simple graphs with that degree sequence. We also show that with high probability, a structural property of the graph called conductance, is bounded below by a constant. This is of independent interest. Finally, we explore random walks with weighted random edge choices. We present a weighting scheme that has a smaller worst case cover time than a simple random walk. We give an upper bound for a random graph of given degree sequence weighted according to our scheme. We demonstrate that the speed-up (that is, the ratio of cover times) over a simple random walk can be unbounded',
	 'authors': u'Mohammed Abdullah,',
	 'category': u'Computer Science ',
	 'date': '2012-2-24',
	 'pdflink': u'http://arxiv.org/pdf/1202.5569',
	 'subjects': u'Probability (math.PR)',
	 'title': u'\nThe Cover Time of Random Walks on Graphs',
	 'urllink': u'http://arxiv.org/abs/1202.5569'}
2015-03-23 23:22:37+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.6866> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:22:37+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.6866>
	{'abstract': u'The interleaving of chaos and cryptography has been the aim of a large set of works since the beginning of the nineties. Many encryption proposals have been introduced to improve conventional cryptography. However, many proposals possess serious problems according to the basic requirements for the secure exchange of information. In this paper we highlight some of the main problems of chaotic cryptography by means of the analysis of a very recent chaotic cryptosystem based on a one round Substitution Permutation Network. More specifically, we show that it is not possible to avoid the security problems of that encryption architecture just by including a chaotic system as core of the derived encryption system.',
	 'authors': u'David Arroyo, Jesus Diaz, F. B. Rodriguez,',
	 'category': u'Computer Science ',
	 'date': '2012-3-30',
	 'pdflink': u'http://arxiv.org/pdf/1203.6866',
	 'subjects': u'Chaotic Dynamics (nlin.CD)',
	 'title': u'\nCryptanalysis of a one round chaos-based Substitution Permutation  Network',
	 'urllink': u'http://arxiv.org/abs/1203.6866'}
2015-03-23 23:22:53+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0178> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:22:53+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0178>
	{'abstract': u'This paper summarizes the fundamental expressiveness, closure, and decidability properties of various finite-state automata classes with multiple input tapes. It also includes an original algorithm for the intersection of one-way nondeterministic finite-state automata.',
	 'authors': u'Carlo A. Furia,',
	 'category': u'Computer Science ',
	 'date': '2012-5-1',
	 'pdflink': u'http://arxiv.org/pdf/1205.0178',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nA Survey of Multi-Tape Automata',
	 'urllink': u'http://arxiv.org/abs/1205.0178'}
2015-03-23 23:23:09+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.1004> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:23:09+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.1004>
	{'abstract': u'This paper mainly investigates the circular open dimension problem (CODP), which consists of packing a set of circles of known radii into a strip of fixed width and unlimited length without overlapping. The objective is to minimize the length of the strip. An iterated tabu search approach, named ITS, is proposed. ITS starts from a randomly generated solution and attempts to gain improvements by a tabu search procedure. After that, if the obtained solution is not feasible, a perturbation operator is subsequently employed to reconstruct the incumbent solution and an acceptance criterion is implemented to determine whether or not accept the perturbed solution. This process is repeated until a feasible solution has been found or the allowed computation time has been elapsed. Computational experiments based on well-known benchmark instances show that ITS produces quite competitive results with respect to the best known results. For 18 representative CODP instances taken from the literature, ITS succeeds in improving 13 best known results within reasonable time. In addition, for another challenging related variant: the problem of packing arbitrary sized circles into a circular container, ITS also succeeds in improving many best known results. Supplementary experiments are also provided to analyze the influence of the perturbation operator, as well as the acceptance criterion.',
	 'authors': u'Zhanghua Fu, Wenqi Huang, Zhipeng Lv,',
	 'category': u'Computer Science ',
	 'date': '2012-3-14',
	 'pdflink': u'http://arxiv.org/pdf/1206.1004',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nIterated tabu search for the circular open dimension problem',
	 'urllink': u'http://arxiv.org/abs/1206.1004'}
2015-03-23 23:23:20+0000 [xxu46_4] INFO: Crawled 368 pages (at 4 pages/min), scraped 362 items (at 4 items/min)
2015-03-23 23:23:27+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.6807> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:23:27+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.6807>
	{'abstract': u'We determine a general formula to compute the number of saturated chains in Dyck lattices, and we apply it to find the number of saturated chains of length 2 and 3. We also compute what we call the Hasse index (of order 2 and 3) of Dyck lattices, which is the ratio between the total number of saturated chains (of length 2 and 3) and the cardinality of the underlying poset.',
	 'authors': u'Luca Ferrari, Emanuele Munarini,',
	 'category': u'Computer Science ',
	 'date': '2012-3-30',
	 'pdflink': u'http://arxiv.org/pdf/1203.6807',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nEnumeration of saturated chains in Dyck lattices',
	 'urllink': u'http://arxiv.org/abs/1203.6807'}
2015-03-23 23:23:42+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0175> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:23:42+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0175>
	{'abstract': u'A covering integer program (CIP) is a mathematical program of the form: min , where A is an m x n matrix, and c and u are n-dimensional vectors, all having non-negative entries. In the online setting, the constraints (i.e., the rows of the constraint matrix A) arrive over time, and the algorithm can only increase the coordinates of vector x to maintain feasibility. As an intermediate step, we consider solving the covering linear program (CLP) online, where the integrality requirement on x is dropped. Our main results are (a) an O(log k)-competitive online algorithm for solving the CLP, and (b) an O(log k log L)-competitive randomized online algorithm for solving the CIP. Here k&lt;=n and L&lt;=m respectively denote the maximum number of non-zero entries in any row and column of the constraint matrix A. By a result of Feige and Korman, this is the best possible for polynomial-time online algorithms, even in the special case of set cover.',
	 'authors': u'Anupam Gupta, Viswanath Nagarajan,',
	 'category': u'Computer Science ',
	 'date': '2012-5-1',
	 'pdflink': u'http://arxiv.org/pdf/1205.0175',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nApproximating Sparse Covering Integer Programs Online',
	 'urllink': u'http://arxiv.org/abs/1205.0175'}
2015-03-23 23:23:57+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0995> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:23:57+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0995>
	{'abstract': u'In [1], we introduced the weakly synchronizing languages for probabilistic automata. In this report, we show that the emptiness problem of weakly synchronizing languages for probabilistic automata is undecidable. This implies that the decidability result of [1-3] for the emptiness problem of weakly synchronizing language is incorrect.',
	 'authors': u'Laurent Doyen, Thierry Massart, Mahsa Shirmohammadi,',
	 'category': u'Computer Science ',
	 'date': '2012-3-19',
	 'pdflink': u'http://arxiv.org/pdf/1206.0995',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nInfinite Synchronizing Words for Probabilistic Automata (Erratum)',
	 'urllink': u'http://arxiv.org/abs/1206.0995'}
2015-03-23 23:24:05+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.5514> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:24:05+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.5514>
	{'abstract': u'This paper deals with the binary classification task when the target class has the lower probability of occurrence. In such situation, it is not possible to build a powerful classifier by using standard methods such as logistic regression, classification tree, discriminant analysis, etc. To overcome this short-coming of these methods which yield classifiers with low sensibility, we tackled the classification problem here through an approach based on the association rules learning. This approach has the advantage of allowing the identification of the patterns that are well correlated with the target class. Association rules learning is a well known method in the area of data-mining. It is used when dealing with large database for unsupervised discovery of local patterns that expresses hidden relationships between input variables. In considering association rules from a supervised learning point of view, a relevant set of weak classifiers is obtained from which one derives a classifier that performs well.',
	 'authors': u'Cheikh Ndour, Aliou Diop, Simplice Dossou-Gb\xe9t\xe9,',
	 'category': u'Computer Science ',
	 'date': '2012-2-24',
	 'pdflink': u'http://arxiv.org/pdf/1202.5514',
	 'subjects': u'Machine Learning (stat.ML)',
	 'title': u'\nClassification approach based on association rules mining for unbalanced  data',
	 'urllink': u'http://arxiv.org/abs/1202.5514'}
2015-03-23 23:24:20+0000 [xxu46_4] INFO: Crawled 372 pages (at 4 pages/min), scraped 366 items (at 4 items/min)
2015-03-23 23:24:23+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.6792> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:24:23+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.6792>
	{'abstract': u'We enumerate the edges in the Hasse diagram of several lattices arising in the combinatorial context of lattice paths. Specifically, we will consider the case of Dyck, Grand Dyck, Motzkin, Grand Motzkin, Schr "oder and Grand Schr "oder lattices. Finally, we give a general formula for the number of edges in an arbitrary Young lattice (which can be interpreted in a natural way as a lattice of paths).',
	 'authors': u'Luca Ferrari, Emanuele Munarini,',
	 'category': u'Computer Science ',
	 'date': '2012-3-30',
	 'pdflink': u'http://arxiv.org/pdf/1203.6792',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nEnumeration of edges in some lattices of paths',
	 'urllink': u'http://arxiv.org/abs/1203.6792'}
2015-03-23 23:24:35+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0170> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:24:35+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0170>
	{'abstract': u'The Mizar language aims to capture mathematical vernacular by providing a rich language for mathematics. From the perspective of a user, the richness of the language is welcome because it makes writing texts more "natural". But for the developer, the richness leads to syntactic complexity, such as dealing with overloading. Recently the Mizar team has been making a fresh approach to the problem of parsing the Mizar language. One aim is to make the language accessible to users and other developers. In this paper we describe these new parsing efforts and some applications thereof, such as large-scale text refactorings, pretty-printing, HTTP parsing services, and normalizations of Mizar texts.',
	 'authors': u'Czeslaw Bylinski, Jesse Alama,',
	 'category': u'Computer Science ',
	 'date': '2012-4-30',
	 'pdflink': u'http://arxiv.org/pdf/1205.0170',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nNew developments in parsing Mizar',
	 'urllink': u'http://arxiv.org/abs/1205.0170'}
2015-03-23 23:24:46+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0994> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:24:46+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0994>
	{'abstract': u'Unsupervised models can provide supplementary soft constraints to help classify new, "target" data since similar instances in the target set are more likely to share the same class label. Such models can also help detect possible differences between training and target distributions, which is useful in applications where concept drift may take place, as in transfer learning settings. This paper describes a general optimization framework that takes as input class membership estimates from existing classifiers learnt on previously encountered "source" data, as well as a similarity matrix from a cluster ensemble operating solely on the target data to be classified, and yields a consensus labeling of the target data. This framework admits a wide range of loss functions and classification/clustering methods. It exploits properties of Bregman divergences in conjunction with Legendre duality to yield a principled and scalable approach. A variety of experiments show that the proposed framework can yield results substantially superior to those provided by popular transductive learning techniques or by naively applying classifiers learnt on the original task to the target data.',
	 'authors': u'Ayan Acharya, Eduardo R. Hruschka, Joydeep Ghosh, Sreangsu Acharyya,',
	 'category': u'Computer Science ',
	 'date': '2012-4-20',
	 'pdflink': u'http://arxiv.org/pdf/1206.0994',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nAn Optimization Framework for Semi-Supervised and Transfer Learning  using Multiple Classifiers and Clusterers',
	 'urllink': u'http://arxiv.org/abs/1206.0994'}
2015-03-23 23:24:53+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.5414> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:24:53+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.5414>
	{'abstract': u'In this work we study the formulation of convection/diffusion equations on the 3D motion group SE(3) in terms of the irreducible representations of SO(3). Therefore, the left-invariant vector-fields on SE(3) are expressed as linear operators, that are differential forms in the translation coordinate and algebraic in the rotation. In the context of 3D image processing this approach avoids the explicit discretization of SO(3) or , respectively. This is particular important for SO(3), where a direct discretization is infeasible due to the enormous memory consumption. We show two applications of the framework: one in the context of diffusion-weighted magnetic resonance imaging and one in the context of object detection.',
	 'authors': u'Marco Reisert, Henrik Skibbe,',
	 'category': u'Computer Science ',
	 'date': '2012-2-24',
	 'pdflink': u'http://arxiv.org/pdf/1202.5414',
	 'subjects': u'Analysis of PDEs (math.AP)',
	 'title': u'\nLeft-Invariant Diffusion on the Motion Group in terms of the Irreducible  Representations of SO(3)',
	 'urllink': u'http://arxiv.org/abs/1202.5414'}
2015-03-23 23:25:10+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.6785> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:25:10+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.6785>
	{'abstract': u'For networked systems, the control law is typically subject to network flaws such as delays and packet dropouts. Hence, the time in between updates of the control law varies unexpectedly. Here, we present a stability theorem for nonlinear model predictive control with varying control horizon in a continuous time setting without stabilizing terminal constraints or costs. It turns out that stability can be concluded under the same conditions as for a (short) fixed control horizon.',
	 'authors': u'Lars Gr\xfcne, J\xfcrgen Pannek, Karl Worthmann,',
	 'category': u'Computer Science ',
	 'date': '2012-3-30',
	 'pdflink': u'http://arxiv.org/pdf/1203.6785',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nEnsuring Stability in Networked Systems with Nonlinear MPC for  Continuous Time Systems',
	 'urllink': u'http://arxiv.org/abs/1203.6785'}
2015-03-23 23:25:20+0000 [xxu46_4] INFO: Crawled 377 pages (at 5 pages/min), scraped 371 items (at 5 items/min)
2015-03-23 23:25:26+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0162> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:25:26+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0162>
	{'abstract': u'We provide the solution for optimizing the power and resource allocation over block-fading relay-assisted broadcast channels in order to maximize the long term average achievable rates region of the users. The problem formulation assumes regenerative (repetition coding) decode-and-forward (DF) relaying strategy, long-term average total transmitted power constraint, orthogonal multiplexing of the users messages within the channel blocks, possibility to use a direct transmission (DT) mode from the base station to the user terminal directly or a relaying (DF) transmission mode, and partial channel state information. We show that our optimization problem can be transformed into an equivalent "no-relaying" broadcast channel optimization problem with each actual user substituted by two virtual users having different channel qualities and multiplexing weights. The proposed power and resource allocation strategies are expressed in closed-form that can be applied practically in centralized relay-assisted wireless networks. Furthermore, we show by numerical examples that our scheme enlarges the achievable rates region significantly.',
	 'authors': u'Mohammad Shaqfeh, Hussein Alnuweiri,',
	 'category': u'Computer Science ',
	 'date': '2012-5-1',
	 'pdflink': u'http://arxiv.org/pdf/1205.0162',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nJoint Power and Resource Allocation for Block-Fading Relay-Assisted  Broadcast Channels',
	 'urllink': u'http://arxiv.org/abs/1205.0162'}
2015-03-23 23:25:39+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0992> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:25:39+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0992>
	{'abstract': u'Gossip algorithms are widely used in modern distributed systems, with applications ranging from sensor networks and peer-to-peer networks to mobile vehicle networks and social networks. A tremendous research effort has been devoted to analyzing and improving the asymptotic rate of convergence for gossip algorithms. In this work we study finite-time convergence of deterministic gossiping. We show that there exists a symmetric gossip algorithm that converges in finite time if and only if the number of network nodes is a power of two, while there always exists an asymmetric gossip algorithm with finite-time convergence, independent of the number of nodes. For nodes, we prove that a fastest convergence can be reached in node updates via symmetric gossiping. On the other hand, under asymmetric gossip among nodes with , it takes at least node updates for achieving finite-time convergence. It is also shown that the existence of finite-time convergent gossiping often imposes strong structural requirements on the underlying interaction graph. Finally, we apply our results to gossip algorithms in quantum networks, where the goal is to control the state of a quantum system via pairwise interactions. We show that finite-time convergence is never possible for such systems.',
	 'authors': u'Guodong Shi, Bo Li, Mikael Johansson, Karl Henrik Johansson,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.0992',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nFinite-time Convergent Gossiping',
	 'urllink': u'http://arxiv.org/abs/1206.0992'}
2015-03-23 23:25:53+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.5398> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:25:53+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.5398>
	{'abstract': u'We propose a new modularity optimization method, Mod-CSA, based on stochastic global optimization algorithm, conformational space annealing (CSA). Our method outperforms simulated annealing in terms of both efficiency and accuracy, finding higher modularity partitions with less computational resources required. The high modularity values found by our method are higher than, or equal to, the largest values previously reported. In addition, the method can be combined with other heuristic methods, and implemented in parallel fashion, allowing it to be applicable to large graphs with more than 10000 nodes.',
	 'authors': u'Juyong Lee, Steven P. Gross, Jooyoung Lee,',
	 'category': u'Computer Science ',
	 'date': '2012-2-24',
	 'pdflink': u'http://arxiv.org/pdf/1202.5398',
	 'subjects': u'Computational Physics (physics.comp-ph)',
	 'title': u'\nMod-CSA: Modularity optimization by conformational space annealing',
	 'urllink': u'http://arxiv.org/abs/1202.5398'}
2015-03-23 23:26:06+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.6782> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:26:06+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.6782>
	{'abstract': u'Capturing disused satellites in orbit and their controlled reentry is the aim of the DEOS space mission. Satellites that ran out of fuel or got damaged pose a threat to working projects in orbit. Additionally, the reentry of such objects endangers the population as the place of impact cannot be controlled anymore. This paper demonstrates the modelling of a rendezvous szenario between a controlled service satellite and an uncontrolled target. The situation is modelled via first order ordinary differental equations where a stable target is considered. In order to prevent a collision of the two spacecrafts and to ensure both satellites are docked at the end of the maneuver, additional state constraints, box contraints for the control and a time dependent rendezvous condition for the final time are added. The problem is formulated as an optimal control problem with Bolza type cost functional and solved using a full discretization approach in AMPL/IpOpt. Last, simulation results for capturing a tumbling satellite are given.',
	 'authors': u'Johannes Michael, Kurt Chudej, J\xfcrgen Pannek,',
	 'category': u'Computer Science ',
	 'date': '2012-3-30',
	 'pdflink': u'http://arxiv.org/pdf/1203.6782',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nModelling and Optimal Control of a Docking Maneuver with an Uncontrolled  Satellite',
	 'urllink': u'http://arxiv.org/abs/1203.6782'}
2015-03-23 23:26:20+0000 [xxu46_4] INFO: Crawled 381 pages (at 4 pages/min), scraped 375 items (at 4 items/min)
2015-03-23 23:26:23+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0157> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:26:23+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0157>
	{'abstract': u"A (t,n)-threshold secret sharing scheme is a method to distribute a secret among n participants in such a way that any t participants can recover the secret, but no t-1 participants can. In this paper, we propose two secret sharing schemes using non-abelian groups. One scheme is the special case where all the participants must get together to recover the secret. The other one is a (t,n)-threshold scheme that is a combination of Shamir's scheme and the group-theoretic scheme proposed in this paper.",
	 'authors': u'Maggie Habeeb, Delaram Kahrobaei, Vladimir Shpilrain,',
	 'category': u'Computer Science ',
	 'date': '2012-5-1',
	 'pdflink': u'http://arxiv.org/pdf/1205.0157',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nA Secret Sharing Scheme Based on Group Presentations and the Word  Problem',
	 'urllink': u'http://arxiv.org/abs/1205.0157'}
2015-03-23 23:26:40+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0988> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:26:40+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0988>
	{'abstract': u'Data centers form a key part of the infrastructure upon which a variety of information technology services are built. They provide the capabilities of centralized repository for storage, management, networking and dissemination of data. With the rapid increase in the capacity and size of data centers, there is a continuous increase in the demand for energy consumption. These data centers not only consume a tremendous amount of energy but are riddled with IT inefficiencies. Data center are plagued with thousands of servers as major components. These servers consume huge energy without performing useful work. In an average server environment, 30% of the servers are "dead" only consuming energy, without being properly utilized. This paper proposes a five step model using an emerging technology called virtualization to achieve energy efficient data centers. The proposed model helps Data Center managers to properly implement virtualization technology in their data centers to make them green and energy efficient so as to ensure that IT infrastructure contributes as little as possible to the emission of greenhouse gases, and helps to regain power and cooling capacity, recapture resilience and dramatically reducing energy costs and total cost of ownership.',
	 'authors': u'Mueen Uddin, Azizah Abdul Rahman,',
	 'category': u'Computer Science ',
	 'date': '2012-4-7',
	 'pdflink': u'http://arxiv.org/pdf/1206.0988',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nVirtualization Implementation Model for Cost Effective & Efficient Data  Centers',
	 'urllink': u'http://arxiv.org/abs/1206.0988'}
2015-03-23 23:26:49+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.5337> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:26:49+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.5337>
	{'abstract': u'A property of finite graphs is called nondeterministically testable if it has a "certificate" such that once the certificate is specified, its correctness can be verified by random local testing. In this paper we study certificates that consist of one or more unary and/or binary relations on the nodes, in the case of dense graphs. Using the theory of graph limits, we prove that nondeterministically testable properties are also deterministically testable.',
	 'authors': u'L\xe1szl\xf3 Lov\xe1sz, Katalin Vesztergombi,',
	 'category': u'Computer Science ',
	 'date': '2012-2-23',
	 'pdflink': u'http://arxiv.org/pdf/1202.5337',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nNondeterministic graph property testing',
	 'urllink': u'http://arxiv.org/abs/1202.5337'}
2015-03-23 23:27:02+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.6758> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:27:02+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.6758>
	{'abstract': u'In this paper we develop hydrodynamic models using spectral differential operators to investigate the spatial stability of swirling fluid systems. Including viscosity as a valid parameter of the fluid, the hydrodynamic model is derived using a nodal Lagrangian basis and the polynomial eigenvalue problem describing the viscous spatial stability is reduced to a generalized eigenvalue problem using the companion vector method. For inviscid study the hydrodynamic model is obtained by means of a class of shifted orthogonal expansion functions and the spectral differentiation matrix is derived to approximate the discrete derivatives. The models were applied to a Q-vortex structure, both schemes providing good results.',
	 'authors': u'Diana Alina Bistrian, Florica Ioana Dragomirescu, George Savii,',
	 'category': u'Computer Science ',
	 'date': '2012-3-30',
	 'pdflink': u'http://arxiv.org/pdf/1203.6758',
	 'subjects': u'Spectral Theory (math.SP)',
	 'title': u'\nSpectral Differentiation Operators and Hydrodynamic Models for Stability  of Swirling Fluid Systems',
	 'urllink': u'http://arxiv.org/abs/1203.6758'}
2015-03-23 23:27:18+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0144> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:27:18+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0144>
	{'abstract': u'The significant progress in constructing graph spanners that are sparse (small number of edges) or light (low total weight) has skipped spanners that are everywhere-sparse (small maximum degree). This disparity is in line with other network design problems, where the maximum-degree objective has been a notorious technical challenge. Our main result is for the Lowest Degree 2-Spanner (LD2S) problem, where the goal is to compute a 2-spanner of an input graph so as to minimize the maximum degree. We design a polynomial-time algorithm achieving approximation factor , where is the maximum degree of the input graph. The previous -approximation was proved nearly two decades ago by Kortsarz and Peleg [SODA 1994, SICOMP 1998]. Our main conceptual contribution is to establish a formal connection between LD2S and a variant of the Densest k-Subgraph (DkS) problem. Specifically, we design for both problems strong relaxations based on the Sherali-Adams linear programming (LP) hierarchy, and show that "faithful" randomized rounding of the DkS-variant can be used to round LD2S solutions. Our notion of faithfulness intuitively means that all vertices and edges are chosen with probability proportional to their LP value, but the precise formulation is more subtle. Unfortunately, the best algorithms known for DkS use the Lov \'asz-Schrijver LP hierarchy in a non-faithful way [Bhaskara, Charikar, Chlamtac, Feige, and Vijayaraghavan, STOC 2010]. Our main technical contribution is to overcome this shortcoming, while still matching the gap that arises in random graphs by planting a subgraph with same log-density.',
	 'authors': u'Eden Chlamtac, Michael Dinitz, Robert Krauthgamer,',
	 'category': u'Computer Science ',
	 'date': '2012-5-1',
	 'pdflink': u'http://arxiv.org/pdf/1205.0144',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nEverywhere-Sparse Spanners via Dense Subgraphs',
	 'urllink': u'http://arxiv.org/abs/1205.0144'}
2015-03-23 23:27:20+0000 [xxu46_4] INFO: Crawled 386 pages (at 5 pages/min), scraped 380 items (at 5 items/min)
2015-03-23 23:27:31+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0985> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:27:31+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0985>
	{'abstract': u"The emph of a Boolean function are its degree-0 and degree-1 Fourier coefficients. It has been known since 1961 (Chow, Tannenbaum) that the (exact values of the) Chow parameters of any linear threshold function uniquely specify within the space of all Boolean functions, but until recently (O'Donnell and Servedio) nothing was known about efficient algorithms for emph (exactly or approximately) from exact or approximate values of its Chow parameters. We refer to this reconstruction problem as the emph Our main result is a new algorithm for the Chow Parameters Problem which, given (sufficiently accurate approximations to) the Chow parameters of any linear threshold function , runs in time and with high probability outputs a representation of an LTF that is -close to . The only previous algorithm (O'Donnell and Servedio) had running time As a byproduct of our approach, we show that for any linear threshold function over , there is a linear threshold function which is -close to and has all weights that are integers at most . This significantly improves the best previous result of Diakonikolas and Servedio which gave a weight bound, and is close to the known lower bound of (Goldberg, Servedio). Our techniques also yield improved algorithms for related problems in learning theory.",
	 'authors': u'Anindya De, Ilias Diakonikolas, Vitaly Feldman, Rocco A. Servedio,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.0985',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nNearly optimal solutions for the Chow Parameters Problem and low-weight  approximation of halfspaces',
	 'urllink': u'http://arxiv.org/abs/1206.0985'}
2015-03-23 23:27:45+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.5299> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:27:45+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.5299>
	{'abstract': u'Culturomics was recently introduced as the application of high-throughput data collection and analysis to the study of human culture. Here we make use of this data by investigating fluctuations in yearly usage frequencies of specific words that describe social and natural phenomena, as derived from books that were published over the course of the past two centuries. We show that the determination of the Hurst parameter by means of fractal analysis provides fundamental insights into the nature of long-range correlations contained in the culturomic trajectories, and by doing so, offers new interpretations as to what might be the main driving forces behind the examined phenomena. Quite remarkably, we find that social and natural phenomena are governed by fundamentally different processes. While natural phenomena have properties that are typical for processes with persistent long-range correlations, social phenomena are better described as nonstationary, on-off intermittent, or Levy walk processes.',
	 'authors': u'Jianbo Gao, Jing Hu, Xiang Mao, Matjaz Perc,',
	 'category': u'Computer Science ',
	 'date': '2012-2-23',
	 'pdflink': u'http://arxiv.org/pdf/1202.5299',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nCulturomics meets random fractal theory: Insights into long-range  correlations of social and natural phenomena over the past two centuries',
	 'urllink': u'http://arxiv.org/abs/1202.5299'}
2015-03-23 23:28:02+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.6749> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:28:02+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.6749>
	{'abstract': u"We consider the dynamics, existence and stability of the equilibrium states for large populations of individuals who can play various types of non--cooperative games. The players imitate the most attractive strategies, and the choice is motivated not only by the material payoffs of the strategies, but also by their popularity in the population. The parameter which determines the weights of both factors in the equilibrium states has the same analytical form for all types of considered games, and is identified with the sensitivity to reinforcements parameter in the Hernstein's Matching Law. We prove theorems of existence and uniqueness, and discuss examples of multiple locally stable polymorphic equilibria for the considered types of games.",
	 'authors': u'Tadeusz Platkowski, Jan Zakrzewski,',
	 'category': u'Computer Science ',
	 'date': '2012-3-30',
	 'pdflink': u'http://arxiv.org/pdf/1203.6749',
	 'subjects': u'Adaptation and Self-Organizing Systems (nlin.AO)',
	 'title': u'\nGame Dynamics for Players with Social and Material Preferences',
	 'urllink': u'http://arxiv.org/abs/1203.6749'}
2015-03-23 23:28:15+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0139> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:28:15+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0139>
	{'abstract': u'-Scale is an enrichment of lambda calculus which is adapted to emergent algebras. It can be used therefore in metric spaces with dilations.',
	 'authors': u'Marius Buliga,',
	 'category': u'Computer Science ',
	 'date': '2012-5-1',
	 'pdflink': u'http://arxiv.org/pdf/1205.0139',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\n$\u03bb$-Scale, a lambda calculus for spaces with dilations',
	 'urllink': u'http://arxiv.org/abs/1205.0139'}
2015-03-23 23:28:20+0000 [xxu46_4] INFO: Crawled 390 pages (at 4 pages/min), scraped 384 items (at 4 items/min)
2015-03-23 23:28:30+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0983> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:28:30+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0983>
	{'abstract': u'The Coding Theorem of L.A. Levin connects unconditional prefix Kolmogorov complexity with the discrete universal distribution. There are conditional versions referred to in several publications but as yet there exist no written proofs in English. Here we provide those proofs. They use a different definition than the standard one for the conditional version of the discrete universal distribution. Under the classic definition of conditional probability, there is no conditional version of the Coding Theorem.',
	 'authors': u'Paul M. B. Vitanyi,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.0983',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nConditional Kolmogorov Complexity and Universal Probability',
	 'urllink': u'http://arxiv.org/abs/1206.0983'}
2015-03-23 23:28:44+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.5198> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:28:44+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.5198>
	{'abstract': u"We have developed different network approaches to complex patterns of frictional interfaces (contact areas developments). Here, we analyze the dynamics of static friction. We found, under the correlation measure, the fraction of triangles correlates with the detachment fronts. Also, for all types of the loops (such as triangles), there is a universal power law between nodes' degree and motifs where motifs frequency follow a power law. This shows high energy localization is characterized by fast variation of the loops fraction. Also, this proves that the congestion of loops occurs around hubs. Furthermore, the motif distributions and modularity space of networks -in terms of within-module degree and participation coefficient- show universal trends, indicating an in common aspect of energy flow in shear ruptures. Moreover, we confirmed that slow ruptures generally hold small localization, while regular ruptures carry a high level of energy localization. We proposed that assortativity, as an index to correlation of node's degree, can uncover acoustic features of the interfaces. We showed that increasing assortativity induces a nearly silent period of fault's activities. Also, we proposed that slow ruptures resulted from within-module developments rather than extra-modules of the networks. Our approach presents a completely new perspective of the evolution of shear ruptures.",
	 'authors': u'H.O. Ghaffari, R.P. Young,',
	 'category': u'Computer Science ',
	 'date': '2012-2-22',
	 'pdflink': u'http://arxiv.org/pdf/1202.5198',
	 'subjects': u'Geophysics (physics.geo-ph)',
	 'title': u'\nNetwork Theory, Cracking and Frictional Sliding',
	 'urllink': u'http://arxiv.org/abs/1202.5198'}
2015-03-23 23:28:56+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.6742> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:28:56+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.6742>
	{'abstract': u'The large amount of information contained in bibliographic databases has recently boosted the use of citations, and other indicators based on citation numbers, as tools for the quantitative assessment of scientific research. Citations counts are often interpreted as proxies for the scientific influence of papers, journals, scholars, and institutions. However, a rigorous and scientifically grounded methodology for a correct use of citation counts is still missing. In particular, cross-disciplinary comparisons in terms of raw citation counts systematically favors scientific disciplines with higher citation and publication rates. Here we perform an exhaustive study of the citation patterns of millions of papers, and derive a simple transformation of citation counts able to suppress the disproportionate citation counts among scientific domains. We find that the transformation is well described by a power-law function, and that the parameter values of the transformation are typical features of each scientific discipline. Universal properties of citation patterns descend therefore from the fact that citation distributions for papers in a specific field are all part of the same family of univariate distributions.',
	 'authors': u'Filippo Radicchi, Claudio Castellano,',
	 'category': u'Computer Science ',
	 'date': '2012-3-30',
	 'pdflink': u'http://arxiv.org/pdf/1203.6742',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nA reverse engineering approach to the suppression of citation biases  reveals universal properties of citation distributions',
	 'urllink': u'http://arxiv.org/abs/1203.6742'}
2015-03-23 23:29:08+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0131> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:29:08+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0131>
	{'abstract': u'A proper edge -coloring of a graph is a coloring of edges of with colors such that each of colors is used, and adjacent edges are colored differently. The set of colors of edges incident with a vertex of is called a spectrum of . A proper edge -coloring of a graph is interval for its vertex if the spectrum of is an interval of integers. A proper edge -coloring of a graph is persistent-interval for its vertex if the spectrum of is an interval of integers beginning from the color 1. For graphs from some classes of graphs, we obtain estimates for the possible number of vertices for which a proper edge -coloring of can be interval or persistent-interval.',
	 'authors': u'R.R. Kamalian,',
	 'category': u'Computer Science ',
	 'date': '2012-5-1',
	 'pdflink': u'http://arxiv.org/pdf/1205.0131',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nEstimates for the number of vertices with an interval spectrum in proper  edge colorings of some graphs',
	 'urllink': u'http://arxiv.org/abs/1205.0131'}
2015-03-23 23:29:20+0000 [xxu46_4] INFO: Crawled 394 pages (at 4 pages/min), scraped 388 items (at 4 items/min)
2015-03-23 23:29:24+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0981> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:29:24+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0981>
	{'abstract': u"The emergence of online social networks and the growing popularity of digital communication has resulted in an increasingly amount of information about individuals available on the Internet. Social network users are given the freedom to create complex digital identities, and enrich them with truthful or even fake personal information. However, this freedom has led to serious security and privacy incidents, due to the role users' identities play in establishing social and privacy settings. In this paper, we take a step toward a better understanding of online information exposure. Based on the detailed analysis of a sample of real-world data, we develop a deception model for online users. The model uses a game theoretic approach to characterizing a user's willingness to release, withhold or lie about information depending on the behavior of individuals within the user's circle of friends. In the model, we take into account both the heterogeneous nature of users and their different attitudes, as well as the different types of information they may expose online.",
	 'authors': u'Anna Squicciarini, Christopher Griffin,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.0981',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nAn Informed Model of Personal Information Release in Social Networking  Sites',
	 'urllink': u'http://arxiv.org/abs/1206.0981'}
2015-03-23 23:29:41+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.5041> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:29:41+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.5041>
	{'abstract': u'We analyze a simple dynamical network model which describes the limited capacity of nodes to process the input information. For a suitable choice of the parameters, the information flow pattern is characterized by exponential distribution of the incoming information and a fat-tailed distribution of the outgoing information, as a signature of the law of diminishing marginal returns. The analysis of a real EEG data-set shows that similar phenomena may be relevant for brain signals.',
	 'authors': u'Daniele Marinazzo, Mario Pellicoro, Guorong Wu, Leonardo Angelini, Sebastiano Stramaglia,',
	 'category': u'Computer Science ',
	 'date': '2012-2-22',
	 'pdflink': u'http://arxiv.org/pdf/1202.5041',
	 'subjects': u'Data Analysis, Statistics and Probability (physics.data-an)',
	 'title': u'\nInformation flow in a network model and the law of diminishing marginal  returns',
	 'urllink': u'http://arxiv.org/abs/1202.5041'}
2015-03-23 23:29:58+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.6673> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:29:58+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.6673>
	{'abstract': u'In this work we study a modified Susceptible-Infected-Susceptible (SIS) model in which the infection rate decays exponentially with the number of reinfections , saturating after . We find a critical decaying rate above which a finite fraction of the population becomes permanently infected. From the mean-field solution and computer simulations on hypercubic lattices we find evidences that the upper critical dimension is 6 like in the SIR model, which can be mapped in ordinary percolation.',
	 'authors': u'Nuno Crokidakis, Marcio Argollo de Menezes,',
	 'category': u'Computer Science ',
	 'date': '2012-3-29',
	 'pdflink': u'http://arxiv.org/pdf/1203.6673',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nCritical behavior of the SIS epidemic model with time-dependent  infection rate',
	 'urllink': u'http://arxiv.org/abs/1203.6673'}
2015-03-23 23:30:14+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0130> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:30:14+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0130>
	{'abstract': u'A proper edge -coloring of a graph is a coloring of edges of with colors such that all colors are used, and no two adjacent edges receive the same color. The set of colors of edges incident with a vertex is called a spectrum of . An arbitrary nonempty subset of consecutive integers is called an interval. We say that a proper edge -coloring of a graph is interval in the vertex if the spectrum of is an interval. We say that a proper edge -coloring of a graph is interval on a subset of vertices of , if for an arbitrary , is interval in . We say that a subset of vertices of has an -property if there is a proper edge -coloring of which is interval on . If is a graph, and a subset of its vertices has an -property, then the minimum value of for which there is a proper edge -coloring of interval on is denoted by . In this paper, for some bipartite graphs, we estimate the value of this parameter in that cases when coincides with the set of all vertices of one part of the graph.',
	 'authors': u'R.R. Kamalian,',
	 'category': u'Computer Science ',
	 'date': '2012-5-1',
	 'pdflink': u'http://arxiv.org/pdf/1205.0130',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nOn one-sided interval edge colorings of biregular bipartite graphs',
	 'urllink': u'http://arxiv.org/abs/1205.0130'}
2015-03-23 23:30:20+0000 [xxu46_4] INFO: Crawled 398 pages (at 4 pages/min), scraped 392 items (at 4 items/min)
2015-03-23 23:30:31+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0978> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:30:31+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0978>
	{'abstract': u'In todays world of technology and gadgets almost every person is having a portable device, be it a laptop or the smart phones. The user would like to have all the services at his fingertips and access them through the portable device he owns. Maybe he wants some data from the fellow user or from the service provider or maybe he wants to control his smart devices at home from wherever he is. In the present era of mobile environments, interactions between the user device and the service provider must be secure enough regardless of the type of device used to access or utilize the services. In this paper we propose a "Secure Three Way Authentication (STWA)" technique intended to preserve the user privacy and to accomplish ownership authentication in order to securely deliver the services to the user devices. This technique will also help the users or the service providers to check if the device is compromised or not with the help of the encrypted pass-phrases that are being exchanged.',
	 'authors': u'Pradeep B. H., Sanjay Singh,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.0978',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nPrivacy Preserving and Ownership Authentication in Ubiquitous Computing  Devices using Secure Three Way Authentication',
	 'urllink': u'http://arxiv.org/abs/1206.0978'}
2015-03-23 23:30:44+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.4974> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:30:44+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.4974>
	{'abstract': u'Motivated by the analysis of social networks, we study a model of random networks that has both a given degree distribution and a tunable clustering coefficient. We consider two types of growth processes on these graphs: diffusion and symmetric threshold model. The diffusion process is inspired from epidemic models. It is characterized by an infection probability, each neighbor transmitting the epidemic independently. In the symmetric threshold process, the interactions are still local but the propagation rule is governed by a threshold (that might vary among the different nodes). An interesting example of symmetric threshold process is the contagion process, which is inspired by a simple coordination game played on the network. Both types of processes have been used to model spread of new ideas, technologies, viruses or worms and results have been obtained for random graphs with no clustering. In this paper, we are able to analyze the impact of clustering on the growth processes. While clustering inhibits the diffusion process, its impact for the contagion process is more subtle and depends on the connectivity of the graph: in a low connectivity regime, clustering also inhibits the contagion, while in a high connectivity regime, clustering favors the appearance of global cascades but reduces their size. For both diffusion and symmetric threshold models, we characterize conditions under which global cascades are possible and compute their size explicitly, as a function of the degree distribution and the clustering coefficient. Our results are applied to regular or power-law graphs with exponential cutoff and shed new light on the impact of clustering.',
	 'authors': u'Emilie Coupechoux, Marc Lelarge,',
	 'category': u'Computer Science ',
	 'date': '2012-2-22',
	 'pdflink': u'http://arxiv.org/pdf/1202.4974',
	 'subjects': u'Probability (math.PR)',
	 'title': u'\nHow Clustering Affects Epidemics in Random Networks',
	 'urllink': u'http://arxiv.org/abs/1202.4974'}
2015-03-23 23:30:58+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.6668> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:30:58+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.6668>
	{'abstract': u'The mixing time of an ergodic, reversible Markov chain can be bounded in terms of the eigenvalues of the chain: specifically, the second-largest eigenvalue and the smallest eigenvalue. It has become standard to focus only on the second-largest eigenvalue, by making the Markov chain "lazy". (A lazy chain does nothing at each step with probability at least 1/2, and has only nonnegative eigenvalues.) An alternative approach to bounding the smallest eigenvalue was given by Diaconis and Stroock and Diaconis and Saloff-Coste. We give examples to show that using this approach it can be quite easy to obtain a bound on the smallest eigenvalue of a combinatorial Markov chain which is several orders of magnitude below the best-known bound on the second-largest eigenvalue.',
	 'authors': u'Catherine Greenhill,',
	 'category': u'Computer Science ',
	 'date': '2012-3-29',
	 'pdflink': u'http://arxiv.org/pdf/1203.6668',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nMaking Markov chains less lazy',
	 'urllink': u'http://arxiv.org/abs/1203.6668'}
2015-03-23 23:31:12+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0128> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:31:12+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0128>
	{'abstract': u'A proper edge -coloring of a graph is a coloring of its edges with colors such that all colors are used, and no two adjacent edges receive the same color. For any integer , all possible values of are found, for which there exists such a proper edge -coloring of the simple cycle C(n), which uses for each pair of adjacent edges either consecutive colors or the first and the last ones.',
	 'authors': u'R.R. Kamalian,',
	 'category': u'Computer Science ',
	 'date': '2012-5-1',
	 'pdflink': u'http://arxiv.org/pdf/1205.0128',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nIt was not known about simple cycles',
	 'urllink': u'http://arxiv.org/abs/1205.0128'}
2015-03-23 23:31:20+0000 [xxu46_4] INFO: Crawled 402 pages (at 4 pages/min), scraped 396 items (at 4 items/min)
2015-03-23 23:31:30+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0976> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:31:30+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0976>
	{'abstract': u"In this paper we present a synthesis of the work performed on two inference algorithms: the Pearl's belief propagation (BP) algorithm applied to Bayesian networks without loops (i.e. polytree) and the Loopy belief propagation (LBP) algorithm (inspired from the BP) which is applied to networks containing undirected cycles. It is known that the BP algorithm, applied to Bayesian networks with loops, gives incorrect numerical results i.e. incorrect posterior probabilities. Murphy and al. [7] find that the LBP algorithm converges on several networks and when this occurs, LBP gives a good approximation of the exact posterior probabilities. However this algorithm presents an oscillatory behaviour when it is applied to QMR (Quick Medical Reference) network [15]. This phenomenon prevents the LBP algorithm from converging towards a good approximation of posterior probabilities. We believe that the translation of the inference computation problem from the probabilistic framework to the possibilistic framework will allow performance improvement of LBP algorithm. We hope that an adaptation of this algorithm to a possibilistic causal network will show an improvement of the convergence of LBP.",
	 'authors': u'Amen Ajroud, Mohamed Nazih Omri, Habib Youssef, Salem Benferhat,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.0976',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nLoopy Belief Propagation in Bayesian Networks : origin and possibilistic  perspectives',
	 'urllink': u'http://arxiv.org/abs/1206.0976'}
2015-03-23 23:31:39+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.4971> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:31:39+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.4971>
	{'abstract': u"We present a numerical model for the dynamics of thin viscous threads based on a discrete, Lagrangian formulation of the smooth equations. The model makes use of a condensed set of coordinates, called the centerline/spin representation: the kinematical constraints linking the centerline's tangent to the orientation of the material frame is used to eliminate two out of three degrees of freedom associated with rotations. Based on a description of twist inspired from discrete differential geometry and from variational principles, we build a full-fledged discrete viscous thread model, which includes in particular a discrete representation of the internal viscous stress. Consistency of the discrete model with the classical, smooth equations is established formally in the limit of a vanishing discretization length. The discrete models lends itself naturally to numerical implementation. Our numerical method is validated against reference solutions for steady coiling. The method makes it possible to simulate the unsteady behavior of thin viscous jets in a robust and efficient way, including the combined effects of inertia, stretching, bending, twisting, large rotations and surface tension.",
	 'authors': u'Basile Audoly, Nicolas Clauvelin, Pierre-Thomas Brun, Mikl\xf3s Bergou, Eitan Grinspun, Max Wardetzky,',
	 'category': u'Computer Science ',
	 'date': '2012-2-22',
	 'pdflink': u'http://arxiv.org/pdf/1202.4971',
	 'subjects': u'Fluid Dynamics (physics.flu-dyn)',
	 'title': u'\nA discrete geometric approach for simulating the dynamics of thin  viscous threads',
	 'urllink': u'http://arxiv.org/abs/1202.4971'}
2015-03-23 23:31:55+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.6536> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:31:55+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.6536>
	{'abstract': u"We give a computer-assisted proof of the fact that . This solves one of the three remaining open cases in Hendry's table, which listed the Ramsey numbers for pairs of graphs on 5 vertices. We find that there exist no -good graphs containing a on 23 or 24 vertices, where a graph is -good if does not contain and the complement of does not contain . The unique -good graph containing a on 22 vertices is presented.",
	 'authors': u'Jesse A. Calvert, Michael J. Schuster, Stanis\u0142aw P. Radziszowski,',
	 'category': u'Computer Science ',
	 'date': '2012-3-29',
	 'pdflink': u'http://arxiv.org/pdf/1203.6536',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nComputing the Ramsey Number $R(K_5-P_3,K_5)$',
	 'urllink': u'http://arxiv.org/abs/1203.6536'}
2015-03-23 23:32:12+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0126> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:32:12+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0126>
	{'abstract': u"The probabilistic (or quantitative) modal mu-calculus is a fixed-point logic de- signed for expressing properties of probabilistic labeled transition systems (PLTS). Two semantics have been studied for this logic, both assigning to every process state a value in the interval [0,1] representing the probability that the property expressed by the formula holds at the state. One semantics is denotational and the other is a game semantics, specified in terms of two-player stochastic games. The two semantics have been proved to coincide on all finite PLTS's, but the equivalence of the two semantics on arbitrary models has been open in literature. In this paper we prove that the equivalence indeed holds for arbitrary infinite models, and thus our result strengthens the fruitful connection between denotational and game semantics. Our proof adapts the unraveling or unfolding method, a general proof technique for proving result of parity games by induction on their complexity.",
	 'authors': u'Matteo Mio,',
	 'category': u'Computer Science ',
	 'date': '2012-5-1',
	 'pdflink': u'http://arxiv.org/pdf/1205.0126',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nOn the equivalence of game and denotational semantics for the  probabilistic mu-calculus',
	 'urllink': u'http://arxiv.org/abs/1205.0126'}
2015-03-23 23:32:20+0000 [xxu46_4] INFO: Crawled 406 pages (at 4 pages/min), scraped 400 items (at 4 items/min)
2015-03-23 23:32:20+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0974> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:32:20+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0974>
	{'abstract': u'In this paper, we study the performance of IPOP-saACM-ES, recently proposed self-adaptive surrogate-assisted Covariance Matrix Adaptation Evolution Strategy. The algorithm was tested using restarts till a total number of function evaluations of was reached, where is the dimension of the function search space. The experiments show that the surrogate model control allows IPOP-saACM-ES to be as robust as the original IPOP-aCMA-ES and outperforms the latter by a factor from 2 to 3 on 6 benchmark problems with moderate noise. On 15 out of 30 benchmark problems in dimension 20, IPOP-saACM-ES exceeds the records observed during BBOB-2009 and BBOB-2010.',
	 'authors': u'Ilya Loshchilov, Marc Schoenauer, Mich\xe8le Sebag,',
	 'category': u'Computer Science ',
	 'date': '2012-4-24',
	 'pdflink': u'http://arxiv.org/pdf/1206.0974',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nBlack-box optimization benchmarking of IPOP-saACM-ES on the BBOB-2012  noisy testbed',
	 'urllink': u'http://arxiv.org/abs/1206.0974'}
2015-03-23 23:32:35+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.4842> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:32:35+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.4842>
	{'abstract': u'For a graph with a given list assignment on the vertices, we give an algebraical description of the set of all weights such that is -colorable, called permissible weights. Moreover, for a graph with a given list and a given permissible weight , we describe the set of all -colorings of . By the way, we solve the . Furthermore, we describe the set of solutions to the : when is not a permissible weight, we find all the nearest permissible weights . Finally, we give a solution to the non-recoloring problem keeping a given subcoloring.',
	 'authors': u'Yves Aubry, Jean-Christophe Godin, Olivier Togni,',
	 'category': u'Computer Science ',
	 'date': '2012-2-22',
	 'pdflink': u'http://arxiv.org/pdf/1202.4842',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nVectorial solutions to list multicoloring problems on graphs',
	 'urllink': u'http://arxiv.org/abs/1202.4842'}
2015-03-23 23:32:48+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.6276> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:32:48+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.6276>
	{'abstract': u'Variable selection is recognized as one of the most critical steps in statistical modeling. The problems encountered in engineering and social sciences are commonly characterized by over-abundance of explanatory variables, non-linearities and unknown interdependencies between the regressors. An added difficulty is that the analysts may have little or no prior knowledge on the relative importance of the variables. To provide a robust method for model selection, this paper introduces the Multi-objective Genetic Algorithm for Variable Selection (MOGA-VS) that provides the user with an optimal set of regression models for a given data-set. The algorithm considers the regression problem as a two objective task, and explores the Pareto-optimal (best subset) models by preferring those models over the other which have less number of regression coefficients and better goodness of fit. The model exploration can be performed based on in-sample or generalization error minimization. The model selection is proposed to be performed in two steps. First, we generate the frontier of Pareto-optimal regression models by eliminating the dominated models without any user intervention. Second, a decision making process is executed which allows the user to choose the most preferred model using visualizations and simple metrics. The method has been evaluated on a recently published real dataset on Communities and Crime within United States.',
	 'authors': u'Ankur Sinha, Pekka Malo, Timo Kuosmanen,',
	 'category': u'Computer Science ',
	 'date': '2012-3-28',
	 'pdflink': u'http://arxiv.org/pdf/1203.6276',
	 'subjects': u'Computation (stat.CO)',
	 'title': u'\nA Multi-objective Exploratory Procedure for Regression Model Selection',
	 'urllink': u'http://arxiv.org/abs/1203.6276'}
2015-03-23 23:32:59+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0125> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:32:59+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0125>
	{'abstract': u'A proper edge -coloring of a graph is a coloring of edges of with colors such that all colors are used, and no two adjacent edges receive the same color. The set of colors of edges incident with a vertex is called a spectrum of . An arbitrary nonempty subset of consecutive integers is called an interval. Suppose that all edges of a graph are colored in the game of Alice and Bob with asymmetric distribution of roles. Alice determines the number of colors in the future proper edge coloring of and aspires to minimize the number of vertices with an interval spectrum in it. Bob colors edges of with colors and aspires to maximize that number. is equal to the number of vertices of with an interval spectrum at the finish of the game on the supposition that both players choose their best strategies. In this paper, for arbitrary positive integers and , the exact value of the parameter is found.',
	 'authors': u'A.M. Khachatryan, R.R. Kamalian,',
	 'category': u'Computer Science ',
	 'date': '2012-5-1',
	 'pdflink': u'http://arxiv.org/pdf/1205.0125',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nOn the parameter $\u03bc_{21}$ of a complete bipartite graph',
	 'urllink': u'http://arxiv.org/abs/1205.0125'}
2015-03-23 23:33:11+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0968> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:33:11+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0968>
	{'abstract': u"In this paper we present a synthesis of work performed on tow information retrieval models: Bayesian network information retrieval model witch encode (in) dependence relation between terms and possibilistic network information retrieval model witch make use of necessity and possibility measures to represent the fuzziness of pertinence measure. It is known that the use of a general Bayesian network methodology as the basis for an IR system is difficult to tackle. The problem mainly appears because of the large number of variables involved and the computational efforts needed to both determine the relationships between variables and perform the inference processes. To resolve these problems, many models have been proposed such as BNR model. Generally, Bayesian network models doesn't consider the fuzziness of natural language in the relevance measure of a document to a given query and possibilistic models doesn't undertake the dependence relations between terms used to index documents. As a first solution we propose a hybridization of these two models in one that will undertake both the relationship between terms and the intrinsic fuzziness of natural language. We believe that the translation of Bayesian network model from the probabilistic framework to possibilistic one will allow a performance improvement of BNRM.",
	 'authors': u'Kamel Garrouch, Mohamed Nazih Omri, Bachir Elayeb,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.0968',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nPertinent Information retrieval based on Possibilistic Bayesian network  : origin and possibilistic perspective',
	 'urllink': u'http://arxiv.org/abs/1206.0968'}
2015-03-23 23:33:20+0000 [xxu46_4] INFO: Crawled 411 pages (at 5 pages/min), scraped 405 items (at 5 items/min)
2015-03-23 23:33:21+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.4707> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:33:21+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.4707>
	{'abstract': u'This preliminary work presents a simple derivation of the standard model-free control in order to control switching minimum phase, non-minimum phase and time-delay systems. The robustness of the proposed method is studied in simulation.',
	 'authors': u'Lo\xefc Michel,',
	 'category': u'Computer Science ',
	 'date': '2012-2-21',
	 'pdflink': u'http://arxiv.org/pdf/1202.4707',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nA unified model-free controller for switching minimum phase, non-minimum  phase and time-delay systems',
	 'urllink': u'http://arxiv.org/abs/1202.4707'}
2015-03-23 23:33:33+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.6242> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:33:33+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.6242>
	{'abstract': u'Quantum computations are easily represented in the graphical notation known as the ZX-calculus, a.k.a. the red-green calculus. We demonstrate its use in reasoning about measurement-based quantum computing, where the graphical syntax directly captures the structure of the entangled states used to represent computations, and show that the notion of information flow within the entangled states gives rise to rewriting strategies for proving the correctness of quantum programs.',
	 'authors': u'Ross Duncan,',
	 'category': u'Computer Science ',
	 'date': '2012-3-28',
	 'pdflink': u'http://arxiv.org/pdf/1203.6242',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nA graphical approach to measurement-based quantum computing',
	 'urllink': u'http://arxiv.org/abs/1203.6242'}
2015-03-23 23:33:48+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0124> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:33:48+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0124>
	{'abstract': u'This paper deals with the study of Earliest Deadline First (EDF) which is an optimal scheduling algorithm for uniprocessor real time systems use for scheduling the periodic task in soft real-time multiprocessor systems. In hard real-time systems, a significant disparity exists EDF-based schemes and RMA scheduling (which is the only known way of optimally scheduling recurrent real-time tasks on multiprocessors): on M processors, all known EDF variants have utilization-based schedulability bounds of approximately M/2, while RMA algorithms can fully utilize all processors. This is unfortunate because EDF based algorithms entail lower scheduling and task migration overheads. In work on hard real-time systems, it has been shown that this disparity in Schedulability can be lessened by placing caps on per task utilizations. Our main contribution is a new EDF based scheme that ensures bounded deadline tardiness. In this scheme, per-task utilizations must be focused,but overall utilization need not be stricted. Our scheme should enable a wide range of soft real-time applications to be scheduled with no constraints on total utilization. Also propose techniques and heuristics that can be used to reduce tardiness as well as increase the efficiency of task.',
	 'authors': u'Jagbeer Singh, Satyendra Prasad Singh,',
	 'category': u'Computer Science ',
	 'date': '2012-5-1',
	 'pdflink': u'http://arxiv.org/pdf/1205.0124',
	 'subjects': u'Operating Systems (cs.OS)',
	 'title': u'\nSchedulability Test for Soft Real-Time Systems under Multiprocessor  Environment by using an Earliest Deadline First Scheduling Algorithm',
	 'urllink': u'http://arxiv.org/abs/1205.0124'}
2015-03-23 23:34:00+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0956> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:34:00+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0956>
	{'abstract': u'In the framework of write-once memory (WOM) codes, it is important to distinguish between codes that can be decoded directly and those that require that the decoder knows the current generation to successfully decode the state of the memory. A widely used approach to construct WOM codes is to design first nondecodable codes that approach the boundaries of the capacity region, and then make them decodable by appending additional cells that store the current generation, at an expense of a rate loss. In this paper, we propose an alternative method to make nondecodable WOM codes decodable by appending cells that also store some additional data. The key idea is to append to the original (nondecodable) code a short synchronous WOM code and write generations of the original code and of the synchronous code simultaneously. We consider both the binary and the nonbinary case. Furthermore, we propose a construction of synchronous WOM codes, which are then used to make nondecodable codes decodable. For short-to-moderate block lengths, the proposed method significantly reduces the rate loss as compared to the standard method.',
	 'authors': u'Nicolas Bitouz\xe9, Alexandre Graell i Amat, Eirik Rosnes,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.0956',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nUsing Short Synchronous WOM Codes to Make WOM Codes Decodable',
	 'urllink': u'http://arxiv.org/abs/1206.0956'}
2015-03-23 23:34:12+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.4554> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:34:12+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.4554>
	{'abstract': u'This paper deals with the modeling of social competition, possibly resulting in the onset of extreme conflicts. More precisely, we discuss models describing the interplay between individual competition for wealth distribution that, when coupled with political stances coming from support or opposition to a government, may give rise to strongly self-enhanced effects. The latter may be thought of as the early stages of massive, unpredictable events known as Black Swans, although no analysis of any fully-developed Black Swan is provided here. Our approach makes use of the framework of the kinetic theory for active particles, where nonlinear interactions among subjects are modeled according to game-theoretical tools.',
	 'authors': u'Nicola Bellomo, Miguel A. Herrero, Andrea Tosin,',
	 'category': u'Computer Science ',
	 'date': '2012-2-21',
	 'pdflink': u'http://arxiv.org/pdf/1202.4554',
	 'subjects': u'Mathematical Physics (math-ph)',
	 'title': u'\nOn the dynamics of social conflicts: looking for the Black Swan',
	 'urllink': u'http://arxiv.org/abs/1202.4554'}
2015-03-23 23:34:20+0000 [xxu46_4] INFO: Crawled 416 pages (at 5 pages/min), scraped 410 items (at 5 items/min)
2015-03-23 23:34:24+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.6178> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:34:24+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.6178>
	{'abstract': u'Finding a basis matrix (dictionary) by which objective signals are represented sparsely is of major relevance in various scientific and technological fields. We consider a problem to learn a dictionary from a set of training signals. We employ techniques of statistical mechanics of disordered systems to evaluate the size of the training set necessary to typically succeed in the dictionary learning. The results indicate that the necessary size is much smaller than previously estimated, which theoretically supports and/or encourages the use of dictionary learning in practical situations.',
	 'authors': u'Ayaka Sakata, Yoshiyuki Kabashima,',
	 'category': u'Computer Science ',
	 'date': '2012-3-28',
	 'pdflink': u'http://arxiv.org/pdf/1203.6178',
	 'subjects': u'Disordered Systems and Neural Networks (cond-mat.dis-nn)',
	 'title': u'\nStatistical Mechanics of Dictionary Learning',
	 'urllink': u'http://arxiv.org/abs/1203.6178'}
2015-03-23 23:34:35+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0110> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:34:35+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0110>
	{'abstract': u"Understanding how spatial configurations of economic activity emerge is important when formulating spatial planning and economic policy. Not only micro-simulation and agent-based model such as UrbanSim, ILUMAS and SIMFIRMS, but also Simon's model of hierarchical concentration have widely applied, for this purpose. These models, however, have limitations with respect to simulating structural changes in spatial economic systems and the impact of proximity. The present paper proposes a model of firm development that is based on behavioural rules such as growth, closure, spin-off and relocation. An important aspect of the model is that locational preferences of firms are based on agglomeration advantages, accessibility of markets and congestion, allowing for a proper description of concentration and deconcentration tendencies. By comparing the outcomes of the proposed model with real world data, we will calibrate the parameters and assess how well the model predicts existing spatial configurations and decide. The model is implemented as an agent-based simulation model describing firm development in the Netherlands in 21 industrial sectors from 1950 to 2004.",
	 'authors': u'Jung-Hun Yang, Dick Ettema, Koen Frenken, Frank Van Oort, Evert-Jan Visser,',
	 'category': u'Computer Science ',
	 'date': '2012-5-1',
	 'pdflink': u'http://arxiv.org/pdf/1205.0110',
	 'subjects': u'Multiagent Systems (cs.MA)',
	 'title': u'\nModelling spatial patterns of economic activity in the Netherlands',
	 'urllink': u'http://arxiv.org/abs/1205.0110'}
2015-03-23 23:34:48+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0951> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:34:48+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0951>
	{'abstract': u'Most of geographic routing approaches in wireless ad hoc and sensor networks do not take into consideration the medium access control (MAC) and physical layers when designing a routing protocol. In this paper, we focus on a cross-layer framework design that exploits the synergies between network, MAC, and physical layers. In the proposed CoopGeo, we use a beaconless forwarding scheme where the next hop is selected through a contention process based on the geographic position of nodes. We optimize this Network-MAC layer interaction using a cooperative relaying technique with a relay selection scheme also based on geographic information in order to improve the system performance in terms of reliability.',
	 'authors': u'Teck Aguilar, Mohamed Chedly Ghedira, Syue-Ju Syue, Vincent Gauthier, Hossam Afifi, Chin-Liang Wang,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.0951',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nA Cross-Layer Design Based on Geographic Information for Cooperative  Wireless Networks',
	 'urllink': u'http://arxiv.org/abs/1206.0951'}
2015-03-23 23:35:06+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.4514> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:35:06+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.4514>
	{'abstract': u'We prove that the expectation value of the index function i(x) over a probability space of injective function f on any finite simple graph G=(V,E) is equal to the curvature K(x) at the vertex x. This result complements and links Gauss-Bonnet sum K(x) = chi(G) and Poincare-Hopf sum i(x) = chi(G) which both hold for arbitrary finite simple graphs.',
	 'authors': u'Oliver Knill,',
	 'category': u'Computer Science ',
	 'date': '2012-2-21',
	 'pdflink': u'http://arxiv.org/pdf/1202.4514',
	 'subjects': u'Differential Geometry (math.DG)',
	 'title': u'\nOn index expectation and curvature for networks',
	 'urllink': u'http://arxiv.org/abs/1202.4514'}
2015-03-23 23:35:15+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.6166> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:35:15+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.6166>
	{'abstract': u'The control of epidemic spreading is essential to avoid potential fatal consequences and also, to lessen unforeseen socio-economic impact. The need for effective control is exemplified during the severe acute respiratory syndrome (SARS) in 2003, which has inflicted near to a thousand deaths as well as bankruptcies of airlines and related businesses. In this article, we examine the efficacy of control strategies on the propagation of infectious diseases based on removing connections within real world airline network with the associated economic and social costs taken into account through defining appropriate quantitative measures. We uncover the surprising results that removing less busy connections can be far more effective in hindering the spread of the disease than removing the more popular connections. Since disconnecting the less popular routes tend to incur less socio-economic cost, our finding suggests the possibility of trading minimal reduction in connectivity of an important hub with efficiencies in epidemic control. In particular, we demonstrate the performance of various local epidemic control strategies, and show how our approach can predict their cost effectiveness through the spreading control characteristics.',
	 'authors': u'N. N. Chung, L. Y. Chew, J. Zhou, C. H. Lai,',
	 'category': u'Computer Science ',
	 'date': '2012-3-28',
	 'pdflink': u'http://arxiv.org/pdf/1203.6166',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nImpact of edge-removal on the centrality betweenness of the best  spreaders',
	 'urllink': u'http://arxiv.org/abs/1203.6166'}
2015-03-23 23:35:20+0000 [xxu46_4] INFO: Crawled 421 pages (at 5 pages/min), scraped 415 items (at 5 items/min)
2015-03-23 23:35:32+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0106> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:35:32+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0106>
	{'abstract': u'High performance computing (HPC) is a very attractive and relatively new area of research, which gives promising results in many applications. In this paper HPC is used for pricing of American options. Although the American options are very significant in computational finance; their valuation is very challenging, especially when the Monte Carlo simulation techniques are used. For getting the most accurate price for these types of options we use Quasi Monte Carlo simulation, which gives the best convergence. Furthermore, this algorithm is implemented on both GPU and CPU. Additionally, the CUDA architecture is used for harnessing the power and the capability of the GPU for executing the algorithm in parallel which is later compared with the serial implementation on the CPU. In conclusion this paper gives the reasons and the advantages of applying HPC in computational finance.',
	 'authors': u'Verche Cvetanoska, Toni Stojanovski,',
	 'category': u'Computer Science ',
	 'date': '2012-5-1',
	 'pdflink': u'http://arxiv.org/pdf/1205.0106',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nUsing high performance computing and Monte Carlo simulation for pricing  american options',
	 'urllink': u'http://arxiv.org/abs/1205.0106'}
2015-03-23 23:35:49+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0925> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:35:49+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0925>
	{'abstract': u"Pertinence Feedback is a technique that enables a user to interactively express his information requirement by modifying his original query formulation with further information. This information is provided by explicitly confirming the pertinent of some indicating objects and/or goals extracted by the system. Obviously the user cannot mark objects and/or goals as pertinent until some are extracted, so the first search has to be initiated by a query and the initial query specification has to be good enough to pick out some pertinent objects and/or goals from the Semantic Network. In this paper we present a short survey of fuzzy and Semantic approaches to Knowledge Extraction. The goal of such approaches is to define flexible Knowledge Extraction Systems able to deal with the inherent vagueness and uncertainty of the Extraction process. It has long been recognised that interactivity improves the effectiveness of Knowledge Extraction systems. Novice user's queries are the most natural and interactive medium of communication and recent progress in recognition is making it possible to build systems that interact with the user. However, given the typical novice user's queries submitted to Knowledge Extraction Systems, it is easy to imagine that the effects of goal recognition errors in novice user's queries must be severely destructive on the system's effectiveness. The experimental work reported in this paper shows that the use of possibility theory in classical Knowledge Extraction techniques for novice user's query processing is more robust than the use of the probability theory. Moreover, both possibilistic and probabilistic pertinence feedback can be effectively employed to improve the effectiveness of novice user's query processing.",
	 'authors': u'Mohamed Nazih Omri,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.0925',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u"\nPossibilistic Pertinence Feedback and Semantic Networks for Goal's  Extraction",
	 'urllink': u'http://arxiv.org/abs/1206.0925'}
2015-03-23 23:36:03+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.4482> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:36:03+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.4482>
	{'abstract': u'This paper investigates how neurons can use metabolic cost to facilitate learning at a population level. Although decision-making by individual neurons has been extensively studied, questions regarding how neurons should behave to cooperate effectively remain largely unaddressed. Under assumptions that capture a few basic features of cortical neurons, we show that constraining reward maximization by metabolic cost aligns the information content of actions with their expected reward. Thus, metabolic cost provides a mechanism whereby neurons encode expected reward into their outputs. Further, aside from reducing energy expenditures, imposing a tight metabolic constraint also increases the accuracy of empirical estimates of rewards, increasing the robustness of distributed learning. Finally, we present two implementations of metabolically constrained learning that confirm our theoretical finding. These results suggest that metabolic cost may be an organizing principle underlying the neural code, and may also provide a useful guide to the design and analysis of other cooperating populations.',
	 'authors': u'David Balduzzi, Pedro A Ortega, Michel Besserve,',
	 'category': u'Computer Science ',
	 'date': '2012-2-20',
	 'pdflink': u'http://arxiv.org/pdf/1202.4482',
	 'subjects': u'Neurons and Cognition (q-bio.NC)',
	 'title': u'\nMetabolic cost as an organizing principle for cooperative learning',
	 'urllink': u'http://arxiv.org/abs/1202.4482'}
2015-03-23 23:36:19+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.6130> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:36:19+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.6130>
	{'abstract': u'Hidden Markov Models (HMMs) can be accurately approximated using co-occurrence frequencies of pairs and triples of observations by using a fast spectral method in contrast to the usual slow methods like EM or Gibbs sampling. We provide a new spectral method which significantly reduces the number of model parameters that need to be estimated, and generates a sample complexity that does not depend on the size of the observation vocabulary. We present an elementary proof giving bounds on the relative accuracy of probability estimates from our model. (Correlaries show our bounds can be weakened to provide either L1 bounds or KL bounds which provide easier direct comparisons to previous work.) Our theorem uses conditions that are checkable from the data, instead of putting conditions on the unobservable Markov transition matrix.',
	 'authors': u'Dean P. Foster, Jordan Rodu, Lyle H. Ungar,',
	 'category': u'Computer Science ',
	 'date': '2012-3-28',
	 'pdflink': u'http://arxiv.org/pdf/1203.6130',
	 'subjects': u'Machine Learning (stat.ML)',
	 'title': u'\nSpectral dimensionality reduction for HMMs',
	 'urllink': u'http://arxiv.org/abs/1203.6130'}
2015-03-23 23:36:20+0000 [xxu46_4] INFO: Crawled 425 pages (at 4 pages/min), scraped 419 items (at 4 items/min)
2015-03-23 23:36:29+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0104> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:36:29+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0104>
	{'abstract': u'Software evolves. After many revisions and improvements software gets retired and replaced. When replacement takes place, one needs to migrate the data from the old database into the new database, so the new application can replace the old application. Student administration application (SAA) currently used by European University (EURM) has been outgrown by the university, and needs replacement. iKnow application developed as part of the iKnow Tempus project is scheduled to replace the existing Student Administration application at EURM. This paper describes the problems that were encountered while migrating the data from the old databases of SAA to the new database designed for the iKnow application. The problems were resolved using the well-known solutions typical for an ETL process, since data migration can be considered as a type of ETL process. In this paper we describe the solutions for the problems that we encountered while migrating the data.',
	 'authors': u'Marko Vu\u010dkovi\u0107, Toni Stojanovski,',
	 'category': u'Computer Science ',
	 'date': '2012-5-1',
	 'pdflink': u'http://arxiv.org/pdf/1205.0104',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nMigration of data for iKnow application at EURM - a case study',
	 'urllink': u'http://arxiv.org/abs/1205.0104'}
2015-03-23 23:36:46+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0918> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:36:46+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0918>
	{'abstract': u'Within the framework proposed in this paper, we address the issue of extending the certain networks to a fuzzy certain networks in order to cope with a vagueness and limitations of existing models for decision under imprecise and uncertain knowledge. This paper proposes a framework that combines two disciplines to exploit their own advantages in uncertain and imprecise knowledge representation problems. The framework proposed is a possibilistic logic based one in which Bayesian nodes and their properties are represented by local necessity-valued knowledge base. Data in properties are interpreted as set of valuated formulas. In our contribution possibilistic Bayesian networks have a qualitative part and a quantitative part, represented by local knowledge bases. The general idea is to study how a fusion of these two formalisms would permit representing compact way to solve efficiently problems for knowledge representation. We show how to apply possibility and necessity measures to the problem of knowledge representation with large scale data. On the other hand fuzzification of crisp certainty degrees to fuzzy variables improves the quality of the network and tends to bring smoothness and robustness in the network performance. The general aim is to provide a new approach for decision under uncertainty that combines three methodologies: Bayesian networks certainty distribution and fuzzy logic.',
	 'authors': u'Abdelkader Heni, Mohamed Nazih Omri, Adel Alimi,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.0918',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nFuzzy Knowledge Representation Based on Possibilistic and Necessary  Bayesian Networks',
	 'urllink': u'http://arxiv.org/abs/1206.0918'}
2015-03-23 23:36:55+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.4411> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:36:55+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.4411>
	{'abstract': u'Using the SIS model on unweighted and weighted networks, we consider the disease localization phenomenon. In contrast to the well-recognized point of view that diseases infect a finite fraction of vertices right above the epidemic threshold, we show that diseases can be localized on a finite number of vertices, where hubs and edges with large weights are centers of localization. Our results follow from the analysis of standard models of networks and empirical data for real-world networks.',
	 'authors': u'A. V. Goltsev, S. N. Dorogovtsev, J. G. Oliveira, J. F. F. Mendes,',
	 'category': u'Computer Science ',
	 'date': '2012-2-20',
	 'pdflink': u'http://arxiv.org/pdf/1202.4411',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nLocalization and Spreading of Diseases in Complex Networks',
	 'urllink': u'http://arxiv.org/abs/1202.4411'}
2015-03-23 23:37:09+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.6093> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:37:09+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.6093>
	{'abstract': u'The community structure of complex networks reveals both their organization and hidden relationships among their constituents. Most community detection methods currently available are not deterministic, and their results typically depend on the specific random seeds, initial conditions and tie-break rules adopted for their execution. Consensus clustering is used in data analysis to generate stable results out of a set of partitions delivered by stochastic methods. Here we show that consensus clustering can be combined with any existing method in a self-consistent way, enhancing considerably both the stability and the accuracy of the resulting partitions. This framework is also particularly suitable to monitor the evolution of community structure in temporal networks. An application of consensus clustering to a large citation network of physics papers demonstrates its capability to keep track of the birth, death and diversification of topics.',
	 'authors': u'Andrea Lancichinetti, Santo Fortunato,',
	 'category': u'Computer Science ',
	 'date': '2012-3-27',
	 'pdflink': u'http://arxiv.org/pdf/1203.6093',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nConsensus clustering in complex networks',
	 'urllink': u'http://arxiv.org/abs/1203.6093'}
2015-03-23 23:37:20+0000 [xxu46_4] INFO: Crawled 429 pages (at 4 pages/min), scraped 423 items (at 4 items/min)
2015-03-23 23:37:25+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0103> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:37:25+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0103>
	{'abstract': u'File carving is one of the most important procedures in Digital Forensic Investigation (DFI). But it is also requires the most computational resources. Parallel processing on Graphics Processing Units have proven to be many times faster than when executed on standard CPU. This paper is inspecting the algorithms and methods to use parallel processing for development of file carving tools that will do their job much faster than the conventional DFI tools.',
	 'authors': u'Neboj\u0161a \u0160krbina, Toni Stojanovski,',
	 'category': u'Computer Science ',
	 'date': '2012-5-1',
	 'pdflink': u'http://arxiv.org/pdf/1205.0103',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nUsing parallel processing for file carving',
	 'urllink': u'http://arxiv.org/abs/1205.0103'}
2015-03-23 23:37:38+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0911> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:37:38+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0911>
	{'abstract': u'Many systems include components interacting with each other that evolve with possibly very different speeds. To deal with this situation many formal models adopt the abstraction of "zero-time transitions", which do not consume time. These however have several drawbacks in terms of naturalness and logic consistency, as a system is modeled to be in different states at the same time. We propose a novel approach that exploits concepts from non-standard analysis to introduce a notion of micro- and macro-steps in an extension of the TRIO metric temporal logic, called X-TRIO. We use X-TRIO to provide a formal semantics and an automated verification technique to Stateflow-like notations used in the design of flexible manufacturing systems.',
	 'authors': u'Luca Ferrucci, Dino Mandrioli, Angelo Morzenti, Matteo Rossi,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.0911',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nNon-null Infinitesimal Micro-steps: a Metric Temporal Logic Approach',
	 'urllink': u'http://arxiv.org/abs/1206.0911'}
2015-03-23 23:37:55+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.4393> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:37:55+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.4393>
	{'abstract': u'The importance of collective social action in current events is manifest in the Arab Spring and Occupy movements. Electronic social media have become a pervasive channel for social interactions, and a basis of collective social response to information. The study of social media can reveal how individual actions combine to become the collective dynamics of society. Characterizing the groups that form spontaneously may reveal both how individuals self-identify and how they will act together. Here we map the social, political, and geographical properties of news-sharing communities on Twitter, a popular micro-blogging platform. We track user-generated messages that contain links to New York Times online articles and we label users according to the topic of the links they share, their geographic location, and their self-descriptive keywords. When users are clustered based on who follows whom in Twitter, we find social groups separate by whether they are interested in local (NY), national (US) or global (cosmopolitan) issues. The national group subdivides into liberal, conservative and other, the latter being a diverse but mostly business oriented group with sports, arts and other splinters. The national political groups are based across the US but are distinct from the national group that is broadly interested in a variety of topics. A person who is cosmopolitan associates with others who are cosmopolitan, and a US liberal / conservative associates with others who are US liberal / conservative, creating separated social groups with those identities. The existence of "citizens" of local, national and cosmopolitan communities is a basis for dialog and action at each of these levels of societal organization.',
	 'authors': u'Ama\xe7 Herda\u011fdelen, Wenyun Zuo, Alexander Gard-Murray, Yaneer Bar-Yam,',
	 'category': u'Computer Science ',
	 'date': '2012-2-20',
	 'pdflink': u'http://arxiv.org/pdf/1202.4393',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nAn Exploration of Social Identity: The Geography and Politics of  News-Sharing Communities in Twitter',
	 'urllink': u'http://arxiv.org/abs/1202.4393'}
2015-03-23 23:38:08+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.5948> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:38:08+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.5948>
	{'abstract': u'We introduce a partial order structure on the set of interval orders of a given size, and prove that such a structure is in fact a lattice. We also provide a way to compute meet and join inside this lattice. Finally, we show that, if we restrict to series parallel interval order, what we obtain is the classical Tamari poset.',
	 'authors': u'Filippo Disanto, Luca Ferrari, Simone Rinaldi,',
	 'category': u'Computer Science ',
	 'date': '2012-3-27',
	 'pdflink': u'http://arxiv.org/pdf/1203.5948',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nA partial order structure on interval orders',
	 'urllink': u'http://arxiv.org/abs/1203.5948'}
2015-03-23 23:38:20+0000 [xxu46_4] INFO: Crawled 433 pages (at 4 pages/min), scraped 427 items (at 4 items/min)
2015-03-23 23:38:24+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0088> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:38:24+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0088>
	{'abstract': u'We propose a Projected Proximal Point Algorithm (ProPPA) for solving a class of optimization problems. The algorithm iteratively computes the proximal point of the last estimated solution projected into an affine space which itself is parallel and approaching to the feasible set. We provide convergence analysis theoretically supporting the general algorithm, and then apply it for solving -minimization problems and the matrix completion problem. These problems arise in many applications including machine learning, image and signal processing. We compare our algorithm with the existing state-of-the-art algorithms. Experimental results on solving these problems show that our algorithm is very efficient and competitive.',
	 'authors': u'Ranch Y.Q. Lai, Pong C. Yuen,',
	 'category': u'Computer Science ',
	 'date': '2012-5-1',
	 'pdflink': u'http://arxiv.org/e-print/1205.0088',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nProPPA: A Fast Algorithm for $\\ell_1$ Minimization and Low-Rank Matrix  Completion',
	 'urllink': u'http://arxiv.org/abs/1205.0088'}
2015-03-23 23:38:42+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0908> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:38:42+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0908>
	{'abstract': u'This paper focuses on the application of soft computing in remanufacturing system, in which end-of-life products are disassembled into basic components and then remanufactured for both economic and environmental reasons. The disassembly activities include disassembly sequencing and planning, while the remanufacturing process is composed of product design, production planning &amp; scheduling, and inventory management. This paper presents a review of the related articles and suggests the corresponding further research directions.',
	 'authors': u'Bo Xing, Wen-Jing Gao, Fulufhelo V. Nelwamondo, Kimberly Battle, Tshilidzi Marwala,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.0908',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nSoft Computing in Product Recovery: A Survey Focusing on Remanufacturing  System',
	 'urllink': u'http://arxiv.org/abs/1206.0908'}
2015-03-23 23:38:53+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.4387> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:38:53+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.4387>
	{'abstract': u'The ability to characterize the color content of natural imagery is an important application of image processing. The pixel by pixel coloring of images may be viewed naturally as points in color space, and the inherent structure and distribution of these points affords a quantization, through clustering, of the color information in the image. In this paper, we present a novel topologically driven clustering algorithm that permits segmentation of the color features in a digital image. The algorithm blends Locally Linear Embedding (LLE) and vector quantization by mapping color information to a lower dimensional space, identifying distinct color regions, and classifying pixels together based on both a proximity measure and color content. It is observed that these techniques permit a significant reduction in color resolution while maintaining the visually important features of images.',
	 'authors': u'Lori Ziegelmeier, Michael Kirby, Chris Peterson,',
	 'category': u'Computer Science ',
	 'date': '2012-2-20',
	 'pdflink': u'http://arxiv.org/pdf/1202.4387',
	 'subjects': u'Geometric Topology (math.GT)',
	 'title': u'\nLocally Linear Embedding Clustering Algorithm for Natural Imagery',
	 'urllink': u'http://arxiv.org/abs/1202.4387'}
2015-03-23 23:39:10+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.5914> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:39:10+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.5914>
	{'abstract': u'This paper introduces a novel framework for the automated tracking of cells, with a particular focus on the challenging situation of phase contrast microscopic videos. Our framework is based on a topology preserving variational segmentation approach applied to normal velocity components obtained from optical flow computations, which appears to yield robust tracking and automated extraction of cell trajectories. In order to obtain improved trackings of local shape features we discuss an additional correction step based on active contours and the image Laplacian which we optimize for an example class of transformed renal epithelial (MDCK-F) cells. We also test the framework for human melanoma cells and murine neutrophil granulocytes that were seeded on different types of extracellular matrices. The results are validated with manual tracking results.',
	 'authors': u'Michael Moeller, Martin Burger, Peter Dieterich, Albrecht Schwab,',
	 'category': u'Computer Science ',
	 'date': '2012-3-27',
	 'pdflink': u'http://arxiv.org/pdf/1203.5914',
	 'subjects': u'Quantitative Methods (q-bio.QM)',
	 'title': u'\nA Framework for Automated Cell Tracking in Phase Contrast Microscopic  Videos based on Normal Velocities',
	 'urllink': u'http://arxiv.org/abs/1203.5914'}
2015-03-23 23:39:20+0000 [xxu46_4] INFO: Crawled 437 pages (at 4 pages/min), scraped 431 items (at 4 items/min)
2015-03-23 23:39:23+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0085> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:39:23+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0085>
	{'abstract': u'Spectrum leasing via cooperation refers to the possibility of primary users leasing a portion of the spectral resources to secondary users in exchange for cooperation. In the presence of an eavesdropper, this correspondence proposes a novel application of this concept in which the secondary cooperation aims at improving secrecy of the primary network by creating more interference to the eavesdropper than to the primary receiver. To generate the interference in a positive way, this work studies an optimal design of a beamformer at the secondary transmitter with multiple antennas that maximizes a secrecy rate of the primary network while satisfying a required rate for the secondary network. Moreover, we investigate two scenarios depending upon the operation of the eavesdropper: i) the eavesdropper treats the interference by the secondary transmission as an additive noise (single-user decoding) and ii) the eavesdropper tries to decode and remove the secondary signal (joint decoding). Numerical results confirm that, for a wide range of required secondary rate constraints, the proposed spectrum-leasing strategy increases the secrecy rate of the primary network compared to the case of no spectrum leasing.',
	 'authors': u'Keonkook Lee, Chan-Byoung Chae, Joonhyuk Kang,',
	 'category': u'Computer Science ',
	 'date': '2012-5-1',
	 'pdflink': u'http://arxiv.org/pdf/1205.0085',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nSpectrum Leasing via Cooperation for Enhanced Physical-Layer Secrecy',
	 'urllink': u'http://arxiv.org/abs/1205.0085'}
2015-03-23 23:39:34+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0905> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:39:34+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0905>
	{'abstract': u'Recent work in machine learning for information extraction has focused on two distinct sub-problems: the conventional problem of filling template slots from natural language text, and the problem of wrapper induction, learning simple extraction procedures ("wrappers") for highly structured text such as Web pages. For suitable regular domains, existing wrapper induction algorithms can efficiently learn wrappers that are simple and highly accurate, but the regularity bias of these algorithms makes them unsuitable for most conventional information extraction tasks. This paper describes a new approach for wrapping semistructured Web pages. The wrapper is capable of learning how to extract relevant information from Web resources on the basis of user supplied examples. It is based on inductive learning techniques as well as fuzzy logic rules. Experimental results show that our approach achieves noticeably better precision and recall coefficient performance measures than SoftMealy, which is one of the most recently reported wrappers capable of wrapping semi-structured Web pages with missing attributes, multiple attributes, variant attribute permutations, exceptions, and typos.',
	 'authors': u'Radhouane Boughamoura, Mohamed Nazih Omri, Habib Youssef,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.0905',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nA Fuzzy Approach for Pertinent Information Extraction from Web Resources',
	 'urllink': u'http://arxiv.org/abs/1206.0905'}
2015-03-23 23:39:44+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.4384> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:39:44+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.4384>
	{'abstract': u'In this PhD thesis we propose an algorithmic approach to the study of the Hilbert scheme. Developing algorithmic methods, we also obtain general results about Hilbert schemes. In Chapter 1 we discuss the equations defining the Hilbert scheme as subscheme of a suitable Grassmannian and in Chapter 5 we determine a new set of equations of degree lower than the degree of equations known so far. In Chapter 2 we study the most important objects used to project algorithmic techniques, namely Borel-fixed ideals. We determine an algorithm computing all the saturated Borel-fixed ideals with Hilbert polynomial assigned and we investigate their combinatorial properties. In Chapter 3 we show a new type of flat deformations of Borel-fixed ideals which lead us to give a new proof of the connectedness of the Hilbert scheme. In Chapter 4 we construct families of ideals that generalize the notion of family of ideals sharing the same initial ideal with respect to a fixed term ordering. Some of these families correspond to open subsets of the Hilbert scheme and can be used to a local study of the Hilbert scheme. In Chapter 6 we deal with the problem of the connectedness of the Hilbert scheme of locally Cohen-Macaulay curves in the projective 3-space. We show that one of the Hilbert scheme considered a "good" candidate to be non-connected, is instead connected. Moreover there are three appendices that present and explain how to use the implementations of the algorithms proposed.',
	 'authors': u'Paolo Lella,',
	 'category': u'Computer Science ',
	 'date': '2012-2-20',
	 'pdflink': u'http://arxiv.org/pdf/1202.4384',
	 'subjects': u'Algebraic Geometry (math.AG)',
	 'title': u'\nComputable Hilbert Schemes',
	 'urllink': u'http://arxiv.org/abs/1202.4384'}
2015-03-23 23:39:56+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.5794> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:39:56+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.5794>
	{'abstract': u'We construct a new secret-key assisted polar coding scheme for private classical communication over a quantum or classical wiretap channel. The security of our scheme rests on an entropic uncertainty relation, in addition to the channel polarization effect. Our scheme achieves the symmetric private information rate by synthesizing "amplitude" and "phase" channels from an arbitrary quantum wiretap channel. We find that the secret-key consumption rate of the scheme vanishes for an arbitrary degradable quantum wiretap channel. Furthermore, we provide an additional sufficient condition for when the secret key rate vanishes, and we suspect that satisfying this condition implies that the scheme requires no secret key at all. Thus, this latter condition addresses an open question from the Mahdavifar-Vardy scheme for polar coding over a classical wiretap channel.',
	 'authors': u'Mark M. Wilde, Joseph M. Renes,',
	 'category': u'Computer Science ',
	 'date': '2012-3-26',
	 'pdflink': u'http://arxiv.org/pdf/1203.5794',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nPolar codes for private classical communication',
	 'urllink': u'http://arxiv.org/abs/1203.5794'}
2015-03-23 23:40:09+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0076> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:40:10+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0076>
	{'abstract': u'Robustness of routing policies for networks is a central problem which is gaining increased attention with a growing awareness to safeguard critical infrastructure networks against natural and man-induced disruptions. Routing under limited information and the possibility of cascades through the network adds serious challenges to this problem. This abstract considers the framework of dynamical networks introduced in our earlier work [1,2], where the network is modeled by a system of ordinary differential equations derived from mass conservation laws on directed acyclic graphs with a single origin-destination pair and a constant inflow at the origin. The rate of change of the particle density on each link of the network equals the difference between the inflow and the outflow on that link. The latter is modeled to depend on the current particle density on that link through a flow function. The novel modeling element in this paper is that every link is assumed to have finite capacity for particle density and that the flow function is modeled to be strictly increasing as density increases from zero up to the maximum density capacity, and is discontinuous at the maximum density capacity, with the flow function value being zero at that point. This feature, in particular, allows for the possibility of spill-backs in our model. In this paper, we present our results on resilience of such networks under distributed routing, towards perturbations that reduce link-wise flow functions.',
	 'authors': u'Giacomo Como, Ketan Savla, Daron Acemoglu, Munther A. Dahleh, Emilio Frazzoli,',
	 'category': u'Computer Science ',
	 'date': '2012-5-1',
	 'pdflink': u'http://arxiv.org/pdf/1205.0076',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nRobust Distributed Routing in Dynamical Networks with Cascading Failures',
	 'urllink': u'http://arxiv.org/abs/1205.0076'}
2015-03-23 23:40:20+0000 [xxu46_4] INFO: Crawled 442 pages (at 5 pages/min), scraped 436 items (at 5 items/min)
2015-03-23 23:40:25+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0893> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:40:25+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0893>
	{'abstract': u"The measurement of performance of Internet Protocol IP network can be done by Transmission Control Protocol TCP because it guarantees send data from one end of the connection actually gets to the other end and in the same order it was send, otherwise an error is reported. There are several methods to measure the performance of TCP among these methods genetic algorithms, neural network, data mining etc, all these methods have weakness and can't reach to correct measure of TCP performance. This paper proposed a new method of measuring TCP performance for real time IP network using Biocomputing, especially molecular calculation because it provides wisdom results and it can exploit all facilities of phylogentic analysis. Applying the new method at real time on Biological Kurdish Messenger BIOKM model designed to measure the TCP performance in two types of protocols File Transfer Protocol FTP and Internet Relay Chat Daemon IRCD. This application gives very close result of TCP performance comparing with TCP performance which obtains from Little's law using same model (BIOKM), i.e. the different percentage of utilization (Busy or traffic industry) and the idle time which are obtained from a new method base on Bio-computing comparing with Little's law was (nearly) 0.13%. KEYWORDS Bio-computing, TCP performance, Phylogenetic tree, Hybridized Model (Normalized), FTP, IRCD",
	 'authors': u'Ayad Ghany Ismaeel, Suha Adham Abdul-Rahman,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.0893',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nNew Method of Measuring TCP Performance of IP Network using  Bio-computing',
	 'urllink': u'http://arxiv.org/abs/1206.0893'}
2015-03-23 23:40:42+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.4375> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:40:42+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.4375>
	{'abstract': u'We develop a framework for formulating a class of stochastic reachability problems with state constraints as a stochastic optimal control problem. Previous approaches to solving these problems are either confined to the deterministic setting or address almost-sure stochastic notions. In contrast, we propose a new methodology to tackle probabilistic specifications that are less stringent than almost sure requirements. To this end, we first establish a connection between two stochastic reach-avoid problems and two classes of different stochastic optimal control problems for diffusions with discontinuous payoff functions. Subsequently, we focus on solutions to one of the classes of stochastic optimal control problems---the exit-time problem, which solves both the reach-avoid problems mentioned above. We then derive a weak version of a dynamic programming principle (DPP) for the corresponding value function; in this direction our contribution compared to the existing literature is to allow for discontinuous payoff functions. Moreover, based on our DPP, we give an alternative characterization of the value function as a solution to a partial differential equation in the sense of discontinuous viscosity solutions, along with boundary conditions both in Dirichlet and viscosity senses. Theoretical justifications are discussed so as to employ off-the-shelf PDE solvers for numerical computations. Finally, we validate the performance of the proposed framework on the stochastic Zermelo navigation problem.',
	 'authors': u'Peyman Mohajerin Esfahani, Debasish Chatterjee, John Lygeros,',
	 'category': u'Computer Science ',
	 'date': '2012-2-20',
	 'pdflink': u'http://arxiv.org/pdf/1202.4375',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nThe Stochastic Reach-Avoid Problem and Set Characterization for  Diffusions',
	 'urllink': u'http://arxiv.org/abs/1202.4375'}
2015-03-23 23:40:59+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.5765> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:40:59+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.5765>
	{'abstract': u'Nordhaus and Gaddum proved, for any graph G, that the chromatic number of G plus the chromatic number of G complement is less than or equal to the number of vertices in G plus 1. Finck characterized the class of graphs that satisfy equality in this bound. In this paper, we provide a new characterization of this class of graphs, based on vertex degrees, which yields a new polynomial-time recognition algorithm and efficient computation of the chromatic number of graphs in this class. Our motivation comes from our theorem that generalizes the Nordhaus-Gaddum theorem to the distinguishing chromatic number: for any graph G, the distinguishing chromatic number of G plus the distinguishing chromatic number of G complement is less than or equal to the number of vertices of G plus the distinguishing number of G. Finally, we characterize those graphs that achieve equality in the sum upper bounds simultaneously for both the chromatic number and for our distinguishing chromatic number analog of the Nordhaus-Gaddum inequality.',
	 'authors': u'Karen L. Collins, Ann Trenk,',
	 'category': u'Computer Science ',
	 'date': '2012-3-26',
	 'pdflink': u'http://arxiv.org/pdf/1203.5765',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nNordhaus-Gaddum Theorem for the Distinguishing Chromatic Number',
	 'urllink': u'http://arxiv.org/abs/1203.5765'}
2015-03-23 23:41:10+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0044> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:41:10+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0044>
	{'abstract': u'Here, we give an algorithm for deciding if the nonnegative rank of a matrix of dimension is at most which runs in time . This is the first exact algorithm that runs in time singly-exponential in . This algorithm (and earlier algorithms) are built on methods for finding a solution to a system of polynomial inequalities (if one exists). Notably, the best algorithms for this task run in time exponential in the number of variables but polynomial in all of the other parameters (the number of inequalities and the maximum degree). Hence these algorithms motivate natural algebraic questions whose solution have immediate implications: How many variables do we need to represent the decision problem, does have nonnegative rank at most ? A naive formulation uses variables and yields an algorithm that is exponential in and even for constant . (Arora, Ge, Kannan, Moitra, STOC 2012) recently reduced the number of variables to , and here we exponentially reduce the number of variables to and this yields our main algorithm. In fact, the algorithm that we obtain is nearly-optimal (under the Exponential Time Hypothesis) since an algorithm that runs in time would yield a subexponential algorithm for 3-SAT . Our main result is based on establishing a normal form for nonnegative matrix factorization - which in turn allows us to exploit algebraic dependence among a large collection of linear transformations with variable entries. Additionally, we also demonstrate that nonnegative rank cannot be certified by even a very large submatrix of , and this property also follows from the intuition gained from viewing nonnegative rank through the lens of systems of polynomial inequalities.',
	 'authors': u'Ankur Moitra,',
	 'category': u'Computer Science ',
	 'date': '2012-4-30',
	 'pdflink': u'http://arxiv.org/pdf/1205.0044',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nA Singly-Exponential Time Algorithm for Computing Nonnegative Rank',
	 'urllink': u'http://arxiv.org/abs/1205.0044'}
2015-03-23 23:41:20+0000 [xxu46_4] INFO: Crawled 446 pages (at 4 pages/min), scraped 440 items (at 4 items/min)
2015-03-23 23:41:24+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0886> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:41:24+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0886>
	{'abstract': u"We introduce a new perspective into the field of quantitative information flow (QIF) analysis that invites the community to bound the leakage, reported by QIF quantifiers, by a range consistent with the size of a program's secret input instead of by a mathematically sound (but counter-intuitive) upper bound of that leakage. To substantiate our position, we present a refinement of a recent QIF metric that appears in the literature. Our refinement is based on slight changes we bring into the design of that metric. These changes do not affect the theoretical premises onto which the original metric is laid. However, they enable the natural association between flow results and the exhaustive search effort needed to uncover a program's secret information (or the residual secret part of that information) to be clearly established. The refinement we discuss in this paper validates our perspective and demonstrates its importance in the future design of QIF quantifiers.",
	 'authors': u'Sari Haj Hussein,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.0886',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nRefining a Quantitative Information Flow Metric',
	 'urllink': u'http://arxiv.org/abs/1206.0886'}
2015-03-23 23:41:32+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.4361> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:41:32+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.4361>
	{'abstract': u'Cheng and Wan have related the decoding of Reed-Solomon codes to the computation of discrete logarithms over finite fields, with the aim of proving the hardness of their decoding. In this work, we experiment with solving the discrete logarithm over GF(q^h) using Reed-Solomon decoding. For fixed h and q going to infinity, we introduce an algorithm (RSDL) needing O (h! q^2) operations over GF(q), operating on a q x q matrix with (h+2) q non-zero coefficients. We give faster variants including an incremental version and another one that uses auxiliary finite fields that need not be subfields of GF(q^h); this variant is very practical for moderate values of q and h. We include some numerical results of our first implementations.',
	 'authors': u'Daniel Augot, Fran\xe7ois Morain,',
	 'category': u'Computer Science ',
	 'date': '2012-2-20',
	 'pdflink': u'http://arxiv.org/pdf/1202.4361',
	 'subjects': u'Number Theory (math.NT)',
	 'title': u'\nDiscrete logarithm computations over finite fields using Reed-Solomon  codes',
	 'urllink': u'http://arxiv.org/abs/1202.4361'}
2015-03-23 23:41:46+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.5706> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:41:46+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.5706>
	{'abstract': u'Grothendieck has proved that each class in the de Rham cohomology of a smooth complex affine variety can be represented by a differential form with polynomial coefficients. After having proved a single exponential bound for the degrees of these forms in the case of a hypersurface, here we generalize this result to arbitrary codimension. More precisely, we show that the p-th de Rham cohomology of a smooth affine variety of dimension m and degree D can be represented by differential forms of degree (pD)^. This result is relevant for the algorithmic computation of the cohomology, but is also motivated by questions in the theory of ordinary differential equations related to the infinitesimal Hilbert 16th problem.',
	 'authors': u'Peter Scheiblechner,',
	 'category': u'Computer Science ',
	 'date': '2012-3-26',
	 'pdflink': u'http://arxiv.org/pdf/1203.5706',
	 'subjects': u'Algebraic Geometry (math.AG)',
	 'title': u'\nEffective de Rham Cohomology - The General Case',
	 'urllink': u'http://arxiv.org/abs/1203.5706'}
2015-03-23 23:42:00+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0042> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:42:00+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0042>
	{'abstract': u'One of the main challenges when verifying multi-threaded Java applications is the state space explosion problem. Due to thread interleavings, the number of states that the model checker has to verify can grow rapidly and impede the feasibility of verification. In the Java language, the source of thread interleavings can be the system under test as well as the Java Development Kit (JDK) itself. In our paper, we propose a method to minimize the state space explosion problem for applications verified under the Java PathFinder (JPF) model checker. Our method is based on abstracting the state of the application to a smaller domain and implementing application behavior using the Model Java Interface (MJI) of JPF. To show the capabilities of our approach, we have created a JPF extension called jpf-concurrent which abstracts classes from the Java Concurrency Utilities. Several benchmarks proved the usefulness of our approach. In all cases, our implementation was faster than the JDK implementation when running under the JPF model checker. Moreover, our implementation led to significantly smaller state spaces.',
	 'authors': u'Mateusz Ujma, Nastaran Shafiei,',
	 'category': u'Computer Science ',
	 'date': '2012-4-30',
	 'pdflink': u'http://arxiv.org/pdf/1205.0042',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\njpf-concurrent: An extension of Java PathFinder for java.util.concurrent',
	 'urllink': u'http://arxiv.org/abs/1205.0042'}
2015-03-23 23:42:16+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0855> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:42:16+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0855>
	{'abstract': u'Partially observable Markov decision processes have been widely used to provide models for real-world decision making problems. In this paper, we will provide a method in which a slightly different version of them called Mixed observability Markov decision process, MOMDP, is going to join with our problem. Basically, we aim at offering a behavioural model for interaction of intelligent agents with musical pitch environment and we will show that how MOMDP can shed some light on building up a decision making model for musical pitch conveniently.',
	 'authors': u'Pouyan Rafiei Fard, Keyvan Yahya,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.0855',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nA Mixed Observability Markov Decision Process Model for Musical Pitch',
	 'urllink': u'http://arxiv.org/abs/1206.0855'}
2015-03-23 23:42:20+0000 [xxu46_4] INFO: Crawled 451 pages (at 5 pages/min), scraped 445 items (at 5 items/min)
2015-03-23 23:42:33+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.4329> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:42:33+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.4329>
	{'abstract': u'Considerable efforts have been made in recent years to produce detailed topologies of the Internet. Although Internet topology data have been brought to the attention of a wide and somewhat diverse audience of scholars, so far they have been overlooked by economists. In this paper, we suggest that such data could be effectively treated as a proxy to characterize the size of the "digital economy" at country level and outsourcing: thus, we analyse the topological structure of the network of trade in digital services (trade in bits) and compare it with that of the more traditional flow of manufactured goods across countries. To perform meaningful comparisons across networks with different characteristics, we define a stochastic benchmark for the number of connections among each country-pair, based on hypergeometric distribution. Original data are thus filtered by means of different thresholds, so that we only focus on the strongest links, i.e., statistically significant links. We find that trade in bits displays a sparser and less hierarchical network structure, which is more similar to trade in high-skill manufactured goods than total trade. Lastly, distance plays a more prominent role in shaping the network of international trade in physical goods than trade in digital services.',
	 'authors': u'Massimo Riccaboni, Alessandro Rossi, Stefano Schiavo,',
	 'category': u'Computer Science ',
	 'date': '2012-2-20',
	 'pdflink': u'http://arxiv.org/pdf/1202.4329',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nGlobal Networks of Trade and Bits',
	 'urllink': u'http://arxiv.org/abs/1202.4329'}
2015-03-23 23:42:46+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.5446> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:42:46+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.5446>
	{'abstract': u"This paper proposes to use a rather new modelling approach in the realm of solar radiation forecasting. In this work, two forecasting models: Autoregressive Moving Average (ARMA) and Neural Network (NN) models are combined to form a model committee. The Bayesian inference is used to affect a probability to each model in the committee. Hence, each model's predictions are weighted by their respective probability. The models are fitted to one year of hourly Global Horizontal Irradiance (GHI) measurements. Another year (the test set) is used for making genuine one hour ahead (h+1) out-of-sample forecast comparisons. The proposed approach is benchmarked against the persistence model. The very first results show an improvement brought by this approach.",
	 'authors': u'Philippe Lauret, Auline Rodler, Marc Muselli, Mathieu David, Hadja Diagne, Cyril Voyant,',
	 'category': u'Computer Science ',
	 'date': '2012-3-24',
	 'pdflink': u'http://arxiv.org/pdf/1203.5446',
	 'subjects': u'Applications (stat.AP)',
	 'title': u'\nA Bayesian Model Committee Approach to Forecasting Global Solar  Radiation',
	 'urllink': u'http://arxiv.org/abs/1203.5446'}
2015-03-23 23:43:00+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0040> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:43:00+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0040>
	{'abstract': u'We report the first steps in creating an optical computing system. This system may solve NP-Hard problems by utilizing a setup of exponential sized masks. This is exponential space complexity but the production of those masks is done with a polynomial time preprocessing. These masks are later used to solve the problem in polynomial time. We propose to reduced the size of the masks to nano-scaled density. Simulations were done to choose a proper design, and actual implementations show the feasibility of such a system.',
	 'authors': u'Eyal Cohen, Shlomi Dolev, Sergey Frenkel, Boris Kryzhanovsky, Alexandr Palagushkin, Michael Rosenblit, Victor Zakharov,',
	 'category': u'Computer Science ',
	 'date': '2012-4-30',
	 'pdflink': u'http://arxiv.org/pdf/1205.0040',
	 'subjects': u'Emerging Technologies (cs.ET)',
	 'title': u'\nOptical Solver of Combinatorial Problems: Nano-Technological Approach',
	 'urllink': u'http://arxiv.org/abs/1205.0040'}
2015-03-23 23:43:15+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0848> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:43:15+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0848>
	{'abstract': u'Recently, arithmetic coding has attracted the attention of many scholars because of its high compression capability. Accordingly, in this paper a method which adds secrecy to this well-known source code is proposed. Finite state arithmetic code (FSAC) is used as source code to add security. Its finite state machine (FSM) characteristic is exploited to insert some random jumps during source coding process. In addition, a Huffman code is designed for each state to make decoding possible even in jumps. Being Prefix free, Huffman codes are useful in tracking correct states for an authorized user when s/he decodes with correct symmetric pseudo random key. The robustness of our proposed scheme is further reinforced by adding another extra uncertainty by swapping outputs of Huffman codes in each state. Several test images are used for inspecting the validity of the proposed Huffman Finite State Arithmetic Coding (HFSAC). The results of several experimental, key space analyses, statistical analysis, key sensitivity and plaintext sensitivity tests show that HFSAC with a little effect on compression efficiency for image cryptosystem provides an efficient and secure way for real-time image encryption and transmission.',
	 'authors': u'Hashem Moradmand Ziyabar, Mahnaz Sinaie, Ali Payandeh, Vahid Tabataba Vakili,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.0848',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nSecure FSM- based arithmetic codes',
	 'urllink': u'http://arxiv.org/abs/1206.0848'}
2015-03-23 23:43:20+0000 [xxu46_4] INFO: Crawled 455 pages (at 4 pages/min), scraped 449 items (at 4 items/min)
2015-03-23 23:43:31+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.4285> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:43:31+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.4285>
	{'abstract': u'In this paper we prove some divisibility properties of the cardinality of elliptic curves modulo primes. These proofs explain the good behavior of certain parameters when using Montgomery or Edwards curves in the setting of the elliptic curve method (ECM) for integer factorization. The ideas of the proofs help us to find new families of elliptic curves with good division properties which increase the success probability of ECM.',
	 'authors': u'Razvan Barbulescu, Joppe W. Bos, Cyril Bouvier, Thorsten Kleinjung, Peter L. Montgomery,',
	 'category': u'Computer Science ',
	 'date': '2012-2-20',
	 'pdflink': u'http://arxiv.org/pdf/1202.4285',
	 'subjects': u'Number Theory (math.NT)',
	 'title': u'\nFinding ECM-friendly curves through a study of Galois properties',
	 'urllink': u'http://arxiv.org/abs/1202.4285'}
2015-03-23 23:43:47+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.5422> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:43:47+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.5422>
	{'abstract': u'We study distribution free, nonparametric prediction bands with a special focus on their finite sample behavior. First we investigate and develop different notions of finite sample coverage guarantees. Then we give a new prediction band estimator by combining the idea of "conformal prediction" (Vovk et al. 2009) with nonparametric conditional density estimation. The proposed estimator, called COPS (Conformal Optimized Prediction Set), always has finite sample guarantee in a stronger sense than the original conformal prediction estimator. Under regularity conditions the estimator converges to an oracle band at a minimax optimal rate. A fast approximation algorithm and a data driven method for selecting the bandwidth are developed. The method is illustrated first in simulated data. Then, an application shows that the proposed method gives desirable prediction intervals in an automatic way, as compared to the classical linear regression modeling.',
	 'authors': u'Jing Lei, Larry Wasserman,',
	 'category': u'Computer Science ',
	 'date': '2012-3-24',
	 'pdflink': u'http://arxiv.org/pdf/1203.5422',
	 'subjects': u'Methodology (stat.ME)',
	 'title': u'\nDistribution Free Prediction Bands',
	 'urllink': u'http://arxiv.org/abs/1203.5422'}
2015-03-23 23:44:01+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0038> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:44:01+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0038>
	{'abstract': u'K-clique percolation is an overlapping community finding algorithm which extracts particular structures, comprised of overlapping cliques, from complex networks. While it is conceptually straightforward, and can be elegantly expressed using clique graphs, certain aspects of k-clique percolation are computationally challenging in practice. In this paper we investigate aspects of empirical social networks, such as the large numbers of overlapping maximal cliques contained within them, that make clique percolation, and clique graph representations, computationally expensive. We motivate a simple algorithm to conduct clique percolation, and investigate its performance compared to current best-in-class algorithms. We present improvements to this algorithm, which allow us to perform k-clique percolation on much larger empirical datasets. Our approaches perform much better than existing algorithms on networks exhibiting pervasively overlapping community structure, especially for higher values of k. However, clique percolation remains a hard computational problem; current algorithms still scale worse than some other overlapping community finding algorithms.',
	 'authors': u'Fergal Reid, Aaron McDaid, Neil Hurley,',
	 'category': u'Computer Science ',
	 'date': '2012-4-30',
	 'pdflink': u'http://arxiv.org/pdf/1205.0038',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nPercolation Computation in Complex Networks',
	 'urllink': u'http://arxiv.org/abs/1205.0038'}
2015-03-23 23:44:19+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0834> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:44:19+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0834>
	{'abstract': u'Recently, multi-scale notions of local homology (a variant of persistent homology) have been used to study the local structure of spaces around a given point from a point cloud sample. Current reconstruction guarantees rely on constructing embedded complexes which become difficult in high dimensions. We show that the persistence diagrams used for estimating local homology, can be approximated using families of Vietoris-Rips complexes, whose simple constructions are robust in any dimension. To the best of our knowledge, our results, for the first time, make applications based on local homology, such as stratification learning, feasible in high dimensions.',
	 'authors': u'Primoz Skraba, Bei Wang,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.0834',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nApproximating Local Homology from Samples',
	 'urllink': u'http://arxiv.org/abs/1206.0834'}
2015-03-23 23:44:20+0000 [xxu46_4] INFO: Crawled 459 pages (at 4 pages/min), scraped 453 items (at 4 items/min)
2015-03-23 23:44:34+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.4177> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:44:34+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.4177>
	{'abstract': u"In clinical practice, physicians make a series of treatment decisions over the course of a patient's disease based on his/her baseline and evolving characteristics. A dynamic treatment regime is a set of sequential decision rules that operationalizes this process. Each rule corresponds to a decision point and dictates the next treatment action based on the accrued information. Using existing data, a key goal is estimating the optimal regime, that, if followed by the patient population, would yield the most favorable outcome on average. Q- and A-learning are two main approaches for this purpose. We provide a detailed account of these methods, study their performance, and illustrate them using data from a depression study.",
	 'authors': u'Phillip J. Schulte, Anastasios A. Tsiatis, Eric B. Laber, Marie Davidian,',
	 'category': u'Computer Science ',
	 'date': '2012-2-19',
	 'pdflink': u'http://arxiv.org/pdf/1202.4177',
	 'subjects': u'Methodology (stat.ME)',
	 'title': u'\n$Q$- and $A$-Learning Methods for Estimating Optimal Dynamic Treatment  Regimes',
	 'urllink': u'http://arxiv.org/abs/1202.4177'}
2015-03-23 23:44:50+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.5351> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:44:50+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.5351>
	{'abstract': u"Network modeling plays a critical role in identifying statistical regularities and structural principles common to many systems. The large majority of recent modeling approaches are connectivity driven. The structural patterns of the network are at the basis of the mechanisms ruling the network formation. Connectivity driven models necessarily provide a time-aggregated representation that may fail to describe the instantaneous and fluctuating dynamics of many networks. We address this challenge by defining the activity potential, a time invariant function characterizing the agents' interactions and constructing an activity driven model capable of encoding the instantaneous time description of the network dynamics. The model provides an explanation of structural features such as the presence of hubs, which simply originate from the heterogeneous activity of agents. Within this framework, highly dynamical networks can be described analytically, allowing a quantitative discussion of the biases induced by the time-aggregated representations in the analysis of dynamical processes.",
	 'authors': u'Nicola Perra, Bruno Gon\xe7alves, Romualdo Pastor-Satorras, Alessandro Vespignani,',
	 'category': u'Computer Science ',
	 'date': '2012-3-23',
	 'pdflink': u'http://arxiv.org/pdf/1203.5351',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nActivity driven modeling of time varying networks',
	 'urllink': u'http://arxiv.org/abs/1203.5351'}
2015-03-23 23:45:06+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0030> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:45:06+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0030>
	{'abstract': u'Since there is, in principle, no reason why third parties should not pay individuals for the use of their data, we introduce a realistic market that would allow these payments to be made while taking into account the privacy attitude of the participants. And since it is usually important to use unbiased samples to obtain credible statistical results, we examine the properties that such a market should have and suggest a mechanism that compensates those individuals that participate according to their risk attitudes. Equally important, we show that this mechanism also benefits buyers, as they pay less for the data than they would if they compensated all individuals with the same maximum fee that the most concerned ones expect.',
	 'authors': u'Christina Aperjis, Bernardo A. Huberman,',
	 'category': u'Computer Science ',
	 'date': '2012-4-30',
	 'pdflink': u'http://arxiv.org/pdf/1205.0030',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nA Market for Unbiased Private Data: Paying Individuals According to  their Privacy Attitudes',
	 'urllink': u'http://arxiv.org/abs/1205.0030'}
2015-03-23 23:45:20+0000 [xxu46_4] INFO: Crawled 462 pages (at 3 pages/min), scraped 456 items (at 3 items/min)
2015-03-23 23:45:21+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0805> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:45:21+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0805>
	{'abstract': u'A (or of a point set in the plane is a convex polygon with vertices in , containing no points of in its interior. Let be a bounded convex region in the plane. We show that the expected number of vertices of the largest convex hole of a set of random points chosen independently and uniformly over is , regardless of the shape of .',
	 'authors': u'J\xf3zsef Balogh, Hern\xe1n Gonz\xe1lez-Aguilar, Gelasio Salazar,',
	 'category': u'Computer Science ',
	 'date': '2012-6-5',
	 'pdflink': u'http://arxiv.org/pdf/1206.0805',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nLarge convex holes in random point sets',
	 'urllink': u'http://arxiv.org/abs/1206.0805'}
2015-03-23 23:45:35+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.4174> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:45:35+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.4174>
	{'abstract': u"Agents' judgment depends on perception and previous knowledge. Assuming that previous knowledge depends on perception, we can say that judgment depends on perception. So, if judgment depends on perception, can agents judge that they have the same perception? In few words, this is the addressed paradox through this document. While illustrating on the paradox, it's found that to reach agreement in communication, it's not necessary for parties to have the same perception however the necessity is to have perception correspondence. The attempted solution to this paradox reveals a potential uncertainty in judging the matter thus supporting the skeptical view of the problem. Moreover, relating perception to intelligence, the same uncertainty is inherited by judging the level of intelligence of an agent compared to others not necessarily from the same kind (e.g. machine intelligence compared to human intelligence). Using a proposed simple mathematical model for perception and action, a tool is developed to construct scenarios, and the problem is addressed mathematically such that conclusions are drawn systematically based on mathematically defined properties. When it comes to formalization, philosophical arguments and views become more visible and explicit.",
	 'authors': u'Ahmed M. Mahran,',
	 'category': u'Computer Science ',
	 'date': '2012-2-19',
	 'pdflink': u'http://arxiv.org/pdf/1202.4174',
	 'subjects': u'Neurons and Cognition (q-bio.NC)',
	 'title': u'\nPerception Lie Paradox: Mathematically Proved Uncertainty about Humans  Perception Similarity',
	 'urllink': u'http://arxiv.org/abs/1202.4174'}
2015-03-23 23:45:49+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.5244> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:45:49+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.5244>
	{'abstract': u'In this paper we give the second weight codewords of the generalized Reed-Muller code of order r and length .',
	 'authors': u'Elodie Leducq,',
	 'category': u'Computer Science ',
	 'date': '2012-3-23',
	 'pdflink': u'http://arxiv.org/pdf/1203.5244',
	 'subjects': u'Number Theory (math.NT)',
	 'title': u'\nSecond weight codewords of generalized Reed-Muller codes',
	 'urllink': u'http://arxiv.org/abs/1203.5244'}
2015-03-23 23:46:00+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1205.0003> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:46:00+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1205.0003>
	{'abstract': u'I propose two simple indices to classify journals, published in Arabic language, and different researchers. These indices depend upon the known impact factor and h-index. The new indices give an easy way to judge the rank of any journal (output of any researcher) without looking for other journals (output of other researchers).',
	 'authors': u'Mahmoud Abdel-Aty,',
	 'category': u'Computer Science ',
	 'date': '2012-4-30',
	 'pdflink': u'http://arxiv.org/pdf/1205.0003',
	 'subjects': u'Digital Libraries (cs.DL)',
	 'title': u'\nIndices to Quantify the Ranking of Arabic Journals and Research Output',
	 'urllink': u'http://arxiv.org/abs/1205.0003'}
2015-03-23 23:46:18+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0788> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:46:18+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0788>
	{'abstract': u'Model-based testing of software and hardware systems uses behavioral and formal models of the systems. The paper presents a technique for model-based black-box conformance testing of real-time systems using Labeled Prioritized Time Petri Nets (LPrTPN). The Timed Input/Output Conformance (tioco) relation, which takes environment assumptions into account, serves as reference to decide of implementation correctness. Test suites are derived automatically from a LPrTPN made up of two concurrent sub-nets that respectively specify the system under test and its environment. The result is optimal in the sense that test cases have the shortest possible accumulated time to be executed. Test cases selection combines test purposes and structural coverage criteria associated with the model. A test purpose or a coverage criterion is specified in a SE-LTL formula. The TIme Petri Net Analyzer TINA has been extended to support concurrent composed subnets. Automatic generation of time-optimal test suites with the Tina toolbox combines the model checker selt and the path analyzer plan. selt outputs a sequence that satisfies the logic formula. plan computes the fastest execution of this sequence which will be transformed in a test cases suite.',
	 'authors': u'Noureddine Adjir, Pierre de Saqui Sannes, M. Kamel Rahmouni, Abdelkader Adla,',
	 'category': u'Computer Science ',
	 'date': '2012-6-4',
	 'pdflink': u'http://arxiv.org/pdf/1206.0788',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nTimed Test Case Generation Using Labeled Prioritized Time Petri Nets',
	 'urllink': u'http://arxiv.org/abs/1206.0788'}
2015-03-23 23:46:20+0000 [xxu46_4] INFO: Crawled 467 pages (at 5 pages/min), scraped 461 items (at 5 items/min)
2015-03-23 23:46:33+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.4087> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:46:33+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.4087>
	{'abstract': u'Many real networks are not isolated from each other but form networks of networks, often interrelated in non trivial ways. Here, we analyze an epidemic spreading process taking place on top of two interconnected complex networks. We develop a heterogeneous mean field approach that allows us to calculate the conditions for the emergence of an endemic state. Interestingly, a global endemic state may arise in the coupled system even though the epidemics is not able to propagate on each network separately, and even when the number of coupling connections is small. Our analytic results are successfully confronted against large-scale numerical simulations.',
	 'authors': u'Anna Saumell-Mendiola, M. \xc1ngeles Serrano, Mari\xe1n Bogu\xf1\xe1,',
	 'category': u'Computer Science ',
	 'date': '2012-2-18',
	 'pdflink': u'http://arxiv.org/pdf/1202.4087',
	 'subjects': u'Disordered Systems and Neural Networks (cond-mat.dis-nn)',
	 'title': u'\nEpidemic spreading on interconnected networks',
	 'urllink': u'http://arxiv.org/abs/1202.4087'}
2015-03-23 23:46:44+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.5186> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:46:44+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.5186>
	{'abstract': u'Proper edge coloring of a graph is called acyclic if there is no bichromatic cycle in . The acyclic chromatic index of , denoted by , is the least number of colors such that has an acyclic edge -coloring. Basavaraju et al. [Acyclic edge-coloring of planar graphs, SIAM J. Discrete Math. 25 (2) (2011), 463--478] showed that for planar graphs with maximum degree . In this paper, the bound is improved to .',
	 'authors': u'Yue Guan, Jianfeng Hou, Yingyuan Yang,',
	 'category': u'Computer Science ',
	 'date': '2012-3-23',
	 'pdflink': u'http://arxiv.org/pdf/1203.5186',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nAn improved bound on acyclic chromatic index of planar graphs',
	 'urllink': u'http://arxiv.org/abs/1203.5186'}
2015-03-23 23:46:58+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.1113> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:46:58+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.1113>
	{'abstract': u'We present a deterministic 2^O(t)q^ algorithm to decide whether a univariate polynomial f, with exactly t monomial terms and degree &lt;q, has a root in F_q. A corollary of our method --- the first with complexity sub-linear in q when t is fixed --- is that the nonzero roots in F_q can be partitioned into at most 2 sqrt (q-1)^ cosets of two subgroups S_1,S_2 of F^*_q, with S_1 in S_2. Another corollary is the first deterministic sub-linear algorithm for detecting common degree one factors of k-tuples of t-nomials in F_q[x] when k and t are fixed. When t is not fixed we show that each of the following problems is NP-hard with respect to BPP-reductions, even when p is prime: (1) detecting roots in F_p for f, (2) deciding whether the square of a degree one polynomial in F_p[x] divides f, (3) deciding whether the discriminant of f vanishes, (4) deciding whether the gcd of two t-nomials in F_p[x] has positive degree. Finally, we prove that if the complexity of root detection is sub-linear (in a refined sense), relative to the straight-line program encoding, then NEXP is not in P/Poly.',
	 'authors': u'Jingguo Bi, Qi Cheng, J. Maurice Rojas,',
	 'category': u'Computer Science ',
	 'date': '2012-4-5',
	 'pdflink': u'http://arxiv.org/pdf/1204.1113',
	 'subjects': u'Number Theory (math.NT)',
	 'title': u'\nSub-Linear Root Detection, and New Hardness Results, for Sparse  Polynomials Over Finite Fields',
	 'urllink': u'http://arxiv.org/abs/1204.1113'}
2015-03-23 23:47:11+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0730> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:47:11+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0730>
	{'abstract': u'This paper explores the theoretical basis of the covariance matrix adaptation evolution strategy (CMA-ES) from the information geometry viewpoint. To establish a theoretical foundation for the CMA-ES, we focus on a geometric structure of a Riemannian manifold of probability distributions equipped with the Fisher metric. We define a function on the manifold which is the expectation of fitness over the sampling distribution, and regard the goal of update of the parameters of sampling distribution in the CMA-ES as maximization of the expected fitness. We investigate the steepest ascent learning for the expected fitness maximization, where the steepest ascent direction is given by the natural gradient, which is the product of the inverse of the Fisher information matrix and the conventional gradient of the function. Our first result is that we can obtain under some types of parameterization of multivariate normal distribution the natural gradient of the expected fitness without the need for inversion of the Fisher information matrix. We find that the update of the distribution parameters in the CMA-ES is the same as natural gradient learning for expected fitness maximization. Our second result is that we derive the range of learning rates such that a step in the direction of the exact natural gradient improves the parameters in the expected fitness. We see from the close relation between the CMA-ES and natural gradient learning that the default setting of learning rates in the CMA-ES seems suitable in terms of monotone improvement in expected fitness. Then, we discuss the relation to the expectation-maximization framework and provide an information geometric interpretation of the CMA-ES.',
	 'authors': u'Youhei Akimoto, Yuichi Nagata, Isao Ono, Shigenobu Kobayashi,',
	 'category': u'Computer Science ',
	 'date': '2012-6-4',
	 'pdflink': u'http://arxiv.org/pdf/1206.0730',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nTheoretical foundation for CMA-ES from information geometric perspective',
	 'urllink': u'http://arxiv.org/abs/1206.0730'}
2015-03-23 23:47:20+0000 [xxu46_4] INFO: Crawled 471 pages (at 4 pages/min), scraped 465 items (at 4 items/min)
2015-03-23 23:47:26+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.4061> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:47:26+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.4061>
	{'abstract': u'This paper describes implementation and computational results of a polynomial test of total unimodularity. The test is a simplified version of a prior method. The program also decides two related unimodularity properties. The software is available free of charge in source code form under the Boost Software License.',
	 'authors': u'Matthias Walter, Klaus Truemper,',
	 'category': u'Computer Science ',
	 'date': '2012-2-18',
	 'pdflink': u'http://arxiv.org/pdf/1202.4061',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nImplementation of a Unimodularity Test',
	 'urllink': u'http://arxiv.org/abs/1202.4061'}
2015-03-23 23:47:43+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.5184> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:47:43+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.5184>
	{'abstract': u'We test a recently proposed model of commuting networks on 80 case studies from different regions of the world (Europe and United-States) and with geographic units of different sizes (municipality, county, region). The model takes as input the number of commuters coming in and out of each geographic unit and generates the matrix of commuting flows betwen the geographic units. We show that the single parameter of the model, which rules the compromise between the influence of the distance and job opportunities, follows a universal law that depends only on the average surface of the geographic units. We verified that the law derived from a part of the case studies yields accurate results on other case studies. We also show that our model significantly outperforms the two other approaches proposing a universal commuting model (Balcan et al. (2009); Simini et al. (2012)), particularly when the geographic units are small (e.g. municipalities).',
	 'authors': u'Maxime Lenormand, Sylvie Huet, Floriana Gargiulo, Guillaume Deffuant,',
	 'category': u'Computer Science ',
	 'date': '2012-3-23',
	 'pdflink': u'http://arxiv.org/pdf/1203.5184',
	 'subjects': u'Statistics Theory (math.ST)',
	 'title': u'\nA Universal Model of Commuting Networks',
	 'urllink': u'http://arxiv.org/abs/1203.5184'}
2015-03-23 23:48:00+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0729> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:48:00+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0729>
	{'abstract': u"Source wavelet estimation is the key in seismic signal processing for resolving subsurface structural properties. Homomorphic deconvolution using cepstrum analysis has been an effective method for wavelet estimation for decades. In general, the inverse of the Fourier transform of the logarithm of a signal's Fourier transform is the cepstral domain representation of that signal. The convolution operation of two signals in the time domain becomes an addition in the cepstral domain. The fractional Fourier transform (FRFT) is the generalization of the standard Fourier transform (FT). In an FRFT, the transformation kernel is a set of linear chirps whereas the kernel is composed of complex sinusoids for the FT. Depending on the fractional order, signals can be represented in multiple domains. This gives FRFT an extra degree of freedom in signal analysis over the standard FT. In this paper, we have taken advantage of the multidomain nature of the FRFT and applied it to cepstral analysis. We term this combination the Fractional-Cepstrum (FC). We derive the real FC formulation, and give an example using wavelets to show the multidomain representation of the traditional cepstrum with different fractional orders of the FRFT.",
	 'authors': u'K. H. Miah, R. H. Herrera, M. van der Baan, M. D. Sacchi,',
	 'category': u'Computer Science ',
	 'date': '2012-6-4',
	 'pdflink': u'http://arxiv.org/pdf/1206.0729',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nApplication of Fractional Fourier Transform in Cepstrum Analysis',
	 'urllink': u'http://arxiv.org/abs/1206.0729'}
2015-03-23 23:48:18+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.4051> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:48:18+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.4051>
	{'abstract': u"Expanding upon Pimbblet's informative 2011 analysis of career h-indices for members of the Astronomical Society of Australia, we provide additional citation metrics which are geared to a) quantifying the current performance of b) all professional astronomers in Australia. We have trawled the staff web-pages of Australian Universities, Observatories and Research Organisations hosting professional astronomers, and identified 383 PhD-qualified, research-active, astronomers in the nation - 131 of these are not members of the Astronomical Society of Australia. Using the SAO/NASA Astrophysics Data System, we provide the three following common metrics based on publications in the first decade of the 21st century (2001-2010): h-index, author-normalised citation count and lead-author citation count. We additionally present a somewhat more inclusive analysis, applicable for many early-career researchers, that is based on publications from 2006-2010. Histograms and percentiles, plus top-performer lists, are presented for each category. Finally, building on Hirsch's empirical equation, we find that the (10-year) h-index and (10-year) total citation count T can be approximated by the relation h = (0.5+sqrt)/sqrt for h &gt; 5.",
	 'authors': u'Katherine H. Kenyon, Arjun Paramasivam, Jiachin Tu, Albert Zhang, Alister W. Graham,',
	 'category': u'Computer Science ',
	 'date': '2012-2-18',
	 'pdflink': u'http://arxiv.org/pdf/1202.4051',
	 'subjects': u'Instrumentation and Methods for Astrophysics (astro-ph.IM)',
	 'title': u'\nCitations to Australian Astronomy: 5 and 10 Year Benchmarks',
	 'urllink': u'http://arxiv.org/abs/1202.4051'}
2015-03-23 23:48:20+0000 [xxu46_4] INFO: Crawled 475 pages (at 4 pages/min), scraped 469 items (at 4 items/min)
2015-03-23 23:48:34+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.5169> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:48:34+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.5169>
	{'abstract': u'Universal cycles are generalizations of de Bruijn cycles and Gray codes that were introduced originally by Chung, Diaconis, and Graham in 1990. They have been developed by many authors since, for various combinatorial objects such as strings, subsets, permutations, partitions, vector spaces, and designs. One generalization of universal cycles, which require almost complete overlap of consecutive words, is s-overlap cycles, which relax such a constraint. In this paper we study weak orders, which are relations that are transitive and complete. We prove the existence of universal and s-overlap cycles for weak orders, as well as for fixed height and/or weight weak orders, and apply the results to cycles for ordered partitions as well.',
	 'authors': u'Victoria Horan, Glenn Hurlbert,',
	 'category': u'Computer Science ',
	 'date': '2012-3-23',
	 'pdflink': u'http://arxiv.org/pdf/1203.5169',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nUniversal Cycles for Weak Orders',
	 'urllink': u'http://arxiv.org/abs/1203.5169'}
2015-03-23 23:48:50+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.0171> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:48:50+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.0171>
	{'abstract': u'In this study, a new Stacked Generalization technique called Fuzzy Stacked Generalization (FSG) is proposed to minimize the difference between N -sample and large-sample classification error of the Nearest Neighbor classifier. The proposed FSG employs a new hierarchical distance learning strategy to minimize the error difference. For this purpose, we first construct an ensemble of base-layer fuzzy k- Nearest Neighbor (k-NN) classifiers, each of which receives a different feature set extracted from the same sample set. The fuzzy membership values computed at the decision space of each fuzzy k-NN classifier are concatenated to form the feature vectors of a fusion space. Finally, the feature vectors are fed to a meta-layer classifier to learn the degree of accuracy of the decisions of the base-layer classifiers for meta-layer classification. Rather than the power of the individual base layer-classifiers, diversity and cooperation of the classifiers become an important issue to improve the overall performance of the proposed FSG. A weak base-layer classifier may boost the overall performance more than a strong classifier, if it is capable of recognizing the samples, which are not recognized by the rest of the classifiers, in its own feature space. The experiments explore the type of the collaboration among the individual classifiers required for an improved performance of the suggested architecture. Experiments on multiple feature real-world datasets show that the proposed FSG performs better than the state of the art ensemble learning algorithms such as Adaboost, Random Subspace and Rotation Forest. On the other hand, compatible performances are observed in the experiments on single feature multi-attribute datasets.',
	 'authors': u'Mete Ozay, Fatos T. Yarman Vural,',
	 'category': u'Computer Science ',
	 'date': '2012-4-1',
	 'pdflink': u'http://arxiv.org/pdf/1204.0171',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nA New Fuzzy Stacked Generalization Technique and Analysis of its  Performance',
	 'urllink': u'http://arxiv.org/abs/1204.0171'}
2015-03-23 23:49:07+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0701> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:49:07+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0701>
	{'abstract': u'Transient diffusion equations arise in many branches of engineering and applied sciences (e.g., heat transfer and mass transfer), and are parabolic partial differential equations. It is well-known that, under certain assumptions on the input data, these equations satisfy important mathematical properties like maximum principles and the non-negative constraint, which have implications in mathematical modeling. However, existing numerical formulations for these types of equations do not, in general, satisfy maximum principles and the non-negative constraint. In this paper, we present a methodology for enforcing maximum principles and the non-negative constraint for transient anisotropic diffusion equation. The method of horizontal lines (also known as the Rothe method) is applied in which the time is discretized first. This results in solving steady anisotropic diffusion equation with decay equation at every discrete time level. The proposed methodology for transient anisotropic diffusion equation will satisfy maximum principles and the non-negative constraint on general computational grids, and with no additional restrictions on the time step. We illustrate the performance and accuracy of the proposed formulation using representative numerical examples. We also perform numerical convergence of the proposed methodology. For comparison, we also present the results from the standard single-field semi-discrete formulation and the results from a popular software package, which all will violate maximum principles and the non-negative constraint.',
	 'authors': u'K. B. Nakshatrala, H. Nagarajan, M. Shabouei,',
	 'category': u'Computer Science ',
	 'date': '2012-6-4',
	 'pdflink': u'http://arxiv.org/pdf/1206.0701',
	 'subjects': u'Numerical Analysis (cs.NA)',
	 'title': u'\nA numerical methodology for enforcing maximum principles and the  non-negative constraint for transient diffusion equations',
	 'urllink': u'http://arxiv.org/abs/1206.0701'}
2015-03-23 23:49:17+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.4045> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:49:17+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.4045>
	{'abstract': u'Our main theoretical result is that, if a simple polytope has a pair of complementary vertices (i.e., two vertices with no facets in common), then it has at least two such pairs, which can be chosen to be disjoint. Using this result, we improve adjacency testing for vertices in both simple and non-simple polytopes: given a polytope in the standard form and a list of its V vertices, we describe an O(n) test to identify whether any two given vertices are adjacent. For simple polytopes this test is perfect; for non-simple polytopes it may be indeterminate, and instead acts as a filter to identify non-adjacent pairs. Our test requires an O(n^2 V + n V^2) precomputation, which is acceptable in settings such as all-pairs adjacency testing. These results improve upon the more general O(nV) combinatorial and O(n^3) algebraic adjacency tests from the literature.',
	 'authors': u'Benjamin A. Burton,',
	 'category': u'Computer Science ',
	 'date': '2012-2-18',
	 'pdflink': u'http://arxiv.org/pdf/1202.4045',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nComplementary vertices and adjacency testing in polytopes',
	 'urllink': u'http://arxiv.org/abs/1202.4045'}
2015-03-23 23:49:20+0000 [xxu46_4] INFO: Crawled 479 pages (at 4 pages/min), scraped 473 items (at 4 items/min)
2015-03-23 23:49:35+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.5161> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:49:35+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.5161>
	{'abstract': u'A dynamical system is controllable if by imposing appropriate external signals on a subset of its nodes, it can be driven from any initial state to any desired state in finite time. Here we study the impact of various network characteristics on the minimal number of driver nodes required to control a network. We find that clustering and modularity have no discernible impact, but the symmetries of the underlying matching problem can produce linear, quadratic or no dependence on degree correlation coefficients, depending on the nature of the underlying correlations. The results are supported by numerical simulations and help narrow the observed gap between the predicted and the observed number of driver nodes in real networks.',
	 'authors': u'M\xe1rton P\xf3sfai, Yang-Yu Liu, Jean-Jacques Slotine, Albert-L\xe1szl\xf3 Barab\xe1si,',
	 'category': u'Computer Science ',
	 'date': '2012-3-23',
	 'pdflink': u'http://arxiv.org/pdf/1203.5161',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nEffect of correlations on network controllability',
	 'urllink': u'http://arxiv.org/abs/1203.5161'}
2015-03-23 23:49:50+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0692> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:49:50+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0692>
	{'abstract': u'This paper presents a new family of localized orthonormal bases - sinlets - which are well suited for both signal and image processing and analysis. One-dimensional sinlets are related to specific solutions of the time-dependent harmonic oscillator equation. By construction, each sinlet is infinitely differentiable and has a well-defined and smooth instantaneous frequency known in analytical form. For square-integrable transient signals with infinite support, one-dimensional sinlet basis provides an advantageous alternative to the Fourier transform by rendering accurate signal representation via a countable set of real-valued coefficients. The properties of sinlets make them suitable for analyzing many real-world signals whose frequency content changes with time including radar and sonar waveforms, music, speech, biological echolocation sounds, biomedical signals, seismic acoustic waves, and signals employed in wireless communication systems. One-dimensional sinlet bases can be used to construct two- and higher-dimensional bases with variety of potential applications including image analysis and representation.',
	 'authors': u'Alexander Y. Davydov,',
	 'category': u'Computer Science ',
	 'date': '2012-6-4',
	 'pdflink': u'http://arxiv.org/pdf/1206.0692',
	 'subjects': u'Multimedia (cs.MM)',
	 'title': u'\nSignal and Image Processing with Sinlets',
	 'urllink': u'http://arxiv.org/abs/1206.0692'}
2015-03-23 23:50:07+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.3985> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:50:07+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.3985>
	{'abstract': u'We present two algorithms that, given a prime ell and an elliptic curve E/Fq, directly compute the polynomial Phi_ell(j(E),Y) in Fq[Y] whose roots are the j-invariants of the elliptic curves that are ell-isogenous to E. We do not assume that the modular polynomial Phi_ell(X,Y) is given. The algorithms may be adapted to handle other types of modular polynomials, and we consider applications to point counting and the computation of endomorphism rings. We demonstrate the practical efficiency of the algorithms by setting a new point-counting record, modulo a prime q with more than 5,000 decimal digits, and by evaluating a modular polynomial of level ell = 100,019.',
	 'authors': u'Andrew V. Sutherland,',
	 'category': u'Computer Science ',
	 'date': '2012-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1202.3985',
	 'subjects': u'Number Theory (math.NT)',
	 'title': u'\nOn the evaluation of modular polynomials',
	 'urllink': u'http://arxiv.org/abs/1202.3985'}
2015-03-23 23:50:20+0000 [xxu46_4] INFO: Crawled 482 pages (at 3 pages/min), scraped 476 items (at 3 items/min)
2015-03-23 23:50:24+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.5158> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:50:24+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.5158>
	{'abstract': u'This study examines long-term trends and shifting behavior in the collaboration network of mathematics literature, using a subset of data from Mathematical Reviews spanning 1985-2009. Rather than modeling the network cumulatively, this study traces the evolution of the "here and now" using fixed-duration sliding windows. The analysis uses a suite of common network diagnostics, including the distributions of degrees, distances, and clustering, to track network structure. Several random models that call these diagnostics as parameters help tease them apart as factors from the values of others. Some behaviors are consistent over the entire interval, but most diagnostics indicate that the network\'s structural evolution is dominated by occasional dramatic shifts in otherwise steady trends. These behaviors are not distributed evenly across the network; stark differences in evolution can be observed between two major subnetworks, loosely thought of as "pure" and "applied", which approximately partition the aggregate. The paper characterizes two major events along the mathematics network trajectory and discusses possible explanatory factors.',
	 'authors': u'Jason Cory Brunson, Steve Fassino, Antonio McInnes, Monisha Narayan, Brianna Richardson, Christopher Franck, Patrick Ion, Reinhard Laubenbacher,',
	 'category': u'Computer Science ',
	 'date': '2012-3-23',
	 'pdflink': u'http://arxiv.org/pdf/1203.5158',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nEvolutionary Events in a Mathematical Sciences Research Collaboration  Network',
	 'urllink': u'http://arxiv.org/abs/1203.5158'}
2015-03-23 23:50:41+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0681> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:50:41+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0681>
	{'abstract': u'Information and Communication Technologies (ICTs) play a key role in Development &amp; Economic growth of the Developing countries of the World. Political, Cultural, Socio-economic Developmental &amp; Behavioral decisions today rests on the ability to access, gather, analyze and utilize Information and Knowledge. Government of India is having an ambitious objective of transforming the citizen-government interaction at all levels to by the electronic mode by 2020.Similarly according to the Vision 2020-The Way Forward presented by His Excellency YAB Dato\' Seri Dr Mahathir Mohamad at the Malaysian Business Council "By the year 2020, Malaysia can be a united nation, with a confident Malaysian society, infused by strong moral and ethical values, living in a society that is democratic, liberal and tolerant, caring, economically just and equitable, progressive and prosperous, and in full possession of an economy that is competitive, dynamic, robust and resilient". This paper presents a comparative study and review relating to e-Governance and application of ICT development between India &amp; Malaysia.',
	 'authors': u'Ganesh Ch Deka, Jasni Mohamad Zain, Prabhat Mahanti,',
	 'category': u'Computer Science ',
	 'date': '2012-3-29',
	 'pdflink': u'http://arxiv.org/pdf/1206.0681',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u"\nICT's role in e-Governance in India and Malaysia: A Review",
	 'urllink': u'http://arxiv.org/abs/1206.0681'}
2015-03-23 23:50:56+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.3952> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:50:56+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.3952>
	{'abstract': u'Molecular biology data are subject to terms of use that vary widely between databases and curating institutions. This research presents a taxonomy of contractual and technical restrictions applicable to databases in life science. It builds upon research led by Science Commons demonstrating why open data and the freedom to integrate facilitate innovation and how this openness can be achieved. The taxonomy describes technical and legal restrictions applicable to life science databases, and its metadata have been used to assess terms of use of databases hosted by Life Science Resource Name (LSRN) Schema. While a few public domain policies are standardized, most terms of use are not harmonized, difficult to understand and impose controls that prevent others from effectively reusing data. Identifying a small number of restrictions allows one to quickly appreciate which databases are open. A checklist for data openness is proposed in order to assist database curators who wish to make their data more open to make sure they do so.',
	 'authors': u'Melanie Dulong De Rosnay,',
	 'category': u'Computer Science ',
	 'date': '2012-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1202.3952',
	 'subjects': u'Quantitative Methods (q-bio.QM)',
	 'title': u'\nCheck Your Data Freedom: A Taxonomy to Assess Life Science Database  Openness',
	 'urllink': u'http://arxiv.org/abs/1202.3952'}
2015-03-23 23:51:07+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.5101> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:51:07+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.5101>
	{'abstract': u"The human sense of hearing perceives a combination of sounds 'in tune' if the corresponding harmonic spectra are correlated, meaning that the neuronal excitation pattern in the inner ear exhibits some kind of order. Based on this observation it is suggested that musical instruments such as pianos can be tuned by minimizing the Shannon entropy of suitably preprocessed Fourier spectra. This method reproduces not only the correct stretch curve but also similar pitch fluctuations as in the case of high-quality aural tuning.",
	 'authors': u'Haye Hinrichsen,',
	 'category': u'Computer Science ',
	 'date': '2012-3-22',
	 'pdflink': u'http://arxiv.org/pdf/1203.5101',
	 'subjects': u'Classical Physics (physics.class-ph)',
	 'title': u'\nEntropy-based Tuning of Musical Instruments',
	 'urllink': u'http://arxiv.org/abs/1203.5101'}
2015-03-23 23:51:20+0000 [xxu46_4] INFO: Crawled 486 pages (at 4 pages/min), scraped 480 items (at 4 items/min)
2015-03-23 23:51:25+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.6509> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:51:25+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.6509>
	{'abstract': u'We introduce in this paper a new way of optimizing the natural extension of the quantization error using in k-means clustering to dissimilarity data. The proposed method is based on hierarchical clustering analysis combined with multi-level heuristic refinement. The method is computationally efficient and achieves better quantization errors than the',
	 'authors': u'Brieuc Conan-Guez, Fabrice Rossi,',
	 'category': u'Computer Science ',
	 'date': '2012-4-29',
	 'pdflink': u'http://arxiv.org/pdf/1204.6509',
	 'subjects': u'Machine Learning (stat.ML)',
	 'title': u'\nDissimilarity Clustering by Hierarchical Multi-Level Refinement',
	 'urllink': u'http://arxiv.org/abs/1204.6509'}
2015-03-23 23:51:39+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0663> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:51:39+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0663>
	{'abstract': u'Signal recovery is one of the key techniques of Compressive sensing (CS). It reconstructs the original signal from the linear sub-Nyquist measurements. Classical methods exploit the sparsity in one domain to formulate the L0 norm optimization. Recent investigation shows that some signals are sparse in multiple domains. To further improve the signal reconstruction performance, we can exploit this multi-sparsity to generate a new convex programming model. The latter is formulated with multiple sparsity constraints in multiple domains and the linear measurement fitting constraint. It improves signal recovery performance by additional a priori information. Since some EMG signals exhibit sparsity both in time and frequency domains, we take them as example in numerical experiments. Results show that the newly proposed method achieves better performance for multi-sparse signals.',
	 'authors': u'Yipeng Liu, Ivan Gligorijevic, Vladimir Matic, Maarten De Vos, Sabine Van Huffel,',
	 'category': u'Computer Science ',
	 'date': '2012-6-4',
	 'pdflink': u'http://arxiv.org/pdf/1206.0663',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nMulti-Sparse Signal Recovery for Compressive Sensing',
	 'urllink': u'http://arxiv.org/abs/1206.0663'}
2015-03-23 23:51:48+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.3861> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:51:48+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.3861>
	{'abstract': u'It is shown that under certain circumstances in particular for small datasets the recently proposed citation impact indicators I3(6PR) and R(6,k) behave inconsistently when additional papers or citations are taken into consideration. Three simple examples are presented, in which the indicators fluctuate strongly and the ranking of scientists in the evaluated group is sometimes completely mixed up by minor changes in the data base. The erratic behavior is traced to the specific way in which weights are attributed to the six percentile rank classes, specifically for the tied papers. For 100 percentile rank classes the effects will be less serious. For the 6 classes it is demonstrated that a different way of assigning weights avoids these problems, although the non-linearity of the weights for the different percentile rank classes can still lead to (much less frequent) changes in the ranking. This behavior is not undesired, because it can be used to correct for differences in citation behavior in different fields. Remaining deviations from the theoretical value R(6,k) = 1.91 can be avoided by a new scoring rule, the fractional scoring. Previously proposed consistency criteria are amended by another property of strict independence which a performance indicator should aim at.',
	 'authors': u'Michael Schreiber,',
	 'category': u'Computer Science ',
	 'date': '2012-2-17',
	 'pdflink': u'http://arxiv.org/pdf/1202.3861',
	 'subjects': u'Applications (stat.AP)',
	 'title': u'\nInconsistencies of Recently Proposed Citation Impact Indicators and how  to Avoid Them',
	 'urllink': u'http://arxiv.org/abs/1202.3861'}
2015-03-23 23:52:02+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.5086> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:52:02+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.5086>
	{'abstract': u'In Nature, the primary goal of any network is to survive. This is less obvious for engineering networks (electric power, gas, water, transportation systems etc.) that are expected to operate under normal conditions most of time. As a result, the ability of a network to withstand massive sudden damage caused by adverse events (or survivability) has not been among traditional goals in the network design. Reality, however, calls for the adjustment of design priorities. As modern networks develop toward increasing their size, complexity, and integration, the likelihood of adverse events increases too due to technological development, climate change, and activities in the political arena among other factors. Under such circumstances, a network failure has an unprecedented effect on lives and economy. To mitigate the impact of adverse events on the network operability, the survivability analysis must be conducted at the early stage of the network design. Such analysis requires the development of new analytical and computational tools. Computational analysis of the network survivability is the exponential time problem at least. The current paper describes a new algorithm, in which the reduction of the computational complexity is achieved by mapping an initial network topology with multiple sources and sinks onto a set of simpler smaller topologies with multiple sources and a single sink. Steps for further reducing the time and space expenses of computations are also discussed.',
	 'authors': u'Svetlana V. Poroseva,',
	 'category': u'Computer Science ',
	 'date': '2012-3-22',
	 'pdflink': u'http://arxiv.org/pdf/1203.5086',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\n"Selfish" algorithm for optimizing the network survivability analysis',
	 'urllink': u'http://arxiv.org/abs/1203.5086'}
2015-03-23 23:52:17+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.6716> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:52:17+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.6716>
	{'abstract': u'Over the past two decades, every scholarly publisher has migrated at least the mechanical aspects of their journal publishing so that they utilize digital means. The academy was comfortable with that for a while, but publishers are under increasing pressure to adapt further. At the American Astronomical Society (AAS), we think that means bringing our publishing program to the point of being fully digital, by establishing procedures and policies that regard the digital objects of publication primarily. We have always thought about our electronic journals as databases of digital articles, from which we can publish and syndicate articles one at a time, and we must now put flesh on those bones by developing practices that are consistent with the realities of article at a time publication online. As a learned society that holds the long-term rights to the literature, we have actively taken responsibility for the preservation of the digital assets that constitute our journals, and in so doing we have not forsaken the legacy pre-digital assets. All of us who serve as the long-term stewards of scholarship must begin to evolve into fully digital publishers.',
	 'authors': u'Chris Biemesderfer,',
	 'category': u'Computer Science ',
	 'date': '2012-4-30',
	 'pdflink': u'http://arxiv.org/pdf/1204.6716',
	 'subjects': u'Instrumentation and Methods for Astrophysics (astro-ph.IM)',
	 'title': u'\nFully Digital: Policy and Process Implications for the AAS',
	 'urllink': u'http://arxiv.org/abs/1204.6716'}
2015-03-23 23:52:20+0000 [xxu46_4] INFO: Crawled 491 pages (at 5 pages/min), scraped 485 items (at 5 items/min)
2015-03-23 23:52:29+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0652> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:52:29+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0652>
	{'abstract': u'We study a social network consisting of agents organized as a hierarchical M-ary rooted tree, common in enterprise and military organizational structures. The goal is to aggregate information to solve a binary hypothesis testing problem. Each agent at a leaf of the tree, and only such an agent, makes a direct measurement of the underlying true hypothesis. The leaf agent then makes a decision and sends it to its supervising agent, at the next level of the tree. Each supervising agent aggregates the decisions from the M members of its group, produces a summary message, and sends it to its supervisor at the next level, and so on. Ultimately, the agent at the root of the tree makes an overall decision. We derive upper and lower bounds for the Type I and II error probabilities associated with this decision with respect to the number of leaf agents, which in turn characterize the converge rates of the Type I, Type II, and total error probabilities. We also provide a message-passing scheme involving non-binary message alphabets and characterize the exponent of the error probability with respect to the message alphabet size.',
	 'authors': u'Zhenliang Zhang, Edwin K. P. Chong, Ali Pezeshki, William Moran, Stephen D. Howard,',
	 'category': u'Computer Science ',
	 'date': '2012-5-30',
	 'pdflink': u'http://arxiv.org/pdf/1206.0652',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nLearning in Hierarchical Social Networks',
	 'urllink': u'http://arxiv.org/abs/1206.0652'}
2015-03-23 23:52:42+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.3774> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:52:42+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.3774>
	{'abstract': u'In this paper, we study the risk bounds for samples independently drawn from an infinitely divisible (ID) distribution. In particular, based on a martingale method, we develop two deviation inequalities for a sequence of random variables of an ID distribution with zero Gaussian component. By applying the deviation inequalities, we obtain the risk bounds based on the covering number for the ID distribution. Finally, we analyze the asymptotic convergence of the risk bound derived from one of the two deviation inequalities and show that the convergence rate of the bound is faster than the result for the generic i.i.d. empirical process (Mendelson, 2003).',
	 'authors': u'Chao Zhang, Dacheng Tao,',
	 'category': u'Computer Science ',
	 'date': '2012-2-14',
	 'pdflink': u'http://arxiv.org/pdf/1202.3774',
	 'subjects': u'Machine Learning (stat.ML)',
	 'title': u'\nRisk Bounds for Infinitely Divisible Distribution',
	 'urllink': u'http://arxiv.org/abs/1202.3774'}
2015-03-23 23:52:54+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.5069> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:52:54+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.5069>
	{'abstract': u'In this paper we prove that random --regular graphs with have traffic congestion of the order where is the number of nodes and geodesic routing is used. We also show that these graphs are not asymptotically --hyperbolic for any non--negative almost surely as .',
	 'authors': u'Gabriel H. Tucci,',
	 'category': u'Computer Science ',
	 'date': '2012-3-22',
	 'pdflink': u'http://arxiv.org/pdf/1203.5069',
	 'subjects': u'Metric Geometry (math.MG)',
	 'title': u'\nRandom Regular Graphs are not Asymptotically Gromov Hyperbolic',
	 'urllink': u'http://arxiv.org/abs/1203.5069'}
2015-03-23 23:53:09+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.6695> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:53:09+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.6695>
	{'abstract': u'String diagrams are a powerful tool for reasoning about physical processes, logic circuits, tensor networks, and many other compositional structures. Dixon, Duncan and Kissinger introduced string graphs, which are a combinatoric representations of string diagrams, amenable to automated reasoning about diagrammatic theories via graph rewrite systems. In this extended abstract, we show how the power of such rewrite systems can be greatly extended by introducing pattern graphs, which provide a means of expressing infinite families of rewrite rules where certain marked subgraphs, called !-boxes ("bang boxes"), on both sides of a rule can be copied any number of times or removed. After reviewing the string graph formalism, we show how string graphs can be extended to pattern graphs and how pattern graphs and pattern rewrite rules can be instantiated to concrete string graphs and rewrite rules. We then provide examples demonstrating the expressive power of pattern graphs and how they can be applied to study interacting algebraic structures that are central to categorical quantum mechanics.',
	 'authors': u'Aleks Kissinger, Alex Merry, Matvey Soloviev,',
	 'category': u'Computer Science ',
	 'date': '2012-4-30',
	 'pdflink': u'http://arxiv.org/pdf/1204.6695',
	 'subjects': u'Category Theory (math.CT)',
	 'title': u'\nPattern graph rewrite systems',
	 'urllink': u'http://arxiv.org/abs/1204.6695'}
2015-03-23 23:53:20+0000 [xxu46_4] INFO: Crawled 495 pages (at 4 pages/min), scraped 489 items (at 4 items/min)
2015-03-23 23:53:21+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0643> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:53:21+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0643>
	{'abstract': u'In this technical report, we analyze the performance of an interference-aware opportunistic relay selection protocol for multi-hop line networks which is based on the following simple rule: a node always transmits if it has a packet, except when its successive node on the line is transmitting. We derive analytically the saturation throughput and the end-to-end delay for two and three hop networks, and present simulation results for higher numbers of hops. In the case of three hops, we determine the throughput-optimal relay positions.',
	 'authors': u'Kostas Stamatiou, Davide Chiarotto, Federico Librino, Michele Zorzi,',
	 'category': u'Computer Science ',
	 'date': '2012-6-4',
	 'pdflink': u'http://arxiv.org/pdf/1206.0643',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nPerformance analysis of an opportunistic relay selection protocol for  multi-hop networks (Technical report)',
	 'urllink': u'http://arxiv.org/abs/1206.0643'}
2015-03-23 23:53:38+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.3765> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:53:38+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.3765>
	{'abstract': u'Structure learning of Gaussian graphical models is an extensively studied problem in the classical multivariate setting where the sample size n is larger than the number of random variables p, as well as in the more challenging setting when p&gt;&gt;n. However, analogous approaches for learning the structure of graphical models with mixed discrete and continuous variables when p&gt;&gt;n remain largely unexplored. Here we describe a statistical learning procedure for this problem based on limited-order correlations and assess its performance with synthetic and real data.',
	 'authors': u'Inma Tur, Robert Castelo,',
	 'category': u'Computer Science ',
	 'date': '2012-2-14',
	 'pdflink': u'http://arxiv.org/pdf/1202.3765',
	 'subjects': u'Methodology (stat.ME)',
	 'title': u'\nLearning mixed graphical models from data with p larger than n',
	 'urllink': u'http://arxiv.org/abs/1202.3765'}
2015-03-23 23:53:50+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.4988> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:53:50+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.4988>
	{'abstract': u'Categorical quantum mechanics studies quantum theory in the framework of dagger-compact closed categories. Using this framework, we establish a tight relationship between two key quantum theoretical notions: non-locality and complementarity. In particular, we establish a direct connection between Mermin-type non-locality scenarios, which we generalise to an arbitrary number of parties, using systems of arbitrary dimension, and performing arbitrary measurements, and a new stronger notion of complementarity which we introduce here. Our derivation of the fact that strong complementarity is a necessary condition for a Mermin scenario provides a crisp operational interpretation for strong complementarity. We also provide a complete classification of strongly complementary observables for quantum theory, something which has not yet been achieved for ordinary complementarity. Since our main results are expressed in the (diagrammatic) language of dagger-compact categories, they can be applied outside of quantum theory, in any setting which supports the purely algebraic notion of strongly complementary observables. We have therefore introduced a method for discussing non-locality in a wide variety of models in addition to quantum theory. The diagrammatic calculus substantially simplifies (and sometimes even trivialises) many of the derivations, and provides new insights. In particular, the diagrammatic computation of correlations clearly shows how local measurements interact to yield a global overall effect. In other words, we depict non-locality.',
	 'authors': u'Bob Coecke, Ross Duncan, Aleks Kissinger, Quanlong Wang,',
	 'category': u'Computer Science ',
	 'date': '2012-3-22',
	 'pdflink': u'http://arxiv.org/pdf/1203.4988',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nStrong Complementarity and Non-locality in Categorical Quantum Mechanics',
	 'urllink': u'http://arxiv.org/abs/1203.4988'}
2015-03-23 23:54:05+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.6687> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:54:05+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.6687>
	{'abstract': u"A sequence S is nonrepetitive if no two adjacent blocks of S are the same. In 1906 Thue proved that there exist arbitrarily long nonrepetitive sequences over 3 symbols. We consider the online variant of this result in which a nonrepetitive sequence is constructed during a play between two players: Bob is choosing a position in a sequence and Alice is inserting a symbol on that position taken from a fixed set A. The goal of Bob is to force Alice to create a repetition, and if he succeeds, then the game stops. The goal of Alice is naturally to avoid that and thereby to construct a nonrepetitive sequence of any given length. We prove that Alice has a strategy to play arbitrarily long provided the size of the set A is at least 12. This is the online version of the Theorem of Thue. The proof is based on nonrepetitive colorings of outerplanar graphs. On the other hand, one can prove that even over 4 symbols Alice has no chance to play for too long. The minimum size of the set of symbols needed for the online version of Thue's theorem remains unknown.",
	 'authors': u'Jaros\u0142aw Grytczuk, Piotr Szafruga, Micha\u0142 Zmarz,',
	 'category': u'Computer Science ',
	 'date': '2012-4-30',
	 'pdflink': u'http://arxiv.org/pdf/1204.6687',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nOnline version of the theorem of Thue',
	 'urllink': u'http://arxiv.org/abs/1204.6687'}
2015-03-23 23:54:20+0000 [xxu46_4] INFO: Crawled 499 pages (at 4 pages/min), scraped 493 items (at 4 items/min)
2015-03-23 23:54:22+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0641> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:54:22+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0641>
	{'abstract': u'Exponential backoff (EB) is a widely adopted collision resolution mechanism in many popular random-access networks including Ethernet and wireless LAN (WLAN). The prominence of EB is primarily attributed to its asymptotic throughput stability, which ensures a non-zero throughput even when the number of users in the network goes to infinity. Recent studies, however, show that EB is fundamentally unsuitable for applications that are sensitive to large delay and delay jitters, as it induces divergent second- and higher-order moments of medium access delay. Essentially, the medium access delay follows a power law distribution, a subclass of heavy-tailed distribution. To understand and alleviate the issue, this paper systematically analyzes the tail delay distribution of general backoff functions, with EB being a special case. In particular, we establish a tradeoff between the tail decaying rate of medium access delay distribution and the stability of throughput. To be more specific, convergent delay moments are attainable only when the backoff functions grows slower than exponential functions, i.e., when for all . On the other hand, non-zero asymptotic throughput is attainable only when backoff functions grow at least as fast as an exponential function, i.e., for some . This implies that bounded delay moments and stable throughput cannot be achieved at the same time. For practical implementation, we show that polynomial backoff (PB), where is a polynomial that grows slower than exponential functions, obtains finite delay moments and good throughput performance at the same time within a practical range of user population. This makes PB a better alternative than EB for multimedia applications with stringent delay requirements.',
	 'authors': u'Suzhi Bi, Ying Jun Zhang,',
	 'category': u'Computer Science ',
	 'date': '2012-6-4',
	 'pdflink': u'http://arxiv.org/pdf/1206.0641',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nThe Cost of Mitigating Power Law Delay in Random Access Networks',
	 'urllink': u'http://arxiv.org/abs/1206.0641'}
2015-03-23 23:54:40+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.3760> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:54:40+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.3760>
	{'abstract': u'Markov jump processes and continuous time Bayesian networks are important classes of continuous time dynamical systems. In this paper, we tackle the problem of inferring unobserved paths in these models by introducing a fast auxiliary variable Gibbs sampler. Our approach is based on the idea of uniformization, and sets up a Markov chain over paths by sampling a finite set of virtual jump times and then running a standard hidden Markov model forward filtering-backward sampling algorithm over states at the set of extant and virtual jump times. We demonstrate significant computational benefits over a state-of-the-art Gibbs sampler on a number of continuous time Bayesian networks.',
	 'authors': u'Vinayak Rao, Yee Whye Teh,',
	 'category': u'Computer Science ',
	 'date': '2012-2-14',
	 'pdflink': u'http://arxiv.org/pdf/1202.3760',
	 'subjects': u'Methodology (stat.ME)',
	 'title': u'\nFast MCMC sampling for Markov jump processes and continuous time  Bayesian networks',
	 'urllink': u'http://arxiv.org/abs/1202.3760'}
2015-03-23 23:54:54+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.4917> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:54:54+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.4917>
	{'abstract': u'This paper introduces and analyzes a particular class of Polya urns: balls are of two colors, can only be added (the urns are said to be additive) and at every step the same constant number of balls is added, thus only the color compositions varies (the urns are said to be balanced). These properties make this class of urns ideally suited for analysis from an "analytic combinatorics" point-of-view, following in the footsteps of Flajolet-Dumas-Puyhaubert, 2006. Through an algebraic generating function to which we apply a multiple coalescing saddle-point method, we are able to give precise asymptotic results for the probability distribution of the composition of the urn, as well as local limit law and large deviation bounds.',
	 'authors': u'Basile Morcrette,',
	 'category': u'Computer Science ',
	 'date': '2012-3-22',
	 'pdflink': u'http://arxiv.org/pdf/1203.4917',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nFully Analyzing an Algebraic Polya Urn Model',
	 'urllink': u'http://arxiv.org/abs/1203.4917'}
2015-03-23 23:55:10+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.6681> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:55:10+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.6681>
	{'abstract': u'A graph is well-covered if every maximal independent set has the same cardinality, namely the vertex independence number. We answer a question of Topp and Volkmann and prove that if the Cartesian product of two graphs is well-covered, then at least one of them must be well-covered.',
	 'authors': u'Bert L. Hartnell, Douglas F. Rall,',
	 'category': u'Computer Science ',
	 'date': '2012-4-30',
	 'pdflink': u'http://arxiv.org/pdf/1204.6681',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nOn the Cartesian product of non well-covered graphs',
	 'urllink': u'http://arxiv.org/abs/1204.6681'}
2015-03-23 23:55:20+0000 [xxu46_4] INFO: Crawled 503 pages (at 4 pages/min), scraped 497 items (at 4 items/min)
2015-03-23 23:55:27+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0638> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:55:27+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0638>
	{'abstract': u'This user manual has been written to describe the open source code WM to be distributed associated with a research article submitted to the information technology journal 45001-ITJ-ANSI, entitled: "Maintenance and Reengineering of software: Creating a Visual C++ Graphical User Interface to Perform Specific Tasks Related to Soil Structure Interaction in Poroelastic Soil".',
	 'authors': u'Amani Tahat, Jordi Marti, Mohammad Tahat,',
	 'category': u'Computer Science ',
	 'date': '2012-6-4',
	 'pdflink': u'http://arxiv.org/pdf/1206.0638',
	 'subjects': u'Computational Engineering, Finance, and Science (cs.CE)',
	 'title': u'\nWM Program manual',
	 'urllink': u'http://arxiv.org/abs/1206.0638'}
2015-03-23 23:55:39+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.3672> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:55:39+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.3672>
	{'abstract': u'We show a model construction for a system of higher-order illative combinatory logic , thus establishing its strong consistency. We also use a variant of this construction to provide a complete embedding of first-order intuitionistic predicate logic with second-order propositional quantifiers into the system of Barendregt, Bunder and Dekkers, which gives a partial answer to a question posed by these authors.',
	 'authors': u'\u0141ukasz Czajka,',
	 'category': u'Computer Science ',
	 'date': '2012-2-16',
	 'pdflink': u'http://arxiv.org/pdf/1202.3672',
	 'subjects': u'Logic (math.LO)',
	 'title': u'\nHigher-order illative combinatory logic',
	 'urllink': u'http://arxiv.org/abs/1202.3672'}
2015-03-23 23:55:56+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.4885> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:55:56+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.4885>
	{'abstract': u'In this thesis, we answer several questions about the behaviour of prover-verifier interactions under parallel repetition when quantum information is allowed, and the verifier acts independently in them. We first consider the case in which a value is associated with each of the possible outcomes of an interaction. We prove that it is not possible for the prover to improve on the optimum average value per repetition by repeating the protocol multiple times in parallel. We look then at games in which the outcomes are classified into two types, winning outcomes and losing outcomes. We ask what is the optimal probability for the prover of winning at least k times out of n parallel repetitions, given that the optimal probability of winning when only one repetition is considered is . A reasonable conjecture for the answer would be sum_ p^m (1-p)^, as that is the answer when it is optimal for the prover to act independently. This is known to be the correct answer when k=n, and also in the classical case. It is also correct in some generalizations of the classical case that we will discuss later. We will show how this cannot be extended to all cases, presenting an example of an interaction with k=1,n=2 in which p approx 0.85, but it is possible to always win at least once. We will then give some upper bounds on the optimal probability for the prover of winning k times out of n parallel repetitions. These bounds are expressed as a function of p. Finally, we will connect our results to the study of error reduction for quantum interactive proofs using parallel repetition.',
	 'authors': u'Abel Molina,',
	 'category': u'Computer Science ',
	 'date': '2012-3-22',
	 'pdflink': u'http://arxiv.org/pdf/1203.4885',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nParallel Repetition of Prover-Verifier Quantum Interactions',
	 'urllink': u'http://arxiv.org/abs/1203.4885'}
2015-03-23 23:56:14+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.6645> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:56:14+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.6645>
	{'abstract': u'Szemer \'edi\'s regularity lemma is a fundamental tool in extremal combinatorics. However, the original version is only helpful in studying dense graphs. In the 1990s, Kohayakawa and R "odl proved an analogue of Szemer \'edi\'s regularity lemma for sparse graphs as part of a general program toward extending extremal results to sparse graphs. Many of the key applications of Szemer \'edi\'s regularity lemma use an associated counting lemma. In order to prove extensions of these results which also apply to sparse graphs, it remained a well-known open problem to prove a counting lemma in sparse graphs. The main advance of this paper lies in a new counting lemma, proved following the functional approach of Gowers, which complements the sparse regularity lemma of Kohayakawa and R "odl, allowing us to count small graphs in regular subgraphs of a sufficiently pseudorandom graph. We use this to prove sparse extensions of several well-known combinatorial theorems, including the removal lemmas for graphs and groups, the Erd Hs-Stone-Simonovits theorem and Ramsey\'s theorem. These results extend and improve upon a substantial body of previous work.',
	 'authors': u'David Conlon, Jacob Fox, Yufei Zhao,',
	 'category': u'Computer Science ',
	 'date': '2012-4-30',
	 'pdflink': u'http://arxiv.org/pdf/1204.6645',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nExtremal results in sparse pseudorandom graphs',
	 'urllink': u'http://arxiv.org/abs/1204.6645'}
2015-03-23 23:56:20+0000 [xxu46_4] INFO: Crawled 507 pages (at 4 pages/min), scraped 501 items (at 4 items/min)
2015-03-23 23:56:32+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0629> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:56:32+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0629>
	{'abstract': u'Community discovery in complex networks is an interesting problem with a number of applications, especially in the knowledge extraction task in social and information networks. However, many large networks often lack a particular community organization at a global level. In these cases, traditional graph partitioning algorithms fail to let the latent knowledge embedded in modular structure emerge, because they impose a top-down global view of a network. We propose here a simple local-first approach to community discovery, able to unveil the modular organization of real complex networks. This is achieved by democratically letting each node vote for the communities it sees surrounding it in its limited view of the global system, i.e. its ego neighborhood, using a label propagation algorithm; finally, the local communities are merged into a global collection. We tested this intuition against the state-of-the-art overlapping and non-overlapping community discovery methods, and found that our new method clearly outperforms the others in the quality of the obtained communities, evaluated by using the extracted communities to predict the metadata about the nodes of several real world networks. We also show how our method is deterministic, fully incremental, and has a limited time complexity, so that it can be used on web-scale real networks.',
	 'authors': u'Michele Coscia, Giulio Rossetti, Fosca Giannotti, Dino Pedreschi,',
	 'category': u'Computer Science ',
	 'date': '2012-6-4',
	 'pdflink': u'http://arxiv.org/pdf/1206.0629',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nDEMON: a Local-First Discovery Method for Overlapping Communities',
	 'urllink': u'http://arxiv.org/abs/1206.0629'}
2015-03-23 23:56:46+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.3663> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:56:46+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.3663>
	{'abstract': u'Identifying clusters of similar objects in data plays a significant role in a wide range of applications. As a model problem for clustering, we consider the densest k-disjoint-clique problem, whose goal is to identify the collection of k disjoint cliques of a given weighted complete graph maximizing the sum of the densities of the complete subgraphs induced by these cliques. In this paper, we establish conditions ensuring exact recovery of the densest k cliques of a given graph from the optimal solution of a particular semidefinite program. In particular, the semidefinite relaxation is exact for input graphs corresponding to data consisting of k large, distinct clusters and a smaller number of outliers. This approach also yields a semidefinite relaxation for the biclustering problem with similar recovery guarantees. Given a set of objects and a set of features exhibited by these objects, biclustering seeks to simultaneously group the objects and features according to their expression levels. This problem may be posed as partitioning the nodes of a weighted bipartite complete graph such that the sum of the densities of the resulting bipartite complete subgraphs is maximized. As in our analysis of the densest k-disjoint-clique problem, we show that the correct partition of the objects and features can be recovered from the optimal solution of a semidefinite program in the case that the given data consists of several disjoint sets of objects exhibiting similar features. Empirical evidence from numerical experiments supporting these theoretical guarantees is also provided.',
	 'authors': u'Brendan P. W. Ames,',
	 'category': u'Computer Science ',
	 'date': '2012-2-16',
	 'pdflink': u'http://arxiv.org/pdf/1202.3663',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nGuaranteed clustering and biclustering via semidefinite programming',
	 'urllink': u'http://arxiv.org/abs/1202.3663'}
2015-03-23 23:57:00+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.4875> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:57:00+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.4875>
	{'abstract': u'Spatial evolution game has traditionally assumed that players interact with neighbors on a single network, which is isolated and not influenced by other systems. We introduce the simple game model into the interdependent networks composed of two networks, and show that when the interdependent factor is smaller than a particular value , homogeneous cooperation can be guaranteed. However, as interdependent factor exceeds , spontaneous symmetry breaking of fraction of cooperators presents itself between different networks. In addition, our results can be well predicted by the strategy-couple pair approximation method.',
	 'authors': u'Qing Jin, Zhen Wang,',
	 'category': u'Computer Science ',
	 'date': '2012-3-22',
	 'pdflink': u'http://arxiv.org/pdf/1203.4875',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nSpontaneous Symmetry Breaking in Interdependent Networked Game',
	 'urllink': u'http://arxiv.org/abs/1203.4875'}
2015-03-23 23:57:12+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.6583> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:57:12+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.6583>
	{'abstract': u'In binary classification problems, mainly two approaches have been proposed; one is loss function approach and the other is uncertainty set approach. The loss function approach is applied to major learning algorithms such as support vector machine (SVM) and boosting methods. The loss function represents the penalty of the decision function on the training samples. In the learning algorithm, the empirical mean of the loss function is minimized to obtain the classifier. Against a backdrop of the development of mathematical programming, nowadays learning algorithms based on loss functions are widely applied to real-world data analysis. In addition, statistical properties of such learning algorithms are well-understood based on a lots of theoretical works. On the other hand, the learning method using the so-called uncertainty set is used in hard-margin SVM, mini-max probability machine (MPM) and maximum margin MPM. In the learning algorithm, firstly, the uncertainty set is defined for each binary label based on the training samples. Then, the best separating hyperplane between the two uncertainty sets is employed as the decision function. This is regarded as an extension of the maximum-margin approach. The uncertainty set approach has been studied as an application of robust optimization in the field of mathematical programming. The statistical properties of learning algorithms with uncertainty sets have not been intensively studied. In this paper, we consider the relation between the above two approaches. We point out that the uncertainty set is described by using the level set of the conjugate of the loss function. Based on such relation, we study statistical properties of learning algorithms using uncertainty sets.',
	 'authors': u'Takafumi Kanamori, Akiko Takeda, Taiji Suzuki,',
	 'category': u'Computer Science ',
	 'date': '2012-4-30',
	 'pdflink': u'http://arxiv.org/pdf/1204.6583',
	 'subjects': u'Machine Learning (stat.ML)',
	 'title': u'\nA Conjugate Property between Loss Functions and Uncertainty Sets in  Classification Problems',
	 'urllink': u'http://arxiv.org/abs/1204.6583'}
2015-03-23 23:57:20+0000 [xxu46_4] INFO: Crawled 511 pages (at 4 pages/min), scraped 505 items (at 4 items/min)
2015-03-23 23:57:26+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0609> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:57:26+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0609>
	{'abstract': u"The problem of proposed topology for network comes when using Prim's algorithm with default distance (unrealistic distances) between network's nodes and don't care about the lakes, high hills, buildings, etc. This problem will cause incorrect estimations for cost (budget) of requirements like the media (optic fibre) and the number or type of Access-points, regenerator, Optic Amplifier, etc. This paper proposed a new technique of implementing Prim's algorithm to obtain realistic topology using realistic distances between network's nodes via Global Positioning System GPS and Geographic Information Systems GIS packages. Applying the new technique on academic institutes network of Erbil city from view of media (optic fibre) shows that there is disability in cost (budget) of the media which is needed (nearly) 4 times if implement default Prim's algorithm (don't using GPS &amp; GIS) base on unrealistic distances between the nodes.",
	 'authors': u'Ayad Ghany Ismaeel,',
	 'category': u'Computer Science ',
	 'date': '2012-6-4',
	 'pdflink': u'http://arxiv.org/pdf/1206.0609',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u"\nNew Technique for Proposing Network's Topology using GPS and GIS",
	 'urllink': u'http://arxiv.org/abs/1206.0609'}
2015-03-23 23:57:42+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.3643> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:57:42+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.3643>
	{'abstract': u'In this work we study the dynamical features of editorial wars in Wikipedia (WP). Based on our previously established algorithm, we build up samples of controversial and peaceful articles and analyze the temporal characteristics of the activity in these samples. On short time scales, we show that there is a clear correspondence between conflict and burstiness of activity patterns, and that memory effects play an important role in controversies. On long time scales, we identify three distinct developmental patterns for the overall behavior of the articles. We are able to distinguish cases eventually leading to consensus from those cases where a compromise is far from achievable. Finally, we analyze discussion networks and conclude that edit wars are mainly fought by few editors only.',
	 'authors': u'Taha Yasseri, Robert Sumi, Andr\xe1s Rung, Andr\xe1s Kornai, J\xe1nos Kert\xe9sz,',
	 'category': u'Computer Science ',
	 'date': '2012-2-16',
	 'pdflink': u'http://arxiv.org/pdf/1202.3643',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nDynamics of conflicts in Wikipedia',
	 'urllink': u'http://arxiv.org/abs/1202.3643'}
2015-03-23 23:57:54+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.4863> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:57:54+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.4863>
	{'abstract': u'In this work we study the degree distribution, the maximum vertex and edge flow in non-uniform random Delaunay triangulations when geodesic routing is used. We also investigate the vertex and edge flow in Erd "os-Renyi random graphs, geometric random graphs, expanders and random -regular graphs. Moreover we show that adding a random matching to the original graph can considerably reduced the maximum vertex flow.',
	 'authors': u'John D. Hobby, Gabriel H. Tucci,',
	 'category': u'Computer Science ',
	 'date': '2012-3-22',
	 'pdflink': u'http://arxiv.org/pdf/1203.4863',
	 'subjects': u'Differential Geometry (math.DG)',
	 'title': u'\nTraffic Analysis in Random Delaunay Tessellations and Other Graphs',
	 'urllink': u'http://arxiv.org/abs/1203.4863'}
2015-03-23 23:58:04+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.6549> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:58:04+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.6549>
	{'abstract': u'The total number of patents produced by a country (or the number of patents produced per capita) is often used as an indicator for innovation. Here we present evidence that the distribution of patents amongst applicants within many OECD countries is well-described by power laws with exponents that vary between 1.66 (Japan) and 2.37 (Poland). Using simulations based on simple preferential attachment-type rules that generate power laws, we find we can explain some of the variation in exponents between countries, with countries that have larger numbers of patents per applicant generally exhibiting smaller exponents in both the simulated and actual data. Similarly we find that the exponents for most countries are inversely correlated with other indicators of innovation, such as R&amp;D intensity or the ubiquity of export baskets. This suggests that in more advanced economies, which tend to have smaller values of the exponent, a greater proportion of the total number of patents are filed by large companies than in less advanced countries.',
	 'authors': u"D. R. J. O'Neale, S. C. Hendy,",
	 'category': u'Computer Science ',
	 'date': '2012-4-30',
	 'pdflink': u'http://arxiv.org/pdf/1204.6549',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nPower Law Distributions of Patents as Indicators of Innovation',
	 'urllink': u'http://arxiv.org/abs/1204.6549'}
2015-03-23 23:58:20+0000 [xxu46_4] INFO: Crawled 515 pages (at 4 pages/min), scraped 509 items (at 4 items/min)
2015-03-23 23:58:21+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0604> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:58:21+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0604>
	{'abstract': u'With the advance of industrial mass production, modern micro-electronics and computers, the intervals between the release of new generations of consumer products have been dramatically reduced and so have their lifetime cycles. While it was very natural in the post-war era, that sophisticated consumer products like television sets and stereo equipment would not be replaced with a new product until they break, and usually beyond that point since it was very common to have a broken television set serviced, the habits of consumers have changed during the last quarter of the 20th century. A modern consumer product, like Apple\'s famous iPhone has a market life of approximately one year until a successor is announced and subsequently pushed into the market. Usually these new generations bring a bunch of new features, have a higher performance while maintaining the price or becoming even cheaper, thus the consumer greatly benefits from the reduced lifetime cycle of these products. However, electronic devices not only require a lot of of Earth\'s limited resources for their production, but their production processes are a major source for harmful climate gases like carbon dioxide and toxic waste like heavy metal alloys, acids and alkalis. And last but not least is every obsoleted iPhone a candidate for waste facilities unless consumers are going to sell them on the second hand market. While we can not expect consumers and manufacturers to go back to the early days of consumer products where lifetime cycles reached up to 20 years, the world record being the famous "Centennial Lightbulb" in Livermore, CA in the US, which has been lit for over 100 years, it is certainly about time to rethink modern consumerism with regard to responsibility to future generations.',
	 'authors': u'John Paul Adrian Glaubitz,',
	 'category': u'Computer Science ',
	 'date': '2012-6-4',
	 'pdflink': u'http://arxiv.org/pdf/1206.0604',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nModern consumerism and the waste problem',
	 'urllink': u'http://arxiv.org/abs/1206.0604'}
2015-03-23 23:58:38+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.3572> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:58:38+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.3572>
	{'abstract': u'In this work, a one-dimensional model of crystalline solids based on the Dirac comb limit of the Kronig-Penney model is considered. From the wave functions of the valence electrons, we calculate a statistical measure of complexity and the Fisher-Shannon information for the lower energy electronic bands appearing in the system. All these magnitudes present an extremal value for the case of solids having half-filled bands, a configuration where in general a high conductivity is attained in real solids, such as it happens with the monovalent metals.',
	 'authors': u'Jaime Sanudo, Ricardo Lopez-Ruiz,',
	 'category': u'Computer Science ',
	 'date': '2012-2-16',
	 'pdflink': u'http://arxiv.org/pdf/1202.3572',
	 'subjects': u'Adaptation and Self-Organizing Systems (nlin.AO)',
	 'title': u'\nCalculation of statistical entropic measures in a model of solids',
	 'urllink': u'http://arxiv.org/abs/1202.3572'}
2015-03-23 23:58:54+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.4807> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:58:54+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.4807>
	{'abstract': u'There is an overall perception of increased interdisciplinarity in science, but this is difficult to confirm quantitatively owing to the lack of adequate methods to evaluate subjective phenomena. This is no different from the difficulties in establishing quantitative relationships in human and social sciences. In this paper we quantified the interdisciplinarity of scientific journals and science fields by using an entropy measurement based on the diversity of the subject categories of journals citing a specific journal. The methodology consisted in building citation networks using the Journal Citation Reports database, in which the nodes were journals and edges were established based on citations among journals. The overall network for the 11-year period (1999-2009) studied was small-world and scale free with regard to the in-strength. Upon visualizing the network topology an overall structure of the various science fields could be inferred, especially their interconnections. We confirmed quantitatively that science fields are becoming increasingly interdisciplinary, with the degree of interdisplinarity (i.e. entropy) correlating strongly with the in-strength of journals and with the impact factor.',
	 'authors': u'Filipi Nascimento Silva, Francisco Aparecido Rodrigues, Osvaldo Novais de Oliveira Junior, Luciano da Fontoura Costa,',
	 'category': u'Computer Science ',
	 'date': '2012-3-21',
	 'pdflink': u'http://arxiv.org/pdf/1203.4807',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nQuantifying the interdisciplinarity of scientific journals and fields',
	 'urllink': u'http://arxiv.org/abs/1203.4807'}
2015-03-23 23:59:11+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.6512> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-23 23:59:11+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.6512>
	{'abstract': u'The numerical solution of high dimensional Vlasov equation is usually performed by particle-in-cell (PIC) methods. However, due to the well-known numerical noise, it is challenging to use PIC methods to get a precise description of the distribution function in phase space. To control the numerical error, we introduce an adaptive phase-space remapping which regularizes the particle distribution by periodically reconstructing the distribution function on a hierarchy of phase-space grids with high-order interpolations. The positivity of the distribution function can be preserved by using a local redistribution technique. The method has been successfully applied to a set of classical plasma problems in one dimension. In this paper, we present the algorithm for the two dimensional Vlasov-Poisson equations. An efficient Poisson solver with infinite domain boundary conditions is used. The parallel scalability of the algorithm on massively parallel computers will be discussed.',
	 'authors': u'Bei Wang, Greg Miller, Phil Colella,',
	 'category': u'Computer Science ',
	 'date': '2012-4-29',
	 'pdflink': u'http://arxiv.org/pdf/1204.6512',
	 'subjects': u'Numerical Analysis (math.NA)',
	 'title': u'\nAn adaptive, high-order phase-space remapping for the two-dimensional  Vlasov-Poisson equations',
	 'urllink': u'http://arxiv.org/abs/1204.6512'}
2015-03-23 23:59:17+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0603> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-23 23:59:17+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0603>
	{'abstract': u'This report presents the tool COMICS, which performs model checking and generates counterexamples for DTMCs. For an input DTMC, COMICS computes an abstract system that carries the model checking information and uses this result to compute a critical subsystem, which induces a counterexample. This abstract subsystem can be refined and concretized hierarchically. The tool comes with a command-line version as well as a graphical user interface that allows the user to interactively influence the refinement process of the counterexample.',
	 'authors': u'Nils Jansen, Erika \xc1brah\xe1m, Maik Scheffler, Matthias Volk, Andreas Vorpahl, Ralf Wimmer, Joost-Pieter Katoen, Bernd Becker,',
	 'category': u'Computer Science ',
	 'date': '2012-6-4',
	 'pdflink': u'http://arxiv.org/pdf/1206.0603',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nThe COMICS Tool - Computing Minimal Counterexamples for Discrete-time  Markov Chains',
	 'urllink': u'http://arxiv.org/abs/1206.0603'}
2015-03-23 23:59:20+0000 [xxu46_4] INFO: Crawled 520 pages (at 5 pages/min), scraped 514 items (at 5 items/min)
2015-03-23 23:59:34+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.3471> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-23 23:59:34+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.3471>
	{'abstract': u'Complex networks are formal frameworks capturing the interdependencies between the elements of large systems and databases. This formalism allows to use network navigation methods to rank the importance that each constituent has on the global organization of the system. A key example is Pagerank navigation which is at the core of the most used search engine of the World Wide Web. Inspired in this classical algorithm, we define a quantum navigation method providing a unique ranking of the elements of a network. We analyze the convergence of quantum navigation to the stationary rank of networks and show that quantumness decreases the number of navigation steps before convergence. In addition, we show that quantum navigation allows to solve degeneracies found in classical ranks. By implementing the quantum algorithm in real networks, we confirm these improvements and show that quantum coherence unveils new hierarchical features about the global organization of complex systems.',
	 'authors': u'Eduardo S\xe1nchez-Burillo, Jordi Duch, Jes\xfas G\xf3mez-Gardenes, David Zueco,',
	 'category': u'Computer Science ',
	 'date': '2012-2-15',
	 'pdflink': u'http://arxiv.org/pdf/1202.3471',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nQuantum Navigation and Ranking in Complex Networks',
	 'urllink': u'http://arxiv.org/abs/1202.3471'}
2015-03-23 23:59:51+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.4757> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-23 23:59:51+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.4757>
	{'abstract': u'We present a novel method for Ankylography: three-dimensional structure reconstruction from a single shot diffraction intensity pattern. Our approach allows reconstruction of objects containing many more details than was ever demonstrated, in a faster and more accurate fashion',
	 'authors': u'Eliyahu Osherovich, Oren Cohen, Yonina C. Eldar, Mordechai Segev,',
	 'category': u'Computer Science ',
	 'date': '2012-3-8',
	 'pdflink': u'http://arxiv.org/pdf/1203.4757',
	 'subjects': u'Optics (physics.optics)',
	 'title': u'\nDesigning and using prior data in Ankylography: Recovering a 3D object  from a single diffraction intensity pattern',
	 'urllink': u'http://arxiv.org/abs/1203.4757'}
2015-03-24 00:00:08+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.6422> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:00:08+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.6422>
	{'abstract': u'Given a hypergraph H = (V, E), a coloring of its vertices is said to be conflict-free if for every hyperedge S in E there is at least one vertex in S whose color is distinct from the colors of all other vertices in S. The discrete interval hypergraph Hn is the hypergraph with vertex set and hyperedge set the family of all subsets of consecutive integers in . We provide a polynomial time algorithm for conflict-free coloring any subhypergraph of Hn, we show that the algorithm has approximation ratio 2, and we prove that our analysis is tight, i.e., there is a subhypergraph for which the algorithm computes a solution which uses twice the number of colors of the optimal solution. We also show that the problem of deciding whether a given subhypergraph of Hn can be colored with at most k colors has a quasipolynomial time algorithm.',
	 'authors': u'Panagiotis Cheilaris, Shakhar Smorodinsky,',
	 'category': u'Computer Science ',
	 'date': '2012-4-28',
	 'pdflink': u'http://arxiv.org/pdf/1204.6422',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nConflict-free coloring with respect to a subset of intervals',
	 'urllink': u'http://arxiv.org/abs/1204.6422'}
2015-03-24 00:00:20+0000 [xxu46_4] INFO: Crawled 523 pages (at 3 pages/min), scraped 517 items (at 3 items/min)
2015-03-24 00:00:21+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0594> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:00:21+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0594>
	{'abstract': u'We adapt a well known streaming algorithm for approximating item frequencies to the matrix sketching setting. The algorithm receives the rows of a large matrix one after the other in a streaming fashion. It maintains a sketch matrix such that for any unit vector [ |Ax |^2 ge |Bx |^2 ge |Ax |^2 - eps |A |_^2 .] Sketch updates per row in require operations in the worst case. A slight modification of the algorithm allows for an amortized update time of operations per row. The presented algorithm stands out in that it is: deterministic, simple to implement, and elementary to prove. It also experimentally produces more accurate sketches than widely used approaches while still being computationally competitive.',
	 'authors': u'Edo Liberty,',
	 'category': u'Computer Science ',
	 'date': '2012-6-4',
	 'pdflink': u'http://arxiv.org/pdf/1206.0594',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nSimple and Deterministic Matrix Sketching',
	 'urllink': u'http://arxiv.org/abs/1206.0594'}
2015-03-24 00:00:31+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.3467> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:00:31+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.3467>
	{'abstract': u'Suppose that two senders each obtain one share of the output of a classical, bivariate, correlated information source. They would like to transmit the correlated source to a receiver using a quantum multiple access channel. In prior work, Cover, El Gamal, and Salehi provided a combined source-channel coding strategy for a classical multiple access channel which outperforms the simpler "separation" strategy where separate codebooks are used for the source coding and the channel coding tasks. In the present paper, we prove that a coding strategy similar to the Cover-El Gamal-Salehi strategy and a corresponding quantum simultaneous decoder allow for the reliable transmission of a source over a quantum multiple access channel, as long as a set of information inequalities involving the Holevo quantity hold.',
	 'authors': u'Mark M. Wilde, Ivan Savov,',
	 'category': u'Computer Science ',
	 'date': '2012-2-15',
	 'pdflink': u'http://arxiv.org/pdf/1202.3467',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nJoint source-channel coding for a quantum multiple access channel',
	 'urllink': u'http://arxiv.org/abs/1202.3467'}
2015-03-24 00:00:46+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.4756> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:00:46+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.4756>
	{'abstract': u'In this work we consider the problem of reconstruction of a signal from the magnitude of its Fourier transform, also known as phase retrieval. The problem arises in many areas of astronomy, crystallography, optics, and coherent diffraction imaging (CDI). Our main goal is to develop an efficient reconstruction method based on continuous optimization techniques. Unlike current reconstruction methods, which are based on alternating projections, our approach leads to a much faster and more robust method. However, all previous attempts to employ continuous optimization methods, such as Newton-type algorithms, to the phase retrieval problem failed. In this work we provide an explanation for this failure, and based on this explanation we devise a sufficient condition that allows development of new reconstruction methods---approximately known Fourier phase. We demonstrate that a rough (up to radians) Fourier phase estimate practically guarantees successful reconstruction by any reasonable method. We also present a new reconstruction method whose reconstruction time is orders of magnitude faster than that of the current method-of-choice in phase retrieval---Hybrid Input-Output (HIO). Moreover, our method is capable of successful reconstruction even in the situations where HIO is known to fail. We also extended our method to other applications: Fourier domain holography, and interferometry. Additionally we developed a new sparsity-based method for sub-wavelength CDI. Using this method we demonstrated experimental resolution exceeding several times the physical limit imposed by the diffraction light properties (so called diffraction limit).',
	 'authors': u'Eliyahu Osherovich,',
	 'category': u'Computer Science ',
	 'date': '2012-3-11',
	 'pdflink': u'http://arxiv.org/pdf/1203.4756',
	 'subjects': u'Optics (physics.optics)',
	 'title': u'\nNumerical methods for phase retrieval',
	 'urllink': u'http://arxiv.org/abs/1203.4756'}
2015-03-24 00:01:02+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.6389> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:01:02+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.6389>
	{'abstract': u'The network approach became a widely used tool to understand the behaviour of complex systems in the last decade. We start from a short description of structural rigidity theory. A detailed account on the combinatorial rigidity analysis of protein structures, as well as local flexibility measures of proteins and their applications in explaining allostery and thermostability is given. We also briefly discuss the network aspects of cytoskeletal tensegrity. Finally, we show the importance of the balance between functional flexibility and rigidity in protein-protein interaction, metabolic, gene regulatory and neuronal networks. Our summary raises the possibility that the concepts of flexibility and rigidity can be generalized to all networks.',
	 'authors': u'Merse E. Gaspar, Peter Csermely,',
	 'category': u'Computer Science ',
	 'date': '2012-4-28',
	 'pdflink': u'http://arxiv.org/pdf/1204.6389',
	 'subjects': u'Biological Physics (physics.bio-ph)',
	 'title': u'\nRigidity and flexibility of biological networks',
	 'urllink': u'http://arxiv.org/abs/1204.6389'}
2015-03-24 00:01:17+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0580> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:01:17+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0580>
	{'abstract': u'The paper describes a novel technique that allows to reduce by half the number of delta values that were required to be computed with complexity O(N) in most of the heuristics for the quadratic assignment problem. Using the correlation between the old and new delta values, obtained in this work, a new formula of complexity O(1) is proposed. Found result leads up to 25% performance increase in such well-known algorithms as Robust Tabu Search and others based on it.',
	 'authors': u'Sergey Podolsky, Yuri Zorin,',
	 'category': u'Computer Science ',
	 'date': '2012-6-4',
	 'pdflink': u'http://arxiv.org/pdf/1206.0580',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nO(1) Delta Component Computation Technique for the Quadratic Assignment  Problem',
	 'urllink': u'http://arxiv.org/abs/1206.0580'}
2015-03-24 00:01:20+0000 [xxu46_4] INFO: Crawled 528 pages (at 5 pages/min), scraped 522 items (at 5 items/min)
2015-03-24 00:01:33+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.3455> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:01:33+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.3455>
	{'abstract': u'Let be a set of points in general position in the plane. A subset of is called an emph if there exists a convex set such that . In this paper we define the emph of as the graph whose vertex consists of all islands of of cardinality , two of which are adjacent if their intersection consists of exactly elements. We show that for large enough values of , this graph is connected, and give upper and lower bounds on its diameter.',
	 'authors': u'Crevel Bautista-Santiago, Javier Cano, Ruy Fabila-Monroy, David Flores-Pe\xf1aloza, Hern\xe1n Gonz\xe1lez-Aguilar, Dolores Lara, Eliseo Sarmiento, Jorge Urrutia,',
	 'category': u'Computer Science ',
	 'date': '2012-2-15',
	 'pdflink': u'http://arxiv.org/pdf/1202.3455',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nOn the Connectedness and Diameter of a Geometric Johnson Graph',
	 'urllink': u'http://arxiv.org/abs/1202.3455'}
2015-03-24 00:01:49+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.4740> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:01:49+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.4740>
	{'abstract': u'Forty years ago, Wiesner pointed out that quantum mechanics raises the striking possibility of money that cannot be counterfeited according to the laws of physics. We propose the first quantum money scheme that is (1) public-key, meaning that anyone can verify a banknote as genuine, not only the bank that printed it, and (2) cryptographically secure, under a "classical" hardness assumption that has nothing to do with quantum money. Our scheme is based on hidden subspaces, encoded as the zero-sets of random multivariate polynomials. A main technical advance is to show that the "black-box" version of our scheme, where the polynomials are replaced by classical oracles, is unconditionally secure. Previously, such a result had only been known relative to a quantum oracle (and even there, the proof was never published). Even in Wiesner\'s original setting -- quantum money that can only be verified by the bank -- we are able to use our techniques to patch a major security hole in Wiesner\'s scheme. We give the first private-key quantum money scheme that allows unlimited verifications and that remains unconditionally secure, even if the counterfeiter can interact adaptively with the bank. Our money scheme is simpler than previous public-key quantum money schemes, including a knot-based scheme of Farhi et al. The verifier needs to perform only two tests, one in the standard basis and one in the Hadamard basis -- matching the original intuition for quantum money, based on the existence of complementary observables. Our security proofs use a new variant of Ambainis\'s quantum adversary method, and several other tools that might be of independent interest.',
	 'authors': u'Scott Aaronson, Paul Christiano,',
	 'category': u'Computer Science ',
	 'date': '2012-3-21',
	 'pdflink': u'http://arxiv.org/pdf/1203.4740',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nQuantum Money from Hidden Subspaces',
	 'urllink': u'http://arxiv.org/abs/1203.4740'}
2015-03-24 00:02:02+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.6376> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:02:02+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.6376>
	{'abstract': u'Topological landscape is introduced for networks with functions defined on the nodes. By extending the notion of gradient flows to the network setting, critical nodes of different indices are defined. This leads to a concise and hierarchical representation of the network. Persistent homology from computational topology is used to design efficient algorithms for performing such analysis. Applications to some examples in social and biological networks are demonstrated, which show that critical nodes carry important information about structures and dynamics of such networks.',
	 'authors': u'E. Weinan, Jianfeng Lu, Yuan Yao,',
	 'category': u'Computer Science ',
	 'date': '2012-4-28',
	 'pdflink': u'http://arxiv.org/pdf/1204.6376',
	 'subjects': u'Methodology (stat.ME)',
	 'title': u'\nThe Landscape of Complex Networks',
	 'urllink': u'http://arxiv.org/abs/1204.6376'}
2015-03-24 00:02:16+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0570> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:02:16+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0570>
	{'abstract': u'The eXtensible Markup Language (XML) can be used as data exchange format in different domains. It allows different parties to exchange data by providing common understanding of the basic concepts in the domain. XML covers the syntactic level, but lacks support for reasoning. Ontology can provide a semantic representation of domain knowledge which supports efficient reasoning and expressive power. One of the most popular ontology languages is the Web Ontology Language (OWL). It can represent domain knowledge using classes, properties, axioms and instances for the use in a distributed environment such as the World Wide Web. This paper presents a new method for automatic generation of OWL ontology from XML data sources.',
	 'authors': u'Nora Yahia, Sahar A. Mokhtar, AbdelWahab Ahmed,',
	 'category': u'Computer Science ',
	 'date': '2012-6-4',
	 'pdflink': u'http://arxiv.org/pdf/1206.0570',
	 'subjects': u'Digital Libraries (cs.DL)',
	 'title': u'\nAutomatic Generation of OWL Ontology from XML Data Source',
	 'urllink': u'http://arxiv.org/abs/1206.0570'}
2015-03-24 00:02:20+0000 [xxu46_4] INFO: Crawled 532 pages (at 4 pages/min), scraped 526 items (at 4 items/min)
2015-03-24 00:02:30+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.3385> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:02:30+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.3385>
	{'abstract': u'Let P be a set of n &gt; 2 points in general position in the plane and let G be a geometric graph with vertex set P. If the number of empty triangles uvw in P for which the subgraph of G induced by is not connected is at most n-3, then G contains a non-self intersecting spanning tree.',
	 'authors': u'Eduardo Rivera-Campo, Virginia Urrutia-Galicia,',
	 'category': u'Computer Science ',
	 'date': '2012-2-15',
	 'pdflink': u'http://arxiv.org/pdf/1202.3385',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nA sufficient condition for the existence of plane spanning trees on  geometric graphs',
	 'urllink': u'http://arxiv.org/abs/1202.3385'}
2015-03-24 00:02:44+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.4705> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:02:44+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.4705>
	{'abstract': u'An out-(in-)branching B_s^+ (B_s^-) rooted at s in a digraph D is a connected spanning subdigraph of D in which every vertex x != s has precisely one arc entering (leaving) it and s has no arcs entering (leaving) it. We settle the complexity of the following two problems: 1) Given a 2-regular digraph , decide if it contains two arc-disjoint branchings B^+_u, B^-_v. 2) Given a 2-regular digraph D, decide if it contains an out-branching B^+_u such that D remains connected after removing the arcs of B^+_u. Both problems are NP-complete for general digraphs. We prove that the first problem remains NP-complete for 2-regular digraphs, whereas the second problem turns out to be polynomial when we do not prescribe the root in advance. We also prove that, for 2-regular digraphs, the latter problem is in fact equivalent to deciding if contains two arc-disjoint out-branchings. We generalize this result to k-regular digraphs where we want to find a number of pairwise arc-disjoint spanning trees and out-branchings such that there are k in total, again without prescribing any roots.',
	 'authors': u'J\xf8rgen Bang-Jensen, Sven Simonsen,',
	 'category': u'Computer Science ',
	 'date': '2012-3-21',
	 'pdflink': u'http://arxiv.org/pdf/1203.4705',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nArc-Disjoint Paths and Trees in 2-Regular Digraphs',
	 'urllink': u'http://arxiv.org/abs/1203.4705'}
2015-03-24 00:03:00+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.6181> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:03:00+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.6181>
	{'abstract': u"Given two subsets A and B of nodes in a directed graph, the conduciveness of the graph from A to B is the ratio representing how many of the edges outgoing from nodes in A are incoming to nodes in B. When the graph's nodes stand for the possible solutions to certain problems of combinatorial optimization, choosing its edges appropriately has been shown to lead to conduciveness properties that provide useful insight into the performance of algorithms to solve those problems. Here we study the conduciveness of CA-rule graphs, that is, graphs whose node set is the set of all CA rules given a cell's number of possible states and neighborhood size. We consider several different edge sets interconnecting these nodes, both deterministic and random ones, and derive analytical expressions for the resulting graph's conduciveness toward rules having a fixed number of non-quiescent entries. We demonstrate that one of the random edge sets, characterized by allowing nodes to be sparsely interconnected across any Hamming distance between the corresponding rules, has the potential of providing reasonable conduciveness toward the desired rules. We conjecture that this may lie at the bottom of the best strategies known to date for discovering complex rules to solve specific problems, all of an evolutionary nature.",
	 'authors': u'Valmir C. Barbosa,',
	 'category': u'Computer Science ',
	 'date': '2012-4-27',
	 'pdflink': u'http://arxiv.org/pdf/1204.6181',
	 'subjects': u'Cellular Automata and Lattice Gases (nlin.CG)',
	 'title': u'\nThe conduciveness of CA-rule graphs',
	 'urllink': u'http://arxiv.org/abs/1204.6181'}
2015-03-24 00:03:09+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0556> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:03:09+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0556>
	{'abstract': u'In this paper we study the problem of improving human hand pose sensing device performance by exploiting the knowledge on how humans most frequently use their hands in grasping tasks. In a companion paper we studied the problem of maximizing the reconstruction accuracy of the hand pose from partial and noisy data provided by any given pose sensing device (a sensorized "glove") taking into account statistical a priori information. In this paper we consider the dual problem of how to design pose sensing devices, i.e. how and where to place sensors on a glove, to get maximum information about the actual hand posture. We study the continuous case, whereas individual sensing elements in the glove measure a linear combination of joint angles, the discrete case, whereas each measure corresponds to a single joint angle, and the most general hybrid case, whereas both continuous and discrete sensing elements are available. The objective is to provide, for given a priori information and fixed number of measurements, the optimal design minimizing in average the reconstruction error. Solutions relying on the geometrical synergy definition as well as gradient flow-based techniques are provided. Simulations of reconstruction performance show the effectiveness of the proposed optimal design.',
	 'authors': u'Matteo Bianchi, Paolo Salaris, Antonio Bicchi,',
	 'category': u'Computer Science ',
	 'date': '2012-6-4',
	 'pdflink': u'http://arxiv.org/pdf/1206.0556',
	 'subjects': u'Robotics (cs.RO)',
	 'title': u'\nSynergy-Based Hand Pose Sensing: Optimal Glove Design',
	 'urllink': u'http://arxiv.org/abs/1206.0556'}
2015-03-24 00:03:20+0000 [xxu46_4] INFO: Crawled 536 pages (at 4 pages/min), scraped 530 items (at 4 items/min)
2015-03-24 00:03:24+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.3338> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:03:24+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.3338>
	{'abstract': u'We generalize a construction of non-binary quantum LDPC codes over due to cite and apply it in particular to toric codes. We obtain in this way not only codes with better rates than toric codes but also improve dramatically the performance of standard iterative decoding. Moreover, the new codes obtained in this fashion inherit the distance properties of the underlying toric codes and have therefore a minimum distance which grows as the square root of the length of the code for fixed .',
	 'authors': u'Iryna Andriyanova, Denise Maurice, Jean-Pierre Tillich,',
	 'category': u'Computer Science ',
	 'date': '2012-2-15',
	 'pdflink': u'http://arxiv.org/pdf/1202.3338',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nNew constructions of CSS codes obtained by moving to higher alphabets',
	 'urllink': u'http://arxiv.org/abs/1202.3338'}
2015-03-24 00:03:40+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.4600> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:03:40+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.4600>
	{'abstract': u'We show that points and two-dimensional algebraic surfaces in can have at most incidences, provided that the algebraic surfaces behave like pseudoflats with degrees of freedom, and that . As a special case, we obtain the Szemer \'edi-Trotter theorem for 2--planes in , provided and the planes intersect transversely. As a further special case, we obtain the Szemer \'edi-Trotter theorem for complex lines in with no restrictions on and (this theorem was originally proved by T \'oth using a different method). As a second special case, we obtain the Szemer \'edi-Trotter theorem for complex unit circles in , which has applications to the complex unit distance problem. We obtain our results by combining several tools, including a "two-level" analogue of the discrete polynomial partitioning theorem and the crossing lemma.',
	 'authors': u'Joshua Zahl,',
	 'category': u'Computer Science ',
	 'date': '2012-3-20',
	 'pdflink': u'http://arxiv.org/pdf/1203.4600',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nA Szemeredi-Trotter type theorem in $\\mathbb{R}^4$',
	 'urllink': u'http://arxiv.org/abs/1203.4600'}
2015-03-24 00:03:53+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.6174> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:03:53+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.6174>
	{'abstract': u'The resilience of Supervisory Control and Data Acquisition (SCADA) systems for electric power networks for certain cyber-attacks is considered. We analyze the vulnerability of the measurement system to false data attack on communicated measurements. The vulnerability analysis problem is shown to be NP-hard, meaning that unless there is no polynomial time algorithm to analyze the vulnerability of the system. Nevertheless, we identify situations, such as the full measurement case, where it can be solved efficiently. In such cases, we show indeed that the problem can be cast as a generalization of the minimum cut problem involving costly nodes. We further show that it can be reformulated as a standard minimum cut problem (without costly nodes) on a modified graph of proportional size. An important consequence of this result is that our approach provides the first exact efficient algorithm for the vulnerability analysis problem under the full measurement assumption. Furthermore, our approach also provides an efficient heuristic algorithm for the general NP-hard problem. Our results are illustrated by numerical studies on benchmark systems including the IEEE 118-bus system.',
	 'authors': u'Julien M. Hendrickx, Karl Henrik Johansson, Raphael M. Jungers, Henrik Sandberg, Kin Cheong Sou,',
	 'category': u'Computer Science ',
	 'date': '2012-4-27',
	 'pdflink': u'http://arxiv.org/pdf/1204.6174',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nEfficient Computations of a Security Index for False Data Attacks in  Power Networks',
	 'urllink': u'http://arxiv.org/abs/1204.6174'}
2015-03-24 00:04:01+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0555> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:04:01+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0555>
	{'abstract': u'Low-cost sensing gloves for reconstruction posture provide measurements which are limited under several regards. They are generated through an imperfectly known model, are subject to noise, and may be less than the number of Degrees of Freedom (DoFs) of the hand. Under these conditions, direct reconstruction of the hand posture is an ill-posed problem, and performance can be very poor. This paper examines the problem of estimating the posture of a human hand using(low-cost) sensing gloves, and how to improve their performance by exploiting the knowledge on how humans most frequently use their hands. To increase the accuracy of pose reconstruction without modifying the glove hardware - hence basically at no extra cost - we propose to collect, organize, and exploit information on the probabilistic distribution of human hand poses in common tasks. We discuss how a database of such an a priori information can be built, represented in a hierarchy of correlation patterns or postural synergies, and fused with glove data in a consistent way, so as to provide a good hand pose reconstruction in spite of insufficient and inaccurate sensing data. Simulations and experiments on a low-cost glove are reported which demonstrate the effectiveness of the proposed techniques.',
	 'authors': u'Matteo Bianchi, Paolo Salaris, Antonio Bicchi,',
	 'category': u'Computer Science ',
	 'date': '2012-6-4',
	 'pdflink': u'http://arxiv.org/pdf/1206.0555',
	 'subjects': u'Robotics (cs.RO)',
	 'title': u'\nSynergy-based Hand Pose Sensing: Reconstruction Enhancement',
	 'urllink': u'http://arxiv.org/abs/1206.0555'}
2015-03-24 00:04:14+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.3294> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:04:14+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.3294>
	{'abstract': u'We provide a constructive characterisation of circuits in the simple (2,2)-sparsity matroid. A circuit is a simple graph G=(V,E) with |E|=2|V|-1 and the number of edges induced by any is at most 2|X|-2. Insisting on simplicity results in the Henneberg operation being enough only when the graph is sufficiently connected. Thus we introduce 3 different join operations to complete the characterisation. Extensions are discussed to when the sparsity matroid is connected and this is applied to the theory of frameworks on surfaces to provide a conjectured characterisation of when frameworks on an infinite circular cylinder are generically globally rigid.',
	 'authors': u'Anthony Nixon,',
	 'category': u'Computer Science ',
	 'date': '2012-2-15',
	 'pdflink': u'http://arxiv.org/pdf/1202.3294',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nA Constructive Characterisation of Circuits in the Simple (2,2)-sparsity  Matroid',
	 'urllink': u'http://arxiv.org/abs/1202.3294'}
2015-03-24 00:04:20+0000 [xxu46_4] INFO: Crawled 541 pages (at 5 pages/min), scraped 535 items (at 5 items/min)
2015-03-24 00:04:29+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.4544> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:04:29+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.4544>
	{'abstract': u'A theory for constructing quantum error correcting codes from Toric surfaces by the Calderbank-Shor-Steane method is presented. In particular we study the method on toric Hirzebruch surfaces. The results are obtained by constructing a dualizing differential form for the toric surface and by using the cohomology and the intersection theory of toric varieties. In earlier work the author developed methods to construct linear error correcting codes from toric varieties and derive the code parameters using the cohomology and the intersection theory on toric varieties. This method is generalized in section to construct linear codes suitable for constructing quantum codes by the Calderbank-Shor-Steane method. Essential for the theory is the existence and the application of a dualizing differential form on the toric surface. A.R. Calderbank, P.W. Shor and A.M. Steane produced stabilizer codes from linear codes containing their dual codes. These two constructions are merged to obtain results for toric surfaces. Similar merging has been done for algebraic curves with different methods by A. Ashikhmin, S. Litsyn and M.A. Tsfasman.',
	 'authors': u'Johan P. Hansen,',
	 'category': u'Computer Science ',
	 'date': '2012-3-20',
	 'pdflink': u'http://arxiv.org/pdf/1203.4544',
	 'subjects': u'Algebraic Geometry (math.AG)',
	 'title': u'\nQuantum Codes from Toric Surfaces',
	 'urllink': u'http://arxiv.org/abs/1203.4544'}
2015-03-24 00:04:42+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.6123> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:04:42+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.6123>
	{'abstract': u'Natural images are typically a composition of cartoon and texture structures. A medical image might, for instance, show a mixture of gray matter and the skull cap. One common task is to separate such an image into two single images, one containing the cartoon part and the other containing the texture part. Recently, a powerful class of algorithms using sparse approximation and minimization has been introduced to resolve this problem, and numerous inspiring empirical results have already been obtained. In this paper we provide the first thorough theoretical study of the separation of a combination of cartoon and texture structures in a model situation using this class of algorithms. The methodology we consider expands the image in a combined dictionary consisting of a curvelet tight frame and a Gabor tight frame and minimizes the norm on the analysis side. Sparse approximation properties then force the cartoon components into the curvelet coefficients and the texture components into the Gabor coefficients, thereby separating the image. Utilizing the fact that the coefficients are clustered geometrically, we prove that at sufficiently fine scales arbitrarily precise separation is possible. Main ingredients of our analysis are the novel notion of cluster coherence and clustered/geometric sparsity. Our analysis also provides a deep understanding on when separation is still possible.',
	 'authors': u'Gitta Kutyniok,',
	 'category': u'Computer Science ',
	 'date': '2012-4-27',
	 'pdflink': u'http://arxiv.org/pdf/1204.6123',
	 'subjects': u'Functional Analysis (math.FA)',
	 'title': u'\nClustered Sparsity and Separation of Cartoon and Texture',
	 'urllink': u'http://arxiv.org/abs/1204.6123'}
2015-03-24 00:04:54+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0549> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:04:54+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0549>
	{'abstract': u'In this paper, we address the problem of controlling a system over an unreliable connection that is affected by time-varying delays and randomly occurring packet losses. A novel sequence-based approach is proposed that extends a given controller designed without consideration of the network-induced disturbances. Its key idea is to model the unknown future control inputs by random variables, the so-called virtual control inputs, which are characterized by discrete probability density functions. Subject to this probabilistic description, the actual sequence of future control inputs is determined and transmitted to the actuator. The high performance of the proposed approach is demonstrated by means of Monte Carlo simulation runs with an inverted pendulum on a cart and by a detailed comparison to standard NCS approaches.',
	 'authors': u'Achim Hekler, J\xf6rg Fischer, Uwe D. Hanebeck,',
	 'category': u'Computer Science ',
	 'date': '2012-6-4',
	 'pdflink': u'http://arxiv.org/pdf/1206.0549',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nSequence-Based Control for Networked Control Systems Based on Virtual  Control Inputs',
	 'urllink': u'http://arxiv.org/abs/1206.0549'}
2015-03-24 00:05:10+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.3192> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:05:10+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.3192>
	{'abstract': u'At present, the power grid has tight control over its dispatchable generation capacity but a very coarse control on the demand. Energy consumers are shielded from making price-aware decisions, which degrades the efficiency of the market. This state of affairs tends to favor fossil fuel generation over renewable sources. Because of the technological difficulties of storing electric energy, the quest for mechanisms that would make the demand for electricity controllable on a day-to-day basis is gaining prominence. The goal of this paper is to provide one such mechanisms, which we call Digital Direct Load Scheduling (DDLS). DDLS is a direct load control mechanism in which we unbundle individual requests for energy and digitize them so that they can be automatically scheduled in a cellular architecture. Specifically, rather than storing energy or interrupting the job of appliances, we choose to hold requests for energy in queues and optimize the service time of individual appliances belonging to a broad class which we refer to as "deferrable loads". The function of each neighborhood scheduler is to optimize the time at which these appliances start to function. This process is intended to shape the aggregate load profile of the neighborhood so as to optimize an objective function which incorporates the spot price of energy, and also allows distributed energy resources to supply part of the generation dynamically.',
	 'authors': u'Mahnoosh Alizadeh, Anna Scaglione, Robert J. Thomas,',
	 'category': u'Computer Science ',
	 'date': '2012-2-15',
	 'pdflink': u'http://arxiv.org/pdf/1202.3192',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nFrom Packet to Power Switching: Digital Direct Load Scheduling',
	 'urllink': u'http://arxiv.org/abs/1202.3192'}
2015-03-24 00:05:20+0000 [xxu46_4] INFO: Crawled 545 pages (at 4 pages/min), scraped 539 items (at 4 items/min)
2015-03-24 00:05:24+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.4483> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:05:24+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.4483>
	{'abstract': u'Let f(k) denote the maximum such that every simple undirected graph containing two vertices s,t and k edge-disjoint s-t paths, also contains two vertices u,v and f(k) independent u-v paths. Here, a set of paths is independent if none of them contains an interior vertex of another. We prove that f(k)=k if k&lt;3, and f(k)=3 otherwise.',
	 'authors': u'Serge Gaspers,',
	 'category': u'Computer Science ',
	 'date': '2012-3-20',
	 'pdflink': u'http://arxiv.org/pdf/1203.4483',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nFrom edge-disjoint paths to independent paths',
	 'urllink': u'http://arxiv.org/abs/1203.4483'}
2015-03-24 00:05:35+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.6120> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:05:35+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.6120>
	{'abstract': u'Modern data is customarily of multimodal nature, and analysis tasks typically require separation into the single components. Although a highly ill-posed problem, the morphological difference of these components sometimes allow a very precise separation such as, for instance, in neurobiological imaging a separation into spines (pointlike structures) and dendrites (curvilinear structures). Recently, applied harmonic analysis introduced powerful methodologies to achieve this task, exploiting specifically designed representation systems in which the components are sparsely representable, combined with either performing minimization or thresholding on the combined dictionary. In this paper we provide a thorough theoretical study of the separation of a distributional model situation of point- and curvilinear singularities exploiting a surprisingly simple single-pass alternating thresholding method applied to the two complementary frames: wavelets and curvelets. Utilizing the fact that the coefficients are clustered geometrically, thereby exhibiting clustered/geometric sparsity in the chosen frames, we prove that at sufficiently fine scales arbitrarily precise separation is possible. Even more surprising, it turns out that the thresholding index sets converge to the wavefront sets of the point- and curvilinear singularities in phase space and that those wavefront sets are perfectly separated by the thresholding procedure. Main ingredients of our analysis are the novel notion of cluster coherence and clustered/geometric sparsity as well as a microlocal analysis viewpoint.',
	 'authors': u'Gitta Kutyniok,',
	 'category': u'Computer Science ',
	 'date': '2012-4-27',
	 'pdflink': u'http://arxiv.org/pdf/1204.6120',
	 'subjects': u'Functional Analysis (math.FA)',
	 'title': u'\nGeometric Separation by Single-Pass Alternating Thresholding',
	 'urllink': u'http://arxiv.org/abs/1204.6120'}
2015-03-24 00:05:52+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0514> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:05:52+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0514>
	{'abstract': u'We discuss the problem of embedding graphs in the plane with restrictions on the vertex mapping. In particular, we introduce a technique for drawing planar graphs with a fixed vertex mapping that bounds the number of times edges bend. An immediate consequence of this technique is that any planar graph can be drawn with a fixed vertex mapping so that edges map to piecewise linear curves with at most bends each. By considering uniformly random planar graphs, we show that bends per edge is sufficient on average. To further utilize our technique, we consider simultaneous embeddings of uniformly random planar graphs with vertices mapping to a fixed, common point set. We explain how to achieve such a drawing so that edges map to piecewise linear curves with bends each, which holds with overwhelming probability. This result improves upon the previously best known result of O(n) bends per edge for the case where . Moreover, we give a lower bound on the number of bends that matches our upper bound, proving our results are optimal.',
	 'authors': u'Taylor Gordon,',
	 'category': u'Computer Science ',
	 'date': '2012-6-4',
	 'pdflink': u'http://arxiv.org/pdf/1206.0514',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nSimultaneous Embeddings with Vertices Mapping to Pre-Specified Points',
	 'urllink': u'http://arxiv.org/abs/1206.0514'}
2015-03-24 00:06:08+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.4422> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:06:08+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.4422>
	{'abstract': u'We address the problems of multi-domain and single-domain regression based on distinct and unpaired labeled training sets for each of the domains and a large unlabeled training set from all domains. We formulate these problems as a Bayesian estimation with partial knowledge of statistical relations. We propose a worst-case design strategy and study the resulting estimators. Our analysis explicitly accounts for the cardinality of the labeled sets and includes the special cases in which one of the labeled sets is very large or, in the other extreme, completely missing. We demonstrate our estimators in the context of removing expressions from facial images and in the context of audio-visual word recognition, and provide comparisons to several recently proposed multi-modal learning algorithms.',
	 'authors': u'Tomer Michaeli, Yonina C. Eldar, Guillermo Sapiro,',
	 'category': u'Computer Science ',
	 'date': '2012-3-20',
	 'pdflink': u'http://arxiv.org/pdf/1203.4422',
	 'subjects': u'Machine Learning (stat.ML)',
	 'title': u'\nSemi-Supervised Single- and Multi-Domain Regression with Multi-Domain  Training',
	 'urllink': u'http://arxiv.org/abs/1203.4422'}
2015-03-24 00:06:20+0000 [xxu46_4] INFO: Crawled 549 pages (at 4 pages/min), scraped 543 items (at 4 items/min)
2015-03-24 00:06:25+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.5958> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:06:25+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.5958>
	{'abstract': u'Many emerging applications involve sparse signals, and their processing is a subject of active research. We desire a large class of sensing matrices which allow the user to discern important properties of the measured sparse signal. Of particular interest are matrices with the restricted isometry property (RIP). RIP matrices are known to enable efficient and stable reconstruction of sufficiently sparse signals, but the deterministic construction of such matrices has proven very difficult. In this thesis, we discuss this matrix design problem in the context of a growing field of study known as frame theory. In the first two chapters, we build large families of equiangular tight frames and full spark frames, and we discuss their relationship to RIP matrices as well as their utility in other aspects of sparse signal processing. In Chapter 3, we pave the road to deterministic RIP matrices, evaluating various techniques to demonstrate RIP, and making interesting connections with graph theory and number theory. We conclude in Chapter 4 with a coherence-based alternative to RIP, which provides near-optimal probabilistic guarantees for various aspects of sparse signal processing while at the same time admitting a whole host of deterministic constructions.',
	 'authors': u'Dustin G. Mixon,',
	 'category': u'Computer Science ',
	 'date': '2012-4-26',
	 'pdflink': u'http://arxiv.org/pdf/1204.5958',
	 'subjects': u'Functional Analysis (math.FA)',
	 'title': u'\nSparse Signal Processing with Frame Theory',
	 'urllink': u'http://arxiv.org/abs/1204.5958'}
2015-03-24 00:06:40+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0489> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:06:40+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0489>
	{'abstract': u'The sumset and inverse sumset theories of Freiman, Pl "nnecke and Ruzsa, give bounds connecting the cardinality of the sumset of two discrete sets , to the cardinalities (or the finer structure) of the original sets . For example, the sum-difference bound of Ruzsa states that, , where the difference set . Interpreting the differential entropy of a continuous random variable as (the logarithm of) the size of the effective support of , the main contribution of this paper is a series of natural information-theoretic analogs for these results. For example, the Ruzsa sum-difference bound becomes the new inequality, , for any pair of independent continuous random variables and . Our results include differential-entropy versions of Ruzsa\'s triangle inequality, the Pl "nnecke-Ruzsa inequality, and the Balog-Szemer \'di-Gowers lemma. Also we give a differential entropy version of the Freiman-Green-Ruzsa inverse-sumset theorem, which can be seen as a quantitative converse to the entropy power inequality. Versions of most of these results for the discrete entropy were recently proved by Tao, relying heavily on a strong, functional form of the submodularity property of . Since differential entropy is functionally submodular, in the continuous case many of the corresponding discrete proofs fail, in many cases requiring substantially new proof strategies. We find that the basic property that naturally replaces the discrete functional submodularity, is the data processing property of mutual information.',
	 'authors': u'Ioannis Kontoyiannis, Mokshay Madiman,',
	 'category': u'Computer Science ',
	 'date': '2012-6-3',
	 'pdflink': u'http://arxiv.org/pdf/1206.0489',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nSumset and Inverse Sumset Inequalities for Differential Entropy and  Mutual Information',
	 'urllink': u'http://arxiv.org/abs/1206.0489'}
2015-03-24 00:06:47+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.3184> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:06:47+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.3184>
	{'abstract': u'This work examines various statistical distributions in connection with random Vandermonde matrices and their extension to --dimensional phase distributions. Upper and lower bound asymptotics for the maximum singular value are found to be and respectively where is the dimension of the matrix, generalizing the results in cite. We further study the behavior of the minimum singular value of these random matrices. In particular, we prove that the minimum singular value is at most with high probability where is a constant independent on . Furthermore, the value of the constant is determined explicitly. The main result is obtained in two different ways. One approach uses techniques from stochastic processes and in particular, a construction related to the Brownian bridge. The other one is a more direct analytical approach involving combinatorics and complex analysis. As a consequence, we obtain a lower bound for the maximum absolute value of a random complex polynomial on the unit circle, which may be of independent mathematical interest. Lastly, for each sequence of positive integers we present a generalized version of the previously discussed matrices. The classical random Vandermonde matrix corresponds to the sequence . We find a combinatorial formula for their moments and we show that the limit eigenvalue distribution converges to a probability measure supported on . Finally, we show that for the sequence the limit eigenvalue distribution is the famous Marchenko--Pastur distribution.',
	 'authors': u'Gabriel H. Tucci, Philip A. Whiting,',
	 'category': u'Computer Science ',
	 'date': '2012-2-15',
	 'pdflink': u'http://arxiv.org/pdf/1202.3184',
	 'subjects': u'Probability (math.PR)',
	 'title': u'\nAsymptotic Behavior of the Maximum and Minimum Singular Value of Random  Vandermonde Matrices',
	 'urllink': u'http://arxiv.org/abs/1202.3184'}
2015-03-24 00:06:57+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.4280> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:06:57+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.4280>
	{'abstract': u'We analyze multi-bounce propagation of light in an unknown hidden volume and demonstrate that the reflected light contains sufficient information to recover the 3D structure of the hidden scene. We formulate the forward and inverse theory of secondary and tertiary scattering reflection using ideas from energy front propagation and tomography. We show that using careful choice of approximations, such as Fresnel approximation, greatly simplifies this problem and the inversion can be achieved via a backpropagation process. We provide a theoretical analysis of the invertibility, uniqueness and choices of space-time-angle dimensions using synthetic examples. We show that a 2D streak camera can be used to discover and reconstruct hidden geometry. Using a 1D high speed time of flight camera, we show that our method can be used recover 3D shapes of objects "around the corner".',
	 'authors': u'Otkrist Gupta, Andreas Velten, Thomas Willwacher, Ashok Veeraraghavan, Ramesh Raskar,',
	 'category': u'Computer Science ',
	 'date': '2012-3-19',
	 'pdflink': u'http://arxiv.org/pdf/1203.4280',
	 'subjects': u'Optics (physics.optics)',
	 'title': u'\nReconstruction of hidden 3D shapes using diffuse reflections',
	 'urllink': u'http://arxiv.org/abs/1203.4280'}
2015-03-24 00:07:14+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.5661> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:07:14+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.5661>
	{'abstract': u'The European sovereign debt crisis has impaired many European banks. The distress on the European banks may transmit worldwide, and result in a large-scale knock-on default of financial institutions. This study presents a computer simulation model to analyze the risk of insolvency of banks and defaults in a bank credit network. Simulation experiments reproduce the knock-on default, and quantify the impact which is imposed on the number of bank defaults by heterogeneity of the bank credit network, the equity capital ratio of banks, and the capital surcharge on big banks.',
	 'authors': u'Yoshiharu Maeno, Satoshi Morinaga, Hirokazu Matsushima, Kenichi Amagai,',
	 'category': u'Computer Science ',
	 'date': '2012-4-25',
	 'pdflink': u'http://arxiv.org/pdf/1204.5661',
	 'subjects': u'Risk Management (q-fin.RM)',
	 'title': u'\nTransmission of distress in a bank credit network',
	 'urllink': u'http://arxiv.org/abs/1204.5661'}
2015-03-24 00:07:20+0000 [xxu46_4] INFO: Crawled 554 pages (at 5 pages/min), scraped 548 items (at 5 items/min)
2015-03-24 00:07:29+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0469> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:07:29+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0469>
	{'abstract': u"Group-buying ads seeking a minimum number of customers before the deal expiry are increasingly used by the daily-deal providers. Unlike the traditional web ads, the advertiser's profits for group-buying ads depends on the time to expiry and additional customers needed to satisfy the minimum group size. Since both these quantities are time-dependent, optimal bid amounts to maximize profits change with every impression. Consequently, traditional static bidding strategies are far from optimal. Instead, bid values need to be optimized in real-time to maximize expected bidder profits. This online optimization of deal profits is made possible by the advent of ad exchanges offering real-time (spot) bidding. To this end, we propose a real-time bidding strategy for group-buying deals based on the online optimization of bid values. We derive the expected bidder profit of deals as a function of the bid amounts, and dynamically vary bids to maximize profits. Further, to satisfy time constraints of the online bidding, we present methods of minimizing computation timings. Subsequently, we derive the real time ad selection, admissibility, and real time bidding of the traditional ads as the special cases of the proposed method. We evaluate the proposed bidding, selection and admission strategies on a multi-million click stream of 935 ads. The proposed real-time bidding, selection and admissibility show significant profit increases over the existing strategies. Further the experiments illustrate the robustness of the bidding and acceptable computation timings.",
	 'authors': u'Raju Balakrishnan, Rushi P Bhatt,',
	 'category': u'Computer Science ',
	 'date': '2012-6-3',
	 'pdflink': u'http://arxiv.org/pdf/1206.0469',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nReal-Time Bid Optimization for Group-Buying Ads',
	 'urllink': u'http://arxiv.org/abs/1206.0469'}
2015-03-24 00:07:39+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.3110> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:07:39+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.3110>
	{'abstract': u'We demonstrate an infinite family of pseudoline arrangements, in which an arrangement of n pseudolines has no member incident to more than 4n/9 points of intersection. This shows the "Strong Dirac" conjecture to be false for pseudolines. We also raise a number of open problems relating to possible differences between the structure of incidences between points and lines versus the structure of incidences between points and pseudolines.',
	 'authors': u'Ben D. Lund, George B. Purdy, Justin W. Smith,',
	 'category': u'Computer Science ',
	 'date': '2012-2-14',
	 'pdflink': u'http://arxiv.org/pdf/1202.3110',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nA Pseudoline Counterexample to the Strong Dirac Conjecture',
	 'urllink': u'http://arxiv.org/abs/1202.3110'}
2015-03-24 00:07:54+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.4200> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:07:54+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.4200>
	{'abstract': u'We give necessary and sufficient conditions for the existence of telescopers for rational functions of two variables in the continuous, discrete and q-discrete settings and characterize which operators can occur as telescopers. Using this latter characterization, we reprove results of Furstenberg and Zeilberger concerning diagonals of power series representing rational functions. The key concept behind these considerations is a generalization of the notion of residue in the continuous case to an analogous concept in the discrete and q-discrete cases.',
	 'authors': u'Shaoshi Chen, Michael F. Singer,',
	 'category': u'Computer Science ',
	 'date': '2012-3-19',
	 'pdflink': u'http://arxiv.org/pdf/1203.4200',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nResidues and Telescopers for Rational Functions',
	 'urllink': u'http://arxiv.org/abs/1203.4200'}
2015-03-24 00:08:08+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.5631> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:08:08+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.5631>
	{'abstract': u'We use G "del\'s Dialectica interpretation to produce a computational version of the well known proof of Ramsey\'s theorem by Erd Hs and Rado. Our proof makes use of the product of selection functions, which forms an intuitive alternative to Spector\'s bar recursion when interpreting proofs in analysis. This case study is another instance of the application of proof theoretic techniques in mathematics.',
	 'authors': u'Paulo Oliva, Thomas Powell,',
	 'category': u'Computer Science ',
	 'date': '2012-4-25',
	 'pdflink': u'http://arxiv.org/pdf/1204.5631',
	 'subjects': u'Logic (math.LO)',
	 'title': u"\nA Constructive Interpretation of Ramsey's Theorem via the Product of  Selection Functions",
	 'urllink': u'http://arxiv.org/abs/1204.5631'}
2015-03-24 00:08:20+0000 [xxu46_4] INFO: Crawled 558 pages (at 4 pages/min), scraped 552 items (at 4 items/min)
2015-03-24 00:08:22+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0447> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:08:22+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0447>
	{'abstract': u"Intelligent Transportation Systems (ITS) are gaining recognition in developing countries like India. This paper describes the various components of our prototype implementation of a Real-time Passenger Information System (RTPIS) for a public transport system like a fleet of buses. Vehicle-mounted units, bus station units and a server located at the transport company premises comprise the system. The vehicle unit reports the current position of the vehicle to a central server periodically via General Packet Radio Service (GPRS). An Estimated Time of Arrival (ETA) algorithm running on the server predicts the arrival times of buses at their stops based on real-time observations of the buses' current Global Positioning System (GPS) coordinates. This information is displayed and announced to passengers at stops using station units, which periodically fetch the required ETA from the server via GPRS. Novel features of our prototype include: (a) a route creator utility which automatically creates new routes from scratch when a bus is driven along the new route, and (b) voice tagging of stops and points of interest along any route. Besides, the prototype provides: (i) web-based applications for passengers, providing useful information like a snapshot of present bus locations on the streets, and (ii) web-based analysis tools for the transport authority, providing information useful for fleet management, like number of trips undertaken by a specific bus. The prototype has been demonstrated in a campus environment, with four-wheelers and two-wheelers emulating buses. The automatic real-time passenger information system has the potential of making the public transport system an attractive alternative for city-dwellers, thereby contributing to fewer private vehicles on the road, leading to lower congestion levels and less pollution.",
	 'authors': u'K. Ganesh, M. Thrivikraman, Joy Kuri, Haresh Dagale, G. Sudhakar, Sugata Sanyal,',
	 'category': u'Computer Science ',
	 'date': '2012-6-3',
	 'pdflink': u'http://arxiv.org/pdf/1206.0447',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nImplementation of a Real Time Passenger Information System',
	 'urllink': u'http://arxiv.org/abs/1206.0447'}
2015-03-24 00:08:36+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.3102> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:08:36+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.3102>
	{'abstract': u"We investigate into the rank-size distributions of urban agglomerations for India between 1981 to 2011. The incidence of a power law tail is prominent. A relevant question persists regarding the evolution of the power tail coefficient. We have developed a methodology to meaningfully track the power law coefficient over time, when a country experience population growth. A relevant dynamic law, Gibrat's law, is empirically tested in this connection. We argue that these empirical findings for India goes in contrast with the findings in case of China, another country with population growth but monolithic political system.",
	 'authors': u'Kausik Gangopadhyay, Banasri Basu,',
	 'category': u'Computer Science ',
	 'date': '2012-2-14',
	 'pdflink': u'http://arxiv.org/pdf/1202.3102',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u"\nEvolution of Zipf's Law for Indian Urban Agglomerations vis-\xe0-vis  Chinese Urban Agglomerations",
	 'urllink': u'http://arxiv.org/abs/1202.3102'}
2015-03-24 00:08:53+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.4184> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:08:53+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.4184>
	{'abstract': u'I present a new approach to recover the primordial density fluctuations and the cosmic web structure underlying a galaxy distribution. The method is based on sampling Gaussian fields which are compatible with a galaxy distribution and a structure formation model. This is achieved by splitting the inversion problem into two Gibbs-sampling steps: the first being a Gaussianisation step transforming a distribution of point sources at Lagrangian positions -which are not a priori given- into a linear alias-free Gaussian field. This step is based on Hamiltonian sampling with a Gaussian-Poisson model. The second step consists on a likelihood comparison in which the set of matter tracers at the initial conditions is constrained on the galaxy distribution and the assumed structure formation model. For computational reasons second order Lagrangian Perturbation Theory is used. However, the presented approach is flexible to adopt any structure formation model. A semi-analytic halo-model based galaxy mock catalog is taken to demonstrate that the recovered initial conditions are closely unbiased with respect to the actual ones from the corresponding N-body simulation down to scales of a ~ 5 Mpc/h. The cross-correlation between them shows a substantial gain of information, being at k ~ 0.3 h/Mpc more than doubled. In addition the initial conditions are extremely well Gaussian distributed and the power-spectra follow the shape of the linear power-spectrum being very close to the actual one from the simulation down to scales of k ~ 1 h/Mpc.',
	 'authors': u'Francisco-Shu Kitaura,',
	 'category': u'Computer Science ',
	 'date': '2012-3-19',
	 'pdflink': u'http://arxiv.org/pdf/1203.4184',
	 'subjects': u'Cosmology and Nongalactic Astrophysics (astro-ph.CO)',
	 'title': u'\nThe Initial Conditions of the Universe from Constrained Simulations',
	 'urllink': u'http://arxiv.org/abs/1203.4184'}
2015-03-24 00:09:06+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.5602> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:09:06+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.5602>
	{'abstract': u"The social network maintained by a focal individual, or ego, is intrinsically dynamic and typically exhibits some turnover in membership over time as personal circumstances change. However, the consequences of such changes on the distribution of an ego's network ties are not well understood. Here we use a unique 18-month data set that combines mobile phone calls and survey data to track changes in the ego networks and communication patterns of students making the transition from school to university or work. Our analysis reveals that individuals display a distinctive and robust social signature, captured by how interactions are distributed across different alters. Notably, for a given ego, these social signatures tend to persist over time, despite considerable turnover in the identity of alters in the ego network. Thus as new network members are added, some old network members are either replaced or receive fewer calls, preserving the overall distribution of calls across network members. This is likely to reflect the consequences of finite resources such as the time available for communication, the cognitive and emotional effort required to sustain close relationships, and the ability to make emotional investments.",
	 'authors': u'J. Saramaki, E. A. Leicht, E. Lopez, S. G. B. Roberts, F. Reed-Tsochas, R. I. M. Dunbar,',
	 'category': u'Computer Science ',
	 'date': '2012-4-25',
	 'pdflink': u'http://arxiv.org/pdf/1204.5602',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nThe persistence of social signatures in human communication',
	 'urllink': u'http://arxiv.org/abs/1204.5602'}
2015-03-24 00:09:19+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0430> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:09:19+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0430>
	{'abstract': u'With the advance of complex large-scale networks, it is becoming increasingly important to understand how selfish and spatially distributed individuals will share network resources without centralized coordinations. In this paper, we introduce the graphical congestion game with weighted edges (GCGWE) as a general theoretical model to study this problem. In GCGWE, we view the players as vertices in a weighted graph. The amount of negative impact (e.g. congestion) caused by two close-by players to each other is determined by the weight of the edge linking them. The GCGWE unifies and significantly generalizes several simpler models considered in the previous literature, and is well suited for modeling a wide range of networking scenarios. One good example is to use the GCGWE to model spectrum sharing in wireless networks, where we can properly define the edge weights and payoff functions to capture the rather complicated interference relationship between wireless nodes. By identifying which GCGWEs possess pure Nash equilibria and the very desirable finite improvement property, we gain insight into when spatially distributed wireless nodes will be able to self-organize into a mutually acceptable resource allocation. We also consider the efficiency of the pure Nash equilibria, and the computational complexity of finding them.',
	 'authors': u'Richard Southwell, Jianwei Huang, Biying Shou,',
	 'category': u'Computer Science ',
	 'date': '2012-6-3',
	 'pdflink': u'http://arxiv.org/pdf/1206.0430',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nCongestion Games on Weighted Directed Graphs, with Applications to  Spectrum Sharing',
	 'urllink': u'http://arxiv.org/abs/1206.0430'}
2015-03-24 00:09:20+0000 [xxu46_4] INFO: Crawled 563 pages (at 5 pages/min), scraped 557 items (at 5 items/min)
2015-03-24 00:09:37+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.3082> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:09:37+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.3082>
	{'abstract': u'We prove, that every connected graph with vertices of degree 3 and vertices of degree at least~4 has a spanning tree with at least leaves, where . Moreover, for all graphs besides three exclusions. All exclusion are regular graphs of degree~4, they are explicitly described in the paper. We present infinite series of graphs, containing only vertices of degrees~3 and~4, for which the maximal number of leaves in a spanning tree is equal for . Therefore we prove that our bound is tight.',
	 'authors': u'D.V. Karpov,',
	 'category': u'Computer Science ',
	 'date': '2012-2-14',
	 'pdflink': u'http://arxiv.org/pdf/1202.3082',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nSpanning trees with many leaves: new lower bounds in terms of number of  vertices of degree~3 and at least~4',
	 'urllink': u'http://arxiv.org/abs/1202.3082'}
2015-03-24 00:09:46+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.4156> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:09:46+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.4156>
	{'abstract': u'We study optimal investment in a financial market having a finite number of assets from a signal processing perspective. We investigate how an investor should distribute capital over these assets and when he should reallocate the distribution of the funds over these assets to maximize the cumulative wealth over any investment period. In particular, we introduce a portfolio selection algorithm that maximizes the expected cumulative wealth in i.i.d. two-asset discrete-time markets where the market levies proportional transaction costs in buying and selling stocks. We achieve this using "threshold rebalanced portfolios", where trading occurs only if the portfolio breaches certain thresholds. Under the assumption that the relative price sequences have log-normal distribution from the Black-Scholes model, we evaluate the expected wealth under proportional transaction costs and find the threshold rebalanced portfolio that achieves the maximal expected cumulative wealth over any investment period. Our derivations can be readily extended to markets having more than two stocks, where these extensions are pointed out in the paper. As predicted from our derivations, we significantly improve the achieved wealth over portfolio selection algorithms from the literature on historical data sets.',
	 'authors': u'Sait Tunc, Suleyman S. Kozat,',
	 'category': u'Computer Science ',
	 'date': '2012-3-19',
	 'pdflink': u'http://arxiv.org/pdf/1203.4156',
	 'subjects': u'Portfolio Management (q-fin.PM)',
	 'title': u'\nOptimal Investment Under Transaction Costs: A Threshold Rebalanced  Portfolio Approach',
	 'urllink': u'http://arxiv.org/abs/1203.4156'}
2015-03-24 00:09:58+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.5563> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:09:58+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.5563>
	{'abstract': u'In this study, we combine bibliometric techniques with a machine learning algorithm, the sequential Information Bottleneck, to assess the interdisciplinarity of research produced by the University of Hawaii NASA Astrobiology Institute (UHNAI). In particular, we cluster abstract data to evaluate Thomson Reuters Web of Knowledge subject categories as descriptive labels for astrobiology documents, assess individual researcher interdisciplinarity, and determine where collaboration opportunities might occur. We find that the majority of the UHNAI team is engaged in interdisciplinary research, and suggest that our method could be applied to additional NASA Astrobiology Institute teams in particular, or other interdisciplinary research teams more broadly, to identify and facilitate collaboration opportunities.',
	 'authors': u'Michael G. Gowanlock, Rich Gazan,',
	 'category': u'Computer Science ',
	 'date': '2012-4-25',
	 'pdflink': u'http://arxiv.org/pdf/1204.5563',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nAssessing Researcher Interdisciplinarity: A Case Study of the University  of Hawaii NASA Astrobiology Institute',
	 'urllink': u'http://arxiv.org/abs/1204.5563'}
2015-03-24 00:10:14+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0425> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:10:14+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0425>
	{'abstract': u'Effective Communication for marketing is a vital field in business organizations, which is used to convey the details about their products and services to the market segments and subsequently to build long lasting customer relationships. This paper focuses on an emerging component of the integrated marketing communication, ie. social media networking, as it is increasingly becoming the trend. In 21st century, the marketing communication platforms show a tendency to shift towards innovative technology bound people networking which is becoming an acceptable domain of interaction. Though the traditional channels like TV, print media etc. are still active and prominent in marketing communication, the presences of the Internet and more specifically the Social Media Networking, has started influencing the way individuals and business enterprises communicate. It has become evident that more individuals and business enterprises are engaging the social media networking sites either to accelerate the sales of their products and services or to provide post-purchase feedbacks. This shift in scenario has motivated this research which took six months (June 2011 - December 2011), using empirical analysis which is carried out based on several primary and secondary evidences. The research paper also analyzes the factors that govern the social media networking sites to influence consumers and subsequently enable their purchase decisions. The secondary data presented for this research were those pertaining to the period between the year 2005 and year 2011. The study revealed promising facts like the transition to marketing through SMN gives visible advantages like bidirectional communication, interactive product presentation, and a firm influence on customer who has a rudimentary interest...',
	 'authors': u'T.R. Gopalakrishnan Nair, Kumarashvari Subramaniam,',
	 'category': u'Computer Science ',
	 'date': '2012-6-3',
	 'pdflink': u'http://arxiv.org/pdf/1206.0425',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nTransformation of Traditional Marketing Communications in to Paradigms  of Social Media Networking',
	 'urllink': u'http://arxiv.org/abs/1206.0425'}
2015-03-24 00:10:20+0000 [xxu46_4] INFO: Crawled 567 pages (at 4 pages/min), scraped 561 items (at 4 items/min)
2015-03-24 00:10:28+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.5393> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:10:28+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.5393>
	{'abstract': u'We prove that the uniform recurrence of morphic sequences is decidable. For this we show that the number of derived sequences of uniformly recurrent morphic sequences is bounded. As a corollary we obtain that uniformly recurrent morphic sequences are primitive substitutive sequences.',
	 'authors': u'Fabien Durand,',
	 'category': u'Computer Science ',
	 'date': '2012-4-24',
	 'pdflink': u'http://arxiv.org/pdf/1204.5393',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nDecidability of uniform recurrence of morphic sequences',
	 'urllink': u'http://arxiv.org/abs/1204.5393'}
2015-03-24 00:10:44+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0414> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:10:44+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0414>
	{'abstract': u'Dynamic Threshold Optimization (DTO) adaptively "compresses" the decision space (DS) in a global search and optimization problem by bounding the objective function from below. This approach is different from "shrinking" DS by reducing bounds on the decision variables. DTO is applied to Schwefel\'s Problem 2.26 in 2 and 30 dimensions with good results. DTO is universally applicable, and the author believes it may be a novel approach to global search and optimization.',
	 'authors': u'Richard A. Formato,',
	 'category': u'Computer Science ',
	 'date': '2012-6-3',
	 'pdflink': u'http://arxiv.org/pdf/1206.0414',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nDynamic Threshold Optimization - A New Approach?',
	 'urllink': u'http://arxiv.org/abs/1206.0414'}
2015-03-24 00:11:00+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6861> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:11:00+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6861>
	{'abstract': u'This paper proposes new formulas for the probabilities of causation difined by Pearl (2000). Tian and Pearl (2000a, 2000b) showed how to bound the quantities of the probabilities of causation from experimental and observational data, under the minimal assumptions about the data-generating process. We derive narrower bounds than Tian-Pearl bounds by making use of the covariate information measured in experimental and observational studies. In addition, we provide identifiable case under no-prevention assumption and discuss the covariate selection problem from the viewpoint of estimation accuracy. These results are helpful in providing more evidence for public policy assessment and dicision making problems.',
	 'authors': u'Manabu Kuroki, Zhihong Cai,',
	 'category': u'Computer Science ',
	 'date': '2012-6-27',
	 'pdflink': u'http://arxiv.org/pdf/1206.6861',
	 'subjects': u'Methodology (stat.ME)',
	 'title': u"\nStratified Analysis of `Probabilities of Causation'",
	 'urllink': u'http://arxiv.org/abs/1206.6861'}
2015-03-24 00:11:16+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.2903> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:11:16+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.2903>
	{'abstract': u"Zipf's law on word frequency is observed in English, French, Spanish, Italian, and so on, yet it does not hold for Chinese, Japanese or Korean characters. A model for writing process is proposed to explain the above difference, which takes into account the effects of finite vocabulary size. Experiments, simulations and analytical solution agree well with each other. The results show that the frequency distribution follows a power law with exponent being equal to 1, at which the corresponding Zipf's exponent diverges. Actually, the distribution obeys exponential form in the Zipf's plot. Deviating from the Heaps' law, the number of distinct words grows with the text length in three stages: It grows linearly in the beginning, then turns to a logarithmical form, and eventually saturates. This work refines previous understanding about Zipf's law and Heaps' law in language systems.",
	 'authors': u'Linyuan Lu, Zi-Ke Zhang, Tao Zhou,',
	 'category': u'Computer Science ',
	 'date': '2012-2-14',
	 'pdflink': u'http://arxiv.org/pdf/1202.2903',
	 'subjects': u'Data Analysis, Statistics and Probability (physics.data-an)',
	 'title': u'\nScaling Laws in Human Language',
	 'urllink': u'http://arxiv.org/abs/1202.2903'}
2015-03-24 00:11:20+0000 [xxu46_4] INFO: Crawled 571 pages (at 4 pages/min), scraped 565 items (at 4 items/min)
2015-03-24 00:11:31+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.4049> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:11:31+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.4049>
	{'abstract': u'An important property of the Kalman filter is that the underlying Riccati flow is a contraction for the natural metric of the cone of symmetric positive definite matrices. The present paper studies the geometry of a low-rank version of the Kalman filter. The underlying Riccati flow evolves on the manifold of fixed rank symmetric positive semidefinite matrices. Contraction properties of the low-rank flow are studied by means of a suitable metric recently introduced by the authors.',
	 'authors': u'Silvere Bonnabel, Rodolphe Sepulchre,',
	 'category': u'Computer Science ',
	 'date': '2012-3-19',
	 'pdflink': u'http://arxiv.org/pdf/1203.4049',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nThe geometry of low-rank Kalman filters',
	 'urllink': u'http://arxiv.org/abs/1203.4049'}
2015-03-24 00:11:39+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.5383> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:11:39+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.5383>
	{'abstract': u'A new approach is proposed for finding the "best cut" in a hierarchy of partitions by energy minimization. Said energy must be "climbing" i.e. it must be hierarchically and scale increasing. It encompasses separable energies and those composed under supremum.',
	 'authors': u'Jean Serra, Bangalore Ravi Kiran,',
	 'category': u'Computer Science ',
	 'date': '2012-4-21',
	 'pdflink': u'http://arxiv.org/pdf/1204.5383',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nClimbing on Pyramids',
	 'urllink': u'http://arxiv.org/abs/1204.5383'}
2015-03-24 00:11:55+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0399> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:11:55+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0399>
	{'abstract': u'Higher-order statistics (HOS) of the channel capacity provide useful information regarding the level of reliability of the signal transmission at a particular rate. We propose in this letter a novel and unified analysis, which is based on the moment-generating function (MGF) approach, to efficiently and accurately compute the HOS of the channel capacity for amplify-and-forward multihop transmission over generalized fading channels. More precisely, our mathematical formulism is easy-to-use and tractable specifically requiring only the reciprocal MGFs of the instantaneous signal-to-noise ratio distributions of the transmission hops. Numerical and simulation results, performed to exemplify the usefulness of the proposed MGF-based analysis, are shown to be in perfect agreement.',
	 'authors': u'Ferkan Yilmaz, Hina Tabassum, Mohamed-Slim Alouini,',
	 'category': u'Computer Science ',
	 'date': '2012-6-2',
	 'pdflink': u'http://arxiv.org/pdf/1206.0399',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOn the Computation of the Higher-Order Statistics of the Channel  Capacity for Amplify-and-Forward Multihop Transmission',
	 'urllink': u'http://arxiv.org/abs/1206.0399'}
2015-03-24 00:12:04+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6845> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:12:04+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6845>
	{'abstract': u'Nonparametric Bayesian approaches to clustering, information retrieval, language modeling and object recognition have recently shown great promise as a new paradigm for unsupervised data analysis. Most contributions have focused on the Dirichlet process mixture models or extensions thereof for which efficient Gibbs samplers exist. In this paper we explore Gibbs samplers for infinite complexity mixture models in the stick breaking representation. The advantage of this representation is improved modeling flexibility. For instance, one can design the prior distribution over cluster sizes or couple multiple infinite mixture models (e.g. over time) at the level of their parameters (i.e. the dependent Dirichlet process model). However, Gibbs samplers for infinite mixture models (as recently introduced in the statistics literature) seem to mix poorly over cluster labels. Among others issues, this can have the adverse effect that labels for the same cluster in coupled mixture models are mixed up. We introduce additional moves in these samplers to improve mixing over cluster labels and to bring clusters into correspondence. An application to modeling of storm trajectories is used to illustrate these ideas.',
	 'authors': u'Ian Porteous, Alexander T. Ihler, Padhraic Smyth, Max Welling,',
	 'category': u'Computer Science ',
	 'date': '2012-6-27',
	 'pdflink': u'http://arxiv.org/pdf/1206.6845',
	 'subjects': u'Methodology (stat.ME)',
	 'title': u'\nGibbs Sampling for (Coupled) Infinite Mixture Models in the Stick  Breaking Representation',
	 'urllink': u'http://arxiv.org/abs/1206.6845'}
2015-03-24 00:12:16+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.2709> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:12:16+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.2709>
	{'abstract': u'Uncovering factors underlying the network formation is a long-standing challenge for data mining and network analysis. In particular, the microscopic organizing principles of directed networks are less understood than those of undirected networks. This article proposes a hypothesis named potential theory, which assumes that every directed link corresponds to a decrease of a unit potential and subgraphs with definable potential values for all nodes are preferred. Combining the potential theory with the clustering and homophily mechanisms, it is deduced that the Bi-fan structure consisting of 4 nodes and 4 directed links is the most favored local structure in directed networks. Our hypothesis receives strongly positive supports from extensive experiments on 15 directed networks drawn from disparate fields, as indicated by the most accurate and robust performance of Bi-fan predictor within the link prediction framework. In summary, our main contribution is twofold: (i) We propose a new mechanism for the local organization of directed networks; (ii) We design the corresponding link prediction algorithm, which can not only testify our hypothesis, but also find out direct applications in missing link prediction and friendship recommendation.',
	 'authors': u'Qian-Ming Zhang, Linyuan L\xfc, Wen-Qiang Wang, Yu-Xiao Zhu, Tao Zhou,',
	 'category': u'Computer Science ',
	 'date': '2012-2-13',
	 'pdflink': u'http://arxiv.org/pdf/1202.2709',
	 'subjects': u'Data Analysis, Statistics and Probability (physics.data-an)',
	 'title': u'\nPotential Theory for Directed Networks',
	 'urllink': u'http://arxiv.org/abs/1202.2709'}
2015-03-24 00:12:20+0000 [xxu46_4] INFO: Crawled 576 pages (at 5 pages/min), scraped 570 items (at 5 items/min)
2015-03-24 00:12:26+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.3961> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:12:26+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.3961>
	{'abstract': u'The positive semidefinite rank of a nonnegative -matrix~ is the minimum number~ such that there exist positive semidefinite -matrices , such that . The most important, lower bound technique for nonnegative rank is solely based on the support of the matrix S, i.e., its zero/non-zero pattern. In this paper, we characterize the power of lower bounds on positive semidefinite rank based on solely on the support.',
	 'authors': u'Troy Lee, Dirk Oliver Theis,',
	 'category': u'Computer Science ',
	 'date': '2012-3-18',
	 'pdflink': u'http://arxiv.org/pdf/1203.3961',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nSupport-based lower bounds for the positive semidefinite rank of a  nonnegative matrix',
	 'urllink': u'http://arxiv.org/abs/1203.3961'}
2015-03-24 00:12:37+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.5371> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:12:37+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.5371>
	{'abstract': u'We study the geometric properties of Cantor subshifts in the Besicovitch space, proving that sofic shifts occupy exactly the homotopy classes of simplicial complexes. In addition, we study canonical projections into subshifts, characterize the cellular automata that are contracting or isometric in the Besicovitch or Weyl spaces, study continuous functions that locally look like cellular automata, and present a new proof for the nonexistence of transitive cellular automata in the Besicovitch space.',
	 'authors': u'Ville Salo, Ilkka T\xf6rm\xe4,',
	 'category': u'Computer Science ',
	 'date': '2012-4-24',
	 'pdflink': u'http://arxiv.org/pdf/1204.5371',
	 'subjects': u'Dynamical Systems (math.DS)',
	 'title': u'\nGeometry and Dynamics of the Besicovitch and Weyl Spaces',
	 'urllink': u'http://arxiv.org/abs/1204.5371'}
2015-03-24 00:12:52+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0396> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:12:52+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0396>
	{'abstract': u'Efficient task partitioning plays a crucial role in achieving high performance at multiprocessor plat forms. This paper addresses the problem of energy-aware static partitioning of periodic real-time tasks on heterogeneous multiprocessor platforms. A Particle Swarm Optimization variant based on Min-min technique for task partitioning is proposed. The proposed approach aims to minimize the overall energy consumption, meanwhile avoid deadline violations. An energy-aware cost function is proposed to be considered in the proposed approach. Extensive simulations and comparisons are conducted in order to validate the effectiveness of the proposed technique. The achieved results demonstrate that the proposed partitioning scheme significantly surpasses previous approaches in terms of both number of iterations and energy savings.',
	 'authors': u'Elsayed Saad, Medhat Awadalla, Mohamed Shalan, Abdullah Elewi,',
	 'category': u'Computer Science ',
	 'date': '2012-6-2',
	 'pdflink': u'http://arxiv.org/pdf/1206.0396',
	 'subjects': u'Operating Systems (cs.OS)',
	 'title': u'\nEnergy-Aware Task Partitioning on Heterogeneous Multiprocessor Platforms',
	 'urllink': u'http://arxiv.org/abs/1206.0396'}
2015-03-24 00:13:02+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6830> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:13:02+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6830>
	{'abstract': u'We investigate methods for parameter learning from incomplete data that is not missing at random. Likelihood-based methods then require the optimization of a profile likelihood that takes all possible missingness mechanisms into account. Optimzing this profile likelihood poses two main difficulties: multiple (local) maxima, and its very high-dimensional parameter space. In this paper a new method is presented for optimizing the profile likelihood that addresses the second difficulty: in the proposed AI&amp;M (adjusting imputation and mazimization) procedure the optimization is performed by operations in the space of data completions, rather than directly in the parameter space of the profile likelihood. We apply the AI&amp;M method to learning parameters for Bayesian networks. The method is compared against conservative inference, which takes into account each possible data completion, and against EM. The results indicate that likelihood-based inference is still feasible in the case of unknown missingness mechanisms, and that conservative inference is unnecessarily weak. On the other hand, our results also provide evidence that the EM algorithm is still quite effective when the data is not missing at random.',
	 'authors': u'Manfred Jaeger,',
	 'category': u'Computer Science ',
	 'date': '2012-6-27',
	 'pdflink': u'http://arxiv.org/pdf/1206.6830',
	 'subjects': u'Methodology (stat.ME)',
	 'title': u'\nThe AI&M Procedure for Learning from Incomplete Data',
	 'urllink': u'http://arxiv.org/abs/1206.6830'}
2015-03-24 00:13:16+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.2651> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:13:16+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.2651>
	{'abstract': u'(2QCFA) were introduced by Ambainis and Watrous in 2002. In this paper we study state succinctness of 2QCFA. For any and any , we show that: there is a promise problem which can be solved by a 2QCFA with one-sided error in a polynomial expected running time with a constant number (that depends neither on nor on ) of quantum states and classical states, whereas the sizes of the corresponding (DFA), (2NFA) and polynomial expected running time (2PFA) are at least , , and , respectively; there exists a language over the alphabet which can be recognized by a 2QCFA with one-sided error in an exponential expected running time with a constant number of quantum states and classical states, whereas the sizes of the corresponding DFA, 2NFA and polynomial expected running time 2PFA are at least , , and , respectively; where is a constant.',
	 'authors': u'Shenggen Zheng, Daowen Qiu, Jozef Gruska, Lvzhou Li, Paulo Mateus,',
	 'category': u'Computer Science ',
	 'date': '2012-2-13',
	 'pdflink': u'http://arxiv.org/pdf/1202.2651',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nState succinctness of two-way finite automata with quantum and classical  states',
	 'urllink': u'http://arxiv.org/abs/1202.2651'}
2015-03-24 00:13:20+0000 [xxu46_4] INFO: Crawled 581 pages (at 5 pages/min), scraped 575 items (at 5 items/min)
2015-03-24 00:13:31+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.3887> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:13:31+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.3887>
	{'abstract': u'The problem of structure estimation in graphical models with latent variables is considered. We characterize conditions for tractable graph estimation and develop efficient methods with provable guarantees. We consider models where the underlying Markov graph is locally tree-like, and the model is in the regime of correlation decay. For the special case of the Ising model, the number of samples required for structural consistency of our method scales as , where p is the number of variables, is the minimum edge potential, is the depth (i.e., distance from a hidden node to the nearest observed nodes), and is a parameter which depends on the bounds on node and edge potentials in the Ising model. Necessary conditions for structural consistency under any algorithm are derived and our method nearly matches the lower bound on sample requirements. Further, the proposed method is practical to implement and provides flexibility to control the number of latent variables and the cycle lengths in the output graph.',
	 'authors': u'Animashree Anandkumar, Ragupathyraj Valluvan,',
	 'category': u'Computer Science ',
	 'date': '2012-3-17',
	 'pdflink': u'http://arxiv.org/pdf/1203.3887',
	 'subjects': u'Machine Learning (stat.ML)',
	 'title': u'\nLearning loopy graphical models with latent variables: Efficient methods  and guarantees',
	 'urllink': u'http://arxiv.org/abs/1203.3887'}
2015-03-24 00:13:48+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.5357> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:13:48+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.5357>
	{'abstract': u"This paper deals with chain graphs under the alternative Andersson-Madigan-Perlman (AMP) interpretation. In particular, we present a constraint based algorithm for learning an AMP chain graph a given probability distribution is faithful to. We also show that the extension of Meek's conjecture to AMP chain graphs does not hold, which compromises the development of efficient and correct score+search learning algorithms under assumptions weaker than faithfulness.",
	 'authors': u'Jose M. Pe\xf1a,',
	 'category': u'Computer Science ',
	 'date': '2012-4-24',
	 'pdflink': u'http://arxiv.org/pdf/1204.5357',
	 'subjects': u'Machine Learning (stat.ML)',
	 'title': u'\nLearning AMP Chain Graphs under Faithfulness',
	 'urllink': u'http://arxiv.org/abs/1204.5357'}
2015-03-24 00:14:05+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0381> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:14:05+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0381>
	{'abstract': u'Universal Networking Language (UNL) is a declarative formal language that is used to represent semantic data extracted from natural language texts. This paper presents a novel approach to converting Bangla natural language text into UNL using a method known as Predicate Preserving Parser (PPP) technique. PPP performs morphological, syntactic and semantic, and lexical analysis of text synchronously. This analysis produces a semantic-net like structure represented using UNL. We demonstrate how Bangla texts are analyzed following the PPP technique to produce UNL documents which can then be translated into any other suitable natural language facilitating the opportunity to develop a universal language translation method via UNL.',
	 'authors': u'Md. Nawab Yousuf Ali, Shamim Ripon, Shaikh Muhammad Allayear,',
	 'category': u'Computer Science ',
	 'date': '2012-6-2',
	 'pdflink': u'http://arxiv.org/pdf/1206.0381',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nUNL Based Bangla Natural Text Conversion - Predicate Preserving Parser  Approach',
	 'urllink': u'http://arxiv.org/abs/1206.0381'}
2015-03-24 00:14:20+0000 [xxu46_4] INFO: Crawled 584 pages (at 3 pages/min), scraped 578 items (at 3 items/min)
2015-03-24 00:14:22+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6778> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:14:22+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6778>
	{'abstract': u'This paper reports a variant of the three-stage quantum cryptography protocol which can be used in low intensity laser output regimes. The variant, which tracks the intensity of the laser beam at the intermediate stages, makes the task of the eavesdropper harder than the standard K06 protocol. The constraints on the iAQC protocol are much less than those on BB84 and in principle it can not only be used for key distribution but also for direct bitwise encryption of data. The iAQC protocol is an improvement on the K06 protocol in that it makes it harder for the eavesdropper to monitor the channel.',
	 'authors': u'Subhash Kak, Yuhua Chen, Pramode Verma,',
	 'category': u'Computer Science ',
	 'date': '2012-6-28',
	 'pdflink': u'http://arxiv.org/pdf/1206.6778',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\niAQC: The Intensity-Aware Quantum Cryptography Protocol',
	 'urllink': u'http://arxiv.org/abs/1206.6778'}
2015-03-24 00:14:39+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.2624> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:14:39+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.2624>
	{'abstract': u'Let g(t) be the minimum number such that every graph G with average degree d(G) geq g(t) contains a K_-minor. Such a function is known to exist, as originally shown by Mader. Kostochka and Thomason independently proved that g(t) in Theta(t*sqrt). This article shows that for all fixed epsilon &gt; 0 and fixed sufficiently large t geq t( epsilon), if d(G) geq (2+ epsilon)g(t) then we can find this K_-minor in linear time. This improves a previous result by Reed and Wood who gave a linear-time algorithm when d(G) geq 2^.',
	 'authors': u'Vida Dujmovi\u0107, Daniel J. Harvey, Gwena\xebl Joret, Bruce Reed, David R. Wood,',
	 'category': u'Computer Science ',
	 'date': '2012-2-13',
	 'pdflink': u'http://arxiv.org/pdf/1202.2624',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nA linear-time algorithm for finding a complete graph minor in a dense  graph',
	 'urllink': u'http://arxiv.org/abs/1202.2624'}
2015-03-24 00:14:56+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.3854> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:14:56+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.3854>
	{'abstract': u'The Steiner Traveling Salesman Problem (STSP) is a variant of the Traveling Salesman Problem (TSP) that is particularly suitable when dealing with sparse networks, such as road networks. The standard integer programming formulation of the STSP has an exponential number of constraints, just like the standard formulation of the TSP. On the other hand, there exist several known formulations of the TSP, i.e., formulations with a polynomial number of both variables and constraints. In this paper, we show that some of these compact formulations can be adapted to the STSP. We also briefly discuss the adaptation of our formulations to some closely-related problems.',
	 'authors': u'Adam N. Letchford, Saeideh D. Nasiri, Dirk Oliver Theis,',
	 'category': u'Computer Science ',
	 'date': '2012-3-17',
	 'pdflink': u'http://arxiv.org/pdf/1203.3854',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nCompact Formulations of the Steiner Traveling Salesman Problem and  Related Problems',
	 'urllink': u'http://arxiv.org/abs/1203.3854'}
2015-03-24 00:15:09+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.5345> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:15:09+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.5345>
	{'abstract': u'We demonstrate an improved technique for implementing logic circuits in light-sensitive chemical excitable media. The technique makes use of the constant-speed propagation of waves along defined channels in an excitable medium based on the Belousov-Zhabotinsky reaction, along with the mutual annihilation of colliding waves. What distinguishes this work from previous work in this area is that regions where channels meet at a junction can periodically alternate between permitting the propagation of waves and blocking them. These valve-like areas are used to select waves based on the length of time that it takes waves to propagate from one valve to another. In an experimental implementation, the channels which make up the circuit layout are projected by a digital projector connected to a computer. Excitable channels are projected as dark areas, unexcitable regions as light areas. Valves alternate between dark and light: every valve has the same period and phase, with a 50% duty cycle. This scheme can be used to make logic gates based on combinations of OR and AND-NOT operations, with few geometrical constraints. Because there are few geometrical constraints, compact circuits can be implemented. Experimental results from an implementation of a 4-bit input, 2-bit output integer square root circuit are given. This is the most complex logic circuit that has been implemented in BZ excitable media to date.',
	 'authors': u'William M. Stevens, Andrew Adamatzky, Ishrat Jahan, Ben de Lacy Costello,',
	 'category': u'Computer Science ',
	 'date': '2012-4-24',
	 'pdflink': u'http://arxiv.org/pdf/1204.5345',
	 'subjects': u'Pattern Formation and Solitons (nlin.PS)',
	 'title': u'\nTime-dependent wave selection for information processing in excitable  media',
	 'urllink': u'http://arxiv.org/abs/1204.5345'}
2015-03-24 00:15:20+0000 [xxu46_4] INFO: Crawled 588 pages (at 4 pages/min), scraped 582 items (at 4 items/min)
2015-03-24 00:15:23+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0377> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:15:23+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0377>
	{'abstract': u'We propose a general method for automated word puzzle generation. Contrary to previous approaches in this novel field, the presented method does not rely on highly structured datasets obtained with serious human annotation effort: it only needs an unstructured and unannotated corpus (i.e., document collection) as input. The method builds upon two additional pillars: (i) a topic model, which induces a topic dictionary from the input corpus (examples include e.g., latent semantic analysis, group-structured dictionaries or latent Dirichlet allocation), and (ii) a semantic similarity measure of word pairs. Our method can (i) generate automatically a large number of proper word puzzles of different types, including the odd one out, choose the related word and separate the topics puzzle. (ii) It can easily create domain-specific puzzles by replacing the corpus component. (iii) It is also capable of automatically generating puzzles with parameterizable levels of difficulty suitable for, e.g., beginners or intermediate learners.',
	 'authors': u'Balazs Pinter, Gyula Voros, Zoltan Szabo, Andras Lorincz,',
	 'category': u'Computer Science ',
	 'date': '2012-6-2',
	 'pdflink': u'http://arxiv.org/pdf/1206.0377',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nAutomated Word Puzzle Generation via Topic Dictionaries',
	 'urllink': u'http://arxiv.org/abs/1206.0377'}
2015-03-24 00:15:37+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6728> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:15:37+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6728>
	{'abstract': u'Recent work has shown that different theoretical approaches to the dynamics of the Susceptible-Infected-Susceptible (SIS) model for epidemics lead to qualitatively different estimates for the position of the epidemic threshold in networks. Here we present large-scale numerical simulations of the SIS dynamics on various types of networks, allowing the precise determination of the effective threshold for systems of finite size N. We compare quantitatively the numerical thresholds with theoretical predictions of the heterogeneous mean-field theory and of the quenched mean-field theory. We show that the latter is in general more accurate, scaling with N with the correct exponent, but often failing to capture the correct prefactor.',
	 'authors': u'Silvio C. Ferreira, Claudio Castellano, Romualdo Pastor-Satorras,',
	 'category': u'Computer Science ',
	 'date': '2012-6-28',
	 'pdflink': u'http://arxiv.org/pdf/1206.6728',
	 'subjects': u'Statistical Mechanics (cond-mat.stat-mech)',
	 'title': u'\nEpidemic thresholds of the Susceptible-Infected-Susceptible model on  networks: A comparison of numerical and theoretical results',
	 'urllink': u'http://arxiv.org/abs/1206.6728'}
2015-03-24 00:15:53+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.2601> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:15:53+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.2601>
	{'abstract': u'Most previous studies of the sorting algorithm QuickSort have used the number of key comparisons as a measure of the cost of executing the algorithm. Here we suppose that the n independent and identically distributed (i.i.d.) keys are each represented as a sequence of symbols from a probabilistic source and that QuickSort operates on individual symbols, and we measure the execution cost as the number of symbol comparisons. Assuming only a mild "tameness" condition on the source, we show that there is a limiting distribution for the number of symbol comparisons after normalization: first centering by the mean and then dividing by n. Additionally, under a condition that grows more restrictive as p increases, we have convergence of moments of orders p and smaller. In particular, we have convergence in distribution and convergence of moments of every order whenever the source is memoryless, that is, whenever each key is generated as an infinite string of i.i.d. symbols. This is somewhat surprising; even for the classical model that each key is an i.i.d. string of unbiased ("fair") bits, the mean exhibits periodic fluctuations of order n.',
	 'authors': u'James Allen Fill,',
	 'category': u'Computer Science ',
	 'date': '2012-2-13',
	 'pdflink': u'http://arxiv.org/pdf/1202.2601',
	 'subjects': u'Probability (math.PR)',
	 'title': u'\nDistributional convergence for the number of symbol comparisons used by  QuickSort',
	 'urllink': u'http://arxiv.org/abs/1202.2601'}
2015-03-24 00:16:04+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.3783> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:16:04+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.3783>
	{'abstract': u'Deep Boltzmann machines are in principle powerful models for extracting the hierarchical structure of data. Unfortunately, attempts to train layers jointly (without greedy layer-wise pretraining) have been largely unsuccessful. We propose a modification of the learning algorithm that initially recenters the output of the activation functions to zero. This modification leads to a better conditioned Hessian and thus makes learning easier. We test the algorithm on real data and demonstrate that our suggestion, the centered deep Boltzmann machine, learns a hierarchy of increasingly abstract representations and a better generative model of data.',
	 'authors': u'Gr\xe9goire Montavon, Klaus-Robert M\xfcller,',
	 'category': u'Computer Science ',
	 'date': '2012-3-16',
	 'pdflink': u'http://arxiv.org/pdf/1203.3783',
	 'subjects': u'Machine Learning (stat.ML)',
	 'title': u'\nLearning Feature Hierarchies with Centered Deep Boltzmann Machines',
	 'urllink': u'http://arxiv.org/abs/1203.3783'}
2015-03-24 00:16:20+0000 [xxu46_4] INFO: Crawled 592 pages (at 4 pages/min), scraped 586 items (at 4 items/min)
2015-03-24 00:16:21+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.5249> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:16:21+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.5249>
	{'abstract': u"Parrondo's paradox occurs in sequences of games in which a winning expectation may be obtained by playing the games in a random order, even though each game in the sequence may be lost when played individually. Several variations of Parrondo's games apparently with paradoxical property have been introduced; history dependence, one dimensional line, two dimensional lattice and so on. In this article, we examine whether Parrondo's paradox occurs or not in scale free networks. This is interesting as an empirical study, since scale free networks are ubiquitous in our real world. First some simulation results are given and after that theoretical studies are made. As a result, we mostly confirm that Parrondo's paradox can not occur in the naive case, where the game has the same number of parameters as the original Parrondo's game.",
	 'authors': u'Norihito Toyota,',
	 'category': u'Computer Science ',
	 'date': '2012-4-24',
	 'pdflink': u'http://arxiv.org/pdf/1204.5249',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nDoes Parrondo Paradox occur in Scale Free Networks? -A simple  Consideration-',
	 'urllink': u'http://arxiv.org/abs/1204.5249'}
2015-03-24 00:16:30+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0376> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:16:30+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0376>
	{'abstract': u'Some contemporary views of the universe assume information and computation to be key in understanding and explaining the basic structure underpinning physical reality. We introduce the Computable Universe exploring some of the basic arguments giving foundation to these visions. We will focus on the algorithmic and quantum aspects, and how these may fit and support the computable universe hypothesis.',
	 'authors': u'Hector Zenil,',
	 'category': u'Computer Science ',
	 'date': '2012-6-2',
	 'pdflink': u'http://arxiv.org/pdf/1206.0376',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nIntroducing the Computable Universe',
	 'urllink': u'http://arxiv.org/abs/1206.0376'}
2015-03-24 00:16:43+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6690> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:16:43+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6690>
	{'abstract': u"For many of the unsolved problems concerning cycles and matchings in graphs it is known that it is sufficient to prove them for emph, the class of nontrivial 3-regular graphs which cannot be 3-edge coloured. In the first part of this paper we present a new algorithm for generating all non-isomorphic snarks of a given order. Our implementation of the new algorithm is 14 times faster than previous programs for generating snarks, and 29 times faster for generating weak snarks. Using this program we have generated all non-isomorphic snarks on vertices. Previously lists up to vertices have been published. In the second part of the paper we analyze the sets of generated snarks with respect to a number of properties and conjectures. We find that some of the strongest versions of the cycle double cover conjecture hold for all snarks of these orders, as does Jaeger's Petersen colouring conjecture, which in turn implies that Fulkerson's conjecture has no small counterexamples. In contrast to these positive results we also find counterexamples to eight previously published conjectures concerning cycle coverings and the general cycle structure of cubic graphs.",
	 'authors': u'Gunnar Brinkmann, Jan Goedgebeur, Jonas H\xe4gglund, Klas Markstr\xf6m,',
	 'category': u'Computer Science ',
	 'date': '2012-6-28',
	 'pdflink': u'http://arxiv.org/pdf/1206.6690',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nGeneration and Properties of Snarks',
	 'urllink': u'http://arxiv.org/abs/1206.6690'}
2015-03-24 00:16:55+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.2599> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:16:55+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.2599>
	{'abstract': u"When the search algorithm QuickSelect compares keys during its execution in order to find a key of target rank, it must operate on the keys' representations or internal structures, which were ignored by the previous studies that quantified the execution cost for the algorithm in terms of the number of required key comparisons. In this paper, we analyze running costs for the algorithm that take into account not only the number of key comparisons but also the cost of each key comparison. We suppose that keys are represented as sequences of symbols generated by various probabilistic sources and that QuickSelect operates on individual symbols in order to find the target key. We identify limiting distributions for the costs and derive integral and series expressions for the expectations of the limiting distributions. These expressions are used to recapture previously obtained results on the number of key comparisons required by the algorithm.",
	 'authors': u'James Allen Fill, Takehiko Nakama,',
	 'category': u'Computer Science ',
	 'date': '2012-2-13',
	 'pdflink': u'http://arxiv.org/pdf/1202.2599',
	 'subjects': u'Probability (math.PR)',
	 'title': u'\nDistributional convergence for the number of symbol comparisons used by  QuickSelect',
	 'urllink': u'http://arxiv.org/abs/1202.2599'}
2015-03-24 00:17:07+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.3725> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:17:07+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.3725>
	{'abstract': u'Undirected graphical models are widely used in statistics, physics and machine vision. However Bayesian parameter estimation for undirected models is extremely challenging, since evaluation of the posterior typically involves the calculation of an intractable normalising constant. This problem has received much attention, but very little of this has focussed on the important practical case where the data consists of noisy or incomplete observations of the underlying hidden structure. This paper specifically addresses this problem, comparing two alternative methodologies. In the first of these approaches particle Markov chain Monte Carlo (Andrieu et al., 2010) is used to efficiently explore the parameter space, combined with the exchange algorithm (Murray et al., 2006) for avoiding the calculation of the intractable normalising constant (a proof showing that this combination targets the correct distribution in found in a supplementary appendix online). This approach is compared with approximate Bayesian computation (Pritchard et al., 1999). Applications to estimating the parameters of Ising models and exponential random graphs from noisy data are presented. Each algorithm used in the paper targets an approximation to the true posterior due to the use of MCMC to simulate from the latent graphical model, in lieu of being able to do this exactly in general. The supplementary appendix also describes the nature of the resulting approximation.',
	 'authors': u'Richard G. Everitt,',
	 'category': u'Computer Science ',
	 'date': '2012-3-14',
	 'pdflink': u'http://arxiv.org/pdf/1203.3725',
	 'subjects': u'Computation (stat.CO)',
	 'title': u'\nBayesian Parameter Estimation for Latent Markov Random Fields and Social  Networks',
	 'urllink': u'http://arxiv.org/abs/1203.3725'}
2015-03-24 00:17:20+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.5244> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:17:20+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.5244>
	{'abstract': u'It has been shown that a functional interpretation of proofs in mathematical analysis can be given by the product of selection functions, a mode of recursion that has an intuitive reading in terms of the computation of optimal strategies in sequential games. We argue that this result has genuine practical value by interpreting some well-known theorems of mathematics and demonstrating that the product gives these theorems a natural computational interpretation that can be clearly understood in game theoretic terms.',
	 'authors': u'Paulo Oliva, Thomas Powell,',
	 'category': u'Computer Science ',
	 'date': '2012-4-24',
	 'pdflink': u'http://arxiv.org/pdf/1204.5244',
	 'subjects': u'Logic (math.LO)',
	 'title': u'\nA Game-Theoretic Computational Interpretation of Proofs in Classical  Analysis',
	 'urllink': u'http://arxiv.org/abs/1204.5244'}
2015-03-24 00:17:20+0000 [xxu46_4] INFO: Crawled 598 pages (at 6 pages/min), scraped 592 items (at 6 items/min)
2015-03-24 00:17:36+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0375> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:17:36+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0375>
	{'abstract': u'While evolution has inspired algorithmic methods of heuristic optimisation, little has been done in the way of using concepts of computation to advance our understanding of salient aspects of biological phenomena. We argue that under reasonable assumptions, interesting conclusions can be drawn that are of relevance to behavioural evolution. We will focus on two important features of life--robustness and fitness--which, we will argue, are related to algorithmic probability and to the thermodynamics of computation, disciplines that may be capable of modelling key features of living organisms, and which can be used in formulating new algorithms of evolutionary computation.',
	 'authors': u'Hector Zenil, James A.R. Marshall,',
	 'category': u'Computer Science ',
	 'date': '2012-6-2',
	 'pdflink': u'http://arxiv.org/pdf/1206.0375',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nSome Computational Aspects of Essential Properties of Evolution and Life',
	 'urllink': u'http://arxiv.org/abs/1206.0375'}
2015-03-24 00:17:48+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6679> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:17:48+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6679>
	{'abstract': u'We propose a general algorithm for approximating nonstandard Bayesian posterior distributions. The algorithm minimizes the Kullback-Leibler divergence of an approximating distribution to the intractable posterior distribution. Our method can be used to approximate any posterior distribution, provided that it is given in closed form up to the proportionality constant. The approximation can be any distribution in the exponential family or any mixture of such distributions, which means that it can be made arbitrarily precise. Several examples illustrate the speed and accuracy of our approximation method in practice.',
	 'authors': u'Tim Salimans, David A. Knowles,',
	 'category': u'Computer Science ',
	 'date': '2012-6-28',
	 'pdflink': u'http://arxiv.org/pdf/1206.6679',
	 'subjects': u'Computation (stat.CO)',
	 'title': u'\nFixed-Form Variational Posterior Approximation through Stochastic Linear  Regression',
	 'urllink': u'http://arxiv.org/abs/1206.6679'}
2015-03-24 00:18:06+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.2595> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:18:06+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.2595>
	{'abstract': u'The analyses of many algorithms and data structures (such as digital search trees) for searching and sorting are based on the representation of the keys involved as bit strings and so count the number of bit comparisons. On the other hand, the standard analyses of many other algorithms (such as Quicksort) are performed in terms of the number of key comparisons. We introduce the prospect of a fair comparison between algorithms of the two types by providing an average-case analysis of the number of bit comparisons required by Quicksort. Counting bit comparisons rather than key comparisons introduces an extra logarithmic factor to the asymptotic average total. We also provide a new algorithm, "BitsQuick", that reduces this factor to constant order by eliminating needless bit comparisons.',
	 'authors': u'James Allen Fill, Svante Janson,',
	 'category': u'Computer Science ',
	 'date': '2012-2-13',
	 'pdflink': u'http://arxiv.org/pdf/1202.2595',
	 'subjects': u'Probability (math.PR)',
	 'title': u'\nThe number of bit comparisons used by Quicksort: an average-case  analysis',
	 'urllink': u'http://arxiv.org/abs/1202.2595'}
2015-03-24 00:18:20+0000 [xxu46_4] INFO: Crawled 601 pages (at 3 pages/min), scraped 595 items (at 3 items/min)
2015-03-24 00:18:22+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.3621> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:18:22+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.3621>
	{'abstract': u'We investigate robustness of correlated networks against propagating attacks modeled by a susceptible-infected-removed model. By Monte-Carlo simulations, we numerically determine the first critical infection rate, above which a global outbreak of disease occurs, and the second critical infection rate, above which disease disintegrates the network. Our result shows that correlated networks are robust compared to the uncorrelated ones, regardless of whether they are assortative or disassortative, when a fraction of infected nodes in an initial state is not too large. For large initial fraction, disassortative network becomes fragile while assortative network holds robustness. This behavior is related to the layered network structure inevitably generated by a rewiring procedure we adopt to realize correlated networks.',
	 'authors': u'Takehisa Hasegawa, Keita Konno, Koji Nemoto,',
	 'category': u'Computer Science ',
	 'date': '2012-3-16',
	 'pdflink': u'http://arxiv.org/pdf/1203.3621',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nRobustness of correlated networks against propagating attacks',
	 'urllink': u'http://arxiv.org/abs/1203.3621'}
2015-03-24 00:18:40+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.5226> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:18:40+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.5226>
	{'abstract': u'This paper addresses the problem of voltage regulation in power distribution networks with deep-penetration of distributed energy resources, e.g., renewable-based generation, and storage-capable loads such as plug-in hybrid electric vehicles. We cast the problem as an optimization program, where the objective is to minimize the losses in the network subject to constraints on bus voltage magnitudes, limits on active and reactive power injections, transmission line thermal limits and losses. We provide sufficient conditions under which the optimization problem can be solved via its convex relaxation. Using data from existing networks, we show that these sufficient conditions are expected to be satisfied by most networks. We also provide an efficient distributed algorithm to solve the problem. The algorithm adheres to a communication topology described by a graph that is the same as the graph that describes the electrical network topology. We illustrate the operation of the algorithm, including its robustness against communication link failures, through several case studies involving 5-, 34-, and 123-bus power distribution systems.',
	 'authors': u'Baosen Zhang, Albert Y.S. Lam, Alejandro Dominguez-Garcia, David Tse,',
	 'category': u'Computer Science ',
	 'date': '2012-4-23',
	 'pdflink': u'http://arxiv.org/pdf/1204.5226',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nAn Optimal and Distributed Method for Voltage Regulation in Power  Distribution Systems',
	 'urllink': u'http://arxiv.org/abs/1204.5226'}
2015-03-24 00:18:58+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0373> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:18:58+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0373>
	{'abstract': u'The process of testing any software system is an enormous task which is time consuming and costly. The time and required effort to do sufficient testing grow, as the size and complexity of the software grows, which may cause overrun of the project budget, delay in the development of software system or some test cases may not be covered. During SDLC (software development life cycle), generally the software testing phase takes around 40-70% of the time and cost. State-based testing is frequently used in software testing. Test data generation is one of the key issues in software testing. A properly generated test suite may not only locate the errors in a software system, but also help in reducing the high cost associated with software testing. It is often desired that test data in the form of test sequences within a test suite can be automatically generated to achieve required test coverage. This paper proposes an optimization approach to test data generation for the state-based software testing. In this paper, first state transition graph is derived from state chart diagram. Then, all the required information are extracted from the state chart diagram. Then, test cases are generated. Lastly, a set of test cases are minimized by calculating the node coverage for each test case. It is also determined that which test cases are covered by other test cases. The advantage of our test generation technique is that it optimizes test coverage by minimizing time and cost. The proposed test data generation scheme generates test cases which satisfy transition path coverage criteria, path coverage criteria and action coverage criteria. A case study on Automatic Ticket Machine (ATM) has been presented to illustrate our approach.',
	 'authors': u'Ranjita Kumari Swain, Prafulla Kumar Behera, Durga Prasad Mohapatra,',
	 'category': u'Computer Science ',
	 'date': '2012-6-2',
	 'pdflink': u'http://arxiv.org/pdf/1206.0373',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nGeneration and Optimization of Test cases for Object-Oriented Software  Using State Chart Diagram',
	 'urllink': u'http://arxiv.org/abs/1206.0373'}
2015-03-24 00:19:09+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6661> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:19:09+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6661>
	{'abstract': u'A differential system , with is said to be in reduced form if where is the Lie algebra of the differential Galois group of . In this article, we give a constructive criterion for a system to be in reduced form. When is reductive and unimodular, the system is in reduced form if and only if all of its invariants (rational solutions of appropriate symmetric powers) have constant coefficients (instead of rational functions). When is non-reductive, we give a similar characterization via the semi-invariants of . In the reductive case, we propose a decision procedure for putting the system into reduced form which, in turn, gives a constructive proof of the classical Kolchin-Kovacic reduction theorem.',
	 'authors': u'Ainhoa Aparicio-Monforte, Elie Compoint, Jacques-Arthur Weil,',
	 'category': u'Computer Science ',
	 'date': '2012-6-28',
	 'pdflink': u'http://arxiv.org/pdf/1206.6661',
	 'subjects': u'Classical Analysis and ODEs (math.CA)',
	 'title': u'\nA Characterization of Reduced Forms of Linear Differential Systems',
	 'urllink': u'http://arxiv.org/abs/1206.6661'}
2015-03-24 00:19:20+0000 [xxu46_4] INFO: Crawled 605 pages (at 4 pages/min), scraped 599 items (at 4 items/min)
2015-03-24 00:19:22+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.2591> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:19:22+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.2591>
	{'abstract': u'Previous work has demonstrated that categories are useful and expressive models for databases. In the present paper we build on that model, showing that certain queries and constraints correspond to lifting problems, as found in modern approaches to algebraic topology. In our formulation, each so-called SPARQL graph pattern query corresponds to a category-theoretic lifting problem, whereby the set of solutions to the query is precisely the set of lifts. We interpret constraints within the same formalism and then investigate some basic properties of queries and constraints. In particular, to any database we can associate a certain derived database of queries on . As an application, we explain how giving users access to certain parts of , rather than direct access to , improves ones ability to manage the impact of schema evolution.',
	 'authors': u'David I. Spivak,',
	 'category': u'Computer Science ',
	 'date': '2012-2-13',
	 'pdflink': u'http://arxiv.org/pdf/1202.2591',
	 'subjects': u'Category Theory (math.CT)',
	 'title': u'\nDatabase queries and constraints via lifting problems',
	 'urllink': u'http://arxiv.org/abs/1202.2591'}
2015-03-24 00:19:36+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.3618> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:19:36+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.3618>
	{'abstract': u"For k &gt;= 3, a k-angulation is a 2-connected plane graph in which every internal face is a k-gon. We say that a point set P admits a plane graph G if there is a straight-line drawing of G that maps V(G) onto P and has the same facial cycles and outer face as G. We investigate the conditions under which a point set P admits a k-angulation and find that, for sets containing at least 2k^2 points, the only obstructions are those that follow from Euler's formula.",
	 'authors': u'Michael S. Payne, Jens M. Schmidt, David R. Wood,',
	 'category': u'Computer Science ',
	 'date': '2012-3-16',
	 'pdflink': u'http://arxiv.org/pdf/1203.3618',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nWhich point sets admit a k-angulation?',
	 'urllink': u'http://arxiv.org/abs/1203.3618'}
2015-03-24 00:19:54+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.5192> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:19:54+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.5192>
	{'abstract': u"A classical result of Robertson and Seymour states that the set of graphs containing a fixed planar graph as a minor has the so-called Erd Hs-P 'osa property; namely, there exists a function depending only on such that, for every graph and every positive integer , the graph has vertex-disjoint subgraphs each containing as a minor, or there exists a subset of vertices of with such that has no -minor. While the best function currently known is exponential in , a bound is known in the special case where is a forest. This is a consequence of a theorem of Bienstock, Robertson, Seymour, and Thomas on the pathwidth of graphs with an excluded forest-minor. In this paper we show that the function can be taken to be linear when is a forest. This is best possible in the sense that no linear bound is possible if has a cycle.",
	 'authors': u'Samuel Fiorini, Gwena\xebl Joret, David R. Wood,',
	 'category': u'Computer Science ',
	 'date': '2012-4-23',
	 'pdflink': u'http://arxiv.org/pdf/1204.5192',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nExcluded Forest Minors and the Erd\u0151s-P\xf3sa Property',
	 'urllink': u'http://arxiv.org/abs/1204.5192'}
2015-03-24 00:20:10+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0361> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:20:10+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0361>
	{'abstract': u'Advancement in fundamental engineering aspects of software development enables IT enterprises to develop a more cost effective and better quality product through aptly organized defect management strategies. Inspection continues to be the most effective and efficient technique of defect management. To have an appropriate measurement of the inspection process, the process metric, Depth of Inspection (DI) and the people metric, Inspection Performance Metric (IPM) are introduced. The introduction of these pair of metrics can yield valuable information from a company in relation to the inspection process.',
	 'authors': u'T. R. Gopalakrishnan Nair, V Suma,',
	 'category': u'Computer Science ',
	 'date': '2012-6-2',
	 'pdflink': u'http://arxiv.org/pdf/1206.0361',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nDefect Management Using Depth of Inspection and the Inspection  Performance Metric',
	 'urllink': u'http://arxiv.org/abs/1206.0361'}
2015-03-24 00:20:20+0000 [xxu46_4] INFO: Crawled 609 pages (at 4 pages/min), scraped 603 items (at 4 items/min)
2015-03-24 00:20:25+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6651> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:20:25+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6651>
	{'abstract': u'The graph layouts used for complex network studies have been mainly been developed to improve visualization. If we interpret the layouts in metric spaces such as Euclidean ones, however, the embedded spatial information can be a valuable cue for various purposes. In this work, we focus on the navigational properties of spatial graphs. We use an recently user-centric navigation protocol to explore spatial layouts of complex networks that are optimal for navigation. These layouts are generated with a simple simulated annealing optimization technique. We compared these layouts to others targeted at better visualization. We discuss the spatial statistical properties of the optimized layouts for better navigability and its implication.',
	 'authors': u'Sang Hoon Lee, Petter Holme,',
	 'category': u'Computer Science ',
	 'date': '2012-6-28',
	 'pdflink': u'http://arxiv.org/pdf/1206.6651',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nGeometric properties of graph layouts optimized for greedy navigation',
	 'urllink': u'http://arxiv.org/abs/1206.6651'}
2015-03-24 00:20:42+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.2585> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:20:42+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.2585>
	{'abstract': u"Option contracts are a type of financial derivative that allow investors to hedge risk and speculate on the variation of an asset's future market price. In short, an option has a particular payout that is based on the market price for an asset on a given date in the future. In 1973, Black and Scholes proposed a valuation model for options that essentially estimates the tail risk of the asset price under the assumption that the price will fluctuate according to geometric Brownian motion. More recently, DeMarzo et al., among others, have proposed more robust valuation schemes, where we can even assume an adversary chooses the price fluctuations. This framework can be considered as a sequential two-player zero-sum game between the investor and Nature. We analyze the value of this game in the limit, where the investor can trade at smaller and smaller time intervals. Under weak assumptions on the actions of Nature (an adversary), we show that the minimax option price asymptotically approaches exactly the Black-Scholes valuation. The key piece of our analysis is showing that Nature's minimax optimal dual strategy converges to geometric Brownian motion in the limit.",
	 'authors': u'Jacob Abernethy, Rafael M. Frongillo, Andre Wibisono,',
	 'category': u'Computer Science ',
	 'date': '2012-2-12',
	 'pdflink': u'http://arxiv.org/pdf/1202.2585',
	 'subjects': u'Computational Finance (q-fin.CP)',
	 'title': u'\nMinimax Option Pricing Meets Black-Scholes in the Limit',
	 'urllink': u'http://arxiv.org/abs/1202.2585'}
2015-03-24 00:20:58+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.3606> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:20:58+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.3606>
	{'abstract': u'We prove that every graph of rank-width is a pivot-minor of a graph of tree-width at most . We also prove that graphs of rank-width at most 1, equivalently distance-hereditary graphs, are exactly vertex-minors of trees, and graphs of linear rank-width at most 1 are precisely vertex-minors of paths. In addition, we show that bipartite graphs of rank-width at most 1 are exactly pivot-minors of trees and bipartite graphs of linear rank-width at most 1 are precisely pivot-minors of paths.',
	 'authors': u'O-joung Kwon, Sang-il Oum,',
	 'category': u'Computer Science ',
	 'date': '2012-3-16',
	 'pdflink': u'http://arxiv.org/pdf/1203.3606',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nGraphs of Small Rank-width are Pivot-minors of Graphs of Small  Tree-width',
	 'urllink': u'http://arxiv.org/abs/1203.3606'}
2015-03-24 00:21:15+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.5074> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:21:15+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.5074>
	{'abstract': u'In this note we construct an explicit optimal (negative-weight) adversary matrix for the element distinctness problem, given that the size of the alphabet is sufficiently large.',
	 'authors': u'Aleksandrs Belovs,',
	 'category': u'Computer Science ',
	 'date': '2012-4-23',
	 'pdflink': u'http://arxiv.org/pdf/1204.5074',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nAdversary Lower Bound for Element Distinctness',
	 'urllink': u'http://arxiv.org/abs/1204.5074'}
2015-03-24 00:21:20+0000 [xxu46_4] INFO: Crawled 613 pages (at 4 pages/min), scraped 607 items (at 4 items/min)
2015-03-24 00:21:23+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0357> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:21:23+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0357>
	{'abstract': u"This paper provides an induction rule that can be used to prove properties of data structures whose types are inductive, i.e., are carriers of initial algebras of functors. Our results are semantic in nature and are inspired by Hermida and Jacobs' elegant algebraic formulation of induction for polynomial data types. Our contribution is to derive, under slightly different assumptions, a sound induction rule that is generic over all inductive types, polynomial or not. Our induction rule is generic over the kinds of properties to be proved as well: like Hermida and Jacobs, we work in a general fibrational setting and so can accommodate very general notions of properties on inductive types rather than just those of a particular syntactic form. We establish the soundness of our generic induction rule by reducing induction to iteration. We then show how our generic induction rule can be instantiated to give induction rules for the data types of rose trees, finite hereditary sets, and hyperfunctions. The first of these lies outside the scope of Hermida and Jacobs' work because it is not polynomial, and as far as we are aware, no induction rules have been known to exist for the second and third in a general fibrational framework. Our instantiation for hyperfunctions underscores the value of working in the general fibrational setting since this data type cannot be interpreted as a set.",
	 'authors': u'Neil Ghani, Patricia Johann, Clement Fumex,',
	 'category': u'Computer Science ',
	 'date': '2012-6-2',
	 'pdflink': u'http://arxiv.org/pdf/1206.0357',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nGeneric Fibrational Induction',
	 'urllink': u'http://arxiv.org/abs/1206.0357'}
2015-03-24 00:21:38+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6648> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:21:38+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6648>
	{'abstract': u'In this paper we propose an approach to the implementation of controllers with decentralized strategies triggering controller updates. We consider set-ups with a central node in charge of the computation of the control commands, and a set of not co-located sensors providing measurements to the controller node. The solution we propose does not require measurements from the sensors to be synchronized in time. The sensors in our proposal provide measurements in an aperiodic way triggered by local conditions. Furthermore, in the proposed implementation (most of) the communication between nodes requires only the exchange of one bit of information (per controller update), which could aid in reducing transmission delays and as a secondary effect result in fewer transmissions being triggered.',
	 'authors': u'Manuel Mazo Jr, Ming Cao,',
	 'category': u'Computer Science ',
	 'date': '2012-6-28',
	 'pdflink': u'http://arxiv.org/pdf/1206.6648',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nAsynchronous Decentralized Event-triggered Control',
	 'urllink': u'http://arxiv.org/abs/1206.6648'}
2015-03-24 00:21:54+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.2577> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:21:54+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.2577>
	{'abstract': u'The contributions of everyday individuals to significant research has grown dramatically beyond the early days of classical birdwatching and endeavors of amateurs of the 19th century. Now people who are casually interested in science can participate directly in research covering diverse scientific fields. Regarding astronomy, volunteers, either as individuals or as networks of people, are involved in a variety of types of studies. Citizen Science is intuitive, engaging, yet necessarily robust in its adoption of sci-entific principles and methods. Herein, we discuss Citizen Science, focusing on fully participatory projects such as Zooniverse (by several of the au-thors CL, AS, LF, SB), with mention of other programs. In particular, we make the case that citizen science (CS) can be an important aspect of the scientific data analysis pipelines provided to scientists by observatories.',
	 'authors': u'Carol Christian, Chris Lintott, Arfon Smith, Lucy Fortson, Steven Bamford,',
	 'category': u'Computer Science ',
	 'date': '2012-2-12',
	 'pdflink': u'http://arxiv.org/pdf/1202.2577',
	 'subjects': u'Instrumentation and Methods for Astrophysics (astro-ph.IM)',
	 'title': u'\nCitizen Science: Contributions to Astronomy Research',
	 'urllink': u'http://arxiv.org/abs/1202.2577'}
2015-03-24 00:22:08+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.3524> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:22:08+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.3524>
	{'abstract': u'Gaussian processes (GP) are attractive building blocks for many probabilistic models. Their drawbacks, however, are the rapidly increasing inference time and memory requirement alongside increasing data. The problem can be alleviated with compactly supported (CS) covariance functions, which produce sparse covariance matrices that are fast in computations and cheap to store. CS functions have previously been used in GP regression but here the focus is in a classification problem. This brings new challenges since the posterior inference has to be done approximately. We utilize the expectation propagation algorithm and show how its standard implementation has to be modified to obtain computational benefits from the sparse covariance matrices. We study four CS covariance functions and show that they may lead to substantial speed up in the inference time compared to globally supported functions.',
	 'authors': u'Jarno Vanhatalo, Aki Vehtari,',
	 'category': u'Computer Science ',
	 'date': '2012-3-15',
	 'pdflink': u'http://arxiv.org/pdf/1203.3524',
	 'subjects': u'Machine Learning (stat.ML)',
	 'title': u'\nSpeeding up the binary Gaussian process classification',
	 'urllink': u'http://arxiv.org/abs/1203.3524'}
2015-03-24 00:22:20+0000 [xxu46_4] INFO: Crawled 617 pages (at 4 pages/min), scraped 611 items (at 4 items/min)
2015-03-24 00:22:25+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.5043> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:22:25+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.5043>
	{'abstract': u'We derive a novel norm that corresponds to the tightest convex relaxation of sparsity combined with an penalty. We show that this new provides a tighter relaxation than the elastic net and is thus a good replacement for the Lasso or the elastic net in sparse prediction problems. Through the study of the -support norm, we also bound the looseness of the elastic net, thus shedding new light on it and providing justification for its use.',
	 'authors': u'Andreas Argyriou, Rina Foygel, Nathan Srebro,',
	 'category': u'Computer Science ',
	 'date': '2012-4-23',
	 'pdflink': u'http://arxiv.org/pdf/1204.5043',
	 'subjects': u'Machine Learning (stat.ML)',
	 'title': u'\nSparse Prediction with the $k$-Support Norm',
	 'urllink': u'http://arxiv.org/abs/1204.5043'}
2015-03-24 00:22:41+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0338> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:22:41+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0338>
	{'abstract': u'Photon-limited imaging arises when the number of photons collected by a sensor array is small relative to the number of detector elements. Photon limitations are an important concern for many applications such as spectral imaging, night vision, nuclear medicine, and astronomy. Typically a Poisson distribution is used to model these observations, and the inherent heteroscedasticity of the data combined with standard noise removal methods yields significant artifacts. This paper introduces a novel denoising algorithm for photon-limited images which combines elements of dictionary learning and sparse patch-based representations of images. The method employs both an adaptation of Principal Component Analysis (PCA) for Poisson noise and recently developed sparsity-regularized convex optimization algorithms for photon-limited images. A comprehensive empirical evaluation of the proposed method helps characterize the performance of this approach relative to other state-of-the-art denoising methods. The results reveal that, despite its conceptual simplicity, Poisson PCA-based denoising appears to be highly competitive in very low light regimes.',
	 'authors': u'Joseph Salmon, Zachary Harmany, Charles-Alban Deledalle, Rebecca Willett,',
	 'category': u'Computer Science ',
	 'date': '2012-6-2',
	 'pdflink': u'http://arxiv.org/pdf/1206.0338',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nPoisson noise reduction with non-local PCA',
	 'urllink': u'http://arxiv.org/abs/1206.0338'}
2015-03-24 00:22:59+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6605> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:22:59+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6605>
	{'abstract': u'We introduce a variant of the cover time of a graph, called cover cost, in which the cost of a step is proportional to the number of yet uncovered vertices. It turns out that cover cost is more tractable than cover time; we provide an algorithm for its computation, as well as some explicit formulae. The two values are not very far from each other, and so cover cost might be a useful tool in the study of cover time.',
	 'authors': u'Agelos Georgakopoulos,',
	 'category': u'Computer Science ',
	 'date': '2012-6-28',
	 'pdflink': u'http://arxiv.org/pdf/1206.6605',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nA Tractable Variant of Cover Time',
	 'urllink': u'http://arxiv.org/abs/1206.6605'}
2015-03-24 00:23:17+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.2564> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:23:17+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.2564>
	{'abstract': u'The area under the ROC curve is widely used as a measure of performance of classification rules. However, it has recently been shown that the measure is fundamentally incoherent, in the sense that it treats the relative severities of misclassifications differently when different classifiers are used. To overcome this, Hand (2009) proposed the measure, which allows a given researcher to fix the distribution of relative severities to a classifier-independent setting on a given problem. This note extends the discussion, and proposes a modified standard distribution for the measure, which better matches the requirements of researchers, in particular those faced with heavily unbalanced datasets, the distribution. [Preprint submitted at Pattern Recognition Letters]',
	 'authors': u'David J. Hand, Christoforos Anagnostopoulos,',
	 'category': u'Computer Science ',
	 'date': '2012-2-12',
	 'pdflink': u'http://arxiv.org/pdf/1202.2564',
	 'subjects': u'Methodology (stat.ME)',
	 'title': u'\nA better Beta for the H measure of classification performance',
	 'urllink': u'http://arxiv.org/abs/1202.2564'}
2015-03-24 00:23:20+0000 [xxu46_4] INFO: Crawled 621 pages (at 4 pages/min), scraped 615 items (at 4 items/min)
2015-03-24 00:23:33+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.3515> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:23:33+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.3515>
	{'abstract': u'Identifying effects of actions (treatments) on outcome variables from observational data and causal assumptions is a fundamental problem in causal inference. This identification is made difficult by the presence of confounders which can be related to both treatment and outcome variables. Confounders are often handled, both in theory and in practice, by adjusting for covariates, in other words considering outcomes conditioned on treatment and covariate values, weighed by probability of observing those covariate values. In this paper, we give a complete graphical criterion for covariate adjustment, which we term the adjustment criterion, and derive some interesting corollaries of the completeness of this criterion.',
	 'authors': u'Ilya Shpitser, Tyler VanderWeele, James M. Robins,',
	 'category': u'Computer Science ',
	 'date': '2012-3-15',
	 'pdflink': u'http://arxiv.org/pdf/1203.3515',
	 'subjects': u'Methodology (stat.ME)',
	 'title': u'\nOn the Validity of Covariate Adjustment for Estimating Causal Effects',
	 'urllink': u'http://arxiv.org/abs/1203.3515'}
2015-03-24 00:23:51+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.5001> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:23:51+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.5001>
	{'abstract': u'In this correspondence information theoretical tools are used to investigate the statistical properties of modeled cochlear nucleus globular bushy cell spike trains. The firing patterns are obtained from a simulation software that generates sample spike trains from any auditory input. Here we analyze for the first time the responses of globular bushy cells to voiced and unvoiced speech sounds. Classical entropy estimates, such as the direct method, are improved upon by considering a time-varying and time-dependent entropy estimate. With this method we investigated the relationship between the predictability of the neuronal response and the frequency content in the auditory signals. The analysis quantifies the temporal precision of the neuronal coding and the memory in the neuronal response.',
	 'authors': u'Andrea Grigorescu, Marek Rudnicki, Michael Isik, Werner Hemmert, Stefano Rini,',
	 'category': u'Computer Science ',
	 'date': '2012-4-23',
	 'pdflink': u'http://arxiv.org/pdf/1204.5001',
	 'subjects': u'Neurons and Cognition (q-bio.NC)',
	 'title': u'\nImproving the Entropy Estimate of Neuronal Firings of Modeled Cochlear  Nucleus Neurons',
	 'urllink': u'http://arxiv.org/abs/1204.5001'}
2015-03-24 00:24:09+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0335> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:24:09+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0335>
	{'abstract': u'Hierarchical Text Categorization (HTC) is becoming increasingly important with the rapidly growing amount of text data available in the World Wide Web. Among the different strategies proposed to cope with HTC, the Local Classifier per Node (LCN) approach attains good performance by mirroring the underlying class hierarchy while enforcing a top-down strategy in the testing step. However, the problem of embedding hierarchical information (parent-child relationship) to improve the performance of HTC systems still remains open. A confidence evaluation method for a selected route in the hierarchy is proposed to evaluate the reliability of the final candidate labels in an HTC system. In order to take into account the information embedded in the hierarchy, weight factors are used to take into account the importance of each level. An acceptance/rejection strategy in the top-down decision making process is proposed, which improves the overall categorization accuracy by rejecting a few percentage of samples, i.e., those with low reliability score. Experimental results on the Reuters benchmark dataset (RCV1- v2) confirm the effectiveness of the proposed method, compared to other state-of-the art HTC methods.',
	 'authors': u'Nima Hatami, Camelia Chira, Giuliano Armano,',
	 'category': u'Computer Science ',
	 'date': '2012-6-2',
	 'pdflink': u'http://arxiv.org/pdf/1206.0335',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nA Route Confidence Evaluation Method for Reliable Hierarchical Text  Categorization',
	 'urllink': u'http://arxiv.org/abs/1206.0335'}
2015-03-24 00:24:20+0000 [xxu46_4] INFO: Crawled 624 pages (at 3 pages/min), scraped 618 items (at 3 items/min)
2015-03-24 00:24:24+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6588> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:24:24+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6588>
	{'abstract': u'Quantitative study of collective dynamics in online social networks is a new challenge based on the abundance of empirical data. Conclusions, however, may depend on factors as user\'s psychology profiles and their reasons to use the online contacts. In this paper we have compiled and analyzed two datasets from texttt. The data contain networked dialogs occurring within a specified time depth, high temporal resolution, and texts of messages, in which the emotion valence is assessed by using SentiStrength classifier. Performing a comprehensive analysis we obtain three groups of results: Dynamic topology of the dialogs-based networks have characteristic structure with Zipf\'s distribution of communities, low link reciprocity, and disassortative correlations. Overlaps supporting "weak-ties" hypothesis are found to follow the laws recently conjectured for online games. Long-range temporal correlations and persistent fluctuations occur in the time series of messages carrying positive (negative) emotion. Patterns of user communications have dominant positive emotion (attractiveness) and strong impact of circadian cycles and nteractivity times longer than one day. Taken together, these results give a new insight into functioning of the online social networks and unveil importance of the amount of information and emotion that is communicated along the social links. (All data used in this study are fully anonymized.)',
	 'authors': u'Milovan Suvakov, Marija Mitrovic, Vladimir Gligorijevic, Bosiljka Tadic,',
	 'category': u'Computer Science ',
	 'date': '2012-6-28',
	 'pdflink': u'http://arxiv.org/pdf/1206.6588',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nHow the online social networks are used: Dialogs-based structure of  MySpace',
	 'urllink': u'http://arxiv.org/abs/1206.6588'}
2015-03-24 00:24:39+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.2518> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:24:39+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.2518>
	{'abstract': u"This paper presents a novel method to segment/decode DNA sequences based on n-grams statistical language model. Firstly, we find the length of most DNA 'words' is 12 to 15 bps by analyzing the genomes of 12 model species. Then we design an unsupervised probability based approach to segment the DNA sequences. The benchmark of segmenting method is also proposed.",
	 'authors': u'Wang Liang,',
	 'category': u'Computer Science ',
	 'date': '2012-2-12',
	 'pdflink': u'http://arxiv.org/pdf/1202.2518',
	 'subjects': u'Genomics (q-bio.GN)',
	 'title': u"\nSegmenting DNA sequence into `words'",
	 'urllink': u'http://arxiv.org/abs/1202.2518'}
2015-03-24 00:24:56+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.3505> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:24:56+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.3505>
	{'abstract': u'The paper provides a simple test for deciding, from a given causal diagram, whether two sets of variables have the same bias-reducing potential under adjustment. The test requires that one of the following two conditions holds: either (1) both sets are admissible (i.e., satisfy the back-door criterion) or (2) the Markov boundaries surrounding the manipulated variable(s) are identical in both sets. Applications to covariate selection and model testing are discussed.',
	 'authors': u'Judea Pearl, Azaria Paz,',
	 'category': u'Computer Science ',
	 'date': '2012-3-15',
	 'pdflink': u'http://arxiv.org/pdf/1203.3505',
	 'subjects': u'Methodology (stat.ME)',
	 'title': u'\nConfounding Equivalence in Causal Inference',
	 'urllink': u'http://arxiv.org/abs/1203.3505'}
2015-03-24 00:25:14+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.4928> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:25:14+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.4928>
	{'abstract': u'FuturICT foundations are social science, complex systems science, and ICT. The main concerns and challenges in the science of complex systems in the context of FuturICT are laid out in this paper with special emphasis on the Complex Systems route to Social Sciences. This include complex systems having: many heterogeneous interacting parts; multiple scales; complicated transition laws; unexpected or unpredicted emergence; sensitive dependence on initial conditions; path-dependent dynamics; networked hierarchical connectivities; interaction of autonomous agents; self-organisation; non-equilibrium dynamics; combinatorial explosion; adaptivity to changing environments; co-evolving subsystems; ill-defined boundaries; and multilevel dynamics. In this context, science is seen as the process of abstracting the dynamics of systems from data. This presents many challenges including: data gathering by large-scale experiment, participatory sensing and social computation, managing huge distributed dynamic and heterogeneous databases; moving from data to dynamical models, going beyond correlations to cause-effect relationships, understanding the relationship between simple and comprehensive models with appropriate choices of variables, ensemble modeling and data assimilation, modeling systems of systems of systems with many levels between micro and macro; and formulating new approaches to prediction, forecasting, and risk, especially in systems that can reflect on and change their behaviour in response to predictions, and systems whose apparently predictable behaviour is disrupted by apparently unpredictable rare or extreme events. These challenges are part of the FuturICT agenda.',
	 'authors': u'Maxi San Miguel, Jeffrey H. Johnson, Janos Kertesz, Kimmo Kaski, Albert D\xedaz-Guilera, Robert S. MacKay, Vittorio Loreto, Peter Erdi, Dirk Helbing,',
	 'category': u'Computer Science ',
	 'date': '2012-4-22',
	 'pdflink': u'http://arxiv.org/pdf/1204.4928',
	 'subjects': u'Adaptation and Self-Organizing Systems (nlin.AO)',
	 'title': u'\nChallenges in Complex Systems Science',
	 'urllink': u'http://arxiv.org/abs/1204.4928'}
2015-03-24 00:25:20+0000 [xxu46_4] INFO: Crawled 628 pages (at 4 pages/min), scraped 622 items (at 4 items/min)
2015-03-24 00:25:24+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0333> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:25:24+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0333>
	{'abstract': u'We study the problem of estimating multiple predictive functions from a dictionary of basis functions in the nonparametric regression setting. Our estimation scheme assumes that each predictive function can be estimated in the form of a linear combination of the basis functions. By assuming that the coefficient matrix admits a sparse low-rank structure, we formulate the function estimation problem as a convex program regularized by the trace norm and the -norm simultaneously. We propose to solve the convex program using the accelerated gradient (AG) method and the alternating direction method of multipliers (ADMM) respectively; we also develop efficient algorithms to solve the key components in both AG and ADMM. In addition, we conduct theoretical analysis on the proposed function estimation scheme: we derive a key property of the optimal solution to the convex program; based on an assumption on the basis functions, we establish a performance bound of the proposed function estimation scheme (via the composite regularization). Simulation studies demonstrate the effectiveness and efficiency of the proposed algorithms.',
	 'authors': u'Jianhui Chen, Jieping Ye,',
	 'category': u'Computer Science ',
	 'date': '2012-6-2',
	 'pdflink': u'http://arxiv.org/pdf/1206.0333',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nSparse Trace Norm Regularization',
	 'urllink': u'http://arxiv.org/abs/1206.0333'}
2015-03-24 00:25:41+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6573> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:25:41+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6573>
	{'abstract': u'We introduce a variant of Dependence Logic in which truth is defined not in terms of existence of winning strategies for the Proponent (Eloise) in a semantic game, but in terms of lack of winning strategies for the Opponent (Abelard). We show that this language is a conservative but paraconsistent extension of First Order Logic, that its validity problem can be reduced to that of First Order Logic, that it capable of expressing its own truth and validity predicates, and that it is expressively equivalent to Universal Second Order Logic. Furthermore, we prove that a Paraconsistent Non-dependence Logic formula is consistent if and only if it is equivalent to some First Order Logic sentence; and we show that, on the other hand, all Paraconsistent Dependence Logic sentences are equivalent to some First Order sentence with respect to truth (but not necessarily with respect to falsity).',
	 'authors': u'Pietro Galliani,',
	 'category': u'Computer Science ',
	 'date': '2012-6-28',
	 'pdflink': u'http://arxiv.org/pdf/1206.6573',
	 'subjects': u'Logic (math.LO)',
	 'title': u'\nDialetheism, Game Theoretic Semantics, and Paraconsistent Team Semantics',
	 'urllink': u'http://arxiv.org/abs/1206.6573'}
2015-03-24 00:25:58+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.2468> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:25:58+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.2468>
	{'abstract': u'To analyze whole-genome genetic data inherited in families, the likelihood is typically obtained from a Hidden Markov Model (HMM) having a state space of 2^n hidden states where n is the number of meioses or edges in the pedigree. There have been several attempts to speed up this calculation by reducing the state-space of the HMM. One of these methods has been automated in a calculation that is more efficient than the naive HMM calculation; however, that method treats a special case and the efficiency gain is available for only those rare pedigrees containing long chains of single-child lineages. The other existing state-space reduction method treats the general case, but the existing algorithm has super-exponential running time. We present three formulations of the state-space reduction problem, two dealing with groups and one with partitions. One of these problems, the maximum isometry group problem was discussed in detail by Browning and Browning. We show that for pedigrees, all three of these problems have identical solutions. Furthermore, we are able to prove the uniqueness of the solution using the algorithm that we introduce. This algorithm leverages the insight provided by the equivalence between the partition and group formulations of the problem to quickly find the optimal state-space reduction for general pedigrees. We propose a new likelihood calculation which is a two-stage process: find the optimal state-space, then run the HMM forward-backward algorithm on the optimal state-space. In comparison with the one-stage HMM calculation, this new method more quickly calculates the exact pedigree likelihood.',
	 'authors': u'Bonnie Kirkpatrick, Kay Kirkpatrick,',
	 'category': u'Computer Science ',
	 'date': '2012-2-11',
	 'pdflink': u'http://arxiv.org/pdf/1202.2468',
	 'subjects': u'Probability (math.PR)',
	 'title': u'\nOptimal State-Space Reduction for Pedigree Hidden Markov Models',
	 'urllink': u'http://arxiv.org/abs/1202.2468'}
2015-03-24 00:26:13+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.3504> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:26:13+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.3504>
	{'abstract': u'This paper addresses the problem of measurement errors in causal inference and highlights several algebraic and graphical methods for eliminating systematic bias induced by such errors. In particulars, the paper discusses the control of partially observable confounders in parametric and non parametric models and the computational problem of obtaining bias-free effect estimates in such models.',
	 'authors': u'Judea Pearl,',
	 'category': u'Computer Science ',
	 'date': '2012-3-15',
	 'pdflink': u'http://arxiv.org/pdf/1203.3504',
	 'subjects': u'Methodology (stat.ME)',
	 'title': u'\nOn Measurement Bias in Causal Inference',
	 'urllink': u'http://arxiv.org/abs/1203.3504'}
2015-03-24 00:26:20+0000 [xxu46_4] INFO: Crawled 632 pages (at 4 pages/min), scraped 626 items (at 4 items/min)
2015-03-24 00:26:31+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.4906> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:26:31+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.4906>
	{'abstract': u"We show that the problem `whether a finite set of regular-linear axioms defines a rigid theory' is undecidable.",
	 'authors': u'Miko\\laj Bojanczyk, Stanis\\law Szawiel, Marek Zawadowski,',
	 'category': u'Computer Science ',
	 'date': '2012-4-22',
	 'pdflink': u'http://arxiv.org/pdf/1204.4906',
	 'subjects': u'Logic (math.LO)',
	 'title': u'\nRigidity is undecidable',
	 'urllink': u'http://arxiv.org/abs/1204.4906'}
2015-03-24 00:26:46+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0323> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:26:46+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0323>
	{'abstract': u'Cooperative vehicle safety (CVS) systems operate based on broadcast of vehicle position and safety information to neighboring cars. The communication medium of CVS is a vehicular ad-hoc network. One of the main challenges in large scale deployment of CVS systems is the issue of scalability. To address the scalability problem, several congestion control methods have been proposed and are currently under field study. These algorithms adapt transmission rate and power based on network measures such as channel busy ratio. We examine two such algorithms and study their dynamic behavior in time and space to evaluate stability (in time) and fairness (in space) properties of these algorithms. We present stability conditions and evaluate stability and fairness of the algorithms through simulation experiments. Results show that there is a trade-off between fast convergence, temporal stability and spatial fairness. The proper ranges of parameters for achieving stability are presented for the discussed algorithms. Stability is verified for all typical road density cases. Fairness is shown to be naturally achieved for some algorithms, while under the same conditions other algorithms may suffer from unfairness issues. A method for resolving unfairness is introduced and evaluated through simulations.',
	 'authors': u'Neda Nasiriani, Yaser P. Fallah, Hariharan Krishnan,',
	 'category': u'Computer Science ',
	 'date': '2012-6-1',
	 'pdflink': u'http://arxiv.org/pdf/1206.0323',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nFairness and Stability Analysis of Congestion Control Schemes in  Vehicular Ad-hoc Networks',
	 'urllink': u'http://arxiv.org/abs/1206.0323'}
2015-03-24 00:27:03+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6570> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:27:03+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6570>
	{'abstract': u'The extension of counterfactual causal graphic model with three variables of vertex set in directed acyclic graph (DAG) is discussed in this paper by extending two- value distribution to three-value distribution of the variables involved in DAG. Using the conditional independence as ancillary information, 6 kinds of extension counterfactual causal graphic models with some variables are extended from two-value distribution to three-value distribution and the sufficient conditions of identifiability are derived.',
	 'authors': u'Jingwei Liu,',
	 'category': u'Computer Science ',
	 'date': '2012-6-28',
	 'pdflink': u'http://arxiv.org/pdf/1206.6570',
	 'subjects': u'Methodology (stat.ME)',
	 'title': u'\nExtension of Three-Variable Counterfactual Casual Graphic Model: from  Two-Value to Three-Value Random Variable',
	 'urllink': u'http://arxiv.org/abs/1206.6570'}
2015-03-24 00:27:15+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.2439> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:27:15+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.2439>
	{'abstract': u"We introduce and analyze a random tree model associated to Hoppe's urn. The tree is built successively by adding nodes to the existing tree when starting with the single root node. In each step a node is added to the tree as a child of an existing node where these parent nodes are chosen randomly with probabilities proportional to their weights. The root node has weight , a given fixed parameter, all other nodes have weight 1. This resembles the stochastic dynamic of Hoppe's urn. For the resulting tree is the well-studied random recursive tree. We analyze the height, internal path length and number of leaves of the Hoppe tree with nodes as well as the depth of the last inserted node asymptotically as . Mainly expectations, variances and asymptotic distributions of these parameters are derived.",
	 'authors': u'Kevin Leckey, Ralph Neininger,',
	 'category': u'Computer Science ',
	 'date': '2012-2-11',
	 'pdflink': u'http://arxiv.org/pdf/1202.2439',
	 'subjects': u'Probability (math.PR)',
	 'title': u'\nAsymptotic analysis of Hoppe trees',
	 'urllink': u'http://arxiv.org/abs/1202.2439'}
2015-03-24 00:27:20+0000 [xxu46_4] INFO: Crawled 636 pages (at 4 pages/min), scraped 630 items (at 4 items/min)
2015-03-24 00:27:27+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.3503> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:27:27+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.3503>
	{'abstract': u'This note deals with a class of variables that, if conditioned on, tends to amplify confounding bias in the analysis of causal effects. This class, independently discovered by Bhattacharya and Vogt (2007) and Wooldridge (2009), includes instrumental variables and variables that have greater influence on treatment selection than on the outcome. We offer a simple derivation and an intuitive explanation of this phenomenon and then extend the analysis to non linear models. We show that: 1. the bias-amplifying potential of instrumental variables extends over to non-linear models, though not as sweepingly as in linear models; 2. in non-linear models, conditioning on instrumental variables may introduce new bias where none existed before; 3. in both linear and non-linear models, instrumental variables have no effect on selection-induced bias.',
	 'authors': u'Judea Pearl,',
	 'category': u'Computer Science ',
	 'date': '2012-3-15',
	 'pdflink': u'http://arxiv.org/pdf/1203.3503',
	 'subjects': u'Methodology (stat.ME)',
	 'title': u'\nOn a Class of Bias-Amplifying Variables that Endanger Effect Estimates',
	 'urllink': u'http://arxiv.org/abs/1203.3503'}
2015-03-24 00:27:41+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.4826> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:27:41+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.4826>
	{'abstract': u'We present an algorithm for the computation of the topological type of a real compact Riemann surface associated to an algebraic curve, i.e., its genus and the properties of the set of fixed points of the anti-holomorphic involution , namely, the number of its connected components, and whether this set divides the surface into one or two connected components. This is achieved by transforming an arbitrary canonical homology basis to a homology basis where the -cycles are invariant under the anti-holomorphic involution .',
	 'authors': u'C. Kalla, C. Klein,',
	 'category': u'Computer Science ',
	 'date': '2012-4-21',
	 'pdflink': u'http://arxiv.org/pdf/1204.4826',
	 'subjects': u'Algebraic Geometry (math.AG)',
	 'title': u'\nComputation of the topological type of a real Riemann surface',
	 'urllink': u'http://arxiv.org/abs/1204.4826'}
2015-03-24 00:27:56+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0305> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:27:56+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0305>
	{'abstract': u'Vehicular Ad hoc Networks is one of the most challenging research area in the field of Mobile Ad Hoc Networks, in this research We propose a flexible, simple, and scalable design for VANET certificates, and new methods for efficient certificate management, which will Reduce channel overhead by eliminating the use of CRL, and make Better certificate Revocation Management. Also it will increase the security of the network and helps in identifying the adversary vehicle.',
	 'authors': u'Ghassan Samara,',
	 'category': u'Computer Science ',
	 'date': '2012-6-1',
	 'pdflink': u'http://arxiv.org/pdf/1206.0305',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nEfficient Certificate Management in VANET',
	 'urllink': u'http://arxiv.org/abs/1206.0305'}
2015-03-24 00:28:11+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6528> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:28:11+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6528>
	{'abstract': u'We prove a tight quantum query lower bound for the problem of deciding whether there exist numbers among that sum up to a prescribed number, provided that the alphabet size is sufficiently large. This is an extended and simplified version of an earlier preprint of one of the authors arXiv:1204.5074.',
	 'authors': u'Aleksandrs Belovs, Robert Spalek,',
	 'category': u'Computer Science ',
	 'date': '2012-6-27',
	 'pdflink': u'http://arxiv.org/pdf/1206.6528',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nAdversary Lower Bound for the k-sum Problem',
	 'urllink': u'http://arxiv.org/abs/1206.6528'}
2015-03-24 00:28:20+0000 [xxu46_4] INFO: Crawled 640 pages (at 4 pages/min), scraped 634 items (at 4 items/min)
2015-03-24 00:28:29+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.2408> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:28:29+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.2408>
	{'abstract': u'This paper studies two spectrum estimation methods for the case that the samples are obtained at a rate lower than the Nyquist rate. The first method is the correlogram method for undersampled data. The algorithm partitions the spectrum into a number of segments and estimates the average power within each spectral segment. We derive the bias and the variance of the spectrum estimator, and show that there is a tradeoff between the accuracy of the estimation and the frequency resolution. The asymptotic behavior of the estimator is also investigated, and it is proved that this spectrum estimator is consistent. A new algorithm for reconstructing signals with sparse spectrum from noisy compressive measurements is also introduced. Such model-based algorithm takes the signal structure into account for estimating the unknown parameters which are the frequencies and the amplitudes of linearly combined sinusoidal signals. A high-resolution spectral estimation method is used to recover the frequencies of the signal elements, while the amplitudes of the signal components are estimated by minimizing the squared norm of the compressed estimation error using the least squares technique. The Cramer-Rao bound for the given system model is also derived. It is shown that the proposed algorithm approaches the bound at high signal to noise ratios.',
	 'authors': u'Mahdi Shaghaghi, Sergiy A. Vorobyov,',
	 'category': u'Computer Science ',
	 'date': '2012-2-11',
	 'pdflink': u'http://arxiv.org/e-print/1202.2408',
	 'subjects': u'Statistics Theory (math.ST)',
	 'title': u'\nSpectral Estimation from Undersampled Data: Correlogram and Model-Based  Least Squares',
	 'urllink': u'http://arxiv.org/abs/1202.2408'}
2015-03-24 00:28:44+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.3484> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:28:44+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.3484>
	{'abstract': u"This paper addresses the problem of sampling from binary distributions with constraints. In particular, it proposes an MCMC method to draw samples from a distribution of the set of all states at a specified distance from some reference state. For example, when the reference state is the vector of zeros, the algorithm can draw samples from a binary distribution with a constraint on the number of active variables, say the number of 1's. We motivate the need for this algorithm with examples from statistical physics and probabilistic inference. Unlike previous algorithms proposed to sample from binary distributions with these constraints, the new algorithm allows for large moves in state space and tends to propose them such that they are energetically favourable. The algorithm is demonstrated on three Boltzmann machines of varying difficulty: A ferromagnetic Ising model (with positive potentials), a restricted Boltzmann machine with learned Gabor-like filters as potentials, and a challenging three-dimensional spin-glass (with positive and negative potentials).",
	 'authors': u'Firas Hamze, Nando de Freitas,',
	 'category': u'Computer Science ',
	 'date': '2012-3-15',
	 'pdflink': u'http://arxiv.org/pdf/1203.3484',
	 'subjects': u'Computation (stat.CO)',
	 'title': u'\nIntracluster Moves for Constrained Discrete-Space MCMC',
	 'urllink': u'http://arxiv.org/abs/1203.3484'}
2015-03-24 00:28:56+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.4779> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:28:56+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.4779>
	{'abstract': u'We propose Paraiso, a domain specific language embedded in functional programming language Haskell, for automated tuning of explicit solvers of partial differential equations (PDEs) on GPUs as well as multicore CPUs. In Paraiso, one can describe PDE solving algorithms succinctly using tensor equations notation. Hydrodynamic properties, interpolation methods and other building blocks are described in abstract, modular, re-usable and combinable forms, which lets us generate versatile solvers from little set of Paraiso source codes. We demonstrate Paraiso by implementing a compressive hydrodynamics solver. A single source code less than 500 lines can be used to generate solvers of arbitrary dimensions, for both multicore CPUs and GPUs. We demonstrate both manual annotation based tuning and evolutionary computing based automated tuning of the program.',
	 'authors': u'Takayuki Muranushi,',
	 'category': u'Computer Science ',
	 'date': '2012-4-21',
	 'pdflink': u'http://arxiv.org/pdf/1204.4779',
	 'subjects': u'Instrumentation and Methods for Astrophysics (astro-ph.IM)',
	 'title': u'\nParaiso : An Automated Tuning Framework for Explicit Solvers of Partial  Differential Equations',
	 'urllink': u'http://arxiv.org/abs/1204.4779'}
2015-03-24 00:29:11+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0303> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:29:11+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0303>
	{'abstract': u'Given two combinatorial triangulations, how many edge flips are necessary and sufficient to convert one into the other? This question has occupied researchers for over 75 years. We provide a comprehensive survey, including full proofs, of the various attempts to answer it.',
	 'authors': u'Prosenjit Bose, Sander Verdonschot,',
	 'category': u'Computer Science ',
	 'date': '2012-6-1',
	 'pdflink': u'http://arxiv.org/pdf/1206.0303',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nA History of Flips in Combinatorial Triangulations',
	 'urllink': u'http://arxiv.org/abs/1206.0303'}
2015-03-24 00:29:20+0000 [xxu46_4] INFO: Crawled 644 pages (at 4 pages/min), scraped 638 items (at 4 items/min)
2015-03-24 00:29:22+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6361> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:29:22+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6361>
	{'abstract': u'In this paper, we present a simple non-parametric method for learning the structure of undirected graphs from data that drawn from an underlying unknown distribution. We propose to use Brownian distance covariance to estimate the conditional independences between the random variables and encodes pairwise Markov graph. This framework can be applied in high-dimensional setting, where the number of parameters much be larger than the sample size.',
	 'authors': u'Ehsan Khoshgnauz,',
	 'category': u'Computer Science ',
	 'date': '2012-6-27',
	 'pdflink': u'http://arxiv.org/pdf/1206.6361',
	 'subjects': u'Machine Learning (stat.ML)',
	 'title': u'\nLearning Markov Network Structure using Brownian Distance Covariance',
	 'urllink': u'http://arxiv.org/abs/1206.6361'}
2015-03-24 00:29:37+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.2283> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:29:37+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.2283>
	{'abstract': u'This paper demonstrates the quantization of a spatial Cournot duopoly model with product choice, a two stage game focusing on non-cooperation in locations and quantities. With quantization, the players can access a continuous set of strategies, using continuous variable quantum mechanical approach. The presence of quantum entanglement in the initial state identifies a quantity equilibrium for every location pair choice with any transport cost. Also higher profit is obtained by the firms at Nash equilibrium. Adoption of quantum strategies rewards us by the existence of a larger quantum strategic space at equilibrium.',
	 'authors': u'Ramij Rahaman, Priyadarshi Majumdar, B. Basu,',
	 'category': u'Computer Science ',
	 'date': '2012-2-10',
	 'pdflink': u'http://arxiv.org/pdf/1202.2283',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nQuantum Cournot equilibrium for the Hotelling-Smithies model of product  choice',
	 'urllink': u'http://arxiv.org/abs/1202.2283'}
2015-03-24 00:29:54+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.3479> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:29:54+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.3479>
	{'abstract': u'Acyclic directed mixed graphs, also known as semi-Markov models represent the conditional independence structure induced on an observed margin by a DAG model with latent variables. In this paper we present the first method for fitting these models to binary data using maximum likelihood estimation.',
	 'authors': u'Robin J. Evans, Thomas S. Richardson,',
	 'category': u'Computer Science ',
	 'date': '2012-3-15',
	 'pdflink': u'http://arxiv.org/pdf/1203.3479',
	 'subjects': u'Methodology (stat.ME)',
	 'title': u'\nMaximum likelihood fitting of acyclic directed mixed graphs to binary  data',
	 'urllink': u'http://arxiv.org/abs/1203.3479'}
2015-03-24 00:30:09+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.4763> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:30:09+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.4763>
	{'abstract': u"A new method for estimating Sobol' indices is proposed. The new method makes use of 3 independent input vectors rather than the usual 2. It attains much greater accuracy on problems where the target Sobol' index is small, even outperforming some oracles which adjust using the true but unknown mean of the function. When the target Sobol' index is quite large, the oracles do better than the new method.",
	 'authors': u'Art B. Owen,',
	 'category': u'Computer Science ',
	 'date': '2012-4-21',
	 'pdflink': u'http://arxiv.org/pdf/1204.4763',
	 'subjects': u'Methodology (stat.ME)',
	 'title': u"\nBetter estimation of small Sobol' sensitivity indices",
	 'urllink': u'http://arxiv.org/abs/1204.4763'}
2015-03-24 00:30:20+0000 [xxu46_4] INFO: Crawled 648 pages (at 4 pages/min), scraped 642 items (at 4 items/min)
2015-03-24 00:30:27+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0302> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:30:27+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0302>
	{'abstract': u'We carried out a qualitative study to identify the "missing pieces" in current computing devices and technologies that are preventing people from eliminating paper from their lives. Most of the existing literature has looked into the work practices of businesses, while a few have researched how high school and college students and teaching assistants at universities work with paper. We were speci?cally interested in analysing paper use for people in the research side of academia, and seeing how our results compare to existing work. We recruited and interviewed participants from academia to understand what kind of tasks they use paper for, what kind of tasks they use computing devices for and what motivates them to use these two media. We found that, despite having access to at least one personal computing device, the participants preferred to work with paper in many situations. This appears to be attributed to certain intrinsic qualities that paper has, such as open format, easy navigation, readability, and the aff?ordances these qualities provide. In order to eventually replace paper with devices, designers of new technology will have to successfully emulate these qualities.',
	 'authors': u'Joey Chakraborty,',
	 'category': u'Computer Science ',
	 'date': '2012-6-1',
	 'pdflink': u'http://arxiv.org/pdf/1206.0302',
	 'subjects': u'Human-Computer Interaction (cs.HC)',
	 'title': u'\nExamining Motivations behind Paper Usage in Academia',
	 'urllink': u'http://arxiv.org/abs/1206.0302'}
2015-03-24 00:30:41+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6352> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:30:41+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6352>
	{'abstract': u"Assessing the impact of astronomical facilities rests upon an evaluation of the scientific discoveries which their data have enabled. Telescope bibliographies, which link data products with the literature, provide a way to use bibliometrics as an impact measure for the underlying data. In this paper we argue that the creation and maintenance of telescope bibliographies should be considered an integral part of an observatory's operations. We review the existing tools, services, and workflows which support these curation activities, giving an estimate of the effort and expertise required to maintain an archive-based telescope bibliography.",
	 'authors': u'Alberto Accomazzi, Edwin Henneken, Christopher Erdmann, Arnold Rots,',
	 'category': u'Computer Science ',
	 'date': '2012-6-27',
	 'pdflink': u'http://arxiv.org/pdf/1206.6352',
	 'subjects': u'Instrumentation and Methods for Astrophysics (astro-ph.IM)',
	 'title': u'\nTelescope Bibliographies: an Essential Component of Archival Data  Management and Operations',
	 'urllink': u'http://arxiv.org/abs/1206.6352'}
2015-03-24 00:30:57+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.2143> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:30:57+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.2143>
	{'abstract': u'The ultimate goal of optimization is to find the minimizer of a target function.However, typical criteria for active optimization often ignore the uncertainty about the minimizer. We propose a novel criterion for global optimization and an associated sequential active learning strategy using Gaussian processes.Our criterion is the reduction of uncertainty in the posterior distribution of the function minimizer. It can also flexibly incorporate multiple global minimizers. We implement a tractable approximation of the criterion and demonstrate that it obtains the global minimizer accurately compared to conventional Bayesian optimization criteria.',
	 'authors': u'Il Memming Park, Marcel Nassar, Mijung Park,',
	 'category': u'Computer Science ',
	 'date': '2012-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1202.2143',
	 'subjects': u'Methodology (stat.ME)',
	 'title': u'\nActive Bayesian Optimization: Minimizing Minimizer Entropy',
	 'urllink': u'http://arxiv.org/abs/1202.2143'}
2015-03-24 00:31:05+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.3368> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:31:05+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.3368>
	{'abstract': u'A central theme in social choice theory is that of impossibility theorems, such as Arrow\'s theorem and the Gibbard-Satterthwaite theorem, which state that under certain natural constraints, social choice mechanisms are impossible to construct. In recent years, beginning in Kalai`01, much work has been done in finding textit versions of these theorems, showing "approximate" impossibility remains even when most, but not all, of the constraints are satisfied. We study a spectrum of settings between the case where society chooses a single outcome ( \'a-la-Gibbard-Satterthwaite) and the choice of a complete order (as in Arrow\'s theorem). We use algebraic techniques, specifically representation theory of the symmetric group, and also prove robust versions of the theorems that we state. Our relaxations of the constraints involve relaxing of a version of "independence of irrelevant alternatives", rather than relaxing the demand of a transitive outcome, as is done in most other robustness results.',
	 'authors': u'Dvir Falik, Ehud Friedgut,',
	 'category': u'Computer Science ',
	 'date': '2012-3-14',
	 'pdflink': u'http://arxiv.org/pdf/1203.3368',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nBetween Arrow and Gibbard-Satterthwaite; A representation theoretic  approach',
	 'urllink': u'http://arxiv.org/abs/1203.3368'}
2015-03-24 00:31:20+0000 [xxu46_4] INFO: Crawled 652 pages (at 4 pages/min), scraped 646 items (at 4 items/min)
2015-03-24 00:31:22+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.4753> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:31:22+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.4753>
	{'abstract': u"For a polytope P, the Chvatal closure P' is obtained by simultaneously strengthening all feasible inequalities cx &lt;= b (with integral c) to cx &lt;= floor(b). The number of iterations of this procedure that are needed until the integral hull of P is reached is called the Chvatal rank. If P is a subset of [0,1]^n, then it is known that O(n^2 log n) iterations always suffice (Eisenbrand and Schulz (1999)) and at least (1+1/e-o(1))n iterations are sometimes needed (Pokutta and Stauffer (2011)), leaving a huge gap between lower and upper bounds. We prove that there is a polytope contained in the 0/1 cube that has Chvatal rank Omega(n^2), closing the gap up to a logarithmic factor. In fact, even a superlinear lower bound was mentioned as an open problem by several authors. Our choice of P is the convex hull of a semi-random Knapsack polytope and a single fractional vertex. The main technical ingredient is linking the Chvatal rank to simultaneous Diophantine approximations w.r.t. the L1-norm of the normal vector defining P.",
	 'authors': u'Thomas Rothvoss, Laura Sanita,',
	 'category': u'Computer Science ',
	 'date': '2012-4-20',
	 'pdflink': u'http://arxiv.org/pdf/1204.4753',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\n0/1 Polytopes with Quadratic Chvatal Rank',
	 'urllink': u'http://arxiv.org/abs/1204.4753'}
2015-03-24 00:31:39+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0285> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:31:39+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0285>
	{'abstract': u'In this paper a novel approach for de noising images corrupted by random valued impulses has been proposed. Noise suppression is done in two steps. The detection of noisy pixels is done using all neighbor directional weighted pixels (ANDWP) in the 5 x 5 window. The filtering scheme is based on minimum variance of the four directional pixels. In this approach, relatively recent category of stochastic global optimization technique i.e., particle swarm optimization (PSO) has also been used for searching the parameters of detection and filtering operators required for optimal performance. Results obtained shows better de noising and preservation of fine details for highly corrupted images.',
	 'authors': u'J. K. Mandal, Somnath Mukhopadhyay,',
	 'category': u'Computer Science ',
	 'date': '2012-2-19',
	 'pdflink': u'http://arxiv.org/pdf/1206.0285',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nImage Filtering using All Neighbor Directional Weighted Pixels:  Optimization using Particle Swarm Optimization',
	 'urllink': u'http://arxiv.org/abs/1206.0285'}
2015-03-24 00:31:57+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6345> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:31:57+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6345>
	{'abstract': u"Let be a differential field and let be a linear differential system where . We say that is in a reduced form if where is the Lie algebra of and denotes the algebraic closure of . We owe the existence of such reduced forms to a result due to Kolchin and Kovacic cite. This paper is devoted to the study of reduced forms, of (higher order) variational equations along a particular solution of a complex analytical hamiltonian system . Using a previous result cite, we will assume that the first order variational equation has an abelian Lie algebra so that, at first order, there are no Galoisian obstructions to Liouville integrability. We give a strategy to (partially) reduce the variational equations at order if the variational equations at order are already in a reduced form and their Lie algebra is abelian. Our procedure stops when we meet obstructions to the meromorphic integrability of . We make strong use both of the lower block triangular structure of the variational equations and of the notion of associated Lie algebra of a linear differential system (based on the works of Wei and Norman in cite). Obstructions to integrability appear when at some step we obtain a non-trivial commutator between a diagonal element and a nilpotent (subdiagonal) element of the associated Lie algebra. We use our method coupled with a reasoning on polylogarithms to give a new and systematic proof of the non-integrability of the H 'enon-Heiles system. We conjecture that our method is not only a partial reduction procedure but a complete reduction algorithm. In the context of complex Hamiltonian systems, this would mean that our method would be an effective version of the Morales-Ramis-Sim 'o theorem.",
	 'authors': u'Ainhoa Aparicio, Jacques-Arthur Weil,',
	 'category': u'Computer Science ',
	 'date': '2012-6-27',
	 'pdflink': u'http://arxiv.org/pdf/1206.6345',
	 'subjects': u'Dynamical Systems (math.DS)',
	 'title': u'\nA Reduction Method for Higher Order Variational Equations of Hamiltonian  Systems',
	 'urllink': u'http://arxiv.org/abs/1206.6345'}
2015-03-24 00:32:13+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.2080> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:32:13+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.2080>
	{'abstract': u"A quantum financial approach to finite games of strategy is addressed, with an extension of Nash's theorem to the quantum financial setting, allowing for an entanglement of games of strategy with two-period financial allocation problems that are expressed in terms of: the consumption plans' optimization problem in pure exchange economies and the finite-state securities market optimization problem, thus addressing, within the financial setting, the interplay between companies' business games and financial agents' behavior. A complete set of quantum Arrow-Debreu prices, resulting from the game of strategy's quantum Nash equilibrium, is shown to hold, even in the absence of securities' market completeness, such that Pareto optimal results are obtained without having to assume the completeness condition that the rank of the securities' payoff matrix is equal to the number of alternative lottery states.",
	 'authors': u'Carlos Pedro Gon\xe7alves,',
	 'category': u'Computer Science ',
	 'date': '2012-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1202.2080',
	 'subjects': u'General Finance (q-fin.GN)',
	 'title': u'\nQuantum Financial Economics of Games of Strategy and Financial Decisions',
	 'urllink': u'http://arxiv.org/abs/1202.2080'}
2015-03-24 00:32:20+0000 [xxu46_4] INFO: Crawled 656 pages (at 4 pages/min), scraped 650 items (at 4 items/min)
2015-03-24 00:32:30+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.3341> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:32:30+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.3341>
	{'abstract': u'In recent years, the embedding approach for solving switched optimal control problems has been developed in a series of papers. However, the embedding approach, which advantageously converts the hybrid optimal control problem to a classical nonlinear optimization, has not been extensively compared to alternative solution approaches. The goal of this paper is thus to compare the embedding approach to multi-parametric programming, mixed-integer programming (e.g., CPLEX), and gradient-descent based methods in the context of five recently published examples: a spring-mass system, moving-target tracking for a mobile robot, two-tank filling, DC-DC boost converter, and skid-steered vehicle. A sixth example, an autonomous switched 11-region linear system, is used to compare a hybrid minimum principle method and traditional numerical programming. For a given performance index for each case, cost and solution times are presented. It is shown that there are numerical advantages of the embedding approach: lower performance index cost (except in some instances when autonomous switches are present), generally faster solution time, and convergence to a solution when other methods may fail. In addition, the embedding method requires no ad hoc assumptions (e.g., predetermined mode sequences) or specialized control models. Theoretical advantages of the embedding approach over the other methods are also described: guaranteed existence of a solution under mild conditions, convexity of the embedded hybrid optimization problem (under the customary conditions on the performance index), solvability with traditional techniques (e.g., sequential quadratic programming) avoiding the combinatorial complexity in the number of modes/discrete variables of mixed-integer programming, applicability to affine nonlinear systems, and no need to explicitly assign discrete/mode variables to autonomous switches.',
	 'authors': u'Richard Meyer, Milo\u0161 \u017defran, Raymond A. DeCarlo,',
	 'category': u'Computer Science ',
	 'date': '2012-3-15',
	 'pdflink': u'http://arxiv.org/pdf/1203.3341',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nA Comparison of the Embedding Method to Multi-Parametric Programming,  Mixed-Integer Programming, Gradient-Descent, and Hybrid Minimum Principle  Based Methods',
	 'urllink': u'http://arxiv.org/abs/1203.3341'}
2015-03-24 00:32:46+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.4717> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:32:46+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.4717>
	{'abstract': u'Improving the energy-efficiency of heating, ventilation, and air-conditioning (HVAC) systems has the potential to realize large economic and societal benefits. This paper concerns the system identification of a hybrid system model of a building-wide HVAC system and its subsequent control using a hybrid system formulation of learning-based model predictive control (LBMPC). Here, the learning refers to model updates to the hybrid system model that incorporate the heating effects due to occupancy, solar effects, outside air temperature (OAT), and equipment, in addition to integrator dynamics inherently present in low-level control. Though we make significant modeling simplifications, our corresponding controller that uses this model is able to experimentally achieve a large reduction in energy usage without any degradations in occupant comfort. It is in this way that we justify the modeling simplifications that we have made. We conclude by presenting results from experiments on our building HVAC testbed, which show an average of 1.5MWh of energy savings per day (p = 0.002) with a 95% confidence interval of 1.0MWh to 2.1MWh of energy savings.',
	 'authors': u'Anil Aswani, Neal Master, Jay Taneja, Andrew Krioukov, David Culler, Claire Tomlin,',
	 'category': u'Computer Science ',
	 'date': '2012-4-20',
	 'pdflink': u'http://arxiv.org/pdf/1204.4717',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nEnergy-Efficient Building HVAC Control Using Hybrid System LBMPC',
	 'urllink': u'http://arxiv.org/abs/1204.4717'}
2015-03-24 00:33:03+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0277> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:33:03+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0277>
	{'abstract': u'We consider the problem of designing optimal () sensing matrices which minimize the maximum condition number of all the submatrices of columns. Such matrices minimize the worst-case estimation errors when only sensors out of sensors are available for sensing at a given time. For M=2 and matrices with unit-normed columns, this problem is equivalent to the problem of maximizing the minimum singular value among all the submatrices of columns. For M=2, we are able to give a closed form formula for the condition number of the submatrices. When M=2 and K=3, for an arbitrary , we derive the optimal matrices which minimize the maximum condition number of all the submatrices of columns. Surprisingly, a uniformly distributed design is often emph the optimal design minimizing the maximum condition number.',
	 'authors': u'Hema Kumari Achanta, Soura Dasgupta, Weiyu Xu,',
	 'category': u'Computer Science ',
	 'date': '2012-6-1',
	 'pdflink': u'http://arxiv.org/pdf/1206.0277',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nSensing with Optimal Matrices',
	 'urllink': u'http://arxiv.org/abs/1206.0277'}
2015-03-24 00:33:12+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6323> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:33:12+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6323>
	{'abstract': u'In this paper, we demonstrate n-party controlled unitary gate implementations locally on arbitrary remote state through linear entangled channel where control parties share entanglement with the adjacent control parties and only one of them shares entanglement with the target party. In such a network, we describe the protocol of simultaneous implementation of controlled-Hermitian gate starting from three party scenario. We also explicate the implementation of three party controlled-Unitary gate, a generalized form of To?oli gate and subsequently generalize the protocol for n-party using minimal cost.',
	 'authors': u'Debashis Saha, Sanket Nandan, Prasanta K. Panigrahi,',
	 'category': u'Computer Science ',
	 'date': '2012-6-27',
	 'pdflink': u'http://arxiv.org/pdf/1206.6323',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nLocal implementations of non-local quantum gates in linear entangled  channel',
	 'urllink': u'http://arxiv.org/abs/1206.6323'}
2015-03-24 00:33:20+0000 [xxu46_4] INFO: Crawled 660 pages (at 4 pages/min), scraped 654 items (at 4 items/min)
2015-03-24 00:33:30+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.1882> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:33:30+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.1882>
	{'abstract': u'We study a basic sequential model for the discovery of winning coalitions in a simple game, well known from its use in defining the Shapley-Shubik power index. We derive in a uniform way a family of measures of collective and individual power in simple games, and show that, as for the Shapley-Shubik index, they extend naturally to measures for TU-games. In particular, the individual measures include all weighted semivalues. We single out the simplest measure in our family for more investigation, as it is new to the literature as far as we know. Although it is very different from the Shapley value, it is closely related in several ways, and is the natural analogue of the Shapley value under a nonstandard, but natural, definition of simple game. We illustrate this new measure by calculating its values on some standard examples.',
	 'authors': u'Geoffrey Pritchard, Reyhaneh Reyhani, Mark C. Wilson,',
	 'category': u'Computer Science ',
	 'date': '2012-2-9',
	 'pdflink': u'http://arxiv.org/pdf/1202.1882',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nPower measures derived from the sequential query process',
	 'urllink': u'http://arxiv.org/abs/1202.1882'}
2015-03-24 00:33:44+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.3274> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:33:44+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.3274>
	{'abstract': u'In this paper, we discuss a voting model with two candidates, C_0 and C_1. We consider two types of voters--herders and independents. The voting of independents is based on their fundamental values; on the other hand, the voting of herders is based on the number of previous votes. We can identify two kinds of phase transitions. One is an information cascade transition similar to a phase transition seen in Ising model. The other is a transition of super and normal diffusions. These phase transitions coexist. We compared our results to the conclusions of experiments and identified the phase transitions in the upper limit of the time t by using analysis of human behavior obtained from experiments.',
	 'authors': u'Masato Hisakado, Shintaro Mori,',
	 'category': u'Computer Science ',
	 'date': '2012-3-15',
	 'pdflink': u'http://arxiv.org/pdf/1203.3274',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nTwo kinds of Phase transitions in a Voting model',
	 'urllink': u'http://arxiv.org/abs/1203.3274'}
2015-03-24 00:33:56+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.4693> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:33:56+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.4693>
	{'abstract': u'We establish basic facts about the varieties of homogeneous polynomials divisible by powers of linear forms, and explain consequences for geometric complexity theory. This includes quadratic set-theoretic equations, a description of the ideal in terms of the kernel of a linear map that generalizes the Foulkes-Howe map, and an explicit description of the coordinate ring of the normalization. We also prove asymptotic injectivity of the Foulkes-Howe map.',
	 'authors': u'Harlan Kadish, J.M. Landsberg,',
	 'category': u'Computer Science ',
	 'date': '2012-4-20',
	 'pdflink': u'http://arxiv.org/pdf/1204.4693',
	 'subjects': u'Algebraic Geometry (math.AG)',
	 'title': u'\nPadded polynomials, their cousins, and geometric complexity theory',
	 'urllink': u'http://arxiv.org/abs/1204.4693'}
2015-03-24 00:34:11+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0259> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:34:11+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0259>
	{'abstract': u'The causal structure of cognition can be simulated but not implemented computationally, just as the causal structure of a comet can be simulated but not implemented computationally. The only thing that allows us even to imagine otherwise is that cognition, unlike a comet, is invisible (to all but the cognizer).',
	 'authors': u'Stevan Harnad,',
	 'category': u'Computer Science ',
	 'date': '2012-2-25',
	 'pdflink': u'http://arxiv.org/pdf/1206.0259',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nThe Causal Topography of Cognition',
	 'urllink': u'http://arxiv.org/abs/1206.0259'}
2015-03-24 00:34:20+0000 [xxu46_4] INFO: Crawled 664 pages (at 4 pages/min), scraped 658 items (at 4 items/min)
2015-03-24 00:34:24+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6294> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:34:24+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6294>
	{'abstract': u'We show that the mean field equations for the SIR epidemic can be exactly solved for a network with arbitrary degree distribution. Our exact solution consists of reducing the dynamics to a lone first order differential equation, which has a solution in terms of an integral over functions dependent on the degree distribution of the network, and reconstructing all mean field functions of interest from this integral. Irreversibility of the SIR epidemic is crucial for the solution. We also find exact solutions to the sexually transmitted disease SI epidemic on bipartite graphs, to a simplified rumor spreading model, and to a new model for recommendation spreading, via similar techniques. Numerical simulations of these processes on scale free networks demonstrate the qualitative validity of mean field theory in most regimes.',
	 'authors': u'Andrew Lucas,',
	 'category': u'Computer Science ',
	 'date': '2012-6-27',
	 'pdflink': u'http://arxiv.org/pdf/1206.6294',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nExact mean field dynamics for epidemic-like processes on heterogeneous  networks',
	 'urllink': u'http://arxiv.org/abs/1206.6294'}
2015-03-24 00:34:42+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.1820> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:34:42+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.1820>
	{'abstract': u'Fatgraphs are multigraphs enriched with a cyclic order of the edges incident to a vertex. This paper presents algorithms to: (1) generate the set of all fatgraphs having a given genus and number of boundary cycles; (2) compute automorphisms of any given fatgraph; (3) compute the homology of the fatgraph complex. The algorithms are suitable for effective computer implementation. In particular, this allows us to compute the rational homology of the moduli space of Riemann surfaces with marked points. We thus compute the Betti numbers of with , corroborating known results.',
	 'authors': u'Riccardo Murri,',
	 'category': u'Computer Science ',
	 'date': '2012-2-8',
	 'pdflink': u'http://arxiv.org/pdf/1202.1820',
	 'subjects': u'Algebraic Geometry (math.AG)',
	 'title': u'\nFatgraph Algorithms and the Homology of the Kontsevich Complex',
	 'urllink': u'http://arxiv.org/abs/1202.1820'}
2015-03-24 00:35:00+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.3271> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:35:00+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.3271>
	{'abstract': u"A system responding to a stochastic driving signal can be interpreted as computing, by means of its dynamics, an implicit model of the environmental variables. The system's state retains information about past environmental fluctuations, and a fraction of this information is predictive of future ones. The remaining nonpredictive information reflects model complexity that does not improve predictive power, and thus represents the ineffectiveness of the model. We expose the fundamental equivalence between this model inefficiency and thermodynamic inefficiency, measured by dissipation. Our results hold arbitrarily far from thermodynamic equilibrium and are applicable to a wide range of systems, including biomolecular machines. They highlight a profound connection between the effective use of information and efficient thermodynamic operation: any system constructed to keep memory about its environment and to operate with maximal energetic efficiency has to be predictive.",
	 'authors': u'Susanne Still, David A. Sivak, Anthony J. Bell, Gavin E. Crooks,',
	 'category': u'Computer Science ',
	 'date': '2012-3-15',
	 'pdflink': u'http://arxiv.org/pdf/1203.3271',
	 'subjects': u'Statistical Mechanics (cond-mat.stat-mech)',
	 'title': u'\nThe thermodynamics of prediction',
	 'urllink': u'http://arxiv.org/abs/1203.3271'}
2015-03-24 00:35:17+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.4691> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:35:17+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.4691>
	{'abstract': u'This paper investigates the number of quantum queries made to solve the problem of reconstructing an unknown string from its substrings in a certain query model. More concretely, the goal of the problem is to identify an unknown string by making queries of the following form: "Is a substring of ?", where is a query string over the given alphabet. The number of queries required to identify the string is the query complexity of this problem. First we show a quantum algorithm that exactly identifies the string with at most queries, where is the length of . This contrasts sharply with the classical query complexity . Our algorithm uses Skiena and Sundaram\'s classical algorithm and the Grover search as subroutines. To make them effectively work, we develop another subroutine that finds a string appearing only once in , which may have an independent interest. We also prove two lower bounds. The first one is a general lower bound of , which means we cannot achieve a query complexity of for any constant . The other one claims that if we cannot use queries of length roughly between and , then we cannot achieve a query complexity of any sublinear function in .',
	 'authors': u'Richard Cleve, Kazuo Iwama, Fran\xe7ois Le Gall, Harumichi Nishimura, Seiichiro Tani, Junichi Teruyama, Shigeru Yamashita,',
	 'category': u'Computer Science ',
	 'date': '2012-4-20',
	 'pdflink': u'http://arxiv.org/pdf/1204.4691',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nReconstructing Strings from Substrings with Quantum Queries',
	 'urllink': u'http://arxiv.org/abs/1204.4691'}
2015-03-24 00:35:20+0000 [xxu46_4] INFO: Crawled 668 pages (at 4 pages/min), scraped 662 items (at 4 items/min)
2015-03-24 00:35:34+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0244> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:35:34+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0244>
	{'abstract': u'We study the distributed detection problem in the context of a balanced binary relay tree, where the leaves of the tree correspond to identical and independent sensors generating binary messages. The root of the tree is a fusion center making an overall decision. Every other node is a relay node that aggregates the messages received from its child nodes into a new message and sends it up toward the fusion center. We derive upper and lower bounds for the total error probability as explicit functions of in the case where nodes and links fail with certain probabilities. These characterize the asymptotic decay rate of the total error probability as goes to infinity. Naturally, this decay rate is not larger than that in the non-failure case, which is . However, we derive an explicit necessary and sufficient condition on the decay rate of the local failure probabilities (combination of node and link failure probabilities at each level) such that the decay rate of the total error probability in the failure case is the same as that of the non-failure case. More precisely, we show that if and only if .',
	 'authors': u'Zhenliang Zhang, Edwin K. P. Chong, Ali Pezeshki, William Moran, Stephen D. Howard,',
	 'category': u'Computer Science ',
	 'date': '2012-6-1',
	 'pdflink': u'http://arxiv.org/pdf/1206.0244',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nDetection Performance in Balanced Binary Relay Trees with Node and Link  Failures',
	 'urllink': u'http://arxiv.org/abs/1206.0244'}
2015-03-24 00:35:51+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6273> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:35:51+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6273>
	{'abstract': u"We present IACTalks, a free and open access seminars archive (this http URL) aimed at promoting astronomy and the exchange of ideas by providing high-quality scientific seminars to the astronomical community. The archive of seminars and talks given at the Instituto de Astrofi 'isica de Canarias goes back to 2008. Over 360 talks and seminars are now freely available by streaming over the internet. We describe the user interface, which includes two video streams, one showing the speaker, the other the presentation. A search function is available, and seminars are indexed by keywords and in some cases by series, such as special training courses or the 2011 Winter School of Astrophysics, on secular evolution of galaxies. The archive is made available as an open resource, to be used by scientists and the public.",
	 'authors': u'Johan H. Knapen, Jorge A. P\xe9rez Prieto, Tariq Shahbaz, Anna Ferr\xe9-Mateu, Nicola Caon, Cristina Ramos Almeida, Brandon Tingley, Valentina Luridiana, In\xe9s Flores-Cacho, Orlagh Creevey, Arturo Manchado Torres, Ignacio Trujillo, Maria Rosa Zapatero Osorio, Francisco S\xe1nchez Mart\xednez, Francisco L\xf3pez Molina, Gabriel P\xe9rez D\xedaz, Miguel Briganti, In\xe9s Bonet,',
	 'category': u'Computer Science ',
	 'date': '2012-6-27',
	 'pdflink': u'http://arxiv.org/pdf/1206.6273',
	 'subjects': u'Instrumentation and Methods for Astrophysics (astro-ph.IM)',
	 'title': u'\nIACTalks: an on-line archive of astronomy-related seminars',
	 'urllink': u'http://arxiv.org/abs/1206.6273'}
2015-03-24 00:36:07+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.1777> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:36:07+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.1777>
	{'abstract': u'New methods for -decomposition analysis are presented. They are based on topology of real algebraic varieties and computational real algebraic geometry. The estimate of number of root invariant regions for polynomial parametric families of polynomial and matrices is given. For the case of two parametric family more sharp estimate is proven. Theoretic results are supported by various numerical simulations that show higher precision of presented methods with respect to traditional ones. The presented methods are inherently global and could be applied for studying -decomposition for the space of parameters as a whole instead of some prescribed regions. For symbolic computations the Maple v.14 software and its package RegularChains are used.',
	 'authors': u"Oleg O. Vasil'ev,",
	 'category': u'Computer Science ',
	 'date': '2012-2-8',
	 'pdflink': u'http://arxiv.org/pdf/1202.1777',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nCounting and computing regions of $D$-decomposition: algebro-geometric  approach',
	 'urllink': u'http://arxiv.org/abs/1202.1777'}
2015-03-24 00:36:20+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.3241> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:36:20+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.3241>
	{'abstract': u"We introduce a simple model of static networks, where nodes are located on a ring structure, and two accompanying dynamic rules of repeated averaging on periodic node states. We assume nodes can interact with neighbors, and will add long-range links randomly. The number of long-range links, E, controls structures of these networks, and we show that there exist many types of fixed points, when E is varied. When E is low, fixed points are mostly diverse states, in which node states are diversely populated; on the other hand, when E is high, fixed points tend to be dominated by converged states, in which node states converge to one value. Numerically, we observe properties of fixed points for various E's, and also estimate points of the transition from diverse states to converged states for four different cases. This kind of simple network models will help us understand how diversities that we encounter in many systems of complex networks are sustained, even when mechanisms of averaging are at work,and when they break down if more long-range connections are added.",
	 'authors': u'Suhan Ree,',
	 'category': u'Computer Science ',
	 'date': '2012-3-15',
	 'pdflink': u'http://arxiv.org/pdf/1203.3241',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nDynamics of periodic node states on a model of static networks with  repeated-averaging rules',
	 'urllink': u'http://arxiv.org/abs/1203.3241'}
2015-03-24 00:36:20+0000 [xxu46_4] INFO: Crawled 672 pages (at 4 pages/min), scraped 666 items (at 4 items/min)
2015-03-24 00:36:32+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.4656> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:36:32+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.4656>
	{'abstract': u'Greedy Pursuits are very popular in Compressed Sensing for sparse signal recovery. Though many of the Greedy Pursuits possess elegant theoretical guarantees for performance, it is well known that their performance depends on the statistical distribution of the non-zero elements in the sparse signal. In practice, the distribution of the sparse signal may not be known a priori. It is also observed that performance of Greedy Pursuits degrades as the number of available measurements decreases from a threshold value which is method dependent. To improve the performance in these situations, we introduce a novel fusion framework for Greedy Pursuits and also propose two algorithms for sparse recovery. Through Monte Carlo simulations we show that the proposed schemes improve sparse signal recovery in clean as well as noisy measurement cases.',
	 'authors': u'Sooraj K. Ambat, Saikat Chatterjee, K. V. S. Hari,',
	 'category': u'Computer Science ',
	 'date': '2012-4-20',
	 'pdflink': u'http://arxiv.org/pdf/1204.4656',
	 'subjects': u'Applications (stat.AP)',
	 'title': u'\nFusion of Greedy Pursuits for Compressed Sensing Signal Reconstruction',
	 'urllink': u'http://arxiv.org/abs/1204.4656'}
2015-03-24 00:36:49+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0238> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:36:49+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0238>
	{'abstract': u'Feature extraction is one of the fundamental problems of character recognition. The performance of character recognition system is depends on proper feature extraction and correct classifier selection. In this article, a rapid feature extraction method is proposed and named as Celled Projection (CP) that compute the projection of each section formed through partitioning an image. The recognition performance of the proposed method is compared with other widely used feature extraction methods that are intensively studied for many different scripts in literature. The experiments have been conducted using Bangla handwritten numerals along with three different well known classifiers which demonstrate comparable results including 94.12% recognition accuracy using celled projection.',
	 'authors': u'M. Zahid Hossain, M. Ashraful Amin, Hong Yan,',
	 'category': u'Computer Science ',
	 'date': '2012-6-1',
	 'pdflink': u'http://arxiv.org/pdf/1206.0238',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nRapid Feature Extraction for Optical Character Recognition',
	 'urllink': u'http://arxiv.org/abs/1206.0238'}
2015-03-24 00:37:01+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6266> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:37:01+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6266>
	{'abstract': u'Correlations may affect propagation processes on complex networks. To analyze their effect, it is useful to build ensembles of networks constrained to have a given value of a structural measure, such as the degree-degree correlation , being random in other aspects and preserving the degree distribution. This can be done through Monte Carlo optimization procedures. Meanwhile, when tuning , other network properties may concomitantly change. Then, in this work we analyze, for the -ensembles, the impact of on properties such as transitivity, branching and characteristic lengths, that are relevant when investigating spreading phenomena on these networks. The present analysis is performed for networks with degree distributions of two main types: either localized around a typical degree (with exponentially bounded asymptotic decay) or broadly distributed (with power-law decay). Correlation bounds and size effects are also investigated.',
	 'authors': u'Marlon Ramos, Celia Anteneodo,',
	 'category': u'Computer Science ',
	 'date': '2012-6-27',
	 'pdflink': u'http://arxiv.org/pdf/1206.6266',
	 'subjects': u'Statistical Mechanics (cond-mat.stat-mech)',
	 'title': u'\nRandom degree-degree correlated networks',
	 'urllink': u'http://arxiv.org/abs/1206.6266'}
2015-03-24 00:37:16+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.1747> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:37:16+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.1747>
	{'abstract': u'Urban transportation systems grow over time as city populations grow and move and their transportation needs evolve. Typical network growth models, such as preferential attachment, grow the network node by node whereas rail and metro systems grow by adding entire lines with all their nodes. The objective of this paper is to see if any canonical regular network forms such as stars or grids capture the growth patterns of urban metro systems for which we have historical data in terms of old maps. Data from these maps reveal that the systems\' Pearson degree correlation grows increasingly from initially negative values toward positive values over time and in some cases becomes decidedly positive. We have derived closed form expressions for degree correlation and clustering coefficient for a variety of canonical forms that might be similar to metro systems. Of all those examined, only a few types patterned after a wide area network (WAN) with a "core-periphery" structure show similar positive-trending degree correlation as network size increases. This suggests that large metro systems either are designed or evolve into the equivalent of message carriers that seek to balance travel between arbitrary node-destination pairs with avoidance of congestion in the central regions of the network. Keywords: metro, subway, urban transport networks, degree correlation',
	 'authors': u'Daniel E. Whitney,',
	 'category': u'Computer Science ',
	 'date': '2012-2-8',
	 'pdflink': u'http://arxiv.org/pdf/1202.1747',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nGrowth Patterns of Subway/Metro Systems Tracked by Degree Correlation',
	 'urllink': u'http://arxiv.org/abs/1202.1747'}
2015-03-24 00:37:20+0000 [xxu46_4] INFO: Crawled 676 pages (at 4 pages/min), scraped 670 items (at 4 items/min)
2015-03-24 00:37:34+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.3165> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:37:34+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.3165>
	{'abstract': u"A recently developed computational methodology for executing numerical calculations with infinities and infinitesimals is described in this paper. The developed approach has a pronounced applied character and is based on the principle `The part is less than the whole' introduced by Ancient Greeks. This principle is used with respect to all numbers (finite, infinite, and infinitesimal) and to all sets and processes (finite and infinite). The point of view on infinities and infinitesimals (and in general, on Mathematics) presented in this paper uses strongly physical ideas emphasizing interrelations holding between a mathematical object under the observation and tools used for this observation. It is shown how a new numeral system allowing one to express different infinite and infinitesimal quantities in a unique framework can be used for theoretical and computational purposes. Numerous examples dealing with infinite sets, divergent series, limits, and probability theory are given.",
	 'authors': u'Yaroslav D. Sergeyev,',
	 'category': u'Computer Science ',
	 'date': '2012-3-14',
	 'pdflink': u'http://arxiv.org/pdf/1203.3165',
	 'subjects': u'Numerical Analysis (math.NA)',
	 'title': u'\nMethodology of Numerical Computations with Infinities and Infinitesimals',
	 'urllink': u'http://arxiv.org/abs/1203.3165'}
2015-03-24 00:37:45+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.4619> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:37:45+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.4619>
	{'abstract': u'We use the venerable "fooling set" method to prove new lower bounds on the quantum communication complexity of various functions. Let f:X x Y--&gt; be a Boolean function, fool^1(f) its maximal fooling set size among 1-inputs, Q_1^*(f) its one-sided error quantum communication complexity with prior entanglement, and NQ(f) its nondeterministic quantum communication complexity (without prior entanglement; this model is trivial with shared randomness or entanglement). Our main results are the following, where logs are to base 2: * If the maximal fooling set is "upper triangular" (which is for instance the case for the equality, disjointness, and greater-than functions), then we have Q_1^*(f)&gt;=(1/2)log fool^1(f) - 1/2, which is essentially optimal by superdense coding. No super-constant lower bound for equality seems to follow from earlier techniques. * For all f we have Q_1^*(f)&gt;=(1/4)log fool^1(f) - 1/2, which is optimal up to a factor of 2. * NQ(f)&gt;=log fool^1(f)/2 + 1. We do not know if the factor 1/2 is needed in this result, but it cannot be replaced by 1: we give an example where NQ(f)~0.613 log fool^1(f).',
	 'authors': u'Hartmut Klauck, Ronald de Wolf,',
	 'category': u'Computer Science ',
	 'date': '2012-4-20',
	 'pdflink': u'http://arxiv.org/pdf/1204.4619',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nFooling One-Sided Quantum Protocols',
	 'urllink': u'http://arxiv.org/abs/1204.4619'}
2015-03-24 00:38:00+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0233> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:38:00+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0233>
	{'abstract': u'A graph G is dually chordal if there is a spanning tree T of G such that any maximal clique of G induces a subtree in T. This paper investigates the Colourability problem on dually chordal graphs. It will show that it is NP-complete in case of four colours and solvable in linear time with a simple algorithm in case of three colours. In addition, it will be shown that a dually chordal graph is 3-colourable if and only if it is perfect and has no clique of size four.',
	 'authors': u'Arne Leitert,',
	 'category': u'Computer Science ',
	 'date': '2012-6-1',
	 'pdflink': u'http://arxiv.org/pdf/1206.0233',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\n3-Colourability of Dually Chordal Graphs in Linear Time',
	 'urllink': u'http://arxiv.org/abs/1206.0233'}
2015-03-24 00:38:18+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6214> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:38:18+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6214>
	{'abstract': u"Empirical research on world cities often draws on Taylor's (2001) notion of an 'interlocking network model', in which office networks of globalized service firms are assumed to shape the spatialities of urban networks. In spite of its many merits, this approach is limited because the resultant adjacency matrices are not really fit for network-analytic calculations. We therefore propose a fresh analytical approach using a primary linkage algorithm that produces a one-mode directed graph based on Taylor's two-mode city/firm network data. The procedure has the advantage of creating less dense networks when compared to the interlocking network model, while nonetheless retaining the network structure apparent in the initial dataset. We randomize the empirical network with a bootstrapping simulation approach, and compare the simulated parameters of this null-model with our empirical network parameter (i.e. betweenness centrality). We find that our approach produces results that are comparable to those of the standard interlocking network model. However, because our approach is based on an actual graph representation and network analysis, we are able to assess cities' position in the network at large. For instance, we find that cities such as Tokyo, Sydney, Melbourne, Almaty and Karachi hold more strategic and valuable positions than suggested in the interlocking networks as they play a bridging role in connecting cities across regions. In general, we argue that our graph representation allows for further and deeper analysis of the original data, further extending world city network research into a theory-based empirical research approach.",
	 'authors': u'Stefan Hennemann, Ben Derudder,',
	 'category': u'Computer Science ',
	 'date': '2012-6-27',
	 'pdflink': u'http://arxiv.org/pdf/1206.6214',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nAn Alternative Approach to the Calculation and Analysis of Connectivity  in the World City Network',
	 'urllink': u'http://arxiv.org/abs/1206.6214'}
2015-03-24 00:38:20+0000 [xxu46_4] INFO: Crawled 680 pages (at 4 pages/min), scraped 674 items (at 4 items/min)
2015-03-24 00:38:31+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.1643> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:38:31+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.1643>
	{'abstract': u'Genetic algorithms (GAs) emulate the process of biological evolution, in a computational setting, in order to generate good solutions to difficult search and optimisation problems. GA-based optimisers tend to be extremely robust and versatile compared to most traditional techniques used to solve optimisation problems. This review paper provides a very brief introduction to GAs and outlines their utility in astronomy and astrophysics.',
	 'authors': u'Vinesh Rajpaul,',
	 'category': u'Computer Science ',
	 'date': '2012-2-8',
	 'pdflink': u'http://arxiv.org/pdf/1202.1643',
	 'subjects': u'Instrumentation and Methods for Astrophysics (astro-ph.IM)',
	 'title': u'\nGenetic algorithms in astronomy and astrophysics',
	 'urllink': u'http://arxiv.org/abs/1202.1643'}
2015-03-24 00:38:45+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.3164> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:38:45+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.3164>
	{'abstract': u'There exist many applications where it is necessary to approximate numerically derivatives of a function which is given by a computer procedure. In particular, all the fields of optimization have a special interest in such a kind of information. In this paper, a new way to do this is presented for a new kind of a computer -- the Infinity Computer -- able to work numerically with finite, infinite, and infinitesimal numbers. It is proved that the Infinity Computer is able to calculate values of derivatives of a higher order for a wide class of functions represented by computer procedures. It is shown that the ability to compute derivatives of arbitrary order automatically and accurate to working precision is an intrinsic property of the Infinity Computer related to its way of functioning. Numerical examples illustrating the new concepts and numerical tools are given.',
	 'authors': u'Yaroslav D. Sergeyev,',
	 'category': u'Computer Science ',
	 'date': '2012-3-14',
	 'pdflink': u'http://arxiv.org/pdf/1203.3164',
	 'subjects': u'Numerical Analysis (math.NA)',
	 'title': u'\nHigher order numerical differentiation on the Infinity Computer',
	 'urllink': u'http://arxiv.org/abs/1203.3164'}
2015-03-24 00:39:01+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.4596> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:39:01+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.4596>
	{'abstract': u'We study the communication complexity of a number of graph properties where the edges of the graph are distributed between Alice and Bob (i.e., each receives some of the edges as input). Our main results are: * An Omega(n) lower bound on the quantum communication complexity of deciding whether an n-vertex graph G is connected, nearly matching the trivial classical upper bound of O(n log n) bits of communication. * A deterministic upper bound of O(n^log n) bits for deciding if a bipartite graph contains a perfect matching, and a quantum lower bound of Omega(n) for this problem. * A Theta(n^2) bound for the randomized communication complexity of deciding if a graph has an Eulerian tour, and a Theta(n^) bound for the quantum communication complexity of this problem. The first two quantum lower bounds are obtained by exhibiting a reduction from the n-bit Inner Product problem to these graph problems, which solves an open question of Babai, Frankl and Simon. The third quantum lower bound comes from recent results about the quantum communication complexity of composed functions. We also obtain essentially tight bounds for the quantum communication complexity of a few other problems, such as deciding if G is triangle-free, or if G is bipartite, as well as computing the determinant of a distributed matrix.',
	 'authors': u'Gabor Ivanyos, Hartmut Klauck, Troy Lee, Miklos Santha, Ronald de Wolf,',
	 'category': u'Computer Science ',
	 'date': '2012-4-20',
	 'pdflink': u'http://arxiv.org/pdf/1204.4596',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nNew bounds on the classical and quantum communication complexity of some  graph properties',
	 'urllink': u'http://arxiv.org/abs/1204.4596'}
2015-03-24 00:39:17+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0232> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:39:17+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0232>
	{'abstract': u'A simple linear loop is a simple while loop with linear assignments and linear loop guards. If a simple linear loop has only two program variables, we give a complete algorithm for computing the set of all the inputs on which the loop does not terminate. For the case of more program variables, we show that the non-termination set cannot be described by Tarski formulae in general',
	 'authors': u'Liyun Dai, Bican Xia,',
	 'category': u'Computer Science ',
	 'date': '2012-5-31',
	 'pdflink': u'http://arxiv.org/pdf/1206.0232',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nNon-Termination Sets of Simple Linear Loops',
	 'urllink': u'http://arxiv.org/abs/1206.0232'}
2015-03-24 00:39:20+0000 [xxu46_4] INFO: Crawled 684 pages (at 4 pages/min), scraped 678 items (at 4 items/min)
2015-03-24 00:39:31+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6161> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:39:31+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6161>
	{'abstract': u'The U.S. Virtual Astronomical Observatory (VAO) is a product-driven organization that provides new scientific research capabilities to the astronomical community. Software development for the VAO follows a lightweight framework that guides development of science applications and infrastructure. Challenges to be overcome include distributed development teams, part-time efforts, and highly constrained schedules. We describe the process we followed to conquer these challenges while developing Iris, the VAO application for analysis of 1-D astronomical spectral energy distributions (SEDs). Iris was successfully built and released in less than a year with a team distributed across four institutions. The project followed existing International Virtual Observatory Alliance inter-operability standards for spectral data and contributed a SED library as a by-product of the project. We emphasize lessons learned that will be folded into future development efforts. In our experience, a well-defined process that provides guidelines to ensure the project is cohesive and stays on track is key to success. Internal product deliveries with a planned test and feedback loop are critical. Release candidates are measured against use cases established early in the process, and provide the opportunity to assess priorities and make course corrections during development. Also key is the participation of a stakeholder such as a lead scientist who manages the technical questions, advises on priorities, and is actively involved as a lead tester. Finally, frequent scheduled communications (for example a bi-weekly tele-conference) assure issues are resolved quickly and the team is working toward a common vision',
	 'authors': u"Janet D. Evans, Raymond L. Plante, Nina Bonaventura, Ivo Busko, Mark Cresitello-Dittmar, Raffaele D'Abrusco, Stephen Doe, Rick Ebert, Omar Laurino, Olga Pevunova, Brian Refsdal, Brian Thomas,",
	 'category': u'Computer Science ',
	 'date': '2012-6-27',
	 'pdflink': u'http://arxiv.org/pdf/1206.6161',
	 'subjects': u'Instrumentation and Methods for Astrophysics (astro-ph.IM)',
	 'title': u'\nManaging Distributed Software Development in the Virtual Astronomical  Observatory',
	 'urllink': u'http://arxiv.org/abs/1206.6161'}
2015-03-24 00:39:45+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.1618> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:39:45+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.1618>
	{'abstract': u'We present a new matrix-valued isospectral ordinary differential equation that asymptotically block-diagonalizes zero-diagonal Jacobi matrices employed as its initial condition. This o.d.e. features a right-hand side with a nested commutator of matrices, and structurally resembles the double-bracket o.d.e. studied by R.W. Brockett in 1991. We prove that its solutions converge asymptotically, that the limit is block-diagonal, and above all, that the limit matrix is defined uniquely as follows: For even, a block-diagonal matrix containing blocks, such that the super-diagonal entries are sorted by strictly increasing absolute value. Furthermore, the off-diagonal entries in these blocks have the same sign as the respective entries in the matrix employed as initial condition. For odd, there is one additional block containing a zero that is the top left entry of the limit matrix. The results presented here extend some early work of Kac and van Moerbeke.',
	 'authors': u'Tobias Sutter, Debasish Chatterjee, Federico Ramponi, John Lygeros,',
	 'category': u'Computer Science ',
	 'date': '2012-2-8',
	 'pdflink': u'http://arxiv.org/pdf/1202.1618',
	 'subjects': u'Dynamical Systems (math.DS)',
	 'title': u'\nIsospectral flows on a class of finite-dimensional Jacobi matrices',
	 'urllink': u'http://arxiv.org/abs/1202.1618'}
2015-03-24 00:40:02+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.3163> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:40:02+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.3163>
	{'abstract': u'Traditional computers work with finite numbers. Situations where the usage of infinite or infinitesimal quantities is required are studied mainly theoretically. In this paper, a recently introduced computational methodology (that is not related to the non-standard analysis) is used to work with finite, infinite, and infinitesimal numbers textit. This can be done on a new kind of a computer - the Infinity Computer - able to work with all these types of numbers. The new computational tools both give possibilities to execute computations of a new type and open new horizons for creating new mathematical models where a computational usage of infinite and/or infinitesimal numbers can be useful. A number of numerical examples showing the potential of the new approach and dealing with divergent series, limits, probability theory, linear algebra, and calculation of volumes of objects consisting of parts of different dimensions are given.',
	 'authors': u'Yaroslav D. Sergeyev,',
	 'category': u'Computer Science ',
	 'date': '2012-3-14',
	 'pdflink': u'http://arxiv.org/pdf/1203.3163',
	 'subjects': u'Numerical Analysis (math.NA)',
	 'title': u'\nNumerical computations and mathematical modelling with infinite and  infinitesimal numbers',
	 'urllink': u'http://arxiv.org/abs/1203.3163'}
2015-03-24 00:40:18+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.4584> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:40:18+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.4584>
	{'abstract': u'Background: How to extract useful information from complex biological networks is a major goal in many fields, especially in genomics and proteomics. We have shown in several works that iterative hierarchical clustering, as implemented in the UVCluster program, is a powerful tool to analyze many of those networks. However, the amount of computation time required to perform UVCluster analyses imposed significant limitations to its use. Methodology/Principal Findings: We describe the suite Jerarca, designed to efficiently convert networks of interacting units into dendrograms by means of iterative hierarchical clustering. Jerarca is divided into three main sections. First, weighted distances among units are computed using up to three different approaches: a more efficient version of UVCluster and two new, related algorithms called RCluster and SCluster. Second, Jerarca builds dendrograms based on those distances, using well-known phylogenetic algorithms, such as UPGMA or Neighbor-Joining. Finally, Jerarca provides optimal partitions of the trees using statistical criteria based on the distribution of intra- and intercluster connections. Outputs compatible with the phylogenetic software MEGA and the Cytoscape package are generated, allowing the results to be easily visualized. Conclusions/Significance: The four main advantages of Jerarca in respect to UVCluster are: 1) Improved speed of a novel UVCluster algorithm; 2) Additional, alternative strategies to perform iterative hierarchical clustering; 3) Automatic evaluation of the hierarchical trees to obtain optimal partitions; and, 4) Outputs compatible with popular software such as MEGA and Cytoscape.',
	 'authors': u'Rodrigo Aldecoa, Ignacio Mar\xedn,',
	 'category': u'Computer Science ',
	 'date': '2012-4-20',
	 'pdflink': u'http://arxiv.org/pdf/1204.4584',
	 'subjects': u'Molecular Networks (q-bio.MN)',
	 'title': u'\nJerarca: Efficient Analysis of Complex Networks Using Hierarchical  Clustering',
	 'urllink': u'http://arxiv.org/abs/1204.4584'}
2015-03-24 00:40:20+0000 [xxu46_4] INFO: Crawled 688 pages (at 4 pages/min), scraped 682 items (at 4 items/min)
2015-03-24 00:40:36+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0217> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:40:36+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0217>
	{'abstract': u'Clustering is one of the major tasks in data mining. In the last few years, Clustering of spatial data has received a lot of research attention. Spatial databases are components of many advanced information systems like geographic information systems VLSI design systems. In this thesis, we introduce several efficient algorithms for clustering spatial data. First, we present a grid-based clustering algorithm that has several advantages and comparable performance to the well known efficient clustering algorithm. The algorithm has several advantages. The algorithm does not require many input parameters. It requires only three parameters, the number of the points in the data space, the number of the cells in the grid and a percentage. The number of the cells in the grid reflects the accuracy that should be achieved by the algorithm. The algorithm is capable of discovering clusters of arbitrary shapes. The computational complexity of the algorithm is comparable to the complexity of the most efficient clustering algorithm. The algorithm has been implemented and tested against different ranges of database sizes. The performance results show that the running time of the algorithm is superior to the most well known algorithms (CLARANS [23]). The results show also that the performance of the algorithm do not degrade as the number of the data points increases.',
	 'authors': u'Mohamed A. El-Zawawy,',
	 'category': u'Computer Science ',
	 'date': '2012-6-1',
	 'pdflink': u'http://arxiv.org/pdf/1206.0217',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nEfficient techniques for mining spatial databases',
	 'urllink': u'http://arxiv.org/abs/1206.0217'}
2015-03-24 00:40:50+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6135> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:40:50+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6135>
	{'abstract': u'Quasi-median graphs are a tool commonly used by evolutionary biologists to visualise the evolution of molecular sequences. As with any graph, a quasi-median graph can contain cut vertices, that is, vertices whose removal disconnect the graph. These vertices induce a decomposition of the graph into blocks, that is, maximal subgraphs which do not contain any cut vertices. Here we show that the special structure of quasi-median graphs can be used to compute their blocks without having to compute the whole graph. In particular we present an algorithm that, for a collection of aligned sequences of length , can compute the blocks of the associated quasi-median graph together with the information required to correctly connect these blocks together in run time , independent of the size of the sequence alphabet. Our primary motivation for presenting this algorithm is the fact that the quasi-median graph associated to a sequence alignment must contain all most parsimonious trees for the alignment, and therefore precomputing the blocks of the graph has the potential to help speed up any method for computing such trees.',
	 'authors': u'Sven Herrmann, Vincent Moulton,',
	 'category': u'Computer Science ',
	 'date': '2012-6-26',
	 'pdflink': u'http://arxiv.org/pdf/1206.6135',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nComputing the blocks of a quasi-median graph',
	 'urllink': u'http://arxiv.org/abs/1206.6135'}
2015-03-24 00:41:02+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.1569> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:41:02+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.1569>
	{'abstract': u'A vertex colouring of a graph is emph if there is no path for which the first half of the path is assigned the same sequence of colours as the second half. The emph of a graph is the minimum integer such that has a nonrepetitive -colouring. Whether planar graphs have bounded nonrepetitive chromatic number is one of the most important open problems in the field. Despite this, the best known upper bound is for -vertex planar graphs. We prove a upper bound.',
	 'authors': u'Vida Dujmovi\u0107, Fabrizio Frati, Gwena\xebl Joret, David R. Wood,',
	 'category': u'Computer Science ',
	 'date': '2012-2-8',
	 'pdflink': u'http://arxiv.org/pdf/1202.1569',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nNonrepetitive Colourings of Planar Graphs with $O(\\log n)$ Colours',
	 'urllink': u'http://arxiv.org/abs/1202.1569'}
2015-03-24 00:41:17+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.3065> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:41:17+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.3065>
	{'abstract': u'We propose an opinion dynamics model that combines processes of vanity and opinion propagation. The interactions take place between randomly chosen pairs. During an interaction, the agents propagate their opinions about themselves and about other people they know. Moreover, each individual is subject to vanity: if her interlocutor seems to value her highly, then she increases her opinion about this interlocutor. On the contrary she tends to decrease her opinion about those who seem to undervalue her. The combination of these dynamics with the hypothesis that the opinion propagation is more efficient when coming from highly valued individuals, leads to different patterns when varying the parameters. For instance, for some parameters the positive opinion links between individuals generate a small world network. In one of the patterns, absolute dominance of one agent alternates with a state of generalised distrust, where all agents have a very low opinion of all the others (including themselves). We provide some explanations of the mechanisms behind these emergent behaviors and finally propose a discussion about their interest',
	 'authors': u'Guillaume Deffuant, Timoteo Carletti, Sylvie Huet,',
	 'category': u'Computer Science ',
	 'date': '2012-3-14',
	 'pdflink': u'http://arxiv.org/pdf/1203.3065',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nThe Leviathan model: Absolute dominance, generalised distrust, small  worlds and other patterns emerging from combining vanity with opinion  propagation',
	 'urllink': u'http://arxiv.org/abs/1203.3065'}
2015-03-24 00:41:20+0000 [xxu46_4] INFO: Crawled 692 pages (at 4 pages/min), scraped 686 items (at 4 items/min)
2015-03-24 00:41:34+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.4539> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:41:34+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.4539>
	{'abstract': u'We consider supervised learning problems where the features are embedded in a graph, such as gene expressions in a gene network. In this context, it is of much interest to automatically select a subgraph with few connected components; by exploiting prior knowledge, one can indeed improve the prediction performance or obtain results that are easier to interpret. Regularization or penalty functions for selecting features in graphs have recently been proposed, but they raise new algorithmic challenges. For example, they typically require solving a combinatorially hard selection problem among all connected subgraphs. In this paper, we propose computationally feasible strategies to select a sparse and well-connected subset of features sitting on a directed acyclic graph (DAG). We introduce structured sparsity penalties over paths on a DAG called "path coding" penalties. Unlike existing regularization functions that model long-range interactions between features in a graph, path coding penalties are tractable. The penalties and their proximal operators involve path selection problems, which we efficiently solve by leveraging network flow optimization. We experimentally show on synthetic, image, and genomic data that our approach is scalable and leads to more connected subgraphs than other regularization functions for graphs.',
	 'authors': u'Julien Mairal, Bin Yu,',
	 'category': u'Computer Science ',
	 'date': '2012-4-20',
	 'pdflink': u'http://arxiv.org/pdf/1204.4539',
	 'subjects': u'Machine Learning (stat.ML)',
	 'title': u'\nSupervised Feature Selection in Graphs with Path Coding Penalties and  Network Flows',
	 'urllink': u'http://arxiv.org/abs/1204.4539'}
2015-03-24 00:41:52+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0206> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:41:52+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0206>
	{'abstract': u"We study the streaming complexity of the membership problem of 1-turn-Dyck2 and Dyck2 when there are a few errors in the input string. 1-turn-Dyck2 with errors: We prove that there exists a randomized one-pass algorithm that given x checks whether there exists a string x' in 1-turn-Dyck2 such that x is obtained by flipping at most locations of x' using: - O(k log n) space, O(k log n) randomness, and poly(k log n) time per item and with error at most 1/poly(n). - O(k^ + log n) space for every 0 &lt;= epsilon &lt;= 1, O(log n) randomness, O(polylog(n) + poly(k)) time per item, with error at most 1/8. Here, we also prove that any randomized one-pass algorithm that makes error at most k/n requires at least Omega(k log(n/k)) space to accept strings which are exactly k-away from strings in 1-turn-Dyck2 and to reject strings which are exactly (k+2)-away from strings in 1-turn-Dyck2. Since 1-turn-Dyck2 and the Hamming Distance problem are closely related we also obtain new upper and lower bounds for this problem. Dyck2 with errors: We prove that there exists a randomized one-pass algorithm that given x checks whether there exists a string x' in Dyck2 such that x is obtained from x' by changing (in some restricted manner) at most k positions using: - O(k log n + sqrt(n log n)) space, O(k log n) randomness, poly(k log n) time per element and with error at most 1/poly(n). - O(k^(1+epsilon)+ sqrt(n log n)) space for every 0 &lt;= epsilon &lt;= 1, O(log n) randomness, O(polylog(n) + poly(k)) time per element, with error at most 1/8.",
	 'authors': u'Andreas Krebs, Nutan Limaye, Srikanth Srinivasan,',
	 'category': u'Computer Science ',
	 'date': '2012-6-1',
	 'pdflink': u'http://arxiv.org/pdf/1206.0206',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nStreaming algorithms for recognizing nearly well-parenthesized  expressions',
	 'urllink': u'http://arxiv.org/abs/1206.0206'}
2015-03-24 00:42:07+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.6036> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:42:07+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.6036>
	{'abstract': u'Empirical studies suggest that contact patterns follow heterogeneous inter-event times, meaning that intervals of high activity are followed by periods of inactivity. Combined with birth and death of individuals, these temporal constraints affect the spread of infections in a non-trivial way and are dependent on the particular contact dynamics. We propose a stochastic model to generate temporal networks where vertices make instantaneous contacts following heterogeneous inter-event times, and leave and enter the system at fixed rates. We study how these temporal properties affect the prevalence of an infection and estimate R0, the number of secondary infections, by modeling simulated infections (SIR, SI and SIS) co-evolving with the network structure. We find that heterogeneous contact patterns cause earlier and larger epidemics on the SIR model in comparison to homogeneous scenarios. In case of SI and SIS, the epidemics is faster in the early stages (up to 90% of prevalence) followed by a slowdown in the asymptotic limit in case of heterogeneous patterns. In the presence of birth and death, heterogeneous patterns always cause higher prevalence in comparison to homogeneous scenarios with same average inter-event times. Our results suggest that R0 may be underestimated if temporal heterogeneities are not taken into account in the modeling of epidemics.',
	 'authors': u'Luis Enrique Correa Rocha, Vincent D. Blondel,',
	 'category': u'Computer Science ',
	 'date': '2012-6-26',
	 'pdflink': u'http://arxiv.org/pdf/1206.6036',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nTemporal Heterogeneities Increase the Prevalence of Epidemics on  Evolving Networks',
	 'urllink': u'http://arxiv.org/abs/1206.6036'}
2015-03-24 00:42:20+0000 [xxu46_4] INFO: Crawled 695 pages (at 3 pages/min), scraped 689 items (at 3 items/min)
2015-03-24 00:42:22+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.1565> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:42:22+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.1565>
	{'abstract': u'Consider the problem when we want to construct some structure on a bounded degree graph, e.g. an almost maximum matching, and we want to decide about each edge depending only on its constant radius neighbourhood. We show that the information about the local statistics of the graph does not help here. Namely, if there exists a random local algorithm which can use any local statistics about the graph, and produces an almost optimal structure, then the same can be achieved by a random local algorithm using no statistics.',
	 'authors': u'Endre Cs\xf3ka,',
	 'category': u'Computer Science ',
	 'date': '2012-2-7',
	 'pdflink': u'http://arxiv.org/pdf/1202.1565',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nRandom local algorithms',
	 'urllink': u'http://arxiv.org/abs/1202.1565'}
2015-03-24 00:42:40+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.3037> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:42:40+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.3037>
	{'abstract': u'We propose a formal expansion of the transfer entropy to put in evidence irreducible sets of variables which provide information for the future state of each assigned target. Multiplets characterized by a large contribution to the expansion are associated to informational circuits present in the system, with an informational character which can be associated to the sign of the contribution. For the sake of computational complexity, we adopt the assumption of Gaussianity and use the corresponding exact formula for the conditional mutual information. We report the application of the proposed methodology on two EEG data sets.',
	 'authors': u'S. Stramaglia, Guo-Rong Wu, M. Pellicoro, D. Marinazzo,',
	 'category': u'Computer Science ',
	 'date': '2012-3-14',
	 'pdflink': u'http://arxiv.org/pdf/1203.3037',
	 'subjects': u'Quantitative Methods (q-bio.QM)',
	 'title': u'\nExpanding the Transfer Entropy to Identify Information Subgraphs in  Complex Systems',
	 'urllink': u'http://arxiv.org/abs/1203.3037'}
2015-03-24 00:42:51+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.4497> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:42:51+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.4497>
	{'abstract': u"Ranking the nodes' ability for spreading in networks is a fundamental problem which relates to many real applications such as information and disease control. In the previous literatures, a network decomposition procedure called k-shell method has been shown to effectively identify the most influential spreaders. In this paper, we find that the k-shell method have some limitations when it is used to rank all the nodes in the network. We also find that these limitations are due to considering only the links between the remaining nodes (residual degree) while entirely ignoring all the links connecting to the removed nodes (exhausted degree) when decomposing the networks. Accordingly, we propose a mixed degree decomposition (MDD) procedure in which both the residual degree and the exhausted degree are considered. By simulating the epidemic process on the real networks, we show that the MDD method can outperform the k-shell and the degree methods in ranking spreaders. Finally, the influence of the network structure on the performance of the MDD method is discussed.",
	 'authors': u'An Zeng, Cheng-Jun Zhang,',
	 'category': u'Computer Science ',
	 'date': '2012-4-19',
	 'pdflink': u'http://arxiv.org/pdf/1204.4497',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nRanking spreaders by decomposing complex networks',
	 'urllink': u'http://arxiv.org/abs/1204.4497'}
2015-03-24 00:43:03+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0197> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:43:03+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0197>
	{'abstract': u'Interference alignment has emerged as a powerful tool in the analysis of multi-user networks. Despite considerable recent progress, the capacity region of the Gaussian K-user interference channel is still unknown in general, in part due to the challenges associated with alignment on the signal scale using lattice codes. This paper develops a new framework for lattice interference alignment, based on the compute-and-forward approach. Within this framework, each receiver decodes by first recovering two or more linear combinations of the transmitted codewords with integer-valued coefficients and then solving these equations for its desired codeword. For the special case of symmetric channel gains, this framework is used to derive the approximate sum capacity of the Gaussian interference channel, up to an explicitly defined outage set of the channel gains. The key contributions are the capacity lower bounds for the weak through strong interference regimes, where each receiver should jointly decode its own codeword along with part of the interfering codewords. As part of the analysis, it is shown that decoding K linear combinations of the codewords can approach the sum capacity of the K-user Gaussian multiple-access channel up to a gap of no more than K log(K)/2 bits.',
	 'authors': u'Or Ordentlich, Uri Erez, Bobak Nazer,',
	 'category': u'Computer Science ',
	 'date': '2012-6-1',
	 'pdflink': u'http://arxiv.org/pdf/1206.0197',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nThe Approximate Sum Capacity of the Symmetric Gaussian K-User  Interference Channel',
	 'urllink': u'http://arxiv.org/abs/1206.0197'}
2015-03-24 00:43:20+0000 [xxu46_4] INFO: Crawled 699 pages (at 4 pages/min), scraped 693 items (at 4 items/min)
2015-03-24 00:43:20+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.5996> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:43:20+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.5996>
	{'abstract': u'In wireless systems there is always a trade-off between reducing the transmit power and mitigating the resultant signal-degradation imposed by the transmit-power reduction with the aid of sophisticated receiver algorithms, when considering the total energy consumption. Quantum-assisted wireless communications exploits the extra computing power offered by quantum mechanics based architectures. This paper summarizes some recent results in quantum computing and the corresponding application areas in wireless communications.',
	 'authors': u'Sandor Imre, Laszlo Gyongyosi,',
	 'category': u'Computer Science ',
	 'date': '2012-6-26',
	 'pdflink': u'http://arxiv.org/pdf/1206.5996',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nQuantum-assisted and Quantum-based Solutions in Wireless Systems',
	 'urllink': u'http://arxiv.org/abs/1206.5996'}
2015-03-24 00:43:36+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.1542> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:43:36+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.1542>
	{'abstract': u"When a set of permutations comprising a pattern class C is submitted as input to a priority queue the resulting output is again a pattern class C'. The basis of C' is determined for pattern classes C whose basis elements have length 3, and is finite in these cases. An example is given of a class C with basis 2431 for which C is not finitely based.",
	 'authors': u'Michael Albert, M. D. Atkinson,',
	 'category': u'Computer Science ',
	 'date': '2012-2-7',
	 'pdflink': u'http://arxiv.org/pdf/1202.1542',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nPattern classes and priority queues',
	 'urllink': u'http://arxiv.org/abs/1202.1542'}
2015-03-24 00:43:53+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.3002> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:43:53+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.3002>
	{'abstract': u'We consider solving the -regularized least-squares (-LS) problem in the context of sparse recovery, for applications such as compressed sensing. The standard proximal gradient method, also known as iterative soft-thresholding when applied to this problem, has low computational cost per iteration but a rather slow convergence rate. Nevertheless, when the solution is sparse, it often exhibits fast linear convergence in the final stage. We exploit the local linear convergence using a homotopy continuation strategy, i.e., we solve the -LS problem for a sequence of decreasing values of the regularization parameter, and use an approximate solution at the end of each stage to warm start the next stage. Although similar strategies have been studied in the literature, there have been no theoretical analysis of their global iteration complexity. This paper shows that under suitable assumptions for sparse recovery, the proposed homotopy strategy ensures that all iterates along the homotopy solution path are sparse. Therefore the objective function is effectively strongly convex along the solution path, and geometric convergence at each stage can be established. As a result, the overall iteration complexity of our method is for finding an -optimal solution, which can be interpreted as global geometric rate of convergence. We also present empirical results to support our theoretical analysis.',
	 'authors': u'Lin Xiao, Tong Zhang,',
	 'category': u'Computer Science ',
	 'date': '2012-3-14',
	 'pdflink': u'http://arxiv.org/pdf/1203.3002',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nA Proximal-Gradient Homotopy Method for the Sparse Least-Squares Problem',
	 'urllink': u'http://arxiv.org/abs/1203.3002'}
2015-03-24 00:44:12+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.4419> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:44:12+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.4419>
	{'abstract': u'We investigate the geometry of injection regions and its relationship to optimization of power flows in tree networks. The injection region is the set of all vectors of bus power injections that satisfy the network and operation constraints. The geometrical object of interest is the set of Pareto-optimal points of the injection region. If the voltage magnitudes are fixed, the injection region of a tree network can be written as a linear transformation of the product of two-bus injection regions, one for each line in the network. Using this decomposition, we show that under the practical condition that the angle difference across each line is not too large, the set of Pareto-optimal points of the injection region remains unchanged by taking the convex hull. Moreover, the resulting convexified optimal power flow problem can be efficiently solved via',
	 'authors': u'Javad Lavaei, David Tse, Baosen Zhang,',
	 'category': u'Computer Science ',
	 'date': '2012-4-19',
	 'pdflink': u'http://arxiv.org/pdf/1204.4419',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nGeometry of Power Flows and Optimization in Distribution Networks',
	 'urllink': u'http://arxiv.org/abs/1204.4419'}
2015-03-24 00:44:20+0000 [xxu46_4] INFO: Crawled 703 pages (at 4 pages/min), scraped 697 items (at 4 items/min)
2015-03-24 00:44:29+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0184> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:44:29+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0184>
	{'abstract': u"The organizational knowledge is one of the most important and valuable assets of organizations. In such environment, organizations with broad, specialized and up-to-date knowledge, adequately using knowledge resources, will be more successful than their competitors. For effective use of knowledge, dynamic knowledge flow from the sources to destinations is essential. In this regard, a novel complex concept in knowledge management is the analysis, design and implementation of knowledge flow management systems. One of the major challenges in such systems is to explore the knowledge flow from the source to the recipient and control the flow for quality improvements concerning the users' needs as possible. Therefore, the purpose of this paper is to provide an architecture in order to solve this challenge. For this purpose, in addition to the architecture for knowledge flow management systems, a new node selection strategy is provided with higher success rate compared to previous strategies.",
	 'authors': u'Ali Jarrahi, Mohammad Reza Kangavari,',
	 'category': u'Computer Science ',
	 'date': '2012-6-1',
	 'pdflink': u'http://arxiv.org/pdf/1206.0184',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nAn Architecture for Context-Aware Knowledge Flow Management Systems',
	 'urllink': u'http://arxiv.org/abs/1206.0184'}
2015-03-24 00:44:40+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.5980> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:44:40+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.5980>
	{'abstract': u'The superactivation of zero-capacity quantum channels makes it possible to use two zero-capacity quantum channels with a positive joint capacity at the output. Currently, we have no theoretical background for describing all possible combinations of superactive zero-capacity channels; hence, there may be many other possible combinations. In this PhD Thesis I provide an algorithmic solution to the problem of superactivation and prove that superactivation effect is rooted in information geometric issues.',
	 'authors': u'Laszlo Gyongyosi,',
	 'category': u'Computer Science ',
	 'date': '2012-6-25',
	 'pdflink': u'http://arxiv.org/pdf/1206.5980',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nInformation Geometric Superactivation of Asymptotic Quantum Capacity and  Classical Zero-Error Capacity of Zero-Capacity Quantum Channels',
	 'urllink': u'http://arxiv.org/abs/1206.5980'}
2015-03-24 00:44:55+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.1498> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:44:55+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.1498>
	{'abstract': u'Many networks exhibit scale free behavior where their degree distribution obeys a power law for large vertex degrees. Models constructed to explain this phenomena have relied on preferential attachment where the networks grow by the addition of both vertices and edges, and the edges attach themselves to a vertex with a probability proportional to its degree. Simulations hint, though not conclusively, that both growth and preferential attachment are necessary for scale free behavior. We derive analytic expressions for degree distributions for networks that grow by the addition of edges to a fixed number of vertices, based on both linear and non-linear preferential attachment, and show that they fall off exponentially as would be expected for purely random networks. From this we conclude that preferential attachment alone might be necessary but is certainly not a sufficient condition for generating scale free networks.',
	 'authors': u'Vijay K Samalam,',
	 'category': u'Computer Science ',
	 'date': '2012-2-7',
	 'pdflink': u'http://arxiv.org/pdf/1202.1498',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nPreferential attachment alone is not sufficient to generate scale free  random networks',
	 'urllink': u'http://arxiv.org/abs/1202.1498'}
2015-03-24 00:45:10+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.2982> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:45:10+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.2982>
	{'abstract': u'In a recent work [Proc. Natl. Acad. Sci. USA 108, 3838 (2011)], the authors proposed a simple measure for network robustness under malicious attacks on nodes. With a greedy algorithm, they found the optimal structure with respect to this quantity is an onion structure in which high-degree nodes form a core surrounded by rings of nodes with decreasing degree. However, in real networks the failure can also occur in links such as dysfunctional power cables and blocked airlines. Accordingly, complementary to the node-robustness measurement (), we propose a link-robustness index (). We show that solely enhancing cannot guarantee the improvement of . Moreover, the structure of -optimized network is found to be entirely different from that of onion network. In order to design robust networks resistant to more realistic attack condition, we propose a hybrid greedy algorithm which takes both the and into account. We validate the robustness of our generated networks against malicious attacks mixed with both nodes and links failure. Finally, some economical constraints for swapping the links in real networks are considered and significant improvement in both aspects of robustness are still achieved.',
	 'authors': u'An Zeng, Weiping Liu,',
	 'category': u'Computer Science ',
	 'date': '2012-3-14',
	 'pdflink': u'http://arxiv.org/pdf/1203.2982',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nEnhancing network robustness for malicious attacks',
	 'urllink': u'http://arxiv.org/abs/1203.2982'}
2015-03-24 00:45:20+0000 [xxu46_4] INFO: Crawled 707 pages (at 4 pages/min), scraped 701 items (at 4 items/min)
2015-03-24 00:45:25+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.4411> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:45:25+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.4411>
	{'abstract': u'The purpose of this paper is to prove the Frame-Stewart algorithm for the generalized Towers of Hanoi problem as well as finding the number of moves required to solve the problem and studying the multitude of optimal solutions. The main idea is to study how to most effectively move away all but the last disc and use the fact that the total number of moves required to solve the problem is twice this number plus one.',
	 'authors': u'Mikael Erik J\xf6rgensen,',
	 'category': u'Computer Science ',
	 'date': '2012-4-19',
	 'pdflink': u'http://arxiv.org/pdf/1204.4411',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nSolutions to the generalized Towers of Hanoi problem',
	 'urllink': u'http://arxiv.org/abs/1204.4411'}
2015-03-24 00:45:39+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0181> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:45:39+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0181>
	{'abstract': u'In this paper, we consider parametric ideals and introduce a notion of comprehensive involutive system. This notion plays the same role in theory of involutive bases as the notion of comprehensive Groebner system in theory of Groebner bases. Given a parametric ideal, the space of parameters is decomposed into a finite set of cells. Each cell yields the corresponding involutive basis of the ideal for the values of parameters in that cell. Using the Gerdt-Blinkov algorithm for computing involutive bases and also the Montes algorithm for computing comprehensive Groebner systems, we present an algorithm for construction of comprehensive involutive systems. The proposed algorithm has been implemented in Maple, and we provide an illustrative example showing the step-by-step construction of comprehensive involutive system by our algorithm.',
	 'authors': u'Vladimir Gerdt, Amir Hashemi,',
	 'category': u'Computer Science ',
	 'date': '2012-6-1',
	 'pdflink': u'http://arxiv.org/pdf/1206.0181',
	 'subjects': u'Symbolic Computation (cs.SC)',
	 'title': u'\nComprehensive Involutive Systems',
	 'urllink': u'http://arxiv.org/abs/1206.0181'}
2015-03-24 00:45:57+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.5937> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:45:57+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.5937>
	{'abstract': u'"Model-free" control and the related "intelligent" proportional-integral (PI) controllers are successfully applied to freeway ramp metering control. Implementing moreover the corresponding control strategy is straightforward. Numerical simulations on the other hand need the identification of quite complex quantities like the free flow sp ^eed and the critical density. This is achieved thanks to new estimation techniques where the differentiation of noisy signals plays a key r ^ole. Several excellent computer simulations are provided and analyzed.',
	 'authors': u'Hassane Abouaissa, Michel Fliess, Violina Iordanova, C\xe9dric Join,',
	 'category': u'Computer Science ',
	 'date': '2012-6-26',
	 'pdflink': u'http://arxiv.org/pdf/1206.5937',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nFreeway ramp metering control made easy and efficient',
	 'urllink': u'http://arxiv.org/abs/1206.5937'}
2015-03-24 00:46:09+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.1370> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:46:09+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.1370>
	{'abstract': u"Methods for proving functional limit laws are developed for sequences of stochastic processes which allow a recursive distributional decomposition either in time or space. Our approach is an extension of the so-called contraction method to the space of continuous functions endowed with uniform topology and the space of c `dl `g functions with the Skorokhod topology. The contraction method originated form the probabilistic analysis of algorithms and random trees where characteristics satisfy natural distributional recurrences. It is based on stochastic fixed-point equations, where probability metrics can be used to obtain contraction properties and allow the application of Banach's fixed-point theorem. We develop the use of the Zolotarev metrics on the spaces and in this context. Applications are given, in particular a short proof of Donsker's functional limit theorem and to recurrences arising in the probabilistic analysis of algorithms.",
	 'authors': u'Ralph Neininger, Henning Sulzbach,',
	 'category': u'Computer Science ',
	 'date': '2012-2-7',
	 'pdflink': u'http://arxiv.org/pdf/1202.1370',
	 'subjects': u'Probability (math.PR)',
	 'title': u'\nOn a functional contraction method',
	 'urllink': u'http://arxiv.org/abs/1202.1370'}
2015-03-24 00:46:19+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.2946> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:46:19+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.2946>
	{'abstract': u'A new format for storing sparse matrices is proposed for efficient sparse matrix-vector (SpMV) product calculation on modern graphics processing units (GPUs). This format extends the standard compressed row storage (CRS) format and can be quickly converted to and from it. Computational performance of two SpMV kernels for the new format is determined for over 130 sparse matrices on Fermi-class and Kepler-class GPUs and compared with that of five existing generic algorithms and industrial implementations, including Nvidia cuSparse CSR and HYB kernels. We found the speedup of up to over the best of the five alternative kernels.',
	 'authors': u'Zbigniew Koza, Maciej Matyka, Sebastian Szkoda, \u0141ukasz Miros\u0142aw,',
	 'category': u'Computer Science ',
	 'date': '2012-3-13',
	 'pdflink': u'http://arxiv.org/pdf/1203.2946',
	 'subjects': u'Computational Physics (physics.comp-ph)',
	 'title': u'\nCompressed Multi-Row Storage Format for Sparse Matrices on Graphics  Processing Units',
	 'urllink': u'http://arxiv.org/abs/1203.2946'}
2015-03-24 00:46:20+0000 [xxu46_4] INFO: Crawled 712 pages (at 5 pages/min), scraped 706 items (at 5 items/min)
2015-03-24 00:46:32+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.4250> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:46:32+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.4250>
	{'abstract': u'As the size of a multiprocessor system increases, processor failure is inevitable, and fault identification in such a system is crucial for reliable computing. The fault diagnosis is the process of identifying faulty processors in a multiprocessor system through testing. For the practical fault diagnosis systems, the probability that all neighboring processors of a processor are faulty simultaneously is very small, and the conditional diagnosability, which is a new metric for evaluating fault tolerance of such systems, assumes that every faulty set does not contain all neighbors of any processor in the systems. This paper shows that the conditional diagnosability of bubble sort graphs under the PMC model is for , which is about four times its ordinary diagnosability under the PMC model.',
	 'authors': u'Shuming Zhou, Jian Wang, Xirong Xu, Jun-Ming Xu,',
	 'category': u'Computer Science ',
	 'date': '2012-4-19',
	 'pdflink': u'http://arxiv.org/pdf/1204.4250',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nConditional Fault Diagnosis of Bubble Sort Graphs under the PMC Model',
	 'urllink': u'http://arxiv.org/abs/1204.4250'}
2015-03-24 00:46:49+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0169> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:46:49+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0169>
	{'abstract': u'With the high demand of the portable electronic products, Low- power design of VLSI circuits &amp; Power dissipation has been recognized as a challenging technology in the recent years. PLA (Programming logic array) is one of the important off shelf part in the industrial application. This paper describes the new design of PLA using power gating structure sleep transistor at circuit level implementation for the low power applications. The important part of the power gating design i.e. header and footer switch selection is also describes in the paper. The simulating results of the proposed architecture of the new PLA is shown and compared with the conventional PLA. This paper clearly shows the optimization in the reduction of power dissipation in the new design implementation of the PLA. The transient response of the power gates structure of PLA is also illustrate in the paper by using TINA-PRO software.',
	 'authors': u'Pradeep Singla, Kamya Dhingra, Naveen Kr. Malik,',
	 'category': u'Computer Science ',
	 'date': '2012-6-1',
	 'pdflink': u'http://arxiv.org/pdf/1206.0169',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nDSTN (Distributed Sleep Transistor Network) for Low Power Programmable  Logic array Design',
	 'urllink': u'http://arxiv.org/abs/1206.0169'}
2015-03-24 00:47:01+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.5901> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:47:01+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.5901>
	{'abstract': u'Modeling important engineering problems related to flow-induced damage (in the context of hydraulic fracturing among others) depends critically on characterizing the interaction of porous media and interstitial fluid flow. This work presents a new formulation for incorporating the effects of pore pressure in a nonlocal representation of solid mechanics. The result is a framework for modeling fluid-structure interaction problems with the discontinuity capturing advantages of an integral based formulation. A number of numerical examples are used to show that the proposed formulation can be applied to measure the effect of leak-off during hydraulic fracturing as well as modeling consolidation of fluid saturated rock and surface subsidence caused by fluid extraction from a geologic reservoir. The formulation incorporates the effect of pore pressure in the constitutive description of the porous material in a way that is appropriate for nonlinear materials, easily implemented in existing codes, straightforward in its evaluation (no history dependence), and justifiable from first principles. A mixture theory approach is used (deviating only slightly where necessary) to motivate an alteration to the peridynamic pressure term based on the fluid pore pressure. The resulting formulation has a number of similarities to the effective stress principle developed by Terzaghi and Biot and close correspondence is shown between the proposed method and the classical effective stress principle.',
	 'authors': u'Daniel Z. Turner,',
	 'category': u'Computer Science ',
	 'date': '2012-6-26',
	 'pdflink': u'http://arxiv.org/pdf/1206.5901',
	 'subjects': u'Numerical Analysis (math.NA)',
	 'title': u'\nA nonlocal model for fluid-structure interaction with applications in  hydraulic fracturing',
	 'urllink': u'http://arxiv.org/abs/1206.5901'}
2015-03-24 00:47:16+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.1359> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:47:16+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.1359>
	{'abstract': u'In this paper, we quantify how much codes can reduce the data retrieval latency in storage systems. By combining a simple linear code with a novel request scheduling algorithm, which we call Blocking-one Scheduling (BoS), we show analytically that it is possible to reduce data retrieval delay by up to 17% over currently popular replication-based strategies. Although in this work we focus on a simplified setting where the storage system stores a single content, the methodology developed can be applied to more general settings with multiple contents. The results also offer insightful guidance to the design of storage systems in data centers and content distribution networks.',
	 'authors': u'Longbo Huang, Sameer Pawar, Hao Zhang, Kannan Ramchandran,',
	 'category': u'Computer Science ',
	 'date': '2012-2-7',
	 'pdflink': u'http://arxiv.org/pdf/1202.1359',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nCodes Can Reduce Queueing Delay in Data Centers',
	 'urllink': u'http://arxiv.org/abs/1202.1359'}
2015-03-24 00:47:20+0000 [xxu46_4] INFO: Crawled 716 pages (at 4 pages/min), scraped 710 items (at 4 items/min)
2015-03-24 00:47:29+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.2860> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:47:29+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.2860>
	{'abstract': u'This paper considers receding horizon control of finite deterministic systems, which must satisfy a high level, rich specification expressed as a linear temporal logic formula. Under the assumption that time-varying rewards are associated with states of the system and they can be observed in real-time, the control objective is to maximize the collected reward while satisfying the high level task specification. In order to properly react to the changing rewards, a controller synthesis framework inspired by model predictive control is proposed, where the rewards are locally optimized at each time-step over a finite horizon, and the immediate optimal control is applied. By enforcing appropriate constraints, the infinite trajectory produced by the controller is guaranteed to satisfy the desired temporal logic formula. Simulation results demonstrate the effectiveness of the approach.',
	 'authors': u'Xuchu Ding, Mircea Lazar, Calin Belta,',
	 'category': u'Computer Science ',
	 'date': '2012-3-13',
	 'pdflink': u'http://arxiv.org/pdf/1203.2860',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nReceding Horizon Temporal Logic Control for Finite Deterministic Systems',
	 'urllink': u'http://arxiv.org/abs/1203.2860'}
2015-03-24 00:47:45+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.4140> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:47:45+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.4140>
	{'abstract': u'Graph sampling via crawling has been actively considered as a generic and important tool for collecting uniform node samples so as to consistently estimate and uncover various characteristics of complex networks. The so-called simple random walk with re-weighting (SRW-rw) and Metropolis-Hastings (MH) algorithm have been popular in the literature for such unbiased graph sampling. However, an unavoidable downside of their core random walks -- slow diffusion over the space, can cause poor estimation accuracy. In this paper, we propose non-backtracking random walk with re-weighting (NBRW-rw) and MH algorithm with delayed acceptance (MHDA) which are theoretically guaranteed to achieve, at almost no additional cost, not only unbiased graph sampling but also higher efficiency (smaller asymptotic variance of the resulting unbiased estimators) than the SRW-rw and the MH algorithm, respectively. In particular, a remarkable feature of the MHDA is its applicability for any non-uniform node sampling like the MH algorithm, but ensuring better sampling efficiency than the MH algorithm. We also provide simulation results to confirm our theoretical findings.',
	 'authors': u'Chul-Ho Lee, Xin Xu, Do Young Eun,',
	 'category': u'Computer Science ',
	 'date': '2012-4-18',
	 'pdflink': u'http://arxiv.org/pdf/1204.4140',
	 'subjects': u'Methodology (stat.ME)',
	 'title': u'\nBeyond Random Walk and Metropolis-Hastings Samplers: Why You Should Not  Backtrack for Unbiased Graph Sampling',
	 'urllink': u'http://arxiv.org/abs/1204.4140'}
2015-03-24 00:48:02+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0154> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:48:02+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0154>
	{'abstract': u'The local broadcast problem assumes that processes in a wireless network are provided messages, one by one, that must be delivered to their neighbors. In this paper, we prove tight bounds for this problem in two well-studied wireless network models: the classical model, in which links are reliable and collisions consistent, and the more recent dual graph model, which introduces unreliable edges. Our results prove that the Decay strategy, commonly used for local broadcast in the classical setting, is optimal. They also establish a separation between the two models, proving that the dual graph setting is strictly harder than the classical setting, with respect to this primitive.',
	 'authors': u'Mohsen Ghaffari, Bernhard Haeupler, Nancy Lynch, Calvin Newport,',
	 'category': u'Computer Science ',
	 'date': '2012-6-1',
	 'pdflink': u'http://arxiv.org/pdf/1206.0154',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nBounds on Contention Management in Radio Networks',
	 'urllink': u'http://arxiv.org/abs/1206.0154'}
2015-03-24 00:48:18+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.5865> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:48:18+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.5865>
	{'abstract': u"The dynamics of many systems nowadays follow not only physical laws but also man-made rules. These systems are known as discrete event dynamic systems and their performances can be accurately evaluated only through simulations. Existing studies on simulation-based optimization (SBO) usually assume deterministic simulation time for each replication. However, in many applications such as evacuation, smoke detection, and territory exploration, the simulation time is stochastic due to the randomness in the system behavior. We consider the computing budget allocation for SBO's with stochastic simulation time in this paper, which has not been addressed in existing literatures to the author's best knowledge. We make the following major contribution. The relationship between simulation time and performance estimation accuracy is quantified. It is shown that when the asymptotic performance is of interest only the mean value of individual simulation time matters. Then based on the existing optimal computing budget allocation (OCBA) method for deterministic simulation time we develop OCBA for stochastic simulation time (OCBAS), and show that OCBAS is asymptotically optimal. Numerical experiments are used to discuss the impact of the variance of simulation time, the impact of correlated simulation time and performance estimation, and to demonstrate the performance of OCBAS on a smoke detection problem in wireless sensor network. The numerical results also show that OCBA for deterministic simulation time is robust even when the simulation time is stochastic.",
	 'authors': u'Qing-Shan Jia,',
	 'category': u'Computer Science ',
	 'date': '2012-6-26',
	 'pdflink': u'http://arxiv.org/pdf/1206.5865',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nEfficient Computing Budget Allocation for Simulation-based Optimization  with Stochastic Simulation Time',
	 'urllink': u'http://arxiv.org/abs/1206.5865'}
2015-03-24 00:48:20+0000 [xxu46_4] INFO: Crawled 720 pages (at 4 pages/min), scraped 714 items (at 4 items/min)
2015-03-24 00:48:31+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.1342> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:48:31+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.1342>
	{'abstract': u'We consider the problem of recovering items matching a partially specified pattern in multidimensional trees (quadtrees and -d trees). We assume the traditional model where the data consist of independent and uniform points in the unit square. For this model, in a structure on points, it is known that the number of nodes to visit in order to report the items matching a random query , independent and uniformly distributed on , satisfies , where and are explicit constants. We develop an approach based on the analysis of the cost of any fixed query , and give precise estimates for the variance and limit distribution of the cost . Our results permit us to describe a limit process for the costs as varies in ; one of the consequences is that ; this settles a question of Devroye [Pers. Comm., 2000].',
	 'authors': u'Nicolas Broutin, Ralph Neininger, Henning Sulzbach,',
	 'category': u'Computer Science ',
	 'date': '2012-2-7',
	 'pdflink': u'http://arxiv.org/pdf/1202.1342',
	 'subjects': u'Probability (math.PR)',
	 'title': u'\nA limit process for partial match queries in random quadtrees and $2$-d  trees',
	 'urllink': u'http://arxiv.org/abs/1202.1342'}
2015-03-24 00:48:49+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.2851> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:48:49+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.2851>
	{'abstract': u'We analyse the results of our experimental laboratory approximation of motorways networks with slime mould Physarum polycephalum. Motorway networks of fourteen geographical areas are considered: Australia, Africa, Belgium, Brazil, Canada, China, Germany, Iberia, Italy, Malaysia, Mexico, The Netherlands, UK, USA. For each geographical entity we represented major urban areas by oat flakes and inoculated the slime mould in a capital. After slime mould spanned all urban areas with a network of its protoplasmic tubes we extracted a generalised Physarum graph from the network and compared the graphs with an abstract motorway graph using most common measures. The measures employed are the number of independent cycles, cohesion, shortest paths lengths, diameter, the Harary index and the Randic index. We obtained a series of intriguing results, and found that the slime mould approximates best of all the motorway graphs of Belgium, Canada and China, and that for all entities studied the best match between Physarum and motorway graphs is detected by the Randic index (molecular branching index).',
	 'authors': u'Andrew Adamatzky, Selim Akl, Ramon Alonso-Sanz, Wesley van Dessel, Zuwairie Ibrahim, Andrew Ilachinski, Jeff Jones, Anne V. D. M. Kayem, Genaro J. Martinez, Pedro de Oliveira, Mikhail Prokopenko, Theresa Schubert, Peter Sloot, Emanuele Strano, Xin-She Yang,',
	 'category': u'Computer Science ',
	 'date': '2012-3-13',
	 'pdflink': u'http://arxiv.org/pdf/1203.2851',
	 'subjects': u'Pattern Formation and Solitons (nlin.PS)',
	 'title': u"\nAre motorways rational from slime mould's point of view?",
	 'urllink': u'http://arxiv.org/abs/1203.2851'}
2015-03-24 00:49:00+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.4134> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:49:00+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.4134>
	{'abstract': u'We describe Janus, a massively parallel FPGA-based computer optimized for the simulation of spin glasses, theoretical models for the behavior of glassy materials. FPGAs (as compared to GPUs or many-core processors) provide a complementary approach to massively parallel computing. In particular, our model problem is formulated in terms of binary variables, and floating-point operations can be (almost) completely avoided. The FPGA architecture allows us to run many independent threads with almost no latencies in memory access, thus updating up to 1024 spins per cycle. We describe Janus in detail and we summarize the physics results obtained in four years of operation of this machine; we discuss two types of physics applications: long simulations on very large systems (which try to mimic and provide understanding about the experimental non-equilibrium dynamics), and low-temperature equilibrium simulations using an artificial parallel tempering dynamics. The time scale of our non-equilibrium simulations spans eleven orders of magnitude (from picoseconds to a tenth of a second). On the other hand, our equilibrium simulations are unprecedented both because of the low temperatures reached and for the large systems that we have brought to equilibrium. A finite-time scaling ansatz emerges from the detailed comparison of the two sets of simulations. Janus has made it possible to perform spin-glass simulations that would take several decades on more conventional architectures. The paper ends with an assessment of the potential of possible future versions of the Janus architecture, based on state-of-the-art technology.',
	 'authors': u'Janus Collaboration, M. Baity-Jesi, R. A. Banos, A. Cruz, L. A. Fernandez, J. M. Gil-Narvion, A. Gordillo-Guerrero, M. Guidetti, D. Iniguez, A. Maiorano, F. Mantovani, E. Marinari, V. Martin-Mayor, J. Monforte-Garcia, A. Munoz Sudupe, D. Navarro, G. Parisi, M. Pivanti, S. Perez-Gaviro, F. Ricci-Tersenghi, J. J. Ruiz-Lorenzo, S. F. Schifano, B. Seoane, A. Tarancon, P. Tellez, R. Tripiccione, D. Yllanes,',
	 'category': u'Computer Science ',
	 'date': '2012-4-18',
	 'pdflink': u'http://arxiv.org/pdf/1204.4134',
	 'subjects': u'Disordered Systems and Neural Networks (cond-mat.dis-nn)',
	 'title': u'\nReconfigurable computing for Monte Carlo simulations: results and  prospects of the Janus project',
	 'urllink': u'http://arxiv.org/abs/1204.4134'}
2015-03-24 00:49:14+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0150> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:49:14+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0150>
	{'abstract': u'We consider the problem of computing a maximal independent set (MIS) in an extremely harsh broadcast model that relies only on carrier sensing. The model consists of an anonymous broadcast network in which nodes have no knowledge about the topology of the network or even an upper bound on its size. Furthermore, it is assumed that an adversary chooses at which time slot each node wakes up. At each time slot a node can either beep, that is, emit a signal, or be silent. At a particular time slot, beeping nodes receive no feedback, while silent nodes can only differentiate between none of its neighbors beeping, or at least one of its neighbors beeping. We start by proving a lower bound that shows that in this model, it is not possible to locally converge to an MIS in sub-polynomial time. We then study four different relaxations of the model which allow us to circumvent the lower bound and find an MIS in polylogarithmic time. First, we show that if a polynomial upper bound on the network size is known, it is possible to find an MIS in O(log^3 n) time. Second, if we assume sleeping nodes are awoken by neighboring beeps, then we can also find an MIS in O(log^3 n) time. Third, if in addition to this wakeup assumption we allow sender-side collision detection, that is, beeping nodes can distinguish whether at least one neighboring node is beeping concurrently or not, we can find an MIS in O(log^2 n) time. Finally, if instead we endow nodes with synchronous clocks, it is also possible to find an MIS in O(log^2 n) time.',
	 'authors': u'Yehuda Afek, Noga Alon, Ziv Bar-Joseph, Alejandro Cornejo, Bernhard Haeupler, Fabian Kuhn,',
	 'category': u'Computer Science ',
	 'date': '2012-6-1',
	 'pdflink': u'http://arxiv.org/pdf/1206.0150',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nBeeping a Maximal Independent Set',
	 'urllink': u'http://arxiv.org/abs/1206.0150'}
2015-03-24 00:49:20+0000 [xxu46_4] INFO: Crawled 724 pages (at 4 pages/min), scraped 718 items (at 4 items/min)
2015-03-24 00:49:29+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.5863> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:49:29+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.5863>
	{'abstract': u'Frameproof codes are used to preserve the security in the context of coalition when fingerprinting digital data. Let be the largest cardinality of a -ary -frameproof code of length and . It has been determined by Blackburn that when , when and is even, and . In this paper, we give a recursive construction for -frameproof codes of length with respect to the alphabet size . As applications of this construction, we establish the existence results for -ary -frameproof codes of length and size for all odd when and for all when . Furthermore, we show that meeting the upper bound given by Blackburn, for all integers such that is a prime power.',
	 'authors': u'Yeow Meng Chee, Xiande Zhang,',
	 'category': u'Computer Science ',
	 'date': '2012-6-26',
	 'pdflink': u'http://arxiv.org/pdf/1206.5863',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nImproved Constructions of Frameproof Codes',
	 'urllink': u'http://arxiv.org/abs/1206.5863'}
2015-03-24 00:49:41+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.1330> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:49:41+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.1330>
	{'abstract': u'We present the result of a dual modeling of opinion network. The model complements the agent-based opinion models by attaching to the social agent (voters) network a political opinion (party) network having its own intrinsic mechanisms of evolution. These two sub-networks form a global network which can be either isolated from or dependent on the external influence. Basically, the evolution of the agent network includes link adding and deleting, the opinion changes influenced by social validation, the political climate, the attractivity of the parties and the interaction between them. The opinion network is initially composed of numerous nodes representing opinions or parties which are located on a one dimensional axis according to their political positions. The mechanism of evolution includes union, splitting, change of position and of attractivity, taken into account the pairwise node interaction decaying with node distance in power law. The global evolution ends in a stable distribution of the social agents over a quasi-stable and fluctuating stationary number of remaining parties. Empirical study on the lifetime distribution of numerous parties and vote results is carried out to verify numerical results.',
	 'authors': u'Ru Wang, Qiuping Alexandre Wang,',
	 'category': u'Computer Science ',
	 'date': '2012-2-7',
	 'pdflink': u'http://arxiv.org/pdf/1202.1330',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nA dual modelling of evolving political opinion networks',
	 'urllink': u'http://arxiv.org/abs/1202.1330'}
2015-03-24 00:49:56+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.2821> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:49:56+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.2821>
	{'abstract': u'We introduce the graphlet decomposition of a weighted network, which encodes a notion of social information based on social structure. We develop a scalable inference algorithm, which combines EM with Bron-Kerbosch in a novel fashion, for estimating the parameters of the model underlying graphlets using one network sample. We explore some theoretical properties of the graphlet decomposition, including computational complexity, redundancy and expected accuracy. We demonstrate graphlets on synthetic and real data. We analyze messaging patterns on Facebook and criminal associations in the 19th century.',
	 'authors': u'Hossein Azari Soufiani, Edoardo M Airoldi,',
	 'category': u'Computer Science ',
	 'date': '2012-3-13',
	 'pdflink': u'http://arxiv.org/pdf/1203.2821',
	 'subjects': u'Methodology (stat.ME)',
	 'title': u'\nGraphlet decomposition of a weighted network',
	 'urllink': u'http://arxiv.org/abs/1203.2821'}
2015-03-24 00:50:11+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1204.4122> (referer: http://arxiv.org/list/cs/12?skip=3000&show=1000)
2015-03-24 00:50:11+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1204.4122>
	{'abstract': u'We study the structure of inter-industry relationships using networks of money flows between industries in 20 national economies. We find these networks vary around a typical structure characterized by a Weibull link weight distribution, exponential industry size distribution, and a common community structure. The community structure is hierarchical, with the top level of the hierarchy comprising five industry communities: food industries, chemical industries, manufacturing industries, service industries, and extraction industries.',
	 'authors': u'James McNerney, Brian D. Fath, Gerald Silverberg,',
	 'category': u'Computer Science ',
	 'date': '2012-4-18',
	 'pdflink': u'http://arxiv.org/pdf/1204.4122',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nNetwork structure of inter-industry flows',
	 'urllink': u'http://arxiv.org/abs/1204.4122'}
2015-03-24 00:50:20+0000 [xxu46_4] INFO: Crawled 728 pages (at 4 pages/min), scraped 722 items (at 4 items/min)
2015-03-24 00:50:23+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.0142> (referer: http://arxiv.org/list/cs/12?skip=4000&show=1000)
2015-03-24 00:50:23+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.0142>
	{'abstract': u'This present project is developing a geographic information system to support the cadastral business. This system based on open source solutions which developed within the National Agency of Land Registry, Cadastre and Cartography (ANCFCC) enabling monitoring and analysis of cadastral procedures as well as offering consumable services by other information systems: consultation and querying spatial data. The project will also assist the various user profiles in the completion of production tasks and the possibility to eliminate the deficiencies identified to ensure an optimum level of productivity',
	 'authors': u'Hicham Elasri, Neknane Mehdi, Aatab Jamila, Ganoun Karima,',
	 'category': u'Computer Science ',
	 'date': '2012-6-1',
	 'pdflink': u'http://arxiv.org/pdf/1206.0142',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nOpen source based cadastral information system : ANCFCC-MOROCCO',
	 'urllink': u'http://arxiv.org/abs/1206.0142'}
2015-03-24 00:50:33+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1206.5856> (referer: http://arxiv.org/list/cs/12?skip=5000&show=1000)
2015-03-24 00:50:33+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1206.5856>
	{'abstract': u"Each year, crowd disasters happen in different areas of the world. How and why do such disasters happen? Are the fatalities caused by relentless behavior of people or a psychological state of panic that makes the crowd 'go mad'? Or are they a tragic consequence of a breakdown of coordination? These and other questions are addressed, based on a qualitative analysis of publicly available videos and materials, which document the planning and organization of the Love Parade in Duisburg, Germany, and the crowd disaster on July 24, 2010. Our analysis reveals a number of misunderstandings that have widely spread. We also provide a new perspective on concepts such as 'intentional pushing', 'mass panic', 'stampede', and 'crowd crushs'. The focus of our analysis is on the contributing causal factors and their mutual interdependencies, not on legal issues or the judgment of personal or institutional responsibilities. Video recordings show that, in Duisburg, people stumbled and piled up due to a 'domino effect', resulting from a phenomenon called 'crowd turbulence' or 'crowd quake'. Crowd quakes are a typical reason for crowd disasters, to be distinguished from crowd disasters resulting from 'panic stampedes' or 'crowd crushes'. In Duisburg, crowd turbulence was the consequence of amplifying feedback and cascading effects, which are typical for systemic instabilities. Accordingly, things can go terribly wrong in spite of no bad intentions from anyone. Comparing the incident in Duisburg with others, we give recommendations to help prevent future crowd disasters. In particular, we introduce a new scale to assess the criticality of conditions in the crowd. This may allow preventative measures to be taken earlier on. Furthermore, we discuss the merits and limitations of citizen science for public investigation, considering that today, almost every event is recorded and reflected in the World Wide Web.",
	 'authors': u'Dirk Helbing, Pratik Mukerji,',
	 'category': u'Computer Science ',
	 'date': '2012-6-25',
	 'pdflink': u'http://arxiv.org/pdf/1206.5856',
	 'subjects': u'Chaotic Dynamics (nlin.CD)',
	 'title': u'\nCrowd Disasters as Systemic Failures: Analysis of the Love Parade  Disaster',
	 'urllink': u'http://arxiv.org/abs/1206.5856'}
2015-03-24 00:50:50+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1202.1303> (referer: http://arxiv.org/list/cs/12?skip=1000&show=1000)
2015-03-24 00:50:50+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1202.1303>
	{'abstract': u"We present a novel algorithm for deciding whether a given planar curve is an image of a given spatial curve, obtained by a central or a parallel projection with unknown parameters. A straightforward approach to this problem consists of setting up a system of conditions on the projection parameters and then checking whether or not this system has a solution. The main advantage of the algorithm presented here, in comparison to algorithms based on the straightforward approach, lies in a significant reduction of a number of real parameters that need to be eliminated in order to establish existence or non-existence of a projection that maps a given spatial curve to a given planar curve. Our algorithm is based on projection criteria that reduce the projection problem to a certain modification of the equivalence problem of planar curves under affine and projective transformations. The latter problem is then solved by differential signature construction based on Cartan's moving frame method. A similar approach can be used to decide whether a given finite set of ordered points on a plane is an image of a given finite set of ordered points in R^3. The motivation comes from the problem of establishing a correspondence between an object and an image, taken by a camera with unknown position and parameters.",
	 'authors': u'Joseph M. Burdis, Irina A. Kogan,',
	 'category': u'Computer Science ',
	 'date': '2012-2-6',
	 'pdflink': u'http://arxiv.org/e-print/1202.1303',
	 'subjects': u'Algebraic Geometry (math.AG)',
	 'title': u'\nObject-image correspondence for curves under projections',
	 'urllink': u'http://arxiv.org/abs/1202.1303'}
2015-03-24 00:51:00+0000 [xxu46_4] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1203.2742> (referer: http://arxiv.org/list/cs/12?skip=2000&show=1000)
2015-03-24 00:51:00+0000 [xxu46_4] DEBUG: Scraped from <200 http://arxiv.org/abs/1203.2742>
	{'abstract': u'Algorithms are presented for evaluating gradients and Hessians of logarithmic barrier functions for two types of convex cones: the cone of positive semidefinite matrices with a given sparsity pattern, and its dual cone, the cone of sparse matrices with the same pattern that have a positive semidefinite completion. Efficient large-scale algorithms for evaluating these barriers and their derivatives are important in interior-point methods for nonsymmetric conic formulations of sparse semidefinite programs. The algorithms are based on the multifrontal method for sparse Cholesky factorization.',
	 'authors': u'Martin S. Andersen, Joachim Dahl, Lieven Vandenberghe,',
	 'category': u'Computer Science ',
	 'date': '2012-3-13',
	 'pdflink': u'http://arxiv.org/pdf/1203.2742',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nLogarithmic barriers for sparse matrix cones',
	 'urllink': u'http://arxiv.org/abs/1203.2742'}
