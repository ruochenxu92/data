nohup: ignoring input
2015-03-23 21:42:08+0000 [scrapy] INFO: Scrapy 0.24.5 started (bot: superqq_spider)
2015-03-23 21:42:08+0000 [scrapy] INFO: Optional features available: ssl, http11, boto
2015-03-23 21:42:08+0000 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'superqq_spider.spiders', 'SPIDER_MODULES': ['superqq_spider.spiders'], 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 81, 'BOT_NAME': 'superqq_spider'}
2015-03-23 21:42:08+0000 [scrapy] INFO: Enabled extensions: LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, SpiderState
2015-03-23 21:42:09+0000 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentPoolMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-03-23 21:42:09+0000 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-03-23 21:42:09+0000 [scrapy] INFO: Enabled item pipelines: JsonWriterPipeline
2015-03-23 21:42:09+0000 [xxu46_7] INFO: Spider opened
2015-03-23 21:42:09+0000 [xxu46_7] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-03-23 21:42:09+0000 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6029
2015-03-23 21:42:09+0000 [scrapy] DEBUG: Web service listening on 127.0.0.1:6086
2015-03-23 21:42:39+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/list/cs/14?skip=0&show=1000> (referer: None)
2015-03-23 21:43:09+0000 [xxu46_7] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2015-03-23 21:43:38+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/list/cs/13?skip=14000&show=1000> (referer: None)
2015-03-23 21:44:09+0000 [xxu46_7] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2015-03-23 21:44:56+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/list/cs/13?skip=13000&show=1000> (referer: None)
2015-03-23 21:45:09+0000 [xxu46_7] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2015-03-23 21:46:09+0000 [xxu46_7] INFO: Crawled 3 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-03-23 21:46:37+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/list/cs/13?skip=12000&show=1000> (referer: None)
2015-03-23 21:47:09+0000 [xxu46_7] INFO: Crawled 4 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2015-03-23 21:48:21+0000 [xxu46_7] INFO: Crawled 4 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-03-23 21:48:39+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/list/cs/13?skip=11000&show=1000> (referer: None)
2015-03-23 21:49:13+0000 [xxu46_7] INFO: Crawled 5 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2015-03-23 21:54:51+0000 [xxu46_7] INFO: Crawled 5 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-03-23 21:55:05+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/list/cs/13?skip=10000&show=1000> (referer: None)
2015-03-23 21:55:09+0000 [xxu46_7] INFO: Crawled 6 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2015-03-23 21:55:57+0000 [xxu46_7] DEBUG: Filtered duplicate request: <GET http://arxiv.org/abs/1309.0569> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2015-03-23 21:56:09+0000 [xxu46_7] INFO: Crawled 6 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-03-23 21:56:42+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/list/cs/13?skip=9000&show=1000> (referer: None)
2015-03-23 21:57:09+0000 [xxu46_7] INFO: Crawled 7 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2015-03-23 21:58:09+0000 [xxu46_7] INFO: Crawled 7 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-03-23 21:58:21+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1401.0001> (referer: http://arxiv.org/list/cs/14?skip=0&show=1000)
2015-03-23 21:58:22+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1401.0001>
	{'abstract': u'In some games, additional information hurts a player, e.g., in games with first-mover advantage, the second-mover is hurt by seeing the first-mover\'s move. What properties of a game determine whether it has such negative "value of information" for a particular player? Can a game have negative value of information for all players? To answer such questions, we generalize the definition of marginal utility of a good to define the marginal utility of a parameter vector specifying a game. So rather than analyze the global structure of the relationship between a game\'s parameter vector and player behavior, as in previous work, we focus on the local structure of that relationship. This allows us to prove that generically, every game can have negative marginal value of information, unless one imposes a priori constraints on allowed changes to the game\'s parameter vector. We demonstrate these and related results numerically, and discuss their implications.',
	 'authors': u'Nils Bertschinger, David H. Wolpert, Eckehard Olbrich, Juergen Jost,',
	 'category': u'Computer Science ',
	 'date': '2013-12-27',
	 'pdflink': u'http://arxiv.org/pdf/1401.0001',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nValue of information in noncooperative games',
	 'urllink': u'http://arxiv.org/abs/1401.0001'}
2015-03-23 21:59:09+0000 [xxu46_7] INFO: Crawled 8 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2015-03-23 21:59:23+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1401.0034> (referer: http://arxiv.org/list/cs/14?skip=0&show=1000)
2015-03-23 21:59:23+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1401.0034>
	{'abstract': u'Mobile cloud computing is a new technology that enhances smartphone applications capabilities in terms of performance, energy efficiency, and execution support. These features are achieved via computation offloading technique that is supported by specialized mobile cloud application development models. However, the cloud-enabled applications are prone to application piracy issue for which the traditional licensing frameworks are of no use. Therefore, a new licensing framework is required to control application piracy in mobile cloud environment. This paper presents a preliminary design of a novel application licensing framework for mobile cloud environment that restricts execution of applications on unauthenticated smartphones and cloud resources.',
	 'authors': u'Atta ur Rehman Khan, Mazliza Othman, Abdul Nasir Khan,',
	 'category': u'Computer Science ',
	 'date': '2013-12-30',
	 'pdflink': u'http://arxiv.org/pdf/1401.0034',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nA Novel Application Licensing Framework for Mobile Cloud Environment',
	 'urllink': u'http://arxiv.org/abs/1401.0034'}
2015-03-23 22:00:09+0000 [xxu46_7] INFO: Crawled 9 pages (at 1 pages/min), scraped 2 items (at 1 items/min)
2015-03-23 22:01:09+0000 [xxu46_7] INFO: Crawled 9 pages (at 0 pages/min), scraped 2 items (at 0 items/min)
2015-03-23 22:01:19+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1401.0042> (referer: http://arxiv.org/list/cs/14?skip=0&show=1000)
2015-03-23 22:01:19+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1401.0042>
	{'abstract': u'We give algorithms for geometric graph problems in the modern parallel models inspired by MapReduce. For example, for the Minimum Spanning Tree (MST) problem over a set of points in the two-dimensional space, our algorithm computes a -approximate MST. Our algorithms work in a constant number of rounds of communication, while using total space and communication proportional to the size of the data (linear space and near linear time algorithms). In contrast, for general graphs, achieving the same result for MST (or even connectivity) remains a challenging open problem, despite drawing significant attention in recent years. We develop a general algorithmic framework that, besides MST, also applies to Earth-Mover Distance (EMD) and the transportation cost problem. Our algorithmic framework has implications beyond the MapReduce model. For example it yields a new algorithm for computing EMD cost in the plane in near-linear time, . We note that while recently Sharathkumar and Agarwal developed a near-linear time algorithm for -approximating EMD, our algorithm is fundamentally different, and, for example, also solves the transportation (cost) problem, raised as an open question in their work. Furthermore, our algorithm immediately gives a -approximation algorithm with space in the streaming-with-sorting model with passes. As such, it is tempting to conjecture that the parallel models may also constitute a concrete playground in the quest for efficient algorithms for EMD (and other similar problems) in the vanilla streaming model, a well-known open problem.',
	 'authors': u'Alexandr Andoni, Aleksandar Nikolov, Krzysztof Onak, Grigory Yaroslavtsev,',
	 'category': u'Computer Science ',
	 'date': '2013-12-30',
	 'pdflink': u'http://arxiv.org/pdf/1401.0042',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nParallel Algorithms for Geometric Graph Problems',
	 'urllink': u'http://arxiv.org/abs/1401.0042'}
2015-03-23 22:02:09+0000 [xxu46_7] INFO: Crawled 10 pages (at 1 pages/min), scraped 3 items (at 1 items/min)
2015-03-23 22:02:48+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1401.0044> (referer: http://arxiv.org/list/cs/14?skip=0&show=1000)
2015-03-23 22:02:48+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1401.0044>
	{'abstract': u'When belief propagation (BP) converges, it does so to a stationary point of the Bethe free energy , and is often strikingly accurate. However, it may converge only to a local optimum or may not converge at all. An algorithm was recently introduced for attractive binary pairwise MRFs which is guaranteed to return an -approximation to the global minimum of in polynomial time provided the maximum degree , where is the number of variables. Here we significantly improve this algorithm and derive several results including a new approach based on analyzing first derivatives of , which leads to performance that is typically far superior and yields a fully polynomial-time approximation scheme (FPTAS) for attractive models without any degree restriction. Further, the method applies to general (non-attractive) models, though with no polynomial time guarantee in this case, leading to the important result that approximating of the Bethe partition function, , for a general model to additive -accuracy may be reduced to a discrete MAP inference problem. We explore an application to predicting equipment failure on an urban power network and demonstrate that the Bethe approximation can perform well even when BP fails to converge.',
	 'authors': u'Adrian Weller, Tony Jebara,',
	 'category': u'Computer Science ',
	 'date': '2013-12-30',
	 'pdflink': u'http://arxiv.org/pdf/1401.0044',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nApproximating the Bethe partition function',
	 'urllink': u'http://arxiv.org/abs/1401.0044'}
2015-03-23 22:03:09+0000 [xxu46_7] INFO: Crawled 11 pages (at 1 pages/min), scraped 4 items (at 1 items/min)
2015-03-23 22:04:00+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1401.0050> (referer: http://arxiv.org/list/cs/14?skip=0&show=1000)
2015-03-23 22:04:00+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1401.0050>
	{'abstract': u'A binary code is called a superimposed cover-free -code if the code is identified by the incidence matrix of a family of finite sets in which no intersection of sets is covered by the union of others. A binary code is called a superimposed list-decoding -code if the code is identified by the incidence matrix of a family of finite sets in which the union of any sets can cover not more than other sets of the family. For , both of the definitions coincide and the corresponding binary code is called a superimposed -code. Our aim is to obtain new lower and upper bounds on the rate of given codes. The most interesting result is a lower bound on the rate of superimposed cover-free -code based on the ensemble of constant-weight binary codes. If parameter is fixed and , then the ratio of this lower bound to the best known upper bound converges to the limit . For the classical case and , the given Statement means that our recurrent upper bound on the rate of superimposed -codes obtained in 1982 is attained to within a constant factor ,',
	 'authors': u"Arkady D'yachkov, Ilya Vorobyev, Nikita Polianskii, Vladislav Shchukin,",
	 'category': u'Computer Science ',
	 'date': '2013-12-30',
	 'pdflink': u'http://arxiv.org/pdf/1401.0050',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nBounds on the rate of superimposed codes',
	 'urllink': u'http://arxiv.org/abs/1401.0050'}
2015-03-23 22:04:09+0000 [xxu46_7] INFO: Crawled 12 pages (at 1 pages/min), scraped 5 items (at 1 items/min)
2015-03-23 22:05:09+0000 [xxu46_7] INFO: Crawled 12 pages (at 0 pages/min), scraped 5 items (at 0 items/min)
2015-03-23 22:05:52+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1401.0052> (referer: http://arxiv.org/list/cs/14?skip=0&show=1000)
2015-03-23 22:05:52+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1401.0052>
	{'abstract': u'Today people increasingly have the opportunity to opt-in to "usage-based" automotive insurance programs for reducing insurance premiums. In these programs, participants install devices in their vehicles that monitor their driving behavior, which raises some privacy concerns. Some devices collect fine-grained speed data to monitor driving habits. Companies that use these devices claim that their approach is privacy-preserving because speedometer measurements do not have physical locations. However, we show that with knowledge of the user\'s home location, as the insurance companies have, speed data is sufficient to discover driving routes and destinations when trip data is collected over a period of weeks. To demonstrate the real-world applicability of our approach we applied our algorithm, elastic pathing, to data collected over hundreds of driving trips occurring over several months. With this data and our approach, we were able to predict trip destinations to within 250 meters of ground truth in 10% of the traces and within 500 meters in 20% of the traces. This result, combined with the amount of speed data that is being collected by insurance companies, constitutes a substantial breach of privacy because a person\'s regular driving pattern can be deduced with repeated examples of the same paths with just a few weeks of monitoring.',
	 'authors': u'Bernhard Firner, Shridatt Sugrim, Yulong Yang, Janne Lindqvist,',
	 'category': u'Computer Science ',
	 'date': '2013-12-30',
	 'pdflink': u'http://arxiv.org/pdf/1401.0052',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nElastic Pathing: Your Speed is Enough to Track You',
	 'urllink': u'http://arxiv.org/abs/1401.0052'}
2015-03-23 22:06:09+0000 [xxu46_7] INFO: Crawled 13 pages (at 1 pages/min), scraped 6 items (at 1 items/min)
2015-03-23 22:07:04+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1401.0069> (referer: http://arxiv.org/list/cs/14?skip=0&show=1000)
2015-03-23 22:07:04+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1401.0069>
	{'abstract': u'Access limitations are restrictions in the way in which the tuples of a relation can be accessed. Under access limitations, query answering becomes more complex than in the traditional case, with no guarantee that the answer tuples that can be extracted (aka maximal answer) are all those that would be found without access limitations (aka complete answer). The field of query answering under access limitations has been broadly investigated in the past. Attention has been devoted to the problem of determining relations that are relevant for a query, i.e., those (possibly off-query) relations that might need to be accessed in order to find all tuples in the maximal answer. In this short paper, we show that relevance is undecidable for Datalog queries.',
	 'authors': u'Davide Martinenghi,',
	 'category': u'Computer Science ',
	 'date': '2013-12-31',
	 'pdflink': u'http://arxiv.org/pdf/1401.0069',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nDetermining Relevant Relations for Datalog Queries under Access  Limitations is Undecidable',
	 'urllink': u'http://arxiv.org/abs/1401.0069'}
2015-03-23 22:07:09+0000 [xxu46_7] INFO: Crawled 14 pages (at 1 pages/min), scraped 7 items (at 1 items/min)
2015-03-23 22:08:09+0000 [xxu46_7] INFO: Crawled 14 pages (at 0 pages/min), scraped 7 items (at 0 items/min)
2015-03-23 22:08:23+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1401.0077> (referer: http://arxiv.org/list/cs/14?skip=0&show=1000)
2015-03-23 22:08:23+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1401.0077>
	{'abstract': u'Multi-modal densities appear frequently in time series and practical applications. However, they cannot be represented by common state estimators, such as the Extended Kalman Filter (EKF) and the Unscented Kalman Filter (UKF), which additionally suffer from the fact that uncertainty is often not captured sufficiently well, which can result in incoherent and divergent tracking performance. In this paper, we address these issues by devising a non-linear filtering algorithm where densities are represented by Gaussian mixture models, whose parameters are estimated in closed form. The resulting method exhibits a superior performance on typical benchmarks.',
	 'authors': u'Sanket Kamthe, Jan Peters, Marc P Deisenroth,',
	 'category': u'Computer Science ',
	 'date': '2013-12-31',
	 'pdflink': u'http://arxiv.org/pdf/1401.0077',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nMulti-modal filtering for non-linear estimation',
	 'urllink': u'http://arxiv.org/abs/1401.0077'}
2015-03-23 22:09:09+0000 [xxu46_7] INFO: Crawled 15 pages (at 1 pages/min), scraped 8 items (at 1 items/min)
2015-03-23 22:09:53+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1401.0085> (referer: http://arxiv.org/list/cs/14?skip=0&show=1000)
2015-03-23 22:09:53+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1401.0085>
	{'abstract': u'In this paper, we introduce a variant of spectral sparsification, called probabilistic -spectral sparsification. Roughly speaking, it preserves the cut value of any cut with an multiplicative error and a additive error. We show how to produce a probabilistic -spectral sparsifier with edges in time time for unweighted undirected graph. This gives fastest known sub-linear time algorithms for different cut problems on unweighted undirected graph such as - An time -approximation algorithm for the sparsest cut problem and the balanced separator problem. - A time approximation minimum s-t cut algorithm with an additive error.',
	 'authors': u'Yin Tat Lee,',
	 'category': u'Computer Science ',
	 'date': '2013-12-31',
	 'pdflink': u'http://arxiv.org/pdf/1401.0085',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nProbabilistic Spectral Sparsification In Sublinear Time',
	 'urllink': u'http://arxiv.org/abs/1401.0085'}
2015-03-23 22:10:09+0000 [xxu46_7] INFO: Crawled 16 pages (at 1 pages/min), scraped 9 items (at 1 items/min)
2015-03-23 22:11:09+0000 [xxu46_7] INFO: Crawled 16 pages (at 0 pages/min), scraped 9 items (at 0 items/min)
2015-03-23 22:11:28+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1401.0092> (referer: http://arxiv.org/list/cs/14?skip=0&show=1000)
2015-03-23 22:11:28+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1401.0092>
	{'abstract': u'In identity management system, commonly used biometric recognition system needs attention towards issue of biometric template protection as far as more reliable solution is concerned. In view of this biometric template protection algorithm should satisfy security, discriminability and cancelability. As no single template protection method is capable of satisfying the basic requirements, a novel technique for face template generation and protection is proposed. The novel approach is proposed to provide security and accuracy in new user enrollment as well as authentication process. This novel technique takes advantage of both the hybrid approach and the binary discriminant analysis algorithm. This algorithm is designed on the basis of random projection, binary discriminant analysis and fuzzy commitment scheme. Three publicly available benchmark face databases are used for evaluation. The proposed novel technique enhances the discriminability and recognition accuracy by 80% in terms of matching score of the face images and provides high security.',
	 'authors': u'Shraddha S. Shinde, Prof. Anagha P. Khedkar,',
	 'category': u'Computer Science ',
	 'date': '2013-12-31',
	 'pdflink': u'http://arxiv.org/pdf/1401.0092',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nA Novel Approach For Generating Face Template Using Bda',
	 'urllink': u'http://arxiv.org/abs/1401.0092'}
2015-03-23 22:12:09+0000 [xxu46_7] INFO: Crawled 17 pages (at 1 pages/min), scraped 10 items (at 1 items/min)
2015-03-23 22:12:49+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1401.3250> (referer: http://arxiv.org/list/cs/14?skip=0&show=1000)
2015-03-23 22:12:49+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1401.3250>
	{'abstract': u'This work focuses on studying the half-duplex (HD) relaying in the Multiple Access Relay Channel (MARC) and the Compound Multiple Access Channel with a Relay (cMACr). A generalized Quantize-and-Forward (GQF) has been proposed to establish the achievable rate regions. Such scheme is developed based on the variation of the Quantize-and-Forward (QF) scheme and single block with two slots coding structure. The results in this paper can also be considered as a significant extension of the achievable rate region of Half-Duplex Relay Channel (HDRC). Furthermore, the rate regions based on GQF scheme is extended to the Gaussian channel case. The scheme performance is shown through some numerical examples.',
	 'authors': u'Ming Lei, Mohammad Reza Soleymani,',
	 'category': u'Computer Science ',
	 'date': '2014-1-14',
	 'pdflink': u'http://arxiv.org/pdf/1401.3250',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nHalf-Duplex Relaying for the Multiuser Channel',
	 'urllink': u'http://arxiv.org/abs/1401.3250'}
2015-03-23 22:13:09+0000 [xxu46_7] INFO: Crawled 18 pages (at 1 pages/min), scraped 11 items (at 1 items/min)
2015-03-23 22:14:08+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1312.4833> (referer: http://arxiv.org/list/cs/13?skip=14000&show=1000)
2015-03-23 22:14:08+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1312.4833>
	{'abstract': u"This paper describes our ongoing work on security verification against inference attacks on data trees. We focus on infinite secrecy against inference attacks, which means that attackers cannot narrow down the candidates for the value of the sensitive information to finite by available information to the attackers. Our purpose is to propose a model under which infinite secrecy is decidable. To be specific, we first propose tree transducers which are expressive enough to represent practical queries. Then, in order to represent attackers' knowledge, we propose data tree types such that type inference and inverse type inference on those tree transducers are possible with respect to data tree types, and infiniteness of data tree types is decidable.",
	 'authors': u'Ryo Iwase, Yasunori Ishihara, Toru Fujiwara,',
	 'category': u'Computer Science ',
	 'date': '2013-11-21',
	 'pdflink': u'http://arxiv.org/pdf/1312.4833',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nToward Security Verification against Inference Attacks on Data Trees',
	 'urllink': u'http://arxiv.org/abs/1312.4833'}
2015-03-23 22:14:09+0000 [xxu46_7] INFO: Crawled 19 pages (at 1 pages/min), scraped 12 items (at 1 items/min)
2015-03-23 22:15:09+0000 [xxu46_7] INFO: Crawled 19 pages (at 0 pages/min), scraped 12 items (at 0 items/min)
2015-03-23 22:15:59+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1311.6009> (referer: http://arxiv.org/list/cs/13?skip=13000&show=1000)
2015-03-23 22:15:59+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1311.6009>
	{'abstract': u'The response time of the smart electrical vehicle (EV) charging infrastructure is the key index of the system performance. The traffic between the smart EV charging station and the control center dominates the response time of the smart charging stations. To accelerate the response of the smart EV charging station, there is a need for a technology that collects the information locally and relays it to the control center periodically. To reduce the traffic between the smart EV charger and the control center, a Power Information Collector (PIC), capable of collecting all the meters power information in the charging station, is proposed and implemented in this paper. The response time is further reduced by pushing the power information to the control center. Thus, a fast response smart EV charging infrastructure is achieved to handle the shortage of energy in the local grid.',
	 'authors': u'Ching-Yen Chung, Joshua Chynoweth, Charlie Qiu, Chi-Cheng Chu, Rajit Gadh,',
	 'category': u'Computer Science ',
	 'date': '2013-11-23',
	 'pdflink': u'http://arxiv.org/pdf/1311.6009',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nDesign of Fast Response Smart Electric Vehicle Charging Infrastructure',
	 'urllink': u'http://arxiv.org/abs/1311.6009'}
2015-03-23 22:16:09+0000 [xxu46_7] INFO: Crawled 20 pages (at 1 pages/min), scraped 13 items (at 1 items/min)
2015-03-23 22:17:09+0000 [xxu46_7] INFO: Crawled 20 pages (at 0 pages/min), scraped 13 items (at 0 items/min)
2015-03-23 22:17:53+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.8148> (referer: http://arxiv.org/list/cs/13?skip=12000&show=1000)
2015-03-23 22:17:53+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.8148>
	{'abstract': u'We study the question of whether, for a given class of finite graphs, one can define, for each graph of the class, a linear ordering in monadic second-order logic, possibly with the help of monadic parameters. We consider two variants of monadic second-order logic: one where we can only quantify over sets of vertices and one where we can also quantify over sets of edges. For several special cases, we present combinatorial characterisations of when such a linear ordering is definable. In some cases, for instance for graph classes that omit a fixed graph as a minor, the presented conditions are necessary and sufficient; in other cases, they are only necessary. Other graph classes we consider include complete bipartite graphs, split graphs, chordal graphs, and cographs. We prove that orderability is decidable for the so called HR-equational classes of graphs, which are described by equation systems and generalize the context-free languages.',
	 'authors': u'Achim Blumensath, Bruno Courcelle,',
	 'category': u'Computer Science ',
	 'date': '2013-10-30',
	 'pdflink': u'http://arxiv.org/pdf/1310.8148',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nMonadic second-order definable graph orderings',
	 'urllink': u'http://arxiv.org/abs/1310.8148'}
2015-03-23 22:18:09+0000 [xxu46_7] INFO: Crawled 21 pages (at 1 pages/min), scraped 14 items (at 1 items/min)
2015-03-23 22:19:06+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.2950> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 22:19:06+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.2950>
	{'abstract': u'Traditionally, Bluetooth has been deemed unsuitable for sustaining a large-scale multi-hop network. There are two main reasons: severe frequency channel collisions under a large-scale network and high complexity of designing an efficient formation protocol. In this work, we reconsider this viewpoint from a practical usability perspective and aim to realize the buried potential of Bluetooth. Firstly, we find that the collision probability under a low-overhead network is fairly small, which is acceptable for practical applications. Secondly, we propose BlueSky, a complete system solution to provide necessary networking functionalities for Bluetooth. In BlueSky, we develop a connection maintenance mechanism for mitigating the influence of collisions and a network formation protocol for reliable packet transmissions. We implement BlueSky on Windows Mobile using 100 commercial smartphones. Comprehensive usability evaluations demonstrate the negligible overheads of BlueSky and its good network performance. In particular, 90%-95% of the whole 100 nodes can participate in the communication smoothly.',
	 'authors': u'Xinfeng Li, Chenshu Wu, Xiaoyuan Wang, Ming Gu, Xiang-Yang Li, Dong Xuan,',
	 'category': u'Computer Science ',
	 'date': '2013-8-13',
	 'pdflink': u'http://arxiv.org/e-print/1308.2950',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nBlueSky: Realizing Buried Potential of Bluetooth to Sustain a  Large-scale Multi-hop Network',
	 'urllink': u'http://arxiv.org/abs/1308.2950'}
2015-03-23 22:19:09+0000 [xxu46_7] INFO: Crawled 22 pages (at 1 pages/min), scraped 15 items (at 1 items/min)
2015-03-23 22:20:09+0000 [xxu46_7] INFO: Crawled 22 pages (at 0 pages/min), scraped 15 items (at 0 items/min)
2015-03-23 22:20:23+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.5124> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-23 22:20:23+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.5124>
	{'abstract': u'Modern social networks frequently encompass multiple distinct types of connectivity information; for instance, explicitly acknowledged friend relationships might complement behavioral measures that link users according to their actions or interests. One way to represent these networks is as multi-layer graphs, where each layer contains a unique set of edges over the same underlying vertices (users). Edges in different layers typically have related but distinct semantics; depending on the application multiple layers might be used to reduce noise through averaging, to perform multifaceted analyses, or a combination of the two. However, it is not obvious how to extend standard graph analysis techniques to the multi-layer setting in a flexible way. In this paper we develop latent variable models and methods for mining multi-layer networks for connectivity patterns based on noisy data.',
	 'authors': u'Brandon Oselio, Alex Kulesza, Alfred O. Hero III,',
	 'category': u'Computer Science ',
	 'date': '2013-9-20',
	 'pdflink': u'http://arxiv.org/pdf/1309.5124',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nMulti-layer graph analysis for dynamic social networks',
	 'urllink': u'http://arxiv.org/abs/1309.5124'}
2015-03-23 22:21:09+0000 [xxu46_7] INFO: Crawled 23 pages (at 1 pages/min), scraped 16 items (at 1 items/min)
2015-03-23 22:22:09+0000 [xxu46_7] INFO: Crawled 23 pages (at 0 pages/min), scraped 16 items (at 0 items/min)
2015-03-23 22:22:22+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.4046> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-23 22:22:22+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.4046>
	{'abstract': u"Standard explicit schemes for parabolic equations are not very convenient for computing practice due to the fact that they have strong restrictions on a time step. More promising explicit schemes are associated with explicit-implicit splitting of the problem operator (Saul'yev asymmetric schemes, explicit alternating direction (ADE) schemes, group explicit method). These schemes belong to the class of unconditionally stable schemes, but they demonstrate bad approximation properties. These explicit schemes are treated as schemes of the alternating triangle method and can be considered as factorized schemes where the problem operator is splitted into the sum of two operators that are adjoint to each other. Here we propose a multilevel modification of the alternating triangle method, which demonstrates better properties in terms of accuracy. We also consider explicit schemes of the alternating triangle method for the numerical solution of boundary value problems for hyperbolic equations of second order. The study is based on the general theory of stability (well-posedness) for operator-difference schemes.",
	 'authors': u'Petr N. Vabishchevich,',
	 'category': u'Computer Science ',
	 'date': '2013-10-15',
	 'pdflink': u'http://arxiv.org/pdf/1310.4046',
	 'subjects': u'Numerical Analysis (cs.NA)',
	 'title': u'\nExplicit schemes for parabolic and hyperbolic equations',
	 'urllink': u'http://arxiv.org/abs/1310.4046'}
2015-03-23 22:23:09+0000 [xxu46_7] INFO: Crawled 24 pages (at 1 pages/min), scraped 17 items (at 1 items/min)
2015-03-23 22:23:59+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1311.3105> (referer: http://arxiv.org/list/cs/13?skip=12000&show=1000)
2015-03-23 22:23:59+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1311.3105>
	{'abstract': u"Wireless Sensor Networks need to be organized for efficient data collection and lifetime maximization. In this paper, we propose a novel routing structure, namely k-DAG, to balance the load of the base station's neighbours while providing the worst-case latency guarantee for data collection, and a distributed algorithm for construction a k-DAG based on a SPD (Shortest Path DAG). In a k-DAG, the lengths of the longest path and the shortest path of each sensor node to the base station differ by at most k. By adding sibling edges to a SPD, our distributed algorithm allows critical nodes to have more routing choices. The simulation results show that our approach significantly outperforms the SPD-based data collection approach in both network lifetime and load balance.",
	 'authors': u'Jingjing Fei, Hui Wu, Yongxin Wang,',
	 'category': u'Computer Science ',
	 'date': '2013-11-13',
	 'pdflink': u'http://arxiv.org/pdf/1311.3105',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nk-DAG Based Lifetime Aware Data Collection in Wireless Sensor Networks',
	 'urllink': u'http://arxiv.org/abs/1311.3105'}
2015-03-23 22:24:09+0000 [xxu46_7] INFO: Crawled 25 pages (at 1 pages/min), scraped 18 items (at 1 items/min)
2015-03-23 22:25:09+0000 [xxu46_7] INFO: Crawled 25 pages (at 0 pages/min), scraped 18 items (at 0 items/min)
2015-03-23 22:25:35+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.0195> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 22:25:35+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.0195>
	{'abstract': u'Connections between nodes in optical networks are realized by lightpaths. Due to the decay of the signal, a regenerator has to be placed on every lightpath after at most hops, for some given positive integer . A regenerator can serve only one lightpath. The placement of regenerators has become an active area of research during recent years, and various optimization problems have been studied. The first such problem is the Regeneration Location Problem (), where the goal is to place the regenerators so as to minimize the total number of nodes containing them. We consider two extreme cases of online regarding the value of and the number of regenerators that can be used in any single node. (1) is arbitrary and unbounded. In this case a feasible solution always exists. We show an -competitive randomized algorithm for any network topology, where is the set of paths of length . The algorithm can be made deterministic in some cases. We show a deterministic lower bound of , where is the edge set. (2) and . In this case there is not necessarily a solution for a given input. We distinguish between feasible inputs (for which there is a solution) and infeasible ones. In the latter case, the objective is to satisfy the maximum number of lightpaths. For a path topology we show a lower bound of for the competitive ratio (where is the number of internal nodes of the longest lightpath) on infeasible inputs, and a tight bound of 3 for the competitive ratio on feasible inputs.',
	 'authors': u'George B. Mertzios, Mordechai Shalom, Prudence W.H. Wong, Shmuel Zaks,',
	 'category': u'Computer Science ',
	 'date': '2013-9-1',
	 'pdflink': u'http://arxiv.org/pdf/1309.0195',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nOnline Regenerator Placement',
	 'urllink': u'http://arxiv.org/abs/1309.0195'}
2015-03-23 22:26:09+0000 [xxu46_7] INFO: Crawled 26 pages (at 1 pages/min), scraped 19 items (at 1 items/min)
2015-03-23 22:27:09+0000 [xxu46_7] INFO: Crawled 26 pages (at 0 pages/min), scraped 19 items (at 0 items/min)
2015-03-23 22:27:35+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.0193> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 22:27:35+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.0193>
	{'abstract': u'This paper proposes an algorithm to search a family of multiple sets of minimum correlated one dimensional uni-polar (optical) orthogonal codes (1-DUOC) or optical orthogonal codes (OOC) with fixed as well as variable code parameters. The cardinality of each set is equal to upper bound. The codes within a set can be searched for general values of code length, code weight, auto-correlation constraint and cross-correlation constraint. Each set forms a maximal clique of the codes within given range of correlation properties . These one-dimensional uni-polar orthogonal codes can find their application as signature sequences for spectral spreading purpose in incoherent optical code division multiple access (CDMA) systems.',
	 'authors': u'Ram Chandra Singh Chauhan, Yatindra Nath Singh, Rachna Asthana,',
	 'category': u'Computer Science ',
	 'date': '2013-9-1',
	 'pdflink': u'http://arxiv.org/pdf/1309.0193',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nDesign of Minimum Correlated, Maximal Clique Sets of One-Dimensional  Uni-polar (Optical) Orthogonal Codes',
	 'urllink': u'http://arxiv.org/abs/1309.0193'}
2015-03-23 22:28:09+0000 [xxu46_7] INFO: Crawled 27 pages (at 1 pages/min), scraped 20 items (at 1 items/min)
2015-03-23 22:29:09+0000 [xxu46_7] INFO: Crawled 27 pages (at 0 pages/min), scraped 20 items (at 0 items/min)
2015-03-23 22:29:15+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.0192> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 22:29:15+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.0192>
	{'abstract': u'We study the uniqueness and accuracy of the numerical solution of the problem of reconstruction of the shape and trajectory of a reflecting obstacle moving in an inhomogeneous medium from travel times, start and end points, and initial angles of ultrasonic rays reflecting at the obstacle. The speed of sound in the domain when there is no obstacle present is known and provided as an input parameter which together with the other initial data enables the algorithm to trace ray paths and find their reflection points. The reflection points determine with high-resolution the shape and trajectory of the obstacle. The method has predictable computational complexity and performance and is very efficient when it is parallelized and optimized because only a small portion of the domain is reconstructed.',
	 'authors': u'Kamen M. Lozev,',
	 'category': u'Computer Science ',
	 'date': '2013-9-1',
	 'pdflink': u'http://arxiv.org/pdf/1309.0192',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nReconstruction and uniqueness of moving obstacles',
	 'urllink': u'http://arxiv.org/abs/1309.0192'}
2015-03-23 22:30:09+0000 [xxu46_7] INFO: Crawled 28 pages (at 1 pages/min), scraped 21 items (at 1 items/min)
2015-03-23 22:30:24+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.0189> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 22:30:24+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.0189>
	{'abstract': u'Information sharing in organization has been considered as an important approach in increasing organizational efficiency, performance and decision making. With the present and advances in information and communication technology, sharing information and exchanging of data across organizations has become more feasible in organization. However, information sharing has been a complex task over the years and identifying factors that influence information sharing across organization has becomes crucial and critical. Researchers have taken several methods and approaches to resolve problems in information sharing at all levels without a lasting solution, as sharing is best understood as a practice that reflects behavior, social, economic, legal and technological influences. Due to the limitation of the conventional ISM3 standards to address culture, social, legislation and human behavior, the findings in this paper suggest that, a centralized information structure without human practice, distribution of information and coordination is not effective. This paper reviews the previous information sharing research, outlines the factors affecting information sharing and the different practices needed to improve the management of information security by recommending several combinations of information security and coordination mechanism for reducing uncertainty during sharing of information .This thesis proposes information security management protocol (ISMP) as an enhancement towards ISM3 to resolve the above problems. This protocol provides a means for practitioners to identify key factors involved in successful information sharing.....',
	 'authors': u'Oyelami Julius Olusegun, Norafida Binti Ithnin,',
	 'category': u'Computer Science ',
	 'date': '2013-9-1',
	 'pdflink': u'http://arxiv.org/pdf/1309.0189',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nEnhancing the Conventional Information Security Management Maturity  Model (ISM3) in Resolving Human Factors in Organization Information Sharing',
	 'urllink': u'http://arxiv.org/abs/1309.0189'}
2015-03-23 22:31:09+0000 [xxu46_7] INFO: Crawled 29 pages (at 1 pages/min), scraped 22 items (at 1 items/min)
2015-03-23 22:31:48+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.0188> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 22:31:48+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.0188>
	{'abstract': u'Educating the users on the essential of information security is very vital and important to the mission of establishing a sustainable information security in any organization and institute. At the University Technology Malaysia (UTM), we have recognized the fact that, it is about time information security should no longer be a lacking factor in productivity, both information security and productivity must work together in closed proximity. We have recently implemented a broad campus information security awareness program to educate faculty member, staff, students and non-academic staff on this essential topic of information security. The program consists of training based on web, personal or individual training with a specific monthly topic, campus campaigns, guest speakers and direct presentations to specialized groups. The goal and the objective are to educate the users on the challenges that are specific to information security and to create total awareness that will change the perceptions of people thinking and ultimately their reactions when it comes to information security. In this paper, we explain how we created and implemented our information security awareness training (ISAT) program and discuss the impediment we encountered along the process. We explore different methods of deliveries such as target audiences, and probably the contents as we believe might be vital to a successful information security program. Finally, we discuss the importance and the flexibility of establishing a sustainable information security training program that could be adopted to meet current and future needs and demands while still relevant to our current users.',
	 'authors': u'Oyelami Julius Olusegun, Norafida Binti Ithnin,',
	 'category': u'Computer Science ',
	 'date': '2013-9-1',
	 'pdflink': u'http://arxiv.org/pdf/1309.0188',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nPeople Are the Answer to Security: Establishing a Sustainable  Information Security Awareness Training (ISAT) Program in Organization',
	 'urllink': u'http://arxiv.org/abs/1309.0188'}
2015-03-23 22:32:09+0000 [xxu46_7] INFO: Crawled 30 pages (at 1 pages/min), scraped 23 items (at 1 items/min)
2015-03-23 22:33:09+0000 [xxu46_7] INFO: Crawled 30 pages (at 0 pages/min), scraped 23 items (at 0 items/min)
2015-03-23 22:33:34+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.0186> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 22:33:34+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.0186>
	{'abstract': u'Erasure codes, such as Reed-Solomon (RS) codes, are being increasingly employed in data centers to combat the cost of reliably storing large amounts of data. Although these codes provide optimal storage efficiency, they require significantly high network and disk usage during recovery of missing data. In this paper, we first present a study on the impact of recovery operations of erasure-coded data on the data-center network, based on measurements from Facebook\'s warehouse cluster in production. To the best of our knowledge, this is the first study of its kind available in the literature. Our study reveals that recovery of RS-coded data results in a significant increase in network traffic, more than a hundred terabytes per day, in a cluster storing multiple petabytes of RS-coded data. To address this issue, we present a new storage code using our recently proposed "Piggybacking" framework, that reduces the network and disk usage during recovery by 30% in theory, while also being storage optimal and supporting arbitrary design parameters. The implementation of the proposed code in the Hadoop Distributed File System (HDFS) is underway. We use the measurements from the warehouse cluster to show that the proposed code would lead to a reduction of close to fifty terabytes of cross-rack traffic per day.',
	 'authors': u'K. V. Rashmi, Nihar B. Shah, Dikang Gu, Hairong Kuang, Dhruba Borthakur, Kannan Ramchandran,',
	 'category': u'Computer Science ',
	 'date': '2013-9-1',
	 'pdflink': u'http://arxiv.org/pdf/1309.0186',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nA Solution to the Network Challenges of Data Recovery in Erasure-coded  Distributed Storage Systems: A Study on the Facebook Warehouse Cluster',
	 'urllink': u'http://arxiv.org/abs/1309.0186'}
2015-03-23 22:34:09+0000 [xxu46_7] INFO: Crawled 31 pages (at 1 pages/min), scraped 24 items (at 1 items/min)
2015-03-23 22:35:09+0000 [xxu46_7] INFO: Crawled 31 pages (at 0 pages/min), scraped 24 items (at 0 items/min)
2015-03-23 22:35:25+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.0185> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 22:35:25+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.0185>
	{'abstract': u"Haptic technology, or haptics, is a tactile feedback technology which takes advantage of a user's sense of touch by applying forces, vibrations, and/or motions upon the user. This mechanical stimulation may be used to assist in the creation of virtual objects (objects existing only in a computer simulation), for control of such virtual objects, and for the enhancement of the remote control of machines and devices. It has been described as for the sense of touch what computer graphics does for vision. Although haptic devices are capable of measuring bulk or reactive forces that are applied by the user, it should not be confused with touch or tactile sensors that measure the pressure or force exerted by the user to the interface.",
	 'authors': u'S. Sri Gurudatta Yadav, R. V. Krishnaiah,',
	 'category': u'Computer Science ',
	 'date': '2013-9-1',
	 'pdflink': u'http://arxiv.org/pdf/1309.0185',
	 'subjects': u'Human-Computer Interaction (cs.HC)',
	 'title': u'\nHaptic Science and Technology',
	 'urllink': u'http://arxiv.org/abs/1309.0185'}
2015-03-23 22:36:09+0000 [xxu46_7] INFO: Crawled 32 pages (at 1 pages/min), scraped 25 items (at 1 items/min)
2015-03-23 22:37:09+0000 [xxu46_7] INFO: Crawled 32 pages (at 0 pages/min), scraped 25 items (at 0 items/min)
2015-03-23 22:37:23+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.0165> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 22:37:23+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.0165>
	{'abstract': u'Reversal of the time direction in stochastic systems driven by white noise has been central throughout the development of stochastic realization theory, filtering and smoothing. Similar ideas were developed in connection with certain problems in the theory of moments, where a duality induced by time reversal was introduced to parametrize solutions. In this latter work it was shown that stochastic systems driven by arbitrary second-order stationary processes can be similarly time-reversed. By combining these two sets of ideas we present herein a generalization of time-reversal in stochastic realization theory.',
	 'authors': u'Tryphon T. Georgiou, Anders Lindquist,',
	 'category': u'Computer Science ',
	 'date': '2013-8-31',
	 'pdflink': u'http://arxiv.org/pdf/1309.0165',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nOn time-reversibility of linear stochastic models',
	 'urllink': u'http://arxiv.org/abs/1309.0165'}
2015-03-23 22:38:09+0000 [xxu46_7] INFO: Crawled 33 pages (at 1 pages/min), scraped 26 items (at 1 items/min)
2015-03-23 22:39:09+0000 [xxu46_7] INFO: Crawled 33 pages (at 0 pages/min), scraped 26 items (at 0 items/min)
2015-03-23 22:39:16+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.0157> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 22:39:16+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.0157>
	{'abstract': u'We present a construction for complementary pairs of arrays that exploits a set of mutually-unbiased bases, and enumerate these arrays as well as the corresponding set of complementary sequences obtained from the arrays by projection. We also sketch an algorithm to uniquely generate these sequences. The pairwise squared inner-product of members of the sequence set is shown to be . Moreover, a subset of the set can be viewed as a codebook that asymptotically achieves times the Welch bound.',
	 'authors': u'Gaofei Wu, Matthew G. Parker,',
	 'category': u'Computer Science ',
	 'date': '2013-8-31',
	 'pdflink': u'http://arxiv.org/pdf/1309.0157',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nA complementary construction using mutually unbiased bases',
	 'urllink': u'http://arxiv.org/abs/1309.0157'}
2015-03-23 22:40:09+0000 [xxu46_7] INFO: Crawled 34 pages (at 1 pages/min), scraped 27 items (at 1 items/min)
2015-03-23 22:40:42+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.0145> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 22:40:42+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.0145>
	{'abstract': u'In this paper, we consider the problem of minimizing the multicast decoding delay of generalized instantly decodable network coding (G-IDNC) over persistent forward and feedback erasure channels with feedback intermittence. In such an environment, the sender does not always receive acknowledgement from the receivers after each transmission. Moreover, both the forward and feedback channels are subject to persistent erasures, which can be modelled by a two state (good and bad states) Markov chain known as Gilbert-Elliott channel (GEC). Due to such feedback imperfections, the sender is unable to determine subsequent instantly decodable packets combination for all receivers. Given this harsh channel and feedback model, we first derive expressions for the probability distributions of decoding delay increments and then employ these expressions in formulating the minimum decoding problem in such environment as a maximum weight clique problem in the G-IDNC graph. We also show that the problem formulations in simpler channel and feedback models are special cases of our generalized formulation. Since this problem is NP-hard, we design a greedy algorithm to solve it and compare it to blind approaches proposed in literature. Through extensive simulations, our adaptive algorithm is shown to outperform the blind approaches in all situations and to achieve significant improvement in the decoding delay, especially when the channel is highly persistent',
	 'authors': u'Ahmed Douik, Sameh Sorour, Mohamed-Slim Alouini, Tareq Y. Al-Naffouri,',
	 'category': u'Computer Science ',
	 'date': '2013-8-31',
	 'pdflink': u'http://arxiv.org/pdf/1309.0145',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nDelay Minimization for Instantly Decodable Network Coding in Persistent  Channels with Feedback Intermittence',
	 'urllink': u'http://arxiv.org/abs/1309.0145'}
2015-03-23 22:41:09+0000 [xxu46_7] INFO: Crawled 35 pages (at 1 pages/min), scraped 28 items (at 1 items/min)
2015-03-23 22:42:09+0000 [xxu46_7] INFO: Crawled 35 pages (at 0 pages/min), scraped 28 items (at 0 items/min)
2015-03-23 22:42:31+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.0141> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 22:42:31+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.0141>
	{'abstract': u'This paper studies several properties of channel codes that approach the fundamental limits of a given (discrete or Gaussian) memoryless channel with a non-vanishing probability of error. The output distribution induced by an -capacity-achieving code is shown to be close in a strong sense to the capacity achieving output distribution. Relying on the concentration of measure (isoperimetry) property enjoyed by the latter, it is shown that regular (Lipschitz) functions of channel outputs can be precisely estimated and turn out to be essentially non-random and independent of the actual code. It is also shown that the output distribution of a good code and the capacity achieving one cannot be distinguished with exponential reliability. The random process produced at the output of the channel is shown to satisfy the asymptotic equipartition property. Using related methods it is shown that quadratic forms and sums of -th powers when evaluated at codewords of good AWGN codes approach the values obtained from a randomly generated Gaussian codeword.',
	 'authors': u'Yury Polyanskiy, Sergio Verdu,',
	 'category': u'Computer Science ',
	 'date': '2013-8-31',
	 'pdflink': u'http://arxiv.org/pdf/1309.0141',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nEmpirical distribution of good channel codes with non-vanishing error  probability (extended version)',
	 'urllink': u'http://arxiv.org/abs/1309.0141'}
2015-03-23 22:43:09+0000 [xxu46_7] INFO: Crawled 36 pages (at 1 pages/min), scraped 29 items (at 1 items/min)
2015-03-23 22:44:09+0000 [xxu46_7] INFO: Crawled 36 pages (at 0 pages/min), scraped 29 items (at 0 items/min)
2015-03-23 22:44:09+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.0136> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 22:44:09+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.0136>
	{'abstract': u'This paper develops an interpolatory framework for weighted- model reduction of MIMO dynamical systems. A new representation of the weighted- inner products in MIMO settings is introduced and used to derive associated first-order necessary conditions satisfied by optimal weighted- reduced-order models. Equivalence of these new interpolatory conditions with earlier Riccati-based conditions given by Halevi is also shown. An examination of realizations for equivalent weighted- systems leads then to an algorithm that remains tractable for large state-space dimension. Several numerical examples illustrate the effectiveness of this approach and its competitiveness with Frequency Weighted Balanced Truncation and an earlier interpolatory approach, the Weighted Iterative Rational Krylov Algorithm.',
	 'authors': u'Tobias Breiten, Christopher Beattie, Serkan Gugercin,',
	 'category': u'Computer Science ',
	 'date': '2013-8-31',
	 'pdflink': u'http://arxiv.org/pdf/1309.0136',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nNear-optimal Frequency-weighted Interpolatory Model Reduction',
	 'urllink': u'http://arxiv.org/abs/1309.0136'}
2015-03-23 22:45:09+0000 [xxu46_7] INFO: Crawled 37 pages (at 1 pages/min), scraped 30 items (at 1 items/min)
2015-03-23 22:45:17+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.0129> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 22:45:17+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.0129>
	{'abstract': u'The recommender system is one of the most promising ways to address the information overload problem in online systems. Based on the personal historical record, the recommender system can find interesting and relevant objects for the user within a huge information space. Many physical processes such as the mass diffusion and heat conduction have been applied to design the recommendation algorithms. The hybridization of these two algorithms has been shown to provide both accurate and diverse recommendation results. In this paper, we proposed two similarity preferential diffusion processes. Extensive experimental analyses on two benchmark data sets demonstrate that both recommendation and accuracy and diversity are improved duet to the similarity preference in the diffusion. The hybridization of the similarity preferential diffusion processes is shown to significantly outperform the state-of-art recommendation algorithm. Finally, our analysis on network sparsity show that there is significant difference between dense and sparse system, indicating that all the former conclusions on recommendation in the literature should be reexamined in sparse system.',
	 'authors': u'An Zeng, Alexandre Vidmer, Matus Medo, Yi-Cheng Zhang,',
	 'category': u'Computer Science ',
	 'date': '2013-8-31',
	 'pdflink': u'http://arxiv.org/pdf/1309.0129',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nInformation filtering via hybridization of similarity preferential  diffusion processes',
	 'urllink': u'http://arxiv.org/abs/1309.0129'}
2015-03-23 22:46:09+0000 [xxu46_7] INFO: Crawled 38 pages (at 1 pages/min), scraped 31 items (at 1 items/min)
2015-03-23 22:46:57+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.0123> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 22:46:57+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.0123>
	{'abstract': u'In this work, a new constrained hybrid variational deblurring model is developed by combining the non-convex first- and second-order total variation regularizers. Moreover, a box constraint is imposed on the proposed model to guarantee high deblurring performance. The developed constrained hybrid variational model could achieve a good balance between preserving image details and alleviating ringing artifacts. In what follows, we present the corresponding numerical solution by employing an iteratively reweighted algorithm based on alternating direction method of multipliers. The experimental results demonstrate the superior performance of the proposed method in terms of quantitative and qualitative image quality assessments.',
	 'authors': u'Ryan Wen Liu, Tian Xu,',
	 'category': u'Computer Science ',
	 'date': '2013-8-31',
	 'pdflink': u'http://arxiv.org/pdf/1309.0123',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nA Robust Alternating Direction Method for Constrained Hybrid Variational  Deblurring Model',
	 'urllink': u'http://arxiv.org/abs/1309.0123'}
2015-03-23 22:47:09+0000 [xxu46_7] INFO: Crawled 39 pages (at 1 pages/min), scraped 32 items (at 1 items/min)
2015-03-23 22:48:09+0000 [xxu46_7] INFO: Crawled 39 pages (at 0 pages/min), scraped 32 items (at 0 items/min)
2015-03-23 22:48:35+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.0111> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 22:48:35+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.0111>
	{'abstract': u"Cooperative behaviors arising from bacterial cell-to-cell communication can be modeled by reaction-diffusion equations having only a single diffusible component. This paper presents the following three contributions for the systematic analysis of Turing instability in such reaction-diffusion systems. (i) We first introduce a unified framework to formulate the reaction-diffusion system as an interconnected multi-agent dynamical system. (ii) Then, we mathematically classify biologically plausible and implausible Turing instabilities and characterize them by the root locus of each agent's dynamics, or the local reaction dynamics. (iii) Using this characterization, we derive analytic conditions for biologically plausible Turing instability, which provide useful guidance for the design and the analysis of biological networks. These results are demonstrated on an extended Gray-Scott model with a single diffuser.",
	 'authors': u'Hiroki Miyazako, Yutaka Hori, Shinji Hara,',
	 'category': u'Computer Science ',
	 'date': '2013-8-31',
	 'pdflink': u'http://arxiv.org/pdf/1309.0111',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nTuring Instability in Reaction-Diffusion Systems with a Single Diffuser:  Characterization Based on Root Locus',
	 'urllink': u'http://arxiv.org/abs/1309.0111'}
2015-03-23 22:49:09+0000 [xxu46_7] INFO: Crawled 40 pages (at 1 pages/min), scraped 33 items (at 1 items/min)
2015-03-23 22:49:36+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.0088> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 22:49:36+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.0088>
	{'abstract': u'We consider the effect of caching in wireless networks where fading is the dominant channel effect. First, we propose a one-hop transmission strategy for cache-enabled wireless networks, which is based on exploiting multi-user diversity gain. Then, we derive a closed-form result for throughput scaling of the proposed scheme in large networks, which reveals the inherent trade-off between cache memory size and network throughput. Our results show that substantial throughput improvements are achievable in networks with sources equipped with large cache size. We also verify our analytical result through simulations.',
	 'authors': u'Seyed Pooya Shariatpanahi, Hamed Shah-Mansouri, Babak Hossein Khalaj,',
	 'category': u'Computer Science ',
	 'date': '2013-8-31',
	 'pdflink': u'http://arxiv.org/pdf/1309.0088',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nCaching Gain in Wireless Networks with Fading: A Multi-User Diversity  Perspective',
	 'urllink': u'http://arxiv.org/abs/1309.0088'}
2015-03-23 22:50:09+0000 [xxu46_7] INFO: Crawled 41 pages (at 1 pages/min), scraped 34 items (at 1 items/min)
2015-03-23 22:51:09+0000 [xxu46_7] INFO: Crawled 41 pages (at 0 pages/min), scraped 34 items (at 0 items/min)
2015-03-23 22:51:34+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.0085> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 22:51:34+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.0085>
	{'abstract': u'Cognitive radio networks (CRNs) are networks of nodes equipped with cognitive radios that can optimize performance by adapting to network conditions. While cognitive radio networks (CRN) are envisioned as intelligent networks, relatively little research has focused on the network level functionality of CRNs. Although various routing protocols, incorporating varying degrees of adaptiveness, have been proposed for CRNs, it is imperative for the long term success of CRNs that the design of cognitive routing protocols be pursued by the research community. Cognitive routing protocols are envisioned as routing protocols that fully and seamless incorporate AI-based techniques into their design. In this paper, we provide a self-contained tutorial on various AI and machine-learning techniques that have been, or can be, used for developing cognitive routing protocols. We also survey the application of various classes of AI techniques to CRNs in general, and to the problem of routing in particular. We discuss various decision making techniques and learning techniques from AI and document their current and potential applications to the problem of routing in CRNs. We also highlight the various inference, reasoning, modeling, and learning sub tasks that a cognitive routing protocol must solve. Finally, open research issues and future directions of work are identified.',
	 'authors': u'Junaid Qadir,',
	 'category': u'Computer Science ',
	 'date': '2013-8-31',
	 'pdflink': u'http://arxiv.org/pdf/1309.0085',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nArtificial Intelligence Based Cognitive Routing for Cognitive Radio  Networks',
	 'urllink': u'http://arxiv.org/abs/1309.0085'}
2015-03-23 22:52:09+0000 [xxu46_7] INFO: Crawled 42 pages (at 1 pages/min), scraped 35 items (at 1 items/min)
2015-03-23 22:53:02+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.0082> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 22:53:02+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.0082>
	{'abstract': u'We consider several combinatorial optimization problems which combine the classic shop scheduling problems, namely open shop scheduling or job shop scheduling, and the shortest path problem. The objective of the obtained problem is to select a subset of jobs that forms a feasible solution of the shortest path problem, and to execute the selected jobs on the open (or job) shop machines to minimize the makespan. We show that these problems are NP-hard even if the number of machines is two, and cannot be approximated within a factor less than 2 if the number of machines is an input unless P=NP. We present several approximation algorithms for these combination problems.',
	 'authors': u'Kameng Nip, Zhenbo Wang, Wenxun Xing,',
	 'category': u'Computer Science ',
	 'date': '2013-8-31',
	 'pdflink': u'http://arxiv.org/pdf/1309.0082',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nCombinations of Some Shop Scheduling Problems and the Shortest Path  Problem: Complexity and Approximation Algorithms',
	 'urllink': u'http://arxiv.org/abs/1309.0082'}
2015-03-23 22:53:09+0000 [xxu46_7] INFO: Crawled 43 pages (at 1 pages/min), scraped 36 items (at 1 items/min)
2015-03-23 22:54:09+0000 [xxu46_7] INFO: Crawled 43 pages (at 0 pages/min), scraped 36 items (at 0 items/min)
2015-03-23 22:54:21+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.0081> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 22:54:21+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.0081>
	{'abstract': u'This paper studies a combinatorial optimization problem which is obtained by combining the flow shop scheduling problem and the shortest path problem. The objective of the obtained problem is to select a subset of jobs that constitutes a feasible solution to the shortest path problem, and to execute the selected jobs on the flow shop machines to minimize the makespan. We argue that this problem is NP-hard even if the number of machines is two, and is NP-hard in the strong sense for the general case. We propose an intuitive approximation algorithm for the case where the number of machines is an input, and an improved approximation algorithm for fixed number of machines.',
	 'authors': u'Kameng Nip, Zhenbo Wang, Fabrice Talla Nobibon, Roel Leus,',
	 'category': u'Computer Science ',
	 'date': '2013-8-31',
	 'pdflink': u'http://arxiv.org/pdf/1309.0081',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nA Combination of Flow Shop Scheduling and the Shortest Path Problem',
	 'urllink': u'http://arxiv.org/abs/1309.0081'}
2015-03-23 22:55:09+0000 [xxu46_7] INFO: Crawled 44 pages (at 1 pages/min), scraped 37 items (at 1 items/min)
2015-03-23 22:56:09+0000 [xxu46_7] INFO: Crawled 44 pages (at 0 pages/min), scraped 37 items (at 0 items/min)
2015-03-23 22:56:21+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.0073> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 22:56:21+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.0073>
	{'abstract': u'With the increased popularity of smartphones, various security threats and privacy leakages targeting them are discovered and investigated. In this work, we present ourprotocoltight, a framework to authenticate users silently and transparently by exploiting dynamics mined from the user touch behavior biometrics and the micro-movement of the device caused by user\'s screen-touch actions. We build a "touch-based biometrics" model of the owner by extracting some principle features, and then verify whether the current user is the owner or guest/attacker. When using the smartphone, the unique operating dynamics of the user is detected and learnt by collecting the sensor data and touch events silently. When users are mobile, the micro-movement of mobile devices caused by touch is suppressed by that due to the large scale user-movement which will render the touch-based biometrics ineffective. To address this, we integrate a movement-based biometrics for each user with previous touch-based biometrics. We conduct extensive evaluations of our approaches on the Android smartphone, we show that the user identification accuracy is over 99%.',
	 'authors': u'Cheng Bo, Lan Zhang, Xiang-Yang Li,',
	 'category': u'Computer Science ',
	 'date': '2013-8-31',
	 'pdflink': u'http://arxiv.org/pdf/1309.0073',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nSilentSense: Silent User Identification via Dynamics of Touch and  Movement Behavioral Biometrics',
	 'urllink': u'http://arxiv.org/abs/1309.0073'}
2015-03-23 22:57:09+0000 [xxu46_7] INFO: Crawled 45 pages (at 1 pages/min), scraped 38 items (at 1 items/min)
2015-03-23 22:58:09+0000 [xxu46_7] INFO: Crawled 45 pages (at 0 pages/min), scraped 38 items (at 0 items/min)
2015-03-23 22:58:09+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.0065> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 22:58:09+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.0065>
	{'abstract': u'Additional material for the original paper "Automated Verification of Interactive Rule-Based Configuration Systems".',
	 'authors': u'Deepak Dhungana, Ching Hoo Tang, Christoph Weidenbach, Patrick Wischnewski,',
	 'category': u'Computer Science ',
	 'date': '2013-8-31',
	 'pdflink': u'http://arxiv.org/pdf/1309.0065',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nAutomated Verification of Interactive Rule-Based Configuration Systems  (Additional Material)',
	 'urllink': u'http://arxiv.org/abs/1309.0065'}
2015-03-23 22:59:09+0000 [xxu46_7] INFO: Crawled 46 pages (at 1 pages/min), scraped 39 items (at 1 items/min)
2015-03-23 22:59:56+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.0052> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 22:59:56+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.0052>
	{'abstract': u"In this paper we discuss ways to reduce the execution time of a software Global Navigation Satellite System (GNSS) receiver that is meant for offline operation in a cloud environment. Client devices record satellite signals they receive, and send them to the cloud, to be processed by this software. The goal of this project is for each client request to be processed as fast as possible, but also to increase total system throughput by making sure as many requests as possible are processed within a unit of time. The characteristics of our application provided both opportunities and challenges for increasing performance. We describe the speedups we obtained by enabling the software to exploit multi-core CPUs and GPGPUs. We mention which techniques worked for us and which did not. To increase throughput, we describe how we control the resources allocated to each invocation of the software to process a client request, such that multiple copies of the application can run at the same time. We use the notion of effective running time to measure the system's throughput when running multiple instances at the same time, and show how we can determine when the system's computing resources have been saturated.",
	 'authors': u'Kamran Karimi, Aleks G. Pamir, M. Haris Afzal,',
	 'category': u'Computer Science ',
	 'date': '2013-8-31',
	 'pdflink': u'http://arxiv.org/pdf/1309.0052',
	 'subjects': u'Performance (cs.PF)',
	 'title': u'\nAccelerating a Cloud-Based Software GNSS Receiver',
	 'urllink': u'http://arxiv.org/abs/1309.0052'}
2015-03-23 23:00:09+0000 [xxu46_7] INFO: Crawled 47 pages (at 1 pages/min), scraped 40 items (at 1 items/min)
2015-03-23 23:01:09+0000 [xxu46_7] INFO: Crawled 47 pages (at 0 pages/min), scraped 40 items (at 0 items/min)
2015-03-23 23:01:50+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.3881> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:01:50+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.3881>
	{'abstract': u"We analyze the strength of Helly's selection theorem HST, which is the most important compactness theorem on the space of functions of bounded variation. For this we utilize a new representation of this space intermediate between and the Sobolev space W1,1, compatible with the, so called, weak* topology. We obtain that HST is instance-wise equivalent to the Bolzano-Weierstra ss principle over RCA0. With this HST is equivalent to ACA0 over RCA0. A similar classification is obtained in the Weihrauch lattice.",
	 'authors': u'Alexander P. Kreuzer,',
	 'category': u'Computer Science ',
	 'date': '2013-8-18',
	 'pdflink': u'http://arxiv.org/pdf/1308.3881',
	 'subjects': u'Logic (math.LO)',
	 'title': u"\nBounded variation and the strength of Helly's selection theorem",
	 'urllink': u'http://arxiv.org/abs/1308.3881'}
2015-03-23 23:02:09+0000 [xxu46_7] INFO: Crawled 48 pages (at 1 pages/min), scraped 41 items (at 1 items/min)
2015-03-23 23:03:09+0000 [xxu46_7] INFO: Crawled 48 pages (at 0 pages/min), scraped 41 items (at 0 items/min)
2015-03-23 23:03:26+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.1975> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:03:26+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.1975>
	{'abstract': u'Motivation. Protein contact map describes the pairwise spatial and functional relationship of residues in a protein and contains key information for protein 3D structure prediction. Although studied extensively, it remains very challenging to predict contact map using only sequence information. Most existing methods predict the contact map matrix element-by-element, ignoring correlation among contacts and physical feasibility of the whole contact map. A couple of recent methods predict contact map based upon residue co-evolution, taking into consideration contact correlation and enforcing a sparsity restraint, but these methods require a very large number of sequence homologs for the protein under consideration and the resultant contact map may be still physically unfavorable. Results. This paper presents a novel method PhyCMAP for contact map prediction, integrating both evolutionary and physical restraints by machine learning and integer linear programming (ILP). The evolutionary restraints include sequence profile, residue co-evolution and context-specific statistical potential. The physical restraints specify more concrete relationship among contacts than the sparsity restraint. As such, our method greatly reduces the solution space of the contact map matrix and thus, significantly improves prediction accuracy. Experimental results confirm that PhyCMAP outperforms currently popular methods no matter how many sequence homologs are available for the protein under consideration. PhyCMAP can predict contacts within minutes after PSIBLAST search for sequence homologs is done, much faster than the two recent methods PSICOV and EvFold. See this http URL for the web server.',
	 'authors': u'Zhiyong Wang, Jinbo Xu,',
	 'category': u'Computer Science ',
	 'date': '2013-8-8',
	 'pdflink': u'http://arxiv.org/pdf/1308.1975',
	 'subjects': u'Quantitative Methods (q-bio.QM)',
	 'title': u'\nPredicting protein contact map using evolutionary and physical  constraints by integer programming (extended version)',
	 'urllink': u'http://arxiv.org/abs/1308.1975'}
2015-03-23 23:04:09+0000 [xxu46_7] INFO: Crawled 49 pages (at 1 pages/min), scraped 42 items (at 1 items/min)
2015-03-23 23:05:09+0000 [xxu46_7] INFO: Crawled 49 pages (at 0 pages/min), scraped 42 items (at 0 items/min)
2015-03-23 23:05:25+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4123> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:05:25+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4123>
	{'abstract': u'We propose a new approach for deriving probabilistic inequalities based on bounding likelihood ratios. We demonstrate that this approach is more general and powerful than the classical method frequently used for deriving concentration inequalities such as Chernoff bounds. We discover that the proposed approach is inherently related to statistical concepts such as monotone likelihood ratio, maximum likelihood, and the method of moments for parameter estimation. A connection between the proposed approach and the large deviation theory is also established. We show that, without using moment generating functions, tightest possible concentration inequalities may be readily derived by the proposed approach. We have derived new concentration inequalities using the proposed approach, which cannot be obtained by the classical approach based on moment generating functions.',
	 'authors': u'Xinjia Chen,',
	 'category': u'Computer Science ',
	 'date': '2013-8-18',
	 'pdflink': u'http://arxiv.org/pdf/1308.4123',
	 'subjects': u'Probability (math.PR)',
	 'title': u'\nA Likelihood Ratio Approach for Probabilistic Inequalities',
	 'urllink': u'http://arxiv.org/abs/1308.4123'}
2015-03-23 23:06:09+0000 [xxu46_7] INFO: Crawled 50 pages (at 1 pages/min), scraped 43 items (at 1 items/min)
2015-03-23 23:07:00+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6833> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:07:00+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6833>
	{'abstract': u'We consider polynomial differential equations and make a number of contributions to the questions of (i) complexity of deciding stability, (ii) existence of polynomial Lyapunov functions, and (iii) existence of sum of squares (sos) Lyapunov functions. (i) We show that deciding local or global asymptotic stability of cubic vector fields is strongly NP-hard. Simple variations of our proof are shown to imply strong NP-hardness of several other decision problems: testing local attractivity of an equilibrium point, stability of an equilibrium point in the sense of Lyapunov, invariance of the unit ball, boundedness of trajectories, convergence of all trajectories in a ball to a given equilibrium point, existence of a quadratic Lyapunov function, local collision avoidance, and existence of a stabilizing control law. (ii) We present a simple, explicit example of a globally asymptotically stable quadratic vector field on the plane which does not admit a polynomial Lyapunov function (joint work with M. Krstic). For the subclass of homogeneous vector fields, we conjecture that asymptotic stability implies existence of a polynomial Lyapunov function, but show that the minimum degree of such a Lyapunov function can be arbitrarily large even for vector fields in fixed dimension and degree. For the same class of vector fields, we further establish that there is no monotonicity in the degree of polynomial Lyapunov functions. (iii) We show via an explicit counterexample that if the degree of the polynomial Lyapunov function is fixed, then sos programming may fail to find a valid Lyapunov function even though one exists. On the other hand, if the degree is allowed to increase, we prove that existence of a polynomial Lyapunov function for a planar or a homogeneous vector field implies existence of a polynomial Lyapunov function that is sos and that the negative of its derivative is also sos.',
	 'authors': u'Amir Ali Ahmadi, Pablo A. Parrilo,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6833',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nStability of Polynomial Differential Equations: Complexity and Converse  Lyapunov Questions',
	 'urllink': u'http://arxiv.org/abs/1308.6833'}
2015-03-23 23:07:09+0000 [xxu46_7] INFO: Crawled 51 pages (at 1 pages/min), scraped 44 items (at 1 items/min)
2015-03-23 23:08:09+0000 [xxu46_7] INFO: Crawled 51 pages (at 0 pages/min), scraped 44 items (at 0 items/min)
2015-03-23 23:08:27+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6783> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:08:27+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6783>
	{'abstract': u'The unambiguous detection and quantification of entanglement is a hot topic of scientific research, though it is limited to low dimensions or specific classes of states. Here we identify an additional class of quantum states, for which bipartite entanglement measures can be efficiently computed, providing new rigorous results. Such states are written in arbitrary dimensions, where each basis state in the subsystem A is paired with only one state in B. This new class, that we refer to as pair basis states, is remarkably relevant in many physical situations, including quantum optics. We find that negativity is a necessary and sufficient measure of entanglement for mixtures of states written in the same pair basis. We also provide analytical expressions for a tight lower-bound estimation of the entanglement of formation, a central quantity in quantum information.',
	 'authors': u'Marco Roncaglia, Arianna Montorsi, Marco Genovese,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6783',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nBipartite entanglement of quantum states in a pair basis',
	 'urllink': u'http://arxiv.org/abs/1308.6783'}
2015-03-23 23:09:09+0000 [xxu46_7] INFO: Crawled 52 pages (at 1 pages/min), scraped 45 items (at 1 items/min)
2015-03-23 23:10:09+0000 [xxu46_7] INFO: Crawled 52 pages (at 0 pages/min), scraped 45 items (at 0 items/min)
2015-03-23 23:10:13+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6774> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:10:13+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6774>
	{'abstract': u"In this paper we study decomposition methods based on separable approximations for minimizing the augmented Lagrangian. In particular, we study and compare the Diagonal Quadratic Approximation Method (DQAM) of Mulvey and Ruszczy 'ski and the Parallel Coordinate Descent Method (PCDM) of Richt 'arik and Tak 'a v. We show that the two methods are equivalent for feasibility problems up to the selection of a single step-size parameter. Furthermore, we prove an improved complexity bound for PCDM under strong convexity, and show that this bound is at least times better than the best known bound for DQAM, where is the degree of partial separability and and are the maximum and average of the block Lipschitz constants of the gradient of the quadratic penalty appearing in the augmented Lagrangian.",
	 'authors': u'Rachael Tappenden, Peter Richtarik, Burak Buke,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6774',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nSeparable Approximations and Decomposition Methods for the Augmented  Lagrangian',
	 'urllink': u'http://arxiv.org/abs/1308.6774'}
2015-03-23 23:11:09+0000 [xxu46_7] INFO: Crawled 53 pages (at 1 pages/min), scraped 46 items (at 1 items/min)
2015-03-23 23:12:07+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6739> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:12:07+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6739>
	{'abstract': u'Let denote the choice number of a graph (also called "list chromatic number" or "choosability" of ). Noel, Reed, and Wu proved the conjecture of Ohba that when . We extend this to a general upper bound: . Our result is sharp for using Ohba\'s examples, and it improves the best-known upper bound for .',
	 'authors': u'Jonathan A. Noel, Douglas B. West, Hehui Wu, Xuding Zhu,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6739',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u"\nBeyond Ohba's Conjecture: A bound on the choice number of $k$-chromatic  graphs with $n$ vertices",
	 'urllink': u'http://arxiv.org/abs/1308.6739'}
2015-03-23 23:12:09+0000 [xxu46_7] INFO: Crawled 54 pages (at 1 pages/min), scraped 47 items (at 1 items/min)
2015-03-23 23:13:09+0000 [xxu46_7] INFO: Crawled 54 pages (at 0 pages/min), scraped 47 items (at 0 items/min)
2015-03-23 23:13:31+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6732> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:13:31+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6732>
	{'abstract': u'This paper strengthens the interpretation and understanding of the classical capacity of the pure-loss bosonic channel, first established in [Giovannetti et al., Physical Review Letters 92, 027902 (2004), arXiv:quant-ph/0308012]. In particular, we first prove that there exists a trade-off between communication rate and error probability if one imposes only a mean-photon number constraint on the channel inputs. That is, if we demand that the mean number of photons at the channel input cannot be any larger than some positive number N_S, then it is possible to respect this constraint with a code that operates at a rate g( eta N_S / (1-p)) where p is the code\'s error probability, eta is the channel transmissivity, and g(x) is the entropy of a bosonic thermal state with mean photon number x. We then prove that a strong converse theorem holds for the classical capacity of this channel (that such a rate-error trade-off cannot occur) if one instead demands for a maximum photon number constraint, in such a way that mostly all of the "shadow" of the average density operator for a given code is required to be on a subspace with photon number no larger than n N_S, so that the shadow outside this subspace vanishes as the number n of channel uses becomes large. Finally, we prove that a small modification of the well-known coherent-state coding scheme meets this more demanding constraint.',
	 'authors': u'Mark M. Wilde, Andreas Winter,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6732',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nStrong converse for the classical capacity of the pure-loss bosonic  channel',
	 'urllink': u'http://arxiv.org/abs/1308.6732'}
2015-03-23 23:14:09+0000 [xxu46_7] INFO: Crawled 55 pages (at 1 pages/min), scraped 48 items (at 1 items/min)
2015-03-23 23:15:09+0000 [xxu46_7] INFO: Crawled 55 pages (at 0 pages/min), scraped 48 items (at 0 items/min)
2015-03-23 23:15:15+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6659> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:15:15+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6659>
	{'abstract': u'In this paper, we present an optimal filter for the enhancement or estimation of signals on the 2-sphere corrupted by noise, when both the signal and noise are realizations of anisotropic processes on the 2-sphere. The estimation of such a signal in the spatial or spectral domain separately can be shown to be inadequate. Therefore, we develop an optimal filter in the joint spatio-spectral domain by using a framework recently presented in the literature --- the spatially localized spherical harmonic transform --- enabling such processing. Filtering of a signal in the spatio-spectral domain facilitates taking into account anisotropic properties of both the signal and noise processes. The proposed spatio-spectral filtering is optimal under the mean-square error criterion. The capability of the proposed filtering framework is demonstrated with by an example to estimate a signal corrupted by an anisotropic noise process.',
	 'authors': u'Zubair Khalid, Rodney A. Kennedy, Parastoo Sadeghi, Salman Durrani,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6659',
	 'subjects': u'Instrumentation and Methods for Astrophysics (astro-ph.IM)',
	 'title': u'\nSpatio-spectral Formulation and Design of Spatially-Varying Filters for  Signal Estimation on the 2-Sphere',
	 'urllink': u'http://arxiv.org/abs/1308.6659'}
2015-03-23 23:16:09+0000 [xxu46_7] INFO: Crawled 56 pages (at 1 pages/min), scraped 49 items (at 1 items/min)
2015-03-23 23:16:57+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6604> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:16:57+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6604>
	{'abstract': u"We introduce a new algorithm for modularity-based community detection in large networks. The algorithm, which we refer to as a smart local moving algorithm, takes advantage of a well-known local moving heuristic that is also used by other algorithms. Compared with these other algorithms, our proposed algorithm uses the local moving heuristic in a more sophisticated way. Based on an analysis of a diverse set of networks, we show that our smart local moving algorithm identifies community structures with higher modularity values than other algorithms for large-scale modularity optimization, among which the popular 'Louvain algorithm' introduced by Blondel et al. (2008). The computational efficiency of our algorithm makes it possible to perform community detection in networks with tens of millions of nodes and hundreds of millions of edges. Our smart local moving algorithm also performs well in small and medium-sized networks. In short computing times, it identifies community structures with modularity values equally high as, or almost as high as, the highest values reported in the literature, and sometimes even higher than the highest values found in the literature.",
	 'authors': u'Ludo Waltman, Nees Jan van Eck,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6604',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nA smart local moving algorithm for large-scale modularity-based  community detection',
	 'urllink': u'http://arxiv.org/abs/1308.6604'}
2015-03-23 23:17:09+0000 [xxu46_7] INFO: Crawled 57 pages (at 1 pages/min), scraped 50 items (at 1 items/min)
2015-03-23 23:18:09+0000 [xxu46_7] INFO: Crawled 57 pages (at 0 pages/min), scraped 50 items (at 0 items/min)
2015-03-23 23:18:19+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6537> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:18:19+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6537>
	{'abstract': u'The k-core decomposition of a network has thus far mainly served as a powerful tool for the empirical study of complex networks. We now propose its explicit integration in a theoretical model. We introduce a Hard-core Random Network model that generates maximally random networks with arbitrary degree distribution and arbitrary k-core structure. We then solve exactly the bond percolation problem on the HRN model and produce fast and precise analytical estimates for the corresponding real networks. Extensive comparison with selected databases reveals that our approach performs better than existing models, while requiring less input information.',
	 'authors': u'Laurent H\xe9bert-Dufresne, Antoine Allard, Jean-Gabriel Young, Louis J. Dub\xe9,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6537',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nPercolation on random networks with arbitrary k-core structure',
	 'urllink': u'http://arxiv.org/abs/1308.6537'}
2015-03-23 23:19:09+0000 [xxu46_7] INFO: Crawled 58 pages (at 1 pages/min), scraped 51 items (at 1 items/min)
2015-03-23 23:20:02+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6503> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:20:02+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6503>
	{'abstract': u'We study non-asymptotic fundamental limits for transmitting classical information over memoryless quantum channels, i.e. we investigate the amount of classical information that can be transmitted when a quantum channel is used a finite number of times and a fixed, non-vanishing average error is permissible. We consider the classical capacity of quantum channels that are image-additive, including all classical to quantum channels, as well as the product state capacity of arbitrary quantum channels. In both cases we show that the non-asymptotic fundamental limit admits a second-order approximation that illustrates the speed at which the rate of optimal codes converges to the Holevo capacity as the blocklength tends to infinity. The behavior is governed by a new channel parameter, called channel dispersion, for which we provide a geometrical interpretation.',
	 'authors': u'Marco Tomamichel, Vincent Y. F. Tan,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6503',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nSecond-Order Asymptotics for the Classical Capacity of Image-Additive  Quantum Channels',
	 'urllink': u'http://arxiv.org/abs/1308.6503'}
2015-03-23 23:20:09+0000 [xxu46_7] INFO: Crawled 59 pages (at 1 pages/min), scraped 52 items (at 1 items/min)
2015-03-23 23:21:09+0000 [xxu46_7] INFO: Crawled 59 pages (at 0 pages/min), scraped 52 items (at 0 items/min)
2015-03-23 23:21:26+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6498> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:21:26+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6498>
	{'abstract': u'This paper proposes a specific type of Local Linear Model, the Shuffled Linear Model (SLM), that can be used as a universal approximator. Local operating points are chosen randomly and linear models are used to approximate a function or system around these points. The model can also be interpreted as an extension to Extreme Learning Machines with Radial Basis Function nodes, or as a specific way of using Takagi-Sugeno fuzzy models. Using the available theory of Extreme Learning Machines, universal approximation of the SLM and an upper bound on the number of models are proved mathematically, and an efficient algorithm is proposed.',
	 'authors': u'Laurens Bliek,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6498',
	 'subjects': u'Dynamical Systems (math.DS)',
	 'title': u'\nUniversal Approximation Using Shuffled Linear Models',
	 'urllink': u'http://arxiv.org/abs/1308.6498'}
2015-03-23 23:22:09+0000 [xxu46_7] INFO: Crawled 60 pages (at 1 pages/min), scraped 53 items (at 1 items/min)
2015-03-23 23:22:55+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6494> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:22:55+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6494>
	{'abstract': u'Spectral methods based on the eigenvectors of matrices are widely used in the analysis of network data, particularly for community detection and graph partitioning. Standard methods based on the adjacency matrix and related matrices, however, break down for very sparse networks, which includes many networks of practical interest. As a solution to this problem it has been recently proposed that we focus instead on the spectrum of the non-backtracking matrix, an alternative matrix representation of a network that shows better behavior in the sparse limit. Inspired by this suggestion, we here make use of a relaxation method to derive a spectral community detection algorithm that works well even in the sparse regime where other methods break down. Interestingly, however, the matrix at the heart of the method, it turns out, is not exactly the non-backtracking matrix, but a variant of it with a somewhat different definition. We study the behavior of this variant matrix for both artificial and real-world networks and find it to have desirable properties, especially in the common case of networks with broad degree distributions, for which it appears to have a better behaved spectrum and eigenvectors than the original non-backtracking matrix.',
	 'authors': u'M. E. J. Newman,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6494',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nSpectral community detection in sparse networks',
	 'urllink': u'http://arxiv.org/abs/1308.6494'}
2015-03-23 23:23:09+0000 [xxu46_7] INFO: Crawled 61 pages (at 1 pages/min), scraped 54 items (at 1 items/min)
2015-03-23 23:24:09+0000 [xxu46_7] INFO: Crawled 61 pages (at 0 pages/min), scraped 54 items (at 0 items/min)
2015-03-23 23:24:56+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6447> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:24:56+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6447>
	{'abstract': u"We present a secure device-independent quantum key distribution scheme based on Hardy's paradox. It has several novel, in comparison with protocols based on Bell inequalities, features: (a) The bits used for secret key do not come from the results of the measurements on an entangled state but from the choices of settings which are harder for an eavesdropper to influence; (b) Instead of a single security parameter (a violation of some Bell inequality) a set of them is used to estimate the level of trust in the secrecy of the key. This further restricts the eavesdropper's options. We prove the security of our protocol in both ideal and noisy case.",
	 'authors': u'Ramij Rahaman, Matthew G. Parker, Piotr Mironowicz, Marcin Paw\u0142owski,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6447',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u"\nDevice-independent quantum key distribution based on Hardy's paradox",
	 'urllink': u'http://arxiv.org/abs/1308.6447'}
2015-03-23 23:25:09+0000 [xxu46_7] INFO: Crawled 62 pages (at 1 pages/min), scraped 55 items (at 1 items/min)
2015-03-23 23:26:09+0000 [xxu46_7] INFO: Crawled 62 pages (at 0 pages/min), scraped 55 items (at 0 items/min)
2015-03-23 23:26:54+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6342> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:26:54+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6342>
	{'abstract': u'We introduce a new embarrassingly parallel parameter learning algorithm for Markov random fields with untied parameters which is efficient for a large class of practical models. Our algorithm parallelizes naturally over cliques and, for graphs of bounded degree, its complexity is linear in the number of cliques. Unlike its competitors, our algorithm is fully parallel and for log-linear models it is also data efficient, requiring only the local sufficient statistics of the data to estimate parameters.',
	 'authors': u'Yariv Dror Mizrahi, Misha Denil, Nando de Freitas,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6342',
	 'subjects': u'Machine Learning (stat.ML)',
	 'title': u'\nLinear and Parallel Learning of Markov Random Fields',
	 'urllink': u'http://arxiv.org/abs/1308.6342'}
2015-03-23 23:27:09+0000 [xxu46_7] INFO: Crawled 63 pages (at 1 pages/min), scraped 56 items (at 1 items/min)
2015-03-23 23:28:09+0000 [xxu46_7] INFO: Crawled 63 pages (at 0 pages/min), scraped 56 items (at 0 items/min)
2015-03-23 23:28:49+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6337> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:28:49+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6337>
	{'abstract': u'Convex optimization models find interesting applications, especially in signal/image processing and compressive sensing. We study some augmented convex models, which are perturbed by strongly convex functions, and propose a dual gradient algorithm. The proposed algorithm includes the linearized Bregman algorithm and the singular value thresholding algorithm as special cases. Based on fundamental properties of proximal operators, we present a concise approach to establish the convergence of both primal and dual sequences, improving the results in the existing literature.',
	 'authors': u'Hui Zhang, Lizhi Cheng, Wotao Yin,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6337',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nA dual algorithm for a class of augmented convex models',
	 'urllink': u'http://arxiv.org/abs/1308.6337'}
2015-03-23 23:29:09+0000 [xxu46_7] INFO: Crawled 64 pages (at 1 pages/min), scraped 57 items (at 1 items/min)
2015-03-23 23:30:03+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6320> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:30:03+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6320>
	{'abstract': u"This paper extends the author's previous two-dimensional work with Ou and LeVeque to high-resolution finite volume modeling of systems of fluids and poroelastic media in three dimensions, using logically rectangular mapped grids. A method is described for calculating consistent cell face areas and normal vectors for a finite volume method on a general non-rectilinear hexahedral grid. A novel limiting algorithm is also developed to cope with difficulties encountered in implementing high-resolution finite volume methods for anisotropic media on non-rectilinear grids; the new limiting approach is compatible with any limiter function, and typically reduces solution error even in situations where it is not necessary for correct functioning of the numerical method. Dimensional splitting is used to reduce the computational cost of the solution. The code implementing the three-dimensional algorithms is verified against known plane wave solutions, with particular attention to the performance of the new limiter algorithm in comparison to the classical one. An acoustic wave in brine striking an uneven bed of orthotropic layered sandstone is also simulated in order to demonstrate the capabilities of the simulation code.",
	 'authors': u'Grady I. Lemoine,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6320',
	 'subjects': u'Numerical Analysis (math.NA)',
	 'title': u'\nThree-Dimensional Mapped-Grid Finite Volume Modeling of  Poroelastic-Fluid Wave Propagation',
	 'urllink': u'http://arxiv.org/abs/1308.6320'}
2015-03-23 23:30:09+0000 [xxu46_7] INFO: Crawled 65 pages (at 1 pages/min), scraped 58 items (at 1 items/min)
2015-03-23 23:31:09+0000 [xxu46_7] INFO: Crawled 65 pages (at 0 pages/min), scraped 58 items (at 0 items/min)
2015-03-23 23:31:56+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6295> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:31:56+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6295>
	{'abstract': u'The identification of modular structures is essential for characterizing real networks formed by a mesoscopic level of organization where clusters contain nodes with a high internal degree of connectivity. Many methods have been developed to unveil community structures, but only a few studies have probed their suitability in incomplete networks. Here we assess the accuracy of community detection techniques in incomplete networks generated in sampling processes. We show that the walktrap and fast greedy algorithms are highly accurate for detecting the modular structure of incomplete complex networks even if many of their nodes are removed. Furthermore, we implemented an approach that improved the time performance of the walktrap and fast greedy algorithms, while retaining the accuracy rate in identifying the community membership of nodes. Taken together our results show that this new approach can be applied to speed up virtually any community detection method in dense complex networks, as it is the case of similarity networks.',
	 'authors': u'Diego R. Amancio, Osvaldo N. Oliveira Jr., Luciano da F. Costa,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6295',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nRobustness of community structure to node removal',
	 'urllink': u'http://arxiv.org/abs/1308.6295'}
2015-03-23 23:32:09+0000 [xxu46_7] INFO: Crawled 66 pages (at 1 pages/min), scraped 59 items (at 1 items/min)
2015-03-23 23:33:09+0000 [xxu46_7] INFO: Crawled 66 pages (at 0 pages/min), scraped 59 items (at 0 items/min)
2015-03-23 23:33:52+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6276> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:33:52+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6276>
	{'abstract': u'Communities play a crucial role to describe and analyse modern networks. However, the size of those networks has grown tremendously with the increase of computational power and data storage. While various methods have been developed to extract community structures, their computational cost or the difficulty to parallelize existing algorithms make partitioning real networks into communities a challenging problem. In this paper, we propose to alter an efficient algorithm, the Louvain method, such that communities are defined as the connected components of a tree-like assignment graph. Within this framework, we precisely describe the different steps of our algorithm and demonstrate its highly parallelizable nature. We then show that despite its simplicity, our algorithm has a partitioning quality similar to the original method on benchmark graphs and even outperforms other algorithms. We also show that, even on a single processor, our method is much faster and allows the analysis of very large networks.',
	 'authors': u'Arnaud Browet, P.-A. Absil, Paul Van Dooren,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6276',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nFast community detection using local neighbourhood search',
	 'urllink': u'http://arxiv.org/abs/1308.6276'}
2015-03-23 23:34:09+0000 [xxu46_7] INFO: Crawled 67 pages (at 1 pages/min), scraped 60 items (at 1 items/min)
2015-03-23 23:34:46+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6220> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:34:46+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6220>
	{'abstract': u'Simulated annealing (SA) was inspired from annealing in metallurgy, a technique involving heating and controlled cooling of a material to increase the size of its crystals and reduce their defects, both are attributes of the material that depend on its thermodynamic free energy. In this Paper, firstly we will study SA in details on its practical implementation. Then, hybrid pure SA with local (or global) search optimization methods allows us to be able to design several effective and efficient global search optimization methods. In order to keep the original sense of SA, we clarify our understandings of SA in crystallography and molecular modeling field through the studies of prion amyloid fibrils.',
	 'authors': u'Jiapu Zhang,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6220',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nSimulated annealing: in mathematical global optimization computation,  hybrid with local or global search, and practical applications in  crystallography and molecular modelling',
	 'urllink': u'http://arxiv.org/abs/1308.6220'}
2015-03-23 23:35:09+0000 [xxu46_7] INFO: Crawled 68 pages (at 1 pages/min), scraped 61 items (at 1 items/min)
2015-03-23 23:36:09+0000 [xxu46_7] INFO: Crawled 68 pages (at 0 pages/min), scraped 61 items (at 0 items/min)
2015-03-23 23:36:16+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6207> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:36:16+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6207>
	{'abstract': u'We propose a new strategy to decode color codes, which is based on the projection of the error onto three surface codes. This provides a method to transform every decoding algorithm of surface codes into a decoding algorithm of color codes. Applying this idea to a family of hexagonal color codes, with the perfect matching decoding algorithm for the three corresponding surface codes, we find a phase error threshold of approximately 8.7%. Finally, our approach enables us to establish a general lower bound on the error threshold of a family of color codes depending on the threshold of the three corresponding surface codes. These results are based on a chain complex interpretation of surface codes and color codes.',
	 'authors': u'Nicolas Delfosse,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6207',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nDecoding color codes by projection onto surface codes',
	 'urllink': u'http://arxiv.org/abs/1308.6207'}
2015-03-23 23:37:09+0000 [xxu46_7] INFO: Crawled 69 pages (at 1 pages/min), scraped 62 items (at 1 items/min)
2015-03-23 23:37:24+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6111> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:37:24+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6111>
	{'abstract': u'In this paper, we improve the classical multiplicative ergodic theorem.',
	 'authors': u'Xiongping Dai,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6111',
	 'subjects': u'Dynamical Systems (math.DS)',
	 'title': u"\nFiner filtration for matrix-valued cocycle based on Oseledec's  multiplicative ergodic theorem",
	 'urllink': u'http://arxiv.org/abs/1308.6111'}
2015-03-23 23:38:09+0000 [xxu46_7] INFO: Crawled 70 pages (at 1 pages/min), scraped 63 items (at 1 items/min)
2015-03-23 23:38:56+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6075> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:38:56+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6075>
	{'abstract': u"Scaling phenomena have been intensively studied during the past decade in the context of complex networks. As part of these works, recently novel methods have appeared to measure the dimension of abstract and spatially embedded networks. In this paper we propose a new dimension measurement method for networks, which does not require global knowledge on the embedding of the nodes, instead it exploits link-wise information (link lengths, link delays or other physical quantities). Our method can be regarded as a generalization of the spectral dimension, that grasps the network's large-scale structure through local observations made by a random walker while traversing the links. We apply the presented method to synthetic and real-world networks, including road maps, the Internet infrastructure and the Gowalla geosocial network. We analyze the theoretically and empirically designated case when the length distribution of the links has the form P(r) ~ 1/r. We show that while previous dimension concepts are not applicable in this case, the new dimension measure still exhibits scaling with two distinct scaling regimes. Our observations suggest that the link length distribution is not sufficient in itself to entirely control the dimensionality of complex networks, and we show that the proposed measure provides information that complements other known measures.",
	 'authors': u'D\xe1niel Kondor, P\xe9ter M\xe1tray, Istv\xe1n Csabai, G\xe1bor Vattay,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6075',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nMeasuring the dimension of partially embedded networks',
	 'urllink': u'http://arxiv.org/abs/1308.6075'}
2015-03-23 23:39:09+0000 [xxu46_7] INFO: Crawled 71 pages (at 1 pages/min), scraped 64 items (at 1 items/min)
2015-03-23 23:40:09+0000 [xxu46_7] INFO: Crawled 71 pages (at 0 pages/min), scraped 64 items (at 0 items/min)
2015-03-23 23:40:49+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6074> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:40:49+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6074>
	{'abstract': u'Over the recent years, the field of whole metagenome shotgun sequencing has witnessed significant growth due to the high-throughput sequencing technologies that allow sequencing genomic samples cheaper, faster, and with better coverage than before. This technical advancement has initiated the trend of sequencing multiple samples in different conditions or environments to explore the similarities and dissimilarities of the microbial communities. Examples include the human microbiome project and various studies of the human intestinal tract. With the availability of ever larger databases of such measurements, finding samples similar to a given query sample is becoming a central operation. In this paper, we develop a content-based exploration and retrieval method for whole metagenome sequencing samples. We apply a distributed string mining framework to efficiently extract all informative sequence -mers from a pool of metagenomic samples and use them to measure the dissimilarity between two samples. We evaluate the performance of the proposed approach on two human gut metagenome data sets as well as human microbiome project metagenomic samples. We observe significant enrichment for diseased gut samples in results of queries with another diseased sample and very high accuracy in discriminating between different body sites even though the method is unsupervised. A software implementation of the DSM framework is available at this https URL',
	 'authors': u'Sohan Seth, Niko V\xe4lim\xe4ki, Samuel Kaski, Antti Honkela,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6074',
	 'subjects': u'Genomics (q-bio.GN)',
	 'title': u'\nExploration and retrieval of whole-metagenome sequencing samples',
	 'urllink': u'http://arxiv.org/abs/1308.6074'}
2015-03-23 23:41:09+0000 [xxu46_7] INFO: Crawled 72 pages (at 1 pages/min), scraped 65 items (at 1 items/min)
2015-03-23 23:42:09+0000 [xxu46_7] INFO: Crawled 72 pages (at 0 pages/min), scraped 65 items (at 0 items/min)
2015-03-23 23:42:26+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6067> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:42:26+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6067>
	{'abstract': u'Consider a protocol in which Belinda seals a (classical) message. She gives the resulting sealed message to Charlie, who can either unseal and read the message or return it unopened to Belinda. If he returns it unopened, Belinda should be able to verify that Charlie neither read the message nor made a copy that would allow him to read it later. Such a protocol is impossible with classical cryptography: Charlie can copy a message and do anything he likes to that copy without damaging the original. With quantum cryptography, on the other hand, the no cloning theorem implies that Charlie cannot simply copy a message and unseal the copy. Abstract In this paper, I prove that any conventional quantum cryptographic protocol can give at best a very weak security guarantee. However, quantum cryptography in conjunction with classical functions that can only be inverted by humans (i.e. CAPTCHAs) can potentially give exponential security.',
	 'authors': u'Andrew Lutomirski,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6067',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nSealed States And Quantum Blackmail',
	 'urllink': u'http://arxiv.org/abs/1308.6067'}
2015-03-23 23:43:09+0000 [xxu46_7] INFO: Crawled 73 pages (at 1 pages/min), scraped 66 items (at 1 items/min)
2015-03-23 23:44:09+0000 [xxu46_7] INFO: Crawled 73 pages (at 0 pages/min), scraped 66 items (at 0 items/min)
2015-03-23 23:44:21+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6062> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:44:21+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6062>
	{'abstract': u'The purpose of this paper is to develop a model reduction theory for linear quantum stochastic systems that are commonly encountered in quantum optics and related fields, modeling devices such as optical cavities and optical parametric amplifiers, as well as quantum networks composed of such devices. Results are derived on subsystem truncation of such systems and it is shown that this truncation preserves the physical realizability property of linear quantum stochastic systems. It is also shown that the property of complete passivity of linear quantum stochastic systems is preserved under subsystem truncation. A necessary and sufficient condition for the existence of a balanced realization of a linear quantum stochastic system under sympletic transformations is derived. Such a condition turns out to be very restrictive and will not be satisfied by generic linear quantum stochastic systems, thus necessary and sufficient conditions for relaxed notions of simultaneous diagonalization of the controllability and observability Gramians of linear quantum stochastic systems under symplectic transformations are also obtained. The notion of a quasi-balanced realization is introduced and it is shown that all asymptotically stable completely passive linear quantum stochastic systems have a quasi-balanced realization. Moreover, an explicit bound for the subsystem truncation error on a quasi-balanceable linear quantum stochastic system is provided. The results are applied in an example of model reduction in the context of low-pass optical filtering of coherent light using a network of optical cavities.',
	 'authors': u'Hendra I. Nurdin,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6062',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nStructures and Transformations for Model Reduction of Linear Quantum  Stochastic Systems',
	 'urllink': u'http://arxiv.org/abs/1308.6062'}
2015-03-23 23:45:09+0000 [xxu46_7] INFO: Crawled 74 pages (at 1 pages/min), scraped 67 items (at 1 items/min)
2015-03-23 23:46:09+0000 [xxu46_7] INFO: Crawled 74 pages (at 0 pages/min), scraped 67 items (at 0 items/min)
2015-03-23 23:46:18+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6038> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:46:18+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6038>
	{'abstract': u'In this paper, we build up a framework for sparse interpolation. We first investigate the theoretical limit of the number of unisolvent points for sparse interpolation under a general setting and try to answer some basic questions of this topic. We also explore the relation between classical interpolation and sparse interpolation. We second consider the design of the interpolation points for the -sparse functions in high dimensional Chebyshev bases, for which the possible applications include uncertainty quantification, numerically solving stochastic or parametric PDEs and compressed sensing. Unlike the traditional random sampling method, we present in this paper a deterministic method to produce the interpolation points, and show its performance with minimization by analyzing the mutual incoherence of the interpolation matrix. Numerical experiments show that the deterministic points have a similar performance with that of the random points.',
	 'authors': u'Zhiqiang Xu, Tao Zhou,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6038',
	 'subjects': u'Numerical Analysis (math.NA)',
	 'title': u'\nOn sparse interpolation and the design of deterministic interpolation  points',
	 'urllink': u'http://arxiv.org/abs/1308.6038'}
2015-03-23 23:47:09+0000 [xxu46_7] INFO: Crawled 75 pages (at 1 pages/min), scraped 68 items (at 1 items/min)
2015-03-23 23:47:50+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5923> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:47:50+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5923>
	{'abstract': u'We develop a model which can be used to analyse the scenario of exploring quantum network with a distracted sense of direction. Using this model we analyse the behaviour of quantum mobile agents operating with non-adaptive and adaptive strategies which can be employed in this scenario. We introduce the notion of node visiting suitable for analysing quantum superpositions of states by distinguishing between visiting and attaining a position. We show that without a proper model of adaptiveness, it is not possible for the party representing the distraction in the sense of direction, to obtain the results analogous to the classical case. Moreover, with additional control resources the total number of attained positions is maintained if the number of visited positions is strictly limited.',
	 'authors': u'Jaros\u0142aw Adam Miszczak, Przemys\u0142aw Sadowski,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5923',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nQuantum network exploration with a faulty sense of direction',
	 'urllink': u'http://arxiv.org/abs/1308.5923'}
2015-03-23 23:48:09+0000 [xxu46_7] INFO: Crawled 76 pages (at 1 pages/min), scraped 69 items (at 1 items/min)
2015-03-23 23:49:09+0000 [xxu46_7] INFO: Crawled 76 pages (at 0 pages/min), scraped 69 items (at 0 items/min)
2015-03-23 23:49:39+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5884> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:49:39+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5884>
	{'abstract': u'We study formal properties of smooth max-information, a generalization of von Neumann mutual information derived from the max-relative entropy. Recent work suggests that it is a useful quantity in one-shot channel coding, quantum rate distortion theory and the physics of quantum many-body systems. Max-information can be defined in multiple ways. We demonstrate that different smoothed definitions are essentially equivalent (up to logarithmic terms in the smoothing parameters). These equivalence relations allow us to derive new chain rules for the max-information in terms of min- and max-entropies, thus extending the smooth entropy formalism to mutual information.',
	 'authors': u'Nikola Ciganovi\u0107, Normand J. Beaudry, Renato Renner,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5884',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nSmooth Max-Information as One-Shot Generalization for Mutual Information',
	 'urllink': u'http://arxiv.org/abs/1308.5884'}
2015-03-23 23:50:09+0000 [xxu46_7] INFO: Crawled 77 pages (at 1 pages/min), scraped 70 items (at 1 items/min)
2015-03-23 23:51:08+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5846> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:51:08+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5846>
	{'abstract': u'We employ a domain decomposition approach with Lagrange multipliers to implement fault slip in a finite-element code, PyLith, for use in both quasi-static and dynamic crustal deformation applications. This integrated approach to solving both quasi-static and dynamic simulations leverages common finite-element data structures and implementations of various boundary conditions, discretization schemes, and bulk and fault rheologies. We have developed a custom preconditioner for the Lagrange multiplier portion of the system of equations that provides excellent scalability with problem size compared to conventional additive Schwarz methods. We demonstrate application of this approach using benchmarks for both quasi-static viscoelastic deformation and dynamic spontaneous rupture propagation that verify the numerical implementation in PyLith.',
	 'authors': u'Brad T. Aagaard, Matthew G. Knepley, Charles A. Williams,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5846',
	 'subjects': u'Geophysics (physics.geo-ph)',
	 'title': u'\nA Domain Decomposition Approach to Implementing Fault Slip in  Finite-Element Models of Quasi-static and Dynamic Crustal Deformation',
	 'urllink': u'http://arxiv.org/abs/1308.5846'}
2015-03-23 23:51:09+0000 [xxu46_7] INFO: Crawled 78 pages (at 1 pages/min), scraped 71 items (at 1 items/min)
2015-03-23 23:52:09+0000 [xxu46_7] INFO: Crawled 78 pages (at 0 pages/min), scraped 71 items (at 0 items/min)
2015-03-23 23:52:36+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5798> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:52:36+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5798>
	{'abstract': u'We prove that there are superexponentially many combinatorially distinct d-dimensional neighborly Delaunay triangulations on n points. These are the first examples of neighborly Delaunay triangulations that cannot be obtained via a stereographic projection of an inscribed cyclic polytope, and provide the current best lower bound for the number of combinatorial types of Delaunay triangulations. To prove this bound we combine recent results on constructions for neighborly and inscribable polytopes to obtain a very simple explicit technique to generate a rich family of inscribable neighborly polytopes, and hence of point configurations with neighborly Delaunay triangulations.',
	 'authors': u'Bernd Gonska, Arnau Padrol,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5798',
	 'subjects': u'Metric Geometry (math.MG)',
	 'title': u'\nNeighborly inscribed polytopes and Delaunay triangulations',
	 'urllink': u'http://arxiv.org/abs/1308.5798'}
2015-03-23 23:53:09+0000 [xxu46_7] INFO: Crawled 79 pages (at 1 pages/min), scraped 72 items (at 1 items/min)
2015-03-23 23:54:09+0000 [xxu46_7] INFO: Crawled 79 pages (at 0 pages/min), scraped 72 items (at 0 items/min)
2015-03-23 23:54:26+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5788> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:54:26+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5788>
	{'abstract': u'We identify a formal connection between physical problems related to the detection of separable (unentangled) quantum states and complexity classes in theoretical computer science. In particular, we show that to nearly every quantum interactive proof complexity class (including BQP, QMA, QMA(2), and QSZK), there corresponds a natural separability testing problem that is complete for that class. Of particular interest is the fact that the problem of determining whether an isometry can be made to produce a separable state is either QMA-complete or QMA(2)-complete, depending upon whether the distance between quantum states is measured by the one-way LOCC norm or the trace norm. We obtain strong hardness results by proving that for each n-qubit maximally entangled state there exists a fixed one-way LOCC measurement that distinguishes it from any separable state with error probability that decays exponentially in n.',
	 'authors': u'Gus Gutoski, Patrick Hayden, Kevin Milner, Mark M. Wilde,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5788',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nQuantum interactive proofs and the complexity of separability testing',
	 'urllink': u'http://arxiv.org/abs/1308.5788'}
2015-03-23 23:55:09+0000 [xxu46_7] INFO: Crawled 80 pages (at 1 pages/min), scraped 73 items (at 1 items/min)
2015-03-23 23:56:09+0000 [xxu46_7] INFO: Crawled 80 pages (at 0 pages/min), scraped 73 items (at 0 items/min)
2015-03-23 23:56:10+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5752> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:56:10+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5752>
	{'abstract': u"We present a simple generalization of Hirsch's h-index, Z = sqrt+C/ sqrt, where C is the total number of citations. Z is aimed at correcting the potentially excessive penalty made by h on a scientist's highly cited papers, because for the majority of scientists analyzed, we find the excess citation fraction (C-h^)/C to be distributed closely around the value 0.75, meaning that 75 percent of the author's impact is neglected. Additionally, Z is less sensitive to local changes in a scientist's citation profile, namely perturbations which increase h while only marginally affecting C. Using real career data for 476 physicists careers and 488 biologist careers, we analyze both the distribution of and the rank stability of Z with respect to the Hirsch index h and the Egghe index g. We analyze careers distributed across a wide range of total impact, including top-cited physicists and biologists for benchmark comparison. In practice, the Z-index requires the same information needed to calculate h and could be effortlessly incorporated within career profile databases, such as Google Scholar and ResearcherID. Because Z incorporates information from the entire publication profile while being more robust than h and g to local perturbations, we argue that Z is better suited for ranking comparisons in academic decision-making scenarios comprising a large number of scientists.",
	 'authors': u'Alexander M. Petersen, Sauro Succi,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5752',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nThe Z-index: A geometric representation of productivity and impact which  accounts for information in the entire rank-citation profile',
	 'urllink': u'http://arxiv.org/abs/1308.5752'}
2015-03-23 23:57:09+0000 [xxu46_7] INFO: Crawled 81 pages (at 1 pages/min), scraped 74 items (at 1 items/min)
2015-03-23 23:57:53+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5728> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:57:53+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5728>
	{'abstract': u'This paper considers some formulations and possible approaches to the coherent LQG and quantum control problems. Some new results for these problems are presented in the case of annihilation operator only quantum systems showing that in this case, the optimal controllers are trivial controllers.',
	 'authors': u'Ian R. Petersen,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5728',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nNotes on Coherent Feedback Control for Linear Quantum Systems',
	 'urllink': u'http://arxiv.org/abs/1308.5728'}
2015-03-23 23:58:09+0000 [xxu46_7] INFO: Crawled 82 pages (at 1 pages/min), scraped 75 items (at 1 items/min)
2015-03-23 23:58:45+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5678> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-23 23:58:45+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5678>
	{'abstract': u'The transmission dynamics of some infectious diseases is related to the contact structure between individuals in a network. We used five algorithms to generate contact networks with different topological structure but with the same scale-free degree distribution. We simulated the spread of acute and chronic infectious diseases on these networks, using SI (Susceptible - Infected) and SIS (Susceptible - Infected - Susceptible) epidemic models. In the simulations, our objective was to observe the effects of the topological structure of the networks on the dynamics and prevalence of the simulated diseases. We found that the dynamics of spread of an infectious disease on different networks with the same degree distribution may be considerably different.',
	 'authors': u'Raul Ossada, Jos\xe9 H. H. Grisi-Filho, Fernando Ferreira, Marcos Amaku,',
	 'category': u'Computer Science ',
	 'date': '2013-8-26',
	 'pdflink': u'http://arxiv.org/pdf/1308.5678',
	 'subjects': u'Populations and Evolution (q-bio.PE)',
	 'title': u'\nModeling the Dynamics of Infectious Diseases in Different Scale-Free  Networks with the Same Degree Distribution',
	 'urllink': u'http://arxiv.org/abs/1308.5678'}
2015-03-23 23:59:09+0000 [xxu46_7] INFO: Crawled 83 pages (at 1 pages/min), scraped 76 items (at 1 items/min)
2015-03-24 00:00:07+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5673> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:00:07+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5673>
	{'abstract': u'We propose a linear compression technique for the time interval distribution of photon pairs. Using a partially frequency-entangled two-photon (TP) state with appropriate mean time width, the compressed TP time interval width can be kept in the minimum limit set by the phase modulation, and is independent of its initial width. As a result of this effect, ultra-narrow TP time interval distribution can be compressed with relatively slow phase modulators to decrease the damage of the phase-instability arising from the phase modulation process.',
	 'authors': u'J.-S. Pan, X.-B. Zou, Z.-Y. Zhou, D.-S. Ding, B.-S. Shi, G.-C. Guo,',
	 'category': u'Computer Science ',
	 'date': '2013-8-26',
	 'pdflink': u'http://arxiv.org/pdf/1308.5673',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nNonlocal linear compression of two-photon time interval distribution',
	 'urllink': u'http://arxiv.org/abs/1308.5673'}
2015-03-24 00:00:09+0000 [xxu46_7] INFO: Crawled 84 pages (at 1 pages/min), scraped 77 items (at 1 items/min)
2015-03-24 00:01:09+0000 [xxu46_7] INFO: Crawled 84 pages (at 0 pages/min), scraped 77 items (at 0 items/min)
2015-03-24 00:01:26+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5626> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:01:26+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5626>
	{'abstract': u'Preconditioning of a linear system obtained from spectral discretization of time-dependent PDEs often results in a full matrix which is expensive to compute and store specially when the problem size increases. A matrix-free implementation is usually applied to resolve this issue. In this framework, preconditioning is typically challenging since the entries of the matrix are not explicitly available. In this short note, we propose a statistical approach to gradually create a preconditioner matrix by collecting the information obtained from matrix-vector product in the Arnoldi loop of an unpreconditioned Krylov subspace algorithm. The gathered information are then correlated using a multiple regressors estimate where the error is assumed to be normally distributed. This procedure yields a banded diagonal matrix which is then used as a preconditioner in the next iterative solve. This is repeated between iterative solves until a good preconditioner is constructed on fly. This statistically iterative procedure is progressive since the fidelity of the preconditioning matrix improves by adding more data obtained from matrix-vector product during the entire solution procedure. The proposed algorithm is validated for a sample implementation.',
	 'authors': u'A. Ghasemi, L. K. Taylor,',
	 'category': u'Computer Science ',
	 'date': '2013-8-26',
	 'pdflink': u'http://arxiv.org/pdf/1308.5626',
	 'subjects': u'Statistics Theory (math.ST)',
	 'title': u'\nA Progressive Statistical Method for Preconditioning Matrix-Free  Solution of High-Order Discretization of Linear Time-Dependent Problems',
	 'urllink': u'http://arxiv.org/abs/1308.5626'}
2015-03-24 00:02:09+0000 [xxu46_7] INFO: Crawled 85 pages (at 1 pages/min), scraped 78 items (at 1 items/min)
2015-03-24 00:03:09+0000 [xxu46_7] INFO: Crawled 85 pages (at 0 pages/min), scraped 78 items (at 0 items/min)
2015-03-24 00:03:12+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5620> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:03:12+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5620>
	{'abstract': u'We study the structure of planar point sets that determine a small number of distinct distances. Specifically, we show that if a set P of n points determines o(n) distinct distances, then no line contains Omega(n^) points of P and no circle contains Omega(n^) points of P. We rely on the bipartite and partial variant of the Elekes-Sharir framework that was presented by Sharir, Sheffer, and Solymosi in cite. For the case of lines we combine this framework with a theorem from additive combinatorics, and for the case of circles we combine it with some basic algebraic geometry and a recent incidence bound for plane algebraic curves by Wang, Yang, and Zhang cite. A significant difference between our approach and that of cite (and other recent extensions) is that, instead of dealing with distances between two point sets that are restricted to one-dimensional curves, we consider distances between one set that is restricted to a curve and one set with no restrictions on it.',
	 'authors': u'Adam Sheffer, Joshua Zahl, Frank de Zeeuw,',
	 'category': u'Computer Science ',
	 'date': '2013-8-26',
	 'pdflink': u'http://arxiv.org/pdf/1308.5620',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nFew distinct distances implies no heavy lines or circles',
	 'urllink': u'http://arxiv.org/abs/1308.5620'}
2015-03-24 00:04:09+0000 [xxu46_7] INFO: Crawled 86 pages (at 1 pages/min), scraped 79 items (at 1 items/min)
2015-03-24 00:04:35+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5586> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:04:35+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5586>
	{'abstract': u'The paper is a part of an ongoing program which aims to show that the existential theory in free groups (hyperbolic groups or even toral relatively hyperbolic) is NP-complete. For that we study compression of solutions with straight-line programs (SLPs) as suggested originally by Plandowski and Rytter in the context of a single word equation. We review some basic results on SLPs and give full proofs in order to keep this fundamental part of the program self-contained. Next we study systems of equations with constraints in free groups and more generally in free products of abelian groups. We show how to compress minimal solutions with extended Parikh-constraints. This type of constraints allows to express semi linear conditions as e.g. alphabetic information. The result relies on some combinatorial analysis and has not been shown elsewhere. We show similar compression results for Boolean formula of equations over a torsion-free -hyperbolic group. The situation is much more delicate than in free groups. As byproduct we improve the estimation of the "capacity" constant used by Rips and Sela in their paper "Canonical representatives and equations in hyperbolic groups" from a double-exponential bound in to some single-exponential bound. The final section shows compression results for toral relatively hyperbolic group using the work of Dahmani: We show that given a system of equations over a fixed toral relatively hyperbolic group, for every solution of length there is an SLP for another solution such that the size of the SLP is bounded by some polynomial where is the size of the system.',
	 'authors': u'Volker Diekert, Olga Kharlampovich, Atefeh Mohajeri Moghaddam,',
	 'category': u'Computer Science ',
	 'date': '2013-8-26',
	 'pdflink': u'http://arxiv.org/pdf/1308.5586',
	 'subjects': u'Group Theory (math.GR)',
	 'title': u'\nSLP compression for solutions of equations with constraints in free and  hyperbolic groups',
	 'urllink': u'http://arxiv.org/abs/1308.5586'}
2015-03-24 00:05:09+0000 [xxu46_7] INFO: Crawled 87 pages (at 1 pages/min), scraped 80 items (at 1 items/min)
2015-03-24 00:06:06+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5576> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:06:06+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5576>
	{'abstract': u'A Bayesian factor graph reduced to normal form consists in the interconnection of diverter units (or equal constraint units) and Single-Input/Single-Output (SISO) blocks. In this framework localized adaptation rules are explicitly derived from a constrained maximum likelihood (ML) formulation and from a minimum KL-divergence criterion using KKT conditions. The learning algorithms are compared with two other updating equations based on a Viterbi-like and on a variational approximation respectively. The performance of the various algorithm is verified on synthetic data sets for various architectures. The objective of this paper is to provide the programmer with explicit algorithms for rapid deployment of Bayesian graphs in the applications.',
	 'authors': u'Francesco A. N. Palmieri,',
	 'category': u'Computer Science ',
	 'date': '2013-8-26',
	 'pdflink': u'http://arxiv.org/pdf/1308.5576',
	 'subjects': u'Machine Learning (stat.ML)',
	 'title': u'\nA Comparison of Algorithms for Learning Hidden Variables in Normal  Graphs',
	 'urllink': u'http://arxiv.org/abs/1308.5576'}
2015-03-24 00:06:09+0000 [xxu46_7] INFO: Crawled 88 pages (at 1 pages/min), scraped 81 items (at 1 items/min)
2015-03-24 00:07:09+0000 [xxu46_7] INFO: Crawled 88 pages (at 0 pages/min), scraped 81 items (at 0 items/min)
2015-03-24 00:07:57+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5546> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:07:57+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5546>
	{'abstract': u'Non-negative blind source separation (BSS) has raised interest in various fields of research, as testified by the wide literature on the topic of non-negative matrix factorization (NMF). In this context, it is fundamental that the sources to be estimated present some diversity in order to be efficiently retrieved. Sparsity is known to enhance such contrast between the sources while producing very robust approaches, especially to noise. In this paper we introduce a new algorithm in order to tackle the blind separation of non-negative sparse sources from noisy measurements. We first show that sparsity and non-negativity constraints have to be carefully applied on the sought-after solution. In fact, improperly constrained solutions are unlikely to be stable and are therefore sub-optimal. The proposed algorithm, named nGMCA (non-negative Generalized Morphological Component Analysis), makes use of proximal calculus techniques to provide properly constrained solutions. The performance of nGMCA compared to other state-of-the-art algorithms is demonstrated by numerical experiments encompassing a wide variety of settings, with negligible parameter tuning. In particular, nGMCA is shown to provide robustness to noise and performs well on synthetic mixtures of real NMR spectra.',
	 'authors': u'J\xe9r\xe9my Rapin, J\xe9r\xf4me Bobin, Anthony Larue, Jean-Luc Starck,',
	 'category': u'Computer Science ',
	 'date': '2013-8-26',
	 'pdflink': u'http://arxiv.org/pdf/1308.5546',
	 'subjects': u'Machine Learning (stat.ML)',
	 'title': u'\nSparse and Non-Negative BSS for Noisy Data',
	 'urllink': u'http://arxiv.org/abs/1308.5546'}
2015-03-24 00:08:09+0000 [xxu46_7] INFO: Crawled 89 pages (at 1 pages/min), scraped 82 items (at 1 items/min)
2015-03-24 00:09:09+0000 [xxu46_7] INFO: Crawled 89 pages (at 0 pages/min), scraped 82 items (at 0 items/min)
2015-03-24 00:09:25+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5533> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:09:25+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5533>
	{'abstract': u'Obtaining reliable answers to the major scientific questions raised by climate change in time to take appropriate action gives added urgency to the open access program.',
	 'authors': u'Ian Percival,',
	 'category': u'Computer Science ',
	 'date': '2013-8-26',
	 'pdflink': u'http://arxiv.org/pdf/1308.5533',
	 'subjects': u'General Physics (physics.gen-ph)',
	 'title': u'\nClimate Change and Open Science',
	 'urllink': u'http://arxiv.org/abs/1308.5533'}
2015-03-24 00:10:09+0000 [xxu46_7] INFO: Crawled 90 pages (at 1 pages/min), scraped 83 items (at 1 items/min)
2015-03-24 00:10:56+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5513> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:10:56+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5513>
	{'abstract': u'We view web forums as virtual living organisms feeding on user\'s attention and investigate how these organisms grow at the expense of collective attention. We find that the "body mass" () and "energy consumption" () of the studied forums exhibits the allometric growth property, i.e., . This implies that within a forum, the network transporting attention flow between threads has a structure invariant of time, despite of the continuously changing of the nodes (threads) and edges (clickstreams). The observed time-invariant topology allows us to explain the dynamics of networks by the behavior of threads. In particular, we describe the clickstream dissipation on threads using the function , in which is the clickstreams to node and is the clickstream dissipated from . It turns out that , an indicator for dissipation efficiency, is negatively correlated with and sets the lower boundary for . Our findings have practical consequences. For example, can be used as a measure of the "stickiness" of forums, because it quantifies the stable ability of forums to convert into , i.e., to remain users "lock-in" the forum. Meanwhile, the correlation between and provides a convenient method to evaluate the `stickiness" of forums. Finally, we discuss an optimized "body mass" of forums at around that minimizes and maximizes .',
	 'authors': u'Lingfei Wu, Jiang Zhang, Min Zhao,',
	 'category': u'Computer Science ',
	 'date': '2013-8-26',
	 'pdflink': u'http://arxiv.org/pdf/1308.5513',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nThe Metabolism and Growth of Web Forums',
	 'urllink': u'http://arxiv.org/abs/1308.5513'}
2015-03-24 00:11:09+0000 [xxu46_7] INFO: Crawled 91 pages (at 1 pages/min), scraped 84 items (at 1 items/min)
2015-03-24 00:12:09+0000 [xxu46_7] INFO: Crawled 91 pages (at 0 pages/min), scraped 84 items (at 0 items/min)
2015-03-24 00:12:44+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5470> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:12:44+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5470>
	{'abstract': u'We demonstrate in this paper the use of tools of complex network theory to describe the strategy of Australia and England in the recently concluded Ashes 2013 Test series. Using partnership data made available by cricinfo during the Ashes 2013 Test series, we generate batting partnership network (BPN) for each team, in which nodes correspond to batsmen and links represent runs scored in partnerships between batsmen. The resulting network display a visual summary of the pattern of run-scoring by each team, which helps us in identifying potential weakness in a batting order. We use different centrality scores to quantify the performance, relative importance and effect of removing a player from the team. We observe that England is an extremely well connected team, in which lower order batsmen consistently contributed significantly to the team score. Contrary to this Australia showed dependence on their top order batsmen.',
	 'authors': u'Satyam Mukherjee,',
	 'category': u'Computer Science ',
	 'date': '2013-8-26',
	 'pdflink': u'http://arxiv.org/pdf/1308.5470',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nAshes 2013 - A network theory analysis of Cricket strategies',
	 'urllink': u'http://arxiv.org/abs/1308.5470'}
2015-03-24 00:13:09+0000 [xxu46_7] INFO: Crawled 92 pages (at 1 pages/min), scraped 85 items (at 1 items/min)
2015-03-24 00:14:09+0000 [xxu46_7] INFO: Crawled 92 pages (at 0 pages/min), scraped 85 items (at 0 items/min)
2015-03-24 00:14:13+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5465> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:14:13+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5465>
	{'abstract': u'In this paper we study the property of phase retrievability by redundant sysems of vectors under perturbations of the frame set. Specifically we show that if a set of vectors in the complex Hilbert space of dimension n allows for vector reconstruction from magnitudes of its coefficients, then there is a perturbation bound so that any frame set within from has the same property. In particular this proves the recent construction in cite is stable under perturbations. By the same token we reduce the critical cardinality conjectured in cite to proving a stability result for non phase-retrievable frames.',
	 'authors': u'Radu Balan,',
	 'category': u'Computer Science ',
	 'date': '2013-8-25',
	 'pdflink': u'http://arxiv.org/pdf/1308.5465',
	 'subjects': u'Functional Analysis (math.FA)',
	 'title': u'\nStability of Phase Retrievable Frames',
	 'urllink': u'http://arxiv.org/abs/1308.5465'}
2015-03-24 00:15:09+0000 [xxu46_7] INFO: Crawled 93 pages (at 1 pages/min), scraped 86 items (at 1 items/min)
2015-03-24 00:15:20+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5317> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:15:20+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5317>
	{'abstract': u'What is the effect of the combined direct and indirect social influences-peer pressure (PP)-on a social groups collective decisions? We present a model that captures PP as a function of the socio-cultural distance between individuals in a social group. Using this model and empirical data from 15 real-world social networks we found that the PP level determines how fast a social group reaches consensus. More importantly, the levels of PP determine the leaders who can achieve full control of their social groups. PP can overcome barriers imposed upon a consensus by the existence of tightly connected communities with local leaders or the existence of leaders with poor cohesiveness of opinions. A moderate level of PP is also necessary to explain the rate at which innovations diffuse through a variety of social groups.',
	 'authors': u'Ernesto Estrada, Eusebio Vargas-Estrada,',
	 'category': u'Computer Science ',
	 'date': '2013-8-24',
	 'pdflink': u'http://arxiv.org/pdf/1308.5317',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nPeer Pressure Shapes Consensus, Leadership, and Innovations in Social  Groups',
	 'urllink': u'http://arxiv.org/abs/1308.5317'}
2015-03-24 00:16:09+0000 [xxu46_7] INFO: Crawled 94 pages (at 1 pages/min), scraped 87 items (at 1 items/min)
2015-03-24 00:17:09+0000 [xxu46_7] INFO: Crawled 94 pages (at 0 pages/min), scraped 87 items (at 0 items/min)
2015-03-24 00:17:17+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5294> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:17:17+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5294>
	{'abstract': u'In this paper, we consider solving multiple-block separable convex minimization problems using alternating direction method of multipliers (ADMM). Motivated by the fact that the existing convergence theory for ADMM is mostly limited to the two-block case, we analyze in this paper, both theoretically and numerically, a new strategy that first transforms a multi-block problem into an equivalent two-block problem (either in the primal domain or in the dual domain) and then solves it using the standard two-block ADMM. In particular, we derive convergence results for this two-block ADMM approach to solve multi-block separable convex minimization problems, including an improved O(1/ epsilon) iteration complexity result. Moreover, we compare the numerical efficiency of this approach with the standard multi-block ADMM on several separable convex minimization problems which include basis pursuit, robust principal component analysis and latent variable Gaussian graphical model selection. The numerical results show that the multiple-block ADMM, although lacks theoretical convergence guarantees, typically outperforms two-block ADMMs.',
	 'authors': u'Xiangfeng Wang, Mingyi Hong, Shiqian Ma, Zhi-Quan Luo,',
	 'category': u'Computer Science ',
	 'date': '2013-8-24',
	 'pdflink': u'http://arxiv.org/pdf/1308.5294',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nSolving Multiple-Block Separable Convex Minimization Problems Using  Two-Block Alternating Direction Method of Multipliers',
	 'urllink': u'http://arxiv.org/abs/1308.5294'}
2015-03-24 00:18:09+0000 [xxu46_7] INFO: Crawled 95 pages (at 1 pages/min), scraped 88 items (at 1 items/min)
2015-03-24 00:18:47+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5261> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:18:47+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5261>
	{'abstract': u'Reconstructing the connections between the nodes of a network is a problem of fundamental importance in the study of neuronal and genetic networks. An underlying related problem is that of observability, i.e., identifying the conditions under which such a reconstruction is possible. In this paper we consider observability of complex dynamical networks,for which we aim at identifying both node and edge states. We use a graphical approach, which we apply to both the Node Inference Diagram (NID) and the Node Edge Inference Diagram (NEID) of the network. We investigate the relationship between the observability of the NID and that of the NEID network representations and conclude that the latter can be derived from the former, under general assumptions. We further consider the effects of graph symmetries on observability and we show how a minimal set of outputs can be selected to obtain observability in the presence of graph symmetries.',
	 'authors': u'Dionicio F. Rios, Afroza Shirin, Francesco Sorrentino,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5261',
	 'subjects': u'Pattern Formation and Solitons (nlin.PS)',
	 'title': u'\nThe Network Observability Problem: Detecting nodes and connections and  the role of graph symmetries',
	 'urllink': u'http://arxiv.org/abs/1308.5261'}
2015-03-24 00:19:09+0000 [xxu46_7] INFO: Crawled 96 pages (at 1 pages/min), scraped 89 items (at 1 items/min)
2015-03-24 00:19:29+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5215> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:19:29+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5215>
	{'abstract': u'In the present study, an advection-diffusion problem has been considered for the numerical solution. The continuum equation is discretized using both upwind and centered scheme. The linear system is solved using the ILU preconditioned BiCGSTAB method. Both Dirichlet and Neumann boundary condition has been considered. The obtained results have been compared for different cases.',
	 'authors': u'Dibakar Datta, Jacobo Carrasco Heres,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5215',
	 'subjects': u'Computational Physics (physics.comp-ph)',
	 'title': u'\nNumerical Solution of Advection-Diffusion Equation Using Preconditionar  as Incomplete LU Decomposition and the BiCGSTAB Aceleration Method',
	 'urllink': u'http://arxiv.org/abs/1308.5215'}
2015-03-24 00:20:09+0000 [xxu46_7] INFO: Crawled 97 pages (at 1 pages/min), scraped 90 items (at 1 items/min)
2015-03-24 00:21:09+0000 [xxu46_7] INFO: Crawled 97 pages (at 0 pages/min), scraped 90 items (at 0 items/min)
2015-03-24 00:21:25+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5208> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:21:25+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5208>
	{'abstract': u'In the present study the software CrackComput, based on the Xfem and Xcrack libraries has been used for three problems- to experiment on the convergence properties of the method applied to elasto-statics crack problems, comparison of stress intensity factors to simplified analytical results and study of the Brazilian fracture test. All the problems are treated in two dimensions under plane strain assumption and the material is supposed elastic and isotropic. For the first example, comparison for different parameter-enrichment type and radius, degree of polynomial has been performed. Second example convergence of SIF with the L/h ratio has been performed and compared with the analytical solution. Third example is the study of snapback phenomenon.',
	 'authors': u'Dibakar Datta,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5208',
	 'subjects': u'Computational Physics (physics.comp-ph)',
	 'title': u'\nIntroduction to eXtended Finite Element (XFEM) Method',
	 'urllink': u'http://arxiv.org/abs/1308.5208'}
2015-03-24 00:22:09+0000 [xxu46_7] INFO: Crawled 98 pages (at 1 pages/min), scraped 91 items (at 1 items/min)
2015-03-24 00:23:09+0000 [xxu46_7] INFO: Crawled 98 pages (at 0 pages/min), scraped 91 items (at 0 items/min)
2015-03-24 00:23:24+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5190> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:23:24+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5190>
	{'abstract': u'Quantifying regularities in behavioral dynamics is of crucial interest for understanding collective social events such as panics or political revolutions. With the widespread use of digital communication media it has become possible to study massive data streams of user-created content in which individuals express their sentiments, often towards a specific topic. Here we investigate messages from various online media created in response to major, collectively followed events such as sport tournaments, presidential elections or a large snow storm. We relate content length and message rate, and find a systematic correlation during events which can be described by a power law relation - the higher the excitation the shorter the messages. We show that on the one hand this effect can be observed in the behavior of most regular users, and on the other hand is accentuated by the engagement of additional user demographics who only post during phases of high collective activity. Further, we identify the distributions of content lengths as lognormals in line with statistical linguistics, and suggest a phenomenological law for the systematic dependence of the message rate to the lognormal mean parameter. Our measurements have practical implications for the design of micro-blogging and messaging services. In the case of the existing service Twitter, we show that the imposed limit of 140 characters per message currently leads to a substantial fraction of possibly dissatisfying to compose tweets that need to be truncated by their users.',
	 'authors': u'Michael Szell, Sebastian Grauwin, Carlo Ratti,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5190',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nContraction of online response to major events',
	 'urllink': u'http://arxiv.org/abs/1308.5190'}
2015-03-24 00:24:09+0000 [xxu46_7] INFO: Crawled 99 pages (at 1 pages/min), scraped 92 items (at 1 items/min)
2015-03-24 00:25:09+0000 [xxu46_7] INFO: Crawled 99 pages (at 0 pages/min), scraped 92 items (at 0 items/min)
2015-03-24 00:25:23+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5170> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:25:23+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5170>
	{'abstract': u'Partial 1-trees are undirected graphs of treewidth at most one. Similarly, partial 1-DAGs are directed graphs of KellyWidth at most two. It is well-known that an undirected graph is a partial 1-tree if and only if it has no K_3 minor. In this paper, we generalize this characterization to partial 1-DAGs. We show that partial 1-DAGs are characterized by three forbidden directed minors, K_3, N_4 and M_5.',
	 'authors': u'Shiva Kintali, Qiuyi Zhang,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5170',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nForbidden Directed Minors and Kelly-width',
	 'urllink': u'http://arxiv.org/abs/1308.5170'}
2015-03-24 00:26:09+0000 [xxu46_7] INFO: Crawled 100 pages (at 1 pages/min), scraped 93 items (at 1 items/min)
2015-03-24 00:27:09+0000 [xxu46_7] INFO: Crawled 100 pages (at 0 pages/min), scraped 93 items (at 0 items/min)
2015-03-24 00:27:20+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5169> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:27:20+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5169>
	{'abstract': u'We obtain closed form expressions for the expected conditional degree distribution and the joint degree distribution of the linear preferential attachment model for network growth in the steady state. We consider the multiple-destination preferential attachment growth model, where incoming nodes at each timestep attach to existing nodes, selected by degree-proportional probabilities. By the conditional degree distribution , we mean the degree distribution of nodes that are connected to a node of degree . By the joint degree distribution , we mean the proportion of links that connect nodes of degrees and . In addition to this growth model, we consider the shifted-linear preferential growth model and solve for the same quantities, as well as a closed form expression for its steady-state degree distribution.',
	 'authors': u'Babak Fotouhi, Michael G. Rabbat,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5169',
	 'subjects': u'Statistical Mechanics (cond-mat.stat-mech)',
	 'title': u'\nDegree Correlation in Scale-Free Graphs',
	 'urllink': u'http://arxiv.org/abs/1308.5169'}
2015-03-24 00:28:09+0000 [xxu46_7] INFO: Crawled 101 pages (at 1 pages/min), scraped 94 items (at 1 items/min)
2015-03-24 00:28:49+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5164> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:28:49+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5164>
	{'abstract': u'We confirm a conjecture of Littlewood: there exist seven infinite circular cylinders of unit radius which mutually touch each other. In fact, we exhibit two such sets of cylinders. Our approach is algebraic and uses symbolic and numerical computational techniques. We consider a system of polynomial equations describing the position of the axes of the cylinders in the 3 dimensional space. To have the same number of equations (namely 20) as the number of variables, the angle of the first two cylinders is fixed to 90 degrees, and a small family of direction vectors is left out of consideration. Homotopy continuation method has been applied to solve the system. The number of paths is about 121 billion, it is hopeless to follow them all. However, after checking 80 million paths, two solutions are found. Their validity, i.e., the existence of exact real solutions close to the approximate solutions at hand, was verified with the alphaCertified method as well as by the interval Krawczyk method.',
	 'authors': u'S\xe1ndor Boz\xf3ki, Tsung-Lin Lee, Lajos R\xf3nyai,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5164',
	 'subjects': u'Metric Geometry (math.MG)',
	 'title': u'\nSeven mutually touching infinite cylinders',
	 'urllink': u'http://arxiv.org/abs/1308.5164'}
2015-03-24 00:29:09+0000 [xxu46_7] INFO: Crawled 102 pages (at 1 pages/min), scraped 95 items (at 1 items/min)
2015-03-24 00:30:09+0000 [xxu46_7] INFO: Crawled 102 pages (at 0 pages/min), scraped 95 items (at 0 items/min)
2015-03-24 00:30:46+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5121> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:30:46+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5121>
	{'abstract': u'In this paper, we consider the voter model with popularity bias. The influence of each node on its neighbors depends on its degree. We find the consensus probabilities and expected consensus times for each of the states. We also find the fixation probability, which is the probability that a single node whose state differs from every other node imposes its state on the entire system. In addition, we find the expected fixation time. Then two extensions to the model are proposed and the motivations behind them are discussed. The first one is confidence, where in addition to the states of neighbors, nodes take their own state into account at each update. We repeat the calculations for the augmented model and investigate the effects of adding confidence to the model. The second proposed extension is irreversibility, where one of the states is given the property that once nodes adopt it, they cannot switch back. The dynamics of densities, fixation times and consensus times are obtained.',
	 'authors': u'Babak Fotouhi, Michael G. Rabbat,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5121',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nVoter Model with Arbitrary Degree Dependence: Clout, Confidence and  Irreversibility',
	 'urllink': u'http://arxiv.org/abs/1308.5121'}
2015-03-24 00:31:09+0000 [xxu46_7] INFO: Crawled 103 pages (at 1 pages/min), scraped 96 items (at 1 items/min)
2015-03-24 00:32:09+0000 [xxu46_7] INFO: Crawled 103 pages (at 0 pages/min), scraped 96 items (at 0 items/min)
2015-03-24 00:32:33+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5094> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:32:33+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5094>
	{'abstract': u'A fitness landscape is a genetic space -- with two genotypes adjacent if they differ in a single locus -- and a fitness function. Evolutionary dynamics produce a flow on this landscape from lower fitness to higher; reaching equilibrium only if a local fitness peak is found. I use computational complexity to question the common assumption that evolution on static fitness landscapes can quickly reach a local fitness peak. I do this by showing that the popular NK model of rugged fitness landscapes is PLS-complete for K &gt;= 2; the reduction from Weighted 2SAT is a bijection on adaptive walks, so there are NK fitness landscapes where every adaptive path from some vertices is of exponential length. Alternatively -- under the standard complexity theoretic assumption that there are problems in PLS not solvable in polynomial time -- this means that there are no evolutionary dynamics (known, or to be discovered, and not necessarily following adaptive paths) that can converge to a local fitness peak on all NK landscapes with K = 2. Applying results from the analysis of simplex algorithms, I show that there exist single-peaked landscapes with no reciprocal sign epistasis where the expected length of an adaptive path following strong selection weak mutation dynamics is even though an adaptive path to the optimum of length less than n is available from every vertex. The technical results are written to be accessible to mathematical biologists without a computer science background, and the biological literature is summarized for the convenience of non-biologists with the aim to open a constructive dialogue between the two disciplines.',
	 'authors': u'Artem Kaznatcheev,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5094',
	 'subjects': u'Populations and Evolution (q-bio.PE)',
	 'title': u'\nComplexity of evolutionary equilibria in static fitness landscapes',
	 'urllink': u'http://arxiv.org/abs/1308.5094'}
2015-03-24 00:33:09+0000 [xxu46_7] INFO: Crawled 104 pages (at 1 pages/min), scraped 97 items (at 1 items/min)
2015-03-24 00:33:49+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5045> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:33:49+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5045>
	{'abstract': u'We take a unified view of network coding and decentralized control. Precisely speaking, we consider both as linear time-invariant systems by appropriately restricting channels and coding schemes of network coding to be linear time-invariant, and the plant and controllers of decentralized control to be linear time-invariant as well. First, we apply linear system theory to network coding. This gives a novel way of converting an arbitrary relay network to an equivalent acyclic single-hop relay network, which we call Network Linearization. Based on network linearization, we prove that the fundamental design limit, mincut, is achievable by a linear time-invariant network-coding scheme regardless of the network topology. Then, we use the network-coding to view decentralized linear systems. We argue that linear time-invariant controllers in a decentralized linear system "communicate" via linear network coding to stabilize the plant. To justify this argument, we give an algorithm to "externalize" the implicit communication between the controllers that we believe must be occurring to stabilize the plant. Based on this, we show that the stabilizability condition for decentralized linear systems comes from an underlying communication limit, which can be described by the algebraic mincut-maxflow theorem. With this re-interpretation in hand, we also consider stabilizability over LTI networks to emphasize the connection with network coding. In particular, in broadcast and unicast problems, unintended messages at the receivers will be modeled as secrecy constraints.',
	 'authors': u'Se Yong Park, Anant Sahai,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5045',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nNetwork Coding meets Decentralized Control: Network Linearization and  Capacity-Stabilizablilty Equivalence',
	 'urllink': u'http://arxiv.org/abs/1308.5045'}
2015-03-24 00:34:09+0000 [xxu46_7] INFO: Crawled 105 pages (at 1 pages/min), scraped 98 items (at 1 items/min)
2015-03-24 00:34:58+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5010> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:34:58+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5010>
	{'abstract': u'Measuring public sentiment is a key task for researchers and policymakers alike. The explosion of available social media data allows for a more time-sensitive and geographically specific analysis than ever before. In this paper we analyze data from the micro-blogging site Twitter and generate a sentiment map of New York City. We develop a classifier specifically tuned for 140-character Twitter messages, or tweets, using key words, phrases and emoticons to determine the mood of each tweet. This method, combined with geotagging provided by users, enables us to gauge public sentiment on extremely fine-grained spatial and temporal scales. We find that public mood is generally highest in public parks and lowest at transportation hubs, and locate other areas of strong sentiment such as cemeteries, medical centers, a jail, and a sewage facility. Sentiment progressively improves with proximity to Times Square. Periodic patterns of sentiment fluctuate on both a daily and a weekly scale: more positive tweets are posted on weekends than on weekdays, with a daily peak in sentiment around midnight and a nadir between 9:00 a.m. and noon.',
	 'authors': u'Karla Z. Bertrand, Maya Bialik, Kawandeep Virdee, Andreas Gros, Yaneer Bar-Yam,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.5010',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nSentiment in New York City: A High Resolution Spatial and Temporal View',
	 'urllink': u'http://arxiv.org/abs/1308.5010'}
2015-03-24 00:35:09+0000 [xxu46_7] INFO: Crawled 106 pages (at 1 pages/min), scraped 99 items (at 1 items/min)
2015-03-24 00:36:09+0000 [xxu46_7] INFO: Crawled 106 pages (at 0 pages/min), scraped 99 items (at 0 items/min)
2015-03-24 00:36:26+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5000> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:36:26+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5000>
	{'abstract': u'We consider algorithms and recovery guarantees for the analysis sparse model in which the signal is sparse with respect to a highly coherent frame. We consider the use of a monotone version of the fast iterative shrinkage- thresholding algorithm (MFISTA) to solve the analysis sparse recovery problem. Since the proximal operator in MFISTA does not have a closed-form solution for the analysis model, it cannot be applied directly. Instead, we examine two alternatives based on smoothing and decomposition transformations that relax the original sparse recovery problem, and then implement MFISTA on the relaxed formulation. We refer to these two methods as smoothing-based and decomposition-based MFISTA. We analyze the convergence of both algorithms, and establish that smoothing- based MFISTA converges more rapidly when applied to general nonsmooth optimization problems. We then derive a performance bound on the reconstruction error using these techniques. The bound proves that our methods can recover a signal sparse in a redundant tight frame when the measurement matrix satisfies a properly adapted restricted isometry property. Numerical examples demonstrate the performance of our methods and show that smoothing-based MFISTA converges faster than the decomposition-based alternative in real applications, such as MRI image reconstruction.',
	 'authors': u'Zhao Tan, Yonina C. Eldar, Amir Beck, Arye Nehorai,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.5000',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nSmoothing and Decomposition for Analysis Sparse Recovery',
	 'urllink': u'http://arxiv.org/abs/1308.5000'}
2015-03-24 00:37:09+0000 [xxu46_7] INFO: Crawled 107 pages (at 1 pages/min), scraped 100 items (at 1 items/min)
2015-03-24 00:38:06+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4969> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:38:06+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4969>
	{'abstract': u'Recent research has identified interactions between networks as crucial for the outcome of evolutionary games taking place on them. While the consensus is that interdependence does promote cooperation by means of organizational complexity and enhanced reciprocity that is out of reach on isolated networks, we here address the question just how much interdependence there should be. Intuitively, one might assume the more the better. However, we show that in fact only an intermediate density of sufficiently strong interactions between networks warrants an optimal resolution of social dilemmas. This is due to an intricate interplay between the heterogeneity that causes an asymmetric strategy flow because of the additional links between the networks, and the independent formation of cooperative patterns on each individual network. Presented results are robust to variations of the strategy updating rule, the topology of interdependent networks, and the governing social dilemma, thus suggesting a high degree of universality.',
	 'authors': u'Zhen Wang, Attila Szolnoki, Matjaz Perc,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4969',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nOptimal interdependence between networks for the evolution of  cooperation',
	 'urllink': u'http://arxiv.org/abs/1308.4969'}
2015-03-24 00:38:09+0000 [xxu46_7] INFO: Crawled 108 pages (at 1 pages/min), scraped 101 items (at 1 items/min)
2015-03-24 00:39:09+0000 [xxu46_7] INFO: Crawled 108 pages (at 0 pages/min), scraped 101 items (at 0 items/min)
2015-03-24 00:39:42+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4880> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:39:42+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4880>
	{'abstract': u'This study extends the SIS epidemic model for single virus propagation over an arbitrary graph to an SI1SI2S epidemic model of two exclusive, competitive viruses over a two-layer network with generic structure, where network layers represent the distinct transmission routes of the viruses. We find analytical results determining extinction, mutual exclusion, and coexistence of the viruses by introducing the concepts of survival threshold and winning threshold. Furthermore, we show the possibility of coexistence in SIS-type competitive spreading over multilayer networks. Not only do we rigorously prove a region of coexistence, we quantitate it via interrelation of central nodes across the network layers. Little to no overlapping of layers central nodes is the key determinant of coexistence. Specifically, we show coexistence is impossible if network layers are identical yet possible if the network layers have distinct dominant eigenvectors and node degree vectors. For example, we show both analytically and numerically that positive correlation of network layers makes it difficult for a virus to survive while in a network with negatively correlated layers survival is easier but total removal of the other virus is more difficult. We believe our methodology has great potentials for application to broader classes of multi-pathogen spreading over multi-layer and interconnected networks.',
	 'authors': u'Faryad Darabi Sahneh, Caterina Scoglio,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4880',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nMay the Best Meme Win!: New Exploration of Competitive Epidemic  Spreading over Arbitrary Multi-Layer Networks',
	 'urllink': u'http://arxiv.org/abs/1308.4880'}
2015-03-24 00:40:09+0000 [xxu46_7] INFO: Crawled 109 pages (at 1 pages/min), scraped 102 items (at 1 items/min)
2015-03-24 00:41:09+0000 [xxu46_7] INFO: Crawled 109 pages (at 0 pages/min), scraped 102 items (at 0 items/min)
2015-03-24 00:41:32+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4847> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:41:32+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4847>
	{'abstract': u'A mass of traces of human activities show diverse dynamic patterns. In this paper, we comprehensively investigate the dynamic pattern of human attention defined by the quantity of interests on subdisciplines in an online academic communication forum. Both the expansion and exploration of human attention have a power-law scaling relation with browsing actions, of which the exponent is close to that in one-dimension random walk. Furthermore, the memory effect of human attention is characterized by the power-law distributions of both the return interval time and return interval steps, which is reinforced by studying the attention shift that monotonically increase with the interval order between pairs of continuously segmental sequences of expansion. At last, the observing dynamic pattern of human attention in the browsing process is analytically described by a dynamic model whose generic mechanism is analogy to that of human spatial mobility. Thus, our work not only enlarges the research scope of human dynamics, but also provides an insight to understand the relationship between the interest transitivity in online activities and human spatial mobility in real world.',
	 'authors': u'Zhi-Dan Zhao, Ya-Chun Gao, Shi-Min Cai,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4847',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nThe dynamic pattern of human attention',
	 'urllink': u'http://arxiv.org/abs/1308.4847'}
2015-03-24 00:42:09+0000 [xxu46_7] INFO: Crawled 110 pages (at 1 pages/min), scraped 103 items (at 1 items/min)
2015-03-24 00:42:56+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4803> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:42:56+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4803>
	{'abstract': u'We obtain a new bound of certain double multiplicative character sums. We use this bound together with some other previously obtained results to obtain new algorithms for finding roots of polynomials modulo a prime .',
	 'authors': u'Jean Bourgain, Sergei Konyagin, Igor Shparlinski,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4803',
	 'subjects': u'Number Theory (math.NT)',
	 'title': u'\nCharacter Sums and Deterministic Polynomial Root Finding in Finite  Fields',
	 'urllink': u'http://arxiv.org/abs/1308.4803'}
2015-03-24 00:43:09+0000 [xxu46_7] INFO: Crawled 111 pages (at 1 pages/min), scraped 104 items (at 1 items/min)
2015-03-24 00:44:09+0000 [xxu46_7] INFO: Crawled 111 pages (at 0 pages/min), scraped 104 items (at 0 items/min)
2015-03-24 00:44:33+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4718> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:44:33+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4718>
	{'abstract': u'This paper is concerned with the question of reconstructing a vector in a finite-dimensional real Hilbert space when only the magnitudes of the coefficients of the vector under a redundant linear map are known. We analyze various Lipschitz bounds of the nonlinear analysis map and we establish theoretical performance bounds of any reconstruction algorithm. We show that robust and stable reconstruction requires additional redundancy than the critical threshold.',
	 'authors': u'Radu Balan, Yang Wang,',
	 'category': u'Computer Science ',
	 'date': '2013-8-21',
	 'pdflink': u'http://arxiv.org/pdf/1308.4718',
	 'subjects': u'Functional Analysis (math.FA)',
	 'title': u'\nInvertibility and Robustness of Phaseless Reconstruction',
	 'urllink': u'http://arxiv.org/abs/1308.4718'}
2015-03-24 00:45:09+0000 [xxu46_7] INFO: Crawled 112 pages (at 1 pages/min), scraped 105 items (at 1 items/min)
2015-03-24 00:46:09+0000 [xxu46_7] INFO: Crawled 112 pages (at 0 pages/min), scraped 105 items (at 0 items/min)
2015-03-24 00:46:17+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4715> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:46:17+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4715>
	{'abstract': u"We consider a variation of cop vs. robber on graph in which the robber is not restricted by the graph edges; instead, he picks a time-independent probability distribution on and moves according to this fixed distribution. The cop moves from vertex to adjacent vertex with the goal of minimizing expected capture time. Players move simultaneously. We show that when the gambler's distribution is known, the expected capture time (with best play) on any connected -vertex graph is exactly . We also give bounds on the (generally greater) expected capture time when the gambler's distribution is unknown to the cop.",
	 'authors': u'Natasha Komarov, Peter Winkler,',
	 'category': u'Computer Science ',
	 'date': '2013-8-21',
	 'pdflink': u'http://arxiv.org/pdf/1308.4715',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nCops vs. Gambler',
	 'urllink': u'http://arxiv.org/abs/1308.4715'}
2015-03-24 00:47:09+0000 [xxu46_7] INFO: Crawled 113 pages (at 1 pages/min), scraped 106 items (at 1 items/min)
2015-03-24 00:47:59+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4577> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:47:59+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4577>
	{'abstract': u"This paper re-introduces the network reliability polynomial - introduced by Moore and Shannon in 1956 -- for studying the effect of network structure on the spread of diseases. We exhibit a representation of the polynomial that is well-suited for estimation by distributed simulation. We describe a collection of graphs derived from Erd Hs-R 'enyi and scale-free-like random graphs in which we have manipulated assortativity-by-degree and the number of triangles. We evaluate the network reliability for all these graphs under a reliability rule that is related to the expected size of a connected component. Through these extensive simulations, we show that for positively or neutrally assortative graphs, swapping edges to increase the number of triangles does not increase the network reliability. Also, positively assortative graphs are more reliable than neutral or disassortative graphs with the same number of edges. Moreover, we show the combined effect of both assortativity-by-degree and the presence of triangles on the critical point and the size of the smallest subgraph that is reliable.",
	 'authors': u'Mina Youssef, Yasamin Khorramzadeh, Stephen Eubank,',
	 'category': u'Computer Science ',
	 'date': '2013-8-21',
	 'pdflink': u'http://arxiv.org/pdf/1308.4577',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nNetwork Reliability: The effect of local network structure on diffusive  processes',
	 'urllink': u'http://arxiv.org/abs/1308.4577'}
2015-03-24 00:48:09+0000 [xxu46_7] INFO: Crawled 114 pages (at 1 pages/min), scraped 107 items (at 1 items/min)
2015-03-24 00:49:09+0000 [xxu46_7] INFO: Crawled 114 pages (at 0 pages/min), scraped 107 items (at 0 items/min)
2015-03-24 00:49:54+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4431> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:49:54+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4431>
	{'abstract': u'In this note we prove that K_ is interval edge-colorable if and only if gcd(m+1,n+1)=1. It settles in the affirmative a conjecture of Petrosyan.',
	 'authors': u'Andrzej Grzesik, Hrant Khachatrian,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/pdf/1308.4431',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nInterval edge-colorings of K_{1,m,n}',
	 'urllink': u'http://arxiv.org/abs/1308.4431'}
2015-03-24 00:50:09+0000 [xxu46_7] INFO: Crawled 115 pages (at 1 pages/min), scraped 108 items (at 1 items/min)
2015-03-24 00:51:05+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4398> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:51:05+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4398>
	{'abstract': u"Containing the spreading of crime is a major challenge for society. Yet, since thousands of years, no effective strategy has been found to overcome crime. To the contrary, empirical evidence shows that crime is recurrent, a fact that is not captured well by rational choice theories of crime. According to these, strong enough punishment should prevent crime from happening. To gain a better understanding of the relationship between crime and punishment, we consider that the latter requires prior discovery of illicit behavior and study a spatial version of the inspection game. Simulations reveal the spontaneous emergence of cyclic dominance between ''criminals'', ''inspectors'', and ''ordinary people'' as a consequence of spatial interactions. Such cycles dominate the evolutionary process, in particular when the temptation to commit crime or the cost of inspection are low or moderate. Yet, there are also critical parameter values beyond which cycles cease to exist and the population is dominated either by a stable mixture of criminals and inspectors or one of these two strategies alone. Both continuous and discontinuous phase transitions to different final states are possible, indicating that successful strategies to contain crime can be very much counter-intuitive and complex. Our results demonstrate that spatial interactions are crucial for the evolutionary outcome of the inspection game, and they also reveal why criminal behavior is likely to be recurrent rather than evolving towards an equilibrium with monotonous parameter dependencies.",
	 'authors': u'Matjaz Perc, Karsten Donnay, Dirk Helbing,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/pdf/1308.4398',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nUnderstanding recurrent crime as system-immanent collective behavior',
	 'urllink': u'http://arxiv.org/abs/1308.4398'}
2015-03-24 00:51:09+0000 [xxu46_7] INFO: Crawled 116 pages (at 1 pages/min), scraped 109 items (at 1 items/min)
2015-03-24 00:52:09+0000 [xxu46_7] INFO: Crawled 116 pages (at 0 pages/min), scraped 109 items (at 0 items/min)
2015-03-24 00:53:06+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4321> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:53:06+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4321>
	{'abstract': u'The obstacle number is a new graph parameter introduced by Alpert, Koch, and Laison (2010). Mukkamala etal (2012) show that there exist graphs with n vertices having obstacle number in Omega(n/ log n). In this note, we up this lower bound to Omega(n/( log log n)^2. Our proof makes use of an upper bound of Mukkamala etal on the number of graphs having obstacle number at most h in such a way that any subsequent improvements to their upper bound will improve our lower bound.',
	 'authors': u'Vida Dujmovi\u0107, Pat Morin,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/pdf/1308.4321',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nOn Obstacle Numbers',
	 'urllink': u'http://arxiv.org/abs/1308.4321'}
2015-03-24 00:53:09+0000 [xxu46_7] INFO: Crawled 117 pages (at 1 pages/min), scraped 110 items (at 1 items/min)
2015-03-24 00:54:09+0000 [xxu46_7] INFO: Crawled 117 pages (at 0 pages/min), scraped 110 items (at 0 items/min)
2015-03-24 00:54:45+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4273> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:54:45+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4273>
	{'abstract': u'Compressive sensing (CS) can effectively recover a signal when it is sparse in some discrete atoms. However, in some applications, signals are sparse in a continuous parameter space, e.g., frequency space, rather than discrete atoms. Usually, we divide the continuous parameter into finite discrete grid points and build a dictionary from these grid points. However, the actual targets may not exactly lie on the grid points no matter how densely the parameter is grided, which introduces mismatch between the predefined dictionary and the actual one. In this article, a novel method, namely adaptive matching pursuit with constrained total least squares (AMP-CTLS), is proposed to find actual atoms even if they are not included in the initial dictionary. In AMP-CTLS, the grid and the dictionary are adaptively updated to better agree with measurements. The convergence of the algorithm is discussed, and numerical experiments demonstrate the advantages of AMP-CTLS.',
	 'authors': u'Tianyao Huang, Yimin Liu, Huadong Meng, Xiqin Wang,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/pdf/1308.4273',
	 'subjects': u'Applications (stat.AP)',
	 'title': u'\nAdaptive matching pursuit for off-grid compressed sensing',
	 'urllink': u'http://arxiv.org/abs/1308.4273'}
2015-03-24 00:55:09+0000 [xxu46_7] INFO: Crawled 118 pages (at 1 pages/min), scraped 111 items (at 1 items/min)
2015-03-24 00:56:09+0000 [xxu46_7] INFO: Crawled 118 pages (at 0 pages/min), scraped 111 items (at 0 items/min)
2015-03-24 00:56:29+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4260> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:56:29+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4260>
	{'abstract': u'Given a set of words, one associates to each word in an undirected graph, called its extension graph, and which describes the possible extensions of on the left and on the right. We investigate the family of sets of words defined by the property of the extension graph of each word in the set to be acyclic or connected or a tree. We prove that in a uniformly recurrent tree set, the sets of first return words are bases of the free group on the alphabet. Concerning acyclic sets, we prove as a main result that a set is acyclic if and only if any bifix code included in is a basis of the subgroup that it generates.',
	 'authors': u'Valerie Berth\xe9, Clelia De Felice, Francesco Dolce, Julien Leroy, Dominique Perrin, Christophe Reutenauer, Giuseppina Rindone,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/pdf/1308.4260',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nAcyclic, connected and tree sets',
	 'urllink': u'http://arxiv.org/abs/1308.4260'}
2015-03-24 00:57:09+0000 [xxu46_7] INFO: Crawled 119 pages (at 1 pages/min), scraped 112 items (at 1 items/min)
2015-03-24 00:58:02+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4259> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:58:02+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4259>
	{'abstract': u"Empirical data on early network history are rare. Students beginning their studies at a university with no or few prior connections to each other offer a unique opportunity to investigate the formation and early development of social networks. During a nine week introductory physics course, first year physics students were asked to identify those with whom they communicated about problem solving in physics during the preceding week. We use these students' self reports to produce time dependent student interaction networks. These networks have also been investigated to elucidate possible effects of gender and students' final course grade. Changes in the weekly number of links are investigated to show that while roughly half of all links change from week to week, students also reestablish a growing number of links as they progress through their first weeks of study. To investigate how students group, Infomap is used to establish groups. Further, student group flow is examined using alluvial diagrams, showing that many students jump between group each week., Finally, a segregation measure is developed which shows that students structure themselves according to gender and laboratory exercise groups and not according to end-of-course grade. The results show the behavior of an early social-educational network, and may have implications for theoretical network models as well as for physics education.",
	 'authors': u'Jesper Bruun, Ian G. Bearden,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/pdf/1308.4259',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nTime Development of Early Social Networks: Link analysis and group  dynamics',
	 'urllink': u'http://arxiv.org/abs/1308.4259'}
2015-03-24 00:58:09+0000 [xxu46_7] INFO: Crawled 120 pages (at 1 pages/min), scraped 113 items (at 1 items/min)
2015-03-24 00:59:09+0000 [xxu46_7] INFO: Crawled 120 pages (at 0 pages/min), scraped 113 items (at 0 items/min)
2015-03-24 00:59:38+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4227> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 00:59:38+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4227>
	{'abstract': u"In this paper, we develop some matrix Poisson's equations satisfied by the mean and variance of the mixing time in an irreducible positive-recurrent discrete-time Markov chain with infinitely-many levels, and provide a computational framework for the solution to the matrix Poisson's equations by means of the UL-type of -factorization as well as the generalized inverses. In an important special case: the level-dependent QBD processes, we provide a detailed computation for the mean and variance of the mixing time. Based on this, we give new highlight on computation of the mixing time in the block-structured Markov chains with infinitely-many levels through the matrix-analytic method.",
	 'authors': u'Quan-Lin Li, Jing Cao,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/pdf/1308.4227',
	 'subjects': u'Probability (math.PR)',
	 'title': u'\nA Computational Framework for the Mixing Times in the QBD Processes with  Infinitely-Many Levels',
	 'urllink': u'http://arxiv.org/abs/1308.4227'}
2015-03-24 01:00:09+0000 [xxu46_7] INFO: Crawled 121 pages (at 1 pages/min), scraped 114 items (at 1 items/min)
2015-03-24 01:01:09+0000 [xxu46_7] INFO: Crawled 121 pages (at 0 pages/min), scraped 114 items (at 0 items/min)
2015-03-24 01:01:37+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4216> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:01:37+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4216>
	{'abstract': u'Many real-world networks depend on other networks, often in non-trivial ways, to maintain their functionality. These interdependent "networks of networks" are often extremely fragile. When a fraction of nodes in one network randomly fails, the damage propagates to nodes in networks that are interdependent and a dynamic failure cascade occurs that affects the entire system. We present dynamic equations for two interdependent networks that allow us to reproduce the failure cascade for an arbitrary pattern of interdependency. We study the "rich club" effect found in many real interdependent network systems in which the high-degree nodes are extremely interdependent, correlating a fraction of the higher degree nodes on each network. We find a rich phase diagram in the plane , with a triple point reminiscent of the triple point of liquids that separates a non-functional phase from two functional phases.',
	 'authors': u'L.D. Valdez, P.A. Macri, H.E. Stanley, L.A. Braunstein,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/pdf/1308.4216',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nTriple Point in Correlated Interdependent Networks',
	 'urllink': u'http://arxiv.org/abs/1308.4216'}
2015-03-24 01:02:09+0000 [xxu46_7] INFO: Crawled 122 pages (at 1 pages/min), scraped 115 items (at 1 items/min)
2015-03-24 01:02:35+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4214> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:02:35+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4214>
	{'abstract': u"Pylearn2 is a machine learning research library. This does not just mean that it is a collection of machine learning algorithms that share a common API; it means that it has been designed for flexibility and extensibility in order to facilitate research projects that involve new or unusual use cases. In this paper we give a brief history of the library, an overview of its basic philosophy, a summary of the library's architecture, and a description of how the Pylearn2 community functions socially.",
	 'authors': u'Ian J. Goodfellow, David Warde-Farley, Pascal Lamblin, Vincent Dumoulin, Mehdi Mirza, Razvan Pascanu, James Bergstra, Fr\xe9d\xe9ric Bastien, Yoshua Bengio,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/pdf/1308.4214',
	 'subjects': u'Machine Learning (stat.ML)',
	 'title': u'\nPylearn2: a machine learning research library',
	 'urllink': u'http://arxiv.org/abs/1308.4214'}
2015-03-24 01:03:09+0000 [xxu46_7] INFO: Crawled 123 pages (at 1 pages/min), scraped 116 items (at 1 items/min)
2015-03-24 01:03:51+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4206> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:03:51+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4206>
	{'abstract': u'Motivated by the analysis of nonnegative data objects, a novel Nested Nonnegative Cone Analysis (NNCA) approach is proposed to overcome some drawbacks of existing methods. The application of traditional PCA/SVD method to nonnegative data often cause the approximation matrix leave the nonnegative cone, which leads to non-interpretable and sometimes nonsensical results. The nonnegative matrix factorization (NMF) approach overcomes this issue, however the NMF approximation matrices suffer several drawbacks: 1) the factorization may not be unique, 2) the resulting approximation matrix at a specific rank may not be unique, and 3) the subspaces spanned by the approximation matrices at different ranks may not be nested. These drawbacks will cause troubles in determining the number of components and in multi-scale (in ranks) interpretability. The NNCA approach proposed in this paper naturally generates a nested structure, and is shown to be unique at each rank. Simulations are used in this paper to illustrate the drawbacks of the traditional methods, and the usefulness of the NNCA method.',
	 'authors': u'Lingsong Zhang, J. S. Marron, Shu Lu,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/pdf/1308.4206',
	 'subjects': u'Methodology (stat.ME)',
	 'title': u'\nNested Nonnegative Cone Analysis',
	 'urllink': u'http://arxiv.org/abs/1308.4206'}
2015-03-24 01:04:09+0000 [xxu46_7] INFO: Crawled 124 pages (at 1 pages/min), scraped 117 items (at 1 items/min)
2015-03-24 01:04:42+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4067> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:04:42+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4067>
	{'abstract': u"The S-metric has grown popular in network studies, as a measure of ``scale-freeness'' restricted to the collection G(D) of connected graphs with a common degree sequence D=(d_1, ldots,d_n). The calculation of S depends on the maximum possible degree assortativity r among graphs in G(D). The original method involves a heuristic construction of a maximally assortative graph g*. The approximation by Beichl and Cloteaux involves constructing a possibly disconnected graph g' with r(g') &gt;= r(g*) and requires O(n^2) tests for the graphicality of a degree sequence. The present paper uses the Tripathi-Vijay test to streamline this approximation, and thereby to investigate two collections of graphs: Barabasi-Albert trees and coauthorship graphs of mathematical sciences researchers. Long-term trends in the coauthorship graphs are discussed, and contextualized by insights derived from the BA trees. It is known that greater degree-based preferential attachment produces greater variance in degree sequences, and these trees exhibited assortativities restricted to a narrow band. In contrast, variance in degree rose over time in the coauthorship graphs in spite of weakening degree-based preferential attachment. These observations and their implications are discussed and avenues of future work are suggested.",
	 'authors': u'Jason Cory Brunson,',
	 'category': u'Computer Science ',
	 'date': '2013-8-19',
	 'pdflink': u'http://arxiv.org/pdf/1308.4067',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nThe S-metric, the Beichl-Cloteaux approximation, and preferential  attachment',
	 'urllink': u'http://arxiv.org/abs/1308.4067'}
2015-03-24 01:05:09+0000 [xxu46_7] INFO: Crawled 125 pages (at 1 pages/min), scraped 118 items (at 1 items/min)
2015-03-24 01:06:09+0000 [xxu46_7] INFO: Crawled 125 pages (at 0 pages/min), scraped 118 items (at 0 items/min)
2015-03-24 01:06:41+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4017> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:06:41+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4017>
	{'abstract': u'This paper presents a study in task-oriented approach to stroke rehabilitation by controlling a haptic device via near-infrared spectroscopy-based brain-computer interface (BCI). The task is to command the haptic device to move in opposing directions of leftward and rightward movement. Our study consists of data acquisition, signal preprocessing, and classification. In data acquisition, we conduct experiments based on two different mental tasks: one on pure motor imagery, and another on combined motor imagery and action observation. The experiments were conducted in both offline and online modes. In the signal preprocessing, we use localization method to eliminate channels that are irrelevant to the mental task, as well as perform feature extraction for subsequent classification. We propose multiple support vector machine classifiers with a majority-voting scheme for improved classification results. And lastly, we present test results to demonstrate the efficacy of our proposed approach to possible stroke rehabilitation practice.',
	 'authors': u'Berdakh Abibullaev, Jinung An, Seung-Hyun Lee, Jeon-Il Moon,',
	 'category': u'Computer Science ',
	 'date': '2013-8-19',
	 'pdflink': u'http://arxiv.org/pdf/1308.4017',
	 'subjects': u'Machine Learning (stat.ML)',
	 'title': u'\nA Study on Stroke Rehabilitation through Task-Oriented Control of a  Haptic Device via Near-Infrared Spectroscopy-Based BCI',
	 'urllink': u'http://arxiv.org/abs/1308.4017'}
2015-03-24 01:07:09+0000 [xxu46_7] INFO: Crawled 126 pages (at 1 pages/min), scraped 119 items (at 1 items/min)
2015-03-24 01:08:09+0000 [xxu46_7] INFO: Crawled 126 pages (at 0 pages/min), scraped 119 items (at 0 items/min)
2015-03-24 01:08:33+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4014> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:08:33+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4014>
	{'abstract': u'Nowadays, the emergence of online services provides various multi-relation information to support the comprehensive understanding of the epidemic spreading process. In this Letter, we consider the edge weights to represent such multi-role relations. In addition, we perform detailed analysis of two representative metrics, outbreak threshold and epidemic prevalence, on SIS and SIR models. Both theoretical and simulation results find good agreements with each other. Furthermore, experiments show that, on fully mixed networks, the weight distribution on edges would not affect the epidemic results once the average weight of whole network is fixed. This work may shed some light on the in-depth understanding of epidemic spreading on multi-relation and weighted networks.',
	 'authors': u'Ye Sun, Chuang Liu, Chu-Xu Zhang, Zi-Ke Zhang,',
	 'category': u'Computer Science ',
	 'date': '2013-8-19',
	 'pdflink': u'http://arxiv.org/pdf/1308.4014',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nEpidemic Spreading on Weighted Complex Networks',
	 'urllink': u'http://arxiv.org/abs/1308.4014'}
2015-03-24 01:09:09+0000 [xxu46_7] INFO: Crawled 127 pages (at 1 pages/min), scraped 120 items (at 1 items/min)
2015-03-24 01:10:09+0000 [xxu46_7] INFO: Crawled 127 pages (at 0 pages/min), scraped 120 items (at 0 items/min)
2015-03-24 01:10:26+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4004> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:10:26+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4004>
	{'abstract': u'The classical k-means algorithm for paritioning n points in R^d into k subsets is one of the most popular and widely spread clustering methods in scientific and business applications. The present paper gives a generalization that is capable of handling weighted point sets and prescribed lower and upper bounds on the cluster sizes. The new algorithm replaces the assignment step of k-means by the computation of a weight-balanced least-squares assignment. This is modelled as a linear program over a weight-balanced partition polytope whose optimal vertices correspond to clusterings that allow strongly feasible power diagrams. We use this correspondence to derive a worst-case upper bound n^O(dk) for the number of operations. This is similar to the known upper bound for k-means, polynomial for fixed k and d, and in view of the known complexity results for k-means, essentially the best one can expect. Further, we show the kernelizability of our approach.',
	 'authors': u'Steffen Borgwardt, Andreas Brieden, Peter Gritzmann,',
	 'category': u'Computer Science ',
	 'date': '2013-8-19',
	 'pdflink': u'http://arxiv.org/pdf/1308.4004',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nA balanced k-means algorithm for weighted point sets',
	 'urllink': u'http://arxiv.org/abs/1308.4004'}
2015-03-24 01:11:09+0000 [xxu46_7] INFO: Crawled 128 pages (at 1 pages/min), scraped 121 items (at 1 items/min)
2015-03-24 01:12:09+0000 [xxu46_7] INFO: Crawled 128 pages (at 0 pages/min), scraped 121 items (at 0 items/min)
2015-03-24 01:12:19+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4002> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:12:19+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4002>
	{'abstract': u'People are often divided into conformists and contrarians, the former tending to align to the majority opinion in their neighborhood and the latter tending to disagree with that majority. In practice, however, the contrarian tendency is rarely followed when there is an overwhelming majority with a given opinion, which denotes a social norm. Such reasonable contrarian behavior is often considered a mark of independent thought, and can be a useful strategy in financial markets. We present the opinion dynamics of a society of reasonable contrarian agents. The model is a cellular automaton of Ising type, with antiferromagnetic pair interactions modeling contrarianism and plaquette terms modeling social norms. We introduce the entropy of the collective variable as a way of comparing deterministic (mean-field) and probabilistic (simulations) bifurcation diagrams. In the mean field approximation the model exhibits bifurcations and a chaotic phase, interpreted as coherent oscillations of the whole society. However, in a one-dimensional spatial arrangement one observes incoherent oscillations and a constant average. In simulations on Watts-Strogatz networks with a small-world effect the mean field behavior is recovered, with a bifurcation diagram that resembles the mean-field one, but using the rewiring probability as the control parameter. Similar bifurcation diagrams are found for scale free networks, and we are able to compute an effective connectivity for such networks.',
	 'authors': u'Franco Bagnoli, Raul Rechtman,',
	 'category': u'Computer Science ',
	 'date': '2013-8-19',
	 'pdflink': u'http://arxiv.org/pdf/1308.4002',
	 'subjects': u'Cellular Automata and Lattice Gases (nlin.CG)',
	 'title': u'\nTopological bifurcations in a model society of reasonable contrarians',
	 'urllink': u'http://arxiv.org/abs/1308.4002'}
2015-03-24 01:13:09+0000 [xxu46_7] INFO: Crawled 129 pages (at 1 pages/min), scraped 122 items (at 1 items/min)
2015-03-24 01:13:28+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.3987> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:13:28+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.3987>
	{'abstract': u"In this note, we prove that all cop-win graphs G in the game in which the robber and the cop move at different speeds s and s' with s'&lt;s, are delta-hyperbolic with delta=O(s^2). We also show that the dependency between delta and s is linear if s-s'= Omega(s) and G obeys a slightly stronger condition. This solves an open question from the paper (J. Chalopin et al., Cop and robber games when the robber can hide and ride, SIAM J. Discr. Math. 25 (2011) 333-359). Since any delta-hyperbolic graph is cop-win for s=2r and s'=r+2 delta for any r&gt;0, this establishes a new - game-theoretical - characterization of Gromov hyperbolicity. We also show that for weakly modular graphs the dependency between delta and s is linear for any s'&lt;s. Using these results, we describe a simple constant-factor approximation of the hyperbolicity delta of a graph on n vertices in O(n^2) time when the graph is given by its distance-matrix.",
	 'authors': u'J\xe9r\xe9mie Chalopin, Victor Chepoi, Panos Papasoglu, Timoth\xe9e Pecatte,',
	 'category': u'Computer Science ',
	 'date': '2013-8-19',
	 'pdflink': u'http://arxiv.org/pdf/1308.3987',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nCop and robber game and hyperbolicity',
	 'urllink': u'http://arxiv.org/abs/1308.3987'}
2015-03-24 01:14:09+0000 [xxu46_7] INFO: Crawled 130 pages (at 1 pages/min), scraped 123 items (at 1 items/min)
2015-03-24 01:14:53+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.3898> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:14:53+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.3898>
	{'abstract': u'Nature-inspired metaheuristic algorithms, especially those based on swarm intelligence, have attracted much attention in the last ten years. Firefly algorithm appeared in about five years ago, its literature has expanded dramatically with diverse applications. In this paper, we will briefly review the fundamentals of firefly algorithm together with a selection of recent publications. Then, we discuss the optimality associated with balancing exploration and exploitation, which is essential for all metaheuristic algorithms. By comparing with intermittent search strategy, we conclude that metaheuristics such as firefly algorithm are better than the optimal intermittent search strategy. We also analyse algorithms and their implications for higher-dimensional optimization problems.',
	 'authors': u'Xin-She Yang, Xingshi He,',
	 'category': u'Computer Science ',
	 'date': '2013-8-18',
	 'pdflink': u'http://arxiv.org/pdf/1308.3898',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nFirefly Algorithm: Recent Advances and Applications',
	 'urllink': u'http://arxiv.org/abs/1308.3898'}
2015-03-24 01:15:09+0000 [xxu46_7] INFO: Crawled 131 pages (at 1 pages/min), scraped 124 items (at 1 items/min)
2015-03-24 01:16:09+0000 [xxu46_7] INFO: Crawled 131 pages (at 0 pages/min), scraped 124 items (at 0 items/min)
2015-03-24 01:16:28+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.3892> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:16:28+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.3892>
	{'abstract': u'The possibility to analyze everyday monetary transactions is limited by the scarcity of available data, as this kind of information is usually considered highly sensitive. Present econophysics models are usually employed on presumed random networks of interacting agents, and only macroscopic properties (e.g. the resulting wealth distribution) are compared to real-world data. In this paper, we analyze BitCoin, which is a novel digital currency system, where the complete list of transactions is publicly available. Using this dataset, we reconstruct the network of transactions, and extract the time and amount of each payment. We analyze the structure of the transaction network by measuring network characteristics over time, such as the degree distribution, degree correlations and clustering. We find that linear preferential attachment drives the growth of the network. We also study the dynamics taking place on the transaction network, i.e. the flow of money. We measure temporal patterns and the wealth accumulation. Investigating the microscopic statistics of money movement, we find that sublinear preferential attachment governs the evolution of the wealth distribution. We report a scaling relation between the degree and wealth associated to individual nodes.',
	 'authors': u'D\xe1niel Kondor, M\xe1rton P\xf3sfai, Istv\xe1n Csabai, G\xe1bor Vattay,',
	 'category': u'Computer Science ',
	 'date': '2013-8-18',
	 'pdflink': u'http://arxiv.org/pdf/1308.3892',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nDo the rich get richer? An empirical analysis of the BitCoin transaction  network',
	 'urllink': u'http://arxiv.org/abs/1308.3892'}
2015-03-24 01:17:09+0000 [xxu46_7] INFO: Crawled 132 pages (at 1 pages/min), scraped 125 items (at 1 items/min)
2015-03-24 01:18:05+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.3860> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:18:05+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.3860>
	{'abstract': u'Finding the rank of a tensor is a problem that has many applications. Unfortunately it is often very difficult to determine the rank of a given tensor. Inspired by the heuristics of convex relaxation, we consider the nuclear norm instead of the rank of a tensor. We determine the nuclear norm of various tensors of interest. Along the way, we also do a systematic study various measures of orthogonality in tensor product spaces and we give a new generalization of the Singular Value Decomposition to higher order tensors.',
	 'authors': u'Harm Derksen,',
	 'category': u'Computer Science ',
	 'date': '2013-8-18',
	 'pdflink': u'http://arxiv.org/pdf/1308.3860',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nOn the Nuclear Norm and the Singular Value Decomposition of Tensors',
	 'urllink': u'http://arxiv.org/abs/1308.3860'}
2015-03-24 01:18:09+0000 [xxu46_7] INFO: Crawled 133 pages (at 1 pages/min), scraped 126 items (at 1 items/min)
2015-03-24 01:19:09+0000 [xxu46_7] INFO: Crawled 133 pages (at 0 pages/min), scraped 126 items (at 0 items/min)
2015-03-24 01:19:31+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.3740> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:19:31+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.3740>
	{'abstract': u"Interestingness measures provide information that can be used to prune or select association rules. A given value of an interestingness measure is often interpreted relative to the overall range of the values that the interestingness measure can take. However, properties of individual association rules restrict the values an interestingness measure can achieve. An interesting measure can be standardized to take this into account, but this has only been done for one interestingness measure to date, i.e., the lift. Standardization provides greater insight than the raw value and may even alter researchers' perception of the data. We derive standardized analogues of three interestingness measures and use real and simulated data to compare them to their raw versions, each other, and the standardized lift.",
	 'authors': u'Mateen Shaikh, Paul D. McNicholas, M. Luiza Antonie, T. Brendan Murphy,',
	 'category': u'Computer Science ',
	 'date': '2013-8-16',
	 'pdflink': u'http://arxiv.org/pdf/1308.3740',
	 'subjects': u'Applications (stat.AP)',
	 'title': u'\nStandardizing Interestingness Measures for Association Rules',
	 'urllink': u'http://arxiv.org/abs/1308.3740'}
2015-03-24 01:20:09+0000 [xxu46_7] INFO: Crawled 134 pages (at 1 pages/min), scraped 127 items (at 1 items/min)
2015-03-24 01:20:44+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.3700> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:20:44+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.3700>
	{'abstract': u'RNA-seq has rapidly become the de facto technique to measure gene expression. However, the time required for analysis has not kept up with the pace of data generation. Here we introduce Sailfish, a novel computational method for quantifying the abundance of previously annotated RNA isoforms from RNA-seq data. Sailfish entirely avoids mapping reads, which is a time-consuming step in all current methods. Sailfish provides quantification estimates much faster than existing approaches (typically 20-times faster) without loss of accuracy.',
	 'authors': u'Rob Patro, Stephen M. Mount, Carl Kingsford,',
	 'category': u'Computer Science ',
	 'date': '2013-8-16',
	 'pdflink': u'http://arxiv.org/pdf/1308.3700',
	 'subjects': u'Genomics (q-bio.GN)',
	 'title': u'\nSailfish: Alignment-free Isoform Quantification from RNA-seq Reads using  Lightweight Algorithms',
	 'urllink': u'http://arxiv.org/abs/1308.3700'}
2015-03-24 01:21:09+0000 [xxu46_7] INFO: Crawled 135 pages (at 1 pages/min), scraped 128 items (at 1 items/min)
2015-03-24 01:22:09+0000 [xxu46_7] INFO: Crawled 135 pages (at 0 pages/min), scraped 128 items (at 0 items/min)
2015-03-24 01:22:25+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.3616> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:22:25+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.3616>
	{'abstract': u"In this paper, new techniques that allow conditional entropy to estimate the combinatorics of symbols are applied to animal communication studies to estimate the communication's repertoire size. By using the conditional entropy estimates at multiple orders, the paper estimates the total repertoire sizes for animal communication across bottlenose dolphins, humpback whales, and several species of birds for N-grams length one to three. In addition to discussing the impact of this method on studies of animal communication complexity, the reliability of these estimates is compared to other methods through simulation. While entropy does undercount the total repertoire size due to rare N-grams, it gives a more accurate picture of the most frequently used repertoire than just repertoire size alone.",
	 'authors': u'Reginald D. Smith,',
	 'category': u'Computer Science ',
	 'date': '2013-8-15',
	 'pdflink': u'http://arxiv.org/pdf/1308.3616',
	 'subjects': u'Populations and Evolution (q-bio.PE)',
	 'title': u'\nComplexity in animal communication: Estimating the size of N-Gram  structures',
	 'urllink': u'http://arxiv.org/abs/1308.3616'}
2015-03-24 01:23:09+0000 [xxu46_7] INFO: Crawled 136 pages (at 1 pages/min), scraped 129 items (at 1 items/min)
2015-03-24 01:24:07+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.3600> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:24:07+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.3600>
	{'abstract': u'Respondent driven sampling (RDS) is a method often used to estimate population properties (e.g. sexual risk behavior) in hard-to-reach populations. It combines an effective modified snowball sampling methodology with an estimation procedure that yields unbiased population estimates under the assumption that the sampling process behaves like a random walk on the social network of the population. Current RDS estimation methodology assumes that the social network is undirected, i.e. that all edges are reciprocal. However, empirical social networks in general also have non-reciprocated edges. To account for this fact, we develop a new estimation method for RDS in the presence of directed edges on the basis of random walks on directed networks. We distinguish directed and undirected edges and consider the possibility that the random walk returns to its current position in two steps through an undirected edge. We derive estimators of the selection probabilities of individuals as a function of the number of outgoing edges of sampled individuals. We evaluate the performance of the proposed estimators on artificial and empirical networks to show that they generally perform better than existing methods. This is in particular the case when the fraction of directed edges in the network is large.',
	 'authors': u'Jens Malmros, Naoki Masuda, Tom Britton,',
	 'category': u'Computer Science ',
	 'date': '2013-8-16',
	 'pdflink': u'http://arxiv.org/pdf/1308.3600',
	 'subjects': u'Methodology (stat.ME)',
	 'title': u'\nRandom Walks on Directed Networks: Inference and Respondent-driven  Sampling',
	 'urllink': u'http://arxiv.org/abs/1308.3600'}
2015-03-24 01:24:09+0000 [xxu46_7] INFO: Crawled 137 pages (at 1 pages/min), scraped 130 items (at 1 items/min)
2015-03-24 01:25:09+0000 [xxu46_7] INFO: Crawled 137 pages (at 0 pages/min), scraped 130 items (at 0 items/min)
2015-03-24 01:26:04+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.3565> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:26:04+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.3565>
	{'abstract': u"[Abridged] We propose a solution to the problem of quickly and accurately predicting gravitational waveforms within any given physical model. The method is relevant for both real-time applications and in more traditional scenarios where the generation of waveforms using standard methods can be prohibitively expensive. Our approach is based on three offline steps resulting in an accurate reduced-order model that can be used as a surrogate for the true/fiducial waveform family. First, a set of m parameter values is determined using a greedy algorithm from which a reduced basis representation is constructed. Second, these m parameters induce the selection of m time values for interpolating a waveform time series using an empirical interpolant. Third, a fit in the parameter dimension is performed for the waveform's value at each of these m times. The cost of predicting L waveform time samples for a generic parameter choice is of order m L + m c_f online operations where c_f denotes the fitting function operation count and, typically, m &lt;&lt; L. We generate accurate surrogate models for Effective One Body (EOB) waveforms of non-spinning binary black hole coalescences with durations as long as 10^5 M, mass ratios from 1 to 10, and for multiple harmonic modes. We find that these surrogates are three orders of magnitude faster to evaluate as compared to the cost of generating EOB waveforms in standard ways. Surrogate model building for other waveform models follow the same steps and have the same low online scaling cost. For expensive numerical simulations of binary black hole coalescences we thus anticipate large speedups in generating new waveforms with a surrogate. As waveform generation is one of the dominant costs in parameter estimation algorithms and parameter space exploration, surrogate models offer a new and practical way to dramatically accelerate such studies without impacting accuracy.",
	 'authors': u'Scott E. Field, Chad R. Galley, Jan S. Hesthaven, Jason Kaye, Manuel Tiglio,',
	 'category': u'Computer Science ',
	 'date': '2013-8-16',
	 'pdflink': u'http://arxiv.org/pdf/1308.3565',
	 'subjects': u'General Relativity and Quantum Cosmology (gr-qc)',
	 'title': u'\nFast prediction and evaluation of gravitational waveforms using  surrogate models',
	 'urllink': u'http://arxiv.org/abs/1308.3565'}
2015-03-24 01:26:09+0000 [xxu46_7] INFO: Crawled 138 pages (at 1 pages/min), scraped 131 items (at 1 items/min)
2015-03-24 01:27:09+0000 [xxu46_7] INFO: Crawled 138 pages (at 0 pages/min), scraped 131 items (at 0 items/min)
2015-03-24 01:27:38+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.3485> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:27:38+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.3485>
	{'abstract': u'More often than not, bad decisions are bad regardless of where and when they are made. Information sharing might thus be utilized to mitigate them. Here we show that sharing the information about strategy choice between players residing on two different networks reinforces the evolution of cooperation. In evolutionary games the strategy reflects the action of each individual that warrants the highest utility in a competitive setting. We therefore assume that identical strategies on the two networks reinforce themselves by lessening their propensity to change. Besides network reciprocity working in favour of cooperation on each individual network, we observe the spontaneous emerge of correlated behaviour between the two networks, which further deters defection. If information is shared not just between individuals but also between groups, the positive effect is even stronger, and this despite the fact that information sharing is implemented without any assumptions with regards to content.',
	 'authors': u'Attila Szolnoki, Matjaz Perc,',
	 'category': u'Computer Science ',
	 'date': '2013-8-15',
	 'pdflink': u'http://arxiv.org/pdf/1308.3485',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nInformation sharing promotes prosocial behaviour',
	 'urllink': u'http://arxiv.org/abs/1308.3485'}
2015-03-24 01:28:09+0000 [xxu46_7] INFO: Crawled 139 pages (at 1 pages/min), scraped 132 items (at 1 items/min)
2015-03-24 01:29:09+0000 [xxu46_7] INFO: Crawled 139 pages (at 0 pages/min), scraped 132 items (at 0 items/min)
2015-03-24 01:29:24+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.3420> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:29:24+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.3420>
	{'abstract': u'In this primer, we will describe a number of projects that can be completed with a 3D printer, particularly by mathematics professors and their students. For many of the projects, we will utilize Mathematica to design objects that mathematicians may be interested in printing. Included in the projects that are described is a method to acquire data from an XBox Kinect.',
	 'authors': u'Edward Aboufadel, Sylvanna V. Krawczyk, Melissa Sherman-Bennett,',
	 'category': u'Computer Science ',
	 'date': '2013-8-13',
	 'pdflink': u'http://arxiv.org/pdf/1308.3420',
	 'subjects': u'History and Overview (math.HO)',
	 'title': u'\n3D Printing for Math Professors and Their Students',
	 'urllink': u'http://arxiv.org/abs/1308.3420'}
2015-03-24 01:30:09+0000 [xxu46_7] INFO: Crawled 140 pages (at 1 pages/min), scraped 133 items (at 1 items/min)
2015-03-24 01:30:41+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.3381> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:30:41+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.3381>
	{'abstract': u'This paper considers the problem of networks reconstruction from heterogeneous data using a Gaussian Graphical Mixture Model (GGMM). It is well known that parameter estimation in this context is challenging due to large numbers of variables coupled with the degeneracy of the likelihood. We propose as a solution a penalized maximum likelihood technique by imposing an penalty on the precision matrix. Our approach shrinks the parameters thereby resulting in better identifiability and variable selection. We use the Expectation Maximization (EM) algorithm which involves the graphical LASSO to estimate the mixing coefficients and the precision matrices. We show that under certain regularity conditions the Penalized Maximum Likelihood (PML) estimates are consistent. We demonstrate the performance of the PML estimator through simulations and we show the utility of our method for high dimensional data analysis in a genomic application.',
	 'authors': u'Anani Lotsi, Ernst Wit,',
	 'category': u'Computer Science ',
	 'date': '2013-8-15',
	 'pdflink': u'http://arxiv.org/pdf/1308.3381',
	 'subjects': u'Machine Learning (stat.ML)',
	 'title': u'\nHigh dimensional Sparse Gaussian Graphical Mixture Model',
	 'urllink': u'http://arxiv.org/abs/1308.3381'}
2015-03-24 01:31:09+0000 [xxu46_7] INFO: Crawled 141 pages (at 1 pages/min), scraped 134 items (at 1 items/min)
2015-03-24 01:32:09+0000 [xxu46_7] INFO: Crawled 141 pages (at 0 pages/min), scraped 134 items (at 0 items/min)
2015-03-24 01:32:28+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.3374> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:32:28+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.3374>
	{'abstract': u"For array processing, we consider the problem of estimating signals of interest, and their directions of arrival (DOA), in unknown colored noise fields. We develop an estimator that efficiently utilizes a set of noise-only samples and, further, can incorporate prior knowledge of the DOAs with varying degrees of certainty. The estimator is compared with state of the art estimators that utilize noise-only samples, and the Cram 'r-Rao bound, exhibiting improved performance for smaller sample sets and in poor signal conditions.",
	 'authors': u'Dave Zachariah, Magnus Jansson, Mats Bengtsson,',
	 'category': u'Computer Science ',
	 'date': '2013-8-15',
	 'pdflink': u'http://arxiv.org/pdf/1308.3374',
	 'subjects': u'Statistics Theory (math.ST)',
	 'title': u'\nUtilization of Noise-Only Samples in Array Processing With Prior  Knowledge',
	 'urllink': u'http://arxiv.org/abs/1308.3374'}
2015-03-24 01:33:09+0000 [xxu46_7] INFO: Crawled 142 pages (at 1 pages/min), scraped 135 items (at 1 items/min)
2015-03-24 01:33:54+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.3354> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:33:54+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.3354>
	{'abstract': u'In the game of Cops and Robbers, the capture time of a graph is the minimum number of moves needed by the cops to capture the robber, assuming optimal play. We prove that the capture time of the -dimensional hypercube is Our methods include a novel randomized strategy for the players, which involves the analysis of the coupon-collector problem.',
	 'authors': u'Anthony Bonato, William B. Kinnersley, P. Gordinowicz, P. Pralat,',
	 'category': u'Computer Science ',
	 'date': '2013-8-15',
	 'pdflink': u'http://arxiv.org/pdf/1308.3354',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nThe capture time of the hypercube',
	 'urllink': u'http://arxiv.org/abs/1308.3354'}
2015-03-24 01:34:09+0000 [xxu46_7] INFO: Crawled 143 pages (at 1 pages/min), scraped 136 items (at 1 items/min)
2015-03-24 01:35:09+0000 [xxu46_7] INFO: Crawled 143 pages (at 0 pages/min), scraped 136 items (at 0 items/min)
2015-03-24 01:35:21+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.3340> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:35:21+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.3340>
	{'abstract': u'One of the most remarkable social phenomena is the formation of communities in social networks corresponding to families, friendship circles, work teams, etc. Since people usually belong to several different communities at the same time, the induced overlaps result in an extremely complicated web of the communities themselves. Thus, uncovering the intricate community structure of social networks is a non-trivial task with great potential for practical applications, gaining a notable interest in the recent years. The Clique Percolation Method (CPM) is one of the earliest overlapping community finding methods, which was already used in the analysis of several different social networks. In this approach the communities correspond to k-clique percolation clusters, and the general heuristic for setting the parameters of the method is to tune the system just below the critical point of k-clique percolation. However, this rule is based on simple physical principles and its validity was never subject to quantitative analysis. Here we examine the quality of the partitioning in the vicinity of the critical point using recently introduced overlapping modularity measures. According to our results on real social- and other networks, the overlapping modularities show a maximum close to the critical point, justifying the original criteria for the optimal parameter settings.',
	 'authors': u'Balint Toth, Tamas Vicsek, Gergely Palla,',
	 'category': u'Computer Science ',
	 'date': '2013-8-15',
	 'pdflink': u'http://arxiv.org/pdf/1308.3340',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nOverlapping modularity at the critical point of k-clique percolation',
	 'urllink': u'http://arxiv.org/abs/1308.3340'}
2015-03-24 01:36:09+0000 [xxu46_7] INFO: Crawled 144 pages (at 1 pages/min), scraped 137 items (at 1 items/min)
2015-03-24 01:37:09+0000 [xxu46_7] INFO: Crawled 144 pages (at 0 pages/min), scraped 137 items (at 0 items/min)
2015-03-24 01:37:20+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.3314> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:37:20+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.3314>
	{'abstract': u"In this note, we introduce a new algorithm to deal with finite dimensional clustering with errors in variables. The design of this algorithm is based on recent theoretical advances (see Loustau (2013a,b)) in statistical learning with errors in variables. As the previous mentioned papers, the algorithm mixes different tools from the inverse problem literature and the machine learning community. Coarsely, it is based on a two-step procedure: (1) a deconvolution step to deal with noisy inputs and (2) Newton's iterations as the popular k-means.",
	 'authors': u'Camille Brunet, S\xe9bastien Loustau,',
	 'category': u'Computer Science ',
	 'date': '2013-8-15',
	 'pdflink': u'http://arxiv.org/pdf/1308.3314',
	 'subjects': u'Machine Learning (stat.ML)',
	 'title': u'\nThe algorithm of noisy k-means',
	 'urllink': u'http://arxiv.org/abs/1308.3314'}
2015-03-24 01:38:09+0000 [xxu46_7] INFO: Crawled 145 pages (at 1 pages/min), scraped 138 items (at 1 items/min)
2015-03-24 01:38:44+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.3182> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:38:44+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.3182>
	{'abstract': u'Many real-world complex systems consist of a set of elementary units connected by relationships of different kinds. All such systems are better described in terms of multiplex networks, where the links at each layer represent a different type of interaction between the same set of nodes, rather than in terms of (single-layer) networks. In this paper we present a general framework to describe and study multiplex networks, whose links are either unweighted or weighted. In particular we propose a series of measures to characterize the multiplexicity of the systems in terms of: i) basic node and link properties such as the node degree, and the edge overlap and reinforcement, ii) local properties such as the clustering coefficient and the transitivity, iii) global properties related to the navigability of the multiplex across the different layers. The measures we introduce are validated on a genuine multiplex data set of Indonesian terrorists, where information among 78 individuals are recorded with respect to mutual trust, common operations, exchanged communications and business relationships.',
	 'authors': u'Federico Battiston, Vincenzo Nicosia, Vito Latora,',
	 'category': u'Computer Science ',
	 'date': '2013-8-14',
	 'pdflink': u'http://arxiv.org/pdf/1308.3182',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nStructural measures for multiplex networks',
	 'urllink': u'http://arxiv.org/abs/1308.3182'}
2015-03-24 01:39:09+0000 [xxu46_7] INFO: Crawled 146 pages (at 1 pages/min), scraped 139 items (at 1 items/min)
2015-03-24 01:40:09+0000 [xxu46_7] INFO: Crawled 146 pages (at 0 pages/min), scraped 139 items (at 0 items/min)
2015-03-24 01:40:24+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.3112> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:40:24+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.3112>
	{'abstract': u'The r-th order nonlinearity of a Boolean function is the minimum number of elements that have to be changed in its truth table to arrive at a Boolean function of degree at most r. It is shown that the (suitably normalised) r-th order nonlinearity of a random Boolean function converges strongly for all r ge 1. This extends results by Rodier for r=1 and by Dib for r=2. The methods in the present paper are mostly of elementary combinatorial nature and also lead to simpler proofs in the cases that r=1 or 2.',
	 'authors': u'Kai-Uwe Schmidt,',
	 'category': u'Computer Science ',
	 'date': '2013-8-14',
	 'pdflink': u'http://arxiv.org/pdf/1308.3112',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nNonlinearity measures of random Boolean functions',
	 'urllink': u'http://arxiv.org/abs/1308.3112'}
2015-03-24 01:41:09+0000 [xxu46_7] INFO: Crawled 147 pages (at 1 pages/min), scraped 140 items (at 1 items/min)
2015-03-24 01:42:05+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.3025> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:42:05+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.3025>
	{'abstract': u'Stern-judging is one of the best-known assessment rules in indirect reciprocity. Indirect reciprocity is a fundamental mechanism for the evolution of cooperation. It relies on mutual monitoring and assessments, i.e., individuals judge, following their own assessment rules, whether other individuals are "good" or "bad" according to information on their past behaviors. Among many assessment rules, stern-judging is known to provide stable cooperation in a population, as observed when all members in the population know all about others\' behaviors (public information case) and when the members never commit an assessment error. In this paper, the effect of assessment error and private information on stern-judging is investigated. By analyzing the image matrix, which describes who is good in the eyes of whom in the population, we analytically show that private information and assessment error cause the collapse of stern-judging: all individuals assess other individuals as "good" at random with a probability of 1/2.',
	 'authors': u'Satoshi Uchida, Tatsuya Sasaki,',
	 'category': u'Computer Science ',
	 'date': '2013-8-14',
	 'pdflink': u'http://arxiv.org/pdf/1308.3025',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nEffect of assessment error and private information on stern-judging in  indirect reciprocity',
	 'urllink': u'http://arxiv.org/abs/1308.3025'}
2015-03-24 01:42:09+0000 [xxu46_7] INFO: Crawled 148 pages (at 1 pages/min), scraped 141 items (at 1 items/min)
2015-03-24 01:43:09+0000 [xxu46_7] INFO: Crawled 148 pages (at 0 pages/min), scraped 141 items (at 0 items/min)
2015-03-24 01:43:53+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.3009> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:43:53+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.3009>
	{'abstract': u'Wireless sensor networks are an important technology for making distributed autonomous measures in hostile or inaccessible environments. Among the challenges they pose, the way data travel among them is a relevant issue since their structure is quite dynamic. The operational topology of such devices can often be described by complex networks. In this work, we assess the variation of measures commonly employed in the complex networks literature applied to wireless sensor networks. Four data communication strategies were considered: geometric, random, small-world, and scale-free models, along with the shortest path length measure. The sensitivity of this measure was analyzed with respect to the following perturbations: insertion and removal of nodes in the geometric strategy; and insertion, removal and rewiring of links in the other models. The assessment was performed using the normalized Kullback-Leibler divergence and Hellinger distance quantifiers, both deriving from the Information Theory framework. The results reveal that the shortest path length is sensitive to perturbations.',
	 'authors': u'Raquel S. Cabral, Andre L. L. Aquino, Alejandro C. Frery, Osvaldo A. Rosso, Jaime A. Ram\xedrez,',
	 'category': u'Computer Science ',
	 'date': '2013-8-14',
	 'pdflink': u'http://arxiv.org/pdf/1308.3009',
	 'subjects': u'Data Analysis, Statistics and Probability (physics.data-an)',
	 'title': u'\nStructural Changes in Data Communication in Wireless Sensor Networks',
	 'urllink': u'http://arxiv.org/abs/1308.3009'}
2015-03-24 01:44:09+0000 [xxu46_7] INFO: Crawled 149 pages (at 1 pages/min), scraped 142 items (at 1 items/min)
2015-03-24 01:45:09+0000 [xxu46_7] INFO: Crawled 149 pages (at 0 pages/min), scraped 142 items (at 0 items/min)
2015-03-24 01:45:16+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.2867> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:45:16+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.2867>
	{'abstract': u'We propose a variable metric framework for minimizing the sum of a self-concordant function and a possibly non-smooth convex function, endowed with an easily computable proximal operator. We theoretically establish the convergence of our framework without relying on the usual Lipschitz gradient assumption on the smooth part. An important highlight of our work is a new set of analytic step-size selection and correction procedures based on the structure of the problem. We describe concrete algorithmic instances of our framework for several interesting applications and demonstrate them numerically on both synthetic and real data.',
	 'authors': u'Quoc Tran-Dinh, Anastasios Kyrillidis, Volkan Cevher,',
	 'category': u'Computer Science ',
	 'date': '2013-8-13',
	 'pdflink': u'http://arxiv.org/pdf/1308.2867',
	 'subjects': u'Machine Learning (stat.ML)',
	 'title': u'\nComposite Self-Concordant Minimization',
	 'urllink': u'http://arxiv.org/abs/1308.2867'}
2015-03-24 01:46:09+0000 [xxu46_7] INFO: Crawled 150 pages (at 1 pages/min), scraped 143 items (at 1 items/min)
2015-03-24 01:47:00+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.2857> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:47:00+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.2857>
	{'abstract': u'We report on a statistical analysis of the engagement in the electoral processes of all Brazilian cities by considering the number of party memberships and the number of candidates for mayor and councillor. By investigating the relationships between the number of party members and the population of voters, we have found that the functional form of these relationships are well described by sub-linear power laws (allometric scaling) surrounded by a multiplicative log-normal noise. We have observed that this pattern is quite similar to those previously-reported for the relationships between the number candidates (mayor and councillor) and population of voters [EPL 96, 48001 (2011)], suggesting that similar universal laws may be ruling the engagement in the electoral processes. We also note that the power law exponents display a clear hierarchy, where the more influential is the political position the smaller is the value of the exponent. We have also investigated the probability distributions of the number of candidates (mayor and councilor), party memberships and voters. The results indicate that the most influential positions are characterized by distributions with very short-tails, while less influential positions display an intermediate power law decay before showing an exponential-like cutoff. We discuss that, in addition to the political power of the position, limitations in the number of available seats can also be connected with this changing of behavior. We further believe that our empirical findings point out to an underrepresentation effect, where the larger city is, the larger are the obstacles for more individuals to become directly engaged in the electoral process.',
	 'authors': u'M. C. Mantovani, H. V. Ribeiro, E. K. Lenzi, S. Picoli Jr., R. S. Mendes,',
	 'category': u'Computer Science ',
	 'date': '2013-8-13',
	 'pdflink': u'http://arxiv.org/pdf/1308.2857',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nEngagement in the electoral processes: scaling laws and the role of the  political positions',
	 'urllink': u'http://arxiv.org/abs/1308.2857'}
2015-03-24 01:47:09+0000 [xxu46_7] INFO: Crawled 151 pages (at 1 pages/min), scraped 144 items (at 1 items/min)
2015-03-24 01:48:09+0000 [xxu46_7] INFO: Crawled 151 pages (at 0 pages/min), scraped 144 items (at 0 items/min)
2015-03-24 01:48:23+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.2843> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:48:23+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.2843>
	{'abstract': u'We consider the new game of Cops and Attacking Robbers, which is identical to the usual Cops and Robbers game except that if the robber moves to a vertex containing a single cop, then that cop is removed from the game. We study the minimum number of cops needed to capture a robber on a graph , written . We give bounds on in terms of the cop number of in the classes of bipartite graphs and diameter two, -free graphs.',
	 'authors': u'Anthony Bonato, Stephen Finbow, Przemyslaw Gordinowicz, Ali Haidar, William B. Kinnersley, Dieter Mitsche, Pawel Pralat, Ladislav Stacho,',
	 'category': u'Computer Science ',
	 'date': '2013-8-13',
	 'pdflink': u'http://arxiv.org/pdf/1308.2843',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nThe robber strikes back',
	 'urllink': u'http://arxiv.org/abs/1308.2843'}
2015-03-24 01:49:09+0000 [xxu46_7] INFO: Crawled 152 pages (at 1 pages/min), scraped 145 items (at 1 items/min)
2015-03-24 01:49:53+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.2839> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:49:53+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.2839>
	{'abstract': u'In this short note, we supply a new upper bound on the cop number in terms of tree decompositions. Our results in some cases extend a previously derived bound on the cop number using treewidth.',
	 'authors': u'Anthony Bonato, N.E. Clarke, S. Finbow, S. Fitzpatrick, M.E. Messinger,',
	 'category': u'Computer Science ',
	 'date': '2013-8-13',
	 'pdflink': u'http://arxiv.org/pdf/1308.2839',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nA note on bounds for the cop number using tree decompositions',
	 'urllink': u'http://arxiv.org/abs/1308.2839'}
2015-03-24 01:50:09+0000 [xxu46_7] INFO: Crawled 153 pages (at 1 pages/min), scraped 146 items (at 1 items/min)
2015-03-24 01:51:09+0000 [xxu46_7] INFO: Crawled 153 pages (at 0 pages/min), scraped 146 items (at 0 items/min)
2015-03-24 01:51:14+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.2794> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:51:14+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.2794>
	{'abstract': u'We give counterexamples to a conjecture of Benny Chor and another of the second author, both from the late 80s, by exhibiting functions for which the influences of large coalitions are unexpectedly small relative to the expectations of the functions.',
	 'authors': u'Jeff Kahn, Gil Kalai,',
	 'category': u'Computer Science ',
	 'date': '2013-8-13',
	 'pdflink': u'http://arxiv.org/pdf/1308.2794',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nFunctions without influential coalitions',
	 'urllink': u'http://arxiv.org/abs/1308.2794'}
2015-03-24 01:52:09+0000 [xxu46_7] INFO: Crawled 154 pages (at 1 pages/min), scraped 147 items (at 1 items/min)
2015-03-24 01:52:25+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.2745> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:52:25+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.2745>
	{'abstract': u'In this paper we discuss the potential of emerging spintorque devices for computing applications. Recent proposals for spinbased computing schemes may be differentiated as all-spin vs. hybrid, programmable vs. fixed, and, Boolean vs. non-Boolean. All spin logic-styles may offer high area-density due to small form-factor of nano-magnetic devices. However, circuit and system-level design techniques need to be explored that leverage the specific spin-device characteristics to achieve energy-efficiency, performance and reliability comparable to those of CMOS. The non-volatility of nanomagnets can be exploited in the design of energy and area-efficient programmable logic. In such logic-styles, spin-devices may play the dual-role of computing as well as memory-elements that provide field-programmability. Spin-based threshold logic design is presented as an example (dynamic resisitve threshold logic and magnetic threshold logic). Emerging spintronic phenomena may lead to ultralow- voltage, current-mode, spin-torque switches that can offer attractive computing capabilities, beyond digital switches. Such devices may be suitable for non-Boolean data-processing applications which involve analog processing. Integration of such spin-torque devices with charge-based devices like CMOS and resistive memory can lead to highly energy-efficient information processing hardware for applications like pattern-matching, neuromorphic-computing, image-processing and data-conversion. Towards the end, we discuss the possibility of applying emerging spin-torque switches in the design of energy-efficient global interconnects, for future chip multiprocessors.',
	 'authors': u'Kaushik Roy, Mrigank Sharad, Deliang Fan, Karthik Yogendra,',
	 'category': u'Computer Science ',
	 'date': '2013-8-13',
	 'pdflink': u'http://arxiv.org/pdf/1308.2745',
	 'subjects': u'Disordered Systems and Neural Networks (cond-mat.dis-nn)',
	 'title': u'\nExploring Boolean and Non-Boolean Computing Applications of Spin Torque  Devices',
	 'urllink': u'http://arxiv.org/abs/1308.2745'}
2015-03-24 01:53:09+0000 [xxu46_7] INFO: Crawled 155 pages (at 1 pages/min), scraped 148 items (at 1 items/min)
2015-03-24 01:54:09+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.2666> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:54:09+0000 [xxu46_7] INFO: Crawled 156 pages (at 1 pages/min), scraped 148 items (at 0 items/min)
2015-03-24 01:54:09+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.2666>
	{'abstract': u'Let be a word in alphabet with \'s and \'s. Interpreting "" as multiplication by , and "" as differentiation with respect to , the identity , valid for any smooth function , defines a sequence , the terms of which we refer to as the of . The nomenclature comes from the fact that when , we have , the ordinary Stirling number of the second kind. Explicit expressions for, and identities satisfied by, the have been obtained by numerous authors, and combinatorial interpretations have been presented. Here we provide a new combinatorial interpretation that retains the spirit of the familiar interpretation of as a count of partitions. Specifically, we associate to each a quasi-threshold graph , and we show that enumerates partitions of the vertex set of into classes that do not span an edge of . We also discuss some relatives of, and consequences of, our interpretation, including -analogs and bijections between families of labelled forests and sets of restricted partitions.',
	 'authors': u'John Engbers, David Galvin, Justin Hilyard,',
	 'category': u'Computer Science ',
	 'date': '2013-8-12',
	 'pdflink': u'http://arxiv.org/pdf/1308.2666',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nCombinatorially interpreting generalized Stirling numbers',
	 'urllink': u'http://arxiv.org/abs/1308.2666'}
2015-03-24 01:55:09+0000 [xxu46_7] INFO: Crawled 156 pages (at 0 pages/min), scraped 149 items (at 1 items/min)
2015-03-24 01:56:03+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.2630> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:56:03+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.2630>
	{'abstract': u'This paper reports on a study in which a novel virtual moving sound-based spatial auditory brain-computer interface (BCI) paradigm is developed. Classic auditory BCIs rely on spatially static stimuli, which are often boring and difficult to perceive when subjects have non-uniform spatial hearing perception characteristics. The concept of moving sound proposed and tested in the paper allows for the creation of a P300 oddball paradigm of necessary target and non-target auditory stimuli, which are more interesting and easier to distinguish. We present a report of our study of seven healthy subjects, which proves the concept of moving sound stimuli usability for a novel BCI. We compare online BCI classification results in static and moving sound paradigms yielding similar accuracy results. The subject preference reports suggest that the proposed moving sound protocol is more comfortable and easier to discriminate with the online BCI.',
	 'authors': u'Yohann Lelievre, Tomasz M. Rutkowski,',
	 'category': u'Computer Science ',
	 'date': '2013-8-12',
	 'pdflink': u'http://arxiv.org/pdf/1308.2630',
	 'subjects': u'Neurons and Cognition (q-bio.NC)',
	 'title': u'\nNovel Virtual Moving Sound-based Spatial Auditory Brain-Computer  Interface Paradigm',
	 'urllink': u'http://arxiv.org/abs/1308.2630'}
2015-03-24 01:56:09+0000 [xxu46_7] INFO: Crawled 157 pages (at 1 pages/min), scraped 150 items (at 1 items/min)
2015-03-24 01:57:09+0000 [xxu46_7] INFO: Crawled 157 pages (at 0 pages/min), scraped 150 items (at 0 items/min)
2015-03-24 01:57:46+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.2516> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:57:46+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.2516>
	{'abstract': u'Power-law correlations have been observed in packet flow over the Internet. The possible origin of these correlations includes demand for Internet services. We observe the demand for e-mail services in an organization, and analyze correlations in the flow and the sequence of send requests using a Detrended Fluctuation Analysis (DFA). The correlation in the flow is found to be weaker than that in the send requests. Four types of artificial flow are constructed to investigate the effects of fluctuations in e-mail sizes. As a result, we find that the correlation in the flow originates from that in the sequence of send requests. The strength of the power-law correlation decreases as a function of the ratio of the standard deviation of e-mail sizes to their average.',
	 'authors': u'Yoshitsugu Matsubara, Yasuhiro Hieida, Shin-ichi Tadaki,',
	 'category': u'Computer Science ',
	 'date': '2013-8-12',
	 'pdflink': u'http://arxiv.org/pdf/1308.2516',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nFluctuation in e-mail sizes weakens power-law correlations in e-mail  flow',
	 'urllink': u'http://arxiv.org/abs/1308.2516'}
2015-03-24 01:58:09+0000 [xxu46_7] INFO: Crawled 158 pages (at 1 pages/min), scraped 151 items (at 1 items/min)
2015-03-24 01:58:59+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.2505> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 01:58:59+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.2505>
	{'abstract': u'This paper provides necessary conditions and sufficient conditions for the (global) Input-to-State Stability property of simple uncertain vehicular-traffic network models under the effect of a PI-regulator. Local stability properties for vehicular-traffic networks under the effect of PI-regulator control are studied as well: the region of attraction of a locally exponentially stable equilibrium point is estimated by means of Lyapunov functions. All obtained results are illustrated by means of simple examples.',
	 'authors': u'Iasson Karafyllis, Markos Papageorgiou,',
	 'category': u'Computer Science ',
	 'date': '2013-8-12',
	 'pdflink': u'http://arxiv.org/pdf/1308.2505',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nStability Results for Simple Traffic Models Under PI-Regulator Control',
	 'urllink': u'http://arxiv.org/abs/1308.2505'}
2015-03-24 01:59:09+0000 [xxu46_7] INFO: Crawled 159 pages (at 1 pages/min), scraped 152 items (at 1 items/min)
2015-03-24 02:00:09+0000 [xxu46_7] INFO: Crawled 159 pages (at 0 pages/min), scraped 152 items (at 0 items/min)
2015-03-24 02:00:49+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.2495> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:00:49+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.2495>
	{'abstract': u'The -dimensional Goldfarb cube is a polytope with the property that all its vertices appear on some emph of it (projection onto a 2-dimensional plane). The Goldfarb cube is the solution set of a system of 2d linear inequalities with at most 3 variables per inequality. We show in this paper that the -dimensional Klee-Minty cube --- constructed from inequalities with at most 2 variables per inequality --- also has a shadow with vertices. In contrast, with one variable per inequality, the size of the shadow is bounded by 2d.',
	 'authors': u'Bernd G\xe4rtner, Christian Helbling, Yoshiki Ota, Takeru Takahashi,',
	 'category': u'Computer Science ',
	 'date': '2013-8-12',
	 'pdflink': u'http://arxiv.org/pdf/1308.2495',
	 'subjects': u'Metric Geometry (math.MG)',
	 'title': u'\nLarge Shadows from Sparse Inequalities',
	 'urllink': u'http://arxiv.org/abs/1308.2495'}
2015-03-24 02:01:09+0000 [xxu46_7] INFO: Crawled 160 pages (at 1 pages/min), scraped 153 items (at 1 items/min)
2015-03-24 02:02:09+0000 [xxu46_7] INFO: Crawled 160 pages (at 0 pages/min), scraped 153 items (at 0 items/min)
2015-03-24 02:02:48+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.2493> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:02:48+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.2493>
	{'abstract': u'The Pauli matrices are a set of three 2x2 complex Hermitian, unitary matrices. In this article, we investigate the relationships between certain roots of the Pauli matrices and how gates implementing those roots are used in quantum circuits. Techniques for simplifying such circuits are given. In particular, we show how those techniques can be used to find a circuit of Clifford+T gates starting from a circuit composed of gates from the well studied NCV library.',
	 'authors': u'Mathias Soeken, D. Michael Miller, Rolf Drechsler,',
	 'category': u'Computer Science ',
	 'date': '2013-8-12',
	 'pdflink': u'http://arxiv.org/pdf/1308.2493',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nOn quantum circuits employing roots of the Pauli matrices',
	 'urllink': u'http://arxiv.org/abs/1308.2493'}
2015-03-24 02:03:09+0000 [xxu46_7] INFO: Crawled 161 pages (at 1 pages/min), scraped 154 items (at 1 items/min)
2015-03-24 02:04:09+0000 [xxu46_7] INFO: Crawled 161 pages (at 0 pages/min), scraped 154 items (at 0 items/min)
2015-03-24 02:04:37+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.2122> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:04:37+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.2122>
	{'abstract': u'We introduce a generalization of tropical polyhedra able to express both strict and non-strict inequalities. Such inequalities are handled by means of a semiring of germs (encoding infinitesimal perturbations). We develop a tropical analogue of Fourier-Motzkin elimination from which we derive geometrical properties of these polyhedra. In particular, we show that they coincide with the tropically convex union of (non-necessarily closed) cells that are convex both classically and tropically. We also prove that the redundant inequalities produced when performing successive elimination steps can be dynamically deleted by reduction to mean payoff game problems. As a complement, we provide a coarser (polynomial time) deletion procedure which is enough to arrive at a simply exponential bound for the total execution time. These algorithms are illustrated by an application to real-time systems (reachability analysis of timed automata).',
	 'authors': u'Xavier Allamigeon, Uli Fahrenberg, St\xe9phane Gaubert, Ricardo D. Katz, Axel Legay,',
	 'category': u'Computer Science ',
	 'date': '2013-8-9',
	 'pdflink': u'http://arxiv.org/pdf/1308.2122',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nTropical Fourier-Motzkin elimination, with an application to real-time  verification',
	 'urllink': u'http://arxiv.org/abs/1308.2122'}
2015-03-24 02:05:09+0000 [xxu46_7] INFO: Crawled 162 pages (at 1 pages/min), scraped 155 items (at 1 items/min)
2015-03-24 02:06:04+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.2015> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:06:04+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.2015>
	{'abstract': u'Taking a pragmatic approach to the processes involved in the phenomena of collective opinion formation, we investigate two specific modifications to the co-evolving network voter model of opinion formation, studied by Holme and Newman [1]. First, we replace the rewiring probability parameter by a distribution of probability of accepting or rejecting opinions between individuals, accounting for the asymmetric influences in relationships among individuals in a social group. Second, we modify the rewiring step by a path-length-based preference for rewiring that reinforces local clustering. We have investigated the influences of these modifications on the outcomes of the simulations of this model. We found that varying the shape of the distribution of probability of accepting or rejecting opinions can lead to the emergence of two qualitatively distinct final states, one having several isolated connected components each in internal consensus leading to the existence of diverse set of opinions and the other having one single dominant connected component with each node within it having the same opinion. Furthermore, and more importantly, we found that the initial clustering in network can also induce similar transitions. Our investigation also brings forward that these transitions are governed by a weak and complex dependence on system size. We found that the networks in the final states of the model have rich structural properties including the small world property for some parameter regimes. [1] P. Holme and M. Newman, Phys. Rev. E 74, 056108 (2006).',
	 'authors': u'Nishant Malik, Peter J. Mucha,',
	 'category': u'Computer Science ',
	 'date': '2013-8-9',
	 'pdflink': u'http://arxiv.org/pdf/1308.2015',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nRole of social environment and social clustering in spread of opinions  in co-evolving networks',
	 'urllink': u'http://arxiv.org/abs/1308.2015'}
2015-03-24 02:06:09+0000 [xxu46_7] INFO: Crawled 163 pages (at 1 pages/min), scraped 156 items (at 1 items/min)
2015-03-24 02:07:08+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.1947> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:07:08+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.1947>
	{'abstract': u'Besides the structure of interactions within networks, also the interactions between networks are of the outmost importance. We therefore study the outcome of the public goods game on two interdependent networks that are connected by means of a utility function, which determines how payoffs on both networks jointly influence the success of players in each individual network. We show that an unbiased coupling allows the spontaneous emergence of interdependent network reciprocity, which is capable to maintain healthy levels of public cooperation even in extremely adverse conditions. The mechanism, however, requires simultaneous formation of correlated cooperator clusters on both networks. If this does not emerge or if the coordination process is disturbed, network reciprocity fails, resulting in the total collapse of cooperation. Network interdependence can thus be exploited effectively to promote cooperation past the limits imposed by isolated networks, but only if the coordination between the interdependent networks is not disturbed.',
	 'authors': u'Zhen Wang, Attila Szolnoki, Matjaz Perc,',
	 'category': u'Computer Science ',
	 'date': '2013-8-8',
	 'pdflink': u'http://arxiv.org/pdf/1308.1947',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nInterdependent network reciprocity in evolutionary games',
	 'urllink': u'http://arxiv.org/abs/1308.1947'}
2015-03-24 02:07:09+0000 [xxu46_7] INFO: Crawled 164 pages (at 1 pages/min), scraped 157 items (at 1 items/min)
2015-03-24 02:07:56+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.1941> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:07:56+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.1941>
	{'abstract': u'Goal oriented error estimation and adaptive procedures are essential for the accurate and efficient evaluation of numerical simulations that involve complex domains. By locally improving the approximation quality we can solve expensive problems which could result intractable otherwise. Here, we present an error estimation technique for enriched finite element approximations that is based on an equilibrated recovery technique, which considers the stress intensity factor as the quantity of interest. The locally equilibrated superconvergent patch recovery is used to obtain enhanced stress fields for the primal and dual problems defined to evaluate the error estimate.',
	 'authors': u'Octavio Andr\xe9s Gonz\xe1lez Estrada, Juan Jos\xe9 R\xf3denas Garc\xeda, St\xe9phane Bordas, E. Nadal, Pierre Kerfriden, F.J. Fuenmayor,',
	 'category': u'Computer Science ',
	 'date': '2013-8-8',
	 'pdflink': u'http://arxiv.org/pdf/1308.1941',
	 'subjects': u'Numerical Analysis (math.NA)',
	 'title': u'\nLocally equilibrated stress recovery for goal oriented error estimation  in the extended finite element method',
	 'urllink': u'http://arxiv.org/abs/1308.1941'}
2015-03-24 02:08:09+0000 [xxu46_7] INFO: Crawled 165 pages (at 1 pages/min), scraped 158 items (at 1 items/min)
2015-03-24 02:09:09+0000 [xxu46_7] INFO: Crawled 165 pages (at 0 pages/min), scraped 158 items (at 0 items/min)
2015-03-24 02:09:51+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.1889> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:09:51+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.1889>
	{'abstract': u'SOSOPT is a Matlab toolbox for formulating and solving Sum-of-Squares (SOS) polynomial optimizations. This document briefly describes the use and functionality of this toolbox. Section 1 introduces the problem formulations for SOS tests, SOS feasibility problems, SOS optimizations, and generalized SOS problems. Section 2 reviews the SOSOPT toolbox for solving these optimizations. This section includes information on toolbox installation, formulating constraints, solving SOS optimizations, and setting optimization options. Finally, Section 3 briefly reviews the connections between SOS optimizations and semide?nite programs (SDPs). It is the connection to SDPs that enables SOS optimizations to be solved in an efficient manner',
	 'authors': u'Peter Seiler,',
	 'category': u'Computer Science ',
	 'date': '2013-8-8',
	 'pdflink': u'http://arxiv.org/pdf/1308.1889',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nSOSOPT: A Toolbox for Polynomial Optimization',
	 'urllink': u'http://arxiv.org/abs/1308.1889'}
2015-03-24 02:10:09+0000 [xxu46_7] INFO: Crawled 166 pages (at 1 pages/min), scraped 159 items (at 1 items/min)
2015-03-24 02:11:09+0000 [xxu46_7] INFO: Crawled 166 pages (at 0 pages/min), scraped 159 items (at 0 items/min)
2015-03-24 02:11:20+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.1827> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:11:20+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.1827>
	{'abstract': u'We consider the problem of approximating an affinely structured matrix, for example a Hankel matrix, by a low-rank matrix with the same structure. This problem occurs in system identification, signal processing and computer algebra, among others. We impose the low-rank by modeling the approximation as a product of two factors with reduced dimension. The structure of the low-rank model is enforced by introducing a penalty term in the objective function. The proposed local optimization algorithm is able to solve the weighted structured low-rank approximation problem, as well as to deal with the cases of missing or fixed elements. In contrast to approaches based on kernel representations (in linear algebraic sense), the proposed algorithm is designed to address the case of small targeted rank. We compare it to existing approaches on numerical examples of system identification, approximate greatest common divisor problem, and symmetric tensor decomposition and demonstrate its consistently good performance.',
	 'authors': u'Mariya Ishteva, Konstantin Usevich, Ivan Markovsky,',
	 'category': u'Computer Science ',
	 'date': '2013-8-8',
	 'pdflink': u'http://arxiv.org/pdf/1308.1827',
	 'subjects': u'Numerical Analysis (math.NA)',
	 'title': u'\nFactorization approach to structured low-rank approximation with  applications',
	 'urllink': u'http://arxiv.org/abs/1308.1827'}
2015-03-24 02:12:09+0000 [xxu46_7] INFO: Crawled 167 pages (at 1 pages/min), scraped 160 items (at 1 items/min)
2015-03-24 02:13:09+0000 [xxu46_7] INFO: Crawled 167 pages (at 0 pages/min), scraped 160 items (at 0 items/min)
2015-03-24 02:13:19+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.1776> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:13:19+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.1776>
	{'abstract': u'This report summarizes the results of a short-term student research project focused on the usage of Swedish Wikipedia. It is trying to answer the following question: To what extent (and why) do people from non-English language communities use the English Wikipedia instead of the one in their local language? Article access time series and article edit time series from major Wikipedias including Swedish Wikipedia are analyzed with various tools.',
	 'authors': u'Berit Schreck, Mirko K\xe4mpf, Jan W. Kantelhardt, Holger Motzkau,',
	 'category': u'Computer Science ',
	 'date': '2013-8-8',
	 'pdflink': u'http://arxiv.org/pdf/1308.1776',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nComparing the usage of global and local Wikipedias with focus on Swedish  Wikipedia',
	 'urllink': u'http://arxiv.org/abs/1308.1776'}
2015-03-24 02:14:09+0000 [xxu46_7] INFO: Crawled 168 pages (at 1 pages/min), scraped 161 items (at 1 items/min)
2015-03-24 02:14:53+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.1747> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:14:53+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.1747>
	{'abstract': u'We present two related anytime algorithms for control of nonlinear systems when the processing resources available are time-varying. The basic idea is to calculate tentative control input sequences for as many time steps into the future as allowed by the available processing resources at every time step. This serves to compensate for the time steps when the processor is not available to perform any control calculations. Using a stochastic Lyapunov function based approach, we analyze the stability of the resulting closed loop system for the cases when the processor availability can be modeled as an independent and identically distributed sequence and via an underlying Markov chain. Numerical simulations indicate that the increase in performance due to the proposed algorithms can be significant.',
	 'authors': u'Daniel E. Quevedo, Vijay Gupta,',
	 'category': u'Computer Science ',
	 'date': '2013-8-8',
	 'pdflink': u'http://arxiv.org/pdf/1308.1747',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nSequence-based Anytime Control',
	 'urllink': u'http://arxiv.org/abs/1308.1747'}
2015-03-24 02:15:09+0000 [xxu46_7] INFO: Crawled 169 pages (at 1 pages/min), scraped 162 items (at 1 items/min)
2015-03-24 02:16:09+0000 [xxu46_7] INFO: Crawled 169 pages (at 0 pages/min), scraped 162 items (at 0 items/min)
2015-03-24 02:16:33+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.1725> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:16:33+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.1725>
	{'abstract': u'Stochastic stability for centralized time-varying Kalman filtering over a wireles ssensor network with correlated fading channels is studied. On their route to the gateway, sensor packets, possibly aggregated with measurements from several nodes, may be dropped because of fading links. To study this situation, we introduce a network state process, which describes a finite set of configurations of the radio environment. The network state characterizes the channel gain distributions of the links, which are allowed to be correlated between each other. Temporal correlations of channel gains are modeled by allowing the network state process to form a (semi-)Markov chain. We establish sufficient conditions that ensure the Kalman filter to be exponentially bounded. In the one-sensor case, this new stability condition is shown to include previous results obtained in the literature as special cases. The results also hold when using power and bit-rate control policies, where the transmission power and bit-rate of each node are nonlinear mapping of the network state and channel gains.',
	 'authors': u'Daniel E. Quevedo, Anders Ahlen, Karl H. Johansson,',
	 'category': u'Computer Science ',
	 'date': '2013-8-8',
	 'pdflink': u'http://arxiv.org/pdf/1308.1725',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nState Estimation over Sensor Networks with Correlated Wireless Fading  Channels',
	 'urllink': u'http://arxiv.org/abs/1308.1725'}
2015-03-24 02:17:09+0000 [xxu46_7] INFO: Crawled 170 pages (at 1 pages/min), scraped 163 items (at 1 items/min)
2015-03-24 02:18:00+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.1605> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:18:00+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.1605>
	{'abstract': u'Recent years have seen a surge of interest in the analysis of complex networks, facilitated by the availability of relational data and the increasingly powerful computational resources that can be employed for their analysis. Naturally, the study of real-world systems leads to highly complex networks and a current challenge is to extract intelligible, simplified descriptions from the network in terms of relevant subgraphs, which can provide insight into the structure and function of the overall system. Sparked by seminal work by Newman and Girvan, an interesting line of research has been devoted to investigating modular community structure in networks, revitalising the classic problem of graph partitioning. However, modular or community structure in networks has notoriously evaded rigorous definition. The most accepted notion of community is perhaps that of a group of elements which exhibit a stronger level of interaction within themselves than with the elements outside the community. This concept has resulted in a plethora of computational methods and heuristics for community detection. Nevertheless a firm theoretical understanding of most of these methods, in terms of how they operate and what they are supposed to detect, is still lacking to date. Here, we will develop a dynamical perspective towards community detection enabling us to define a measure named the stability of a graph partition. It will be shown that a number of previously ad-hoc defined heuristics for community detection can be seen as particular cases of our method providing us with a dynamic reinterpretation of those measures. Our dynamics-based approach thus serves as a unifying framework to gain a deeper understanding of different aspects and problems associated with community detection and allows us to propose new dynamically-inspired criteria for community structure.',
	 'authors': u'Jean-Charles Delvenne, Michael T. Schaub, Sophia N. Yaliraki, Mauricio Barahona,',
	 'category': u'Computer Science ',
	 'date': '2013-8-7',
	 'pdflink': u'http://arxiv.org/pdf/1308.1605',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nThe stability of a graph partition: A dynamics-based framework for  community detection',
	 'urllink': u'http://arxiv.org/abs/1308.1605'}
2015-03-24 02:18:09+0000 [xxu46_7] INFO: Crawled 171 pages (at 1 pages/min), scraped 164 items (at 1 items/min)
2015-03-24 02:19:09+0000 [xxu46_7] INFO: Crawled 171 pages (at 0 pages/min), scraped 164 items (at 0 items/min)
2015-03-24 02:19:37+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.1552> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:19:37+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.1552>
	{'abstract': u'Are editorial decisions biased? A recent discussion in Learned Publishing has focused on one aspect of potential bias in editorial decisions, namely seasonal (e.g., monthly) variations in acceptance rates of research journals. In this letter, we contribute to the discussion by analyzing data from Physical Review Letters (PRL), a journal published by the American Physical Society. We studied the 190,106 papers submitted to PRL from January 1990 until September 2012. No statistically significant variations were found in the monthly acceptance rates. We conclude that the time of year that the authors of a paper submit their work to PRL has no effect on the fate of the paper through the review process.',
	 'authors': u'Manolis Antonoyiannakis,',
	 'category': u'Computer Science ',
	 'date': '2013-8-7',
	 'pdflink': u'http://arxiv.org/pdf/1308.1552',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nAcceptance Rates in Physical Review Letters: No Seasonal Bias',
	 'urllink': u'http://arxiv.org/abs/1308.1552'}
2015-03-24 02:20:09+0000 [xxu46_7] INFO: Crawled 172 pages (at 1 pages/min), scraped 165 items (at 1 items/min)
2015-03-24 02:21:09+0000 [xxu46_7] INFO: Crawled 172 pages (at 0 pages/min), scraped 165 items (at 0 items/min)
2015-03-24 02:21:32+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.1533> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:21:32+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.1533>
	{'abstract': u"Many complex networks demonstrate a phenomenon of striking degree correlations, i.e., a node tends to link to other nodes with similar (or dissimilar) degrees. From the perspective of degree correlations, this paper attempts to characterize topological structures of urban street networks. We adopted six urban street networks (three European and three North American), and converted them into network topologies in which nodes and edges respectively represent individual streets and street intersections, and compared the network topologies to three reference network topologies (biological, technological, and social). The urban street network topologies (with the exception of Manhattan) showed a consistent pattern that distinctly differs from the three reference networks. The topologies of urban street networks lack striking degree correlations in general. Through reshuffling the network topologies towards for example maximum or minimum degree correlations while retaining the initial degree distributions, we found that all the surrogate topologies of the urban street networks, as well as the reference ones, tended to deviate from small world properties. This implies that the initial degree correlations do not have any positive or negative effect on the networks' performance or functions. Keywords: Scale free, small world, rewiring, rich club effect, reshuffle, and complex networks",
	 'authors': u'Bin Jiang, Yingying Duan, Feng Lu, Tinghong Yang, Jing Zhao,',
	 'category': u'Computer Science ',
	 'date': '2013-8-7',
	 'pdflink': u'http://arxiv.org/pdf/1308.1533',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nTopological Structure of Urban Street Networks from the Perspective of  Degree Correlations',
	 'urllink': u'http://arxiv.org/abs/1308.1533'}
2015-03-24 02:22:09+0000 [xxu46_7] INFO: Crawled 173 pages (at 1 pages/min), scraped 166 items (at 1 items/min)
2015-03-24 02:23:09+0000 [xxu46_7] INFO: Crawled 173 pages (at 0 pages/min), scraped 166 items (at 0 items/min)
2015-03-24 02:23:28+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.1481> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:23:28+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.1481>
	{'abstract': u"The casino game of baccara chemin de fer is a bimatrix game, not a matrix game, because the house collects a five percent commission on Banker wins. We generalize the game, allowing Banker's strategy to be unconstrained and assuming a 100alpha percent commission on Banker wins, where 0&lt;=alpha&lt;2/5. Assuming for simplicity that cards are dealt with replacement, we show that, with one exception at alpha=alpha_0 (approximately 0.140705), there is a unique Nash equilibrium, and we evaluate it. Player's equilibrium mixed strategy depends explicitly on alpha, whereas Banker's equilibrium mixed strategy depends only on whether alpha&lt;alpha_0 or alpha&gt;alpha_0.",
	 'authors': u'S. N. Ethier, Jiyeon Lee,',
	 'category': u'Computer Science ',
	 'date': '2013-8-7',
	 'pdflink': u'http://arxiv.org/pdf/1308.1481',
	 'subjects': u'Optimization and Control (math.OC)',
	 'title': u'\nCasino baccara chemin de fer as a bimatrix game',
	 'urllink': u'http://arxiv.org/abs/1308.1481'}
2015-03-24 02:24:09+0000 [xxu46_7] INFO: Crawled 174 pages (at 1 pages/min), scraped 167 items (at 1 items/min)
2015-03-24 02:24:54+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.1391> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:24:54+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.1391>
	{'abstract': u'The two-way continuous-variable quantum key distribution (CVQKD) systems allow higher key rates and improved transmission distances over standard telecommunication networks in comparison to the one-way CVQKD protocols. To exploit the real potential of two-way CVQKD systems a robust reconciliation technique is needed. It is currently unavailable, which makes it impossible to reach the real performance of a two-way CVQKD system. The reconciliation process of correlated Gaussian variables is a complex problem that requires either tomography in the physical layer that is intractable in a practical scenario, or high-cost calculations in the multidimensional spherical space with strict dimensional limitations. To avoid these issues, we propose an efficient logical layer-based reconciliation method for two-way CVQKD to extract binary information from correlated Gaussian variables. We demonstrate that by operating on the raw-data level, the noise of the quantum channel can be corrected in the scalar space and the reconciliation can be extended to arbitrary high dimensions. We prove that the error probability of scalar reconciliation is zero in any practical CVQKD scenario, and provides unconditional security. The results allow to significantly improve the currently available key rates and transmission distances of two-way CVQKD. The proposed scalar reconciliation can also be applied in one-way systems as well, to replace the existing reconciliation schemes.',
	 'authors': u'Laszlo Gyongyosi,',
	 'category': u'Computer Science ',
	 'date': '2013-8-6',
	 'pdflink': u'http://arxiv.org/pdf/1308.1391',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nScalar Reconciliation for Gaussian Modulation of Two-Way  Continuous-Variable Quantum Key Distribution',
	 'urllink': u'http://arxiv.org/abs/1308.1391'}
2015-03-24 02:25:09+0000 [xxu46_7] INFO: Crawled 175 pages (at 1 pages/min), scraped 168 items (at 1 items/min)
2015-03-24 02:26:09+0000 [xxu46_7] INFO: Crawled 175 pages (at 0 pages/min), scraped 168 items (at 0 items/min)
2015-03-24 02:26:45+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.1324> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:26:45+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.1324>
	{'abstract': u'In Diagonally Non-Computable Functions and Bi-Immunity, Carl Jockusch and Andrew Lewis proved that every DNC function computes a bi-immune set. They asked whether every DNC function computes an effectively bi-immune set. We construct a DNC function that computes no effectively bi-immune set, thereby answering their question in the negative.',
	 'authors': u'Achilles A. Beros,',
	 'category': u'Computer Science ',
	 'date': '2013-8-6',
	 'pdflink': u'http://arxiv.org/pdf/1308.1324',
	 'subjects': u'Logic (math.LO)',
	 'title': u'\nA DNC function that computes no effectively bi-immune set',
	 'urllink': u'http://arxiv.org/abs/1308.1324'}
2015-03-24 02:27:09+0000 [xxu46_7] INFO: Crawled 176 pages (at 1 pages/min), scraped 169 items (at 1 items/min)
2015-03-24 02:28:09+0000 [xxu46_7] INFO: Crawled 176 pages (at 0 pages/min), scraped 169 items (at 0 items/min)
2015-03-24 02:28:44+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.1257> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:28:44+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.1257>
	{'abstract': u'We analyze information diffusion using empirical data that tracks online communication around two instances of mass political mobilization, including the year that lapsed in-between the protests. We compare the global properties of the topological and dynamic networks through which communication took place as well as local changes in network composition. We show that changes in network structure underlie aggregated differences on how information diffused: an increase in network hierarchy is accompanied by a reduction in the average size of cascades. The increasing hierarchy affects not only the underlying communication topology but also the more dynamic structure of information exchange; the increase is especially noticeable amongst certain categories of nodes (or users). This suggests that the relationship between the structure of networks and their function in diffusing information is not as straightforward as some theoretical models of diffusion in networks imply.',
	 'authors': u'Raquel A. Ba\xf1os, Javier Borge-Holthoefer, Ning Wang, Yamir Moreno, Sandra Gonz\xe1lez-Bail\xf3n,',
	 'category': u'Computer Science ',
	 'date': '2013-8-6',
	 'pdflink': u'http://arxiv.org/pdf/1308.1257',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nDiffusion Dynamics with Changing Network Composition',
	 'urllink': u'http://arxiv.org/abs/1308.1257'}
2015-03-24 02:29:09+0000 [xxu46_7] INFO: Crawled 177 pages (at 1 pages/min), scraped 170 items (at 1 items/min)
2015-03-24 02:30:09+0000 [xxu46_7] INFO: Crawled 177 pages (at 0 pages/min), scraped 170 items (at 0 items/min)
2015-03-24 02:30:19+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.1247> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:30:19+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.1247>
	{'abstract': u"Over the next ten years, the physics reach of the Large Hadron Collider (LHC) at the European Organization for Nuclear Research (CERN) will be greatly extended through increases in the instantaneous luminosity of the accelerator and large increases in the amount of collected data. Due to changes in the way Moore's Law computing performance gains have been realized in the past decade, an aggressive program of R&amp;D is needed to ensure that the computing capability of CMS will be up to the task of collecting and analyzing this data.",
	 'authors': u'Peter Elmer, Salvatore Rappoccio, Kevin Stenson, Peter Wittich,',
	 'category': u'Computer Science ',
	 'date': '2013-8-6',
	 'pdflink': u'http://arxiv.org/pdf/1308.1247',
	 'subjects': u'High Energy Physics - Experiment (hep-ex)',
	 'title': u'\nThe Need for an R&D and Upgrade Program for CMS Software and Computing',
	 'urllink': u'http://arxiv.org/abs/1308.1247'}
2015-03-24 02:31:09+0000 [xxu46_7] INFO: Crawled 178 pages (at 1 pages/min), scraped 171 items (at 1 items/min)
2015-03-24 02:31:21+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.1147> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:31:21+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.1147>
	{'abstract': u'We consider the random design regression model with square loss. We propose a method that aggregates empirical minimizers (ERM) over appropriately chosen random subsets and reduces to ERM in the extreme case, and we establish sharp oracle inequalities for its risk. We show that, under the growth of the empirical -entropy, the excess risk of the proposed method attains the rate for and for where is the sample size. Furthermore, for , the excess risk rate matches the behavior of the minimax risk of function estimation in regression problems under the well-specified model. This yields a conclusion that the rates of statistical estimation in well-specified models (minimax risk) and in misspecified models (minimax regret) are equivalent in the regime . In other words, for the problem of statistical learning enjoys the same minimax rate as the problem of statistical estimation. On the contrary, for we show that the rates of the minimax regret are, in general, slower than for the minimax risk. Our oracle inequalities also imply the rates for Vapnik-Chervonenkis type classes of dimension without the usual convexity assumption on the class; we show that these rates are optimal. Finally, for a slightly modified method, we derive a bound on the excess risk of -sparse convex aggregation improving that of (Lounici 07) and providing the optimal rate.',
	 'authors': u'Alexander Rakhlin, Karthik Sridharan, Alexandre B. Tsybakov,',
	 'category': u'Computer Science ',
	 'date': '2013-8-6',
	 'pdflink': u'http://arxiv.org/pdf/1308.1147',
	 'subjects': u'Statistics Theory (math.ST)',
	 'title': u'\nEmpirical Entropy, Minimax Regret and Minimax Risk',
	 'urllink': u'http://arxiv.org/abs/1308.1147'}
2015-03-24 02:32:09+0000 [xxu46_7] INFO: Crawled 179 pages (at 1 pages/min), scraped 172 items (at 1 items/min)
2015-03-24 02:33:09+0000 [xxu46_7] INFO: Crawled 179 pages (at 0 pages/min), scraped 172 items (at 0 items/min)
2015-03-24 02:33:15+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.1084> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:33:15+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.1084>
	{'abstract': u'We give a characterization of vertex-monotone properties with sharp thresholds in a Poisson random geometric graph or hypergraph. As an application we show that a geometric model of random k-SAT exhibits a sharp threshold for satisfiability.',
	 'authors': u'Milan Bradonji\u0107, Will Perkins,',
	 'category': u'Computer Science ',
	 'date': '2013-8-5',
	 'pdflink': u'http://arxiv.org/pdf/1308.1084',
	 'subjects': u'Probability (math.PR)',
	 'title': u'\nOn Sharp Thresholds in Random Geometric Graphs',
	 'urllink': u'http://arxiv.org/abs/1308.1084'}
2015-03-24 02:34:09+0000 [xxu46_7] INFO: Crawled 180 pages (at 1 pages/min), scraped 173 items (at 1 items/min)
2015-03-24 02:34:55+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.1066> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:34:55+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.1066>
	{'abstract': u'Adaptive trials are now mainstream science. Recently, researchers have taken the adaptive trial concept to its natural conclusion, proposing what we call "Global Cumulative Treatment Analysis" (GCTA). Similar to the adaptive trial, decision making and data collection and analysis in the GCTA are continuous and integrated, and treatments are ranked in accord with the statistics of this information, combined with what offers the most information gain. Where GCTA differs from an adaptive trial, or, for that matter, from any trial design, is that all patients are implicitly participants in the GCTA process, regardless of whether they are formally enrolled in a trial. This paper discusses some of the theoretical and practical issues that arise in the design of a GCTA, along with some preliminary thoughts on how they might be approached.',
	 'authors': u'Jeff Shrager,',
	 'category': u'Computer Science ',
	 'date': '2013-8-5',
	 'pdflink': u'http://arxiv.org/pdf/1308.1066',
	 'subjects': u'Applications (stat.AP)',
	 'title': u'\nTheoretical Issues for Global Cumulative Treatment Analysis (GCTA)',
	 'urllink': u'http://arxiv.org/abs/1308.1066'}
2015-03-24 02:35:09+0000 [xxu46_7] INFO: Crawled 181 pages (at 1 pages/min), scraped 174 items (at 1 items/min)
2015-03-24 02:36:09+0000 [xxu46_7] INFO: Crawled 181 pages (at 0 pages/min), scraped 174 items (at 0 items/min)
2015-03-24 02:36:52+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.0994> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:36:52+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.0994>
	{'abstract': u'The boxdot conjecture asserts that every normal modal logic that faithfully interprets T by the well-known boxdot translation is in fact included in T. We confirm that the conjecture is true. More generally, we present a simple semantic condition on modal logics which ensures that the largest logic where embeds faithfully by the boxdot translation is itself. In particular, this natural generalization of the boxdot conjecture holds for S4, S5, and KTB in place of T.',
	 'authors': u'Emil Je\u0159\xe1bek,',
	 'category': u'Computer Science ',
	 'date': '2013-8-5',
	 'pdflink': u'http://arxiv.org/pdf/1308.0994',
	 'subjects': u'Logic (math.LO)',
	 'title': u'\nCluster expansion and the boxdot conjecture',
	 'urllink': u'http://arxiv.org/abs/1308.0994'}
2015-03-24 02:37:09+0000 [xxu46_7] INFO: Crawled 182 pages (at 1 pages/min), scraped 175 items (at 1 items/min)
2015-03-24 02:38:09+0000 [xxu46_7] INFO: Crawled 182 pages (at 0 pages/min), scraped 175 items (at 0 items/min)
2015-03-24 02:38:43+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.0900> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:38:43+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.0900>
	{'abstract': u'We devise a USDCHF trading strategy using the dynamics of gold as a filter. Our strategy involves modelling both USDCHF and gold using a coupled hidden Markov model (CHMM). The observations will be indicators, RSI and CCI, which will be used as triggers for our trading signals. Upon decoding the model in each iteration, we can get the next most probable state and the next most probable observation. Hopefully by taking advantage of intermarket analysis and the Markov property implicit in the model, trading with these most probable values will produce profitable results.',
	 'authors': u'Donny Lee,',
	 'category': u'Computer Science ',
	 'date': '2013-8-5',
	 'pdflink': u'http://arxiv.org/pdf/1308.0900',
	 'subjects': u'Machine Learning (stat.ML)',
	 'title': u'\nTrading USDCHF filtered by Gold dynamics via HMM coupling',
	 'urllink': u'http://arxiv.org/abs/1308.0900'}
2015-03-24 02:39:09+0000 [xxu46_7] INFO: Crawled 183 pages (at 1 pages/min), scraped 176 items (at 1 items/min)
2015-03-24 02:39:42+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.0892> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:39:42+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.0892>
	{'abstract': u"We consider three problems about cities from Alcuin's_Propositiones ad acuendos juvenes_. These problems can be considered as the earliest packing problems difficult also for modern state-of-the-art packing algorithms. We discuss the Alcuin's solutions and give the known (to the author) best solutions to these problems.",
	 'authors': u'Nikolai Yu. Zolotykh,',
	 'category': u'Computer Science ',
	 'date': '2013-8-5',
	 'pdflink': u'http://arxiv.org/pdf/1308.0892',
	 'subjects': u'History and Overview (math.HO)',
	 'title': u"\nAlcuin's Propositiones de Civitatibus: the Earliest Packing Problems",
	 'urllink': u'http://arxiv.org/abs/1308.0892'}
2015-03-24 02:40:09+0000 [xxu46_7] INFO: Crawled 184 pages (at 1 pages/min), scraped 177 items (at 1 items/min)
2015-03-24 02:41:06+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.0843> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:41:06+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.0843>
	{'abstract': u"Snowmass is a US long-term planning study for the high-energy community by the American Physical Society's Division of Particles and Fields. For its simulation studies, opportunistic resources are harnessed using the Open Science Grid infrastructure. Late binding grid technology, GlideinWMS, was used for distributed scheduling of the simulation jobs across many sites mainly in the US. The pilot infrastructure also uses the Parrot mechanism to dynamically access CvmFS in order to ascertain a homogeneous environment across the nodes. This report presents the resource usage and the storage model used for simulating large statistics Standard Model backgrounds needed for Snowmass Energy Frontier studies.",
	 'authors': u'A. Avetisyan, S. Bhattacharya, M. Narain, S. Padhi, J. Hirschauer, T. Levshina, P. McBride, C. Sehgal, M. Slyz, M. Rynge, S. Malik, J. Stupak III,',
	 'category': u'Computer Science ',
	 'date': '2013-8-4',
	 'pdflink': u'http://arxiv.org/pdf/1308.0843',
	 'subjects': u'High Energy Physics - Experiment (hep-ex)',
	 'title': u'\nSnowmass Energy Frontier Simulations using the Open Science Grid (A  Snowmass 2013 whitepaper)',
	 'urllink': u'http://arxiv.org/abs/1308.0843'}
2015-03-24 02:41:09+0000 [xxu46_7] INFO: Crawled 185 pages (at 1 pages/min), scraped 178 items (at 1 items/min)
2015-03-24 02:42:09+0000 [xxu46_7] INFO: Crawled 185 pages (at 0 pages/min), scraped 178 items (at 0 items/min)
2015-03-24 02:43:05+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.0833> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:43:05+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.0833>
	{'abstract': u"This survey summarizes several results about quantum computing related to (mostly static) data structures. First, we describe classical data structures for the set membership and the predecessor search problems: Perfect Hash tables for set membership by Fredman, Koml 's and Szemer 'di and a data structure by Beame and Fich for predecessor search. We also prove results about their space complexity (how many bits are required) and time complexity (how many bits have to be read to answer a query). After that, we turn our attention to classical data structures with quantum access. In the quantum access model, data is stored in classical bits, but they can be accessed in a quantum way: We may read several bits in superposition for unit cost. We give proofs for lower bounds in this setting that show that the classical data structures from the first section are, in some sense, asymptotically optimal - even in the quantum model. In fact, these proofs are simpler and give stronger results than previous proofs for the classical model of computation. The lower bound for set membership was proved by Radhakrishnan, Sen and Venkatesh and the result for the predecessor problem by Sen and Venkatesh. Finally, we examine fully quantum data structures. Instead of encoding the data in classical bits, we now encode it in qubits. We allow any unitary operation or measurement in order to answer queries. We describe one data structure by de Wolf for the set membership problem and also a general framework using fully quantum data structures in quantum walks by Jeffery, Kothari and Magniez.",
	 'authors': u'Maximilian Fillinger,',
	 'category': u'Computer Science ',
	 'date': '2013-8-4',
	 'pdflink': u'http://arxiv.org/pdf/1308.0833',
	 'subjects': u'Quantum Physics (quant-ph)',
	 'title': u'\nData Structures in Classical and Quantum Computing',
	 'urllink': u'http://arxiv.org/abs/1308.0833'}
2015-03-24 02:43:09+0000 [xxu46_7] INFO: Crawled 186 pages (at 1 pages/min), scraped 179 items (at 1 items/min)
2015-03-24 02:44:09+0000 [xxu46_7] INFO: Crawled 186 pages (at 0 pages/min), scraped 179 items (at 0 items/min)
2015-03-24 02:45:01+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.0827> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:45:01+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.0827>
	{'abstract': u'Fix g&gt;1. Every graph of large enough tree-width contains a g x g grid as a minor; but here we prove that every four-edge-connected graph of large enough tree-width contains a g x g grid as an immersion (and hence contains any fixed graph with maximum degree at most four as an immersion). This result has a number of applications.',
	 'authors': u'Maria Chudnovsky, Zden\u011bk Dvo\u0159\xe1k, Tereza Klimo\u0161ov\xe1, Paul Seymour,',
	 'category': u'Computer Science ',
	 'date': '2013-8-4',
	 'pdflink': u'http://arxiv.org/pdf/1308.0827',
	 'subjects': u'Combinatorics (math.CO)',
	 'title': u'\nImmersion in four-edge-connected graphs',
	 'urllink': u'http://arxiv.org/abs/1308.0827'}
2015-03-24 02:45:09+0000 [xxu46_7] INFO: Crawled 187 pages (at 1 pages/min), scraped 180 items (at 1 items/min)
2015-03-24 02:46:09+0000 [xxu46_7] INFO: Crawled 187 pages (at 0 pages/min), scraped 180 items (at 0 items/min)
2015-03-24 02:46:40+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.0801> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:46:40+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.0801>
	{'abstract': u"In this paper we study the relationship between a very classical algebraic object associated to a filtration of spaces, namely a spectral sequence introduced by Leray in the 1940's, and a more recently invented object that has found many applications -- namely, its persistent homology groups. We show the existence of a long exact sequence of groups linking these two objects and using it derive formulas expressing the dimensions of each individual groups of one object in terms of the dimensions of the groups in the other object. The main tool used to mediate between these objects is the notion of exact couples first introduced by Massey in 1952.",
	 'authors': u'Saugata Basu, Laxmi Parida,',
	 'category': u'Computer Science ',
	 'date': '2013-8-4',
	 'pdflink': u'http://arxiv.org/pdf/1308.0801',
	 'subjects': u'Algebraic Topology (math.AT)',
	 'title': u'\nSpectral Sequences, Exact Couples and Persistent Homology of filtrations',
	 'urllink': u'http://arxiv.org/abs/1308.0801'}
2015-03-24 02:47:09+0000 [xxu46_7] INFO: Crawled 188 pages (at 1 pages/min), scraped 181 items (at 1 items/min)
2015-03-24 02:48:09+0000 [xxu46_7] INFO: Crawled 188 pages (at 0 pages/min), scraped 181 items (at 0 items/min)
2015-03-24 02:48:11+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.0729> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:48:11+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.0729>
	{'abstract': u'Homotopy type theory is a new branch of mathematics, based on a recently discovered connection between homotopy theory and type theory, which brings new ideas into the very foundation of mathematics. On the one hand, Voevodsky\'s subtle and beautiful "univalence axiom" implies that isomorphic structures can be identified. On the other hand, "higher inductive types" provide direct, logical descriptions of some of the basic spaces and constructions of homotopy theory. Both are impossible to capture directly in classical set-theoretic foundations, but when combined in homotopy type theory, they permit an entirely new kind of "logic of homotopy types". This suggests a new conception of foundations of mathematics, with intrinsic homotopical content, an "invariant" conception of the objects of mathematics -- and convenient machine implementations, which can serve as a practical aid to the working mathematician. This book is intended as a first systematic exposition of the basics of the resulting "Univalent Foundations" program, and a collection of examples of this new style of reasoning -- but without requiring the reader to know or learn any formal logic, or to use any computer proof assistant.',
	 'authors': u'Univalent Foundations Program,',
	 'category': u'Computer Science ',
	 'date': '2013-8-3',
	 'pdflink': u'http://arxiv.org/pdf/1308.0729',
	 'subjects': u'Logic (math.LO)',
	 'title': u'\nHomotopy Type Theory: Univalent Foundations of Mathematics',
	 'urllink': u'http://arxiv.org/abs/1308.0729'}
2015-03-24 02:49:09+0000 [xxu46_7] INFO: Crawled 189 pages (at 1 pages/min), scraped 182 items (at 1 items/min)
2015-03-24 02:50:09+0000 [xxu46_7] INFO: Crawled 189 pages (at 0 pages/min), scraped 182 items (at 0 items/min)
2015-03-24 02:50:09+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.0726> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:50:09+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.0726>
	{'abstract': u'What makes economic and ecological networks so unlike other highly skewed networks in their tendency toward turbulence and collapse? Here, we explore the consequences of a defining feature of these networks: their nodes are tied together by flow. We show that flow networks tend to the power law degree distribution (PLDD) due to a self-reinforcing process involving position within the global network structure, and thus present the first random graph model for PLDDs that does not depend on a rich-get-richer function of nodal degree. We also show that in contrast to non-flow networks, PLDD flow networks are dramatically more vulnerable to catastrophic failure than non-PLDD flow networks, a finding with potential explanatory power in our age of resource- and financial-interdependence and turbulence.',
	 'authors': u'Jesse Shore, Catherine J. Chu, Matt T. Bianchi,',
	 'category': u'Computer Science ',
	 'date': '2013-8-3',
	 'pdflink': u'http://arxiv.org/pdf/1308.0726',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nPower Laws and Fragility in Flow Networks',
	 'urllink': u'http://arxiv.org/abs/1308.0726'}
2015-03-24 02:51:09+0000 [xxu46_7] INFO: Crawled 190 pages (at 1 pages/min), scraped 183 items (at 1 items/min)
2015-03-24 02:51:10+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.0723> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:51:10+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.0723>
	{'abstract': u'The increasing availability of temporal network data is calling for more research on extracting and characterizing mesoscopic structures in temporal networks and on relating such structure to specific functions or properties of the system. An outstanding challenge is the extension of the results achieved for static networks to time-varying networks, where the topological structure of the system and the temporal activity patterns of its components are intertwined. Here we investigate the use of a latent factor decomposition technique, non-negative tensor factorization, to extract the community-activity structure of temporal networks. The method is intrinsically temporal and allows to simultaneously identify communities and to track their activity over time. We represent the time-varying adjacency matrix of a temporal network as a three-way tensor and approximate this tensor as a sum of terms that can be interpreted as communities of nodes with an associated activity time series. We summarize known computational techniques for tensor decomposition and discuss some quality metrics that can be used to tune the complexity of the factorized representation. We subsequently apply tensor factorization to a temporal network for which a ground truth is available for both the community structure and the temporal activity patterns. The data we use describe the social interactions of students in a school, the associations between students and school classes, and the spatio-temporal trajectories of students over time. We show that non-negative tensor factorization is capable of recovering the class structure with high accuracy. In particular, the extracted tensor components can be validated either as known school classes, or in terms of correlated activity patterns, i.e., of spatial and temporal coincidences that are determined by the known school activity schedule.',
	 'authors': u'Laetitia Gauvin, Andr\xe9 Panisson, Ciro Cattuto,',
	 'category': u'Computer Science ',
	 'date': '2013-8-3',
	 'pdflink': u'http://arxiv.org/pdf/1308.0723',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nDetecting the community structure and activity patterns of temporal  networks: a non-negative tensor factorization approach',
	 'urllink': u'http://arxiv.org/abs/1308.0723'}
2015-03-24 02:52:09+0000 [xxu46_7] INFO: Crawled 191 pages (at 1 pages/min), scraped 184 items (at 1 items/min)
2015-03-24 02:53:07+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.0586> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:53:07+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.0586>
	{'abstract': u'It is well know that for globally contractive autonomous systems, there exists a unique equilibrium and the distance to the equilibrium evaluated along any trajectory decreases exponentially with time. We show that, additionally, the magnitude of the velocity evaluated along any trajectory decreases exponentially, thus giving an alternative choice of Lyapunov function.',
	 'authors': u'Samuel Coogan, Murat Arcak,',
	 'category': u'Computer Science ',
	 'date': '2013-7-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.0586',
	 'subjects': u'Dynamical Systems (math.DS)',
	 'title': u'\nA note on norm-based Lyapunov functions via contraction analysis',
	 'urllink': u'http://arxiv.org/abs/1308.0586'}
2015-03-24 02:53:09+0000 [xxu46_7] INFO: Crawled 192 pages (at 1 pages/min), scraped 185 items (at 1 items/min)
2015-03-24 02:54:09+0000 [xxu46_7] INFO: Crawled 192 pages (at 0 pages/min), scraped 185 items (at 0 items/min)
2015-03-24 02:55:02+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.0376> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:55:02+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.0376>
	{'abstract': u'We report a calculation reduction method for color computer-generated holograms (CGHs) using color space conversion. Color CGHs are generally calculated on RGB space. In this paper, we calculate color CGHs in other color spaces: for example, YCbCr color space. In YCbCr color space, a RGB image is converted to the luminance component (Y), blue-difference chroma (Cb) and red-difference chroma (Cr) components. In terms of the human eye, although the negligible difference of the luminance component is well-recognized, the difference of the other components is not. In this method, the luminance component is normal sampled and the chroma components are down-sampled. The down-sampling allows us to accelerate the calculation of the color CGHs. We compute diffraction calculations from the components, and then we convert the diffracted results in YCbCr color space to RGB color space.',
	 'authors': u'Tomoyoshi Shimobaba, Takashi Kakue, Minoru Oikawa, Naoki Takada, Naohisa Okada, Yutaka Endo, Ryuji Hirayama, Tomoyoshi Ito,',
	 'category': u'Computer Science ',
	 'date': '2013-8-1',
	 'pdflink': u'http://arxiv.org/pdf/1308.0376',
	 'subjects': u'Optics (physics.optics)',
	 'title': u'\nCalculation reduction method for color computer-generated hologram using  color space conversion',
	 'urllink': u'http://arxiv.org/abs/1308.0376'}
2015-03-24 02:55:09+0000 [xxu46_7] INFO: Crawled 193 pages (at 1 pages/min), scraped 186 items (at 1 items/min)
2015-03-24 02:56:09+0000 [xxu46_7] INFO: Crawled 193 pages (at 0 pages/min), scraped 186 items (at 0 items/min)
2015-03-24 02:56:31+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.0247> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:56:31+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.0247>
	{'abstract': u'In this paper we present a novel termination order the (PLPO for short), a syntactic restriction of the lexicographic path order. As well as lexicographic path orders, several non-trivial primitive recursive equations, e.g., primitive recursion with parameter substitution, unnested multiple recursion, or simple nested recursion, can be oriented with PLPOs. It can be shown that the PLPO however only induces primitive recursive upper bounds on derivation lengths of compatible rewrite systems. This yields an alternative proof of a classical fact that the class of primitive recursive functions is closed under those non-trivial primitive recursive equations.',
	 'authors': u'Naohi Eguchi,',
	 'category': u'Computer Science ',
	 'date': '2013-8-1',
	 'pdflink': u'http://arxiv.org/pdf/1308.0247',
	 'subjects': u'Logic (math.LO)',
	 'title': u'\nPredicative Lexicographic Path Orders: An Application of Term Rewriting  to the Region of Primitive Recursive Functions',
	 'urllink': u'http://arxiv.org/abs/1308.0247'}
2015-03-24 02:57:09+0000 [xxu46_7] INFO: Crawled 194 pages (at 1 pages/min), scraped 187 items (at 1 items/min)
2015-03-24 02:58:01+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.0239> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:58:01+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.0239>
	{'abstract': u"Contemporary collective action, much of which involves social media and other Internet-based platforms, leaves a digital imprint which may be harvested to better understand the dynamics of mobilization. Petition signing is an example of collective action which has gained in popularity with rising use of social media and provides such data for the whole population of petition signatories for a given platform. This paper tracks the growth curves of all 20,000 petitions to the UK government over 18 months, analyzing the rate of growth and outreach mechanism. Previous research has suggested the importance of the first day to the ultimate success of a petition, but has not examined early growth within that day, made possible here through hourly resolution in the data. The analysis shows that the vast majority of petitions do not achieve any measure of success; over 99 percent fail to get the 10,000 signatures required for an official response and only 0.1 percent attain the 100,000 required for a parliamentary debate. We analyze the data through a multiplicative process model framework to explain the heterogeneous growth of signatures at the population level. We define and measure an average outreach factor for petitions and show that it decays very fast (reducing to 0.1% after 10 hours). After 24 hours, a petition's fate is virtually set. The findings seem to challenge conventional analyses of collective action from economics and political science, where the production function has been assumed to follow an S-shaped curve.",
	 'authors': u'Taha Yasseri, Scott A. Hale, Helen Margetts,',
	 'category': u'Computer Science ',
	 'date': '2013-8-1',
	 'pdflink': u'http://arxiv.org/pdf/1308.0239',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nModeling the Rise in Internet-based Petitions',
	 'urllink': u'http://arxiv.org/abs/1308.0239'}
2015-03-24 02:58:09+0000 [xxu46_7] INFO: Crawled 195 pages (at 1 pages/min), scraped 188 items (at 1 items/min)
2015-03-24 02:59:09+0000 [xxu46_7] INFO: Crawled 195 pages (at 0 pages/min), scraped 188 items (at 0 items/min)
2015-03-24 02:59:32+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.0174> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 02:59:32+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.0174>
	{'abstract': u'Blackouts in power grids typically result from cascading failures. The key importance of the electric power grid to society encourages further research into sustaining power system reliability and developing new methods to manage the risks of cascading blackouts. Adequate software tools are required to better analyze, understand, and assess the consequences of the cascading failures. This paper presents MATCASC, an open source MATLAB based tool to analyse cascading failures in power grids. Cascading effects due to line overload outages are considered. The applicability of the MATCASC tool is demonstrated by assessing the robustness of IEEE test systems and real-world power grids with respect to cascading failures.',
	 'authors': u'Yakup Ko\xe7, Trivik Verma, Nuno A. M. Araujo, Martijn Warnier,',
	 'category': u'Computer Science ',
	 'date': '2013-8-1',
	 'pdflink': u'http://arxiv.org/pdf/1308.0174',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nMATCASC: A tool to analyse cascading line outages in power grids',
	 'urllink': u'http://arxiv.org/abs/1308.0174'}
2015-03-24 03:00:09+0000 [xxu46_7] INFO: Crawled 196 pages (at 1 pages/min), scraped 189 items (at 1 items/min)
2015-03-24 03:01:09+0000 [xxu46_7] INFO: Crawled 196 pages (at 0 pages/min), scraped 189 items (at 0 items/min)
2015-03-24 03:01:18+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.0168> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:01:18+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.0168>
	{'abstract': u"We present a cut elimination argument that witnesses the conservativity of the compositional axioms for truth (without the extended induction axiom) over any theory interpreting a weak subsystem of arithmetic. In doing so we also fix a critical error in Halbach's original presentation. Our methods show that the admission of these axioms determines a hyper-exponential reduction in the size of derivations of truth-free statements.",
	 'authors': u'Graham E. Leigh,',
	 'category': u'Computer Science ',
	 'date': '2013-8-1',
	 'pdflink': u'http://arxiv.org/pdf/1308.0168',
	 'subjects': u'Logic (math.LO)',
	 'title': u'\nConservativity for theories of compositional truth via cut elimination',
	 'urllink': u'http://arxiv.org/abs/1308.0168'}
2015-03-24 03:02:09+0000 [xxu46_7] INFO: Crawled 197 pages (at 1 pages/min), scraped 190 items (at 1 items/min)
2015-03-24 03:03:09+0000 [xxu46_7] INFO: Crawled 197 pages (at 0 pages/min), scraped 190 items (at 0 items/min)
2015-03-24 03:03:13+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.0104> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:03:13+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.0104>
	{'abstract': u'We propose an eigenvalue based technique to solve the Homogeneous Quadratic Constrained Quadratic Programming problem (HQCQP) with at most 3 constraints which arise in many signal processing problems. Semi-Definite Relaxation (SDR) is the only known approach and is computationally intensive. We study the performance of the proposed fast eigen approach through simulations in the context of MIMO relays and show that the solution converges to the solution obtained using the SDR approach with significant reduction in complexity.',
	 'authors': u'Dinesh Dileep Gaurav, K.V.S. Hari,',
	 'category': u'Computer Science ',
	 'date': '2013-8-1',
	 'pdflink': u'http://arxiv.org/pdf/1308.0104',
	 'subjects': u'Numerical Analysis (math.NA)',
	 'title': u'\nA Fast Eigen Solution for Homogeneous Quadratic Minimization with at  most Three Constraints',
	 'urllink': u'http://arxiv.org/abs/1308.0104'}
2015-03-24 03:04:09+0000 [xxu46_7] INFO: Crawled 198 pages (at 1 pages/min), scraped 191 items (at 1 items/min)
2015-03-24 03:05:06+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.0075> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:05:06+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.0075>
	{'abstract': u"A new ESPRIT-based algorithm is proposed to estimate the direction-of-arrival of an arbitrary degree polynomial-phase signal with a single acoustic vector sensor. The proposed approach requires neither a priori knowledge of the polynomial-phase signal's coefficients nor a priori knowledge of the polynomial-phase signal's frequency-spectrum. A pre-processing technique is also proposed to incorporate the single-forgetting-factor algorithm and multiple-forgetting-factor adaptive tracking algorithm to track a polynomial-phase signal using one acoustic vector sensor. Simulation results verify the efficacy of the proposed direction finding and source tracking algorithms.",
	 'authors': u'Xin Yuan,',
	 'category': u'Computer Science ',
	 'date': '2013-8-1',
	 'pdflink': u'http://arxiv.org/pdf/1308.0075',
	 'subjects': u'Applications (stat.AP)',
	 'title': u'\nPolynomial-Phase Signal Direction-Finding & Source-Tracking with an  Acoustic Vector Sensor',
	 'urllink': u'http://arxiv.org/abs/1308.0075'}
2015-03-24 03:05:09+0000 [xxu46_7] INFO: Crawled 199 pages (at 1 pages/min), scraped 192 items (at 1 items/min)
2015-03-24 03:06:09+0000 [xxu46_7] INFO: Crawled 199 pages (at 0 pages/min), scraped 192 items (at 0 items/min)
2015-03-24 03:07:07+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.0068> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:07:07+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.0068>
	{'abstract': u"The movement of data (communication) between levels of a memory hierarchy, or between parallel processors on a network, can greatly dominate the cost of computation, so algorithms that minimize communication are of interest. Motivated by this, attainable lower bounds for the amount of communication required by algorithms were established by several groups for a variety of algorithms, including matrix computations. Prior work of Ballard-Demmel-Holtz-Schwartz relied on a geometric inequality of Loomis and Whitney for this purpose. In this paper the general theory of discrete multilinear Holder-Brascamp-Lieb (HBL) inequalities is used to establish communication lower bounds for a much wider class of algorithms. In some cases, algorithms are presented which attain these lower bounds. Several contributions are made to the theory of HBL inequalities proper. The optimal constant in such an inequality for torsion-free Abelian groups is shown to equal one whenever it is finite. Bennett-Carbery-Christ-Tao had characterized the tuples of exponents for which such an inequality is valid as the convex polyhedron defined by a certain finite list of inequalities. The problem of constructing an algorithm to decide whether a given inequality is on this list, is shown to be equivalent to Hilbert's Tenth Problem over the rationals, which remains open. Nonetheless, an algorithm which computes the polyhedron itself is constructed.",
	 'authors': u'Michael Christ, James Demmel, Nicholas Knight, Thomas Scanlon, Katherine Yelick,',
	 'category': u'Computer Science ',
	 'date': '2013-8-1',
	 'pdflink': u'http://arxiv.org/pdf/1308.0068',
	 'subjects': u'Classical Analysis and ODEs (math.CA)',
	 'title': u'\nCommunication lower bounds and optimal algorithms for programs that  reference arrays -- Part 1',
	 'urllink': u'http://arxiv.org/abs/1308.0068'}
2015-03-24 03:07:09+0000 [xxu46_7] INFO: Crawled 200 pages (at 1 pages/min), scraped 193 items (at 1 items/min)
2015-03-24 03:08:09+0000 [xxu46_7] INFO: Crawled 200 pages (at 0 pages/min), scraped 193 items (at 0 items/min)
2015-03-24 03:08:52+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.0029> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:08:52+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.0029>
	{'abstract': u'Hierarchy is one of the most conspicuous features of numerous natural, technological and social systems. The underlying structures are typically complex and their most relevant organizational principle is the ordering of the ties among the units they are made of according to a network displaying hierarchical features. In spite of the abundant presence of hierarchy no quantitative theoretical interpretation of the origins of a multi-level, knowledge-based social network exists. Here we introduce an approach which is capable of reproducing the emergence of a multi-levelled network structure based on the plausible assumption that the individuals (representing the nodes of the network) can make the right estimate about the state of their changing environment to a varying degree. Our model accounts for a fundamental feature of knowledge-based organizations: the less capable individuals tend to follow those who are better at solving the problems they all face. We find that relatively simple rules lead to hierarchical self-organization and the specific structures we obtain possess the two, perhaps most important features of complex systems: a simultaneous presence of adaptability and stability. In addition, the performance (success score) of the emerging networks is significantly higher than the average expected score of the individuals without letting them copy the decisions of the others. The results of our calculations are in agreement with a related experiment and can be useful from the point of designing the optimal conditions for constructing a given complex social structure as well as understanding the hierarchical organization of such biological structures of major importance as the regulatory pathways or the dynamics of neural networks.',
	 'authors': u'Tam\xe1s Nepusz, Tam\xe1s Vicsek,',
	 'category': u'Computer Science ',
	 'date': '2013-7-31',
	 'pdflink': u'http://arxiv.org/pdf/1308.0029',
	 'subjects': u'Physics and Society (physics.soc-ph)',
	 'title': u'\nHierarchical self-organization of non-cooperating individuals',
	 'urllink': u'http://arxiv.org/abs/1308.0029'}
2015-03-24 03:09:09+0000 [xxu46_7] INFO: Crawled 201 pages (at 1 pages/min), scraped 194 items (at 1 items/min)
2015-03-24 03:10:09+0000 [xxu46_7] INFO: Crawled 201 pages (at 0 pages/min), scraped 194 items (at 0 items/min)
2015-03-24 03:10:53+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6824> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:10:53+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6824>
	{'abstract': u'We define strict confluent drawing, a form of confluent drawing in which the existence of an edge is indicated by the presence of a smooth path through a system of arcs and junctions (without crossings), and in which such a path, if it exists, must be unique. We prove that it is NP-complete to determine whether a given graph has a strict confluent drawing but polynomial to determine whether it has an outerplanar strict confluent drawing with a fixed vertex ordering (a drawing within a disk, with the vertices placed in a given order on the boundary).',
	 'authors': u'David Eppstein, Danny Holten, Maarten L\xf6ffler, Martin N\xf6llenburg, Bettina Speckmann, Kevin Verbeek,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6824',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nStrict Confluent Drawing',
	 'urllink': u'http://arxiv.org/abs/1308.6824'}
2015-03-24 03:11:09+0000 [xxu46_7] INFO: Crawled 202 pages (at 1 pages/min), scraped 195 items (at 1 items/min)
2015-03-24 03:12:09+0000 [xxu46_7] INFO: Crawled 202 pages (at 0 pages/min), scraped 195 items (at 0 items/min)
2015-03-24 03:12:45+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6823> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:12:45+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6823>
	{'abstract': u'In modern data science problems, techniques for extracting value from big data require performing large-scale optimization over heterogenous, irregularly structured data. Much of this data is best represented as multi-relational graphs, making vertex programming abstractions such as those of Pregel and GraphLab ideal fits for modern large-scale data analysis. In this paper, we describe a vertex-programming implementation of a popular consensus optimization technique known as the alternating direction of multipliers (ADMM). ADMM consensus optimization allows elegant solution of complex objectives such as inference in rich probabilistic models. We also introduce a novel hypergraph partitioning technique that improves over state-of-the-art partitioning techniques for vertex programming and significantly reduces the communication cost by reducing the number of replicated nodes up to an order of magnitude. We implemented our algorithm in GraphLab and measure scaling performance on a variety of realistic bipartite graph distributions and a large synthetic voter-opinion analysis application. In our experiments, we are able to achieve a 50% improvement in runtime over the current state-of-the-art GraphLab partitioning scheme.',
	 'authors': u'Hui Miao, Xiangyang Liu, Bert Huang, Lise Getoor,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6823',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nA Hypergraph-Partitioned Vertex Programming Approach for Large-scale  Consensus Optimization',
	 'urllink': u'http://arxiv.org/abs/1308.6823'}
2015-03-24 03:13:09+0000 [xxu46_7] INFO: Crawled 203 pages (at 1 pages/min), scraped 196 items (at 1 items/min)
2015-03-24 03:14:09+0000 [xxu46_7] INFO: Crawled 203 pages (at 0 pages/min), scraped 196 items (at 0 items/min)
2015-03-24 03:14:26+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6810> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:14:26+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6810>
	{'abstract': u'We propose an axiomatic generic framework for modelling weak memory. We show how to instantiate this framework for SC, TSO, C++ restricted to release-acquire atomics, and Power. For Power, we compare our model to a preceding operational model in which we found a flaw. To do so, we define an operational model that we show equivalent to our axiomatic model. We also propose a model for ARM. Our testing on this architecture revealed a behaviour later acknowledged as a bug by ARM, and more recently 33 additional anomalies. We offer a new simulation tool, called herd, which allows the user to specify the model of his choice in a concise way. Given a specification of a model, the tool becomes a simulator for that model. The tool relies on an axiomatic description; this choice allows us to outperform all previous simulation tools. Additionally, we confirm that verification time is vastly improved, in the case of bounded model-checking. Finally, we put our models in perspective, in the light of empirical data obtained by analysing the C and C++ code of a Debian Linux distribution. We present our new analysis tool, called mole, which explores a piece of code to find the weak memory idioms that it uses.',
	 'authors': u'Jade Alglave, Luc Maranget, Michael Tautschnig,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6810',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nHerding Cats - Modelling, simulation, testing, and data-mining for weak  memory',
	 'urllink': u'http://arxiv.org/abs/1308.6810'}
2015-03-24 03:15:09+0000 [xxu46_7] INFO: Crawled 204 pages (at 1 pages/min), scraped 197 items (at 1 items/min)
2015-03-24 03:16:09+0000 [xxu46_7] INFO: Crawled 204 pages (at 0 pages/min), scraped 197 items (at 0 items/min)
2015-03-24 03:16:23+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6807> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:16:23+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6807>
	{'abstract': u'In earlier work, we showed that it is possible to achieve streaming delay with high probability in a peer-to-peer network, where each peer has as little as four neighbors, while achieving any arbitrary fraction of the maximum possible streaming rate. However, the constant in the delay term becomes rather large as we get closer to the maximum streaming rate. In this paper, we design an alternative pairing and chunk dissemination algorithm that allows us to transmit at the maximum streaming rate while ensuring that all, but a negligible fraction of the peers, receive the data stream with delay with high probability. The result is established by examining the properties of graph formed by the union of two or more random 1-regular digraphs, i.e., directed graphs in which each node has an incoming and an outgoing node degree both equal to one.',
	 'authors': u'Joohwan Kim, R. Srikant,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6807',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nAchieving the Optimal Steaming Capacity and Delay Using Random Regular  Digraphs in P2P Networks',
	 'urllink': u'http://arxiv.org/abs/1308.6807'}
2015-03-24 03:17:09+0000 [xxu46_7] INFO: Crawled 205 pages (at 1 pages/min), scraped 198 items (at 1 items/min)
2015-03-24 03:17:42+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6805> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:17:42+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6805>
	{'abstract': u'Without requiring objects to carry any transceiver, device-free based object tracking provides a promising solution for many localization and tracking systems to monitor non-cooperative objects such as intruders. However, existing device-free solutions mainly use sensors and active RFID tags, which are much more expensive compared to passive tags. In this paper, we propose a novel motion detection and tracking method using passive RFID tags, named Twins. The method leverages a newly observed phenomenon called critical state caused by interference among passive tags. We contribute to both theory and practice of such phenomenon by presenting a new interference model that perfectly explains this phenomenon and using extensive experiments to validate it. We design a practical Twins based intrusion detection scheme and implement a real prototype with commercial off-the-shelf reader and tags. The results show that Twins is effective in detecting the moving object, with low location error of 0.75m in average.',
	 'authors': u'Jinsong Han, Chen Qian, Dan Ma, Xing Wang, Jizhong Zhao, Pengfeng Zhang, Wei Xi, Zhiping Jiang,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6805',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nTwins:Device-free Object Tracking using Passive Tags',
	 'urllink': u'http://arxiv.org/abs/1308.6805'}
2015-03-24 03:18:09+0000 [xxu46_7] INFO: Crawled 206 pages (at 1 pages/min), scraped 199 items (at 1 items/min)
2015-03-24 03:19:09+0000 [xxu46_7] INFO: Crawled 206 pages (at 0 pages/min), scraped 199 items (at 0 items/min)
2015-03-24 03:19:26+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6804> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:19:26+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6804>
	{'abstract': u'Intrinsic isometric shape matching has become the standard approach for pose invariant correspondence estimation among deformable shapes. Most existing approaches assume global consistency, i.e., the metric structure of the whole manifold must not change significantly. While global isometric matching is well understood, only a few heuristic solutions are known for partial matching. Partial matching is particularly important for robustness to topological noise (incomplete data and contacts), which is a common problem in real-world 3D scanner data. In this paper, we introduce a new approach to partial, intrinsic isometric matching. Our method is based on the observation that isometries are fully determined by purely local information: a map of a single point and its tangent space fixes an isometry for both global and the partial maps. From this idea, we develop a new representation for partial isometric maps based on equivalence classes of correspondences between pairs of points and their tangent spaces. From this, we derive a local propagation algorithm that find such mappings efficiently. In contrast to previous heuristics based on RANSAC or expectation maximization, our method is based on a simple and sound theoretical model and fully deterministic. We apply our approach to register partial point clouds and compare it to the state-of-the-art methods, where we obtain significant improvements over global methods for real-world data and stronger guarantees than previous heuristic partial matching algorithms.',
	 'authors': u'Alan Brunton, Michael Wand, Stefanie Wuhrer, Hans-Peter Seidel, Tino Weinkauf,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6804',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nA Low-Dimensional Representation for Robust Partial Isometric  Correspondences Computation',
	 'urllink': u'http://arxiv.org/abs/1308.6804'}
2015-03-24 03:20:09+0000 [xxu46_7] INFO: Crawled 207 pages (at 1 pages/min), scraped 200 items (at 1 items/min)
2015-03-24 03:21:09+0000 [xxu46_7] INFO: Crawled 207 pages (at 0 pages/min), scraped 200 items (at 0 items/min)
2015-03-24 03:21:23+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6801> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:21:23+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6801>
	{'abstract': u'In this paper we study emph. In this new many-to-one model, a horizontal backbone reaches out of each label into the feature-enclosing rectangle. Feature points that need to be connected to this label are linked via vertical line segments to the backbone. We present dynamic programming algorithms for label number and total leader length minimization of crossing-free backbone labelings. When crossings are allowed, we aim to obtain solutions with the minimum number of crossings. This can be achieved efficiently in the case of fixed label order, however, in the case of flexible label order we show that minimizing the number of leader crossings is NP-hard.',
	 'authors': u'Michael A. Bekos, Sabine Cornelsen, Martin Fink, Seokhee Hong, Michael Kaufmann, Martin N\xf6llenburg, Ignaz Rutter, Antonios Symvonis,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6801',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nMany-to-One Boundary Labeling with Backbones',
	 'urllink': u'http://arxiv.org/abs/1308.6801'}
2015-03-24 03:22:09+0000 [xxu46_7] INFO: Crawled 208 pages (at 1 pages/min), scraped 201 items (at 1 items/min)
2015-03-24 03:22:44+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6797> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:22:44+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6797>
	{'abstract': u'Given a set of objects, an online ranking system outputs at each time step a full ranking of the set, observes a feedback of some form and suffers a loss. We study the setting in which the (adversarial) feedback is an element in , and the loss is the position (0th, 1st, 2nd...) of the item in the outputted ranking. More generally, we study a setting in which the feedback is a subset of at most elements in , and the loss is the sum of the positions of those elements. We present an algorithm of expected regret over a time horizon of steps with respect to the best single ranking in hindsight. This improves previous algorithms and analyses either by a factor of either , a factor of or by improving running time from quadratic to per round. We also prove a matching lower bound. Our techniques also imply an improved regret bound for online rank aggregation over the Spearman correlation measure, and to other more complex ranking loss functions.',
	 'authors': u'Nir Ailon,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6797',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nOnline Ranking: Discrete Choice, Spearman Correlation and Other Feedback',
	 'urllink': u'http://arxiv.org/abs/1308.6797'}
2015-03-24 03:23:09+0000 [xxu46_7] INFO: Crawled 209 pages (at 1 pages/min), scraped 202 items (at 1 items/min)
2015-03-24 03:24:09+0000 [xxu46_7] INFO: Crawled 209 pages (at 0 pages/min), scraped 202 items (at 0 items/min)
2015-03-24 03:24:45+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6778> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:24:45+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6778>
	{'abstract': u'We present a simple and versatile formulation of grid-based graph representation problems as an integer linear program (ILP) and a corresponding SAT instance. In a grid-based representation vertices and edges correspond to axis-parallel boxes on an underlying integer grid; boxes can be further constrained in their shapes and interactions by additional problem-specific constraints. We describe a general d-dimensional model for grid representation problems. This model can be used to solve a variety of NP-hard graph problems, including pathwidth, bandwidth, optimum st-orientation, area-minimal (bar-k) visibility representation, boxicity-k graphs and others. We implemented SAT-models for all of the above problems and evaluated them on the Rome graphs collection. The experiments show that our model successfully solves NP-hard problems within few minutes on small to medium-size Rome graphs.',
	 'authors': u'Therese Biedl, Thomas Bl\xe4sius, Benjamin Niedermann, Martin N\xf6llenburg, Roman Prutkin, Ignaz Rutter,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6778',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nUsing ILP/SAT to determine pathwidth, visibility representations, and  other grid-based graph drawings',
	 'urllink': u'http://arxiv.org/abs/1308.6778'}
2015-03-24 03:25:09+0000 [xxu46_7] INFO: Crawled 210 pages (at 1 pages/min), scraped 203 items (at 1 items/min)
2015-03-24 03:26:09+0000 [xxu46_7] INFO: Crawled 210 pages (at 0 pages/min), scraped 203 items (at 0 items/min)
2015-03-24 03:26:31+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6768> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:26:31+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6768>
	{'abstract': u'Tor hidden services allow running Internet services while protecting the location of the servers. Their main purpose is to enable freedom of speech even in situations in which powerful adversaries try to suppress it. However, providing location privacy and client anonymity also makes Tor hidden services an attractive platform for every kind of imaginable shady service. The ease with which Tor hidden services can be set up has spurred a huge growth of anonymously provided Internet services of both types. In this paper we analyse the landscape of Tor hidden services. We have studied Tor hidden services after collecting 39824 hidden service descriptors on 4th of Feb 2013 by exploiting protocol and implementation flaws in Tor: we scanned them for open ports; in the case of HTTP services, we analysed and classified their content. We also estimated the popularity of hidden services by looking at the request rate for hidden service descriptors by clients. We found that while the content of Tor hidden services is rather varied, the most popular hidden services are related to botnets.',
	 'authors': u'Alex Biryukov, Ivan Pustogarov, Fabrice Thill, Ralf-Philipp Weinmann,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6768',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nContent and popularity analysis of Tor hidden services',
	 'urllink': u'http://arxiv.org/abs/1308.6768'}
2015-03-24 03:27:09+0000 [xxu46_7] INFO: Crawled 211 pages (at 1 pages/min), scraped 204 items (at 1 items/min)
2015-03-24 03:28:09+0000 [xxu46_7] INFO: Crawled 211 pages (at 0 pages/min), scraped 204 items (at 0 items/min)
2015-03-24 03:28:18+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6760> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:28:18+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6760>
	{'abstract': u"Digital payment schemes show an ever increasing importance. Out of the countless different schemes available this article focuses on the popular Bitcoin system. The authors provide a description of Bitcoin's unique technological basis and its accompanying ecosystem of users, miners, trading platforms and vendors. Furthermore, this article discusses Bitcoin's currency-like features and the first regulatory actions take in the European Union and in the United States of America.",
	 'authors': u'Artus Krohn-Grimberghe Christoph Sorge,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6760',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nPractical Aspects of the Bitcoin System',
	 'urllink': u'http://arxiv.org/abs/1308.6760'}
2015-03-24 03:29:09+0000 [xxu46_7] INFO: Crawled 212 pages (at 1 pages/min), scraped 205 items (at 1 items/min)
2015-03-24 03:30:09+0000 [xxu46_7] INFO: Crawled 212 pages (at 0 pages/min), scraped 205 items (at 0 items/min)
2015-03-24 03:30:11+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6750> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:30:11+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6750>
	{'abstract': u'In theory coordinated multi-point transmission (CoMP) promises vast gains in spectral efficiency. But industrial field trials show rather disappointing throughput gains, whereby the major limiting factor is proper sharing of channel state information. Many recent papers consider this so-called limited feedback problem in the context of CoMP. Usually taking the assumptions: 1) infinite SNR regime, 2) no user selection and 3) ideal link adaptation; rendering the analysis too optimistic. In this paper we make a step forward towards a more realistic assessment of the limited feedback problem by introducing an improved metric for the performance evaluation which better captures the throughput degradation. We find the relevant scaling laws (lower and upper bounds) and how that they are different from existing ones. Moreover, we provide a robust iterative interference alignment algorithm and corresponding feedback strategies achieving the obtained scaling laws. The main idea is that instead of sending the complete channel matrix each user fixes a receive filter and feeds back a quantized version of the effective channel. Finally we underline our findings with simulations for the proposed system.',
	 'authors': u'Jan Schreck, Gerhard Wunder, Peter Jung,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6750',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nRobust Iterative Interference Alignment for Cellular Networks with  Limited Feedback',
	 'urllink': u'http://arxiv.org/abs/1308.6750'}
2015-03-24 03:31:09+0000 [xxu46_7] INFO: Crawled 213 pages (at 1 pages/min), scraped 206 items (at 1 items/min)
2015-03-24 03:31:32+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6745> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:31:32+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6745>
	{'abstract': u'Cloud Computing is a recent computing model provides consistent access to wide area distributed resources. It revolutionized the IT world with its services provision infrastructure, less maintenance cost, data and service availability assurance, rapid accessibility and scalability. Grid and Cloud Computing Intrusion Detection System detects encrypted node communication and find the hidden attack trial which inspects and detects those attacks that network based and host based cant identify. It incorporates Knowledge and behavior analysis to identify specific intrusions. Signature based IDS monitor the packets in the network and identifies those threats by matching with database but It fails to detect those attacks that are not included in database. Signature based IDS will perform poor capturing in large volume of anomalies. Another problem is that Cloud Service Provider hides the attack that is caused by intruder, due to distributed nature cloud environment has high possibility for vulnerable resources. By impersonating legitimate users, the intruders can use a services abundant resources maliciously. In Proposed System we combine few concepts which are available with new intrusion detection techniques. Here to merge Entropy based System with Anomaly detection System for providing multilevel Distributed Denial of Service. This is done in two steps: First, Users are allowed to pass through router in network site in that it incorporates Detection Algorithm and detects for legitimate user. Second, again it pass through router placed in cloud site in that it incorporates confirmation Algorithm and checks for threshold value, if its beyond the threshold value it considered as legitimate user, else its an intruder found in environment.',
	 'authors': u'A.S.Syed Navaz, V.Sangeetha, C.Prabhadevi,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6745',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nEntropy based Anomaly Detection System to Prevent DDoS Attacks in Cloud',
	 'urllink': u'http://arxiv.org/abs/1308.6745'}
2015-03-24 03:32:09+0000 [xxu46_7] INFO: Crawled 214 pages (at 1 pages/min), scraped 207 items (at 1 items/min)
2015-03-24 03:33:09+0000 [xxu46_7] INFO: Crawled 214 pages (at 0 pages/min), scraped 207 items (at 0 items/min)
2015-03-24 03:33:17+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6744> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:33:17+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6744>
	{'abstract': u'Data Mining is a way of extracting data or uncovering hidden patterns of information from databases. So, there is a need to prevent the inference rules from being disclosed such that the more secure data sets cannot be identified from non sensitive attributes. This can be done through removing or adding certain item sets in the transactions Sanitization. The purpose is to hide the Inference rules, so that the user may not be able to discover any valuable information from other non sensitive data and any organisation can release all samples of their data without the fear of Knowledge Discovery In Databases which can be achieved by investigating frequently occurring item sets, rules that can be mined from them with the objective of hiding them. Another way is to release only limited samples in the new database so that there is no information loss and it also satisfies the legitimate needs of the users. The major problem is uncovering hidden patterns, which causes a threat to the database security. Sensitive data are inferred from non-sensitive data based on the semantics of the application the user has, commonly known as the inference problem. Two fundamental approaches to protect sensitive rules from disclosure are that, preventing rules from being generated by hiding the frequent sets of data items and reducing the importance of the rules by setting their confidence below a user-specified threshold.',
	 'authors': u'A.S.Syed Navaz, M.Ravi, T.Prabhu,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6744',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nPreventing Disclosure of Sensitive Knowledge by Hiding Inference',
	 'urllink': u'http://arxiv.org/abs/1308.6744'}
2015-03-24 03:34:09+0000 [xxu46_7] INFO: Crawled 215 pages (at 1 pages/min), scraped 208 items (at 1 items/min)
2015-03-24 03:34:45+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6736> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:34:45+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6736>
	{'abstract': u'In this paper, we consider the secrecy capacity of a wiretap channel in the presence of causal state information and secure rate-limited feedback. In this scenario, the causal state information from the channel is available to both the legitimate transmitter and legitimate receiver. In addition, the legitimate receiver can send secure feedback to the transmitter at a limited rate Rf . We shown that the secrecy capacity is bounded. Moreover, when the channel to the legitimate receiver is less noisy than the channel to the eavesdropper, the bound is shown to be tight. The capacity achieving scheme is based on both the Wyner wiretap coding and two steps of shared-key generation: one from the state information and one via the noiseless feedback. Finally, we consider several special cases. When state information is available only at the legitimate receiver, the analysis suggests that unlike previous results involving feedback, it is better to use the feedback to send the state information to the transmitter (when possible), rather than send a random key.',
	 'authors': u'Alejandro Cohen, Asaf Cohen,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6736',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nWiretap Channel With Causal State Information and Secure Rate-Limited  Feedback',
	 'urllink': u'http://arxiv.org/abs/1308.6736'}
2015-03-24 03:35:09+0000 [xxu46_7] INFO: Crawled 216 pages (at 1 pages/min), scraped 209 items (at 1 items/min)
2015-03-24 03:36:09+0000 [xxu46_7] INFO: Crawled 216 pages (at 0 pages/min), scraped 209 items (at 0 items/min)
2015-03-24 03:36:30+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6730> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:36:30+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6730>
	{'abstract': u'We study a three-dimensional analogue to the well-known graph visualization approach known as arc diagrams. We provide several algorithms that achieve good angular resolution for 3D arc diagrams, even for cases when the arcs must project to a given 2D straight-line drawing of the input graph. Our methods make use of various graph coloring algorithms, including an algorithm for a new coloring problem, which we call localized edge coloring.',
	 'authors': u'Michael T. Goodrich, Pawe\u0142 Pszona,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6730',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nAchieving Good Angular Resolution in 3D Arc Diagrams',
	 'urllink': u'http://arxiv.org/abs/1308.6730'}
2015-03-24 03:37:09+0000 [xxu46_7] INFO: Crawled 217 pages (at 1 pages/min), scraped 210 items (at 1 items/min)
2015-03-24 03:37:41+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6728> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:37:41+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6728>
	{'abstract': u'This is a draft of summary of multi-model algorithm of extended object tracking based on random matrix (RMF-MM).',
	 'authors': u'Borui Li, Chundi Mu, Shuli Han, Tianming Bai,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/e-print/1308.6728',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nExtension of "Model Parameter Adaptive Approach of Extended Object  Tracking Using Random Matrix"',
	 'urllink': u'http://arxiv.org/abs/1308.6728'}
2015-03-24 03:38:09+0000 [xxu46_7] INFO: Crawled 218 pages (at 1 pages/min), scraped 211 items (at 1 items/min)
2015-03-24 03:39:09+0000 [xxu46_7] INFO: Crawled 218 pages (at 0 pages/min), scraped 211 items (at 0 items/min)
2015-03-24 03:39:25+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6721> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:39:25+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6721>
	{'abstract': u'The Random Walks (RW) algorithm is one of the most e - cient and easy-to-use probabilistic segmentation methods. By combining contrast terms with prior terms, it provides accurate segmentations of medical images in a fully automated manner. However, one of the main drawbacks of using the RW algorithm is that its parameters have to be hand-tuned. we propose a novel discriminative learning framework that estimates the parameters using a training dataset. The main challenge we face is that the training samples are not fully supervised. Speci cally, they provide a hard segmentation of the images, instead of a proba- bilistic segmentation. We overcome this challenge by treating the opti- mal probabilistic segmentation that is compatible with the given hard segmentation as a latent variable. This allows us to employ the latent support vector machine formulation for parameter estimation. We show that our approach signi cantly outperforms the baseline methods on a challenging dataset consisting of real clinical 3D MRI volumes of skeletal muscles.',
	 'authors': u'Pierre-Yves Baudin, Danny Goodman, Puneet Kumar, Noura Azzabou, Pierre G. Carlier, Nikos Paragios, M. Pawan Kumar,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6721',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nDiscriminative Parameter Estimation for Random Walks Segmentation',
	 'urllink': u'http://arxiv.org/abs/1308.6721'}
2015-03-24 03:40:09+0000 [xxu46_7] INFO: Crawled 219 pages (at 1 pages/min), scraped 212 items (at 1 items/min)
2015-03-24 03:41:09+0000 [xxu46_7] INFO: Crawled 219 pages (at 0 pages/min), scraped 212 items (at 0 items/min)
2015-03-24 03:41:25+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6711> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:41:25+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6711>
	{'abstract': u'In streamed graph drawing, a planar graph, G, is given incrementally as a data stream and a straight-line drawing of G must be updated after each new edge is released. To preserve the mental map, changes to the drawing should be minimized after each update, and Binucci et al.show that exponential area is necessary and sufficient for a number of streamed graph drawings for trees if edges are not allowed to move at all. We show that a number of streamed graph drawings can, in fact, be done with polynomial area, including planar streamed graph drawings of trees, tree-maps, and outerplanar graphs, if we allow for a small number of coordinate movements after each update. Our algorithms involve an interesting connection to a classic algorithmic problem - the file maintenance problem - and we also give new algorithms for this problem in a framework where bulk memory moves are allowed.',
	 'authors': u'Michael T. Goodrich, Pawe\u0142 Pszona,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6711',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nStreamed Graph Drawing and the File Maintenance Problem',
	 'urllink': u'http://arxiv.org/abs/1308.6711'}
2015-03-24 03:42:09+0000 [xxu46_7] INFO: Crawled 220 pages (at 1 pages/min), scraped 213 items (at 1 items/min)
2015-03-24 03:43:05+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6709> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:43:05+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6709>
	{'abstract': u'This paper considers the distributed H-infinity leader-following tracking problem for a class of discrete time multi-agent systems with a high-dimensional dynamic leader. It is assumed that output information about the leader is only available to designated followers, and the dynamics of the followers are subject to perturbations. To achieve distributed H-infinity leader-following tracking, a new class of control protocols is proposed which is based on the feedback from the nearest neighbors as well as a distributed state estimator. Under the assumptions that dynamics of the leader are detectable and the communication topology contains a directed spanning tree, sufficient conditions are obtained that enable all followers to track the leader while achieving a desired H-infinity leader-following tracking performance. Numerical simulations illustrate the effectiveness of the theoretical analysis.',
	 'authors': u'Guanghui Wen, Valery Ugrinovskii,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6709',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nDistributed H-infinity Tracking Control for Discrete-Time Multi-Agent  Systems with a High-Dimensional Leader',
	 'urllink': u'http://arxiv.org/abs/1308.6709'}
2015-03-24 03:43:09+0000 [xxu46_7] INFO: Crawled 221 pages (at 1 pages/min), scraped 214 items (at 1 items/min)
2015-03-24 03:44:09+0000 [xxu46_7] INFO: Crawled 221 pages (at 0 pages/min), scraped 214 items (at 0 items/min)
2015-03-24 03:44:46+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6706> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:44:46+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6706>
	{'abstract': u'We initiate the study of the following problem: Given a non-planar graph G and a planar subgraph S of G, does there exist a straight-line drawing of G in the plane such that the edges of S are not crossed in by any edge of G? We give positive and negative results for different kinds of connected spanning subgraphs S of G. Moreover, in order to enlarge the subset of instances that admit a solution, we consider the possibility of bending the edges of G not in S; in this setting we discuss different trade-offs between the number of bends and the required drawing area.',
	 'authors': u'Patrizio Angelini, Carla Binucci, Giordano Da Lozzo, Walter Didimo, Luca Grilli, Fabrizio Montecchiani, Maurizio Patrignani, Ioannis G. Tollis,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6706',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nAlgorithms and Bounds for Drawing Non-planar Graphs with Crossing-free  Subgraphs',
	 'urllink': u'http://arxiv.org/abs/1308.6706'}
2015-03-24 03:45:09+0000 [xxu46_7] INFO: Crawled 222 pages (at 1 pages/min), scraped 215 items (at 1 items/min)
2015-03-24 03:46:09+0000 [xxu46_7] INFO: Crawled 222 pages (at 0 pages/min), scraped 215 items (at 0 items/min)
2015-03-24 03:46:39+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6705> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:46:39+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6705>
	{'abstract': u"Many modern and growing cities are facing declines in public transport usage, with few efficient methods to explain why. In this article, we show that urban mobility patterns and transport mode choices can be derived from cellphone call detail records coupled with public transport data recorded from smart cards. Specifically, we present new data mining approaches to determine the spatial and temporal variability of public and private transportation usage and transport mode preferences across Singapore. Our results, which were validated by Singapore's quadriennial Household Interview Travel Survey (HITS), revealed that there are 3.5 (HITS: 3.5 million) million and 4.3 (HITS: 4.4 million) million inter-district passengers by public and private transport, respectively. Along with classifying which transportation connections are weak or underserved, the analysis shows that the mode share of public transport use increases from 38 percent in the morning to 44 percent around mid-day and 52 percent in the evening.",
	 'authors': u'Thomas Holleczek, Liang Yu, Joseph K. Lee, Oliver Senn, Kristian Kloeckl, Carlo Ratti, Patrick Jaillet,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6705',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nDigital breadcrumbs: Detecting urban mobility patterns and transport  mode choices from cellphone networks',
	 'urllink': u'http://arxiv.org/abs/1308.6705'}
2015-03-24 03:47:09+0000 [xxu46_7] INFO: Crawled 223 pages (at 1 pages/min), scraped 216 items (at 1 items/min)
2015-03-24 03:48:09+0000 [xxu46_7] INFO: Crawled 223 pages (at 0 pages/min), scraped 216 items (at 0 items/min)
2015-03-24 03:48:32+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6702> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:48:32+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6702>
	{'abstract': u"Recall the classical hypothesis testing setting with two convex sets of probability distributions P and Q. One receives either n i.i.d. samples from a distribution p in P or from a distribution q in Q and wants to decide from which set the points were sampled. It is known that the optimal exponential rate at which errors decrease can be achieved by a simple maximum-likelihood ratio test which does not depend on p or q, but only on the sets P and Q. We consider an adaptive generalization of this model where the choice of p in P and q in Q can change in each sample in some way that depends arbitrarily on the previous samples. In other words, in the k'th round, an adversary, having observed all the previous samples in rounds 1,...,k-1, chooses p_k in P and q_k in Q, with the goal of confusing the hypothesis test. We prove that even in this case, the optimal exponential error rate can be achieved by a simple maximum-likelihood test that depends only on P and Q. We then show that the adversarial model has applications in hypothesis testing for quantum states using restricted measurements. For example, it can be used to study the problem of distinguishing entangled states from the set of all separable states using only measurements that can be implemented with local operations and classical communication (LOCC). The basic idea is that in our setup, the deleterious effects of entanglement can be simulated by an adaptive classical adversary. We prove a quantum Stein's Lemma in this setting: In many circumstances, the optimal hypothesis testing rate is equal to an appropriate notion of quantum relative entropy between two states. In particular, our arguments yield an alternate proof of Li and Winter's recent strengthening of strong subadditivity for quantum relative entropy.",
	 'authors': u'Fernando G.S.L. Brandao, Aram W. Harrow, James R. Lee, Yuval Peres,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6702',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u"\nAdversarial hypothesis testing and a quantum Stein's Lemma for  restricted measurements",
	 'urllink': u'http://arxiv.org/abs/1308.6702'}
2015-03-24 03:49:09+0000 [xxu46_7] INFO: Crawled 224 pages (at 1 pages/min), scraped 217 items (at 1 items/min)
2015-03-24 03:50:09+0000 [xxu46_7] INFO: Crawled 224 pages (at 0 pages/min), scraped 217 items (at 0 items/min)
2015-03-24 03:50:25+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6701> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:50:25+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6701>
	{'abstract': u'Integrating data is a basic concern in many accredited laboratories that perform a large variety of measurements. However, the present working style in engineering faculties does not focus much on this aspect. To deal with this challenge, we developed an educational platform that allows characterization of acquisition ensembles, generation of Web pages for lessons, as well as transformation of measured data and storage in a common format. As generally we had to develop individual parsers for each instrument, we also added the possibility to integrate the LabVIEW workbench, often used for rapid development of applications in electrical engineering and automatic control. This paper describes how we configure the platform for specific equipment, i.e. how we model it, how we create the learning material and how we integrate the results in a central database. It also introduces a case study for collecting data from a thermocouple-based acquisition system based on LabVIEW, used by students for a laboratory of measurement technologies and transducers.',
	 'authors': u'Adriana Olteanu, Grigore Stamatescu, Anca Daniela Ionita, Valentin Sgarciu,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6701',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nEnhanced Data Integration for LabVIEW Laboratory Systems',
	 'urllink': u'http://arxiv.org/abs/1308.6701'}
2015-03-24 03:51:09+0000 [xxu46_7] INFO: Crawled 225 pages (at 1 pages/min), scraped 218 items (at 1 items/min)
2015-03-24 03:52:09+0000 [xxu46_7] INFO: Crawled 225 pages (at 0 pages/min), scraped 218 items (at 0 items/min)
2015-03-24 03:52:16+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6697> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:52:16+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6697>
	{'abstract': u'Adverse drug reactions (ADRs) are big concern for public health. ADRs are one of most common causes to withdraw some drugs from markets. Now two major methods for detecting ADRs are spontaneous reporting system (SRS), and prescription event monitoring (PEM). The World Health Organization (WHO) defines a signal in pharmacovigilance as "any reported information on a possible causal relationship between an adverse event and a drug, the relationship being unknown or incompletely documented previously". For spontaneous reporting systems, many machine learning methods are used to detect ADRs, such as Bayesian confidence propagation neural network (BCPNN), decision support methods, genetic algorithms, knowledge based approaches, etc. One limitation is the reporting mechanism to submit ADR reports, which has serious underreporting and is not able to accurately quantify the corresponding risk. Another limitation is hard to detect ADRs with small number of occurrences of each drug-event association in the database. In this paper we propose feature selection approach to detect ADRs from The Health Improvement Network (THIN) database. First a feature matrix, which represents the medical events for the patients before and after taking drugs, is created by linking patients\' prescriptions and corresponding medical events together. Then significant features are selected based on feature selection methods, comparing the feature matrix before patients take drugs with one after patients take drugs. Finally the significant ADRs can be detected from thousands of medical events based on corresponding features. Experiments are carried out on the drug Atorvastatin. Good performance is achieved.',
	 'authors': u'Yihui Liu, Uwe Aickelin,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6697',
	 'subjects': u'Computational Engineering, Finance, and Science (cs.CE)',
	 'title': u'\nDetect adverse drug reactions for drug Atorvastatin',
	 'urllink': u'http://arxiv.org/abs/1308.6697'}
2015-03-24 03:53:09+0000 [xxu46_7] INFO: Crawled 226 pages (at 1 pages/min), scraped 219 items (at 1 items/min)
2015-03-24 03:54:09+0000 [xxu46_7] INFO: Crawled 226 pages (at 0 pages/min), scraped 219 items (at 0 items/min)
2015-03-24 03:54:17+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6694> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:54:17+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6694>
	{'abstract': u'We study balancedness properties of words given by the Arnoux-Rauzy and Brun multi-dimensional continued fraction algorithms. We show that almost all Brun words on 3 letters and Arnoux-Rauzy words over arbitrary alphabets are finitely balanced; in particular, boundedness of the strong partial quotients implies balancedness. On the other hand, we provide examples of unbalanced Brun words on 3 letters.',
	 'authors': u'Vincent Delecroix, Tom\xe1\u0161 Hejda, Wolfgang Steiner,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6694',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nBalancedness of Arnoux-Rauzy and Brun words',
	 'urllink': u'http://arxiv.org/abs/1308.6694'}
2015-03-24 03:55:09+0000 [xxu46_7] INFO: Crawled 227 pages (at 1 pages/min), scraped 220 items (at 1 items/min)
2015-03-24 03:56:09+0000 [xxu46_7] INFO: Crawled 227 pages (at 0 pages/min), scraped 220 items (at 0 items/min)
2015-03-24 03:56:10+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6693> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:56:10+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6693>
	{'abstract': u'There are numerous styles of planar graph drawings, notably straight-line drawings, poly-line drawings, orthogonal graph drawings and visibility representations. In this note, we show that many of these drawings can be transformed from one style to another without changing the height of the drawing. We then give some applications of these transformations.',
	 'authors': u'Therese Biedl,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6693',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nTransforming planar graph drawings while maintaining height',
	 'urllink': u'http://arxiv.org/abs/1308.6693'}
2015-03-24 03:57:09+0000 [xxu46_7] INFO: Crawled 228 pages (at 1 pages/min), scraped 221 items (at 1 items/min)
2015-03-24 03:57:38+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6687> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:57:38+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6687>
	{'abstract': u'With the rapid development of digital imaging and communication technologies, image set based face recognition (ISFR) is becoming increasingly important. One key issue of ISFR is how to effectively and efficiently represent the query face image set by using the gallery face image sets. The set-to-set distance based methods ignore the relationship between gallery sets, while representing the query set images individually over the gallery sets ignores the correlation between query set images. In this paper, we propose a novel image set based collaborative representation and classification method for ISFR. By modeling the query set as a convex or regularized hull, we represent this hull collaboratively over all the gallery sets. With the resolved representation coefficients, the distance between the query set and each gallery set can then be calculated for classification. The proposed model naturally and effectively extends the image based collaborative representation to an image set based one, and our extensive experiments on benchmark ISFR databases show the superiority of the proposed method to state-of-the-art ISFR methods under different set sizes in terms of both recognition rate and efficiency.',
	 'authors': u'Pengfei Zhu, Wangmeng Zuo, Lei Zhang, Simon C.K. Shiu, David Zhang,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6687',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nImage Set based Collaborative Representation for Face Recognition',
	 'urllink': u'http://arxiv.org/abs/1308.6687'}
2015-03-24 03:58:09+0000 [xxu46_7] INFO: Crawled 229 pages (at 1 pages/min), scraped 222 items (at 1 items/min)
2015-03-24 03:59:09+0000 [xxu46_7] INFO: Crawled 229 pages (at 0 pages/min), scraped 222 items (at 0 items/min)
2015-03-24 03:59:09+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6683> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 03:59:09+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6683>
	{'abstract': u'Business Intelligence plays an important role in decision making. Based on data warehouses and Online Analytical Processing, a business intelligence tool can be used to analyze complex data. Still, summarizability issues in data warehouses cause ineffective analyses that may become critical problems to businesses. To settle this issue, many researchers have studied and proposed various solutions, both in relational and XML data warehouses. However, they find difficulty in evaluating the performance of their proposals since the available benchmarks lack complex hierarchies. In order to contribute to summarizability analysis, this paper proposes an extension to the XML warehouse benchmark (XWeB) with complex hierarchies. The benchmark enables us to generate XML data warehouses with scalable complex hierarchies as well as summarizability processing. We experimentally demonstrated that complex hierarchies can definitely be included into a benchmark dataset, and that our benchmark is able to compare two alternative approaches dealing with summarizability issues.',
	 'authors': u'Chantola Kit, Marouane Hachicha, J\xe9r\xf4me Darmont,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6683',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nBenchmarking Summarizability Processing in XML Warehouses with Complex  Hierarchies',
	 'urllink': u'http://arxiv.org/abs/1308.6683'}
2015-03-24 04:00:09+0000 [xxu46_7] INFO: Crawled 230 pages (at 1 pages/min), scraped 223 items (at 1 items/min)
2015-03-24 04:00:20+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6682> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 04:00:20+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6682>
	{'abstract': u'The business intelligence and decision-support systems used in many application domains casually rely on data warehouses, which are decision-oriented data repositories modeled as multidimensional (MD) structures. MD structures help navigate data through hierarchical levels of detail. In many real-world situations, hierarchies in MD models are complex, which causes data aggregation issues, collectively known as the summarizability problem. This problem leads to incorrect analyses and critically affects decision making. To enforce summarizability, existing approaches alter either MD models or data, and must be applied a priori, on a case-by-case basis, by an expert. To alter neither models nor data, a few query-time approaches have been proposed recently, but they only detect summarizability issues without solving them. Thus, we propose in this paper a novel approach that automatically detects and processes summarizability issues at query time, without requiring any particular expertise from the user. Moreover, while most existing approaches are based on the relational model, our approach focus on an XML MD model, since XML data is customarily used to represent business data and its format better copes with complex hierarchies than the relational model. Finally, our experiments show that our method is likely to scale better than a reference approach for addressing the summarizability problem in the MD context.',
	 'authors': u'Marouane Hachicha, Chantola Kit, J\xe9r\xf4me Darmont,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6682',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nA Novel Query-Based Approach for Addressing Summarizability Issues in  XOLAP',
	 'urllink': u'http://arxiv.org/abs/1308.6682'}
2015-03-24 04:01:09+0000 [xxu46_7] INFO: Crawled 231 pages (at 1 pages/min), scraped 224 items (at 1 items/min)
2015-03-24 04:02:09+0000 [xxu46_7] INFO: Crawled 231 pages (at 0 pages/min), scraped 224 items (at 0 items/min)
2015-03-24 04:02:19+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6663> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 04:02:19+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6663>
	{'abstract': u"Although WiFi fingerprint-based indoor localization is attractive, its accuracy remains a primary challenge especially in mobile environments. Existing approaches either appeal to physical layer information or rely on extra wireless signals for high accuracy. In this paper, we revisit the RSS fingerprint-based localization scheme and reveal crucial observations that act as the root causes of localization errors, yet are surprisingly overlooked or even unseen in previous works. Specifically, we recognize APs' diverse discrimination for fingerprinting a specific location, observe the RSS inconsistency caused by signal fluctuations and human body blockages, and uncover the RSS outdated problem on commodity smartphones. Inspired by these insights, we devise a discrimination factor to quantify different APs' discrimination, incorporate robust regression to tolerate outlier measurements, and reassemble different fingerprints to cope with outdated RSSs. Combining these techniques in a unified solution, we propose DorFin, a novel scheme of fingerprint generation, representation, and matching, which yields remarkable accuracy without incurring extra cost. Extensive experiments demonstrate that DorFin achieves mean error of 2 meters and more importantly, bounds the 95th percentile error under 5.5 meters; these are about 56% and 69% lower, respectively, compared with the state-of-the-art schemes such as Horus and RADAR.",
	 'authors': u'Chenshu Wu, Zheng Yang, Zimu Zhou, Yunhao Liu, Mingyan Liu,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6663',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nDorFin: WiFi Fingerprint-based Localization Revisited',
	 'urllink': u'http://arxiv.org/abs/1308.6663'}
2015-03-24 04:03:09+0000 [xxu46_7] INFO: Crawled 232 pages (at 1 pages/min), scraped 225 items (at 1 items/min)
2015-03-24 04:04:01+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6646> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 04:04:01+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6646>
	{'abstract': u'Two-direction multiscaling functions and two-direction multiwavelets associated with are more general and more flexible setting than one-direction multiscaling functions and multiwavelets. In this paper, we investigate how to find and normalize point values and those of derivatives of the two-direction multiscaling functions and multiwavelets . %associated with . For finding point values, we investigate the eigenvalue approach. For normalization, we investigate the normalizing conditions for them by normalizing the zeroth continuous moment of . Examples for illustrating the general theory are given.',
	 'authors': u'Fritz Keinert, Soon-Geol Kwon,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6646',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nPoint values and normalization of two-direction multiwavelets and their  derivatives',
	 'urllink': u'http://arxiv.org/abs/1308.6646'}
2015-03-24 04:04:09+0000 [xxu46_7] INFO: Crawled 233 pages (at 1 pages/min), scraped 226 items (at 1 items/min)
2015-03-24 04:04:53+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6641> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 04:04:53+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6641>
	{'abstract': u"We study a new variant of consensus problems, termed `local average consensus', in networks of agents. We consider the task of using sensor networks to perform distributed measurement of a parameter which has both spatial (in this paper 1D) and temporal variations. Our idea is to maintain potentially useful local information regarding spatial variation, as contrasted with reaching a single, global consensus, as well as to mitigate the effect of measurement errors. We employ two schemes for computation of local average consensus: exponential weighting and uniform finite window. In both schemes, we design local average consensus algorithms to address first the case where the measured parameter has spatial variation but is constant in time, and then the case where the measured parameter has both spatial and temporal variations. Our designed algorithms are distributed, in that information is exchanged only among neighbors. Moreover, we analyze both spatial and temporal frequency responses and noise propagation associated with the algorithms. The tradeoffs of using local consensus, as compared to standard global consensus, include higher memory requirement and degraded noise performance. Arbitrary updating weights and random spacing between sensors are analyzed in the proposed algorithms.",
	 'authors': u'Kai Cai, Brian D.O. Anderson, Changbin Yu, Guoqiang Mao,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6641',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nLocal Average Consensus in Distributed Measurement of Spatial-Temporal  Varying Parameters: 1D Case',
	 'urllink': u'http://arxiv.org/abs/1308.6641'}
2015-03-24 04:05:09+0000 [xxu46_7] INFO: Crawled 234 pages (at 1 pages/min), scraped 227 items (at 1 items/min)
2015-03-24 04:06:04+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7937> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 04:06:04+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7937>
	{'abstract': u'Functional electrical stimulation (FES) is used to activate the dysfunctional lower limb muscles of individuals with neuromuscular disorders to produce cycling as a means of exercise and rehabilitation. However, FES-cycling is still metabolically inefficient and yields low power output at the cycle crank compared to able-bodied cycling. Previous literature suggests that these problems are symptomatic of poor muscle control and non-physiological muscle fiber recruitment. The latter is a known problem with FES in general, and the former motivates investigation of better control methods for FES-cycling.In this paper, a stimulation pattern for quadriceps femoris-only FES-cycling is derived based on the effectiveness of knee joint torque in producing forward pedaling. In addition, a switched sliding-mode controller is designed for the uncertain, nonlinear cycle-rider system with autonomous state-dependent switching. The switched controller yields ultimately bounded tracking of a desired trajectory in the presence of an unknown, time-varying, bounded disturbance, provided a reverse dwell-time condition is satisfied by appropriate choice of the control gains and a sufficient desired cadence. Stability is derived through Lyapunov methods for switched systems, and experimental results demonstrate the performance of the switched control system under typical cycling conditions.',
	 'authors': u'Matthew J. Bellman, Teng-Hu Cheng, Ryan J. Downey, Warren E. Dixon,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7937',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nStationary Cycling Induced by Switched Functional Electrical Stimulation  Control',
	 'urllink': u'http://arxiv.org/abs/1309.7937'}
2015-03-24 04:06:09+0000 [xxu46_7] INFO: Crawled 235 pages (at 1 pages/min), scraped 228 items (at 1 items/min)
2015-03-24 04:07:09+0000 [xxu46_7] INFO: Crawled 235 pages (at 0 pages/min), scraped 228 items (at 0 items/min)
2015-03-24 04:07:48+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6635> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 04:07:48+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6635>
	{'abstract': u'Graphs are extremely versatile and ubiquitous mathematical structures with potential to model a wide range of domains. For this reason, graph problems have been of interest since the early days of computer science. Some of these problems consider substructures of a graph that have certain properties. These substructures of interest, generally called patterns, are often meaningful in the domain being modeled. Classic examples of patterns include spanning trees, cycles and subgraphs. This thesis focuses on the topic of explicitly listing all the patterns existing in an input graph. One of the defining features of this problem is that the number of patterns is frequently exponential on the size of the input graph. Thus, the time complexity of listing algorithms is parameterized by the size of the output. The main contribution of this work is the presentation of optimal algorithms for four different problems of listing patterns in graphs, namely the listing of k-subtrees, k-subgraphs, st-paths and cycles. The algorithms presented are framed within the same generic approach, based in a recursive partition of the search space that divides the problem into subproblems. The key to an efficient implementation of this approach is to avoid recursing into subproblems that do not list any patterns. With this goal in sight, a dynamic data structure, called the certificate, is introduced and maintained throughout the recursion. Moreover, properties of the recursion tree and lower bounds on the number of patterns are used to amortize the cost of the algorithm on the size of the output.',
	 'authors': u'Rui Ferreira,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6635',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nEfficiently Listing Combinatorial Patterns in Graphs',
	 'urllink': u'http://arxiv.org/abs/1308.6635'}
2015-03-24 04:08:09+0000 [xxu46_7] INFO: Crawled 236 pages (at 1 pages/min), scraped 229 items (at 1 items/min)
2015-03-24 04:09:09+0000 [xxu46_7] INFO: Crawled 236 pages (at 0 pages/min), scraped 229 items (at 0 items/min)
2015-03-24 04:09:23+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7935> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 04:09:23+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7935>
	{'abstract': u'We consider the problem of a social group of users trying to obtain a "universe" of files, first from a server and then via exchange amongst themselves. We consider the selfish file-exchange paradigm of give-and-take, whereby two users can exchange files only if each has something unique to offer the other. We are interested in maximizing the number of users who can obtain the universe through a schedule of file-exchanges. We first present a practical paradigm of file acquisition. We then present an algorithm which ensures that at least half the users obtain the universe with high probability for files and users when , thereby showing an approximation ratio of 2. Extending these ideas, we show a - approximation algorithm for , and a - approximation algorithm for , , . Finally, we show that for any , there exists a schedule of file exchanges which ensures that at least half the users obtain the universe.',
	 'authors': u'Ashwin Pananjady, Vivek Kumar Bagaria, Rahul Vaze,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7935',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nMaximizing Utility Among Selfish Users in Social Groups',
	 'urllink': u'http://arxiv.org/abs/1309.7935'}
2015-03-24 04:10:09+0000 [xxu46_7] INFO: Crawled 237 pages (at 1 pages/min), scraped 230 items (at 1 items/min)
2015-03-24 04:11:09+0000 [xxu46_7] INFO: Crawled 237 pages (at 0 pages/min), scraped 230 items (at 0 items/min)
2015-03-24 04:11:13+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6633> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 04:11:13+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6633>
	{'abstract': u'We analyzed the cross-correlation of Photovoltaic (PV) output fluctuation for the actual PV output time series data in both the Tokyo area and the whole of Japan using the principal component analysis with the random matrix theory. Based on the obtained cross-correlation coefficients, the forecast error for PV output was estimated with/without considering the cross-correlations. Then operation schedule of thermal plants is calculated to integrate PV output using our unit commitment model with the estimated forecast error. The cost for grid integration of PV system was also estimated. Finally, validity of the concept of "local production for local consumption of renewable energy" and alternative policy implications were also discussed.',
	 'authors': u'Yuichi Ikeda, Kazuhiko Ogimoto,',
	 'category': u'Computer Science ',
	 'date': '2013-8-30',
	 'pdflink': u'http://arxiv.org/pdf/1308.6633',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nCross-Correlation of Photovoltaic Output Fluctuation in Power System  Operation for Large-Scale Photovoltaic Integration',
	 'urllink': u'http://arxiv.org/abs/1308.6633'}
2015-03-24 04:12:09+0000 [xxu46_7] INFO: Crawled 238 pages (at 1 pages/min), scraped 231 items (at 1 items/min)
2015-03-24 04:13:03+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7912> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 04:13:03+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7912>
	{'abstract': u'This work aims at generating a model of the ocean surface and its dynamics from one or more video cameras. The idea is to model wave patterns from video as a first step towards a larger system of photogrammetric monitoring of marine conditions for use in offshore oil drilling platforms. The first part of the proposed approach consists in reducing the dimensionality of sensor data made up of the many pixels of each frame of the input video streams. This enables finding a concise number of most relevant parameters to model the temporal dataset, yielding an efficient data-driven model of the evolution of the observed surface. The second part proposes stochastic modeling to better capture the patterns embedded in the data. One can then draw samples from the final model, which are expected to simulate the behavior of previously observed flow, in order to determine conditions that match new observations. In this paper we focus on proposing and discussing the overall approach and on comparing two different techniques for dimensionality reduction in the first stage: principal component analysis and diffusion maps. Work is underway on the second stage of constructing better stochastic models of fluid surface dynamics as proposed here.',
	 'authors': u'Mauro de Amorim, Ricardo Fabbri, Lucia Maria dos Santos Pinto, Francisco Duarte Moura Neto,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7912',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nAn Image-Based Fluid Surface Pattern Model',
	 'urllink': u'http://arxiv.org/abs/1309.7912'}
2015-03-24 04:13:09+0000 [xxu46_7] INFO: Crawled 239 pages (at 1 pages/min), scraped 232 items (at 1 items/min)
2015-03-24 04:14:09+0000 [xxu46_7] INFO: Crawled 239 pages (at 0 pages/min), scraped 232 items (at 0 items/min)
2015-03-24 04:14:56+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6628> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 04:14:56+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6628>
	{'abstract': u'We propose a framework for parsing video and text jointly for understanding events and answering user queries. Our framework produces a parse graph that represents the compositional structures of spatial information (objects and scenes), temporal information (actions and events) and causal information (causalities between events and fluents) in the video and text. The knowledge representation of our framework is based on a spatial-temporal-causal And-Or graph (S/T/C-AOG), which jointly models possible hierarchical compositions of objects, scenes and events as well as their interactions and mutual contexts, and specifies the prior probabilistic distribution of the parse graphs. We present a probabilistic generative model for joint parsing that captures the relations between the input video/text, their corresponding parse graphs and the joint parse graph. Based on the probabilistic model, we propose a joint parsing system consisting of three modules: video parsing, text parsing and joint inference. Video parsing and text parsing produce two parse graphs from the input video and text respectively. The joint inference module produces a joint parse graph by performing matching, deduction and revision on the video and text parse graphs. The proposed framework has the following objectives: Firstly, we aim at deep semantic parsing of video and text that goes beyond the traditional bag-of-words approaches; Secondly, we perform parsing and reasoning across the spatial, temporal and causal dimensions based on the joint S/T/C-AOG representation; Thirdly, we show that deep joint parsing facilitates subsequent applications such as generating narrative text descriptions and answering queries in the forms of who, what, when, where and why. We empirically evaluated our system based on comparison against ground-truth as well as accuracy of query answering and obtained satisfactory results.',
	 'authors': u'Kewei Tu, Meng Meng, Mun Wai Lee, Tae Eun Choe, Song-Chun Zhu,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6628',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nJoint Video and Text Parsing for Understanding Events and Answering  Queries',
	 'urllink': u'http://arxiv.org/abs/1308.6628'}
2015-03-24 04:15:09+0000 [xxu46_7] INFO: Crawled 240 pages (at 1 pages/min), scraped 233 items (at 1 items/min)
2015-03-24 04:16:09+0000 [xxu46_7] INFO: Crawled 240 pages (at 0 pages/min), scraped 233 items (at 0 items/min)
2015-03-24 04:16:22+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7910> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 04:16:22+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7910>
	{'abstract': u'Low-density parity-check (LDPC) convolutional codes (or spatially-coupled codes) were recently shown to approach capacity on the binary erasure channel (BEC) and binary-input memoryless symmetric channels. The mechanism behind this spectacular performance is now called threshold saturation via spatial coupling. This new phenomenon is characterized by the belief-propagation threshold of the spatially-coupled ensemble increasing to an intrinsic noise threshold defined by the uncoupled system. In this paper, we present a simple proof of threshold saturation that applies to a wide class of coupled scalar recursions. Our approach is based on constructing potential functions for both the coupled and uncoupled recursions. Our results actually show that the fixed point of the coupled recursion is essentially determined by the minimum of the uncoupled potential function and we refer to this phenomenon as Maxwell saturation. A variety of examples are considered including the density-evolution equations for: irregular LDPC codes on the BEC, irregular low-density generator matrix codes on the BEC, a class of generalized LDPC codes with BCH component codes, the joint iterative decoding of LDPC codes on intersymbol-interference channels with erasure noise, and the compressed sensing of random vectors with i.i.d. components.',
	 'authors': u'Arvind Yedla, Yung-Yih Jian, Phong S. Nguyen, Henry D. Pfister,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7910',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nA Simple Proof of Maxwell Saturation for Coupled Scalar Recursions',
	 'urllink': u'http://arxiv.org/abs/1309.7910'}
2015-03-24 04:17:09+0000 [xxu46_7] INFO: Crawled 241 pages (at 1 pages/min), scraped 234 items (at 1 items/min)
2015-03-24 04:17:41+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6627> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 04:17:41+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6627>
	{'abstract': u'Sampling from combinatorial families can be difficult. However, complicated families can often be embedded within larger, simpler ones, for which easy sampling algorithms are known. We take advantage of such a relationship to describe a sampling algorithm for the smaller family, via a Markov chain started at a random sample of the larger family. The utility of the method is demonstrated via several examples, with particular emphasis on sampling labelled graphs with given degree sequence, a well-studied problem for which existing algorithms leave much room for improvement. For graphs with given degrees, with maximum degree where is the number of edges, we obtain an asymptotically uniform sample in steps, which substantially improves upon existing algorithms.',
	 'authors': u'James Y. Zhao,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6627',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nExpand and Contract: Sampling graphs with given degrees and other  combinatorial families',
	 'urllink': u'http://arxiv.org/abs/1308.6627'}
2015-03-24 04:18:09+0000 [xxu46_7] INFO: Crawled 242 pages (at 1 pages/min), scraped 235 items (at 1 items/min)
2015-03-24 04:19:09+0000 [xxu46_7] INFO: Crawled 242 pages (at 0 pages/min), scraped 235 items (at 0 items/min)
2015-03-24 04:19:31+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7901> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 04:19:31+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7901>
	{'abstract': u'The concept of prefactors is considered in order to decrease the complexity of the Guruswami-Sudan interpolation step for generalized Reed-Solomon codes. It is shown that the well-known re-encoding projection due to Koetter et al. leads to one type of such prefactors. The new type of Sierpinski prefactors is introduced. The latter are based on the fact that many binomial coefficients in the Hasse derivative associated with the Guruswami-Sudan interpolation step are zero modulo the base field characteristic. It is shown that both types of prefactors can be combined and how arbitrary prefactors can be used to derive a reduced Guruswami-Sudan interpolation step.',
	 'authors': u'Christian Senger,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7901',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nPrefactor Reduction of the Guruswami-Sudan Interpolation Step',
	 'urllink': u'http://arxiv.org/abs/1309.7901'}
2015-03-24 04:20:09+0000 [xxu46_7] INFO: Crawled 243 pages (at 1 pages/min), scraped 236 items (at 1 items/min)
2015-03-24 04:21:01+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6566> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 04:21:01+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6566>
	{'abstract': u'This paper considers the construction of Reproducing Kernel Hilbert Spaces (RKHS) on the sphere as an alternative to the conventional Hilbert space using the inner product that yields the L^2(S^2) function space of finite energy signals. In comparison with wavelet representations, which have multi-resolution properties on L^2(S^2), the representations that arise from the RKHS approach, which uses different inner products, have an overall smoothness constraint, which may offer advantages and simplifications in certain contexts. The key contribution of this paper is to construct classes of closed-form kernels, such as one based on the von Mises-Fisher distribution, which permits efficient inner product computation using kernel evaluations. Three classes of RKHS are defined: isotropic kernels and non-isotropic kernels both with spherical harmonic eigenfunctions, and general anisotropic kernels.',
	 'authors': u'Rodney A. Kennedy, Parastoo Sadeghi, Zubair Khalid, Jason D. McEwen,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6566',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nClassification and construction of closed-form kernels for signal  representation on the 2-sphere',
	 'urllink': u'http://arxiv.org/abs/1308.6566'}
2015-03-24 04:21:09+0000 [xxu46_7] INFO: Crawled 244 pages (at 1 pages/min), scraped 237 items (at 1 items/min)
2015-03-24 04:22:09+0000 [xxu46_7] INFO: Crawled 244 pages (at 0 pages/min), scraped 237 items (at 0 items/min)
2015-03-24 04:22:41+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7891> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 04:22:41+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7891>
	{'abstract': u'In the Tree Deletion Set problem the input is a graph G together with an integer k. The objective is to determine whether there exists a set S of at most k vertices such that G-S is a tree. The problem is NP-complete and even NP-hard to approximate within any factor of OPT^c for any constant c. In this paper we give a O(k^4) size kernel for the Tree Deletion Set problem. To the best of our knowledge our result is the first counterexample to the "conventional wisdom" that kernelization algorithms automatically provide approximation algorithms with approximation ratio close to the size of the kernel. An appealing feature of our kernelization algorithm is a new algebraic reduction rule that we use to handle the instances on which Tree Deletion Set is hard to approximate.',
	 'authors': u'Archontia C. Giannopoulou, Daniel Lokshtanov, Saket Saurabh, Ondrej Suchy,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7891',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nTree Deletion Set has a Polynomial Kernel (but no OPT^O(1)  approximation)',
	 'urllink': u'http://arxiv.org/abs/1309.7891'}
2015-03-24 04:23:09+0000 [xxu46_7] INFO: Crawled 245 pages (at 1 pages/min), scraped 238 items (at 1 items/min)
2015-03-24 04:24:09+0000 [xxu46_7] INFO: Crawled 245 pages (at 0 pages/min), scraped 238 items (at 0 items/min)
2015-03-24 04:24:09+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6552> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 04:24:09+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6552>
	{'abstract': u'Integer-Forcing (IF) is a new framework, based on compute-and-forward, for decoding multiple integer linear combinations from the output of a Gaussian multiple-input multiple-output channel. This work applies the IF approach to arrive at a new low-complexity scheme, IF source coding, for distributed lossy compression of correlated Gaussian sources under a minimum mean squared error distortion measure. All encoders use the same nested lattice codebook. Each encoder quantizes its observation using the fine lattice as a quantizer and reduces the result modulo the coarse lattice, which plays the role of binning. Rather than directly recovering the individual quantized signals, the decoder first recovers a full-rank set of judiciously chosen integer linear combinations of the quantized signals, and then inverts it. In general, the linear combinations have smaller average powers than the original signals. This allows to increase the density of the coarse lattice, which in turn translates to smaller compression rates. We also propose and analyze a one-shot version of IF source coding, that is simple enough to potentially lead to a new design principle for analog-to-digital converters that can exploit spatial correlations between the sampled signals.',
	 'authors': u'Or Ordentlich, Uri Erez,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6552',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nInteger-Forcing Source Coding',
	 'urllink': u'http://arxiv.org/abs/1308.6552'}
2015-03-24 04:25:09+0000 [xxu46_7] INFO: Crawled 246 pages (at 1 pages/min), scraped 239 items (at 1 items/min)
2015-03-24 04:26:01+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7881> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 04:26:01+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7881>
	{'abstract': u'This study explores the throughput and delay that can be achieved by various forwarding schemes employing multiple paths and different degrees of redundancy focusing on linear network coding. The key contribution of the study is an analytical framework for modeling the throughput and delay for various schemes considering wireless mesh networks where, unicast traffic is forwarded and hop-by-hop retransmissions are employed for achieving reliability. The analytical framework is generalized for an arbitrary number of paths and hops per path. Another key contribution of the study is the evaluation and extension of the numerical results drawn from the analysis through NS-2 simulations. Our results show that in scenarios with significant interference the best throughput-delay tradeoff is achieved by single path forwarding. Moreover, when significant interference is present and network coding employs the larger packet generation size it experiences higher delay than all other schemes due to the inter-arrival times aggregating over all coded packets required to decode a packet generation.',
	 'authors': u'Manolis Ploumidis, Nikolaos Pappas, Vasilios A. Siris, Apostolos Traganitis,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7881',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nOn the Performance of Network Coding and Forwarding Schemes with  Different Degrees of Redundancy for Wireless Mesh Networks',
	 'urllink': u'http://arxiv.org/abs/1309.7881'}
2015-03-24 04:26:09+0000 [xxu46_7] INFO: Crawled 247 pages (at 1 pages/min), scraped 240 items (at 1 items/min)
2015-03-24 04:27:09+0000 [xxu46_7] INFO: Crawled 247 pages (at 0 pages/min), scraped 240 items (at 0 items/min)
2015-03-24 04:27:39+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6543> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 04:27:39+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6543>
	{'abstract': u"In a MIMO radar network the multiple transmit elements may emit waveforms that differ on power and bandwidth. In this paper, we are asking, given that these two resources are limited, what is the optimal power, optimal bandwidth and optimal joint power and bandwidth allocation for best localization of multiple targets. The well known Cr 'amer-Rao lower bound for target localization accuracy is used as a figure of merit and approximate solutions are found by minimizing a sequence of convex problems. Their quality is assessed through extensive numerical simulations and with the help of a lower-bound on the true solution. Simulations results reveal that bandwidth allocation policies have a definitely stronger impact on performance than power.",
	 'authors': u'Nil Garcia, Alexander M. Haimovich, Martial Coulon, Marco Lops,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6543',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nResource Allocation in MIMO Radar With Multiple Targets for Non-Coherent  Localization',
	 'urllink': u'http://arxiv.org/abs/1308.6543'}
2015-03-24 04:28:09+0000 [xxu46_7] INFO: Crawled 248 pages (at 1 pages/min), scraped 241 items (at 1 items/min)
2015-03-24 04:29:09+0000 [xxu46_7] INFO: Crawled 248 pages (at 0 pages/min), scraped 241 items (at 0 items/min)
2015-03-24 04:29:39+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7843> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 04:29:39+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7843>
	{'abstract': u'Wireless telemonitoring of physiological signals is an important topic in eHealth. In order to reduce on-chip energy consumption and extend sensor life, recorded signals are usually compressed before transmission. In this paper, we adopt compressed sensing (CS) as a low-power compression framework, and propose a fast block sparse Bayesian learning (BSBL) algorithm to reconstruct original signals. Experiments on real-world fetal ECG signals and epilepsy EEG signals showed that the proposed algorithm has good balance between speed and data reconstruction fidelity when compared to state-of-the-art CS algorithms. Further, we implemented the CS-based compression procedure and a low-power compression procedure based on a wavelet transform in Filed Programmable Gate Array (FPGA), showing that the CS-based compression can largely save energy and other on-chip computing resources.',
	 'authors': u'Benyuan Liu, Zhilin Zhang, Gary Xu, Hongqi Fan, Qiang Fu,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7843',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nEnergy Efficient Telemonitoring of Physiological Signals via Compressed  Sensing: A Fast Algorithm and Power Consumption Evaluation',
	 'urllink': u'http://arxiv.org/abs/1309.7843'}
2015-03-24 04:30:09+0000 [xxu46_7] INFO: Crawled 249 pages (at 1 pages/min), scraped 242 items (at 1 items/min)
2015-03-24 04:31:09+0000 [xxu46_7] INFO: Crawled 249 pages (at 0 pages/min), scraped 242 items (at 0 items/min)
2015-03-24 04:31:36+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6526> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 04:31:36+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6526>
	{'abstract': u'This work uses Game Theory to study the effectiveness of punishments as an incentive for rational nodes to follow an epidemic dissemination protocol. The dissemination process is modeled as an infinite repetition of a stage game. At the end of each stage, a monitoring mechanism informs each player of the actions of other nodes. The effectiveness of a punishing strategy is measured as the range of values for the benefit-to-cost ratio that sustain cooperation. This paper studies both public and private monitoring. Under public monitoring, we show that direct reciprocity is not an effective incentive, whereas full indirect reciprocity provides a nearly optimal effectiveness. Under private monitoring, we identify necessary conditions regarding the topology of the graph in order for punishments to be effective. When punishments are coordinated, full indirect reciprocity is also effective with private monitoring.',
	 'authors': u'Xavier Vila\xe7a, Lu\xeds Rodrigues,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6526',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nOn the Effectiveness of Punishments in a Repeated Epidemic Dissemination  Game',
	 'urllink': u'http://arxiv.org/abs/1308.6526'}
2015-03-24 04:32:09+0000 [xxu46_7] INFO: Crawled 250 pages (at 1 pages/min), scraped 243 items (at 1 items/min)
2015-03-24 04:33:09+0000 [xxu46_7] INFO: Crawled 250 pages (at 0 pages/min), scraped 243 items (at 0 items/min)
2015-03-24 04:33:24+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7841> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 04:33:24+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7841>
	{'abstract': u'We consider two variants of the classical gossip algorithm. The first variant is a version of asynchronous stochastic approximation. We highlight a fundamental difficulty associated with the classical asynchronous gossip scheme, viz., that it may not converge to a desired average, and suggest an alternative scheme based on reinforcement learning that has guaranteed convergence to the desired average. We then discuss a potential application to a wireless network setting with simultaneous link activation constraints. The second variant is a gossip algorithm for distributed computation of the Perron-Frobenius eigenvector of a nonnegative matrix. While the first variant draws upon a reinforcement learning algorithm for an average cost controlled Markov decision problem, the second variant draws upon a reinforcement learning algorithm for risk-sensitive control. We then discuss potential applications of the second variant to ranking schemes, reputation networks, and principal component analysis.',
	 'authors': u'Vivek S. Borkar, Rahul Makhijani, Rajesh Sundaresan,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7841',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nAsynchronous Gossip for Averaging and Spectral Ranking',
	 'urllink': u'http://arxiv.org/abs/1309.7841'}
2015-03-24 04:34:09+0000 [xxu46_7] INFO: Crawled 251 pages (at 1 pages/min), scraped 244 items (at 1 items/min)
2015-03-24 04:35:09+0000 [xxu46_7] INFO: Crawled 251 pages (at 0 pages/min), scraped 244 items (at 0 items/min)
2015-03-24 04:35:23+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6523> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 04:35:23+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6523>
	{'abstract': u'Accurate and comprehensible knowledge about the position of branch cuts is essential for correctly working with multi-valued functions, such as the square root and logarithm. We discuss the new tools in Maple 17 for calculating and visualising the branch cuts of such functions, and others built up from them. The cuts are described in an intuitive and accurate form, offering substantial improvement on the descriptions previously available.',
	 'authors': u'M. England, E. Cheb-Terrab, R. Bradford, J.H. Davenport, D. Wilson,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6523',
	 'subjects': u'Symbolic Computation (cs.SC)',
	 'title': u'\nBranch Cuts in Maple 17',
	 'urllink': u'http://arxiv.org/abs/1308.6523'}
2015-03-24 04:36:09+0000 [xxu46_7] INFO: Crawled 252 pages (at 1 pages/min), scraped 245 items (at 1 items/min)
2015-03-24 04:37:00+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7829> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 04:37:00+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7829>
	{'abstract': u'Bounding hull, such as convex hull, concave hull, alpha shapes etc. has vast applications in different areas especially in computational geometry. Alpha shape and concave hull are generalizations of convex hull. Unlike the convex hull, they construct non-convex enclosure on a set of points. In this paper, we introduce another generalization of convex hull, named alpha-concave hull, and compare this concept with convex hull and alpha shape. We show that the alpha-concave hull is also a generalization of an NP-complete problem named min-area TSP. We prove that computing the alpha-concave hull is NP-hard on a set of points.',
	 'authors': u'Saeed Asaeedi, Farzad Didehvar, Ali Mohades,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7829',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nAlpha-Concave Hull, a Generalization of Convex Hull',
	 'urllink': u'http://arxiv.org/abs/1309.7829'}
2015-03-24 04:37:09+0000 [xxu46_7] INFO: Crawled 253 pages (at 1 pages/min), scraped 246 items (at 1 items/min)
2015-03-24 04:38:09+0000 [xxu46_7] INFO: Crawled 253 pages (at 0 pages/min), scraped 246 items (at 0 items/min)
2015-03-24 04:38:38+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6509> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 04:38:38+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6509>
	{'abstract': u'Given an LZW/LZ78 compressed text, we want to find an approximate occurrence of a given pattern of length m. The goal is to achieve time complexity depending on the size n of the compressed representation of the text instead of its length. We consider two specific definitions of approximate matching, namely the Hamming distance and the edit distance, and show how to achieve O(nm^0.5k^2) and O(nm^0.5k^3) running time, respectively, where k is the bound on the distance. Both algorithms use just linear space. Even for very small values of k, the best previously known solutions required O(nm) time. Our main contribution is applying a periodicity-based argument in a way that is computationally effective even if we need to operate on a compressed representation of a string, while the previous solutions were either based on a dynamic programming, or a black-box application of tools developed for uncompressed strings.',
	 'authors': u'Pawel Gawrychowski, Damian Straszak,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6509',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nBeating O(nm) in approximate LZW-compressed pattern matching',
	 'urllink': u'http://arxiv.org/abs/1308.6509'}
2015-03-24 04:39:09+0000 [xxu46_7] INFO: Crawled 254 pages (at 1 pages/min), scraped 247 items (at 1 items/min)
2015-03-24 04:40:09+0000 [xxu46_7] INFO: Crawled 254 pages (at 0 pages/min), scraped 247 items (at 0 items/min)
2015-03-24 04:40:38+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7824> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 04:40:38+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7824>
	{'abstract': u'Linear regression amounts to estimating a linear model that maps features (e.g., age or gender) to corresponding data (e.g., the answer to a survey or the outcome of a medical exam). It is a ubiquitous tool in experimental sciences. We study a setting in which features are public but the data is private information. While the estimation of the linear model may be useful to participating individuals, (if, e.g., it leads to the discovery of a treatment to a disease), individuals may be reluctant to disclose their data due to privacy concerns. In this paper, we propose a generic game-theoretic model to express this trade-off. Users add noise to their data before releasing it. In particular, they choose the variance of this noise to minimize a cost comprising two components: (a) a privacy cost, representing the loss of privacy incurred by the release; and (b) an estimation cost, representing the inaccuracy in the linear model estimate. We study the Nash equilibria of this game, establishing the existence of a unique non-trivial equilibrium. We determine its efficiency for several classes of privacy and estimation costs, using the concept of the price of stability. Finally, we prove that, for a specific estimation cost, the generalized least-square estimator is optimal among all linear unbiased estimators in our non-cooperative setting: this result extends the famous Aitken/Gauss-Markov theorem in statistics, establishing that its conclusion persists even in the presence of strategic individuals.',
	 'authors': u'Stratis Ioannidis, Patrick Loiseau,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7824',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nLinear Regression as a Non-Cooperative Game',
	 'urllink': u'http://arxiv.org/abs/1309.7824'}
2015-03-24 04:41:09+0000 [xxu46_7] INFO: Crawled 255 pages (at 1 pages/min), scraped 248 items (at 1 items/min)
2015-03-24 04:42:09+0000 [xxu46_7] INFO: Crawled 255 pages (at 0 pages/min), scraped 248 items (at 0 items/min)
2015-03-24 04:42:24+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6505> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 04:42:24+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6505>
	{'abstract': u"In this paper we consider skew bisubmodular functions as introduced in [9]. We construct a convex extension of a skew bisubmodular function which we call Lov 'asz extension in correspondence to the submodular case. We use this extension to show that skew bisubmodular functions given by an oracle can be minimised in polynomial time.",
	 'authors': u'Anna Huber, Andrei Krokhin,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6505',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nOracle Tractability of Skew Bisubmodular Functions',
	 'urllink': u'http://arxiv.org/abs/1308.6505'}
2015-03-24 04:43:09+0000 [xxu46_7] INFO: Crawled 256 pages (at 1 pages/min), scraped 249 items (at 1 items/min)
2015-03-24 04:44:09+0000 [xxu46_7] INFO: Crawled 256 pages (at 0 pages/min), scraped 249 items (at 0 items/min)
2015-03-24 04:44:16+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7818> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 04:44:16+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7818>
	{'abstract': u'Polar codes are a new family of error correction codes for which efficient hardware architectures have to be defined for the encoder and the decoder. Polar codes are decoded using the successive cancellation decoding algorithm that includes partial sums computations. We take advantage of the recursive structure of polar codes to introduce an efficient partial sums computation unit that can also implements the encoder. The proposed architecture is synthesized for several codelengths in 65nm ASIC technology. The area of the resulting design is reduced up to 26% and the maximum working frequency is improved by ~25%.',
	 'authors': u'Guillaume Berhault, Camille Leroux, Christophe Jego, Dominique Dallet,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7818',
	 'subjects': u'Hardware Architecture (cs.AR)',
	 'title': u'\nPartial Sums Generation Architecture for Successive Cancellation  Decoding of Polar Codes',
	 'urllink': u'http://arxiv.org/abs/1309.7818'}
2015-03-24 04:45:09+0000 [xxu46_7] INFO: Crawled 257 pages (at 1 pages/min), scraped 250 items (at 1 items/min)
2015-03-24 04:46:09+0000 [xxu46_7] INFO: Crawled 257 pages (at 0 pages/min), scraped 250 items (at 0 items/min)
2015-03-24 04:46:12+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6504> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 04:46:12+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6504>
	{'abstract': u'For high-dimensional sparse parameter estimation problems, Log-Sum Penalty (LSP) regularization effectively reduces the sampling sizes in practice. However, it still lacks theoretical analysis to support the experience from previous empirical study. The analysis of this article shows that, like -regularization, sampling size is enough for proper LSP, where is the non-zero components of the true parameter. We also propose an efficient algorithm to solve LSP regularization problem. The solutions given by the proposed algorithm give consistent parameter estimations under less restrictive conditions than -regularization.',
	 'authors': u'Zheng Pan, Guangdong Hou, Changshui Zhang,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/e-print/1308.6504',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOn the Conditions of Sparse Parameter Estimation via Log-Sum Penalty  Regularization',
	 'urllink': u'http://arxiv.org/abs/1308.6504'}
2015-03-24 04:47:09+0000 [xxu46_7] INFO: Crawled 258 pages (at 1 pages/min), scraped 251 items (at 1 items/min)
2015-03-24 04:48:09+0000 [xxu46_7] INFO: Crawled 258 pages (at 0 pages/min), scraped 251 items (at 0 items/min)
2015-03-24 04:48:11+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7817> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 04:48:11+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7817>
	{'abstract': u'In this paper, we consider massive multiple-input multiple-output (MIMO) systems for both downlink and uplink scenarios, where three radio units (RUs) connected via one digital unit (DU) support multiple user equipments (UEs) at the cell-boundary through the same radio resource, i.e., the same time-frequency slot. Zero-forcing (ZF) and maximum ratio transmission (MRT) are considered as downlink transmitter options, while ZF and maximum ratio combining (MRC) are considered as uplink receiver options. We derive simple closed form formulas for the sum rate of each such technique. Based on our analytical results, for the downlink, we observe that vector normalization is better for ZF while matrix normalization is better for MRT, in the simple but practically relevant case where uniform power is allocated to all downlink data streams. For a given antenna and users configuration, we also derive analytically the SNR level below which MRC should be used instead of ZF. Numerical simulations confirm our analytical results.',
	 'authors': u'Yeon-Geun Lim, Chan-Byoung Chae, Giuseppe Caire,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7817',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nPerformance Analysis of Massive MIMO for Cell-Boundary Users',
	 'urllink': u'http://arxiv.org/abs/1309.7817'}
2015-03-24 04:49:09+0000 [xxu46_7] INFO: Crawled 259 pages (at 1 pages/min), scraped 252 items (at 1 items/min)
2015-03-24 04:49:47+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6487> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 04:49:47+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6487>
	{'abstract': u"This paper presents a new approach for filter design based on stochastic distances and tests between distributions. A window is defined around each pixel, overlapping samples are compared and only those which pass a goodness-of-fit test are used to compute the filtered value. The technique is applied to intensity SAR data with homogeneous regions using the Gamma model. The proposal is compared with the Lee's filter using a protocol based on Monte Carlo. Among the criteria used to quantify the quality of filters, we employ the equivalent number of looks, line and edge preservation. Moreover, we also assessed the filters by the Universal Image Quality Index and the Pearson's correlation on edges regions.",
	 'authors': u'Leonardo Torres, Tamer Cavalcante, Alejandro C. Frery,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6487',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nA New Algorithm of Speckle Filtering using Stochastic Distances',
	 'urllink': u'http://arxiv.org/abs/1308.6487'}
2015-03-24 04:50:09+0000 [xxu46_7] INFO: Crawled 260 pages (at 1 pages/min), scraped 253 items (at 1 items/min)
2015-03-24 04:51:09+0000 [xxu46_7] INFO: Crawled 260 pages (at 0 pages/min), scraped 253 items (at 0 items/min)
2015-03-24 04:51:23+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7803> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 04:51:23+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7803>
	{'abstract': u'This paper considers the problem of computing the weak visibility polygon (WVP) of any query line segment pq (or WVP(pq)) inside a given simple polygon P. We present an algorithm that preprocesses P and creates a data structure from which WVP(pq) is efficiently reported in an output sensitive manner. Our algorithm needs O(n^2 log n) time and O(n^2) space in the preprocessing phase to report WVP(pq) of any query line segment pq in time O(log^2 n + |WVP(pq)|). We improve the preprocessing time and space of current results for this problem at the expense of more query time.',
	 'authors': u'Mojtaba Nouri Bygi, Mohammad Ghodsi,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7803',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nNear Optimal Line Segment Weak Visibility Queries in Simple Polygons',
	 'urllink': u'http://arxiv.org/abs/1309.7803'}
2015-03-24 04:52:09+0000 [xxu46_7] INFO: Crawled 261 pages (at 1 pages/min), scraped 254 items (at 1 items/min)
2015-03-24 04:53:09+0000 [xxu46_7] INFO: Crawled 261 pages (at 0 pages/min), scraped 254 items (at 0 items/min)
2015-03-24 04:53:15+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6481> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 04:53:15+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6481>
	{'abstract': u'We consider nonparametric or universal sequential hypothesis testing problem when the distribution under the null hypothesis is fully known but the alternate hypothesis corresponds to some other unknown distribution. These algorithms are primarily motivated from spectrum sensing in Cognitive Radios and intruder detection in wireless sensor networks. We use easily implementable universal lossless source codes to propose simple algorithms for such a setup. The algorithms are first proposed for discrete alphabet. Their performance and asymptotic properties are studied theoretically. Later these are extended to continuous alphabets. Their performance with two well known universal source codes, Lempel-Ziv code and Krichevsky-Trofimov estimator with Arithmetic Encoder are compared. These algorithms are also compared with the tests using various other nonparametric estimators. Finally a decentralized version utilizing spatial diversity is also proposed. Its performance is analysed and asymptotic properties are proved.',
	 'authors': u'Jithin K. Sreedharan, Vinod Sharma,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6481',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nNonparametric Decentralized Sequential Detection via Universal Source  Coding',
	 'urllink': u'http://arxiv.org/abs/1308.6481'}
2015-03-24 04:54:09+0000 [xxu46_7] INFO: Crawled 262 pages (at 1 pages/min), scraped 255 items (at 1 items/min)
2015-03-24 04:55:09+0000 [xxu46_7] INFO: Crawled 262 pages (at 0 pages/min), scraped 255 items (at 0 items/min)
2015-03-24 04:55:09+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7776> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 04:55:09+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7776>
	{'abstract': u'In this paper, we show that there is no vectorial Boolean function of degree 4e, with e satisfaying certain conditions, which is APN over infinitely many extensions of its field of definition. It is a new step in the proof of the conjecture of Aubry, McGuire and Rodier',
	 'authors': u'Florian Caullery,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7776',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nA new large class of functions not APN infinitely often',
	 'urllink': u'http://arxiv.org/abs/1309.7776'}
2015-03-24 04:56:09+0000 [xxu46_7] INFO: Crawled 263 pages (at 1 pages/min), scraped 256 items (at 1 items/min)
2015-03-24 04:56:55+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6475> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 04:56:55+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6475>
	{'abstract': u'Time division multiple access (TDMA) is a method for sharing communication media. In wireless communications, TDMA algorithms often divide the radio time into timeslots of uniform size, , and then combine them into frames of uniform size, . We consider TDMA algorithms that allocate at least one timeslot in every frame to every node. Given a maximal node degree, , and no access to external references for collision detection, time or position, we consider the problem of collision-free self-stabilizing TDMA algorithms that use constant frame size. We demonstrate that this problem has no solution when the frame size is , where is the chromatic number for distance- vertex coloring. As a complement to this lower bound, we focus on proving the existence of collision-free self-stabilizing TDMA algorithms that use constant frame size of . We consider basic settings (no hardware support for collision detection and no prior clock synchronization), and the collision of concurrent transmissions from transmitters that are at most two hops apart. In the context of self-stabilizing systems that have no external reference, we are the first to study this problem (to the best of our knowledge), and use simulations to show convergence even with computation time uncertainties.',
	 'authors': u'Thomas Petig, Elad M. Schiller, Philippas Tsigas,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6475',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nSelf-stabilizing TDMA Algorithms for Wireless Ad-hoc Networks without  External Reference',
	 'urllink': u'http://arxiv.org/abs/1308.6475'}
2015-03-24 04:57:09+0000 [xxu46_7] INFO: Crawled 264 pages (at 1 pages/min), scraped 257 items (at 1 items/min)
2015-03-24 04:58:09+0000 [xxu46_7] INFO: Crawled 264 pages (at 0 pages/min), scraped 257 items (at 0 items/min)
2015-03-24 04:58:26+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7750> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 04:58:26+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7750>
	{'abstract': u'The k-Nearest Neighbor (k-NN) classification algorithm is one of the most widely-used lazy classifiers because of its simplicity and ease of implementation. It is considered to be an effective classifier and has many applications. However, its major drawback is that when sequential search is used to find the neighbors, it involves high computational cost. Speeding-up k-NN search is still an active research field. Hwang and Cho have recently proposed an adaptive cluster-based method for fast Nearest Neighbor searching. The effectiveness of this method is based on the adjustment of three parameters. However, the authors evaluated their method by setting specific parameter values and using only one dataset. In this paper, an extensive experimental study of this method is presented. The results, which are based on five real life datasets, illustrate that if the parameters of the method are carefully defined, one can achieve even better classification performance.',
	 'authors': u'Stefanos Ougiaroglou, Georgios Evangelidis, Dimitris A. Dervos,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7750',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nAn Extensive Experimental Study on the Cluster-based Reference Set  Reduction for speeding-up the k-NN Classifier',
	 'urllink': u'http://arxiv.org/abs/1309.7750'}
2015-03-24 04:59:09+0000 [xxu46_7] INFO: Crawled 265 pages (at 1 pages/min), scraped 258 items (at 1 items/min)
2015-03-24 05:00:09+0000 [xxu46_7] INFO: Crawled 265 pages (at 0 pages/min), scraped 258 items (at 0 items/min)
2015-03-24 05:00:12+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6469> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 05:00:12+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6469>
	{'abstract': u'To cope with the complex embedded system design, early design space exploration (DSE) is used to make design decisions early in the design phase. For early DSE it is crucial that the running time of the exploration is as small as possible. In this paper, we describe both the porting of our scenario-based DSE to the SPARC T3-4 server and the analysis of its performance behavior.',
	 'authors': u'P. van Stralen,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6469',
	 'subjects': u'Performance (cs.PF)',
	 'title': u'\nUsing Chip Multithreading to Speed Up Scenario-Based Design Space  Exploration',
	 'urllink': u'http://arxiv.org/abs/1308.6469'}
2015-03-24 05:01:09+0000 [xxu46_7] INFO: Crawled 266 pages (at 1 pages/min), scraped 259 items (at 1 items/min)
2015-03-24 05:02:08+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7747> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 05:02:08+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7747>
	{'abstract': u'In recent years, the international scientific community has been rocked by a number of serious cases of research misconduct. In one of these, Woo Suk Hwang, a Korean stem cell researcher published two articles on research with ground-breaking results in Science in 2004 and 2005. Both articles were later revealed to be fakes. This paper provides an overview of what research misconduct is generally understood to be, its manifestations and the extent to which they are thought to exist.',
	 'authors': u'Lutz Bornmann,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7747',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nResearch misconduct: definitions, manifestations and extent',
	 'urllink': u'http://arxiv.org/abs/1309.7747'}
2015-03-24 05:02:09+0000 [xxu46_7] INFO: Crawled 267 pages (at 1 pages/min), scraped 260 items (at 1 items/min)
2015-03-24 05:03:09+0000 [xxu46_7] INFO: Crawled 267 pages (at 0 pages/min), scraped 260 items (at 0 items/min)
2015-03-24 05:03:39+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6464> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 05:03:39+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6464>
	{'abstract': u'A network is called localizable if the positions of all the nodes of the network can be computed uniquely. If a network is localizable and embedded in plane with generic configuration, the positions of the nodes may be computed uniquely in finite time. Therefore, identifying localizable networks is an important function. If the complete information about the network is available at a single place, localizability can be tested in polynomial time. In a distributed environment, networks with trilateration orderings (popular in real applications) and wheel extensions (a specific class of localizable networks) embedded in plane can be identified by existing techniques. We propose a distributed technique which efficiently identifies a larger class of localizable networks. This class covers both trilateration and wheel extensions. In reality, exact distance is almost impossible or costly. The proposed algorithm based only on connectivity information. It requires no distance information.',
	 'authors': u'Buddhadeb Sau, Krishnendu Mukhopadhyaya,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6464',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nLocalizability of Wireless Sensor Networks: Beyond Wheel Extension',
	 'urllink': u'http://arxiv.org/abs/1308.6464'}
2015-03-24 05:04:09+0000 [xxu46_7] INFO: Crawled 268 pages (at 1 pages/min), scraped 261 items (at 1 items/min)
2015-03-24 05:04:48+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7739> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 05:04:48+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7739>
	{'abstract': u'Equality and disjointness are two of the most studied problems in communication complexity. They have been studied for both classical and also quantum communication and for various models and modes of communication. Buhrman et al. [Buh98] proved that the exact quantum communication complexity for a promise version of the equality problem is while the classical deterministic communication complexity is for two-way communication, which was the first impressively large (exponential) gap between quantum and classical (deterministic and probabilistic) communication complexity. If an error is tolerated, both quantum and probabilistic communication complexities for equality are . However, even if an error is tolerated, the gaps between quantum (probabilistic) and deterministic complexity are not larger than quadratic for the disjointness problem. It is therefore interesting to ask whether there are some promise versions of the disjointness problem for which bigger gaps can be shown. We give a positive answer to such a question. Namely, we prove that there exists an exponential gap between quantum (even probabilistic) communication complexity and classical deterministic communication complexity of some specific versions of the disjointness problem. Klauck [Kla00] proved, for any language, that the state complexity of exact quantum/classical finite automata, which is a general model of one-way quantum finite automata, is not less than the state complexity of an equivalent one-way deterministic finite automata (1DFA). In this paper we show, using a communication complexity result, that situation may be different for some promise problems. Namely, we show for certain promise problem that the gap between the state complexity of exact one-way quantum finite automata and 1DFA can be exponential.',
	 'authors': u'Jozef Gruska, Daowen Qiu, Shenggen Zheng,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7739',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nCommunication complexity of promise problems and their applications to  finite automata',
	 'urllink': u'http://arxiv.org/abs/1309.7739'}
2015-03-24 05:05:09+0000 [xxu46_7] INFO: Crawled 269 pages (at 1 pages/min), scraped 262 items (at 1 items/min)
2015-03-24 05:06:08+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6444> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 05:06:08+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6444>
	{'abstract': u'We present an algorithm that computes a maximum stable set of any perfect graph with no balanced skew-partition. We present time algorithm that colors them.',
	 'authors': u'Maria Chudnovsky, Nicolas Trotignon, Th\xe9ophile Trunck, Kristina Vuskovic,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6444',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nColoring perfect graphs with no balanced skew-partitions',
	 'urllink': u'http://arxiv.org/abs/1308.6444'}
2015-03-24 05:06:09+0000 [xxu46_7] INFO: Crawled 270 pages (at 1 pages/min), scraped 263 items (at 1 items/min)
2015-03-24 05:07:09+0000 [xxu46_7] INFO: Crawled 270 pages (at 0 pages/min), scraped 263 items (at 0 items/min)
2015-03-24 05:08:08+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7735> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 05:08:08+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7735>
	{'abstract': u'Crowd sensing is a new paradigm that leverages pervasive sensor-equipped mobile devices to provide sensing services like forensic analysis, documenting public spaces, and collaboratively constructing statistical models. Extensive user participation is indispensable for achieving good service quality. Nowadays, most of existing mechanisms focus on guaranteeing good service quality based on instantaneous extensive user participation for crowd sensing applications. Little attention has been dedicated to maximizing long-term service quality for crowd sensing applications due to their asymmetric interests, preferences, selfish behaviors, etc. To fill these gaps, in this paper, we derive the closed expression of the marginal sensing data quality based on the monopoly aggregation in economics. Furthermore, we design marginalquality based incentive mechanisms for long-term crowd sensing applications, not only to enhance extensive user participation by maximizing the expected total profits of mobile users, but also to stimulate mobile users to produce high-quality contents by applying the marginal quality. Finally, simulation results show that our mechanisms outperform the existing solutions.',
	 'authors': u'Jiajun Sun,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7735',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nLong-Term Profit-Maximizing Incentive for Crowd Sensing in Mobile Social  Networks',
	 'urllink': u'http://arxiv.org/abs/1309.7735'}
2015-03-24 05:08:09+0000 [xxu46_7] INFO: Crawled 271 pages (at 1 pages/min), scraped 264 items (at 1 items/min)
2015-03-24 05:09:09+0000 [xxu46_7] INFO: Crawled 271 pages (at 0 pages/min), scraped 264 items (at 0 items/min)
2015-03-24 05:09:52+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6437> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 05:09:52+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6437>
	{'abstract': u"This study examines the use of nonsystematic channel codes to obtain secure transmissions over the additive white Gaussian noise (AWGN) wire-tap channel. Unlike the previous approaches, we propose to implement nonsystematic coded transmission by scrambling the information bits, and characterize the bit error rate of scrambled transmissions through theoretical arguments and numerical simulations. We have focused on some examples of Bose-Chaudhuri-Hocquenghem (BCH) and low-density parity-check (LDPC) codes to estimate the security gap, which we have used as a measure of physical layer security, in addition to the bit error rate. Based on a number of numerical examples, we found that such a transmission technique can outperform alternative solutions. In fact, when an eavesdropper (Eve) has a worse channel than the authorized user (Bob), the security gap required to reach a given level of security is very small. The amount of degradation of Eve's channel with respect to Bob's that is needed to achieve sufficient security can be further reduced by implementing scrambling and descrambling operations on blocks of frames, rather than on single frames. While Eve's channel has a quality equal to or better than that of Bob's channel, we have shown that the use of a hybrid automatic repeat-request (HARQ) protocol with authentication still allows achieving a sufficient level of security. Finally, the secrecy performance of some practical schemes has also been measured in terms of the equivocation rate about the message at the eavesdropper and compared with that of ideal codes.",
	 'authors': u'Marco Baldi, Marco Bianchi, Franco Chiaraluce,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6437',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nCoding with Scrambling, Concatenation, and HARQ for the AWGN Wire-Tap  Channel: A Security Gap Analysis',
	 'urllink': u'http://arxiv.org/abs/1308.6437'}
2015-03-24 05:10:09+0000 [xxu46_7] INFO: Crawled 272 pages (at 1 pages/min), scraped 265 items (at 1 items/min)
2015-03-24 05:11:09+0000 [xxu46_7] INFO: Crawled 272 pages (at 0 pages/min), scraped 265 items (at 0 items/min)
2015-03-24 05:11:50+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7734> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 05:11:50+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7734>
	{'abstract': u'The determination of the cross correlation between an -sequence and its decimated sequence has been a long-standing research problem. Considering a ternary -sequence of period , we determine the cross correlation distribution for decimations and , where . Meanwhile, for a binary -sequence of period , we make an initial investigation for the decimation , where is even and . It is shown that the cross correlation takes at least four values. Furthermore, we confirm the validity of two famous conjectures due to Sarwate et al. and Helleseth in this case.',
	 'authors': u'Tao Zhang, Shuxing Li, Tao Feng, Gennian Ge,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7734',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nSome New Results on the Cross Correlation of $m$-sequences',
	 'urllink': u'http://arxiv.org/abs/1309.7734'}
2015-03-24 05:12:09+0000 [xxu46_7] INFO: Crawled 273 pages (at 1 pages/min), scraped 266 items (at 1 items/min)
2015-03-24 05:12:45+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6433> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 05:12:45+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6433>
	{'abstract': u'A emph is a graph made of a cycle of length at least~4 together with a vertex that has at least three neighbors in the cycle. We prove that the problem whose instance is a graph and whose question is "does contains a wheel as an induced subgraph" is NP-complete. We also settle the complexity of several similar problems.',
	 'authors': u'Emilie Diot, S\xe9bastien Tavenas, Nicolas Trotignon,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6433',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nDetecting wheels',
	 'urllink': u'http://arxiv.org/abs/1308.6433'}
2015-03-24 05:13:09+0000 [xxu46_7] INFO: Crawled 274 pages (at 1 pages/min), scraped 267 items (at 1 items/min)
2015-03-24 05:14:09+0000 [xxu46_7] INFO: Crawled 274 pages (at 0 pages/min), scraped 267 items (at 0 items/min)
2015-03-24 05:14:26+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7731> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 05:14:26+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7731>
	{'abstract': u'We consider the problem of synthesizing optimal linear feedback policies subject to arbitrary convex constraints on the feedback matrix. This is known to be a hard problem in the usual formulations () and previous works have focused on characterizing classes of structural constraints that allow efficient solution through convex optimization or dynamic programming techniques. In this paper, we propose a new control objective and show that this formulation makes the problem of computing optimal linear feedback matrices convex under arbitrary convex constraints on the feedback matrix. This allows us to solve problems in decentralized control (sparsity in the feedback matrices), control with delays and variable impedance control. Although the control objective is nonstandard, we present theoretical and empirical evidence that it agrees well with standard notions of control. We also present an extension to nonlinear control affine systems. We present numerical experiments validating our approach.',
	 'authors': u'Krishnamurthy Dvijotham, Emanuel Todorov, Maryam Fazel,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7731',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nConvex Structured Controller Design',
	 'urllink': u'http://arxiv.org/abs/1309.7731'}
2015-03-24 05:15:09+0000 [xxu46_7] INFO: Crawled 275 pages (at 1 pages/min), scraped 268 items (at 1 items/min)
2015-03-24 05:16:09+0000 [xxu46_7] INFO: Crawled 275 pages (at 0 pages/min), scraped 268 items (at 0 items/min)
2015-03-24 05:16:26+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6432> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 05:16:26+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6432>
	{'abstract': u'The problem of stationary robust L_infinity-induced deconvolution filtering for the uncertain continuous-time linear stochastic systems is addressed. The state space model of the system contains state- and input-dependent noise and deterministic parameter uncertainties residing in a given polytope. In the presence of input-dependent noise, we extend the derived lemma in Berman and Shaked (2010) characterizing the induced L_infinity norm by linear matrix inequalities (LMIs), according to which we solve the deconvolution problem in the quadratic framework. By decoupling product terms between the Lyapunov matrix and system matrices, an improved version of the proposed L_infinity-induced norm bound lemma for continuous-time stochastic systems is obtained, which allows us to realize exploit parameter-dependent stability idea in the deconvolution filter design. The theories presented are utilized for sensor fault reconstruction in uncertain linear stochastic systems. The effectiveness and advantages of the proposed design methods are shown via two numerical examples.',
	 'authors': u'Mehrdad Tabarraie,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6432',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nRobust L_infinity-induced deconvolution filtering for linear stochastic  systems and its application to fault reconstruction',
	 'urllink': u'http://arxiv.org/abs/1308.6432'}
2015-03-24 05:17:09+0000 [xxu46_7] INFO: Crawled 276 pages (at 1 pages/min), scraped 269 items (at 1 items/min)
2015-03-24 05:18:09+0000 [xxu46_7] INFO: Crawled 276 pages (at 0 pages/min), scraped 269 items (at 0 items/min)
2015-03-24 05:18:15+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7724> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 05:18:15+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7724>
	{'abstract': u'In this paper, we construct a data structure to efficiently compute the longest increasing subsequence of a sequence subject to dynamic updates. Our data structure supports a query for the longest increasing subsequence in worst-case time and supports inserts anywhere in the sequence in worst-case time (where is the length of the longest increasing subsequence). The same data structure with a minor modification supports worst-case time insertions if the insertions are performed at the end of the sequence. The data structure presented can also be augmented to support delete operations in the same worst-case time as insertions.',
	 'authors': u'Alex Chen, Timothy Chu, Nathan Pinsker,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7724',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nThe Dynamic Longest Increasing Subsequence Problem',
	 'urllink': u'http://arxiv.org/abs/1309.7724'}
2015-03-24 05:19:09+0000 [xxu46_7] INFO: Crawled 277 pages (at 1 pages/min), scraped 270 items (at 1 items/min)
2015-03-24 05:20:09+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6415> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 05:20:09+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6415>
	{'abstract': u'Procedural content generation (PCG) has recently become one of the hottest topics in computational intelligence and AI game researches. Among a variety of PCG techniques, search-based approaches overwhelmingly dominate PCG development at present. While SBPCG leads to promising results and successful applications, it poses a number of challenges ranging from representation to evaluation of the content being generated. In this paper, we present an alternative yet generic PCG framework, named learning-based procedure content generation (LBPCG), to provide potential solutions to several challenging problems in existing PCG techniques. By exploring and exploiting information gained in game development and public beta test via data-driven learning, our framework can generate robust content adaptable to end-user or target players on-line with minimal interruption to their experience. Furthermore, we develop enabling techniques to implement the various models required in our framework. For a proof of concept, we have developed a prototype based on the classic open source first-person shooter game, Quake. Simulation results suggest that our framework is promising in generating quality content.',
	 'authors': u'Jonathan Roberts, Ke Chen,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6415',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nLearning-Based Procedural Content Generation',
	 'urllink': u'http://arxiv.org/abs/1308.6415'}
2015-03-24 05:20:09+0000 [xxu46_7] INFO: Crawled 278 pages (at 1 pages/min), scraped 271 items (at 1 items/min)
2015-03-24 05:21:09+0000 [xxu46_7] INFO: Crawled 278 pages (at 0 pages/min), scraped 271 items (at 0 items/min)
2015-03-24 05:21:18+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7723> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 05:21:18+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7723>
	{'abstract': u'This paper is concerned with performance analysis for data association, in a target tracking environment. Effects of misassociation are considered in a simple (linear) multiscan framework so as to provide closed-form expressions of the probability of correct association. In this paper, we focus on the development of explicit approximations of this probability. Via rigorous calculations the effect of dimensioning parameters (number of scans, false measurement positions or densities) is analyzed, for various modelings of the false measurements. Remarkably, it is possible to derive very simple expressions of the probability of correct association which are independent of the scenario kinematic parameters.',
	 'authors': u'Adrien Ickowicz, Jean-Pierre Le Cadre,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7723',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOn the Effect of Data Contamination on Track Purity',
	 'urllink': u'http://arxiv.org/abs/1309.7723'}
2015-03-24 05:22:09+0000 [xxu46_7] INFO: Crawled 279 pages (at 1 pages/min), scraped 272 items (at 1 items/min)
2015-03-24 05:22:44+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6413> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 05:22:44+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6413>
	{'abstract': u'Service orientation fosters a high-level model for distributed applications development, which is based on the discovery, composition and reuse of existing software services. However, the heterogeneity among current service-oriented technologies renders the important task of service discovery tedious and ineffective. This dissertation proposes a new approach to address this challenge. Specifically, it contributes a framework supporting the unified discovery of heterogeneous services, with a focus on web, peer-to-peer, and grid services. The framework comprises a service query language and its enacting service discovery engine. Overall, the proposed solution is characterized by generality and flexibility, which are ensured by appropriate abstractions, extension points, and their sup- porting mechanisms. The viability, performance, and effectiveness of the proposed framework are demonstrated by experimental measurements.',
	 'authors': u'Michael Pantazoglou,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6413',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nDevelopment of a language and its enacting engine for the unified  discovery of heterogeneous services',
	 'urllink': u'http://arxiv.org/abs/1308.6413'}
2015-03-24 05:23:09+0000 [xxu46_7] INFO: Crawled 280 pages (at 1 pages/min), scraped 273 items (at 1 items/min)
2015-03-24 05:24:09+0000 [xxu46_7] INFO: Crawled 280 pages (at 0 pages/min), scraped 273 items (at 0 items/min)
2015-03-24 05:24:40+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7720> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 05:24:40+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7720>
	{'abstract': u'Large-scale storage cluster systems need to manage a vast amount of information denoting combinations of data identifiers (IDs) and corresponding nodes that store the data. Management using data distribution algorithms, rather than management using tables, has been proposed in recent research. In algorithm management, data are distributed in accordance with a data distribution algorithm that is capable of determining, on the basis of the datum ID, the node in which the required data is being stored. Among the requirements for a data distribution algorithm are short calculation times, low memory consumption, uniform data distribution in accordance with the capacity of each node and the ability to handle the addition or removal of nodes. This paper presents a data distribution algorithm called ASURA (Advanced Scalable and Uniform storage by Random number Algorithm), which satisfies these requirements. It offers roughly 0.6-s calculation time, kilobyte-order memory consumption, less than 1% maximum variability between nodes in data distribution, data distribution in accordance with the capacity of each node and optimal data movement to maintain data distribution in accordance with node capacity when nodes are added or removed. ASURA is contrasted in this paper qualitatively and quantitatively with representative data distribution algorithms: Consistent Hashing and Straw Buckets in CRUSH. The comparison results show that ASURA can achieve the same storage cluster capacity as Consistent Hashing with dozens fewer nodes by virtue of the uniformity of its distribution with the same level calculation time. They also show that the execution time of ASURA is shorter than that of Straw Buckets in CRUSH. The results reveal that ASURA is the best algorithm for large-scale storage cluster systems.',
	 'authors': u'Ken-ichiro Ishikawa,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7720',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nASURA: Scalable and Uniform Data Distribution Algorithm for Storage  Clusters',
	 'urllink': u'http://arxiv.org/abs/1309.7720'}
2015-03-24 05:25:09+0000 [xxu46_7] INFO: Crawled 281 pages (at 1 pages/min), scraped 274 items (at 1 items/min)
2015-03-24 05:25:42+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6401> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 05:25:42+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6401>
	{'abstract': u'In this paper we present a practical approach for generating an occlusion-free textured 3D map of urban facades by the synergistic use of terrestrial images, 3D point clouds and area-based information. Particularly in dense urban environments, the high presence of urban objects in front of the facades causes significant difficulties for several stages in computational building modeling. Major challenges lie on the one hand in extracting complete 3D facade quadrilateral delimitations and on the other hand in generating occlusion-free facade textures. For these reasons, we describe a straightforward approach for completing and recovering facade geometry and textures by exploiting the data complementarity of terrestrial multi-source imagery and area-based information.',
	 'authors': u'Karim Hammoudi, Fadi Dornaika, Bahman Soheilian, Bruno Vallet, John McDonald, Nicolas Paparoditis,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6401',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nA Synergistic Approach for Recovering Occlusion-Free Textured 3D Maps of  Urban Facades from Heterogeneous Cartographic Data',
	 'urllink': u'http://arxiv.org/abs/1308.6401'}
2015-03-24 05:26:09+0000 [xxu46_7] INFO: Crawled 282 pages (at 1 pages/min), scraped 275 items (at 1 items/min)
2015-03-24 05:27:09+0000 [xxu46_7] INFO: Crawled 282 pages (at 0 pages/min), scraped 275 items (at 0 items/min)
2015-03-24 05:27:41+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7712> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 05:27:41+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7712>
	{'abstract': u'The concept of deploying a large number of antennas at the base station, often called massive multiple-input multiple-output (MIMO), has drawn considerable interest because of its potential ability to revolutionize current wireless communication systems. Most literature on massive MIMO systems assumes time division duplexing (TDD), although frequency division duplexing (FDD) dominates current cellular systems. Due to the large number of transmit antennas at the base station, currently standardized approaches would require a large percentage of the precious downlink and uplink resources in FDD massive MIMO be used for training signal transmissions and channel state information (CSI) feedback. To reduce the overhead of the downlink training phase, we propose practical open-loop and closed-loop training frameworks in this paper. We assume the base station and the user share a common set of training signals in advance. In open-loop training, the base station transmits training signals in a round-robin manner, and the user successively estimates the current channel using long-term channel statistics such as temporal and spatial correlations and previous channel estimates. In closed-loop training, the user feeds back the best training signal to be sent in the future based on channel prediction and the previously received training signals. With a small amount of feedback from the user to the base station, closed-loop training offers better performance in the data communication phase, especially when the signal-to-noise ratio is low, the number of transmit antennas is large, or prior channel estimates are not accurate at the beginning of the communication setup, all of which would be mostly beneficial for massive MIMO systems.',
	 'authors': u'Junil Choi, David J. Love, Patrick Bidigare,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7712',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nDownlink Training Techniques for FDD Massive MIMO Systems: Open-Loop and  Closed-Loop Training with Memory',
	 'urllink': u'http://arxiv.org/abs/1309.7712'}
2015-03-24 05:28:09+0000 [xxu46_7] INFO: Crawled 283 pages (at 1 pages/min), scraped 276 items (at 1 items/min)
2015-03-24 05:29:09+0000 [xxu46_7] INFO: Crawled 283 pages (at 0 pages/min), scraped 276 items (at 0 items/min)
2015-03-24 05:29:36+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6388> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 05:29:36+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6388>
	{'abstract': u'In this paper we propose the Graduated NonConvexity and Graduated Concavity Procedure (GNCGCP) as a general optimization framework to approximately solve the combinatorial optimization problems on the set of partial permutation matrices. GNCGCP comprises two sub-procedures, graduated nonconvexity (GNC) which realizes a convex relaxation and graduated concavity (GC) which realizes a concave relaxation. It is proved that GNCGCP realizes exactly a type of convex-concave relaxation procedure (CCRP), but with a much simpler formulation without needing convex or concave relaxation in an explicit way. Actually, GNCGCP involves only the gradient of the objective function and is therefore very easy to use in practical applications. Two typical NP-hard problems, (sub)graph matching and quadratic assignment problem (QAP), are employed to demonstrate its simplicity and state-of-the-art performance.',
	 'authors': u'Zhi-Yong Liu, Hong Qiao,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6388',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nGNCGCP - Graduated NonConvexity and Graduated Concavity Procedure',
	 'urllink': u'http://arxiv.org/abs/1308.6388'}
2015-03-24 05:30:09+0000 [xxu46_7] INFO: Crawled 284 pages (at 1 pages/min), scraped 277 items (at 1 items/min)
2015-03-24 05:31:09+0000 [xxu46_7] INFO: Crawled 284 pages (at 0 pages/min), scraped 277 items (at 0 items/min)
2015-03-24 05:31:33+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7702> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 05:31:33+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7702>
	{'abstract': u"We present a new model of the evolutionary dynamics and the growth of on-line social networks. The model emulates people's strategies for acquiring information in social networks, emphasising the local subjective view of an individual and what kind of information the individual can acquire when arriving in a new social context. The model proceeds through two phases: (a) a discovery phase, in which the individual becomes aware of the surrounding world and (b) an elaboration phase, in which the individual elaborates locally the information trough a cognitive-inspired algorithm. Model generated networks reproduce main features of both theoretical and real-world networks, such as high clustering coefficient, low characteristic path length, strong division in communities, and variability of degree distributions.",
	 'authors': u'Emanuele Massaro, Henrik Olsson, Andrea Guazzini, Franco Bagnoli,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7702',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nImpact of local information in growing networks',
	 'urllink': u'http://arxiv.org/abs/1309.7702'}
2015-03-24 05:32:09+0000 [xxu46_7] INFO: Crawled 285 pages (at 1 pages/min), scraped 278 items (at 1 items/min)
2015-03-24 05:33:09+0000 [xxu46_7] INFO: Crawled 285 pages (at 0 pages/min), scraped 278 items (at 0 items/min)
2015-03-24 05:33:26+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6384> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 05:33:26+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6384>
	{'abstract': u'Motivated by a problem in the theory of randomized search heuristics, we give a very precise analysis for the coupon collector problem where the collector starts with a random set of coupons (chosen uniformly from all sets). We show that the expected number of rounds until we have a coupon of each type is , where denotes the th harmonic number when is even, and when is odd. Consequently, the coupon collector with random initial stake is by half a round faster than the one starting with exactly coupons (apart from additive terms). This result implies that classic simple heuristic called emph needs an expected number of iterations to find the optimum of any monotonic function defined on bit-strings of length .',
	 'authors': u'Benjamin Doerr, Carola Doerr,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6384',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nCollecting Coupons with Random Initial Stake',
	 'urllink': u'http://arxiv.org/abs/1308.6384'}
2015-03-24 05:34:09+0000 [xxu46_7] INFO: Crawled 286 pages (at 1 pages/min), scraped 279 items (at 1 items/min)
2015-03-24 05:34:54+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7698> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 05:34:54+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7698>
	{'abstract': u"We outline a model to study the evolution of cooperation in a population of agents playing the prisoner's dilemma in signed networks. We highlight that if only dyadic interactions are taken into account, cooperation never evolves. However, when triadic considerations are introduced, a window of opportunity for emergence of cooperation as a stable behaviour emerges.",
	 'authors': u'Simone Righi, K\xe1roly Tak\xe1cs,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7698',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nSigned Networks, Triadic Interactions and the Evolution of Cooperation',
	 'urllink': u'http://arxiv.org/abs/1309.7698'}
2015-03-24 05:35:09+0000 [xxu46_7] INFO: Crawled 287 pages (at 1 pages/min), scraped 280 items (at 1 items/min)
2015-03-24 05:36:09+0000 [xxu46_7] INFO: Crawled 287 pages (at 0 pages/min), scraped 280 items (at 0 items/min)
2015-03-24 05:36:52+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6373> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 05:36:52+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6373>
	{'abstract': u'Starting from special near-bent functions in dimension 2t-1 we construct bent functions in dimension 2t having a specific derivative. We deduce new famillies of bent functions',
	 'authors': u'Jacques Wolfmann,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6373',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nSpecial Bent and Near-bent Functions',
	 'urllink': u'http://arxiv.org/abs/1308.6373'}
2015-03-24 05:37:09+0000 [xxu46_7] INFO: Crawled 288 pages (at 1 pages/min), scraped 281 items (at 1 items/min)
2015-03-24 05:38:09+0000 [xxu46_7] INFO: Crawled 288 pages (at 0 pages/min), scraped 281 items (at 0 items/min)
2015-03-24 05:38:52+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7697> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 05:38:52+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7697>
	{'abstract': u'Over the last decades, the amount of data of all kinds available electronically has increased dramatically. Data are accessible through a range of interfaces including Web browsers, database query languages, application-specific interfaces, built on top of a number of different data exchange formats. All these data span from un-structured to highly structured data. Very often, some of them have structure even if the structure is implicit, and not as rigid or regular as that found in standard database systems. Spreadsheet documents are prototypical in this respect. Spreadsheets are the lightweight technology able to supply companies with easy to build business management and business intelligence applications, and business people largely adopt spreadsheets as smart vehicles for data files generation and sharing. Actually, the more spreadsheets grow in complexity (e.g., their use in product development plans and quoting), the more their arrangement, maintenance, and analysis appear as a knowledge-driven activity. The algorithmic approach to the problem of automatic data structure extraction from spreadsheet documents (i.e., grid-structured and free topological-related data) emerges from the WIA project: Worksheets Intelligent Analyser. The WIA-algorithm shows how to provide a description of spreadsheet contents in terms of higher level of abstractions or conceptualisations. In particular, the WIA-algorithm target is about the extraction of i) the calculus work-flow implemented in the spreadsheets formulas and ii) the logical role played by the data which take part into the calculus. The aim of the resulting conceptualisations is to provide spreadsheets with abstract representations useful for further model refinements and optimizations through evolutionary algorithms computations.',
	 'authors': u'Gianluca Colombo, Ettore Colombo, Andrea Bonomi, Alessandro Mosca, Simone Bassis,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7697',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nSemi-structured data extraction and modelling: the WIA Project',
	 'urllink': u'http://arxiv.org/abs/1309.7697'}
2015-03-24 05:39:09+0000 [xxu46_7] INFO: Crawled 289 pages (at 1 pages/min), scraped 282 items (at 1 items/min)
2015-03-24 05:40:09+0000 [xxu46_7] INFO: Crawled 289 pages (at 0 pages/min), scraped 282 items (at 0 items/min)
2015-03-24 05:40:45+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6368> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 05:40:45+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6368>
	{'abstract': u'We explore various techniques to incorporate grid-like layout conventions into a force-directed, constraint-based graph layout framework. In doing so we are able to provide high-quality layout---with predominantly axis-aligned edges---that is more flexible than previous grid-like layout methods and which can capture layout conventions in notations such as SBGN (Systems Biology Graphical Notation). Furthermore, the layout is easily able to respect user-defined constraints and adapt to interaction in online systems and diagram editors such as Dunnart.',
	 'authors': u'Steve Kieffer, Tim Dwyer, Kim Marriott, Michael Wybrow,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6368',
	 'subjects': u'Human-Computer Interaction (cs.HC)',
	 'title': u'\nIncremental Grid-like Layout Using Soft and Hard Constraints',
	 'urllink': u'http://arxiv.org/abs/1308.6368'}
2015-03-24 05:41:09+0000 [xxu46_7] INFO: Crawled 290 pages (at 1 pages/min), scraped 283 items (at 1 items/min)
2015-03-24 05:41:49+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7696> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 05:41:49+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7696>
	{'abstract': u'An extensive rewiring of cell metabolism supports enhanced proliferation in cancer cells. We propose a systems level approach to describe this phenomenon based on Flux Balance Analysis (FBA). The approach does not explicit a cell biomass formation reaction to be maximized, but takes into account an ensemble of alternative flux distributions that match the cancer metabolic rewiring (CMR) phenotype description. The underlying concept is that the analysis the common/distinguishing properties of the ensemble can provide indications on how CMR is achieved and sustained and thus on how it can be controlled.',
	 'authors': u'Chiara Damiani, Riccardo Colombo, Sara Molinari, Dario Pescini, Daniela Gaglio, Marco Vanoni,  et al. (2 additional authors not shown),',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7696',
	 'subjects': u'Computational Engineering, Finance, and Science (cs.CE)',
	 'title': u'\nAn ensemble approach to the study of the emergence of metabolic and  proliferative disorders via Flux Balance Analysis',
	 'urllink': u'http://arxiv.org/abs/1309.7696'}
2015-03-24 05:42:09+0000 [xxu46_7] INFO: Crawled 291 pages (at 1 pages/min), scraped 284 items (at 1 items/min)
2015-03-24 05:43:09+0000 [xxu46_7] INFO: Crawled 291 pages (at 0 pages/min), scraped 284 items (at 0 items/min)
2015-03-24 05:43:50+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6363> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 05:43:50+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6363>
	{'abstract': u"This work proposes a method for the measurement of a country's digital investigation capacity and saturation for the assessment of future capacity expansion. The focus is on external, or international, partners being a factor that could negatively affect the return on investment when attempting to expand investigation capacity nationally. This work concludes with the argument that when dealing with digital crime, target international partners should be a consideration in expansion, and could potentially be a bottleneck of investigation requests.",
	 'authors': u'Joshua I. James, Yunsik Jake Jang,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6363',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nMeasuring digital crime investigation capacity to guide international  crime prevention strategies',
	 'urllink': u'http://arxiv.org/abs/1308.6363'}
2015-03-24 05:44:09+0000 [xxu46_7] INFO: Crawled 292 pages (at 1 pages/min), scraped 285 items (at 1 items/min)
2015-03-24 05:45:09+0000 [xxu46_7] INFO: Crawled 292 pages (at 0 pages/min), scraped 285 items (at 0 items/min)
2015-03-24 05:45:41+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7695> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 05:45:41+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7695>
	{'abstract': u'The study of biological systems witnessed a pervasive cross-fertilization between experimental investigation and computational methods. This gave rise to the development of new methodologies, able to tackle the complexity of biological systems in a quantitative manner. Computer algorithms allow to faithfully reproduce the dynamics of the corresponding biological system, and, at the price of a large number of simulations, it is possible to extensively investigate the system functioning across a wide spectrum of natural conditions. To enable multiple analysis in parallel, using cheap, diffused and highly efficient multi-core devices we developed GPU-powered simulation algorithms for stochastic, deterministic and hybrid modeling approaches, so that also users with no knowledge of GPUs hardware and programming can easily access the computing power of graphics engines.',
	 'authors': u'Daniela Besozzi, Giulio Caravagna, Paolo Cazzaniga, Marco Nobile, Dario Pescini, Alessandro Re,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7695',
	 'subjects': u'Computational Engineering, Finance, and Science (cs.CE)',
	 'title': u'\nGPU-powered Simulation Methodologies for Biological Systems',
	 'urllink': u'http://arxiv.org/abs/1309.7695'}
2015-03-24 05:46:09+0000 [xxu46_7] INFO: Crawled 293 pages (at 1 pages/min), scraped 286 items (at 1 items/min)
2015-03-24 05:47:09+0000 [xxu46_7] INFO: Crawled 293 pages (at 0 pages/min), scraped 286 items (at 0 items/min)
2015-03-24 05:47:10+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6356> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 05:47:10+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6356>
	{'abstract': u'Respondent-driven sampling (RDS) is a commonly used method for acquiring data on hidden communities, i.e., those that lack unbiased sampling frames or face social stigmas that make their mem- bers unwilling to identify themselves. Obtaining accurate statistical data about such communities is important because, for instance, they often have different health burdens from the greater population, and without good statistics it is hard and expensive to effectively reach them for pre- vention or treatment interventions. Online social networks (OSN) have the potential to transform RDS for the better. We present a new RDS recruitment protocol for (OSNs) and show via simulation that it out- performs the standard RDS protocol in terms of sampling accuracy and approaches the accuracy of Markov chain Monte Carlo random walks.',
	 'authors': u'Christopher M. Homan, Vincent Silenzio, Randall Sell,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6356',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nRespondent-Driven Sampling in Online Social Networks',
	 'urllink': u'http://arxiv.org/abs/1308.6356'}
2015-03-24 05:48:09+0000 [xxu46_7] INFO: Crawled 294 pages (at 1 pages/min), scraped 287 items (at 1 items/min)
2015-03-24 05:48:57+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7694> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 05:48:57+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7694>
	{'abstract': u'An approach that combines Self-Organizing maps, hierarchical clustering and network components is presented, aimed at comparing protein conformational ensembles obtained from multiple Molecular Dynamic simulations. As a first result the original ensembles can be summarized by using only the representative conformations of the clusters obtained. In addition the network components analysis allows to discover and interpret the dynamic behavior of the conformations won by each neuron. The results showed the ability of this approach to efficiently derive a functional interpretation of the protein dynamics described by the original conformational ensemble, highlighting its potential as a support for protein engineering.',
	 'authors': u'Domenico Fraccalvieri, Laura Bonati, Fabio Stella,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7694',
	 'subjects': u'Computational Engineering, Finance, and Science (cs.CE)',
	 'title': u'\nSelf Organizing Maps to efficiently cluster and functionally interpret  protein conformational ensembles',
	 'urllink': u'http://arxiv.org/abs/1309.7694'}
2015-03-24 05:49:09+0000 [xxu46_7] INFO: Crawled 295 pages (at 1 pages/min), scraped 288 items (at 1 items/min)
2015-03-24 05:50:09+0000 [xxu46_7] INFO: Crawled 295 pages (at 0 pages/min), scraped 288 items (at 0 items/min)
2015-03-24 05:50:52+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6339> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 05:50:52+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6339>
	{'abstract': u"This paper analyzes circulant Johnson-Lindenstrauss (JL) embeddings which, as an important class of structured random JL embeddings, are formed by randomizing the column signs of a circulant matrix generated by a random vector. With the help of recent decoupling techniques and matrix-valued Bernstein inequalities, we obtain a new bound for Gaussian circulant JL embeddings. Moreover, by using the Laplace transform technique (also called Bernstein's trick), we extend the result to subgaussian case. The bounds in this paper offer a small improvement over the current best bounds for Gaussian circulant JL embeddings for certain parameter regimes and are derived using more direct methods.",
	 'authors': u'Hui Zhang, Lizhi Cheng,',
	 'category': u'Computer Science ',
	 'date': '2013-8-29',
	 'pdflink': u'http://arxiv.org/pdf/1308.6339',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nNew bounds for circulant Johnson-Lindenstrauss embeddings',
	 'urllink': u'http://arxiv.org/abs/1308.6339'}
2015-03-24 05:51:09+0000 [xxu46_7] INFO: Crawled 296 pages (at 1 pages/min), scraped 289 items (at 1 items/min)
2015-03-24 05:52:09+0000 [xxu46_7] INFO: Crawled 296 pages (at 0 pages/min), scraped 289 items (at 0 items/min)
2015-03-24 05:52:31+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7693> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 05:52:31+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7693>
	{'abstract': u'The preliminary analyses on a multiscale model of intestinal crypt dynamics are here presented. The model combines a morphological model, based on the Cellular Potts Model (CPM), and a gene regulatory network model, based on Noisy Random Boolean Networks (NRBNs). Simulations suggest that the stochastic differentiation process is itself sufficient to ensure the general homeostasis in the asymptotic states, as proven by several measures.',
	 'authors': u'Giulio Caravagna, Alex Graudenzi, Marco Antoniotti, Giovanni de Matteis,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7693',
	 'subjects': u'Computational Engineering, Finance, and Science (cs.CE)',
	 'title': u'\nAnalysis of the spatial and dynamical properties of a multiscale model  of intestinal crypts',
	 'urllink': u'http://arxiv.org/abs/1309.7693'}
2015-03-24 05:53:09+0000 [xxu46_7] INFO: Crawled 297 pages (at 1 pages/min), scraped 290 items (at 1 items/min)
2015-03-24 05:54:09+0000 [xxu46_7] INFO: Crawled 297 pages (at 0 pages/min), scraped 290 items (at 0 items/min)
2015-03-24 05:54:17+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6324> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 05:54:17+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6324>
	{'abstract': u'In this paper, we apply Classification Restricted Boltzmann Machine (ClassRBM) to the problem of predicting breast cancer recurrence. According to the Polish National Cancer Registry, in 2010 only, the breast cancer caused almost 25% of all diagnosed cases of cancer in Poland. We propose how to use ClassRBM for predicting breast cancer return and discovering relevant inputs (symptoms) in illness reappearance. Next, we outline a general probabilistic framework for learning Boltzmann machines with masks, which we refer to as Dropping. The fashion of generating masks leads to different learning methods, i.e., DropOut, DropConnect. We propose a new method called DropPart which is a generalization of DropConnect. In DropPart the Beta distribution instead of Bernoulli distribution in DropConnect is used. At the end, we carry out an experiment using real-life dataset consisting of 949 cases, provided by the Institute of Oncology Ljubljana.',
	 'authors': u'Jakub M. Tomczak,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6324',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nPrediction of breast cancer recurrence using Classification Restricted  Boltzmann Machine with Dropping',
	 'urllink': u'http://arxiv.org/abs/1308.6324'}
2015-03-24 05:55:09+0000 [xxu46_7] INFO: Crawled 298 pages (at 1 pages/min), scraped 291 items (at 1 items/min)
2015-03-24 05:55:47+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7692> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 05:55:47+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7692>
	{'abstract': u'The Spatial Processes package enables an explicit definition of a spatial environment on top of the normal dynamic modeling SBML capabilities. The possibility of an explicit representation of spatial dynamics increases the representation power of SBML. In this work we used those new SBML features to define an extensive model of colonic crypts composed of the main cellular types (from stem cells to fully differentiated cells), alongside their spatial dynamics.',
	 'authors': u'Daniele Ramazzotti, Carlo Maj, Marco Antoniotti,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7692',
	 'subjects': u'Computational Engineering, Finance, and Science (cs.CE)',
	 'title': u'\nA Model of Colonic Crypts using SBML Spatial',
	 'urllink': u'http://arxiv.org/abs/1309.7692'}
2015-03-24 05:56:09+0000 [xxu46_7] INFO: Crawled 299 pages (at 1 pages/min), scraped 292 items (at 1 items/min)
2015-03-24 05:57:09+0000 [xxu46_7] INFO: Crawled 299 pages (at 0 pages/min), scraped 292 items (at 0 items/min)
2015-03-24 05:57:42+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6319> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 05:57:42+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6319>
	{'abstract': u'Characterizing noisy or ancient documents is a challenging problem up to now. Many techniques have been done in order to effectuate feature extraction and image indexation for such documents. Global approaches are in general less robust and exact than local approaches. That\'s why, we propose in this paper, a hybrid system based on global approach(fractal dimension), and a local one based on SIFT descriptor. The Scale Invariant Feature Transform seems to do well with our application since it\'s rotation invariant and relatively robust to changing illumination.In the first step the calculation of fractal dimension is applied to images in order to eliminate images which have distant features than image request characteristics. Next, the SIFT is applied to show which images match well the request. However the average matching time using the hybrid approach is better than "fractal dimension" and "SIFT descriptor" if they are used alone.',
	 'authors': u'Nizar Zaghden, Remy Mullot, Mohamed Adel Alimi,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6319',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nA proposition of a robust system for historical document images  indexation',
	 'urllink': u'http://arxiv.org/abs/1308.6319'}
2015-03-24 05:58:09+0000 [xxu46_7] INFO: Crawled 300 pages (at 1 pages/min), scraped 293 items (at 1 items/min)
2015-03-24 05:59:09+0000 [xxu46_7] INFO: Crawled 300 pages (at 0 pages/min), scraped 293 items (at 0 items/min)
2015-03-24 05:59:41+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7691> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 05:59:41+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7691>
	{'abstract': u'In this work we introduce some preliminary analyses on the role of a semi-permeable membrane in the dynamics of a stochastic model of catalytic reaction sets (CRSs) of molecules. The results of the simulations performed on ensembles of randomly generated reaction schemes highlight remarkable differences between this very simple protocell description model and the classical case of the continuous stirred-tank reactor (CSTR). In particular, in the CSTR case, distinct simulations with the same reaction scheme reach the same dynamical equilibrium, whereas, in the protocell case, simulations with identical reaction schemes can reach very different dynamical states, despite starting from the same initial conditions.',
	 'authors': u'Roberto Serra, Alessandro Filisetti, Alex Graudenzi, Chiara Damiani, Marco Villani,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7691',
	 'subjects': u'Computational Engineering, Finance, and Science (cs.CE)',
	 'title': u'\nA model of protocell based on the introduction of a semi-permeable  membrane in a stochastic model of catalytic reaction networks',
	 'urllink': u'http://arxiv.org/abs/1309.7691'}
2015-03-24 06:00:09+0000 [xxu46_7] INFO: Crawled 301 pages (at 1 pages/min), scraped 294 items (at 1 items/min)
2015-03-24 06:01:09+0000 [xxu46_7] INFO: Crawled 301 pages (at 0 pages/min), scraped 294 items (at 0 items/min)
2015-03-24 06:01:38+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6316> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 06:01:38+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6316>
	{'abstract': u'Jamming attacks can significantly impact the performance of wireless communication systems. In addition to reducing the capacity, such attacks may lead to insurmountable overhead in terms of re-transmissions and increased power consumption. In this paper, we consider the multiple-input single-output (MISO) broadcast channel (BC) in the presence of a jamming attack in which a subset of the receivers can be jammed at any given time. Further, countermeasures for mitigating the effects of such jamming attacks are presented. The effectiveness of these anti-jamming countermeasures is quantified in terms of the degrees-of-freedom (DoF) of the MISO BC under various assumptions regarding the availability of the channel state information (CSIT) and the jammer state information at the transmitter (JSIT). The main contribution of this paper is the characterization of the DoF region of the two user MISO BC under various assumptions on the availability of CSIT and JSIT. Partial extensions to the multi-user broadcast channels are also presented.',
	 'authors': u'SaiDhiraj Amuru, Ravi Tandon, R. Michael Buehrer, T. Charles Clancy,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6316',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nRetroactive Anti-Jamming for MISO Broadcast Channels',
	 'urllink': u'http://arxiv.org/abs/1308.6316'}
2015-03-24 06:02:09+0000 [xxu46_7] INFO: Crawled 302 pages (at 1 pages/min), scraped 295 items (at 1 items/min)
2015-03-24 06:03:09+0000 [xxu46_7] INFO: Crawled 302 pages (at 0 pages/min), scraped 295 items (at 0 items/min)
2015-03-24 06:03:28+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7690> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 06:03:28+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7690>
	{'abstract': u'The hydrophobic-polar (HP) model has been widely studied in the field of protein structure prediction (PSP) both for theoretical purposes and as a benchmark for new optimization strategies. In this work we introduce a new heuristics based on Ant Colony Optimization (ACO) and Markov Chain Monte Carlo (MCMC) that we called Hybrid Monte Carlo Ant Colony Optimization (HMCACO). We describe this method and compare results obtained on well known HP instances in the 3 dimensional cubic lattice to those obtained with standard ACO and Simulated Annealing (SA). All methods were implemented using an unconstrained neighborhood and a modified objective function to prevent the creation of overlapping walks. Results show that our methods perform better than the other heuristics in all benchmark instances.',
	 'authors': u'Andrea G. Citrolo, Giancarlo Mauri,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7690',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nA Hybrid Monte Carlo Ant Colony Optimization Approach for Protein  Structure Prediction in the HP Model',
	 'urllink': u'http://arxiv.org/abs/1309.7690'}
2015-03-24 06:04:09+0000 [xxu46_7] INFO: Crawled 303 pages (at 1 pages/min), scraped 296 items (at 1 items/min)
2015-03-24 06:05:09+0000 [xxu46_7] INFO: Crawled 303 pages (at 0 pages/min), scraped 296 items (at 0 items/min)
2015-03-24 06:05:26+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6311> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 06:05:26+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6311>
	{'abstract': u'The analysis of historical documents is still a topical issue given the importance of information that can be extracted and also the importance given by the institutions to preserve their heritage. The main idea in order to characterize the content of the images of ancient documents after attempting to clean the image is segmented blocks texts from the same image and tries to find similar blocks in either the same image or the entire image database. Most approaches of offline handwriting recognition proceed by segmenting words into smaller pieces (usually characters) which are recognized separately. Recognition of a word then requires the recognition of all characters (OCR) that compose it. Our work focuses mainly on the characterization of classes in images of old documents. We use Som toolbox for finding classes in documents. We applied also fractal dimensions and points of interest to categorize and match ancient documents.',
	 'authors': u'Nizar Zaghden, Remy Mullot, Mohamed Adel Alimi,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6311',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nCategorizing ancient documents',
	 'urllink': u'http://arxiv.org/abs/1308.6311'}
2015-03-24 06:06:09+0000 [xxu46_7] INFO: Crawled 304 pages (at 1 pages/min), scraped 297 items (at 1 items/min)
2015-03-24 06:07:09+0000 [xxu46_7] INFO: Crawled 304 pages (at 0 pages/min), scraped 297 items (at 0 items/min)
2015-03-24 06:07:20+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7689> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 06:07:20+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7689>
	{'abstract': u'Reactions forming a pathway can be rewritten by making explicit the different molecular components involved in them. A molecular component represents a biological entity (e.g. a protein) in all its states (free, bound, degraded, etc.). In this paper we show the application of a component identification algorithm to a number of real-world models to experimentally validate the approach. Components identification allows subpathways to be computed to better understand the pathway functioning.',
	 'authors': u'Andrea Maggiolo-Schettini, Paolo Milazzo, Giovanni Pardini,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7689',
	 'subjects': u'Computational Engineering, Finance, and Science (cs.CE)',
	 'title': u'\nApplication of a Semi-automatic Algorithm for Identification of  Molecular Components in SBML Models',
	 'urllink': u'http://arxiv.org/abs/1309.7689'}
2015-03-24 06:08:09+0000 [xxu46_7] INFO: Crawled 305 pages (at 1 pages/min), scraped 298 items (at 1 items/min)
2015-03-24 06:08:44+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6309> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 06:08:44+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6309>
	{'abstract': u'This paper deals with the recognition and matching of text in both cartographic maps and ancient documents. The purpose of this work is to find similar text regions based on statistical and global features. A phase of normalization is done first, in object to well categorize the same quantity of information. A phase of wordspotting is done next by combining local and global features. We make different experiments by combining the different techniques of extracting features in order to obtain better results in recognition phase. We applied fontspotting on both ancient documents and cartographic ones. We also applied the wordspotting in which we adopted a new technique which tries to compare the images of character and not the entire images words. We present the precision and recall values obtained with three methods for the new method of wordspotting applied on characters only.',
	 'authors': u'Nizar Zaghden, Badreddine Khelifi, Adel M. Alimi, Remy Mullot,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6309',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nText recognition in both ancient and cartographic documents',
	 'urllink': u'http://arxiv.org/abs/1308.6309'}
2015-03-24 06:09:09+0000 [xxu46_7] INFO: Crawled 306 pages (at 1 pages/min), scraped 299 items (at 1 items/min)
2015-03-24 06:10:09+0000 [xxu46_7] INFO: Crawled 306 pages (at 0 pages/min), scraped 299 items (at 0 items/min)
2015-03-24 06:10:37+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7688> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 06:10:37+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7688>
	{'abstract': u'Epigenetic Tracking (ET) is an Artificial Embryology system which allows for the evolution and development of large complex structures built from artificial cells. In terms of the number of cells, the complexity of the bodies generated with ET is comparable with the complexity of biological organisms. We have previously used ET to simulate the growth of multicellular bodies with arbitrary 3-dimensional shapes which perform computation using the paradigm of "metabolic computing". In this paper we investigate the memory capacity of such computational structures and analyse the trade-off between shape and computation. We now plan to build on these foundations to create a biologically-inspired model in which the encoding of the phenotype is efficient (in terms of the compactness of the genome) and evolvable in tasks involving non-trivial computation, robust to damage and capable of self-maintenance and self-repair.',
	 'authors': u'Alessandro Fontana, Borys Wr\xf3bel,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7688',
	 'subjects': u'Computational Engineering, Finance, and Science (cs.CE)',
	 'title': u'\nEvolution and development of complex computational systems using the  paradigm of metabolic computing in Epigenetic Tracking',
	 'urllink': u'http://arxiv.org/abs/1309.7688'}
2015-03-24 06:11:09+0000 [xxu46_7] INFO: Crawled 307 pages (at 1 pages/min), scraped 300 items (at 1 items/min)
2015-03-24 06:12:09+0000 [xxu46_7] INFO: Crawled 307 pages (at 0 pages/min), scraped 300 items (at 0 items/min)
2015-03-24 06:12:30+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6300> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 06:12:30+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6300>
	{'abstract': u'Knowing the degree of semantic contrast between words has widespread application in natural language processing, including machine translation, information retrieval, and dialogue systems. Manually-created lexicons focus on opposites, such as and . Opposites are of many kinds such as antipodals, complementaries, and gradable. However, existing lexicons often do not classify opposites into the different kinds. They also do not explicitly list word pairs that are not opposites but yet have some degree of contrast in meaning, such as and or and . We propose an automatic method to identify contrasting word pairs that is based on the hypothesis that if a pair of words, and , are contrasting, then there is a pair of opposites, and , such that and are strongly related and and are strongly related. (For example, there exists the pair of opposites and such that is related to and is related to .) We will call this the contrast hypothesis. We begin with a large crowdsourcing experiment to determine the amount of human agreement on the concept of oppositeness and its different kinds. In the process, we flesh out key features of different kinds of opposites. We then present an automatic and empirical measure of lexical contrast that relies on the contrast hypothesis, corpus statistics, and the structure of a -like thesaurus. We show that the proposed measure of lexical contrast obtains high precision and large coverage, outperforming existing methods.',
	 'authors': u'Saif M. Mohammad, Bonnie J. Dorr, Graeme Hirst, Peter D. Turney,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6300',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nComputing Lexical Contrast',
	 'urllink': u'http://arxiv.org/abs/1308.6300'}
2015-03-24 06:13:09+0000 [xxu46_7] INFO: Crawled 308 pages (at 1 pages/min), scraped 301 items (at 1 items/min)
2015-03-24 06:13:30+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7687> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 06:13:30+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7687>
	{'abstract': u'The bottom-up construction of synthetic cells is one of the most intriguing and interesting research arenas in synthetic biology. Synthetic cells are built by encapsulating biomolecules inside lipid vesicles (liposomes), allowing the synthesis of one or more functional proteins. Thanks to the in situ synthesized proteins, synthetic cells become able to perform several biomolecular functions, which can be exploited for a large variety of applications. This paves the way to several advanced uses of synthetic cells in basic science and biotechnology, thanks to their versatility, modularity, biocompatibility, and programmability. In the previous WIVACE (2012) we presented the state-of-the-art of semi-synthetic minimal cell (SSMC) technology and introduced, for the first time, the idea of chemical communication between synthetic cells and natural cells. The development of a proper synthetic communication protocol should be seen as a tool for the nascent field of bio/chemical-based Information and Communication Technologies (bio-chem-ICTs) and ultimately aimed at building soft-wet-micro-robots. In this contribution (WIVACE, 2013) we present a blueprint for realizing this project, and show some preliminary experimental results. We firstly discuss how our research goal (based on the natural capabilities of biological systems to manipulate chemical signals) finds a proper place in the current scientific and technological contexts. Then, we shortly comment on the experimental approaches from the viewpoints of (i) synthetic cell construction, and (ii) bioengineering of microorganisms, providing up-to-date results from our laboratory. Finally, we shortly discuss how autopoiesis can be used as a theoretical framework for defining synthetic minimal life, minimal cognition, and as bridge between synthetic biology and artificial intelligence.',
	 'authors': u"Giordano Rampioni, Luisa Damiano, Marco Messina, Francesca D'Angelo, Livia Leoni, Pasquale Stano,",
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7687',
	 'subjects': u'Computational Engineering, Finance, and Science (cs.CE)',
	 'title': u'\nChemical communication between synthetic and natural cells: a possible  experimental design',
	 'urllink': u'http://arxiv.org/abs/1309.7687'}
2015-03-24 06:14:09+0000 [xxu46_7] INFO: Crawled 309 pages (at 1 pages/min), scraped 302 items (at 1 items/min)
2015-03-24 06:14:32+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6297> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 06:14:32+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6297>
	{'abstract': u'Even though considerable attention has been given to the polarity of words (positive and negative) and the creation of large polarity lexicons, research in emotion analysis has had to rely on limited and small emotion lexicons. In this paper we show how the combined strength and wisdom of the crowds can be used to generate a large, high-quality, word-emotion and word-polarity association lexicon quickly and inexpensively. We enumerate the challenges in emotion annotation in a crowdsourcing scenario and propose solutions to address them. Most notably, in addition to questions about emotions associated with terms, we show how the inclusion of a word choice question can discourage malicious data entry, help identify instances where the annotator may not be familiar with the target term (allowing us to reject such annotations), and help obtain annotations at sense level (rather than at word level). We conducted experiments on how to formulate the emotion-annotation questions, and show that asking if a term is associated with an emotion leads to markedly higher inter-annotator agreement than that obtained by asking if a term evokes an emotion.',
	 'authors': u'Saif M. Mohammad, Peter D. Turney,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6297',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nCrowdsourcing a Word-Emotion Association Lexicon',
	 'urllink': u'http://arxiv.org/abs/1308.6297'}
2015-03-24 06:15:09+0000 [xxu46_7] INFO: Crawled 310 pages (at 1 pages/min), scraped 303 items (at 1 items/min)
2015-03-24 06:16:05+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7686> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 06:16:05+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7686>
	{'abstract': u'Over the last years, analyses performed on a stochastic model of catalytic reaction networks have provided some indications about the reasons why wet-lab experiments hardly ever comply with the phase transition typically predicted by theoretical models with regard to the emergence of collectively self-replicating sets of molecule (also defined as autocatalytic sets, ACSs), a phenomenon that is often observed in nature and that is supposed to have played a major role in the emergence of the primitive forms of life. The model at issue has allowed to reveal that the emerging ACSs are characterized by a general dynamical fragility, which might explain the difficulty to observe them in lab experiments. In this work, the main results of the various analyses are reviewed, with particular regard to the factors able to affect the generic properties of catalytic reactions network, for what concerns, not only the probability of ACSs to be observed, but also the overall activity of the system, in terms of production of new species, reactions and matter.',
	 'authors': u'Chiara Damiani, Alessandro Filisetti, Alex Graudenzi, Marco Villani, Roberto Serra,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7686',
	 'subjects': u'Computational Engineering, Finance, and Science (cs.CE)',
	 'title': u'\nRecent developments in research on catalytic reaction networks',
	 'urllink': u'http://arxiv.org/abs/1309.7686'}
2015-03-24 06:16:09+0000 [xxu46_7] INFO: Crawled 311 pages (at 1 pages/min), scraped 304 items (at 1 items/min)
2015-03-24 06:17:09+0000 [xxu46_7] INFO: Crawled 311 pages (at 0 pages/min), scraped 304 items (at 0 items/min)
2015-03-24 06:18:03+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6292> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 06:18:03+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6292>
	{'abstract': u'Artifact-Centric systems have emerged in the last years as a suitable framework to model business-relevant entities, by combining their static and dynamic aspects. In particular, the Guard-Stage-Milestone (GSM) approach has been recently proposed to model artifacts and their lifecycle in a declarative way. In this paper, we enhance GSM with a Semantic Layer, constituted by a full-fledged OWL 2 QL ontology linked to the artifact information models through mapping specifications. The ontology provides a conceptual view of the domain under study, and allows one to understand the evolution of the artifact system at a higher level of abstraction. In this setting, we present a technique to specify temporal properties expressed over the Semantic Layer, and verify them according to the evolution in the underlying GSM model. This technique has been implemented in a tool that exploits state-of-the-art ontology-based data access technologies to manipulate the temporal properties according to the ontology and the mappings, and that relies on the GSMC model checker for verification.',
	 'authors': u'Babak Bagheri Hariri, Diego Calvanese, Marco Montali, Ario Santoso, Dmitry Solomakhin,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6292',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nVerification of Semantically-Enhanced Artifact Systems (Extended  Version)',
	 'urllink': u'http://arxiv.org/abs/1308.6292'}
2015-03-24 06:18:09+0000 [xxu46_7] INFO: Crawled 312 pages (at 1 pages/min), scraped 305 items (at 1 items/min)
2015-03-24 06:19:09+0000 [xxu46_7] INFO: Crawled 312 pages (at 0 pages/min), scraped 305 items (at 0 items/min)
2015-03-24 06:19:49+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7685> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 06:19:49+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7685>
	{'abstract': u'Porting GCC to new architecture requires writing a Machine Description (MD) file that contains mapping from GCC\'s intermediate form to the target assembly code. Constructing an MD file is a difficult task because it requires the user to understand both (a) the internals of GCC, and (b) the intricacies of the target architecture. Instruction sets of different architectures exhibit significant amount of semantic similarities across a large class (for example, the instruction sets for RISC architectures) and differ only in syntax. Therefore, it is expected that MD files of machines with similar architectures should also have similarities. To confirm our hypothesis, we created "mdcompare", a tool to (a) extract RTL patterns (machine independent abstraction of RTL templates) from MD files of well known architectures and (b) compare the similarity of patterns across architectures. The results are encouraging; we found that 28% -- 70% RTL expressions are similar across pairs of MD files, the similarity percentage being on the higher side for pairs of similar architectures.',
	 'authors': u'Saravana Perumal P, Amey Karkare,',
	 'category': u'Computer Science ',
	 'date': '2013-9-30',
	 'pdflink': u'http://arxiv.org/pdf/1309.7685',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nRetargeting GCC: Do We Reinvent the Wheel Every Time?',
	 'urllink': u'http://arxiv.org/abs/1309.7685'}
2015-03-24 06:20:09+0000 [xxu46_7] INFO: Crawled 313 pages (at 1 pages/min), scraped 306 items (at 1 items/min)
2015-03-24 06:21:09+0000 [xxu46_7] INFO: Crawled 313 pages (at 0 pages/min), scraped 306 items (at 0 items/min)
2015-03-24 06:21:27+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6273> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 06:21:27+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6273>
	{'abstract': u'In sparse recovery we are given a matrix (the dictionary) and a vector of the form where is sparse, and the goal is to recover . This is a central notion in signal processing, statistics and machine learning. But in applications such as sparse coding, edge detection, compression and super resolution, the dictionary is unknown and has to be learned from random examples of the form where is drawn from an appropriate distribution --- this is the dictionary learning problem. In most settings, is overcomplete: it has more columns than rows. This paper presents a polynomial-time algorithm for learning overcomplete dictionaries; the only previously known algorithm with provable guarantees is the recent work of Spielman, Wang and Wright who gave an algorithm for the full-rank case, which is rarely the case in applications. Our algorithm applies to incoherent dictionaries which have been a central object of study since they were introduced in seminal work of Donoho and Huo. In particular, a dictionary is -incoherent if each pair of columns has inner product at most . The algorithm makes natural stochastic assumptions about the unknown sparse vector , which can contain non-zero entries (for any ). This is close to the best allowable by the best sparse recovery algorithms even if one knows the dictionary exactly. Moreover, both the running time and sample complexity depend on , where is the target accuracy, and so our algorithms converge very quickly to the true dictionary. Our algorithm can also tolerate substantial amounts of noise provided it is incoherent with respect to the dictionary (e.g., Gaussian). In the noisy setting, our running time and sample complexity depend polynomially on , and this is necessary.',
	 'authors': u'Sanjeev Arora, Rong Ge, Ankur Moitra,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6273',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nNew Algorithms for Learning Incoherent and Overcomplete Dictionaries',
	 'urllink': u'http://arxiv.org/abs/1308.6273'}
2015-03-24 06:22:09+0000 [xxu46_7] INFO: Crawled 314 pages (at 1 pages/min), scraped 307 items (at 1 items/min)
2015-03-24 06:22:35+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7676> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 06:22:35+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7676>
	{'abstract': u'The condensed nearest neighbor (CNN) algorithm is a heuristic for reducing the number of prototypical points stored by a nearest neighbor classifier, while keeping the classification rule given by the reduced prototypical set consistent with the full set. I present an upper bound on the number of prototypical points accumulated by CNN. The bound originates in a bound on the number of times the decision rule is updated during training in the multiclass perceptron algorithm, and thus is independent of training set size.',
	 'authors': u'Eric Christiansen,',
	 'category': u'Computer Science ',
	 'date': '2013-9-29',
	 'pdflink': u'http://arxiv.org/pdf/1309.7676',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nAn upper bound on prototype set size for condensed nearest neighbor',
	 'urllink': u'http://arxiv.org/abs/1309.7676'}
2015-03-24 06:23:09+0000 [xxu46_7] INFO: Crawled 315 pages (at 1 pages/min), scraped 308 items (at 1 items/min)
2015-03-24 06:24:09+0000 [xxu46_7] INFO: Crawled 315 pages (at 0 pages/min), scraped 308 items (at 0 items/min)
2015-03-24 06:24:34+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6255> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 06:24:34+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6255>
	{'abstract': u"One of the long-debated issues in coalitional game theory is how to extend the Shapley value to games with externalities (partition-function games). When externalities are present, not only can a player's marginal contribution - a central notion to the Shapley value - be defined in a variety of ways, but it is also not obvious which axiomatization should be used. Consequently, a number of authors extended the Shapley value using complex and often unintuitive axiomatizations. Furthermore, no algorithm to approximate any extension of the Shapley value to partition-function games has been proposed to date. Given this background, we prove in this paper that, for any well-defined measure of marginal contribution, Shapley's original four axioms imply a unique value for games with externalities. As an consequence of this general theorem, we show that values proposed by Macho-Stadler et al., McQuillin and Bolger can be derived from Shapley's axioms. Building upon our analysis of marginal contribution, we develop a general algorithm to approximate extensions of the Shapley value to games with externalities using a Monte Carlo simulation technique.",
	 'authors': u'Oskar Skibski, Tomasz P. Michalak, Michael Wooldridge,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6255',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nThe Shapley Axiomatization for Values in Partition Function Games',
	 'urllink': u'http://arxiv.org/abs/1308.6255'}
2015-03-24 06:25:09+0000 [xxu46_7] INFO: Crawled 316 pages (at 1 pages/min), scraped 309 items (at 1 items/min)
2015-03-24 06:26:09+0000 [xxu46_7] INFO: Crawled 316 pages (at 0 pages/min), scraped 309 items (at 0 items/min)
2015-03-24 06:26:27+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7666> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 06:26:27+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7666>
	{'abstract': u'This paper considers the chattering problem of sliding mode control while delay in robot manipulator caused chaos in such electromechanical systems. Fractional calculus as a powerful theorem to produce a novel sliding mode; which has a dynamic essence is used for chattering elimination. To realize the control of a class of chaotic systems in master-slave configuration this novel fractional dynamic sliding mode control scheme is presented and examined on delay based chaotic robot in joint and work space. Also the stability of the closed-loop system is guaranteed by Lyapunov stability theory. Beside these, delayed robot motions are sorted out for qualitative and quantification study. Finally, numerical simulation example illustrates the feasibility of proposed control method.',
	 'authors': u'Sara Gholipour P., Heydar Toosian Sh,',
	 'category': u'Computer Science ',
	 'date': '2013-9-29',
	 'pdflink': u'http://arxiv.org/pdf/1309.7666',
	 'subjects': u'Robotics (cs.RO)',
	 'title': u'\nDynamic Sliding Mode Control based on Fractional calculus subject to  uncertain delay based chaotic pneumatic robot',
	 'urllink': u'http://arxiv.org/abs/1309.7666'}
2015-03-24 06:27:09+0000 [xxu46_7] INFO: Crawled 317 pages (at 1 pages/min), scraped 310 items (at 1 items/min)
2015-03-24 06:28:09+0000 [xxu46_7] INFO: Crawled 317 pages (at 0 pages/min), scraped 310 items (at 0 items/min)
2015-03-24 06:28:28+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6251> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 06:28:28+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6251>
	{'abstract': u'In this paper, we investigate the implementation of wavelet modulation (WM) in a digital communication system and propose novel methods to improve its performance. We will put particular focus on the structure of an optimal detector in AWGN channels and address two main methods for inserting the samples of the message signal in different frequency layers. Finally, computer based algorithms are described in order to implement and optimize receivers and transmitters.',
	 'authors': u'Rad Niazadeh, Sahar Nassirpour, Mohammad B. Shamsollahi,',
	 'category': u'Computer Science ',
	 'date': '2013-8-25',
	 'pdflink': u'http://arxiv.org/pdf/1308.6251',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nImplementation and optimization of Wavelet modulation in Additive  Gaussian channels',
	 'urllink': u'http://arxiv.org/abs/1308.6251'}
2015-03-24 06:29:09+0000 [xxu46_7] INFO: Crawled 318 pages (at 1 pages/min), scraped 311 items (at 1 items/min)
2015-03-24 06:30:09+0000 [xxu46_7] INFO: Crawled 318 pages (at 0 pages/min), scraped 311 items (at 0 items/min)
2015-03-24 06:30:27+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7665> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 06:30:27+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7665>
	{'abstract': u'Unique lifting factorization results for group lifting structures are used to characterize the group-theoretic structure of two-channel linear phase FIR perfect reconstruction filter bank groups. For D-invariant, order-increasing group lifting structures, it is shown that the associated lifting cascade group C is isomorphic to the free product of the upper and lower triangular lifting matrix groups. Under the same hypotheses, the associated scaled lifting group S is the semidirect product of C by the diagonal gain scaling matrix group D. These results apply to the group lifting structures for the two principal classes of linear phase perfect reconstruction filter banks, the whole- and half-sample symmetric classes. Since the unimodular whole-sample symmetric class forms a group, W, that is in fact equal to its own scaled lifting group, W=S_W, the results of this paper characterize the group-theoretic structure of W up to isomorphism. Although the half-sample symmetric class H does not form a group, it can be partitioned into cosets of its lifting cascade group, C_H, or, alternatively, into cosets of its scaled lifting group, S_H. Homomorphic comparisons reveal that scaled lifting groups covered by the results in this paper have a structure analogous to a "noncommutative vector space."',
	 'authors': u'Christopher M. Brislawn,',
	 'category': u'Computer Science ',
	 'date': '2013-9-29',
	 'pdflink': u'http://arxiv.org/pdf/1309.7665',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nGroup-theoretic structure of linear phase multirate filter banks',
	 'urllink': u'http://arxiv.org/abs/1309.7665'}
2015-03-24 06:31:09+0000 [xxu46_7] INFO: Crawled 319 pages (at 1 pages/min), scraped 312 items (at 1 items/min)
2015-03-24 06:32:01+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6250> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 06:32:01+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6250>
	{'abstract': u'This paper presents two control algorithms enabling a UAV to circumnavigate an unknown target using range and range rate (i.e., the derivative of range) measurements. Given a prescribed orbit radius, both control algorithms (i) tend to drive the UAV toward the tangent of prescribed orbit when the UAV is outside or on the orbit, and (ii) apply zero control input if the UAV is inside the desired orbit. The algorithms differ in that, the first algorithm is smooth and unsaturated while the second algorithm is non-smooth and saturated. By analyzing properties associated with the bearing angle of the UAV relative to the target and through proper design of Lyapunov functions, it is shown that both algorithms produce the desired orbit for an arbitrary initial state. Three examples are provided as a proof of concept.',
	 'authors': u'Yongcan Cao, Jonathan Muse, David Casbeer, Derek Kingston,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6250',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nCircumnavigation of an Unknown Target Using UAVs with Range and Range  Rate Measurements',
	 'urllink': u'http://arxiv.org/abs/1308.6250'}
2015-03-24 06:32:09+0000 [xxu46_7] INFO: Crawled 320 pages (at 1 pages/min), scraped 313 items (at 1 items/min)
2015-03-24 06:33:09+0000 [xxu46_7] INFO: Crawled 320 pages (at 0 pages/min), scraped 313 items (at 0 items/min)
2015-03-24 06:33:44+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6242> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 06:33:44+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6242>
	{'abstract': u'In this paper, we describe how we created two state-of-the-art SVM classifiers, one to detect the sentiment of messages such as tweets and SMS (message-level task) and one to detect the sentiment of a term within a submissions stood first in both tasks on tweets, obtaining an F-score of 69.02 in the message-level task and 88.93 in the term-level task. We implemented a variety of surface-form, semantic, and sentiment features. with sentiment-word hashtags, and one from tweets with emoticons. In the message-level task, the lexicon-based features provided a gain of 5 F-score points over all others. Both of our systems can be replicated us available resources.',
	 'authors': u'Saif M. Mohammad, Svetlana Kiritchenko, Xiaodan Zhu,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6242',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nNRC-Canada: Building the State-of-the-Art in Sentiment Analysis of  Tweets',
	 'urllink': u'http://arxiv.org/abs/1308.6242'}
2015-03-24 06:34:09+0000 [xxu46_7] INFO: Crawled 321 pages (at 1 pages/min), scraped 314 items (at 1 items/min)
2015-03-24 06:35:09+0000 [xxu46_7] INFO: Crawled 321 pages (at 0 pages/min), scraped 314 items (at 0 items/min)
2015-03-24 06:35:44+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7615> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 06:35:44+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7615>
	{'abstract': u'Image fusion is one of the recent trends in image registration which is an essential field of image processing. The basic principle of this paper is to fuse multi-focus images using simple statistical standard deviation. Firstly, the simple standard deviation for the k-by-k window inside each of the multi-focus images was computed. The contribution in this paper came from the idea that the focused part inside an image had high details rather than the unfocused part. Hence, the dispersion between pixels inside the focused part is higher than the dispersion inside the unfocused part. Secondly, a simple comparison between the standard deviation for each k-by-k window in the multi-focus images could be computed. The highest standard deviation between all the computed standard deviations for the multi-focus images could be treated as the optimal that is to be placed in the fused image. The experimental visual results show that the proposed method produces very satisfactory results in spite of its simplicity.',
	 'authors': u'Firas A. Jassim,',
	 'category': u'Computer Science ',
	 'date': '2013-9-29',
	 'pdflink': u'http://arxiv.org/pdf/1309.7615',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nCorrecting Multi-focus Images via Simple Standard Deviation for Image  Fusion',
	 'urllink': u'http://arxiv.org/abs/1309.7615'}
2015-03-24 06:36:09+0000 [xxu46_7] INFO: Crawled 322 pages (at 1 pages/min), scraped 315 items (at 1 items/min)
2015-03-24 06:37:05+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6217> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 06:37:05+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6217>
	{'abstract': u'Robustness is as important as efficiency in air transportation. All components in the air traffic system are connected to form an interactive network. So, a disturbance that occurs in one component, for example, a severe delay at an airport, can influence the entire network. Delays are easily propagated between flights through gates, but the propagation can be reduced if gate assignments are robust against stochastic delays. In this paper, we analyze gate delays and suggest an approach that involves assigning gates while making them robust against stochastic delays. We extract an example flight schedule from data source and generate schedules with increased traffic to analyze how the compact flight schedules impact the robustness of gate assignment. Simulation results show that our approach improves the robustness of gate assignment. Particularly, the robust gate assignment reduces average duration of gate conflicts by 96.3% and the number of gate conflicts by 96.7% compared to the baseline assignment. However, the robust gate assignment results in longer transit time for passengers, and a trade-off between the robustness of gate assignment and passenger transit time is presented.',
	 'authors': u'Sang Hyun Kim, Eric Feron,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6217',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nNumerical Analysis of Gate Conflict Duration and Passenger Transit Time  in Airport',
	 'urllink': u'http://arxiv.org/abs/1308.6217'}
2015-03-24 06:37:09+0000 [xxu46_7] INFO: Crawled 323 pages (at 1 pages/min), scraped 316 items (at 1 items/min)
2015-03-24 06:38:09+0000 [xxu46_7] INFO: Crawled 323 pages (at 0 pages/min), scraped 316 items (at 0 items/min)
2015-03-24 06:38:26+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7611> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 06:38:26+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7611>
	{'abstract': u'Albeit the implicit feedback based recommendation problem - when only the user history is available but there are no ratings - is the most typical setting in real-world applications, it is much less researched than the explicit feedback case. State-of-the-art algorithms that are efficient on the explicit case cannot be automatically transformed to the implicit case if scalability should be maintained. There are few implicit feedback benchmark data sets, therefore new ideas are usually experimented on explicit benchmarks. In this paper, we propose a generic context-aware implicit feedback recommender algorithm, coined iTALS. iTALS applies a fast, ALS-based tensor factorization learning method that scales linearly with the number of non-zero elements in the tensor. We also present two approximate and faster variants of iTALS using coordinate descent and conjugate gradient methods at learning. The method also allows us to incorporate various contextual information into the model while maintaining its computational efficiency. We present two context-aware variants of iTALS incorporating seasonality and item purchase sequentiality into the model to distinguish user behavior at different time intervals, and product types with different repetitiveness. Experiments run on six data sets shows that iTALS clearly outperforms context-unaware models and context aware baselines, while it is on par with factorization machines (beats 7 times out of 12 cases) both in terms of recall and MAP.',
	 'authors': u'Bal\xe1zs Hidasi, Domonkos Tikk,',
	 'category': u'Computer Science ',
	 'date': '2013-9-29',
	 'pdflink': u'http://arxiv.org/pdf/1309.7611',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nContext-aware recommendations from implicit data via scalable tensor  factorization',
	 'urllink': u'http://arxiv.org/abs/1309.7611'}
2015-03-24 06:39:09+0000 [xxu46_7] INFO: Crawled 324 pages (at 1 pages/min), scraped 317 items (at 1 items/min)
2015-03-24 06:40:09+0000 [xxu46_7] INFO: Crawled 324 pages (at 0 pages/min), scraped 317 items (at 0 items/min)
2015-03-24 06:40:13+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6216> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 06:40:13+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6216>
	{'abstract': u'Cognitive Radio (CR) is a promising technology for next-generation wireless networks in order to efficiently utilize the limited spectrum resources and satisfy the rapidly increasing demand for wireless applications and services. Security is a very important but not well addressed issue in CR networks. In this paper we focus on security problems arising from Primary User Emulation (PUE) attacks in CR networks. We present a comprehensive introduction to PUE attacks, from the attacking rationale and its impact on CR networks, to detection and defense approaches. In order to secure CR networks against PUE attacks, a two-level database-assisted detection approach is proposed to detect such attacks. Energy detection and location verification are combined for fast and reliable detection. An admission control based defense approach is proposed to mitigate the performance degradation of a CR network under a PUE attack. Illustrative results are presented to demonstrate the effectiveness of the proposed detection and defense approaches.',
	 'authors': u'Rong Yu, Yan Zhang, Yi Liu, Stein Gjessing, Mohsen Guizani,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6216',
	 'subjects': u'Emerging Technologies (cs.ET)',
	 'title': u'\nSecuring Cognitive Radio Networks against Primary User Emulation Attacks',
	 'urllink': u'http://arxiv.org/abs/1308.6216'}
2015-03-24 06:41:09+0000 [xxu46_7] INFO: Crawled 325 pages (at 1 pages/min), scraped 318 items (at 1 items/min)
2015-03-24 06:42:02+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7609> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 06:42:02+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7609>
	{'abstract': u'The effects of global climate change on Peruvian glaciers have brought about several processes of deglaciation during the last few years. The immediate effect is the change of size of lakes and rivers. Public institutions that monitor water resources currently have only recent studies which make up less than 10% of the total. The effects of climate change and the lack of updated information intensify social-economic problems related to water resources in Peru. The objective of this research is to develop a software application to automate the Cadastral Registry of Water Bodies in Peru, using techniques of digital image processing, which would provide tools for detection, record, temporal analysis and visualization of water bodies. The images used are from the satellite Landsat5, which undergo a pre-processing of calibration and correction of the satellite. Detection results are archived into a file that contains location vectors and images of the segmentated bodies of water.',
	 'authors': u'Kevin Rojas Laura, Christhian Cardenas Alvarez,',
	 'category': u'Computer Science ',
	 'date': '2013-9-29',
	 'pdflink': u'http://arxiv.org/pdf/1309.7609',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nIdentificaci\xf3n y Registro Catastral de Cuerpos de Agua mediante  T\xe9cnicas de Procesamiento Digital de Imagenes',
	 'urllink': u'http://arxiv.org/abs/1309.7609'}
2015-03-24 06:42:09+0000 [xxu46_7] INFO: Crawled 326 pages (at 1 pages/min), scraped 319 items (at 1 items/min)
2015-03-24 06:43:09+0000 [xxu46_7] INFO: Crawled 326 pages (at 0 pages/min), scraped 319 items (at 0 items/min)
2015-03-24 06:43:59+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6208> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 06:43:59+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6208>
	{'abstract': u'In the era of Internet of Things, all components in intelligent transportation systems will be connected to improve transport safety, relieve traffic congestion, reduce air pollution and enhance the comfort of driving. The vision of all vehicles connected poses a significant challenge to the collection and storage of large amounts of traffic-related data. In this article, we propose to integrate cloud computing into vehicular networks such that the vehicles can share computation resources, storage resources and bandwidth resources. The proposed architecture includes a vehicular cloud, a roadside cloud, and a central cloud. Then, we study cloud resource allocation and virtual machine migration for effective resource management in this cloud-based vehicular network. A game-theoretical approach is presented to optimally allocate cloud resources. Virtual machine migration due to vehicle mobility is solved based on a resource reservation scheme.',
	 'authors': u'Rong Yu, Yan Zhang, Stein Gjessing, Wenlong Xia, Kun Yang,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6208',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nToward Cloud-based Vehicular Networks with Efficient Resource Management',
	 'urllink': u'http://arxiv.org/abs/1308.6208'}
2015-03-24 06:44:09+0000 [xxu46_7] INFO: Crawled 327 pages (at 1 pages/min), scraped 320 items (at 1 items/min)
2015-03-24 06:45:09+0000 [xxu46_7] INFO: Crawled 327 pages (at 0 pages/min), scraped 320 items (at 0 items/min)
2015-03-24 06:45:19+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7598> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 06:45:19+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7598>
	{'abstract': u'In this paper we describe how MAP inference can be used to sample efficiently from Gibbs distributions. Specifically, we provide means for drawing either approximate or unbiased samples from Gibbs\' distributions by introducing low dimensional perturbations and solving the corresponding MAP assignments. Our approach also leads to new ways to derive lower bounds on partition functions. We demonstrate empirically that our method excels in the typical "high signal - high coupling" regime. The setting results in ragged energy landscapes that are challenging for alternative approaches to sampling and/or lower bounds.',
	 'authors': u'Tamir Hazan, Subhransu Maji, Tommi Jaakkola,',
	 'category': u'Computer Science ',
	 'date': '2013-9-29',
	 'pdflink': u'http://arxiv.org/pdf/1309.7598',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nOn Sampling from the Gibbs Distribution with Random Maximum A-Posteriori  Perturbations',
	 'urllink': u'http://arxiv.org/abs/1309.7598'}
2015-03-24 06:46:09+0000 [xxu46_7] INFO: Crawled 328 pages (at 1 pages/min), scraped 321 items (at 1 items/min)
2015-03-24 06:46:44+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6206> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 06:46:44+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6206>
	{'abstract': u'The partner units problem (PUP) is an acknowledged hard benchmark problem for the Logic Programming community with various industrial application fields like surveillance, electrical engineering, computer networks or railway safety systems. However, computational complexity remained widely unclear so far. In this paper we provide all missing complexity results making the PUP better exploitable for benchmark testing. Furthermore, we present QuickPup, a heuristic search algorithm for PUP instances which outperforms all state-of-the-art solving approaches and which is already in use in real world industrial configuration environments.',
	 'authors': u'Erich Christian Teppan, Gerhard Friedrich,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6206',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nThe Partner Units Configuration Problem: Completing the Picture',
	 'urllink': u'http://arxiv.org/abs/1308.6206'}
2015-03-24 06:47:09+0000 [xxu46_7] INFO: Crawled 329 pages (at 1 pages/min), scraped 322 items (at 1 items/min)
2015-03-24 06:48:09+0000 [xxu46_7] INFO: Crawled 329 pages (at 0 pages/min), scraped 322 items (at 0 items/min)
2015-03-24 06:48:44+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7584> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 06:48:44+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7584>
	{'abstract': u"This paper has the goals (1) of unifying top-down parsing with shift-reduce parsing to yield a single simple and consistent framework, and (2) of producing provably correct parsing methods, deterministic as well as tabular ones, for extended context-free grammars (EBNF) represented as state-transition networks. Departing from the traditional way of presenting as independent algorithms the deterministic bottom-up LR(1), the top-down LL(1) and the general tabular (Earley) parsers, we unify them in a coherent minimalist framework. We present a simple general construction method for EBNF ELR(1) parsers, where the new category of convergence conflicts is added to the classical shift-reduce and reduce-reduce conflicts; we prove its correctness and show two implementations by deterministic push-down machines and by vector-stack machines, the latter to be also used for Earley parsers. Then the Beatty's theoretical characterization of LL(1) grammars is adapted to derive the extended ELL(1 parsing method, first by minimizing the ELR(1) parser and then by simplifying its state information. Through using the same notations in the ELR(1) case, the extended Earley parser is obtained. Since all the parsers operate on compatible representations, it is feasible to combine them into mixed mode algorithms.",
	 'authors': u'Luca Breveglieri, Stefano Crespi Reghizzi, Angelo Morzenti,',
	 'category': u'Computer Science ',
	 'date': '2013-9-29',
	 'pdflink': u'http://arxiv.org/pdf/1309.7584',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nParsing methods streamlined',
	 'urllink': u'http://arxiv.org/abs/1309.7584'}
2015-03-24 06:49:09+0000 [xxu46_7] INFO: Crawled 330 pages (at 1 pages/min), scraped 323 items (at 1 items/min)
2015-03-24 06:49:48+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6203> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 06:49:48+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6203>
	{'abstract': u"In this paper, an abstract definition and formal specification is presented for the task of adaptive-threshold OSAHS events detection and severity characterization. Specifically, a low-level pseudocode is designed for the algorithm of raw oximetry signal pre-processing, calculation of the 'drop' and 'rise' frames in the related time series, detection of valid apnea/hypopnea events via SpO2 saturation level tracking, as well as calculation of corresponding event rates for OSAHS severity characterization. The designed algorithm can be used as the first module in a machine learning application where these data can be used as inputs or encoded into higher-level statistics (features) for pattern classifiers, in the context of computer-aided or fully automated diagnosis of OSAHS and related pathologies.",
	 'authors': u'Harris V. Georgiou,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6203',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nAdaptive detection and severity level characterization algorithm for  Obstructive Sleep Apnea Hypopnea Syndrome (OSAHS) via oximetry signal  analysis',
	 'urllink': u'http://arxiv.org/abs/1308.6203'}
2015-03-24 06:50:09+0000 [xxu46_7] INFO: Crawled 331 pages (at 1 pages/min), scraped 324 items (at 1 items/min)
2015-03-24 06:51:09+0000 [xxu46_7] INFO: Crawled 331 pages (at 0 pages/min), scraped 324 items (at 0 items/min)
2015-03-24 06:51:26+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7583> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 06:51:26+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7583>
	{'abstract': u'In many practical communication systems, one binary encoder/decoder pair is used to communicate over a set of parallel channels. Examples of this setup include multi-carrier transmission, rate-compatible puncturing of turbo-like codes, and bit-interleaved coded modulation (BICM). A bit mapper is commonly employed to determine how the coded bits are allocated to the channels. In this paper, we study spatially coupled low-density parity check codes over parallel channels and optimize the bit mapper using BICM as the driving example. For simplicity, the parallel bit channels that arise in BICM are replaced by independent binary erasure channels (BECs). For two parallel BECs modeled according to a 4-PAM constellation labeled by the binary reflected Gray code, the optimization results show that the decoding threshold can be improved over a uniform random bit mapper, or, alternatively, the spatial chain length of the code can be reduced for a given gap to capacity. It is also shown that for rate-loss free, circular (tail-biting) ensembles, a decoding wave effect can be initiated using only an optimized bit mapper.',
	 'authors': u'Christian H\xe4ger, Alexandre Graell i Amat, Alex Alvarado, Fredrik Br\xe4nnstr\xf6m, Erik Agrell,',
	 'category': u'Computer Science ',
	 'date': '2013-9-29',
	 'pdflink': u'http://arxiv.org/pdf/1309.7583',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOptimized Bit Mappings for Spatially Coupled LDPC Codes over Parallel  Binary Erasure Channels',
	 'urllink': u'http://arxiv.org/abs/1309.7583'}
2015-03-24 06:52:09+0000 [xxu46_7] INFO: Crawled 332 pages (at 1 pages/min), scraped 325 items (at 1 items/min)
2015-03-24 06:53:09+0000 [xxu46_7] INFO: Crawled 332 pages (at 0 pages/min), scraped 325 items (at 0 items/min)
2015-03-24 06:53:14+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6202> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 06:53:14+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6202>
	{'abstract': u"We study how to enable auctions in the big data context to solve many upcoming data-based decision problems in the near future. We consider the characteristics of the big data including, but not limited to, velocity, volume, variety, and veracity, and we believe any auction mechanism design in the future should take the following factors into consideration: 1) generality (variety); 2) efficiency and scalability (velocity and volume); 3) truthfulness and verifiability (veracity). In this paper, we propose a privacy-preserving construction for auction mechanism design in the big data, which prevents adversaries from learning unnecessary information except those implied in the valid output of the auction. More specifically, we considered one of the most general form of the auction (to deal with the variety), and greatly improved the the efficiency and scalability by approximating the NP-hard problems and avoiding the design based on garbled circuits (to deal with velocity and volume), and finally prevented stakeholders from lying to each other for their own benefit (to deal with the veracity). We achieve these by introducing a novel privacy-preserving winner determination algorithm and a novel payment mechanism. Additionally, we further employ a blind signature scheme as a building block to let bidders verify the authenticity of their payment reported by the auctioneer. The comparison with peer work shows that we improve the asymptotic performance of peer works' overhead from the exponential growth to a linear growth and from linear growth to a logarithmic growth, which greatly improves the scalability.",
	 'authors': u'Taeho Jung, Xiang-Yang Li,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6202',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nEnabling Privacy-preserving Auctions in Big Data',
	 'urllink': u'http://arxiv.org/abs/1308.6202'}
2015-03-24 06:54:09+0000 [xxu46_7] INFO: Crawled 333 pages (at 1 pages/min), scraped 326 items (at 1 items/min)
2015-03-24 06:54:47+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7572> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 06:54:48+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7572>
	{'abstract': u'In this letter, we consider a multiple-input multiple-output two-way cognitive radio system under a spectrum sharing scenario, where primary and secondary users operate on the same frequency band. The secondary terminals aims to exchange different messages with each other using multiple relays where each relay employs an amplify-and-forward strategy. The main objective of our work is to maximize the secondary sum rate allowed to share the spectrum with the primary users by respecting a primary user tolerated interference threshold. In this context, we derive a closed-form expression of the optimal power allocated to each antenna of the terminals. We then discuss the impact of some system parameters on the performance in the numerical result section.',
	 'authors': u'Ahmad Alsharoa, Hakim Ghazzai, Mohamed-Slim Alouini,',
	 'category': u'Computer Science ',
	 'date': '2013-9-29',
	 'pdflink': u'http://arxiv.org/pdf/1309.7572',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOptimal Transmit Power Allocation for MIMO Two-Way Cognitive Relay  Networks with Multiple Relays',
	 'urllink': u'http://arxiv.org/abs/1309.7572'}
2015-03-24 06:55:09+0000 [xxu46_7] INFO: Crawled 334 pages (at 1 pages/min), scraped 327 items (at 1 items/min)
2015-03-24 06:55:54+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6198> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 06:55:54+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6198>
	{'abstract': u'Third-party analysis on private records is becoming increasingly important due to the widespread data collection for various analysis purposes. However, the data in its original form often contains sensitive information about individuals, and its publication will severely breach their privacy. In this paper, we present a novel Privacy-preserving Data Analytic framework PDA, which allows a third-party aggregator to obliviously conduct infinitely many analyses on private data records provided by a dynamic group of users. Notably, every user needs to keep only O(n) keys to join data analyses among different groups of participants, and any data analysis that is represented by polynomials is supported by our framework. Besides, a real implementation shows the performance of our framework is comparable to the peer works who present ad-hoc solutions for specific data analysis applications. Despite such nice properties of PDA, it is provably secure against a very powerful attacker (chosen-plaintext attack) even in the Dolev-Yao network model where all communication channels are insecure.',
	 'authors': u'Taeho Jung, Xiang-Yang Li, Junze Han,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6198',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nInfinite Choices of Data Aggregations with Linear Number of Keys',
	 'urllink': u'http://arxiv.org/abs/1308.6198'}
2015-03-24 06:56:09+0000 [xxu46_7] INFO: Crawled 335 pages (at 1 pages/min), scraped 328 items (at 1 items/min)
2015-03-24 06:57:09+0000 [xxu46_7] INFO: Crawled 335 pages (at 0 pages/min), scraped 328 items (at 0 items/min)
2015-03-24 06:57:41+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7565> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 06:57:41+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7565>
	{'abstract': u'We consider the randomized decision tree complexity of the recursive 3-majority function. We prove a lower bound of for the two-sided-error randomized decision tree complexity of evaluating height formulae with error . This improves the lower bound of given by Jayram, Kumar, and Sivakumar (STOC\'03), and the one of given by Leonardos (ICALP\'13). Second, we improve the upper bound by giving a new zero-error randomized decision tree algorithm that has complexity at most . The previous best known algorithm achieved complexity . The new lower bound follows from a better analysis of the base case of the recursion of Jayram et al. The new algorithm uses a novel "interleaving" of two recursive algorithms.',
	 'authors': u'Frederic Magniez, Ashwin Nayak, Miklos Santha, Jonah Sherman, Gabor Tardos, David Xiao,',
	 'category': u'Computer Science ',
	 'date': '2013-9-29',
	 'pdflink': u'http://arxiv.org/pdf/1309.7565',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nImproved bounds for the randomized decision tree complexity of recursive  majority',
	 'urllink': u'http://arxiv.org/abs/1309.7565'}
2015-03-24 06:58:09+0000 [xxu46_7] INFO: Crawled 336 pages (at 1 pages/min), scraped 329 items (at 1 items/min)
2015-03-24 06:59:09+0000 [xxu46_7] INFO: Crawled 336 pages (at 0 pages/min), scraped 329 items (at 0 items/min)
2015-03-24 06:59:29+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6181> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 06:59:29+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6181>
	{'abstract': u'Classifiers based on probabilistic graphical models are very effective. In continuous domains, maximum likelihood is usually used to assess the predictions of those classifiers. When data is scarce, this can easily lead to overfitting. In any probabilistic setting, Bayesian averaging (BA) provides theoretically optimal predictions and is known to be robust to overfitting. In this work we introduce Bayesian Conditional Gaussian Network Classifiers, which efficiently perform exact Bayesian averaging over the parameters. We evaluate the proposed classifiers against the maximum likelihood alternatives proposed so far over standard UCI datasets, concluding that performing BA improves the quality of the assessed probabilities (conditional log likelihood) whilst maintaining the error rate. Overfitting is more likely to occur in domains where the number of data items is small and the number of variables is large. These two conditions are met in the realm of bioinformatics, where the early diagnosis of cancer from mass spectra is a relevant task. We provide an application of our classification framework to that problem, comparing it with the standard maximum likelihood alternative, where the improvement of quality in the assessed probabilities is confirmed.',
	 'authors': u'Victor Bellon, Jesus Cerquides, Ivo Grosse,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6181',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nBayesian Conditional Gaussian Network Classifiers with Applications to  Mass Spectra Classification',
	 'urllink': u'http://arxiv.org/abs/1308.6181'}
2015-03-24 07:00:09+0000 [xxu46_7] INFO: Crawled 337 pages (at 1 pages/min), scraped 330 items (at 1 items/min)
2015-03-24 07:01:09+0000 [xxu46_7] INFO: Crawled 337 pages (at 0 pages/min), scraped 330 items (at 0 items/min)
2015-03-24 07:01:22+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7564> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 07:01:22+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7564>
	{'abstract': u'Due to its time-varying nature, oscillator phase noise can significantly degrade the performance of channel estimation, carrier recovery, and data detection blocks in high-speed wireless communication systems. In this paper, we analyze joint channel, emph, and phase noise estimation plus data detection in emph relay systems. To achieve this goal, a detailed transmission framework involving both training and data symbols is presented. In the data transmission phase, a comb-type OFDM symbol consisting of both pilots and data symbols is proposed to track phase noise over an OFDM frame. Next, a novel algorithm that applies the training symbols to jointly estimate the channel responses, CFO, and phase noise based on the maximum a posteriori criterion is proposed. Additionally, a new emphr-Rao lower bound for evaluating the performance of channel estimation and carrier recovery algorithms in OFDM relay networks is derived. Finally, an iterative receiver for joint phase noise estimation and data detection at the destination node is derived. Extensive simulations demonstrate that the application of the proposed estimation and receiver blocks significantly improves the performance of OFDM relay networks in the presence of phase noise.',
	 'authors': u'Rui Wang, Hani Mehrpouyan, Meixia Tao, Yingbo Hua,',
	 'category': u'Computer Science ',
	 'date': '2013-9-29',
	 'pdflink': u'http://arxiv.org/pdf/1309.7564',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nChannel Estimation, Carrier Recovery, and Data Detection in the Presence  of Phase Noise in OFDM Relay Systems',
	 'urllink': u'http://arxiv.org/abs/1309.7564'}
2015-03-24 07:02:09+0000 [xxu46_7] INFO: Crawled 338 pages (at 1 pages/min), scraped 331 items (at 1 items/min)
2015-03-24 07:03:08+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6175> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 07:03:08+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6175>
	{'abstract': u"Most practical constructions of lattice codes with high coding gains are multilevel constructions where each level corresponds to an underlying code component. Construction D, Construction D, and Forney's code formula are classical constructions that produce such lattices explicitly from a family of nested binary linear codes. In this paper, we investigate these three closely related constructions along with the recently developed Construction A of lattices from codes over the polynomial ring . We show that Construction by Code Formula produces a lattice packing if and only if the nested codes being used are closed under Schur product, thus proving the similarity of Construction D and Construction by Code Formula when applied to Reed-Muller codes. In addition, we relate Construction by Code Formula to Construction A by finding a correspondence between nested binary codes and codes over . This proves that any lattice constructible using Construction by Code Formula is also constructible using Construction A. Finally, we show that Construction A produces a lattice if and only if the corresponding code over is closed under shifted Schur product.",
	 'authors': u'Wittawat Kositwattanarerk, Fr\xe9d\xe9rique Oggier,',
	 'category': u'Computer Science ',
	 'date': '2013-8-26',
	 'pdflink': u'http://arxiv.org/pdf/1308.6175',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nConnections Between Construction D and Related Constructions of Lattices',
	 'urllink': u'http://arxiv.org/abs/1308.6175'}
2015-03-24 07:03:09+0000 [xxu46_7] INFO: Crawled 339 pages (at 1 pages/min), scraped 332 items (at 1 items/min)
2015-03-24 07:04:09+0000 [xxu46_7] INFO: Crawled 339 pages (at 0 pages/min), scraped 332 items (at 0 items/min)
2015-03-24 07:04:58+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7543> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 07:04:58+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7543>
	{'abstract': u'Spatially-coupled low-density parity-check (LDPC) codes, which were first introduced as LDPC convolutional codes, have been shown to exhibit excellent performance under low-complexity belief-propagation decoding. This phenomenon is now termed threshold saturation via spatial coupling. Spatially-coupled codes have been successfully applied in numerous areas. In particular, it was proven that spatially-coupled regular LDPC codes universally achieve capacity over the class of binary memoryless symmetric (BMS) channels under belief-propagation decoding. Recently, potential functions have been used to simplify threshold saturation proofs for scalar and vector recursions. In this paper, potential functions are used to prove threshold saturation for irregular LDPC and low-density generator-matrix (LDGM) codes on BMS channels, extending the simplified proof technique to BMS channels. The corresponding potential functions are closely related to the average Bethe free entropy of the ensembles in the large-system limit. These functions also appear in statistical physics when the replica method is used to analyze optimal decoding.',
	 'authors': u'Santhosh Kumar, Andrew J. Young, Nicolas Macris, Henry D. Pfister,',
	 'category': u'Computer Science ',
	 'date': '2013-9-29',
	 'pdflink': u'http://arxiv.org/pdf/1309.7543',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nThreshold Saturation for Spatially-Coupled LDPC and LDGM Codes on BMS  Channels',
	 'urllink': u'http://arxiv.org/abs/1309.7543'}
2015-03-24 07:05:09+0000 [xxu46_7] INFO: Crawled 340 pages (at 1 pages/min), scraped 333 items (at 1 items/min)
2015-03-24 07:06:09+0000 [xxu46_7] INFO: Crawled 340 pages (at 0 pages/min), scraped 333 items (at 0 items/min)
2015-03-24 07:06:57+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6166> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 07:06:57+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6166>
	{'abstract': u'Let B be a finite collection of geometric (not necessarily convex) bodies in the plane. Clearly, this class of geometric objects naturally generalizes the class of disks, lines, ellipsoids, and even convex polygons. We consider geometric intersection graphs GB where each body of the collection B is represented by a vertex, and two vertices of GB are adjacent if the intersection of the corresponding bodies is non-empty. For such graph classes and under natural restrictions on their maximum degree or subgraph exclusion, we prove that the relation between their treewidth and the maximum size of a grid minor is linear. These combinatorial results vastly extend the applicability of all the meta-algorithmic results of the bidimensionality theory to geometrically defined graph classes.',
	 'authors': u'Alexander Grigoriev, Athanassios Koutsonas, Dimitrios M. Thilikos,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6166',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nBidimensionality of Geometric Intersection Graphs',
	 'urllink': u'http://arxiv.org/abs/1308.6166'}
2015-03-24 07:07:09+0000 [xxu46_7] INFO: Crawled 341 pages (at 1 pages/min), scraped 334 items (at 1 items/min)
2015-03-24 07:08:09+0000 [xxu46_7] INFO: Crawled 341 pages (at 0 pages/min), scraped 334 items (at 0 items/min)
2015-03-24 07:08:38+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7540> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 07:08:38+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7540>
	{'abstract': u'Large multiple-input multiple-output (MIMO) networks promise high energy efficiency, i.e., much less power is required to achieve the same capacity compared to the conventional MIMO networks if perfect channel state information (CSI) is available at the transmitter. However, in such networks, huge overhead is required to obtain full CSI especially for Frequency-Division Duplex (FDD) systems. To reduce overhead, we propose a downlink antenna selection scheme, which selects S antennas from M&gt;S transmit antennas based on the large scale fading to serve K leq S users in large distributed MIMO networks employing regularized zero-forcing (RZF) precoding. In particular, we study the joint optimization of antenna selection, regularization factor, and power allocation to maximize the average weighted sum-rate. This is a mixed combinatorial and non-convex problem whose objective and constraints have no closed-form expressions. We apply random matrix theory to derive asymptotically accurate expressions for the objective and constraints. As such, the joint optimization problem is decomposed into subproblems, each of which is solved by an efficient algorithm. In addition, we derive structural solutions for some special cases and show that the capacity of very large distributed MIMO networks scales as O left(K textrmM right) when M rightarrow infty with K,S fixed. Simulations show that the proposed scheme achieves significant performance gain over various baselines.',
	 'authors': u'An Liu, Vincent Lau,',
	 'category': u'Computer Science ',
	 'date': '2013-9-29',
	 'pdflink': u'http://arxiv.org/pdf/1309.7540',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nJoint Power and Antenna Selection Optimization in Large Cloud Radio  Access Networks',
	 'urllink': u'http://arxiv.org/abs/1309.7540'}
2015-03-24 07:09:09+0000 [xxu46_7] INFO: Crawled 342 pages (at 1 pages/min), scraped 335 items (at 1 items/min)
2015-03-24 07:10:09+0000 [xxu46_7] INFO: Crawled 342 pages (at 0 pages/min), scraped 335 items (at 0 items/min)
2015-03-24 07:10:27+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6149> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 07:10:27+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6149>
	{'abstract': u'Due to its status as the most popular video sharing platform, YouTube plays an important role in the online strategy of extreme right groups, where it is often used to host associated content such as music and other propaganda. In this paper, we develop a categorization suitable for the analysis of extreme right channels found on YouTube. By combining this with an NMF-based topic modelling method, we categorize channels originating from links propagated by extreme right Twitter accounts. This method is also used to categorize related channels, which are determined using results returned by YouTube\'s related video service. We identify the existence of a "filter bubble", whereby users who access an extreme right YouTube video are highly likely to be recommended further extreme right content.',
	 'authors': u"Derek O'Callaghan, Derek Greene, Maura Conway, Joe Carthy, P\xe1draig Cunningham,",
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6149',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nThe Extreme Right Filter Bubble',
	 'urllink': u'http://arxiv.org/abs/1308.6149'}
2015-03-24 07:11:09+0000 [xxu46_7] INFO: Crawled 343 pages (at 1 pages/min), scraped 336 items (at 1 items/min)
2015-03-24 07:12:09+0000 [xxu46_7] INFO: Crawled 343 pages (at 0 pages/min), scraped 336 items (at 0 items/min)
2015-03-24 07:12:15+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7528> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 07:12:15+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7528>
	{'abstract': u'In this paper, we derive non-asymptotic achievability and converse bounds on the source coding with/without side-information, the random number generation with/without side-information, and the channel coding for the regular channel. Our bounds are efficiently computable in the sense that the computational complexity does not depend on the block length. We also characterize the asymptotic behaviors of the large deviation regime and the moderate deviation regime by using our bounds, which implies that our bounds are asymptotically tight in those regimes. We also show the second order rates of those problems, and derive single letter forms of the variances characterizing the second order rates.',
	 'authors': u'Masahito Hayashi, Shun Watanabe,',
	 'category': u'Computer Science ',
	 'date': '2013-9-29',
	 'pdflink': u'http://arxiv.org/pdf/1309.7528',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nNon-Asymptotic and Asymptotic Analyses of Information Processing on  Markov Chains',
	 'urllink': u'http://arxiv.org/abs/1309.7528'}
2015-03-24 07:13:09+0000 [xxu46_7] INFO: Crawled 344 pages (at 1 pages/min), scraped 337 items (at 1 items/min)
2015-03-24 07:14:06+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6145> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 07:14:06+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6145>
	{'abstract': u"This technical report is an extension of the paper of the same title, which is to appear at MUCOCOS'13. The technical report proves correctness of the ELB-trees operations' semantics and that the operations are lock-free.",
	 'authors': u'Lars F. Bonnichsen, Sven Karlsson, Christian W. Probst,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6145',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nELB-Trees, An Efficient and Lock-free B-tree Derivative',
	 'urllink': u'http://arxiv.org/abs/1308.6145'}
2015-03-24 07:14:09+0000 [xxu46_7] INFO: Crawled 345 pages (at 1 pages/min), scraped 338 items (at 1 items/min)
2015-03-24 07:15:01+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7527> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 07:15:01+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7527>
	{'abstract': u'We study joint spectrum allocation and user association in heterogeneous cellular networks with multiple tiers of base stations. A stochastic geometric approach is applied as the basis to derive the average downlink user data rate in a closed-form expression. Then, the expression is employed as the objective function in jointly optimizing spectrum allocation and user association, which is of non-convex programming in nature. A computationally efficient Structured Spectrum Allocation and User Association (SSAUA) approach is proposed, solving the optimization problem optimally when the density of users is low, and near-optimally with a guaranteed performance bound when the density of users is high. A Surcharge Pricing Scheme (SPS) is also presented, such that the designed association bias values can be achieved in Nash equilibrium. Simulations and numerical studies are conducted to validate the accuracy and efficiency of the proposed SSAUA approach and SPS.',
	 'authors': u'Wei Bao, Ben Liang,',
	 'category': u'Computer Science ',
	 'date': '2013-9-29',
	 'pdflink': u'http://arxiv.org/pdf/1309.7527',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nStructured Spectrum Allocation and User Association in Heterogeneous  Cellular Networks',
	 'urllink': u'http://arxiv.org/abs/1309.7527'}
2015-03-24 07:15:09+0000 [xxu46_7] INFO: Crawled 346 pages (at 1 pages/min), scraped 339 items (at 1 items/min)
2015-03-24 07:16:09+0000 [xxu46_7] INFO: Crawled 346 pages (at 0 pages/min), scraped 339 items (at 0 items/min)
2015-03-24 07:16:59+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6138> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 07:16:59+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6138>
	{'abstract': u"Modern multi-domain networks now span over datacenter networks, enterprise networks, customer sites and mobile entities. Such networks are critical and, thus, must be resilient, scalable and easily extensible. The emergence of Software-Defined Networking (SDN) protocols, which enables to decouple the data plane from the control plane and dynamically program the network, opens up new ways to architect such networks. In this paper, we propose DISCO, an open and extensible DIstributed SDN COntrol plane able to cope with the distributed and heterogeneous nature of modern overlay networks and wide area networks. DISCO controllers manage their own network domain and communicate with each others to provide end-to-end network services. This communication is based on a unique lightweight and highly manageable control channel used by agents to self-adaptively share aggregated network-wide information. We implemented DISCO on top of the Floodlight OpenFlow controller and the AMQP protocol. We demonstrated how DISCO's control plane dynamically adapts to heterogeneous network topologies while being resilient enough to survive to disruptions and attacks and providing classic functionalities such as end-point migration and network-wide traffic engineering. The experimentation results we present are organized around three use cases: inter-domain topology disruption, end-to-end priority service request and virtual machine migration.",
	 'authors': u'K\xe9vin Phemius, Mathieu Bouet, J\xe9r\xe9mie Leguay,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6138',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nDISCO: Distributed Multi-domain SDN Controllers',
	 'urllink': u'http://arxiv.org/abs/1308.6138'}
2015-03-24 07:17:09+0000 [xxu46_7] INFO: Crawled 347 pages (at 1 pages/min), scraped 340 items (at 1 items/min)
2015-03-24 07:18:09+0000 [xxu46_7] INFO: Crawled 347 pages (at 0 pages/min), scraped 340 items (at 0 items/min)
2015-03-24 07:18:52+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7524> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 07:18:52+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7524>
	{'abstract': u"Holland's (1975) genetic algorithm is a minimal computer model of natural selection that made it possible to investigate the effect of manipulating specific parameters on the evolutionary process. If culture is, like biology, a form of evolution, it should be possible to similarly abstract the underlying skeleton of the process and develop a minimal model of it. Meme and Variations, or MAV, is a computational model, inspired by the genetic algorithm, of how ideas evolve in a society of interacting individuals (Gabora 1995). The name is a pun on the classical music form 'theme and variations', because it is based on the premise that novel ideas are variations of old ones; they result from tweaking or combining existing ideas in new ways (Holland et al. 1981). MAV explores the impact of biological phenomena such as over-dominance and epistasis as well as cognitive and social phenomena such as the ability to learn generalizations or imitate others on the fitness and diversity of cultural transmissible actions.",
	 'authors': u'Liane Gabora,',
	 'category': u'Computer Science ',
	 'date': '2013-9-29',
	 'pdflink': u'http://arxiv.org/pdf/1309.7524',
	 'subjects': u'Multiagent Systems (cs.MA)',
	 'title': u'\nMeme and Variations: A Computer Model of Cultural Evolution',
	 'urllink': u'http://arxiv.org/abs/1309.7524'}
2015-03-24 07:19:09+0000 [xxu46_7] INFO: Crawled 348 pages (at 1 pages/min), scraped 341 items (at 1 items/min)
2015-03-24 07:20:05+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6118> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 07:20:05+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6118>
	{'abstract': u'Bipartite user-object networks are becoming increasingly popular in representing user interaction data in a web or e-commerce environment. They have certain characteristics and challenges that differentiates them from other bipartite networks. This paper analyzes the properties of five real world user-object networks. In all cases we found a heavy tail object degree distribution with popular objects connecting together a large part of the users causing significant edge inflation in the projected users network. We propose a novel edge weighting strategy based on tf-idf and show that the new scheme improves both the density and the quality of the community structure in the projections. The improvement is also noticed when comparing to partially random networks.',
	 'authors': u'Sorin Alupoaie, P\xe1draig Cunningham,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6118',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nUsing tf-idf as an edge weighting scheme in user-object bipartite  networks',
	 'urllink': u'http://arxiv.org/abs/1308.6118'}
2015-03-24 07:20:09+0000 [xxu46_7] INFO: Crawled 349 pages (at 1 pages/min), scraped 342 items (at 1 items/min)
2015-03-24 07:21:09+0000 [xxu46_7] INFO: Crawled 349 pages (at 0 pages/min), scraped 342 items (at 0 items/min)
2015-03-24 07:22:04+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7522> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 07:22:04+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7522>
	{'abstract': u'The examination of Osteoarthritis disease through X-ray by rheumatology can be classified into four grade of severity. This paper discusses about the application of artificial neural network backpropagation method for measuring the severity of the disease, where the observed X-ray range from wrist to fingers. The main procedures of system in this paper is divided into three, which are image processing, feature extraction, and artificial neural network process. First, an X-ray image digital (200x150 pixels and greyscale) will be thresholded, then extracted features based on probabilistic values of the color intensity of seven bit quantization result, and statistical textures. That feature values then will be normalizing to interval [0.1, 0.9], and then the result would be processing on backpropagation artificial neural network system as input to determine the severity of disease from an X-ray had input before it. From testing with learning rate 0.3, momentum 0.4, hidden units five pieces and about 132 feature vectors, this system had had a level of accuracy of 100% for learning data, 80% for learning and non-learning data, and 66.6% for non-learning data',
	 'authors': u'Dian Pratiwi, Diaz D. Santika, Bens Pardamean,',
	 'category': u'Computer Science ',
	 'date': '2013-9-29',
	 'pdflink': u'http://arxiv.org/pdf/1309.7522',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nAn Application of Backpropagation Artificial Neural Network Method for  Measuring The Severity of Osteoarthritis',
	 'urllink': u'http://arxiv.org/abs/1309.7522'}
2015-03-24 07:22:09+0000 [xxu46_7] INFO: Crawled 350 pages (at 1 pages/min), scraped 343 items (at 1 items/min)
2015-03-24 07:23:09+0000 [xxu46_7] INFO: Crawled 350 pages (at 0 pages/min), scraped 343 items (at 0 items/min)
2015-03-24 07:23:46+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6096> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 07:23:46+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6096>
	{'abstract': u'A compact version of MACRO SPITBOL, a compiler/ interpreter for a variant of SNOBOL4, has been developed for use on microcomputer systems. The techniques for producing an implementation are largely automatic in order to preserve the integrity and portability of the SPITBOL system. These techniques are discussed along with a description of an initial implementation on a 65K byte minicomputer. An interesting theoretical problem which arises when using procedures which compact the interpretive object code is also analyzed.',
	 'authors': u'Robert B. K. Dewar, Martin Charles Golumbic, Clinton F. Goss,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6096',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nMicro Spitbol',
	 'urllink': u'http://arxiv.org/abs/1308.6096'}
2015-03-24 07:24:09+0000 [xxu46_7] INFO: Crawled 351 pages (at 1 pages/min), scraped 344 items (at 1 items/min)
2015-03-24 07:25:09+0000 [xxu46_7] INFO: Crawled 351 pages (at 0 pages/min), scraped 344 items (at 0 items/min)
2015-03-24 07:25:42+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7518> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 07:25:42+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7518>
	{'abstract': u'This paper considers detection and error control coding for the two-dimensional magnetic recording (TDMR) channel modeled by the two-dimensional (2D) four-rectangular-grain model proposed by Kavcic, Huang et. al. in 2010. This simple model captures the effects of different 2D grain sizes and shapes, as well as the TDMR grain overwrite effect: grains large enough to be written by successive bits retain the polarity of only the last bit written. We construct a row-by-row BCJR detection algorithm that considers outputs from two rows at a time over two adjacent columns, thereby enabling consideration of more grain and data states than previously proposed algorithms that scan only one row at a time. The proposed algorithm employs soft-decision feedback of grain states from previous rows to aid the estimation of current data bits and grain states. Simulation results using the same average coded bit density and serially concatenated convolutional code (SCCC) as a previous paper by Pan, Ryan, et. al. show gains in user bits/grain of up to 6.7% over the previous work when no iteration is performed between the TDMR BCJR and the SCCC, and gains of up to 13.4% when the detector and the decoder iteratively exchange soft information.',
	 'authors': u'Michael Carosino, Yiming Chen, Benjamin J. Belzer, Krishnamoorthy Sivakumar, Jacob Murray, Paul Wettin,',
	 'category': u'Computer Science ',
	 'date': '2013-9-29',
	 'pdflink': u'http://arxiv.org/pdf/1309.7518',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nIterative Detection and Decoding for the Four-Rectangular-Grain TDMR  Model',
	 'urllink': u'http://arxiv.org/abs/1309.7518'}
2015-03-24 07:26:09+0000 [xxu46_7] INFO: Crawled 352 pages (at 1 pages/min), scraped 345 items (at 1 items/min)
2015-03-24 07:27:09+0000 [xxu46_7] INFO: Crawled 352 pages (at 0 pages/min), scraped 345 items (at 0 items/min)
2015-03-24 07:27:31+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6086> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 07:27:31+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6086>
	{'abstract': u'We consider the problem of in-network compressed sensing from distributed measurements. Every agent has a set of measurements of a signal , and the objective is for the agents to recover from their collective measurements using only communication with neighbors in the network. Our distributed approach to this problem is based on the centralized Iterative Hard Thresholding algorithm (IHT). We first present a distributed IHT algorithm for static networks that leverages standard tools from distributed computing to execute in-network computations with minimized bandwidth consumption. Next, we address distributed signal recovery in networks with time-varying topologies. The network dynamics necessarily introduce inaccuracies to our in-network computations. To accommodate these inaccuracies, we show how centralized IHT can be extended to include inexact computations while still providing the same recovery guarantees as the original IHT algorithm. We then leverage these new theoretical results to develop a distributed version of IHT for time-varying networks. Evaluations show that our distributed algorithms for both static and time-varying networks outperform previously proposed solutions in time and bandwidth by several orders of magnitude.',
	 'authors': u'Stacy Patterson, Yonina C. Eldar, Idit Keidar,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6086',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nDistributed Compressed Sensing For Static and Time-Varying Networks',
	 'urllink': u'http://arxiv.org/abs/1308.6086'}
2015-03-24 07:28:09+0000 [xxu46_7] INFO: Crawled 353 pages (at 1 pages/min), scraped 346 items (at 1 items/min)
2015-03-24 07:28:37+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7517> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 07:28:37+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7517>
	{'abstract': u'Tag recommendation is a major aspect of collaborative tagging systems. It aims to recommend tags to a user for tagging an item. In this paper we present a part of our work in progress which is a novel improvement of recommendations by re-ranking the output of a tag recommender. We mine association rules between candidates tags in order to determine a more consistent list of tags to recommend. Our method is an add-on one which leads to better recommendations as we show in this paper. It is easily parallelizable and morever it may be applied to a lot of tag recommenders. The experiments we did on five datasets with two kinds of tag recommender demonstrated the efficiency of our method.',
	 'authors': u'Modou Gueye, Talel Abdessalem, Hubert Naacke,',
	 'category': u'Computer Science ',
	 'date': '2013-9-29',
	 'pdflink': u'http://arxiv.org/pdf/1309.7517',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nImproving tag recommendation by folding in more consistency',
	 'urllink': u'http://arxiv.org/abs/1309.7517'}
2015-03-24 07:29:09+0000 [xxu46_7] INFO: Crawled 354 pages (at 1 pages/min), scraped 347 items (at 1 items/min)
2015-03-24 07:30:09+0000 [xxu46_7] INFO: Crawled 354 pages (at 0 pages/min), scraped 347 items (at 0 items/min)
2015-03-24 07:30:35+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6058> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 07:30:35+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6058>
	{'abstract': u'Data grid is a distributed computing architecture that integrates a large number of data and computing resources into a single virtual data management system. It enables the sharing and coordinated use of data from various resources and provides various services to fit the needs of high performance distributed and data-intensive computing. Here data partitioning and dynamic replication in data grid are considered. In which security and access performance of a system are efficient. There are several important requirements for data grids, including information survivability, security, and access performance. More specifically, the investigation is the problem of optimal allocation of sensitive data objects that are partitioned by using secret sharing scheme or erasure coding scheme and replicated. DATA PARTITIONING is known as the single data can be divided into multiple objects. REPLICATION is known as process of sharing information. storing same data in multiple systems. Replication techniques are frequently used to improve data availability. Single point failure does not affect this system. Where the data will be secured.',
	 'authors': u'A.S.Syed Navaz, C.Prabhadevi, V.Sangeetha,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6058',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nData Grid Concepts for Data Security in Distributed Computing',
	 'urllink': u'http://arxiv.org/abs/1308.6058'}
2015-03-24 07:31:09+0000 [xxu46_7] INFO: Crawled 355 pages (at 1 pages/min), scraped 348 items (at 1 items/min)
2015-03-24 07:32:09+0000 [xxu46_7] INFO: Crawled 355 pages (at 0 pages/min), scraped 348 items (at 0 items/min)
2015-03-24 07:32:31+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7512> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 07:32:31+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7512>
	{'abstract': u'Submodular functions can be exactly minimized in polynomial time, and the special case that graph cuts solve with max flow cite has had significant impact in computer vision cite. In this paper we address the important class of sum-of-submodular (SoS) functions cite, which can be efficiently minimized via a variant of max flow called submodular flow cite. SoS functions can naturally express higher order priors involving, e.g., local image patches; however, it is difficult to fully exploit their expressive power because they have so many parameters. Rather than trying to formulate existing higher order priors as an SoS function, we take a discriminative learning approach, effectively searching the space of SoS functions for a higher order prior that performs well on our training set. We adopt a structural SVM approach cite and formulate the training problem in terms of quadratic programming; as a result we can efficiently search the space of SoS priors via an extended cutting-plane algorithm. We also show how the state-of-the-art max flow method for vision problems cite can be modified to efficiently solve the submodular flow problem. Experimental comparisons are made against the OpenCV implementation of the GrabCut interactive segmentation technique cite, which uses hand-tuned parameters instead of machine learning. On a standard dataset cite our method learns higher order priors with hundreds of parameter values, and produces significantly better segmentations. While our focus is on binary labeling problems, we show that our techniques can be naturally generalized to handle more than two labels.',
	 'authors': u'Alexander Fix, Thorsten Joachims, Sam Park, Ramin Zabih,',
	 'category': u'Computer Science ',
	 'date': '2013-9-28',
	 'pdflink': u'http://arxiv.org/pdf/1309.7512',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nStructured learning of sum-of-submodular higher order energy functions',
	 'urllink': u'http://arxiv.org/abs/1309.7512'}
2015-03-24 07:33:09+0000 [xxu46_7] INFO: Crawled 356 pages (at 1 pages/min), scraped 349 items (at 1 items/min)
2015-03-24 07:33:37+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6056> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 07:33:37+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6056>
	{'abstract': u'Multiphase active contour based models are useful in identifying multiple regions with different characteristics such as the mean values of regions. This is relevant in brain magnetic resonance images (MRIs), allowing the differentiation of white matter against gray matter. We consider a well defined globally convex formulation of Vese and Chan multiphase active contour model for segmenting brain MRI images. A well-established theory and an efficient dual minimization scheme are thoroughly described which guarantees optimal solutions and provides stable segmentations. Moreover, under the dual minimization implementation our model perfectly describes disjoint regions by avoiding local minima solutions. Experimental results indicate that the proposed approach provides better accuracy than other related multiphase active contour algorithms even under severe noise, intensity inhomogeneities, and partial volume effects.',
	 'authors': u'Juan C. Moreno, V. B. S. Prasath, Hugo Proenca, K. Palaniappan,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6056',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nBrain MRI Segmentation with Fast and Globally Convex Multiphase Active  Contours',
	 'urllink': u'http://arxiv.org/abs/1308.6056'}
2015-03-24 07:34:09+0000 [xxu46_7] INFO: Crawled 357 pages (at 1 pages/min), scraped 350 items (at 1 items/min)
2015-03-24 07:35:09+0000 [xxu46_7] INFO: Crawled 357 pages (at 0 pages/min), scraped 350 items (at 0 items/min)
2015-03-24 07:35:35+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7508> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 07:35:35+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7508>
	{'abstract': u"Self-avoiding walks (SAWs) were introduced in chemistry to model the real-life behavior of chain-like entities such as solvents and polymers, whose physical volume prohibits multiple occupation of the same spatial point. In mathematics, a SAW lives in the n-dimensional lattices. In this paper, SAWs are a metaphor for walks across faces of n-dimensional dice, or more formally, a hyperhedron family H(Theta, b, n). Each face is assigned a label ; x represents a unique n-dimensional coordinate string, Theta(x) is the value of the function. The walk searches Theta(x) for optima by following five simple rules: (1) select a random coordinate and mark it as the `initial pivot'; (2) probe all unmarked adjacent coordinates, then select and mark the coordinate with the 'best value' as the new pivot; (3) continue the walk until either the 'best value' &lt;= `target value' or the walk is being blocked by adjacent coordinates that are already pivots; (4) if the walk is blocked, restart the walk from a randomly selected `new initial pivot'; (5) if needed, manage the memory overflow with a streaming-like buffer of appropriate size. Hard instances from a number of problem domains, including the 2D protein folding problem, with up to (2^)*(3^) coordinates, have been solved with SAWs in less than 1,000,000 steps -- while also exceeding the quality of best known solutions to date.",
	 'authors': u'Franc Brglez,',
	 'category': u'Computer Science ',
	 'date': '2013-9-28',
	 'pdflink': u'http://arxiv.org/pdf/1309.7508',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nOn Self-Avoiding Walks across n-Dimensional Dice and Combinatorial  Optimization: An Introduction',
	 'urllink': u'http://arxiv.org/abs/1309.7508'}
2015-03-24 07:36:09+0000 [xxu46_7] INFO: Crawled 358 pages (at 1 pages/min), scraped 351 items (at 1 items/min)
2015-03-24 07:37:09+0000 [xxu46_7] INFO: Crawled 358 pages (at 0 pages/min), scraped 351 items (at 0 items/min)
2015-03-24 07:37:30+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6029> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 07:37:30+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6029>
	{'abstract': u'A hierarchy of semidefinite programming (SDP) relaxations approximates the global optimum of polynomial optimization problems of noncommuting variables. Generating the relaxation, however, is a computationally demanding task, and only problems of commuting variables have efficient generators. We develop an implementation for problems of noncommuting problems that creates the relaxation to be solved by SDPA -- a high-performance solver that runs in a distributed environment. We further exploit the inherent sparsity of optimization problems in quantum physics to reduce the complexity of resulting relaxation. Constrained problems with a relaxation of order one may contain up to hundreds of variables. The implementation is available in C++ and Python. The tool helps solve problems such as finding the ground state energy or testing quantum correlations.',
	 'authors': u'Peter Wittek,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6029',
	 'subjects': u'Mathematical Software (cs.MS)',
	 'title': u'\nNcpol2sdpa -- Sparse Semidefinite Programming Relaxations for Polynomial  Optimization Problems of Noncommuting Variables',
	 'urllink': u'http://arxiv.org/abs/1308.6029'}
2015-03-24 07:38:09+0000 [xxu46_7] INFO: Crawled 359 pages (at 1 pages/min), scraped 352 items (at 1 items/min)
2015-03-24 07:39:09+0000 [xxu46_7] INFO: Crawled 359 pages (at 0 pages/min), scraped 352 items (at 0 items/min)
2015-03-24 07:39:30+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7484> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 07:39:30+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7484>
	{'abstract': u'In the past decade, SIFT descriptor has been witnessed as one of the most robust local invariant feature descriptors and widely used in various vision tasks. Most traditional image classification systems depend on the luminance-based SIFT descriptors, which only analyze the gray level variations of the images. Misclassification may happen since their color contents are ignored. In this article, we concentrate on improving the performance of existing image classification algorithms by adding color information. To achieve this purpose, different kinds of colored SIFT descriptors are introduced and implemented. Locality-constrained Linear Coding (LLC), a state-of-the-art sparse coding technology, is employed to construct the image classification system for the evaluation. The real experiments are carried out on several benchmarks. With the enhancements of color SIFT, the proposed image classification system obtains approximate 3% improvement of classification accuracy on the Caltech-101 dataset and approximate 4% improvement of classification accuracy on the Caltech-256 dataset.',
	 'authors': u'Chen Junzhou, Li Qing, Peng Qiang, Kin Hong Wong,',
	 'category': u'Computer Science ',
	 'date': '2013-9-28',
	 'pdflink': u'http://arxiv.org/pdf/1309.7484',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nCSIFT Based Locality-constrained Linear Coding for Image Classification',
	 'urllink': u'http://arxiv.org/abs/1309.7484'}
2015-03-24 07:40:09+0000 [xxu46_7] INFO: Crawled 360 pages (at 1 pages/min), scraped 353 items (at 1 items/min)
2015-03-24 07:41:09+0000 [xxu46_7] INFO: Crawled 360 pages (at 0 pages/min), scraped 353 items (at 0 items/min)
2015-03-24 07:41:25+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6025> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 07:41:25+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6025>
	{'abstract': u'We prove the existence of approximate correlated equilibrium of support size polylogarithmic in the number of players and the number of actions per player. In particular, using the probabilistic method, we show that there exists a multiset of polylogarithmic size such that the uniform distribution over this multiset forms an approximate correlated equilibrium. Along similar lines, we establish the existence of approximate coarse correlated equilibrium with logarithmic support. We complement these results by considering the computational complexity of determining small-support approximate equilibria. We show that random sampling can be used to efficiently determine an approximate coarse correlated equilibrium with logarithmic support. But, such a tight result does not hold for correlated equilibrium, i.e., sampling might generate an approximate correlated equilibrium of support size Omega(m) where m is the number of actions per player. Finally, we show that finding an exact correlated equilibrium with smallest possible support is NP-hard under Cook reductions, even in the case of two-player zero-sum games.',
	 'authors': u'Yakov Babichenko, Siddharth Barman, Ron Peretz,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6025',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nSmall-Support Approximate Correlated Equilibria',
	 'urllink': u'http://arxiv.org/abs/1308.6025'}
2015-03-24 07:42:09+0000 [xxu46_7] INFO: Crawled 361 pages (at 1 pages/min), scraped 354 items (at 1 items/min)
2015-03-24 07:43:09+0000 [xxu46_7] INFO: Crawled 361 pages (at 0 pages/min), scraped 354 items (at 0 items/min)
2015-03-24 07:43:14+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7478> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 07:43:14+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7478>
	{'abstract': u'Demixing is the problem of identifying multiple structured signals from a superimposed, undersampled, and noisy observation. This work analyzes a general framework, based on convex optimization, for solving demixing problems. When the constituent signals follow a generic incoherence model, this analysis leads to precise recovery guarantees. These results admit an attractive interpretation: each signal possesses an intrinsic degrees-of-freedom parameter, and demixing can succeed if and only if the dimension of the observation exceeds the total degrees of freedom present in the observation.',
	 'authors': u'Michael B. McCoy, Joel A. Tropp,',
	 'category': u'Computer Science ',
	 'date': '2013-9-28',
	 'pdflink': u'http://arxiv.org/pdf/1309.7478',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nThe achievable performance of convex demixing',
	 'urllink': u'http://arxiv.org/abs/1309.7478'}
2015-03-24 07:44:09+0000 [xxu46_7] INFO: Crawled 362 pages (at 1 pages/min), scraped 355 items (at 1 items/min)
2015-03-24 07:44:17+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6021> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 07:44:17+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6021>
	{'abstract': u'Associative memories are structures that can retrieve previously stored information given a partial input pattern instead of an explicit address as in indexed memories. A few hardware approaches have recently been introduced for a new family of associative memories based on Sparse-Clustered Networks (SCN) that show attractive features. These architectures are suitable for implementations with low retrieval latency, but are limited to small networks that store a few hundred data entries. In this paper, a new hardware architecture of SCNs is proposed that features a new data-storage technique as well as a method we refer to as Selective Decoding (SD-SCN). The SD-SCN has been implemented using a similar FPGA used in the previous efforts and achieves two orders of magnitude higher capacity, with no error-performance penalty but with the cost of few extra clock cycles per data access.',
	 'authors': u'Hooman Jarollahi, Naoya Onizawa, Warren J. Gross,',
	 'category': u'Computer Science ',
	 'date': '2013-8-28',
	 'pdflink': u'http://arxiv.org/pdf/1308.6021',
	 'subjects': u'Hardware Architecture (cs.AR)',
	 'title': u'\nSelective Decoding in Associative Memories Based on Sparse-Clustered  Networks',
	 'urllink': u'http://arxiv.org/abs/1308.6021'}
2015-03-24 07:45:09+0000 [xxu46_7] INFO: Crawled 363 pages (at 1 pages/min), scraped 356 items (at 1 items/min)
2015-03-24 07:46:04+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7472> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 07:46:04+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7472>
	{'abstract': u'A comprehensive framework for detection and characterization of overlapping intrinsic symmetry over 3D shapes is proposed. To identify prominent symmetric regions which overlap in space and vary in form, the proposed framework is decoupled into a Correspondence Space Voting procedure followed by a Transformation Space Mapping procedure. In the correspondence space voting procedure, significant symmetries are first detected by identifying surface point pairs on the input shape that exhibit local similarity in terms of their intrinsic geometry while simultaneously maintaining an intrinsic distance structure at a global level. Since different point pairs can share a common point, the detected symmetric shape regions can potentially overlap. To this end, a global intrinsic distance-based voting technique is employed to ensure the inclusion of only those point pairs that exhibit significant symmetry. In the transformation space mapping procedure, the Functional Map framework is employed to generate the final map of symmetries between point pairs. The transformation space mapping procedure ensures the retrieval of the underlying dense correspondence map throughout the 3D shape that follows a particular symmetry. Additionally, the formulation of a novel cost matrix enables the inner product to succesfully indicate the complexity of the underlying symmetry transformation. The proposed transformation space mapping procedure is shown to result in the formulation of a semi-metric symmetry space where each point in the space represents a specific symmetry transformation and the distance between points represents the complexity between the corresponding transformations. Experimental results show that the proposed framework can successfully process complex 3D shapes that possess rich symmetries.',
	 'authors': u'Anirban Mukhopadhyay, Suchendra M. Bhandarkar, Fatih Porikli,',
	 'category': u'Computer Science ',
	 'date': '2013-9-28',
	 'pdflink': u'http://arxiv.org/pdf/1309.7472',
	 'subjects': u'Graphics (cs.GR)',
	 'title': u'\nDetection and Characterization of Intrinsic Symmetry',
	 'urllink': u'http://arxiv.org/abs/1309.7472'}
2015-03-24 07:46:09+0000 [xxu46_7] INFO: Crawled 364 pages (at 1 pages/min), scraped 357 items (at 1 items/min)
2015-03-24 07:47:09+0000 [xxu46_7] INFO: Crawled 364 pages (at 0 pages/min), scraped 357 items (at 0 items/min)
2015-03-24 07:47:42+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6007> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 07:47:42+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6007>
	{'abstract': u'We propose a new conjecture on some exponential sums. These particular sums have not apparently been considered in the literature. Subject to the conjecture we obtain the first effective construction of asymptotically good tree codes. The available numerical evidence is consistent with the conjecture and is sufficient to certify codes for significant-length communications.',
	 'authors': u'Cristopher Moore, Leonard J. Schulman,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.6007',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nTree Codes and a Conjecture on Exponential Sums',
	 'urllink': u'http://arxiv.org/abs/1308.6007'}
2015-03-24 07:48:09+0000 [xxu46_7] INFO: Crawled 365 pages (at 1 pages/min), scraped 358 items (at 1 items/min)
2015-03-24 07:48:48+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7461> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 07:48:48+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7461>
	{'abstract': u'Wireless Sensor Networks (WSNs) are used to perform distributed sensing in various fields, such as health, military, home etc. In WSNs, sensor nodes should communicate among themselves and do distributed computation over the sensed values to identify the occurrence of an event. This paper assumes the no memory computation model for sensor nodes, i.e. the sensor nodes only have two registers. This paper presents an optimal architecture for the distributed computation in WSN and also claims that this architecture is the optimal for the described computation model.',
	 'authors': u'Rama Murthy Garimella, Deepti Singhal,',
	 'category': u'Computer Science ',
	 'date': '2013-9-28',
	 'pdflink': u'http://arxiv.org/pdf/1309.7461',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nGrid-based Network Architecture for Distributed Computation in Wireless  Sensor Networks',
	 'urllink': u'http://arxiv.org/abs/1309.7461'}
2015-03-24 07:49:09+0000 [xxu46_7] INFO: Crawled 366 pages (at 1 pages/min), scraped 359 items (at 1 items/min)
2015-03-24 07:49:35+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.6003> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 07:49:35+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.6003>
	{'abstract': u'The Gripon-Berrou neural network (GBNN) is a recently invented recurrent neural network embracing a LDPC-like sparse encoding setup which makes it extremely resilient to noise and errors. A natural use of GBNN is as an associative memory. There are two activation rules for the neuron dynamics, namely sum-of-sum and sum-of-max. The latter outperforms the former in terms of retrieval rate by a huge margin. In prior discussions and experiments, it is believed that although sum-of-sum may lead the network to oscillate, sum-of-max always converges to an ensemble of neuron cliques corresponding to previously stored patterns. However, this is not entirely correct. In fact, sum-of-max often converges to bogus fixed points where the ensemble only comprises a small subset of the converged state. By taking advantage of this overlooked fact, we can greatly improve the retrieval rate. We discuss this particular issue and propose a number of heuristics to push sum-of-max beyond these bogus fixed points. To tackle the problem directly and completely, a novel post-processing algorithm is also developed and customized to the structure of GBNN. Experimental results show that the new algorithm achieves a huge performance boost in terms of both retrieval rate and run-time, compared to the standard sum-of-max and all the other heuristics.',
	 'authors': u'Zhe Yao, Vincent Gripon, Michael Rabbat,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.6003',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nImproving Sparse Associative Memories by Escaping from Bogus Fixed  Points',
	 'urllink': u'http://arxiv.org/abs/1308.6003'}
2015-03-24 07:50:09+0000 [xxu46_7] INFO: Crawled 367 pages (at 1 pages/min), scraped 360 items (at 1 items/min)
2015-03-24 07:51:09+0000 [xxu46_7] INFO: Crawled 367 pages (at 0 pages/min), scraped 360 items (at 0 items/min)
2015-03-24 07:51:13+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7457> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 07:51:13+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7457>
	{'abstract': u'For any time bound f, let H(f) denote the hierarchy conjecture which means that the restriction of the numbers of work tapes of deterministic Turing machines to some b generates an infinite hierarchy of proper subclasses DTIME_b(f) subset DTIME(f). We show that H(f) implies separations of deterministic from nondeterministic time classes. H(f) follows from the gap property, G(f), which says that there is a time-constructible bound f_2 such that f in o(f_2) and DTIME(f)=DTIME(f_2). G(f) implies further separations. All these relationships relativize.',
	 'authors': u'Armin Hemmerling,',
	 'category': u'Computer Science ',
	 'date': '2013-9-28',
	 'pdflink': u'http://arxiv.org/pdf/1309.7457',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nOn the Tape-Number Problem for Deterministic Time Classes',
	 'urllink': u'http://arxiv.org/abs/1309.7457'}
2015-03-24 07:52:09+0000 [xxu46_7] INFO: Crawled 368 pages (at 1 pages/min), scraped 361 items (at 1 items/min)
2015-03-24 07:52:56+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5999> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 07:52:56+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5999>
	{'abstract': u'The advent of Bluetooth wireless technology makes it possible to transmit real-time audio in mobile devices. Bluetooth is cost-efficient and power-efficient, but it is not suitable for traditional audio encoding and real-time streaming due to limited bandwidth, high degree of error rates, and the time-varying nature of the radio link. Therefore, audio streaming over Bluetooth poses problems such as guzzling of both power and bandwidth. In order to overcome the above mentioned problems, an algorithm is proposed in this work to optimize the audio stream from the source to the sink by estimating the proximity between them. The optimization is achieved by adjusting the bit rate of the audio stream thus conserving power. We considered carefully various Bluetooth signal parameters and the most suitable parameter for estimating the proximity has been determined experimentally. The experiments were carried out using Class II BS003 Bluesoleil dongle. This work will enable the Bluetooth users to perform a seamless and optimized streaming of MP3 stereo audio data.',
	 'authors': u'Ka. Selvaradjou, A. Sharma Shankar, U. Anandakumar, N. Sivasundar,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5999',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nOptimization of Bluetooth Audio Stream based on the Estimation of  Proximity',
	 'urllink': u'http://arxiv.org/abs/1308.5999'}
2015-03-24 07:53:09+0000 [xxu46_7] INFO: Crawled 369 pages (at 1 pages/min), scraped 362 items (at 1 items/min)
2015-03-24 07:54:09+0000 [xxu46_7] INFO: Crawled 369 pages (at 0 pages/min), scraped 362 items (at 0 items/min)
2015-03-24 07:54:54+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7451> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 07:54:54+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7451>
	{'abstract': u"In this paper, we propose opportunistic jammer selection in a wireless security system for increasing the secure degrees of freedom (DoF) between a transmitter and a legitimate receiver (say, Alice and Bob). There is a jammer group consisting of jammers among which Bob selects jammers. The selected jammers transmit independent and identically distributed Gaussian signals to hinder the eavesdropper (Eve). Since the channels of Bob and Eve are independent, we can select the jammers whose jamming channels are aligned at Bob, but not at Eve. As a result, Eve cannot obtain any DoF unless it has more than receive antennas, where is the number of jammer's transmit antenna each, and hence can be regarded as defensible dimensions against Eve. For the jamming signal alignment at Bob, we propose two opportunistic jammer selection schemes and find the scaling law of the required number of jammers for target secure DoF by a geometrical interpretation of the received signals.",
	 'authors': u'Jung Hoon Lee, Wan Choi,',
	 'category': u'Computer Science ',
	 'date': '2013-9-28',
	 'pdflink': u'http://arxiv.org/pdf/1309.7451',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nMultiuser Diversity for Secrecy Communications Using Opportunistic  Jammer Selection -- Secure DoF and Jammer Scaling Law',
	 'urllink': u'http://arxiv.org/abs/1309.7451'}
2015-03-24 07:55:09+0000 [xxu46_7] INFO: Crawled 370 pages (at 1 pages/min), scraped 363 items (at 1 items/min)
2015-03-24 07:56:09+0000 [xxu46_7] INFO: Crawled 370 pages (at 0 pages/min), scraped 363 items (at 0 items/min)
2015-03-24 07:56:47+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5996> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 07:56:47+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5996>
	{'abstract': u'The Cloud Computing concept offers dynamically scalable resources provisioned as a service over the Internet.Economic benefits are the main driver for the Cloud, since it promises the reduction of capital expenditure and operational expenditure.In order for this to become reality, however, there are still some challenges to be solved. Amongst these are security and trust issues, since the user data has to be released to the Cloud and thus leaves the protection sphere of the data owner. Most of the discussions on these topics are mainly driven by arguments related to organisational means. This paper focuses on various security issues arising from the usage of Cloud services and especially by the rapid development of Cloud computing arena. It also discusses basic security model followed by various High Level Security threats in the industry.',
	 'authors': u'Harit Shah, Sharma Shankar Anandane, Shrikanth,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5996',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nSecurity Issues on Cloud Computing',
	 'urllink': u'http://arxiv.org/abs/1308.5996'}
2015-03-24 07:57:09+0000 [xxu46_7] INFO: Crawled 371 pages (at 1 pages/min), scraped 364 items (at 1 items/min)
2015-03-24 07:58:09+0000 [xxu46_7] INFO: Crawled 371 pages (at 0 pages/min), scraped 364 items (at 0 items/min)
2015-03-24 07:58:44+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7440> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 07:58:44+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7440>
	{'abstract': u'High triangle density -- the graph property stating that a constant fraction of two-hop paths belong to a triangle -- is a common signature of social networks. This paper studies triangle-dense graphs from a structural perspective. We prove constructively that significant portions of a triangle-dense graph are contained in a disjoint union of dense, radius 2 subgraphs. This result quantifies the extent to which triangle-dense graphs resemble unions of cliques. We also show that our algorithm recovers planted clusterings in approximation-stable k-median instances.',
	 'authors': u'Rishi Gupta, Tim Roughgarden, C. Seshadhri,',
	 'category': u'Computer Science ',
	 'date': '2013-9-28',
	 'pdflink': u'http://arxiv.org/pdf/1309.7440',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nDecompositions of Triangle-Dense Graphs',
	 'urllink': u'http://arxiv.org/abs/1309.7440'}
2015-03-24 07:59:09+0000 [xxu46_7] INFO: Crawled 372 pages (at 1 pages/min), scraped 365 items (at 1 items/min)
2015-03-24 08:00:09+0000 [xxu46_7] INFO: Crawled 372 pages (at 0 pages/min), scraped 365 items (at 0 items/min)
2015-03-24 08:00:22+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5964> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 08:00:22+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5964>
	{'abstract': u"This article describes the application of a credible autocoding framework for control systems towards a nonlinear car controller example. The framework generates code, along with guarantees of high level functional properties about the code that can be independently verified. These high-level functional properties not only serves as a certificate of good system behvaior but also can be used to guarantee the absence of runtime errors. In one of our previous works, we have constructed a prototype autocoder with proofs that demonstrates this framework in a fully automatic fashion for linear and quasi-nonlinear controllers. With the nonlinear car example, we propose to further extend the prototype's dataflow annotation language environment with with several new annotation symbols to enable the expression of general predicates and dynamical systems. We demonstrate manually how the new extensions to the prototype autocoder work on the car controller using the output language Matlab. Finally, we discuss the requirements and scalability issues of the automatic analysis and verification of the documented output code.",
	 'authors': u'Timothy Wang, Eric Feron,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5964',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nAutomated, Credible Autocoding of An Unmanned Aggressive Maneuvering Car  Controller',
	 'urllink': u'http://arxiv.org/abs/1308.5964'}
2015-03-24 08:01:09+0000 [xxu46_7] INFO: Crawled 373 pages (at 1 pages/min), scraped 366 items (at 1 items/min)
2015-03-24 08:02:03+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7439> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 08:02:03+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7439>
	{'abstract': u'Recent advances in cellular communication systems resulted in a huge increase in spectrum demand. To meet the requirements of the ever-growing need for spectrum, efficient utilization of the existing resources is of utmost importance. Channel Allocation, has thus become an inevitable research topic in wireless communications. In this paper, we propose an optimal channel allocation scheme, Optimal Hybrid Channel Allocation (OHCA) for an effective allocation of channels. We improvise upon the existing Fixed Channel Allocation (FCA) technique by imparting intelligence to the existing system by employing the multilayer perceptron technique.',
	 'authors': u'K Viswanadh, Dr.G Rama Murthy,',
	 'category': u'Computer Science ',
	 'date': '2013-9-28',
	 'pdflink': u'http://arxiv.org/pdf/1309.7439',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nOptimal Hybrid Channel Allocation:Based On Machine Learning Algorithms',
	 'urllink': u'http://arxiv.org/abs/1309.7439'}
2015-03-24 08:02:09+0000 [xxu46_7] INFO: Crawled 374 pages (at 1 pages/min), scraped 367 items (at 1 items/min)
2015-03-24 08:03:09+0000 [xxu46_7] INFO: Crawled 374 pages (at 0 pages/min), scraped 367 items (at 0 items/min)
2015-03-24 08:04:09+0000 [xxu46_7] INFO: Crawled 374 pages (at 0 pages/min), scraped 367 items (at 0 items/min)
2015-03-24 08:04:48+0000 [xxu46_7] DEBUG: Retrying <GET http://arxiv.org/abs/1308.5952> (failed 1 times): [<twisted.python.failure.Failure <class 'twisted.internet.error.ConnectionLost'>>]
2015-03-24 08:05:09+0000 [xxu46_7] INFO: Crawled 374 pages (at 0 pages/min), scraped 367 items (at 0 items/min)
2015-03-24 08:06:06+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7437> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 08:06:07+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7437>
	{'abstract': u'This paper shows that the Maddah-Ali--Tse (MAT) scheme which establishes the symmetric capacity of two example broadcast channels with strictly causal state information at the transmitter is a simple special case of the Shayevitz--Wigger scheme for the broadcast channel with generalized feedback, which involves block Markov coding, compression, superposition coding, Marton coding, and coded time sharing. Focusing on the class of symmetric broadcast channels with state, we derive an expression for the maximum achievable symmetric rate using the Shayevitz--Wigger scheme. We show that the MAT results can be recovered by evaluating this expression for the special case in which superposition coding and Marton coding are not used. We then introduce a new broadcast channel example that shares many features of the MAT examples. We show that another special case of our maximum symmetric rate expression in which superposition coding is also used attains a higher symmetric rate than the MAT scheme. The symmetric capacity of this example is not known, however.',
	 'authors': u'Hyeji Kim, Yeow-Khiang Chia, Abbas El Gamal,',
	 'category': u'Computer Science ',
	 'date': '2013-9-28',
	 'pdflink': u'http://arxiv.org/pdf/1309.7437',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nA Note on Broadcast Channels with Stale State Information at the  Transmitter',
	 'urllink': u'http://arxiv.org/abs/1309.7437'}
2015-03-24 08:06:09+0000 [xxu46_7] INFO: Crawled 375 pages (at 1 pages/min), scraped 368 items (at 1 items/min)
2015-03-24 08:07:09+0000 [xxu46_7] INFO: Crawled 375 pages (at 0 pages/min), scraped 368 items (at 0 items/min)
2015-03-24 08:08:03+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5938> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 08:08:03+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5938>
	{'abstract': u"Shaping gain is attained in schemes where a shaped subcode is chosen from a larger codebook by a codeword selection process. This includes the popular method of Trellis Shaping (TS), originally proposed by Forney for average power reduction. The decoding process of such schemes is mismatched, since it is aware of only the large codebook. This study models such schemes by a random code construction and derives achievable bounds on the transmission rate under matched and mismatched decoding. For matched decoding the bound is obtained using a modified asymptotic equipartition property (AEP) theorem derived to suit this particular code construction. For mismatched decoding, relying on the large codebook performance is generally wrong, since the performance of the non-typical codewords within the large codebook may differ substantially from the typical ones. Hence, we present two novel lower bounds on the capacity under mismatched decoding. The first is based upon Gallager's random exponent, whereas the second on a modified version of the joint-typicality decoder.",
	 'authors': u'Stella Achtenberg, Dan Raphaeli,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5938',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nTheoretic Shaping Bounds for Single Letter Constraints and Mismatched  Decoding',
	 'urllink': u'http://arxiv.org/abs/1308.5938'}
2015-03-24 08:08:09+0000 [xxu46_7] INFO: Crawled 376 pages (at 1 pages/min), scraped 369 items (at 1 items/min)
2015-03-24 08:09:09+0000 [xxu46_7] INFO: Crawled 376 pages (at 0 pages/min), scraped 369 items (at 0 items/min)
2015-03-24 08:09:56+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7434> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 08:09:56+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7434>
	{'abstract': u'This paper proposes a new approach for face verification, where a pair of images needs to be classified as belonging to the same person or not. This problem is relatively new and not well-explored in the literature. Current methods mostly adopt techniques borrowed from face recognition, and process each of the images in the pair independently, which is counter intuitive. In contrast, we propose to extract cross-image features, i.e. features across the pair of images, which, as we demonstrate, is more discriminative to the similarity and the dissimilarity of faces. Our features are derived from the popular Haar-like features, however, extended to handle the face verification problem instead of face detection. We collect a large bank of cross-image features using filters of different sizes, locations, and orientations. Consequently, we use AdaBoost to select and weight the most discriminative features. We carried out extensive experiments on the proposed ideas using three standard face verification datasets, and obtained promising results outperforming state-of-the-art.',
	 'authors': u'Dong Zhang, Omar Oreifej, Mubarak Shah,',
	 'category': u'Computer Science ',
	 'date': '2013-9-28',
	 'pdflink': u'http://arxiv.org/pdf/1309.7434',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nFace Verification Using Boosted Cross-Image Features',
	 'urllink': u'http://arxiv.org/abs/1309.7434'}
2015-03-24 08:10:09+0000 [xxu46_7] INFO: Crawled 377 pages (at 1 pages/min), scraped 370 items (at 1 items/min)
2015-03-24 08:11:09+0000 [xxu46_7] INFO: Crawled 377 pages (at 0 pages/min), scraped 370 items (at 0 items/min)
2015-03-24 08:11:47+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5937> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 08:11:47+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5937>
	{'abstract': u'The performance of a business is chiefly determined by the business model adopted and its environment of operation. This paper emphasizes on the integration of Web 2.0 services like social networking to your existing business, which helps in the progressive sustainability of the business organization. The usage of Web 2.0 tools, such as Wikipedia, blogs and social networking services such as Facebook, LinkedIn, Orkut by individuals in all societies, has been pervasive and very successful in proliferating their use at the professional or business levels. This paper puts forth the discussion which helps in better understanding of what social networking encompasses for present day business. It also aims to educate business decision makers about the benefits and risks associated in incorporating business model with social networking. Thus, the paper focuses on the implementation of social networking platforms in business operations and discusses the different attributes of business performance and gives an overview in choosing a social networking platform for its business purposes.',
	 'authors': u'Abhinov Balagoni, Vinay Kumar Chavala,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5937',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nA Multilayered Approach to Estimate Business Performance',
	 'urllink': u'http://arxiv.org/abs/1308.5937'}
2015-03-24 08:12:09+0000 [xxu46_7] INFO: Crawled 378 pages (at 1 pages/min), scraped 371 items (at 1 items/min)
2015-03-24 08:13:09+0000 [xxu46_7] INFO: Crawled 378 pages (at 0 pages/min), scraped 371 items (at 0 items/min)
2015-03-24 08:13:24+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7430> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 08:13:24+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7430>
	{'abstract': u'In this paper, the problem of pilot beam pattern design for channel estimation in massive multiple-input multiple-output systems with a large number of transmit antennas at the base station is considered, and a new algorithm for pilot beam pattern design for optimal channel estimation is proposed under the assumption that the channel is a stationary Gauss-Markov random process. The proposed algorithm designs the pilot beam pattern sequentially by exploiting the properties of Kalman filtering and the associated prediction error covariance matrices and also the channel statistics such as spatial and temporal channel correlation. The resulting design generates a sequentially-optimal sequence of pilot beam patterns with low complexity for a given set of system parameters. Numerical results show the effectiveness of the proposed algorithm.',
	 'authors': u'Song Noh, Michael D. Zoltowski, Youngchul Sung, David J. Love,',
	 'category': u'Computer Science ',
	 'date': '2013-9-28',
	 'pdflink': u'http://arxiv.org/pdf/1309.7430',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nPilot Beam Pattern Design for Channel Estimation in Massive MIMO Systems',
	 'urllink': u'http://arxiv.org/abs/1309.7430'}
2015-03-24 08:14:09+0000 [xxu46_7] INFO: Crawled 379 pages (at 1 pages/min), scraped 372 items (at 1 items/min)
2015-03-24 08:15:09+0000 [xxu46_7] INFO: Crawled 379 pages (at 0 pages/min), scraped 372 items (at 0 items/min)
2015-03-24 08:15:10+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5933> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 08:15:10+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5933>
	{'abstract': u'This paper presents a proposed model for database replication model in private cloud availability regions, which is an enhancement of the SQL Server AlwaysOn Layers of Protection Model presents by Microsoft in 2012. The enhancement concentrates in the database replication for private cloud availability regions through the use of primary and secondary servers. The processes of proposed model during the client send Write/Read Request to the server, in synchronous and semi synchronous replication level has been described in details also the processes of proposed model when the client send Write/Read Request to the Primary Server presented in details. All the types of automatic failover situations are presented in this thesis. Using the proposed models will increase the performance because each one of the secondary servers will open for Read / Write and allow the clients to connect to the nearby secondary and less loading on each server. Keywords: Availability Regions, Cloud Computing, Database Replication, SQL Server AlwaysOn, Synchronization.',
	 'authors': u"Ala'a Atallah Al-Mughrabi, Hussein Owaied,",
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5933',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nFramework Model for Database Replication within the Availability Zones',
	 'urllink': u'http://arxiv.org/abs/1308.5933'}
2015-03-24 08:16:09+0000 [xxu46_7] INFO: Crawled 380 pages (at 1 pages/min), scraped 373 items (at 1 items/min)
2015-03-24 08:17:04+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7429> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 08:17:04+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7429>
	{'abstract': u'Distributed storage systems with replication are well known for storing large amount of data. A large number of replication is done in order to provide reliability. This makes the system expensive. Various methods have been proposed over time to reduce the degree of replication and yet provide same level of reliability. One recently suggested scheme is of Regenerating codes, where a file is divided in to parts which are then processed by a coding mechanism and network coding to provide large number of parts. These are stored at various nodes with more than one part at each node. These codes can generate whole file and can repair a failed node by contacting some out of total existing nodes. This property ensures reliability in case of node failure and uses clever replication. This also optimizes bandwidth usage. In a practical scenario, the original file will be read and updated many times. With every update, we will have to update the data stored at many nodes. Handling multiple requests at the same time will bring a lot of complexity. Reading and writing or multiple writing on the same data at the same time should also be prevented. In this paper, we propose an algorithm that manages and executes all the requests from the users which reduces the update complexity. We also try to keep an adequate amount of availability at the same time. We use a voting based mechanism and form read, write and repair quorums. We have also done probabilistic analysis of regenerating codes.',
	 'authors': u'Mit Sheth, Krishna Gopal Benerjee, Manish K. Gupta,',
	 'category': u'Computer Science ',
	 'date': '2013-9-28',
	 'pdflink': u'http://arxiv.org/pdf/1309.7429',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nQuorum Sensing for Regenerating Codes in Distributed Storage',
	 'urllink': u'http://arxiv.org/abs/1309.7429'}
2015-03-24 08:17:09+0000 [xxu46_7] INFO: Crawled 381 pages (at 1 pages/min), scraped 374 items (at 1 items/min)
2015-03-24 08:18:09+0000 [xxu46_7] INFO: Crawled 381 pages (at 0 pages/min), scraped 374 items (at 0 items/min)
2015-03-24 08:19:03+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5915> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 08:19:03+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5915>
	{'abstract': u'The celebrated Perron--Frobenius (PF) theorem is stated for irreducible nonnegative square matrices, and provides a simple characterization of their eigenvectors and eigenvalues. The importance of this theorem stems from the fact that eigenvalue problems on such matrices arise in many fields of science and engineering, including dynamical systems theory, economics, statistics and optimization. However, many real-life scenarios give rise to nonsquare matrices. A natural question is whether the PF Theorem (along with its applications) can be generalized to a nonsquare setting. Our paper provides a generalization of the PF Theorem to nonsquare matrices. The extension can be interpreted as representing client-server systems with additional degrees of freedom, where each client may choose between multiple servers that can cooperate in serving it (while potentially interfering with other clients). This formulation is motivated by applications to power control in wireless networks, economics and others, all of which extend known examples for the use of the original PF Theorem. We show that the option of cooperation between servers does not improve the situation, in the sense that in the optimal solution no cooperation is needed, and only one server needs to serve each client. Hence, the additional power of having several potential servers per client translates into emph the best single server and not into emph the load between the servers in some way, as one might have expected. The two main contributions of the paper are (i) a generalized PF Theorem that characterizes the optimal solution for a non-convex nonsquare problem, and (ii) an algorithm for finding the optimal solution in polynomial time.',
	 'authors': u'Chen Avin, Michael Borokhovich, Yoram Haddad, Erez Kantor, Zvi Lotker, Merav Parter, David Peleg,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5915',
	 'subjects': u'Numerical Analysis (cs.NA)',
	 'title': u'\nGeneralized Perron--Frobenius Theorem for Nonsquare Matrices',
	 'urllink': u'http://arxiv.org/abs/1308.5915'}
2015-03-24 08:19:09+0000 [xxu46_7] INFO: Crawled 382 pages (at 1 pages/min), scraped 375 items (at 1 items/min)
2015-03-24 08:20:09+0000 [xxu46_7] INFO: Crawled 382 pages (at 0 pages/min), scraped 375 items (at 0 items/min)
2015-03-24 08:21:00+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7423> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 08:21:00+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7423>
	{'abstract': u'Differentially 4-uniform permutations on with high nonlinearity are often chosen as Substitution boxes in both block and stream ciphers. Recently, Qu et al. introduced a class of functions, which are called preferred functions, to construct a lot of infinite families of such permutations cite. In this paper, we propose a particular type of Boolean functions to characterize the preferred functions. On the one hand, such Boolean functions can be determined by solving linear equations, and they give rise to a huge number of differentially 4-uniform permutations over . Hence they may provide more choices for the design of Substitution boxes. On the other hand, by investigating the number of these Boolean functions, we show that the number of CCZ-inequivalent differentially 4-uniform permutations over grows exponentially when increases, which gives a positive answer to an open problem proposed in cite.',
	 'authors': u'Longjiang Qu, Yin Tan, Chao Li, Guang Gong,',
	 'category': u'Computer Science ',
	 'date': '2013-9-28',
	 'pdflink': u'http://arxiv.org/pdf/1309.7423',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nMore Constructions of Differentially 4-uniform Permutations on  $\\gf_{2^{2k}}$',
	 'urllink': u'http://arxiv.org/abs/1309.7423'}
2015-03-24 08:21:09+0000 [xxu46_7] INFO: Crawled 383 pages (at 1 pages/min), scraped 376 items (at 1 items/min)
2015-03-24 08:22:09+0000 [xxu46_7] INFO: Crawled 383 pages (at 0 pages/min), scraped 376 items (at 0 items/min)
2015-03-24 08:22:20+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5906> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 08:22:20+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5906>
	{'abstract': u'The limits of TDF (time, dose, and fractionation) and linear quadratic models have been known for a long time. Medical physicists and physicians are required to provide fast and reliable interpretations regarding the delivered doses or any future prescriptions relating to treatment changes. We therefore propose a calculation interface under the GNU license to be used for equivalent doses, biological doses, and normal tumor complication probability (Lyman model). The methodology used draws from several sources: the linear-quadratic-linear model of Astrahan, the repopulation effects of Dale, and the prediction of multi-fractionated treatments of Thames. The results are obtained from an algorithm that minimizes an ad-hoc cost function, and then compared to the equivalent dose computed using standard calculators in seven French radiotherapy centers.',
	 'authors': u'Cyril Voyant, Daniel Julian, Rudy Roustit, Katia Biffi, Celine Lantieri Marcovici,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5906',
	 'subjects': u'Computational Engineering, Finance, and Science (cs.CE)',
	 'title': u'\nBiological effects and equivalent doses in radiotherapy: a software  solution',
	 'urllink': u'http://arxiv.org/abs/1308.5906'}
2015-03-24 08:23:09+0000 [xxu46_7] INFO: Crawled 384 pages (at 1 pages/min), scraped 377 items (at 1 items/min)
2015-03-24 08:24:02+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7393> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 08:24:02+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7393>
	{'abstract': u'Similarity search is an important function in many applications, which usually focuses on measuring the similarity between objects with the same type. However, in many scenarios, we need to measure the relatedness between objects with different types. With the surge of study on heterogeneous networks, the relevance measure on objects with different types becomes increasingly important. In this paper, we study the relevance search problem in heterogeneous networks, where the task is to measure the relatedness of heterogeneous objects (including objects with the same type or different types). A novel measure HeteSim is proposed, which has the following attributes: (1) a uniform measure: it can measure the relatedness of objects with the same or different types in a uniform framework; (2) a path-constrained measure: the relatedness of object pairs are defined based on the search path that connect two objects through following a sequence of node types; (3) a semi-metric measure: HeteSim has some good properties (e.g., self-maximum and symmetric), that are crucial to many data mining tasks. Moreover, we analyze the computation characteristics of HeteSim and propose the corresponding quick computation strategies. Empirical studies show that HeteSim can effectively and efficiently evaluate the relatedness of heterogeneous objects.',
	 'authors': u'Chuan Shi, Xiangnan Kong, Yue Huang, Philip S. Yu, Bin Wu,',
	 'category': u'Computer Science ',
	 'date': '2013-9-28',
	 'pdflink': u'http://arxiv.org/pdf/1309.7393',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nHeteSim: A General Framework for Relevance Measure in Heterogeneous  Networks',
	 'urllink': u'http://arxiv.org/abs/1309.7393'}
2015-03-24 08:24:09+0000 [xxu46_7] INFO: Crawled 385 pages (at 1 pages/min), scraped 378 items (at 1 items/min)
2015-03-24 08:25:09+0000 [xxu46_7] INFO: Crawled 385 pages (at 0 pages/min), scraped 378 items (at 0 items/min)
2015-03-24 08:25:20+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5896> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 08:25:20+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5896>
	{'abstract': u'This volume contains the proceedings of the Ninth Workshop on Fixed Points in Computer Science which took place on the September 1st, 2013 in Torino, Italy as a CSL-affiliated workshop. Past workshops have been held in Brno (1998, MFCS/CSL workshop), Paris (2000, LC workshop), Florence (2001, PLI workshop), Copenhagen (2002, LICS (FLoC) workshop), Warsaw (2003, ETAPS workshop), Coimbra (2009, CSL workshop), Brno (2010, MFCS-CSL workshop), Tallinn (2012, CSL workshop). Fixed points play a fundamental role in several areas of computer science. They are used to justify (co)recursive definitions and associated reasoning techniques. The construction and properties of fixed points have been investigated in many different settings such as: design and implementation of programming languages, logics, verification, databases. The aim of this workshop is to provide a forum for researchers to present their results to those members of the computer science and logic communities who study or apply the theory of fixed points.',
	 'authors': u'David Baelde, Arnaud Carayol,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/html/1308.5896',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nProceedings Workshop on Fixed Points in Computer Science',
	 'urllink': u'http://arxiv.org/abs/1308.5896'}
2015-03-24 08:26:09+0000 [xxu46_7] INFO: Crawled 386 pages (at 1 pages/min), scraped 379 items (at 1 items/min)
2015-03-24 08:27:09+0000 [xxu46_7] INFO: Crawled 386 pages (at 0 pages/min), scraped 379 items (at 0 items/min)
2015-03-24 08:27:15+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7391> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 08:27:15+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7391>
	{'abstract': u"Constructionism is a learning theory that states that we learn more when we construct tangible objects. In the process of building and presenting our work, we make concrete the abstract mental models we've formed, see where they breakdown through the feedback we receive, and revise the models accordingly. Computer programming has long been taught under a constructionist approach using sensory-rich contexts like robots, media, and Logo-style environments. Now, with affordable 3-D printers in the hands of consumers, we have a new medium in which learners may realize their computational ideas. In this demonstration, we share a mobile development environment named Madeup, which empowers its users to navigate 3-D space using a Logo-like imperative and functional language. Every stop in space becomes a vertex in a 3-D model. The generated models may be exported or uploaded to a 3-D printing service.",
	 'authors': u'Chris Johnson,',
	 'category': u'Computer Science ',
	 'date': '2013-9-27',
	 'pdflink': u'http://arxiv.org/pdf/1309.7391',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nMadeup: A Mobile Development Environment for Programming 3-D Models',
	 'urllink': u'http://arxiv.org/abs/1309.7391'}
2015-03-24 08:28:09+0000 [xxu46_7] INFO: Crawled 387 pages (at 1 pages/min), scraped 380 items (at 1 items/min)
2015-03-24 08:28:32+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5885> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 08:28:32+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5885>
	{'abstract': u'Let be an odd integer and be an odd prime. % with , where is an odd integer. In this paper, many classes of three-weight cyclic codes over are presented via an examination of the condition for the cyclic codes and , which have parity-check polynomials and respectively, to have the same weight distribution, where is the minimal polynomial of over for a primitive element of . %For , the duals of five classes of the proposed cyclic codes are optimal in the sense that they meet certain bounds on linear codes. Furthermore, for and positive integers such that there exist integers with and satisfying , the value distributions of the two exponential sums and where , are settled. As an application, the value distribution of is utilized to investigate the weight distribution of the cyclic codes with parity-check polynomial . In the case of and even satisfying the above condition, the duals of the cyclic codes have the optimal minimum distance.',
	 'authors': u'Chunlei Li, Nian Li, Tor Helleseth, Cunsheng Ding,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5885',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOn the weight distributions of several classes of cyclic codes from APN  monomials',
	 'urllink': u'http://arxiv.org/abs/1308.5885'}
2015-03-24 08:29:09+0000 [xxu46_7] INFO: Crawled 388 pages (at 1 pages/min), scraped 381 items (at 1 items/min)
2015-03-24 08:30:09+0000 [xxu46_7] INFO: Crawled 388 pages (at 0 pages/min), scraped 381 items (at 0 items/min)
2015-03-24 08:30:30+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7367> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 08:30:30+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7367>
	{'abstract': u'This paper studies online shortest path routing over dynamic multi-hop networks. Link costs or delays are time-varying and modelled by independent and identically distributed random processes, whose parameters are initially unknown. The parameters, and hence the optimal path, can only be estimated by routing packets through the network and observing the realized delays. Our aim is to find a routing policy that minimizes the regret (the cumulative delay difference) between the path chosen by the policy and the unknown optimal path. We formulate the problem as a combinatorial bandit optimization problem and consider several scenarios that differ in where routing decisions are made and in the information available when making the decision. For each scenario, we derive the tight asymptotic lower bound on the regret that has to be satisfied by any online routing policy. These bounds help us to understand the performance improvements we can expect when (i) taking routing decisions at each hop rather than at the source only, and (ii) observing per-link costs rather than aggregate path costs. In particular, we show that (i) is of no use while (ii) can have a spectacular impact. Efficient algorithms are proposed and evaluated against the state-of-the art.',
	 'authors': u'Zhenhua Zou, Alexandre Proutiere, Mikael Johansson,',
	 'category': u'Computer Science ',
	 'date': '2013-9-27',
	 'pdflink': u'http://arxiv.org/pdf/1309.7367',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nOnline Shortest Path Routing: The Value of Information',
	 'urllink': u'http://arxiv.org/abs/1309.7367'}
2015-03-24 08:31:09+0000 [xxu46_7] INFO: Crawled 389 pages (at 1 pages/min), scraped 382 items (at 1 items/min)
2015-03-24 08:32:08+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5876> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 08:32:08+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5876>
	{'abstract': u'An approach for effective implementation of greedy selection methodologies, to approximate an image partitioned into blocks, is proposed. The method is specially designed for approximating partitions on a transformed image. It evolves by selecting, at each iteration step, i) the elements for approximating each of the blocks partitioning the image and ii) the hierarchized sequence in which the blocks are approximated to reach the required global condition on sparsity.',
	 'authors': u'Laura Rebollo-Neira, Ryszard Maciol, Shabnam Bibi,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5876',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nHierarchized block wise image approximation by greedy pursuit strategies',
	 'urllink': u'http://arxiv.org/abs/1308.5876'}
2015-03-24 08:32:09+0000 [xxu46_7] INFO: Crawled 390 pages (at 1 pages/min), scraped 383 items (at 1 items/min)
2015-03-24 08:33:09+0000 [xxu46_7] INFO: Crawled 390 pages (at 0 pages/min), scraped 383 items (at 0 items/min)
2015-03-24 08:33:56+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7366> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 08:33:56+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7366>
	{'abstract': u"The security of any cryptosystem relies on the secrecy of the system's secret keys. Yet, recent experimental work demonstrates that tens of thousands of devices on the Internet use RSA and DSA secrets drawn from a small pool of candidate values. As a result, an adversary can derive the device's secret keys without breaking the underlying cryptosystem. We introduce a new threat model, under which there is a systemic solution to such randomness flaws. In our model, when a device generates a cryptographic key, it incorporates some random values from an entropy authority into its cryptographic secrets and then proves to the authority, using zero-knowledge-proof techniques, that it performed this operation correctly. By presenting an entropy-authority-signed public-key certificate to a third party (like a certificate authority or SSH client), the device can demonstrate that its public key incorporates randomness from the authority and is therefore drawn from a large pool of candidate values. Where possible, our protocol protects against eavesdroppers, entropy authority misbehavior, and devices attempting to discredit the entropy authority. To demonstrate the practicality of our protocol, we have implemented and evaluated its performance on a commodity wireless home router. When running on a home router, our protocol incurs a 2.1x slowdown over conventional RSA key generation and it incurs a 4.4x slowdown over conventional EC-DSA key generation.",
	 'authors': u'Henry Corrigan-Gibbs, Wendy Mu, Dan Boneh, Bryan Ford,',
	 'category': u'Computer Science ',
	 'date': '2013-9-27',
	 'pdflink': u'http://arxiv.org/pdf/1309.7366',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nEnsuring High-Quality Randomness in Cryptographic Key Generation',
	 'urllink': u'http://arxiv.org/abs/1309.7366'}
2015-03-24 08:34:09+0000 [xxu46_7] INFO: Crawled 391 pages (at 1 pages/min), scraped 384 items (at 1 items/min)
2015-03-24 08:35:09+0000 [xxu46_7] INFO: Crawled 391 pages (at 0 pages/min), scraped 384 items (at 0 items/min)
2015-03-24 08:35:40+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5865> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 08:35:40+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5865>
	{'abstract': u'Graph sampling is a technique to pick a subset of vertices and/ or edges from original graph. It has a wide spectrum of applications, e.g. survey hidden population in sociology [54], visualize social graph [29], scale down Internet AS graph [27], graph sparsification [8], etc. In some scenarios, the whole graph is known and the purpose of sampling is to obtain a smaller graph. In other scenarios, the graph is unknown and sampling is regarded as a way to explore the graph. Commonly used techniques are Vertex Sampling, Edge Sampling and Traversal Based Sampling. We provide a taxonomy of different graph sampling objectives and graph sampling approaches. The relations between these approaches are formally argued and a general framework to bridge theoretical analysis and practical implementation is provided. Although being smaller in size, sampled graphs may be similar to original graphs in some way. We are particularly interested in what graph properties are preserved given a sampling procedure. If some properties are preserved, we can estimate them on the sampled graphs, which gives a way to construct efficient estimators. If one algorithm relies on the perserved properties, we can expect that it gives similar output on original and sampled graphs. This leads to a systematic way to accelerate a class of graph algorithms. In this survey, we discuss both classical text-book type properties and some advanced properties. The landscape is tabularized and we see a lot of missing works in this field. Some theoretical studies are collected in this survey and simple extensions are made. Most previous numerical evaluation works come in an ad hoc fashion, i.e. evaluate different type of graphs, different set of properties, and different sampling algorithms. A systematical and neutral evaluation is needed to shed light on further graph sampling studies.',
	 'authors': u'Pili Hu, Wing Cheong Lau,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5865',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nA Survey and Taxonomy of Graph Sampling',
	 'urllink': u'http://arxiv.org/abs/1308.5865'}
2015-03-24 08:36:09+0000 [xxu46_7] INFO: Crawled 392 pages (at 1 pages/min), scraped 385 items (at 1 items/min)
2015-03-24 08:36:57+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7341> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 08:36:57+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7341>
	{'abstract': u'In collaborative agile ontology development projects support for modular reuse of ontologies from large existing remote repositories, ontology project life cycle management, and transitive dependency management are important needs. The Apache Maven approach has proven its success in distributed collaborative Software Engineering by its widespread adoption. The contribution of this paper is a new design artifact called OntoMaven. OntoMaven adopts the Maven-based development methodology and adapts its concepts to knowledge engineering for Maven-based ontology development and management of ontology artifacts in distributed ontology repositories.',
	 'authors': u'Adrian Paschke,',
	 'category': u'Computer Science ',
	 'date': '2013-9-27',
	 'pdflink': u'http://arxiv.org/pdf/1309.7341',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nOntoMaven: Maven-based Ontology Development and Management of  Distributed Ontology Repositories',
	 'urllink': u'http://arxiv.org/abs/1309.7341'}
2015-03-24 08:37:09+0000 [xxu46_7] INFO: Crawled 393 pages (at 1 pages/min), scraped 386 items (at 1 items/min)
2015-03-24 08:38:09+0000 [xxu46_7] INFO: Crawled 393 pages (at 0 pages/min), scraped 386 items (at 0 items/min)
2015-03-24 08:38:38+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5858> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 08:38:38+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5858>
	{'abstract': u'This paper includes notes to accompany a reading of Thue\'s 1914 paper "Probleme uber Veranderungen von Zeichenreihen nach gegebenen Reglen", along with a translation of that paper. Thue\'s 1914 paper is mainly famous for proving an early example of an undecidable problem, cited prominently by Post. However, Post\'s paper principally makes use of the definition of Thue systems, described on the first two pages of Thue\'s paper, and does not depend on the more specific results in the remainder of Thue\'s paper. A closer study of the remaining parts of that paper highlight a number of important themes in the history of computing: the transition from algebra to formal language theory, the analysis of the "computational power" (in a pre-1936 sense) of rules, and the development of algorithms to generate rule-sets.',
	 'authors': u'James F. Power,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5858',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u"\nThue's 1914 paper: a translation",
	 'urllink': u'http://arxiv.org/abs/1308.5858'}
2015-03-24 08:39:09+0000 [xxu46_7] INFO: Crawled 394 pages (at 1 pages/min), scraped 387 items (at 1 items/min)
2015-03-24 08:40:09+0000 [xxu46_7] INFO: Crawled 394 pages (at 0 pages/min), scraped 387 items (at 0 items/min)
2015-03-24 08:40:26+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7340> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 08:40:26+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7340>
	{'abstract': u'Influenza is an acute respiratory illness that occurs virtually every year and results in substantial disease, death and expense. Detection of Influenza in its earliest stage would facilitate timely action that could reduce the spread of the illness. Existing systems such as CDC and EISS which try to collect diagnosis data, are almost entirely manual, resulting in about two-week delays for clinical data acquisition. Twitter, a popular microblogging service, provides us with a perfect source for early-stage flu detection due to its real- time nature. For example, when a flu breaks out, people that get the flu may post related tweets which enables the detection of the flu breakout promptly. In this paper, we investigate the real-time flu detection problem on Twitter data by proposing Flu Markov Network (Flu-MN): a spatio-temporal unsupervised Bayesian algorithm based on a 4 phase Markov Network, trying to identify the flu breakout at the earliest stage. We test our model on real Twitter datasets from the United States along with baselines in multiple applications, such as real-time flu breakout detection, future epidemic phase prediction, or Influenza-like illness (ILI) physician visits. Experimental results show the robustness and effectiveness of our approach. We build up a real time flu reporting system based on the proposed approach, and we are hopeful that it would help government or health organizations in identifying flu outbreaks and facilitating timely actions to decrease unnecessary mortality.',
	 'authors': u'Jiwei Li, Claire Cardie,',
	 'category': u'Computer Science ',
	 'date': '2013-9-27',
	 'pdflink': u'http://arxiv.org/pdf/1309.7340',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nEarly Stage Influenza Detection from Twitter',
	 'urllink': u'http://arxiv.org/abs/1309.7340'}
2015-03-24 08:41:09+0000 [xxu46_7] INFO: Crawled 395 pages (at 1 pages/min), scraped 388 items (at 1 items/min)
2015-03-24 08:41:22+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5847> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 08:41:22+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5847>
	{'abstract': u'The applicability of Virtual Reality for evaluating engineering analysis results is beginning to receive increased appreciation in the last years. The problem many engineers are still facing is how to import their model together with the analysis results in a virtual reality environment for exploration and results validation. In this paper we propose an algorithm for transforming model data and results from finite element analysis (FEA) solving application to a format easily interpretable by a virtual reality application. The algorithm includes also steps for reducing the face-count of the resulting mesh by eliminating faces from the inner part of the model in the cases when only the surfaces of the model is analyzed. We also describe a possibility for simultaneously assessing multiple analysis results relying on multimodal results presentation by stimulating different senses of the operator.',
	 'authors': u'Stoyan Maleshkov, Dimo Chotrov,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5847',
	 'subjects': u'Graphics (cs.GR)',
	 'title': u'\nPost-processing of Engineering Analysis Results for Visualization in VR  Systems',
	 'urllink': u'http://arxiv.org/abs/1308.5847'}
2015-03-24 08:42:09+0000 [xxu46_7] INFO: Crawled 396 pages (at 1 pages/min), scraped 389 items (at 1 items/min)
2015-03-24 08:42:49+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7334> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 08:42:49+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7334>
	{'abstract': u'Orthogonal Frequency Division Multiplexing (OFDM) is a multi-carrier modulation technique which is very much popular in new wireless networks of IEEE standard, digital television, audio broadcasting and 4G mobile communications. The main benefit of OFDM over single-carrier schemes is its ability to cope with severe channel conditions without complex equalization filters. It has improved the quality of long-distance communication by eliminating InterSymbol Interference (ISI) and improving Signal-to-Noise ratio (SNR). The main drawbacks of OFDM are its high peak to average power ratio and its sensitivity to phase noise and frequency offset. This paper gives an overview of OFDM, its applications in various systems such as IEEE 802.11a, Digital Audio Broadcasting (DAB) and Digital Broadcast Services to Handheld Devices (DVB-H) along with its advantages and disadvantages.',
	 'authors': u'Ankit Chadha, Neha Satam, Beena Ballal,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.7334',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nOrthogonal Frequency Division Multiplexing and its Applications',
	 'urllink': u'http://arxiv.org/abs/1309.7334'}
2015-03-24 08:43:09+0000 [xxu46_7] INFO: Crawled 397 pages (at 1 pages/min), scraped 390 items (at 1 items/min)
2015-03-24 08:44:09+0000 [xxu46_7] INFO: Crawled 397 pages (at 0 pages/min), scraped 390 items (at 0 items/min)
2015-03-24 08:44:27+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5843> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 08:44:27+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5843>
	{'abstract': u'A flexible, scalable and affordable virtual reality software system architecture is proposed. This solution can be easily implemented on different hardware configurations: on a single computer or on a computer cluster. The architecture is aimed to be integrated in the workflow for solving engineering tasks and oriented towards presenting implicit object properties through multiple sensorial channels (visual, audio and haptic). Implicit properties represent hidden object features (i.e. magnetization, radiation, humidity, toxicity, etc.) which cannot be perceived by the observer through his or her senses but require specialized equipment in order to expand the sensory ability of the observer. Our approach extends the underlying general scene graph structure incorporating additional effects nodes for implicit properties representation.',
	 'authors': u'Stoyan Maleshkov, Dimo Chotrov,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5843',
	 'subjects': u'Graphics (cs.GR)',
	 'title': u'\nAffordable Virtual Reality System Architecture for Representation of  Implicit Object Properties',
	 'urllink': u'http://arxiv.org/abs/1308.5843'}
2015-03-24 08:45:09+0000 [xxu46_7] INFO: Crawled 398 pages (at 1 pages/min), scraped 391 items (at 1 items/min)
2015-03-24 08:45:53+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7321> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 08:45:53+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7321>
	{'abstract': u'In this work, we provide energy-efficient architectural support for floating point accuracy. Our goal is to provide accuracy that is far greater than that provided by the processor\'s hardware floating point unit (FPU). Specifically, for each floating point addition performed, we "recycle" that operation\'s error: the difference between the finite-precision result produced by the hardware and the result that would have been produced by an infinite-precision FPU. We make this error architecturally visible such that it can be used, if desired, by software. Experimental results on physical hardware show that software that exploits architecturally recycled error bits can achieve accuracy comparable to a 2B-bit FPU with performance and energy that are comparable to a B-bit FPU.',
	 'authors': u'Ralph Nathan, Bryan Anthonio, Shih-Lien Lu, Helia Naeimi, Daniel J. Sorin, Xiaobai Sun,',
	 'category': u'Computer Science ',
	 'date': '2013-9-27',
	 'pdflink': u'http://arxiv.org/pdf/1309.7321',
	 'subjects': u'Hardware Architecture (cs.AR)',
	 'title': u'\nRecycled Error Bits: Energy-Efficient Architectural Support for Higher  Precision Floating Point',
	 'urllink': u'http://arxiv.org/abs/1309.7321'}
2015-03-24 08:46:09+0000 [xxu46_7] INFO: Crawled 399 pages (at 1 pages/min), scraped 392 items (at 1 items/min)
2015-03-24 08:47:09+0000 [xxu46_7] INFO: Crawled 399 pages (at 0 pages/min), scraped 392 items (at 0 items/min)
2015-03-24 08:47:52+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5841> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 08:47:52+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5841>
	{'abstract': u'Computer has been incorporated into day to day activities of almost every field of human endeavour, offices to different shops. Therefore many people are now working with computer for longer hours of time. There is no doubt that this incorporation of computer has helped users a lot but it also brings problems to the users. One of the problems is Repetitive Strain Injury (RSI). Five hundred and thirty one (531) questionnaires were personally administered to different categories of people that use computer in various works of life, ranging from banking sector, civil service, educational sector, health sector to private sector. The distribution cut across different professions. A statistical analysis was conducted on the data obtained using frequency distribution, Pearson Correlation and Linear Regression. The result obtained showed that 94.3% of the respondents suffered pain from one or more parts of the body. 86.8% of the respondents suffered from eyestrain, 63.9% suffered from low back pain, 67.4% with wrist pain, 64.7% finger pain while the least suffered pain was foot pain which only 19% responded positively to it. There are significant relationships between duration of computer usage, type of chair used, type and size of monitor used and the incidence of RSI. RSI modeled was formulated through linear regression which showed that a unit change in computer will result in corresponding 1.76 unit increases in RSI and a unit change in ergonomic deficiency will also result in corresponding 0.66 increases in RSI. The existence of RSI was established and it was discovered that the more time spent on the computer system, the more the proximity of having strain or pain in one or more part(s) of the body.',
	 'authors': u'Olatunde Olabiyisi, Yusuff Akingboye, Adebayo Abayomi-Alli, Fred Izilein, Iyiola Adeleke,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5841',
	 'subjects': u'Human-Computer Interaction (cs.HC)',
	 'title': u'\nAn Investigation of the Incidences of Repetitive Strain Injury among  computer Users in Nigeria',
	 'urllink': u'http://arxiv.org/abs/1308.5841'}
2015-03-24 08:48:09+0000 [xxu46_7] INFO: Crawled 400 pages (at 1 pages/min), scraped 393 items (at 1 items/min)
2015-03-24 08:49:09+0000 [xxu46_7] INFO: Crawled 400 pages (at 0 pages/min), scraped 393 items (at 0 items/min)
2015-03-24 08:49:49+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7315> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 08:49:49+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7315>
	{'abstract': u'Many systems for which compressive sensing is used today are dynamical. The common approach is to neglect the dynamics and see the problem as a sequence of independent problems. This approach has two disadvantages. Firstly, the temporal dependency in the state could be used to improve the accuracy of the state estimates. Secondly, having an estimate for the state and its support could be used to reduce the computational load of the subsequent step. In the linear Gaussian setting, compressive sensing was recently combined with the Kalman filter to mitigate above disadvantages. In the nonlinear dynamical case, compressive sensing can not be used and, if the state dimension is high, the particle filter would perform poorly. In this paper we combine one of the most novel developments in compressive sensing, nonlinear compressive sensing, with the particle filter. We show that the marriage of the two is essential and that neither the particle filter or nonlinear compressive sensing alone gives a satisfying solution.',
	 'authors': u'Henrik Ohlsson, Michel Verhaegen, S. Shankar Sastry,',
	 'category': u'Computer Science ',
	 'date': '2013-9-8',
	 'pdflink': u'http://arxiv.org/pdf/1309.7315',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nNonlinear Compressive Particle Filtering',
	 'urllink': u'http://arxiv.org/abs/1309.7315'}
2015-03-24 08:50:09+0000 [xxu46_7] INFO: Crawled 401 pages (at 1 pages/min), scraped 394 items (at 1 items/min)
2015-03-24 08:51:09+0000 [xxu46_7] INFO: Crawled 401 pages (at 0 pages/min), scraped 394 items (at 0 items/min)
2015-03-24 08:51:18+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5835> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 08:51:18+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5835>
	{'abstract': u'The design of distributed mechanisms for interference management is one of the key challenges in emerging wireless small cell networks whose backhaul is capacity limited and heterogeneous (wired, wireless and a mix thereof). In this paper, a novel, backhaul-aware approach to interference management in wireless small cell networks is proposed. The proposed approach enables macrocell user equipments (MUEs) to optimize their uplink performance, by exploiting the presence of neighboring small cell base stations. The problem is formulated as a noncooperative game among the MUEs that seek to optimize their delay-rate tradeoff, given the conditions of both the radio access network and the -- possibly heterogeneous -- backhaul. To solve this game, a novel, distributed learning algorithm is proposed using which the MUEs autonomously choose their optimal uplink transmission strategies, given a limited amount of available information. The convergence of the proposed algorithm is shown and its properties are studied. Simulation results show that, under various types of backhauls, the proposed approach yields significant performance gains, in terms of both average throughput and delay for the MUEs, when compared to existing benchmark algorithms.',
	 'authors': u'Sumudu Samarakoon, Mehdi Bennis, Walid Saad, Matti Latva-aho,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5835',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nBackhaul-Aware Interference Management in the Uplink of Wireless Small  Cell Networks',
	 'urllink': u'http://arxiv.org/abs/1308.5835'}
2015-03-24 08:52:09+0000 [xxu46_7] INFO: Crawled 402 pages (at 1 pages/min), scraped 395 items (at 1 items/min)
2015-03-24 08:53:00+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7313> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 08:53:00+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7313>
	{'abstract': u"In this paper, we propose a unsupervised framework to reconstruct a person's life history by creating a chronological list for (PIE) of individuals based on the tweets they published. By analyzing individual tweet collections, we find that what are suitable for inclusion in the personal timeline should be tweets talking about personal (as opposed to public) and time-specific (as opposed to time-general) topics. To further extract these types of topics, we introduce a non-parametric multi-level Dirichlet Process model to recognize four types of tweets: personal time-specific (PersonTS), personal time-general (PersonTG), public time-specific (PublicTS) and public time-general (PublicTG) topics, which, in turn, are used for further personal event extraction and timeline generation. To the best of our knowledge, this is the first work focused on the generation of timeline for individuals from twitter data. For evaluation, we have built a new golden standard Timelines based on Twitter and Wikipedia that contain PIE related events from 20 and 20 . Experiments on real Twitter data quantitatively demonstrate the effectiveness of our approach.",
	 'authors': u'Jiwei Li, Claire Cardie,',
	 'category': u'Computer Science ',
	 'date': '2013-9-27',
	 'pdflink': u'http://arxiv.org/pdf/1309.7313',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nTimeline Generation: Tracking individuals on Twitter',
	 'urllink': u'http://arxiv.org/abs/1309.7313'}
2015-03-24 08:53:09+0000 [xxu46_7] INFO: Crawled 403 pages (at 1 pages/min), scraped 396 items (at 1 items/min)
2015-03-24 08:54:09+0000 [xxu46_7] INFO: Crawled 403 pages (at 0 pages/min), scraped 396 items (at 0 items/min)
2015-03-24 08:54:32+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5820> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 08:54:32+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5820>
	{'abstract': u'This study proposes a feedback linearisation based on the back-stepping method with simple implementation and unique design process to design a non-linear controller with a goal of improving both steady-state and transient stability. The proposed method is designed based on a standard third-order model of synchronous generator. A comparison based on simulation is then performed between the proposed method and two conventional control schemes (i.e. conventional power system stabiliser and direct feedback linearisation). The simulation results demonstrate that fast response, robustness, damping, steady-state and transient stability as well as voltage regulation are all achieved satisfactorily.',
	 'authors': u'E. Babaei, S.A.KH. Mozaffari Niapour, Mehrdad Tabarraie,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5820',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nDesign of a non-linear power system stabiliser using the concept of the  feedback linearisation based on the back-stepping technique',
	 'urllink': u'http://arxiv.org/abs/1308.5820'}
2015-03-24 08:55:09+0000 [xxu46_7] INFO: Crawled 404 pages (at 1 pages/min), scraped 397 items (at 1 items/min)
2015-03-24 08:56:09+0000 [xxu46_7] INFO: Crawled 404 pages (at 0 pages/min), scraped 397 items (at 0 items/min)
2015-03-24 08:56:15+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7312> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 08:56:15+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7312>
	{'abstract': u'A balanced speech corpus is the basic need for any speech processing task. In this report we describe our effort on development of Assamese speech corpus. We mainly focused on some issues and challenges faced during development of the corpus. Being a less computationally aware language, this is the first effort to develop speech corpus for Assamese. As corpus development is an ongoing process, in this paper we report only the initial task.',
	 'authors': u'Himangshu Sarma, Navanath Saharia, Utpal Sharma, Smriti Kumar Sinha, Mancha Jyoti Malakar,',
	 'category': u'Computer Science ',
	 'date': '2013-9-27',
	 'pdflink': u'http://arxiv.org/pdf/1309.7312',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nDevelopment and Transcription of Assamese Speech Corpus',
	 'urllink': u'http://arxiv.org/abs/1309.7312'}
2015-03-24 08:57:09+0000 [xxu46_7] INFO: Crawled 405 pages (at 1 pages/min), scraped 398 items (at 1 items/min)
2015-03-24 08:57:56+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5811> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 08:57:56+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5811>
	{'abstract': u'We report the current status of our research on the clean-slate design of next-generation optical access (NGOA). We have been studying candidate architectures with a major focus on their elasticity to user demands, energy efficiency, and support of better Quality of Experience (QoE). One of the major challenges in this study is to establish a comparative analysis framework where we can assess the performances of candidate architectures in an objective and quantifiable way. In this paper we describe our efforts to meet this challenge: (1) the development of a new comparison framework based on integrated QoE and statistical hypothesis testing and (2) the implementation of a virtual test bed capturing important aspects from physical layer to application layer to end-user behaviour governing traffic generation. The comparison framework and the virtual test bed will provide researchers a sound basis and useful tools for comparative analysis in the clean-slate design of NGOA.',
	 'authors': u'Kyeong Soo Kim, Karin Ennser, Yogesh K. Dwivedi,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5811',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nClean-Slate Design of Next-Generation Optical Access',
	 'urllink': u'http://arxiv.org/abs/1308.5811'}
2015-03-24 08:58:09+0000 [xxu46_7] INFO: Crawled 406 pages (at 1 pages/min), scraped 399 items (at 1 items/min)
2015-03-24 08:58:53+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7289> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 08:58:53+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7289>
	{'abstract': u'Social networks are an important infrastructure for information, viruses and innovations propagation. Since users behavior has influenced by other users activity, some groups of people would be made regard to similarity of users interests. On the other hand, dealing with many events in real worlds, can be justified in social networks; spreading disease is one instance of them. People manner and infection severity are more important parameters in dissemination of diseases. Both of these reasons derive, whether the diffusion leads to an epidemic or not. SIRS is a hybrid model of SIR and SIS disease models to spread contamination. A person in this model can be returned to susceptible state after it removed. According to communities which are established on the social network, we use the compartmental type of SIRS model. During this paper, a general compartmental information diffusion model would be proposed and extracted some of the beneficial parameters to analyze our model. To adapt our model to realistic behaviors, we use Markovian model, which would be helpful to create a stochastic manner of the proposed model. In the case of random model, we can calculate probabilities of transaction between states and predicting value of each state. The comparison between two mode of the model shows that, the prediction of population would be verified in each state.',
	 'authors': u'Hamidreza Sotoodeh, Farshad Safaei, Arghavan Sanei, Elahe Daei,',
	 'category': u'Computer Science ',
	 'date': '2013-9-27',
	 'pdflink': u'http://arxiv.org/pdf/1309.7289',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nA General Stochastic Information Diffusion Model in Social Networks  based on Epidemic Diseases',
	 'urllink': u'http://arxiv.org/abs/1309.7289'}
2015-03-24 08:59:09+0000 [xxu46_7] INFO: Crawled 407 pages (at 1 pages/min), scraped 400 items (at 1 items/min)
2015-03-24 09:00:09+0000 [xxu46_7] INFO: Crawled 407 pages (at 0 pages/min), scraped 400 items (at 0 items/min)
2015-03-24 09:00:33+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5809> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 09:00:33+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5809>
	{'abstract': u'Several practical multi-user multi-carrier communication systems are characterized by a multi-carrier interference channel system model where the interference is treated as noise. For these systems, spectrum optimization is a promising means to mitigate interference. This however corresponds to a challenging nonconvex optimization problem. Existing iterative convex approximation (ICA) methods consist in solving a series of improving convex approximations and are typically implemented in a per-user iterative approach. However they do not take this typical iterative implementation into account in their design. This paper proposes a novel class of iterative approximation methods that focuses explicitly on the per-user iterative implementation, which allows to relax the problem significantly, dropping joint convexity and even convexity requirements for the approximations. A systematic design framework is proposed to construct instances of this novel class, where several new iterative approximation methods are developed with improved per-user convex and nonconvex approximations that are both tighter and simpler to solve (in closed-form). As a result, these novel methods display a much faster convergence speed and require a significantly lower computational cost. Furthermore, a majority of the proposed methods can tackle the issue of getting stuck in bad locally optimal solutions, and hence improve solution quality compared to existing ICA methods.',
	 'authors': u'Paschalis Tsiaflakis, Fran\xe7ois Glineur,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5809',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nSpectrum optimization in multi-user multi-carrier systems with iterative  convex and nonconvex approximation methods',
	 'urllink': u'http://arxiv.org/abs/1308.5809'}
2015-03-24 09:01:09+0000 [xxu46_7] INFO: Crawled 408 pages (at 1 pages/min), scraped 401 items (at 1 items/min)
2015-03-24 09:02:09+0000 [xxu46_7] INFO: Crawled 408 pages (at 0 pages/min), scraped 401 items (at 0 items/min)
2015-03-24 09:02:19+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7288> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 09:02:19+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7288>
	{'abstract': u"The time complexity of the presented in 2013 by the author small universal Petri nets with the pairs of places/transitions numbers (14,42) and (14,29) was estimated as exponential. In the present paper, it is shown, that their slight modification and interpretation as timed Petri nets with multichannel transitions, introduced by the author in 1991, allows obtaining polynomial time complexity. The modification concerns using only inhibitor arcs to control transitions' firing in multiple instances and employing an inverse control flow represented by moving zero. Thus, small universal Petri nets are efficient that justifies their application as models of high performance computations.",
	 'authors': u'Dmitry A. Zaitsev,',
	 'category': u'Computer Science ',
	 'date': '2013-9-27',
	 'pdflink': u'http://arxiv.org/pdf/1309.7288',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nSmall Polynomial Time Universal Petri Nets',
	 'urllink': u'http://arxiv.org/abs/1309.7288'}
2015-03-24 09:03:09+0000 [xxu46_7] INFO: Crawled 409 pages (at 1 pages/min), scraped 402 items (at 1 items/min)
2015-03-24 09:03:54+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5807> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 09:03:54+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5807>
	{'abstract': u'Wireless mesh networks have seen a real progress due of their implementation at a low cost. They present one of Next Generation Networks technologies and can serve as home, companies and universities networks. In this paper, we propose and discuss a new multi-objective model for nodes deployment optimization in Multi-Radio Multi-Channel Wireless Mesh Networks. We exploit the trade-off between network cost and the overall network performance. This optimization problem is solved simultaneously by using a meta-heuristic method that returns a non-dominated set of near optimal solutions. A comparative study was driven to evaluate the efficiency of the proposed model.',
	 'authors': u'Tarik Mountassir Bouchaib Nassereddine, Abdelkrim Haqiq, Samir Bennani,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5807',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nMulti-Objective Particle Swarm Optimization for Facility Location  Problem in Wireless Mesh Networks',
	 'urllink': u'http://arxiv.org/abs/1308.5807'}
2015-03-24 09:04:09+0000 [xxu46_7] INFO: Crawled 410 pages (at 1 pages/min), scraped 403 items (at 1 items/min)
2015-03-24 09:05:09+0000 [xxu46_7] INFO: Crawled 410 pages (at 0 pages/min), scraped 403 items (at 0 items/min)
2015-03-24 09:05:52+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7276> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 09:05:52+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7276>
	{'abstract': u'Human identification has always been a topic that interested researchers around the world. Biometric methods are found to be more effective and much easier for the users than the traditional identification methods like keys, smart cards and passwords. Unlike with the traditional methods, with biometric methods the data acquisition is most of the times passive, which means the users do not take active part in data acquisition. Data acquisition can be performed using cameras, scanners or sensors. Human physiological biometrics such as face, eye and ear are good candidates for uniquely identifying an individual. However, human ear scores over face and eye because of certain advantages it has over face. The most challenging phase in human identification based on ear biometric is the segmentation of the ear image from the captured image which may contain many unwanted details. In this work, PDE based image processing techniques are used to segment out the ear image. Level Set Theory based image processing is employed to obtain the contour of the ear image. A few Level set algorithms are compared for their efficiency in segmenting test ear images.',
	 'authors': u'Bijeesh T. V, Nimmi I. P,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.7276',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nAdopting level set theory based algorithms to segment human ear',
	 'urllink': u'http://arxiv.org/abs/1309.7276'}
2015-03-24 09:06:09+0000 [xxu46_7] INFO: Crawled 411 pages (at 1 pages/min), scraped 404 items (at 1 items/min)
2015-03-24 09:07:09+0000 [xxu46_7] INFO: Crawled 411 pages (at 0 pages/min), scraped 404 items (at 0 items/min)
2015-03-24 09:07:19+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6686> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 09:07:19+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6686>
	{'abstract': u'The software engineering is a relatively new discipline compared to other sciences, since the origins of the term itself dates back to the years 1968 and 1969. At present, the market and the software industry have a significant relevance in several countries of the world; however, although Mexico is immersed in this race, has not even reached the level of success achieved in other countries in this sector. This paper presents an overview of the situation that keeps the practice of software engineering in Mexico, with emphasis on the academic realm. It shows a compilation of scientific research activity carried out in universities, as well as a brief analysis of undergraduate educational programs including the software engineering discipline . At the end, future work to be done is proposed in order to find a point of convergence between academia and industry, and also to support the flourishing of this business which somehow will have a positive impact on the economy of our country.',
	 'authors': u'Reyes Ju\xe1rez-Ram\xedrez, Karen Cort\xe9s Verd\xedn, Beatriz Ang\xe9lica Toscano de la Torre, Hanna Oktaba, Carlos Alberto Fern\xe1ndez-y-Fern\xe1ndez, Brenda Leticia Flores R\xedos, Fabiola Angulo Molina,',
	 'category': u'Computer Science ',
	 'date': '2013-10-24',
	 'pdflink': u'http://arxiv.org/pdf/1310.6686',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nEstado Actual de la Pr\xe1ctica de la Ingenier\xeda de Software en  M\xe9xico',
	 'urllink': u'http://arxiv.org/abs/1310.6686'}
2015-03-24 09:08:09+0000 [xxu46_7] INFO: Crawled 412 pages (at 1 pages/min), scraped 405 items (at 1 items/min)
2015-03-24 09:09:09+0000 [xxu46_7] INFO: Crawled 412 pages (at 0 pages/min), scraped 405 items (at 0 items/min)
2015-03-24 09:09:09+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5793> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 09:09:09+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5793>
	{'abstract': u'Consider a single-user or multiple-access channel with a large output alphabet. A method to approximate the channel by an upgraded version having a smaller output alphabet is presented and analyzed. The gain in symmetric channel capacity is controlled through a fidelity parameter. The larger the fidelity parameter, the better the approximation on the one hand, but the larger the new output alphabet on the other. The approximation method is instrumental when constructing polar codes. No assumption is made on the symmetry of the original channel, and the input alphabet need not be binary.',
	 'authors': u'Uzi Pereg, Ido Tal,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5793',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nChannel Upgradation for Non-Binary Input Alphabets and MACs',
	 'urllink': u'http://arxiv.org/abs/1308.5793'}
2015-03-24 09:10:09+0000 [xxu46_7] INFO: Crawled 413 pages (at 1 pages/min), scraped 406 items (at 1 items/min)
2015-03-24 09:10:30+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7270> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 09:10:30+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7270>
	{'abstract': u'Despite the prevalence of sentiment-related content on the Web, there has been limited work on focused crawlers capable of effectively collecting such content. In this study, we evaluated the efficacy of using sentiment-related information for enhanced focused crawling of opinion-rich web content regarding a particular topic. We also assessed the impact of using sentiment-labeled web graphs to further improve collection accuracy. Experimental results on a large test bed encompassing over half a million web pages revealed that focused crawlers utilizing sentiment information as well as sentiment-labeled web graphs are capable of gathering more holistic collections of opinion-related content regarding a particular topic. The results have important implications for business and marketing intelligence gathering efforts in the Web 2.0 era.',
	 'authors': u'Tianjun Fu, Ahmed Abbasi, Daniel Zeng, Hsinchun Chen,',
	 'category': u'Computer Science ',
	 'date': '2013-9-27',
	 'pdflink': u'http://arxiv.org/pdf/1309.7270',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nEvaluating the Usefulness of Sentiment Information for Focused Crawlers',
	 'urllink': u'http://arxiv.org/abs/1309.7270'}
2015-03-24 09:11:09+0000 [xxu46_7] INFO: Crawled 414 pages (at 1 pages/min), scraped 407 items (at 1 items/min)
2015-03-24 09:12:06+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6674> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 09:12:06+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6674>
	{'abstract': u"This paper considers the problem of interference control through the use of second-order statistics in massive MIMO multi-cell networks. We consider both the cases of co-located massive arrays and large-scale distributed antenna settings. We are interested in characterizing the low-rankness of users' channel covariance matrices, as such a property can be exploited towards improved channel estimation (so-called pilot decontamination) as well as interference rejection via spatial filtering. In previous work, it was shown that massive MIMO channel covariance matrices exhibit a useful finite rank property that can be modeled via the angular spread of multipath at a MIMO uniform linear array. This paper extends this result to more general settings including certain non-uniform arrays, and more surprisingly, to two dimensional distributed large scale arrays. In particular our model exhibits the dependence of the signal subspace's richness on the scattering radius around the user terminal, through a closed form expression. The applications of the low-rankness covariance property to channel estimation's denoising and low-complexity interference filtering are highlighted.",
	 'authors': u'Haifan Yin, David Gesbert, Laura Cottatellucci,',
	 'category': u'Computer Science ',
	 'date': '2013-10-24',
	 'pdflink': u'http://arxiv.org/pdf/1310.6674',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nDealing with Interference in Distributed Large-scale MIMO Systems: A  Statistical Approach',
	 'urllink': u'http://arxiv.org/abs/1310.6674'}
2015-03-24 09:12:09+0000 [xxu46_7] INFO: Crawled 415 pages (at 1 pages/min), scraped 408 items (at 1 items/min)
2015-03-24 09:13:09+0000 [xxu46_7] INFO: Crawled 415 pages (at 0 pages/min), scraped 408 items (at 0 items/min)
2015-03-24 09:14:01+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5786> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 09:14:01+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5786>
	{'abstract': u'Dynamic spectrum management is recognized as a key technique to tackle interference in multi-user multi-carrier communication systems and networks. However existing dynamic spectrum management algorithms may not be suitable when the available computation time and compute power are limited, i.e., when a very fast responsiveness is required. In this paper, we present a new paradigm, theory and algorithm for real-time dynamic spectrum management (RT-DSM) under tight real-time constraints. Specifically, a RT-DSM algorithm can be stopped at any point in time while guaranteeing a feasible and improved solution. This is enabled by the introduction of a novel difference-of-variables (DoV) transformation and problem reformulation, for which a primal coordinate ascent approach is proposed with exact line search via a logarithmicly scaled grid search. The concrete proposed algorithm is referred to as iterative power difference balancing (IPDB). Simulations for different realistic wireline and wireless interference limited systems demonstrate its good performance, low complexity and wide applicability under different configurations.',
	 'authors': u'Paschalis Tsiaflakis, Fran\xe7ois Glineur, Marc Moonen,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5786',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nReal-time dynamic spectrum management for multi-user multi-carrier  communication systems',
	 'urllink': u'http://arxiv.org/abs/1308.5786'}
2015-03-24 09:14:09+0000 [xxu46_7] INFO: Crawled 416 pages (at 1 pages/min), scraped 409 items (at 1 items/min)
2015-03-24 09:15:09+0000 [xxu46_7] INFO: Crawled 416 pages (at 0 pages/min), scraped 409 items (at 0 items/min)
2015-03-24 09:15:24+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7266> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 09:15:24+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7266>
	{'abstract': u'Fake online pharmacies have become increasingly pervasive, constituting over 90% of online pharmacy websites. There is a need for fake website detection techniques capable of identifying fake online pharmacy websites with a high degree of accuracy. In this study, we compared several well-known link-based detection techniques on a large-scale test bed with the hyperlink graph encompassing over 80 million links between 15.5 million web pages, including 1.2 million known legitimate and fake pharmacy pages. We found that the QoC and QoL class propagation algorithms achieved an accuracy of over 90% on our dataset. The results revealed that algorithms that incorporate dual class propagation as well as inlink and outlink information, on page-level or site-level graphs, are better suited for detecting fake pharmacy websites. In addition, site-level analysis yielded significantly better results than page-level analysis for most algorithms evaluated.',
	 'authors': u'Ahmed Abbasi, Siddharth Kaza, F. Mariam Zahedi,',
	 'category': u'Computer Science ',
	 'date': '2013-9-27',
	 'pdflink': u'http://arxiv.org/pdf/1309.7266',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nEvaluating Link-Based Techniques for Detecting Fake Pharmacy Websites',
	 'urllink': u'http://arxiv.org/abs/1309.7266'}
2015-03-24 09:16:09+0000 [xxu46_7] INFO: Crawled 417 pages (at 1 pages/min), scraped 410 items (at 1 items/min)
2015-03-24 09:17:01+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6670> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 09:17:01+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6670>
	{'abstract': u'The recent extensive availability of "big data" platforms calls for a more widespread adoption by the formal verification community. In fact, formal verification requires high performance data processing software for extracting knowledge from the unprecedented amount of data which come from analyzed systems. Since cloud based computing resources have became easily accessible, there is an opportunity for verification techniques and tools to undergo a deep technological transition to exploit the new available architectures. This has created an increasing interest in parallelizing and distributing verification techniques. In this paper we introduce a distributed approach which exploits techniques typically used by the "big data" community to enable verification of Computation Tree Logic (CTL) formulas on very large state spaces using distributed systems and cloud computing facilities. The outcome of several tests performed on benchmark specifications are presented, thus showing the convenience of the proposed approach.',
	 'authors': u'Carlo Bellettini, Matteo Camilli, Lorenzo Capra, Mattia Monga,',
	 'category': u'Computer Science ',
	 'date': '2013-10-24',
	 'pdflink': u'http://arxiv.org/pdf/1310.6670',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nDistributed CTL Model Checking in the Cloud',
	 'urllink': u'http://arxiv.org/abs/1310.6670'}
2015-03-24 09:17:09+0000 [xxu46_7] INFO: Crawled 418 pages (at 1 pages/min), scraped 411 items (at 1 items/min)
2015-03-24 09:18:09+0000 [xxu46_7] INFO: Crawled 418 pages (at 0 pages/min), scraped 411 items (at 0 items/min)
2015-03-24 09:18:24+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5741> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 09:18:24+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5741>
	{'abstract': u'We investigate exact crossing minimization for graphs that differ from trees by a small number of additional edges, for several variants of the crossing minimization problem. In particular, we provide fixed parameter tractable algorithms for the 1-page book crossing number, the 2-page book crossing number, and the minimum number of crossed edges in 1-page and 2-page book drawings.',
	 'authors': u'Michael J. Bannister, David Eppstein, Joseph A. Simons,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5741',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nFixed parameter tractability of crossing minimization of almost-trees',
	 'urllink': u'http://arxiv.org/abs/1308.5741'}
2015-03-24 09:19:09+0000 [xxu46_7] INFO: Crawled 419 pages (at 1 pages/min), scraped 412 items (at 1 items/min)
2015-03-24 09:19:22+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7262> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 09:19:22+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7262>
	{'abstract': u'Fake websites have emerged as a major source of online fraud, accounting for billions of dollars of loss by Internet users. We explore the process by which salient design elements could increase the use of protective tools, thus reducing the success rate of fake websites. Using the protection motivation theory, we conceptualize a model to investigate how salient design elements of detection tools could influence user perceptions of the tools, efficacy in dealing with threats, and use of such tools. The research method was a controlled lab experiment with a novel and extensive experimental design and protocol. We found that trust in the detector is the pivotal coping mechanism in dealing with security threats and is a major conduit for transforming salient design elements into increased use. We also found that design elements have profound and unexpected impacts on self-efficacy. The significant theoretical and empirical implications of findings are discussed.',
	 'authors': u'F. Mariam Zahedi, Ahmed Abbasi, Yan Chen,',
	 'category': u'Computer Science ',
	 'date': '2013-9-27',
	 'pdflink': u'http://arxiv.org/pdf/1309.7262',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nDesign Elements that Promote the use of Fake Website Detection Tools',
	 'urllink': u'http://arxiv.org/abs/1309.7262'}
2015-03-24 09:20:09+0000 [xxu46_7] INFO: Crawled 420 pages (at 1 pages/min), scraped 413 items (at 1 items/min)
2015-03-24 09:21:04+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6669> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 09:21:04+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6669>
	{'abstract': u'This contribution investigates the Degrees-of-Freedom region of a two-user frequency correlated Multiple-Input-Single-Output (MISO) Broadcast Channel (BC) with imperfect Channel State Information at the transmitter (CSIT). We assume that the system consists of an arbitrary number of subbands, denoted as . Besides, the CSIT state varies across users and subbands. A tight outer-bound is found as a function of the minimum average CSIT quality between the two users. Based on the CSIT states across the subbands, the DoF region is interpreted as a weighted sum of the optimal DoF regions in the scenarios where the CSIT of both users are perfect, alternatively perfect and not known. Inspired by the weighted-sum interpretation and identifying the benefit of the optimal scheme for the unmatched CSIT proposed by Chen et al., we also design a scheme achieving the upper-bound for the general -subband scenario in frequency domain BC, thus showing the optimality of the DoF region.',
	 'authors': u'Chenxi Hao, Borzoo Rassouli, Bruno Clerckx,',
	 'category': u'Computer Science ',
	 'date': '2013-10-24',
	 'pdflink': u'http://arxiv.org/pdf/1310.6669',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nDegrees-of-Freedom Region of MISO-OFDMA Broadcast Channel with Imperfect  CSIT',
	 'urllink': u'http://arxiv.org/abs/1310.6669'}
2015-03-24 09:21:09+0000 [xxu46_7] INFO: Crawled 421 pages (at 1 pages/min), scraped 414 items (at 1 items/min)
2015-03-24 09:22:09+0000 [xxu46_7] INFO: Crawled 421 pages (at 0 pages/min), scraped 414 items (at 0 items/min)
2015-03-24 09:22:32+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5737> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 09:22:32+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5737>
	{'abstract': u'Permutation polynomials are an interesting subject of mathematics and have applications in other areas of mathematics and engineering. In this paper, we develop general theorems on permutation polynomials over finite fields. As a demonstration of the theorems, we present a number of classes of explicit permutation polynomials on .',
	 'authors': u'Pingzhi Yuan, Cunsheng Ding,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/pdf/1308.5737',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nFurther Results on Permutation Polynomials over Finite Fields',
	 'urllink': u'http://arxiv.org/abs/1308.5737'}
2015-03-24 09:23:09+0000 [xxu46_7] INFO: Crawled 422 pages (at 1 pages/min), scraped 415 items (at 1 items/min)
2015-03-24 09:24:07+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7261> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 09:24:07+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7261>
	{'abstract': u'The ability to automatically detect fraudulent escrow websites is important in order to alleviate online auction fraud. Despite research on related topics, fake escrow website categorization has received little attention. In this study we evaluated the effectiveness of various features and techniques for detecting fake escrow websites. Our analysis included a rich set of features extracted from web page text, image, and link information. We also proposed a composite kernel tailored to represent the properties of fake websites, including content duplication and structural attributes. Experiments were conducted to assess the proposed features, techniques, and kernels on a test bed encompassing nearly 90,000 web pages derived from 410 legitimate and fake escrow sites. The combination of an extended feature set and the composite kernel attained over 98% accuracy when differentiating fake sites from real ones, using the support vector machines algorithm. The results suggest that automated web-based information systems for detecting fake escrow sites could be feasible and may be utilized as authentication mechanisms.',
	 'authors': u'Ahmed Abbasi, Hsinchun Chen,',
	 'category': u'Computer Science ',
	 'date': '2013-9-27',
	 'pdflink': u'http://arxiv.org/pdf/1309.7261',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nDetecting Fake Escrow Websites using Rich Fraud Cues and Kernel Based  Methods',
	 'urllink': u'http://arxiv.org/abs/1309.7261'}
2015-03-24 09:24:09+0000 [xxu46_7] INFO: Crawled 423 pages (at 1 pages/min), scraped 416 items (at 1 items/min)
2015-03-24 09:25:09+0000 [xxu46_7] INFO: Crawled 423 pages (at 0 pages/min), scraped 416 items (at 0 items/min)
2015-03-24 09:26:02+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6657> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 09:26:02+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6657>
	{'abstract': u'In this contribution, we focus on a frequency domain two-user Multiple-Input-Single-Output Broadcast Channel (MISO BC) where the transmitter has imperfect and (un)matched Channel State Information (CSI) of the two users in two subbands. We provide an upper-bound to the Degrees-of-Freedom (DoF) region, which is tight compared to the state of the art. By decomposing the subbands into subchannels according to the CSI feedback qualities, we interpret the DoF region as the weighted-sum of that in each subchannel. Moreover, we study the sum emph loss when employing sub-optimal schemes, namely Frequency Division Multiple Access (FDMA), Zero-Forcing Beamforming (ZFBF) and the scheme proposed by Tandon et al. The results show that by switching among the sub-optimal strategies, we can obtain at least 80% and 66.7% of the optimal sum emph performance for the unmatched and matched CSIT scenario respectively.',
	 'authors': u'Chenxi Hao, Bruno Clerckx,',
	 'category': u'Computer Science ',
	 'date': '2013-10-24',
	 'pdflink': u'http://arxiv.org/pdf/1310.6657',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nMISO Broadcast Channel with Imperfect and (Un)matched CSIT in the  Frequency Domain: DoF Region and Transmission Strategies',
	 'urllink': u'http://arxiv.org/abs/1310.6657'}
2015-03-24 09:26:09+0000 [xxu46_7] INFO: Crawled 424 pages (at 1 pages/min), scraped 417 items (at 1 items/min)
2015-03-24 09:27:09+0000 [xxu46_7] INFO: Crawled 424 pages (at 0 pages/min), scraped 417 items (at 0 items/min)
2015-03-24 09:27:36+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5724> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 09:27:36+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5724>
	{'abstract': u'This volume contains the proceedings of the Second International Workshop Hybrid Systems and Biology (HSB 2013) held in Taormina (Italy), on September 2th, 2013. The workshop is affiliated to the 12th European Conference on Artificial Life (ECAL 2013). Systems biology aims at providing a system-level understanding of biological systems by unveiling their structure, dynamics and control methods. Due to the intrinsic multi-scale nature of these systems in space, in organization levels and in time, it is extremely difficult to model them in a uniform way, e.g., by means of differential equations or discrete stochastic processes. Furthermore, such models are often not easily amenable to formal analysis, and their simulations at the organ or even at the cell levels are frequently impractical. Indeed, an important open problem is finding appropriate computational models that scale well for both simulation and formal analysis of biological processes. Hybrid modeling techniques, combining discrete and continuous processes, are gaining more and more attention in such a context, and they have been successfully applied to capture the behavior of many biological complex systems, ranging from genetic networks, biochemical reactions, signaling pathways, cardiac tissues electro-physiology, and tumor genesis. This workshop aims at bringing together researchers in computer science, mathematics, and life sciences, interested in the opportunities and the challenges of hybrid modeling applied to systems biology. The workshop programme included the keynote presentation of Alessandro Astolfi (Imperial College of London, UK) on Immune response enhancement via hybrid control. Furthermore, 8 papers were selected out of 13 submissions by the Program Committee of HSB 2013. The papers in this volume address the hybrid modeling of a number important biological processes (iron homeostasis network, mammalian cell cycle, vascular endothelial growth factor (VEGF), genetic regulatory network in mammalian sclera) and, the formalisms and techniques for specifying and validating properties of biological systems (such as, robustness, oscillations).',
	 'authors': u'Thao Dang, Carla Piazza,',
	 'category': u'Computer Science ',
	 'date': '2013-8-27',
	 'pdflink': u'http://arxiv.org/html/1308.5724',
	 'subjects': u'Computational Engineering, Finance, and Science (cs.CE)',
	 'title': u'\nProceedings Second International Workshop on Hybrid Systems and Biology',
	 'urllink': u'http://arxiv.org/abs/1308.5724'}
2015-03-24 09:28:09+0000 [xxu46_7] INFO: Crawled 425 pages (at 1 pages/min), scraped 418 items (at 1 items/min)
2015-03-24 09:29:09+0000 [xxu46_7] INFO: Crawled 425 pages (at 0 pages/min), scraped 418 items (at 0 items/min)
2015-03-24 09:29:29+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7258> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 09:29:29+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7258>
	{'abstract': u'In an epsilon-approximate Nash equilibrium, a player can gain at most epsilon in expectation by unilateral deviation. An epsilon well-supported approximate Nash equilibrium has the stronger requirement that every pure strategy used with positive probability must have payoff within epsilon of the best response payoff. Daskalakis, Mehta and Papadimitriou conjectured that every win-lose bimatrix game has a 2/3-well-supported Nash equilibrium that uses supports of cardinality at most three. Indeed, they showed that such an equilibrium will exist subject to the correctness of a graph-theoretic conjecture. Regardless of the correctness of this conjecture, we show that the barrier of a 2/3 payoff guarantee cannot be broken with constant size supports; we construct win-lose games that require supports of cardinality at least Omega((log n)^(1/3)) in any epsilon-well supported equilibrium with epsilon &lt; 2/3. The key tool in showing the validity of the construction is a proof of a bipartite digraph variant of the well-known Caccetta-Haggkvist conjecture. A probabilistic argument shows that there exist epsilon-well-supported equilibria with supports of cardinality O(log n/(epsilon^2)), for any epsilon&gt; 0; thus, the polylogarithmic cardinality bound presented cannot be greatly improved. We also show that for any delta &gt; 0, there exist win-lose games for which no pair of strategies with support sizes at most two is a (1-delta)-well-supported Nash equilibrium. In contrast, every bimatrix game with payoffs in [0,1] has a 1/2-approximate Nash equilibrium where the supports of the players have cardinality at most two.',
	 'authors': u'Yogesh Anbalagan, Sergey Norin, Rahul Savani, Adrian Vetta,',
	 'category': u'Computer Science ',
	 'date': '2013-9-27',
	 'pdflink': u'http://arxiv.org/pdf/1309.7258',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nPolylogarithmic Supports are required for Approximate Well-Supported  Nash Equilibria below 2/3',
	 'urllink': u'http://arxiv.org/abs/1309.7258'}
2015-03-24 09:30:09+0000 [xxu46_7] INFO: Crawled 426 pages (at 1 pages/min), scraped 419 items (at 1 items/min)
2015-03-24 09:30:27+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6654> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 09:30:27+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6654>
	{'abstract': u'In recent years, Printed Circuit Boards (PCB) have become the backbone of a large number of consumer electronic devices leading to a surge in their production. This has made it imperative to employ automatic inspection systems to identify manufacturing defects in PCB before they are installed in the respective systems. An important task in this regard is the classification of defects as either true or pseudo defects, which decides if the PCB is to be re-manufactured or not. This work proposes a novel approach to detect most common defects in the PCBs. The problem has been approached by employing highly discriminative features based on multi-scale wavelet transform, which are further boosted by using a kernalized version of the support vector machines (SVM). A real world printed circuit board dataset has been used for quantitative analysis. Experimental results demonstrated the efficacy of the proposed method.',
	 'authors': u'Sahil Sikka, Karan Sikka, M.K. Bhuyan, Yuji Iwahori,',
	 'category': u'Computer Science ',
	 'date': '2013-10-24',
	 'pdflink': u'http://arxiv.org/pdf/1310.6654',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nPseudo vs. True Defect Classification in Printed Circuits Boards using  Wavelet Features',
	 'urllink': u'http://arxiv.org/abs/1310.6654'}
2015-03-24 09:31:09+0000 [xxu46_7] INFO: Crawled 427 pages (at 1 pages/min), scraped 420 items (at 1 items/min)
2015-03-24 09:31:51+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5706> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 09:31:51+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5706>
	{'abstract': u'We review scale-discretized wavelets on the sphere, which are directional and allow one to probe oriented structure in data defined on the sphere. Furthermore, scale-discretized wavelets allow in practice the exact synthesis of a signal from its wavelet coefficients. We present exact and efficient algorithms to compute the scale-discretized wavelet transform of band-limited signals on the sphere. These algorithms are implemented in the publicly available S2DW code. We release a new version of S2DW that is parallelized and contains additional code optimizations. Note that scale-discretized wavelets can be viewed as a directional generalization of needlets. Finally, we outline future improvements to the algorithms presented, which can be achieved by exploiting a new sampling theorem on the sphere developed recently by some of the authors.',
	 'authors': u'J. D. McEwen, P. Vandergheynst, Y. Wiaux,',
	 'category': u'Computer Science ',
	 'date': '2013-8-26',
	 'pdflink': u'http://arxiv.org/pdf/1308.5706',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOn the computation of directional scale-discretized wavelet transforms  on the sphere',
	 'urllink': u'http://arxiv.org/abs/1308.5706'}
2015-03-24 09:32:09+0000 [xxu46_7] INFO: Crawled 428 pages (at 1 pages/min), scraped 421 items (at 1 items/min)
2015-03-24 09:33:09+0000 [xxu46_7] INFO: Crawled 428 pages (at 0 pages/min), scraped 421 items (at 0 items/min)
2015-03-24 09:33:42+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7198> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 09:33:42+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7198>
	{'abstract': u'The analysis of the structure of chemical reaction networks is crucial for a better understanding of chemical processes. Such networks are well described as hypergraphs. However, due to the available methods, analyses regarding network properties are typically made on standard graphs derived from the full hypergraph description, e.g. on the so-called species and reaction graphs. However, a reconstruction of the underlying hypergraph from these graphs is not necessarily unique. In this paper, we address the problem of reconstructing a hypergraph from its species and reaction graph and show NP-completeness of the problem in its Boolean formulation. Furthermore we study the problem empirically on random and real world instances in order to investigate its computational limits in practice.',
	 'authors': u'Rolf Fagerberg, Christoph Flamm, Daniel Merkle, Philipp Peters, Peter F. Stadler,',
	 'category': u'Computer Science ',
	 'date': '2013-9-27',
	 'pdflink': u'http://arxiv.org/pdf/1309.7198',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nOn the Complexity of Reconstructing Chemical Reaction Networks',
	 'urllink': u'http://arxiv.org/abs/1309.7198'}
2015-03-24 09:34:09+0000 [xxu46_7] INFO: Crawled 429 pages (at 1 pages/min), scraped 422 items (at 1 items/min)
2015-03-24 09:34:59+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6650> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 09:34:59+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6650>
	{'abstract': u'A hybrid automatic repeat request scheme with Chase combing (HARQ-CC) of polar codes is proposed. The existing analysis tools of the underlying rate-compatible punctured polar (RCPP) codes for additive white Gaussian noise (AWGN) channels are extended to Rayleigh fading channels. Then, an approximation bound of the throughput efficiency for the polar coded HARQ-CC scheme is derived. Utilizing this bound, the parameter configurations of the proposed scheme can be optimized. Simulation results show that, the proposed HARQ-CC scheme under a low-complexity SC decoding is only about dB away from the existing schemes with incremental redundancy ( mbox). Compared with the polar coded mbox scheme, the proposed HARQ-CC scheme requires less retransmissions and has the advantage of good compatibility to other communication techniques.',
	 'authors': u'Kai Chen, Kai Niu, Zhiqiang He, Jiaru Lin,',
	 'category': u'Computer Science ',
	 'date': '2013-10-24',
	 'pdflink': u'http://arxiv.org/pdf/1310.6650',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nPolar Coded HARQ Scheme with Chase Combining',
	 'urllink': u'http://arxiv.org/abs/1310.6650'}
2015-03-24 09:35:09+0000 [xxu46_7] INFO: Crawled 430 pages (at 1 pages/min), scraped 423 items (at 1 items/min)
2015-03-24 09:36:02+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5703> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 09:36:02+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5703>
	{'abstract': u'Although RDF graphs have schema information associated with them, in practice it is very common to find cases in which data do not fully conform to their schema. A prominent example of this is DBpedia, which is RDF data extracted from Wikipedia, a publicly editable source of information. In such situations, it becomes interesting to study the structural properties of the actual data, because the schema gives an incomplete description of the organization of a dataset. In this paper we have approached the study of the structuredness of an RDF graph in a principled way: we propose a framework for specifying structuredness functions, which gauge the degree to which an RDF graph conforms to a schema. In particular, we first define a formal language for specifying structuredness functions with expressions we call rules. This language allows a user or a database administrator to state a rule to which an RDF graph may fully or partially conform. Then we consider the issue of discovering a refinement of a sort (type) by partitioning the dataset into subsets whose structuredness is over a specified threshold. In particular, we prove that the natural decision problem associated to this refinement problem is NP-complete, and we provide a natural translation of this problem into Integer Linear Programming (ILP). Finally, we test this ILP solution with two real world datasets, DBpedia Persons and WordNet Nouns, and 4 different and intuitive rules, which gauge the structuredness in different ways. The rules give meaningful refinements of the datasets, showing that our language can be a powerful tool for understanding the structure of RDF data.',
	 'authors': u'Marcelo Arenas, Gonzalo I. Diaz, Achille Fokoue, Anastasios Kementsietsidis, Kavitha Srinivas,',
	 'category': u'Computer Science ',
	 'date': '2013-8-26',
	 'pdflink': u'http://arxiv.org/pdf/1308.5703',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nA Principled Approach to Bridging the Gap between Graph Data and their  Schemas',
	 'urllink': u'http://arxiv.org/abs/1308.5703'}
2015-03-24 09:36:09+0000 [xxu46_7] INFO: Crawled 431 pages (at 1 pages/min), scraped 424 items (at 1 items/min)
2015-03-24 09:37:09+0000 [xxu46_7] INFO: Crawled 431 pages (at 0 pages/min), scraped 424 items (at 0 items/min)
2015-03-24 09:37:18+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7187> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 09:37:18+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7187>
	{'abstract': u'Role analysis in online communities allows us to understand and predict users behavior. Though several approaches have been followed, there is still lack of generalization of their methods and their results. In this paper, we discuss about the ground theory of roles and search for a consistent and computable definition that allows the automatic detection of roles played by users in forum threads on the internet. We analyze the web site IMDb to illustrate the discussion.',
	 'authors': u'Alberto Lumbreras, James Lanagan, Julien Velcin, Bertrand Jouve,',
	 'category': u'Computer Science ',
	 'date': '2013-9-27',
	 'pdflink': u'http://arxiv.org/pdf/1309.7187',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nAnalyse des r\xf4les dans les communaut\xe9s virtuelles : d\xe9finitions et  premi\xe8res exp\xe9rimentations sur IMDb',
	 'urllink': u'http://arxiv.org/abs/1309.7187'}
2015-03-24 09:38:09+0000 [xxu46_7] INFO: Crawled 432 pages (at 1 pages/min), scraped 425 items (at 1 items/min)
2015-03-24 09:38:30+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6637> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 09:38:30+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6637>
	{'abstract': u'Web usage mining is a process of extracting useful information from server logs i.e. users history. Web usage mining is a process of finding out what users are looking for on the internet. Some users might be looking at only textual data, where as some others might be interested in multimedia data. One would retrieve the data by copying it and pasting it to the relevant document. But this is tedious and time consuming as well as difficult when the data to be retrieved is plenty. Extracting structured data from a web page is challenging problem due to complicated structured pages. Earlier they were used web page programming language dependent; the main problem is to analyze the html source code. In earlier they were considered the scripts such as java scripts and cascade styles in the html files. When it makes different for existing solutions to infer the regularity of the structure of the Web Pages only by analyzing the tag structures. To overcome this problem we are using a new algorithm called VIPS algorithm i.e. independent language. This approach primary utilizes the visual features on the webpage to implement web data extraction.',
	 'authors': u'P YesuRaju, P KiranSree,',
	 'category': u'Computer Science ',
	 'date': '2013-10-24',
	 'pdflink': u'http://arxiv.org/pdf/1310.6637',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nA language independent web data extraction using vision based page  segmentation algorithm',
	 'urllink': u'http://arxiv.org/abs/1310.6637'}
2015-03-24 09:39:09+0000 [xxu46_7] INFO: Crawled 433 pages (at 1 pages/min), scraped 426 items (at 1 items/min)
2015-03-24 09:40:09+0000 [xxu46_7] INFO: Crawled 433 pages (at 0 pages/min), scraped 426 items (at 0 items/min)
2015-03-24 09:40:18+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5697> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 09:40:18+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5697>
	{'abstract': u'The development of randomized algorithms for numerical linear algebra, e.g. for computing approximate QR and SVD factorizations, has recently become an intense area of research. This paper studies one of the most frequently discussed algorithms in the literature for dimensionality reduction---specifically for approximating an input matrix with a low-rank element. We introduce a novel and rather intuitive analysis of the algorithm in Martinsson et al. (2008), which allows us to derive sharp estimates and give new insights about its performance. This analysis yields theoretical guarantees about the approximation error and at the same time, ultimate limits of performance (lower bounds) showing that our upper bounds are tight. Numerical experiments complement our study and show the tightness of our predictions compared with empirical observations.',
	 'authors': u'Rafi Witten, Emmanuel Candes,',
	 'category': u'Computer Science ',
	 'date': '2013-8-26',
	 'pdflink': u'http://arxiv.org/pdf/1308.5697',
	 'subjects': u'Numerical Analysis (cs.NA)',
	 'title': u'\nRandomized algorithms for low-rank matrix factorizations: sharp  performance bounds',
	 'urllink': u'http://arxiv.org/abs/1308.5697'}
2015-03-24 09:41:09+0000 [xxu46_7] INFO: Crawled 434 pages (at 1 pages/min), scraped 427 items (at 1 items/min)
2015-03-24 09:42:03+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7173> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 09:42:03+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7173>
	{'abstract': u'Analysis of seven optimization techniques grouped under three categories (hardware, back-end, and front-end) is done to study the reduction in average user response time for Modular Object Oriented Dynamic Learning Environment (Moodle), a Learning Management System which is scripted in PHP5, runs on Apache web server and utilizes MySQL database software. Before the implementation of these techniques, performance analysis of Moodle is performed for varying number of concurrent users. The results obtained for each optimization technique are then reported in a tabular format. The maximum reduction in end user response time was achieved for hardware optimization which requires Moodle server and database to be installed on solid state disk.',
	 'authors': u'Priyanka Manchanda,',
	 'category': u'Computer Science ',
	 'date': '2013-9-27',
	 'pdflink': u'http://arxiv.org/pdf/1309.7173',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nAnalysis of Optimization Techniques to Improve User Response Time of Web  Applications and Their Implementation for MOODLE',
	 'urllink': u'http://arxiv.org/abs/1309.7173'}
2015-03-24 09:42:09+0000 [xxu46_7] INFO: Crawled 435 pages (at 1 pages/min), scraped 428 items (at 1 items/min)
2015-03-24 09:43:09+0000 [xxu46_7] INFO: Crawled 435 pages (at 0 pages/min), scraped 428 items (at 0 items/min)
2015-03-24 09:44:03+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6635> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 09:44:03+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6635>
	{'abstract': u"We show preliminary results for the performance of Network Coded TCP (CTCP) over large latency networks. While CTCP performs very well in networks with relatively short RTT, the slow-start mechanism currently employed does not adequately fill the available bandwidth when the RTT is large. Regardless, we show that CTCP still outperforms current TCP variants (i.e., Cubic TCP and Hybla TCP) for high packet loss rates (e.g., &gt;2.5%). We then explore the possibility of a modified congestion control mechanism based off of H-TCP that opens the congestion window quickly to overcome the challenges of large latency networks. Preliminary results are provided that show the combination of network coding with an appropriate congestion control algorithm can provide gains on the order of 20 times that of existing TCP variants. Finally, we provide a discussion of the future work needed to increase CTCP's performance in these networks.",
	 'authors': u'Jason Cloud, Douglas Leith, Muriel Medard,',
	 'category': u'Computer Science ',
	 'date': '2013-10-24',
	 'pdflink': u'http://arxiv.org/pdf/1310.6635',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nNetwork Coded TCP (CTCP) Performance over Satellite Networks',
	 'urllink': u'http://arxiv.org/abs/1310.6635'}
2015-03-24 09:44:09+0000 [xxu46_7] INFO: Crawled 436 pages (at 1 pages/min), scraped 429 items (at 1 items/min)
2015-03-24 09:45:09+0000 [xxu46_7] INFO: Crawled 436 pages (at 0 pages/min), scraped 429 items (at 0 items/min)
2015-03-24 09:45:41+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5661> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 09:45:41+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5661>
	{'abstract': u'With rapid advances in digital information processing systems, and more specifically in digital image processing software, there is a widespread development of advanced tools and techniques for digital image forgery. One of the techniques most commonly used is the Copy-move forgery which proceeds by copying a part of an image and pasting it into the same image, in order to maliciously hide an object or a region. In this paper, we propose a method to detect this specific kind of counterfeit. Firstly, the color image is converted from RGB color space to YCbCr color space and then the R, G, B and Y-component are splitted into fixed-size overlapping blocks and, features are extracted from the R, G and B-components image blocks on one hand and on the other, from the DCT representation of the R, G, B and Ycomponent image block. The feature vectors obtained are then lexicographically sorted to make similar image blocks neighbors and duplicated image blocks are identified using Euclidean distance as similarity criterion. Experimental results showed that the proposed method can detect the duplicated regions when there is more than one copy move forged area in the image and even in case of slight rotations, JPEG compression, shift, scale, blur and noise addition.',
	 'authors': u'Nathalie Diane Wandji, Sun Xingming, Moise Fah Kue,',
	 'category': u'Computer Science ',
	 'date': '2013-8-26',
	 'pdflink': u'http://arxiv.org/pdf/1308.5661',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nDetection of copy-move forgery in digital images based on DCT',
	 'urllink': u'http://arxiv.org/abs/1308.5661'}
2015-03-24 09:46:09+0000 [xxu46_7] INFO: Crawled 437 pages (at 1 pages/min), scraped 430 items (at 1 items/min)
2015-03-24 09:47:09+0000 [xxu46_7] INFO: Crawled 437 pages (at 0 pages/min), scraped 430 items (at 0 items/min)
2015-03-24 09:47:41+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7170> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 09:47:41+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7170>
	{'abstract': u"Vector-quantization can be a computationally expensive step in visual bag-of-words (BoW) search when the vocabulary is large. A BoW-based appearance SLAM needs to tackle this problem for an efficient real-time operation. We propose an effective method to speed up the vector-quantization process in BoW-based visual SLAM. We employ a graph-based nearest neighbor search (GNNS) algorithm to this aim, and experimentally show that it can outperform the state-of-the-art. The graph-based search structure used in GNNS can efficiently be integrated into the BoW model and the SLAM framework. The graph-based index, which is a k-NN graph, is built over the vocabulary words and can be extracted from the BoW's vocabulary construction procedure, by adding one iteration to the k-means clustering, which adds small extra cost. Moreover, exploiting the fact that images acquired for appearance-based SLAM are sequential, GNNS search can be initiated judiciously which helps increase the speedup of the quantization process considerably.",
	 'authors': u'Kiana Hajebi, Hong Zhang,',
	 'category': u'Computer Science ',
	 'date': '2013-9-27',
	 'pdflink': u'http://arxiv.org/pdf/1309.7170',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nAn Efficient Index for Visual Search in Appearance-based SLAM',
	 'urllink': u'http://arxiv.org/abs/1309.7170'}
2015-03-24 09:48:09+0000 [xxu46_7] INFO: Crawled 438 pages (at 1 pages/min), scraped 431 items (at 1 items/min)
2015-03-24 09:49:09+0000 [xxu46_7] INFO: Crawled 438 pages (at 0 pages/min), scraped 431 items (at 0 items/min)
2015-03-24 09:49:39+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6564> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 09:49:39+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6564>
	{'abstract': u"Cloud-based infrastructure has been increasingly adopted by the industry in distributed software development (DSD) environments. Its proponents claim that its several benefits include reduced cost, increased speed and greater productivity in software development. Empirical evaluations, however, are in the nascent stage of examining both the benefits and the risks of cloud-based infrastructure. The objective of this paper is to identify potential benefits and risks of using cloud in a DSD project conducted by teams based in Helsinki and Madrid. A cross-case qualitative analysis is performed based on focus groups conducted at the Helsinki and Madrid sites. Participants' observations are used to supplement the analysis. The results of the analysis indicated that the main benefits of using cloud are rapid development, continuous integration, cost savings, code sharing, and faster ramp-up. The key risks determined by the project are dependencies, unavailability of access to the cloud, code commitment and integration, technical debt, and additional support costs. The results revealed that if such environments are not planned and set up carefully, the benefits of using cloud in DSD projects might be overshadowed by the risks associated with it.",
	 'authors': u'Nilay Oza, J\xfcrgen M\xfcnch, Juan Garbajosa, Agustin Yague, Eloy Gonzalez Ortega,',
	 'category': u'Computer Science ',
	 'date': '2013-10-24',
	 'pdflink': u'http://arxiv.org/pdf/1310.6564',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nIdentifying Potential Risks and Benefits of Using Cloud in Distributed  Software Development',
	 'urllink': u'http://arxiv.org/abs/1310.6564'}
2015-03-24 09:50:09+0000 [xxu46_7] INFO: Crawled 439 pages (at 1 pages/min), scraped 432 items (at 1 items/min)
2015-03-24 09:51:09+0000 [xxu46_7] INFO: Crawled 439 pages (at 0 pages/min), scraped 432 items (at 0 items/min)
2015-03-24 09:51:39+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5625> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 09:51:39+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5625>
	{'abstract': u'The paper aims at proposing the first shape identification and classification algorithm in echolocation. The approach is based on first extracting geometric features from the reflected waves and then matching them with precomputed ones associated with a dictionary of targets. The construction of such frequency-dependent shape descriptors is based on some important properties of the scattering coefficients and new invariants. The stability and resolution of the proposed identification algorithm with respect to measurement noise and the limited-view aspect are analytically and numerically quantified.',
	 'authors': u'Habib Ammari, Minh Phuong Tran, Han Wang,',
	 'category': u'Computer Science ',
	 'date': '2013-8-26',
	 'pdflink': u'http://arxiv.org/pdf/1308.5625',
	 'subjects': u'Numerical Analysis (cs.NA)',
	 'title': u'\nShape identification and classification in echolocation',
	 'urllink': u'http://arxiv.org/abs/1308.5625'}
2015-03-24 09:52:09+0000 [xxu46_7] INFO: Crawled 440 pages (at 1 pages/min), scraped 433 items (at 1 items/min)
2015-03-24 09:53:04+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7163> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 09:53:04+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7163>
	{'abstract': u'This paper proposes a Low-Power, Energy Efficient 4-bit Binary Coded Decimal (BCD) adder design where the conventional 4-bit BCD adder has been modified with the Clock Gated Power Gating Technique. Moreover, the concept of DVT (Dual-vth) scheme has been introduced while designing the full adder blocks to reduce the Leakage Power, as well as, to maintain the overall performance of the entire circuit. The reported architecture of 4-bit BCD adder is designed using 45 nm technology and it consumes 1.384 Watt of Average Power while operating with a frequency of 200 MHz, and a Supply Voltage (Vdd) of 1 Volt. The results obtained from different simulation runs on SPICE, indicate the superiority of the proposed design compared to the conventional 4-bit BCD adder. Considering the product of Average Power and Delay, for the operating frequency of 200 MHz, a fair 47.41 % reduction compared to the conventional design has been achieved with this proposed scheme.',
	 'authors': u'Dipankar Saha, Subhramita Basak, Sagar Mukherjee, C. K. Sarkar,',
	 'category': u'Computer Science ',
	 'date': '2013-9-27',
	 'pdflink': u'http://arxiv.org/pdf/1309.7163',
	 'subjects': u'Hardware Architecture (cs.AR)',
	 'title': u'\nA Low-Voltage, Low-Power 4-bit BCD Adder, designed using the Clock Gated  Power Gating, and the DVT Scheme',
	 'urllink': u'http://arxiv.org/abs/1309.7163'}
2015-03-24 09:53:09+0000 [xxu46_7] INFO: Crawled 441 pages (at 1 pages/min), scraped 434 items (at 1 items/min)
2015-03-24 09:54:09+0000 [xxu46_7] INFO: Crawled 441 pages (at 0 pages/min), scraped 434 items (at 0 items/min)
2015-03-24 09:54:58+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6555> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 09:54:58+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6555>
	{'abstract': u"Scholars have made handwritten notes and comments in books and manuscripts for centuries. Today's blogs and news sites typically invite users to express their opinions on the published content; URLs allow web resources to be shared with accompanying annotations and comments using third-party services like Twitter or Facebook. These contributions have until recently been constrained within specific services, making them second-class citizens of the Web. Web Annotations are now emerging as fully independent Linked Data in their own right, no longer restricted to plain textual comments in application silos. Annotations can now range from bookmarks and comments, to fine-grained annotations of a selection of, for example, a section of a frame within a video stream. Technologies and standards now exist to create, publish, syndicate, mash-up and consume, finely targeted, semantically rich digital annotations on practically any content, as first-class Web citizens. This development is being driven by the need for collaboration and annotation reuse amongst domain researchers, computer scientists, scientific publishers, and scholarly content databases.",
	 'authors': u'Paolo Ciccarese, Stian Soiland-Reyes, Tim Clark,',
	 'category': u'Computer Science ',
	 'date': '2013-10-24',
	 'pdflink': u'http://arxiv.org/pdf/1310.6555',
	 'subjects': u'Digital Libraries (cs.DL)',
	 'title': u'\nWeb Annotation as a First Class Object',
	 'urllink': u'http://arxiv.org/abs/1310.6555'}
2015-03-24 09:55:09+0000 [xxu46_7] INFO: Crawled 442 pages (at 1 pages/min), scraped 435 items (at 1 items/min)
2015-03-24 09:56:09+0000 [xxu46_7] INFO: Crawled 442 pages (at 0 pages/min), scraped 435 items (at 0 items/min)
2015-03-24 09:56:54+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5608> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 09:56:54+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5608>
	{'abstract': u'Let Omega be a set of unsatisfiable clauses, an implicit resolution refutation of Omega is a circuit beta with a resolution proof of the statement " beta describes a correct tree-like resolution refutation of Omega". We show that such system is p-equivalent to Extended Frege. More generally, let be a tautology, a [P, Q]-proof of is a pair ( alpha, beta) s.t. alpha is a P-proof of the statement " beta is a circuit describing a correct Q-proof of tau". We prove that [EF,P] leq p [R,P] for arbitrary Cook-Reckhow proof system P.',
	 'authors': u'Zi Chao Wang,',
	 'category': u'Computer Science ',
	 'date': '2013-8-26',
	 'pdflink': u'http://arxiv.org/pdf/1308.5608',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nImplicit Resolution',
	 'urllink': u'http://arxiv.org/abs/1308.5608'}
2015-03-24 09:57:09+0000 [xxu46_7] INFO: Crawled 443 pages (at 1 pages/min), scraped 436 items (at 1 items/min)
2015-03-24 09:57:54+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7145> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 09:57:54+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7145>
	{'abstract': u'Constraints over finite sequences of variables are ubiquitous in sequencing and timetabling. Moreover, the wide variety of such constraints in practical applications led to general modelling techniques and generic propagation algorithms, often based on deterministic finite automata (DFA) and their extensions. We consider counter-DFAs (cDFA), which provide concise models for regular counting constraints, that is constraints over the number of times a regular-language pattern occurs in a sequence. We show how to enforce domain consistency in polynomial time for atmost and atleast regular counting constraints based on the frequent case of a cDFA with only accepting states and a single counter that can be incremented by transitions. We also prove that the satisfaction of exact regular counting constraints is NP-hard and indicate that an incomplete algorithm for exact regular counting constraints is faster and provides more pruning than the existing propagator from [3]. Regular counting constraints are closely related to the CostRegular constraint but contribute both a natural abstraction and some computational advantages.',
	 'authors': u'Nicolas Beldiceanu, Pierre Flener, Justin Pearson, Pascal Van Hentenryck,',
	 'category': u'Computer Science ',
	 'date': '2013-9-27',
	 'pdflink': u'http://arxiv.org/pdf/1309.7145',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nPropagating Regular Counting Constraints',
	 'urllink': u'http://arxiv.org/abs/1309.7145'}
2015-03-24 09:58:09+0000 [xxu46_7] INFO: Crawled 444 pages (at 1 pages/min), scraped 437 items (at 1 items/min)
2015-03-24 09:59:09+0000 [xxu46_7] INFO: Crawled 444 pages (at 0 pages/min), scraped 437 items (at 0 items/min)
2015-03-24 09:59:40+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6546> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 09:59:40+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6546>
	{'abstract': u"Along with today's data explosion and application diversification, a variety of hardware platforms for big data are emerging, attracting interests from both industry and academia. The existing hardware platforms represent a wide range of implementation approaches, and different hardware platforms have different strengths. In this paper, we conduct comprehensive evaluations on three representative big data systems: Intel Xeon, Atom (low power processors), and many-core Tilera using BigDataBench - a big data benchmark suite. Then we explore the relative performance of the three implementation approaches by running BigDataBench, and provide strong guidance for the big data systems construction. Through our experiments, we have inferred that a big data system based on specific hardware has different performance in the context of different applications and data volumes. When we construct a system, we should take into account not only the performance or energy consumption of the pure hardware, but also the characteristics of applications running on them. Data scale, application type and complexity should be considered comprehensively when researchers or architects plan to choose fundamental components for their big data systems.",
	 'authors': u'Jing Quan, Yingjie Shi, Ming Zhao, Wei Yang,',
	 'category': u'Computer Science ',
	 'date': '2013-10-24',
	 'pdflink': u'http://arxiv.org/pdf/1310.6546',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nThe Implications from Benchmarking Three Big Data Systems',
	 'urllink': u'http://arxiv.org/abs/1310.6546'}
2015-03-24 10:00:09+0000 [xxu46_7] INFO: Crawled 445 pages (at 1 pages/min), scraped 438 items (at 1 items/min)
2015-03-24 10:01:09+0000 [xxu46_7] INFO: Crawled 445 pages (at 0 pages/min), scraped 438 items (at 0 items/min)
2015-03-24 10:01:29+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5597> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 10:01:29+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5597>
	{'abstract': u'The problem of estimating a sparse channel, i.e. a channel with a few non-zero taps, appears in various areas of communications. Recently, we have developed an algorithm based on iterative alternating minimization which iteratively detects the location and the value of the taps. This algorithms involves an approximate Maximum A Posteriori (MAP) probability scheme for detection of the location of taps, while a least square method is used for estimating the values at each iteration. In this work, based on the method of factor graphs and message passing algorithms, we will compute an exact solution for the MAP estimation problem. Indeed, we first find a factor graph model of this problem, and then perform the well-known min-sum algorithm on the edges of this graph. Consequently, we will find an exact estimator for the MAP problem that its complexity grows linearly with respect to the channel memory. By substituting this estimator in the mentioned alternating minimization method, we will propose an estimator that will nearly achieve the Cramer-Rao bound of the genie-aided estimation of sparse channels (estimation based on knowing the location of non-zero taps of the channel), while it can perform faster than most of the proposed algorithms in literature.',
	 'authors': u'Rad Niazadeh, Masoud Babaie-Zadeh, Christian Jutten,',
	 'category': u'Computer Science ',
	 'date': '2013-8-26',
	 'pdflink': u'http://arxiv.org/pdf/1308.5597',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nSparse Channel Estimation by Factor Graphs',
	 'urllink': u'http://arxiv.org/abs/1308.5597'}
2015-03-24 10:02:09+0000 [xxu46_7] INFO: Crawled 446 pages (at 1 pages/min), scraped 439 items (at 1 items/min)
2015-03-24 10:02:42+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7141> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 10:02:42+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7141>
	{'abstract': u'Given an elementary chain of vertex set V, seen as a labelling of V by the set , and another discrete structure over , say a graph G, the problem of common intervals is to compute the induced subgraphs G[I], such that is an interval of [1, n] and G[I] satisfies some property Pi (as for example Pi= "being connected"). This kind of problems comes from comparative genomic in bioinformatics, mainly when the graph is a chain or a tree (Heber and Stoye 2001, Heber and Savage 2005, Bergeron et al 2008). When the family of intervals is closed under intersection, we present here the combination of two approaches, namely the idea of potential beginning developed in Uno, Yagiura 2000 and Bui-Xuan et al 2005 and the notion of generator as defined in Bergeron et al 2008. This yields a very simple generic algorithm to compute all common intervals, which gives optimal algorithms in various applications. For example in the case where is a tree, our framework yields the first linear time algorithms for the two properties: "being connected" and "being a path". In the case where is a chain, the problem is known as: common intervals of two permutations (Uno and Yagiura 2000), our algorithm provides not only the set of all common intervals but also with some easy modifications a tree structure that represents this set.',
	 'authors': u'Ismael Belghiti, Michel Habib,',
	 'category': u'Computer Science ',
	 'date': '2013-9-27',
	 'pdflink': u'http://arxiv.org/pdf/1309.7141',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nA general method for common intervals',
	 'urllink': u'http://arxiv.org/abs/1309.7141'}
2015-03-24 10:03:09+0000 [xxu46_7] INFO: Crawled 447 pages (at 1 pages/min), scraped 440 items (at 1 items/min)
2015-03-24 10:04:09+0000 [xxu46_7] INFO: Crawled 447 pages (at 0 pages/min), scraped 440 items (at 0 items/min)
2015-03-24 10:04:17+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6542> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 10:04:17+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6542>
	{'abstract': u"Although Cloud Computing promises to lower IT costs and increase users' productivity in everyday life, the unattractive aspect of this new technology is that the user no longer owns all the devices which process personal data. To lower scepticism, the project SensorCloud investigates techniques to understand and compensate these adoption barriers in a scenario consisting of cloud applications that utilize sensors and actuators placed in private places. This work provides an interdisciplinary overview of the social and technical core research challenges for the trustworthy integration of sensor and actuator devices with the Cloud Computing paradigm. Most importantly, these challenges include i) ease of development, ii) security and privacy, and iii) social dimensions of a cloud-based system which integrates into private life. When these challenges are tackled in the development of future cloud systems, the attractiveness of new use cases in a sensor-enabled world will considerably be increased for users who currently do not trust the Cloud.",
	 'authors': u'Michael Eggert, Roger H\xe4u\xdfling, Martin Henze, Lars Hermerschmidt, Ren\xe9 Hummen, Daniel Kerpen, Antonio Navarro P\xe9rez, Bernhard Rumpe, Dirk Thi\xdfen, Klaus Wehrle,',
	 'category': u'Computer Science ',
	 'date': '2013-10-24',
	 'pdflink': u'http://arxiv.org/pdf/1310.6542',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nSensorCloud: Towards the Interdisciplinary Development of a Trustworthy  Platform for Globally Interconnected Sensors and Actuators',
	 'urllink': u'http://arxiv.org/abs/1310.6542'}
2015-03-24 10:05:09+0000 [xxu46_7] INFO: Crawled 448 pages (at 1 pages/min), scraped 441 items (at 1 items/min)
2015-03-24 10:05:34+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5585> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 10:05:34+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5585>
	{'abstract': u"The standard approach for optimization of XPath queries by rewriting using views techniques consists in navigating inside a view's output, thus allowing the usage of only one view in the rewritten query. Algorithms for richer classes of XPath rewritings, using intersection or joins on node identifiers, have been proposed, but they either lack completeness guarantees, or require additional information about the data. We identify the tightest restrictions under which an XPath can be rewritten in polynomial time using an intersection of views and propose an algorithm that works for any documents or type of identifiers. As a side-effect, we analyze the complexity of the related problem of deciding if an XPath with intersection can be equivalently rewritten as one without intersection or union. We extend our formal study of the view-based rewriting problem for XPath by describing also (i) algorithms for more complex rewrite plans, with no limitations on the number of intersection and navigation steps inside view outputs they employ, and (ii) adaptations of our techniques to deal with XML documents without persistent node Ids, in the presence of XML keys. Complementing our computational complexity study, we describe a proof-of-concept implementation of our techniques and possible choices that may speed up execution in practice, regarding how rewrite plans are built, tested and executed. We also give a thorough experimental evaluation of these techniques, focusing on scalability and the running time improvements achieved by the execution of view-based plans.",
	 'authors': u'Bogdan Cautis, Alin Deutsch, Ioana Ileana, Nicola Onose,',
	 'category': u'Computer Science ',
	 'date': '2013-8-26',
	 'pdflink': u'http://arxiv.org/pdf/1308.5585',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nRewriting XPath Queries using View Intersections: Tractability versus  Completeness',
	 'urllink': u'http://arxiv.org/abs/1308.5585'}
2015-03-24 10:06:09+0000 [xxu46_7] INFO: Crawled 449 pages (at 1 pages/min), scraped 442 items (at 1 items/min)
2015-03-24 10:07:09+0000 [xxu46_7] INFO: Crawled 449 pages (at 0 pages/min), scraped 442 items (at 0 items/min)
2015-03-24 10:07:32+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7140> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 10:07:32+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7140>
	{'abstract': u'In this paper we propose a solution for transmitting digital information within the cardiocirculatory system. In particular, we make use of a channel delivering burst of molecules, emitted by mobile transmitters, which diffuse in the blood towards fixed receivers, that are attached to the vessel walls. This communication scheme has been inspired by the real signaling between platelets and endothelial cells, the behavior of which has been investigated experimentally. We thus believe that our proposal can be successfully deployed in living bodies. On the basis of the results achieved through simulations on the communication system capabilities, we propose a simple but effective receiver scheme, and we outline the future research directions.',
	 'authors': u'Luca Felicetti, Mauro Femminella, Gianluca Reali,',
	 'category': u'Computer Science ',
	 'date': '2013-9-27',
	 'pdflink': u'http://arxiv.org/pdf/1309.7140',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nEstablishing digital molecular communications in blood vessels',
	 'urllink': u'http://arxiv.org/abs/1309.7140'}
2015-03-24 10:08:09+0000 [xxu46_7] INFO: Crawled 450 pages (at 1 pages/min), scraped 443 items (at 1 items/min)
2015-03-24 10:08:45+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6536> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 10:08:45+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6536>
	{'abstract': u'Despite its size and complexity, the human cortex exhibits striking anatomical regularities, suggesting there may simple meta-algorithms underlying cortical learning and computation. We expect such meta-algorithms to be of interest since they need to operate quickly, scalably and effectively with little-to-no specialized assumptions. This note focuses on a specific question: How can neurons use vast quantities of unlabeled data to speed up learning from the comparatively rare labels provided by reward systems? As a partial answer, we propose randomized co-training as a biologically plausible meta-algorithm satisfying the above requirements. As evidence, we describe a biologically-inspired algorithm, Correlated Nystrom Views (XNV) that achieves state-of-the-art performance in semi-supervised learning, and sketch work in progress on a neuronal implementation.',
	 'authors': u'David Balduzzi,',
	 'category': u'Computer Science ',
	 'date': '2013-10-24',
	 'pdflink': u'http://arxiv.org/pdf/1310.6536',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nRandomized co-training: from cortical neurons to machine learning and  back again',
	 'urllink': u'http://arxiv.org/abs/1310.6536'}
2015-03-24 10:09:09+0000 [xxu46_7] INFO: Crawled 451 pages (at 1 pages/min), scraped 444 items (at 1 items/min)
2015-03-24 10:10:05+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5571> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 10:10:05+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5571>
	{'abstract': u'In this paper, novel cooperative automatic repeat request (ARQ) methods with network coding are proposed for two way relaying network. Upon a failed transmission of a packet, the network enters cooperation phase, where the retransmission of the packets is aided by the relay node. The proposed approach integrates network coding into cooperative ARQ, aiming to improve the network throughput by reducing the number of retransmissions. For successive retransmission, three different methods for choosing the retransmitting node are considered. The throughput of the methods are analyzed and compared. The analysis is based on binary Markov channel which takes the correlation of the channel coefficients in time into account. Analytical results show that the proposed use of network coding result in throughput performance superior to traditional ARQ and cooperative ARQ without network coding. It is also observed that correlation can have significant effect on the performance of the proposed cooperative network coded ARQ approach. In particular the proposed approach is advantageous for slow to moderately fast fading channels.',
	 'authors': u'Rasit Tutgun, Emre Aktas,',
	 'category': u'Computer Science ',
	 'date': '2013-8-26',
	 'pdflink': u'http://arxiv.org/pdf/1308.5571',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nCooperative Network Coded ARQ Strategies for Two Way Relay Channel',
	 'urllink': u'http://arxiv.org/abs/1308.5571'}
2015-03-24 10:10:09+0000 [xxu46_7] INFO: Crawled 452 pages (at 1 pages/min), scraped 445 items (at 1 items/min)
2015-03-24 10:11:09+0000 [xxu46_7] INFO: Crawled 452 pages (at 0 pages/min), scraped 445 items (at 0 items/min)
2015-03-24 10:11:59+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7122> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 10:11:59+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7122>
	{'abstract': u'The Wivace 2013 Electronic Proceedings in Theoretical Computer Science (EPTCS) contain some selected long and short articles accepted for the presentation at Wivace 2013 - Italian Workshop on Artificial Life and Evolutionary Computation, which was held at the University of Milan-Bicocca, Milan, on the 1st and 2nd of July, 2013.',
	 'authors': u'Alex Graudenzi, Giulio Caravagna, Giancarlo Mauri, Marco Antoniotti,',
	 'category': u'Computer Science ',
	 'date': '2013-9-27',
	 'pdflink': u'http://arxiv.org/html/1309.7122',
	 'subjects': u'Computational Engineering, Finance, and Science (cs.CE)',
	 'title': u'\nProceedings Wivace 2013 - Italian Workshop on Artificial Life and  Evolutionary Computation',
	 'urllink': u'http://arxiv.org/abs/1309.7122'}
2015-03-24 10:12:09+0000 [xxu46_7] INFO: Crawled 453 pages (at 1 pages/min), scraped 446 items (at 1 items/min)
2015-03-24 10:13:09+0000 [xxu46_7] INFO: Crawled 453 pages (at 0 pages/min), scraped 446 items (at 0 items/min)
2015-03-24 10:13:23+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6524> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 10:13:23+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6524>
	{'abstract': u'We consider parameterised subgraph-counting problems of the following form: given a graph G, how many k-tuples of its vertices have a given property? A number of such problems are known to be #W[1]-complete; here we substantially generalise some of these existing results by proving hardness for two large families of such problems. We demonstrate that it is #W[1]-hard to count the number of k-vertex subgraphs having any property where the number of distinct edge-densities of labelled subgraphs that satisfy the property is o(k^2). In the special case that the property in question depends only on the number of edges in the subgraph, we give a strengthening of this result which leads to our second family of hard problems.',
	 'authors': u'Mark Jerrum, Kitty Meeks,',
	 'category': u'Computer Science ',
	 'date': '2013-10-24',
	 'pdflink': u'http://arxiv.org/pdf/1310.6524',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nSome hard families of parameterised counting problems',
	 'urllink': u'http://arxiv.org/abs/1310.6524'}
2015-03-24 10:14:09+0000 [xxu46_7] INFO: Crawled 454 pages (at 1 pages/min), scraped 447 items (at 1 items/min)
2015-03-24 10:14:39+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5550> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 10:14:39+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5550>
	{'abstract': u'Given a tesselation of the plane, defined by a planar straight-line graph , we want to find a minimal set of points in the plane, such that the Voronoi diagram associated with "fits" . This is the Generalized Inverse Voronoi Problem (GIVP), defined in cite and rediscovered recently in cite. Here we give an algorithm that solves this problem with a number of points that is linear in the size of , assuming that the smallest angle in is constant.',
	 'authors': u'Greg Aloupis, Hebert P\xe9rez-Ros\xe9s, Guillermo Pineda-Villavicencio, Perouz Taslakian, Dannier Trinchet,',
	 'category': u'Computer Science ',
	 'date': '2013-8-26',
	 'pdflink': u'http://arxiv.org/pdf/1308.5550',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nFitting Voronoi Diagrams to Planar Tesselations',
	 'urllink': u'http://arxiv.org/abs/1308.5550'}
2015-03-24 10:15:09+0000 [xxu46_7] INFO: Crawled 455 pages (at 1 pages/min), scraped 448 items (at 1 items/min)
2015-03-24 10:16:09+0000 [xxu46_7] INFO: Crawled 455 pages (at 0 pages/min), scraped 448 items (at 0 items/min)
2015-03-24 10:16:31+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7119> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 10:16:31+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7119>
	{'abstract': u'The prediction of a stock market direction may serve as an early recommendation system for short-term investors and as an early financial distress warning system for long-term shareholders. In this paper, we propose an empirical study on the Korean and Hong Kong stock market with an integrated machine learning framework that employs Principal Component Analysis (PCA) and Support Vector Machine (SVM). We try to predict the upward or downward direction of stock market index and stock price. In the proposed framework, PCA, as a feature selection method, identifies principal components in the stock market movement and SVM, as a classifier for future stock market movement, processes them along with other economic factors in training and forecasting. We present the results of an extensive empirical study of the proposed method on the Korean composite stock price index (KOSPI) and Hangseng index (HSI), as well as the individual constituents included in the indices. In our experiment, ten years data (from January 1st, 2002 to January 1st, 2012) are collected and schemed by rolling windows to predict one-day-ahead directions. The experimental results show notably high hit ratios in predicting the movements of the individual constituents in the KOSPI and HSI. The results also varify the textit effect between the Korean (Hong Kong) stock market and the American stock market.',
	 'authors': u'Yanshan Wang, In-Chan Choi,',
	 'category': u'Computer Science ',
	 'date': '2013-9-27',
	 'pdflink': u'http://arxiv.org/pdf/1309.7119',
	 'subjects': u'Computational Engineering, Finance, and Science (cs.CE)',
	 'title': u'\nMarket Index and Stock Price Direction Prediction using Machine Learning  Techniques: An empirical study on the KOSPI and HSI',
	 'urllink': u'http://arxiv.org/abs/1309.7119'}
2015-03-24 10:17:09+0000 [xxu46_7] INFO: Crawled 456 pages (at 1 pages/min), scraped 449 items (at 1 items/min)
2015-03-24 10:17:33+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6516> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 10:17:33+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6516>
	{'abstract': u'From the perspective of reindustrialization, it is important to understand the evolution of the structure of the network of organizations employment structure, and organization value. Understanding the potential influence of collaborative networks (CNs) on these aspects may lead to the development of appropriate economic policies. In this paper, we propose a theoretical approach to analysis this potential influence, based on a model of dynamic networked ecosystem of organizations encompassing collaboration relations among organization, employment mobility, and organization value. A large number of simulations has been performed to identify factors influencing the structure of the network of organizations employment structure, and organization value. The main findings are that 1) the higher the number of members of CNs, the better the clustering and the shorter the average path length among organizations; 2) the constitution of CNs does not affect neither the structure of the network of organizations, nor the employment structure and the organization value.',
	 'authors': u'Willy Picard,',
	 'category': u'Computer Science ',
	 'date': '2013-10-24',
	 'pdflink': u'http://arxiv.org/pdf/1310.6516',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nSimulating the Influence of Collaborative Networks on the Structure of  Networks of Organizations, Employment Structure, and Organization Value',
	 'urllink': u'http://arxiv.org/abs/1310.6516'}
2015-03-24 10:18:09+0000 [xxu46_7] INFO: Crawled 457 pages (at 1 pages/min), scraped 450 items (at 1 items/min)
2015-03-24 10:19:09+0000 [xxu46_7] INFO: Crawled 457 pages (at 0 pages/min), scraped 450 items (at 0 items/min)
2015-03-24 10:19:13+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5506> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 10:19:13+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5506>
	{'abstract': u'We study, in the context of algorithmic randomness, the closed amenable subgroups of the symmetric group of a countable set. In this paper we address this problem by investigating a link between the symmetries associated with Ramsey Fra "iss \'e order classes and algorithmic randomness.',
	 'authors': u'Willem L. Fouch\xe9,',
	 'category': u'Computer Science ',
	 'date': '2013-8-26',
	 'pdflink': u'http://arxiv.org/pdf/1308.5506',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nAlgorithmic randomness and Ramsey properties of countable homogeneous  structures',
	 'urllink': u'http://arxiv.org/abs/1308.5506'}
2015-03-24 10:20:09+0000 [xxu46_7] INFO: Crawled 458 pages (at 1 pages/min), scraped 451 items (at 1 items/min)
2015-03-24 10:20:59+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7109> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 10:20:59+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7109>
	{'abstract': u'We present a novel class of divergences induced by a smooth convex function called total Jensen divergences. Those total Jensen divergences are invariant by construction to rotations, a feature yielding regularization of ordinary Jensen divergences by a conformal factor. We analyze the relationships between this novel class of total Jensen divergences and the recently introduced total Bregman divergences. We then proceed by defining the total Jensen centroids as average distortion minimizers, and study their robustness performance to outliers. Finally, we prove that the k-means++ initialization that bypasses explicit centroid computations is good enough in practice to guarantee probabilistically a constant approximation factor to the optimal k-means clustering.',
	 'authors': u'Frank Nielsen, Richard Nock,',
	 'category': u'Computer Science ',
	 'date': '2013-9-27',
	 'pdflink': u'http://arxiv.org/pdf/1309.7109',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nTotal Jensen divergences: Definition, Properties and k-Means++  Clustering',
	 'urllink': u'http://arxiv.org/abs/1309.7109'}
2015-03-24 10:21:09+0000 [xxu46_7] INFO: Crawled 459 pages (at 1 pages/min), scraped 452 items (at 1 items/min)
2015-03-24 10:22:09+0000 [xxu46_7] INFO: Crawled 459 pages (at 0 pages/min), scraped 452 items (at 0 items/min)
2015-03-24 10:22:41+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6511> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 10:22:41+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6511>
	{'abstract': u'Energy harvesting (EH) from ambient radio-frequency (RF) electromagnetic waves is an efficient solution for fully autonomous and sustainable communication networks. Most of the related works presented in the literature are based on specific (and small-scale) network structures, which although give useful insights on the potential benefits of the RF-EH technology, cannot characterize the performance of general networks. In this paper, we adopt a large-scale approach of the RF-EH technology and we characterize the performance of a network with random number of transmitter-receiver pairs by using stochastic-geometry tools. Specifically, we analyze the outage probability performance and the average harvested energy, when receivers employ power splitting (PS) technique for "simultaneous" information and energy transfer. A non-cooperative scheme, where information/energy are conveyed only via direct links, is firstly considered and the outage performance of the system as well as the average harvested energy are derived in closed form in function of the power splitting. For this protocol, an interesting optimization problem which minimizes the transmitted power under outage probability and harvesting constraints, is formulated and solved in closed form. In addition, we study a cooperative protocol where sources\' transmissions are supported by a random number of potential relays that are randomly distributed into the network. In this case, information/energy can be received at each destination via two independent and orthogonal paths (in case of relaying). We characterize both performance metrics, when a selection combining scheme is applied at the receivers and a single relay is randomly selected for cooperative diversity.',
	 'authors': u'Ioannis Krikidis,',
	 'category': u'Computer Science ',
	 'date': '2013-10-24',
	 'pdflink': u'http://arxiv.org/pdf/1310.6511',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nSimultaneous Information and Energy Transfer in Large-Scale Networks  with/without Relaying',
	 'urllink': u'http://arxiv.org/abs/1310.6511'}
2015-03-24 10:23:09+0000 [xxu46_7] INFO: Crawled 460 pages (at 1 pages/min), scraped 453 items (at 1 items/min)
2015-03-24 10:24:09+0000 [xxu46_7] INFO: Crawled 460 pages (at 0 pages/min), scraped 453 items (at 0 items/min)
2015-03-24 10:24:14+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5499> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 10:24:14+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5499>
	{'abstract': u'This text is a conceptual introduction to mixed effects modeling with linguistic applications, using the R programming environment. The reader is introduced to linear modeling and assumptions, as well as to mixed effects/multilevel modeling, including a discussion of random intercepts, random slopes and likelihood ratio tests. The example used throughout the text focuses on the phonetic analysis of voice pitch data.',
	 'authors': u'Bodo Winter,',
	 'category': u'Computer Science ',
	 'date': '2013-8-26',
	 'pdflink': u'http://arxiv.org/pdf/1308.5499',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nLinear models and linear mixed effects models in R with linguistic  applications',
	 'urllink': u'http://arxiv.org/abs/1308.5499'}
2015-03-24 10:25:09+0000 [xxu46_7] INFO: Crawled 461 pages (at 1 pages/min), scraped 454 items (at 1 items/min)
2015-03-24 10:26:09+0000 [xxu46_7] INFO: Crawled 461 pages (at 0 pages/min), scraped 454 items (at 0 items/min)
2015-03-24 10:26:12+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7102> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 10:26:12+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7102>
	{'abstract': u'In this paper, we study the performance of finite-length LDPC codes in the waterfall region. We propose an algorithm to predict the error performance of finite-length LDPC codes over various binary memoryless channels. Through numerical results, we find that our technique gives better performance prediction compared to existing techniques.',
	 'authors': u'Md. Noor-A-Rahim, Khoa D. Nguyen, Gottfried Lechner,',
	 'category': u'Computer Science ',
	 'date': '2013-9-27',
	 'pdflink': u'http://arxiv.org/pdf/1309.7102',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nFinite Length Analysis of LDPC Codes',
	 'urllink': u'http://arxiv.org/abs/1309.7102'}
2015-03-24 10:27:09+0000 [xxu46_7] INFO: Crawled 462 pages (at 1 pages/min), scraped 455 items (at 1 items/min)
2015-03-24 10:27:51+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6502> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 10:27:51+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6502>
	{'abstract': u'The rapid growth of data volume brings big challenges to the data center computing, and energy efficiency is one of the most concerned problems. Researchers from various fields are now proposing solutions to green the data center operations. Power usage effectiveness metric plays an important role in the energy saving research. However, the exising usage effectiveness metrics focus on measuring the relationship between the total facility energy consumed and the IT equipment energy consumed, without reflecting the energy efficiency of applications. In this paper, we analyze the requirements of application-level metrics for power usage efficiency of the data centers, and propose two novel energy efficiency metrics to provide strong guidance and useful insight to data center design and optimization. We conduct comprehensive experiments in the practical data centers using BigDataBench, a big data benchmark suite, and the results demonstrate the rationality and efficiency of AxPUE in measuring the actual computation energy consumption in data centers.',
	 'authors': u'Runlin Zhou, Yingjie Shi, Chunge Zhu, Fan Liu,',
	 'category': u'Computer Science ',
	 'date': '2013-10-24',
	 'pdflink': u'http://arxiv.org/pdf/1310.6502',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nAxPUE: Application Level Metrics for Power Usage Effectiveness in Data  Centers',
	 'urllink': u'http://arxiv.org/abs/1310.6502'}
2015-03-24 10:28:09+0000 [xxu46_7] INFO: Crawled 463 pages (at 1 pages/min), scraped 456 items (at 1 items/min)
2015-03-24 10:29:09+0000 [xxu46_7] INFO: Crawled 463 pages (at 0 pages/min), scraped 456 items (at 0 items/min)
2015-03-24 10:29:20+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5480> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 10:29:20+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5480>
	{'abstract': u'Pressing questions in cosmology such as the nature of dark matter and dark energy can be addressed using large galaxy surveys, which measure the positions, properties and redshifts of galaxies in order to map the large-scale structure of the Universe. We review the Fourier-Laguerre transform, a novel transform in 3D spherical coordinates which is based on spherical harmonics combined with damped Laguerre polynomials and appropriate for analysing galaxy surveys. We also recall the construction of flaglets, 3D wavelets obtained through a tiling of the Fourier-Laguerre space, which can be used to extract scale-dependent, spatially localised features on the ball. We exploit a sampling theorem to obtain exact Fourier-Laguerre and flaglet transforms, such that band-limited signals can analysed and reconstructed at floating point accuracy on a finite number of voxels on the ball. We present a potential application of the flaglet transform for finding voids in galaxy surveys and studying the large-scale structure of the Universe.',
	 'authors': u'Boris Leistedt, Hiranya V. Peiris, Jason D. McEwen,',
	 'category': u'Computer Science ',
	 'date': '2013-8-26',
	 'pdflink': u'http://arxiv.org/pdf/1308.5480',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nFlaglets for studying the large-scale structure of the Universe',
	 'urllink': u'http://arxiv.org/abs/1308.5480'}
2015-03-24 10:30:09+0000 [xxu46_7] INFO: Crawled 464 pages (at 1 pages/min), scraped 457 items (at 1 items/min)
2015-03-24 10:31:09+0000 [xxu46_7] INFO: Crawled 464 pages (at 0 pages/min), scraped 457 items (at 0 items/min)
2015-03-24 10:31:18+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7099> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 10:31:18+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7099>
	{'abstract': u'The Academic Ranking of World Universities (ARWU) published by researchers at Shanghai Jiao Tong University has become a major source of information for university administrators, country officials, students and the public at large. Recent discoveries regarding its internal dynamics allow the inversion of published ARWU indicator scores to reconstruct raw scores for five hundred world class universities. This paper explores raw scores in the ARWU and in other contests to contrast the dynamics of rank-driven and score-driven tables, and to explain why the ARWU ranking is a score-driven procedure. We show that the ARWU indicators constitute sub-scales of a single factor accounting for research performance, and provide an account of the system of gains and non-linearities used by ARWU. The paper discusses the non-linearities selected by ARWU, concluding that they are designed to represent the regressive character of indicators measuring research performance. We propose that the utility and usability of the ARWU could be greatly improved by replacing the unwanted dynamical effects of the annual re-scaling based on raw scores of the best performers.',
	 'authors': u'Domingo Docampo, Lawrence Cram,',
	 'category': u'Computer Science ',
	 'date': '2013-9-27',
	 'pdflink': u'http://arxiv.org/pdf/1309.7099',
	 'subjects': u'Digital Libraries (cs.DL)',
	 'title': u'\nOn the Internal Dynamics of the Shanghai Ranking',
	 'urllink': u'http://arxiv.org/abs/1309.7099'}
2015-03-24 10:32:09+0000 [xxu46_7] INFO: Crawled 465 pages (at 1 pages/min), scraped 458 items (at 1 items/min)
2015-03-24 10:33:09+0000 [xxu46_7] INFO: Crawled 465 pages (at 0 pages/min), scraped 458 items (at 0 items/min)
2015-03-24 10:33:14+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6486> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 10:33:14+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6486>
	{'abstract': u'Research capacity is critical in understanding systemic risk and informing new regulation. Banking regulation has not kept pace with all the complexities of financial innovation. The academic literature on systemic risk is rapidly expanding. The majority of papers analyse a single source or a consolidated source of risk and its effect. A fraction of publications quantify systemic risk measures or formulate penalties for systemically important financial institutions that are of practical regulatory relevance. The challenges facing systemic risk evaluation and regulation still persist, as the definition of systemic risk is somewhat unsettled and that affects attempts to provide solutions. Our understanding of systemic risk is evolving and the awareness of data relevance is rising gradually; this challenge is reflected in the focus of major international research initiatives. There is a consensus that the direct and indirect costs of a systemic crisis are enormous as opposed to preventing it, and that without regulation the externalities will not be prevented; but there is no consensus yet on the extent and detail of regulation, and research expectations are to facilitate the regulatory process. This report outlines an integrated approach for systemic risk evaluation based on multiple types of interbank exposures through innovative modelling approaches as tensorial multilayer networks, suggests how to relate underlying economic data and how to extend the network to cover financial market information. We reason about data requirements and time scale effects, and outline a multi-model hypernetwork of systemic risk knowledge as a scenario analysis and policy support tool. The argument is that logical steps forward would incorporate the range of risk sources and their interrelated effects as contributions towards an overall systemic risk indicator, would perform an integral analysis of ...',
	 'authors': u'Antoaneta Sergueiva,',
	 'category': u'Computer Science ',
	 'date': '2013-10-24',
	 'pdflink': u'http://arxiv.org/pdf/1310.6486',
	 'subjects': u'Computational Engineering, Finance, and Science (cs.CE)',
	 'title': u'\nSystemic Risk Identification, Modelling, Analysis, and Monitoring: An  Integrated Approach',
	 'urllink': u'http://arxiv.org/abs/1310.6486'}
2015-03-24 10:34:09+0000 [xxu46_7] INFO: Crawled 466 pages (at 1 pages/min), scraped 459 items (at 1 items/min)
2015-03-24 10:34:52+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5447> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 10:34:52+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5447>
	{'abstract': u'The phase retrieval problem has a long history and is an important problem in many areas of optics. Theoretical understanding of phase retrieval is still limited and fundamental questions such as uniqueness and stability of the recovered solution are not yet fully understood. This paper provides several additions to the theoretical understanding of sparse phase retrieval. In particular we show that if the measurement ensemble can be chosen freely, as few as 4k-1 phaseless measurements suffice to guarantee uniqueness of a k-sparse M-dimensional real solution. We also prove that 2(k^2-k+1) Fourier magnitude measurements are sufficient under rather general conditions.',
	 'authors': u'Henrik Ohlsson, Yonina C. Eldar,',
	 'category': u'Computer Science ',
	 'date': '2013-8-25',
	 'pdflink': u'http://arxiv.org/pdf/1308.5447',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOn Conditions for Uniqueness in Sparse Phase Retrieval',
	 'urllink': u'http://arxiv.org/abs/1308.5447'}
2015-03-24 10:35:09+0000 [xxu46_7] INFO: Crawled 467 pages (at 1 pages/min), scraped 460 items (at 1 items/min)
2015-03-24 10:36:09+0000 [xxu46_7] INFO: Crawled 467 pages (at 0 pages/min), scraped 460 items (at 0 items/min)
2015-03-24 10:36:13+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7084> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 10:36:13+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7084>
	{'abstract': u'The Chord algorithm is a popular, simple method for the succinct approximation of curves, which is widely used, under different names, in a variety of areas, such as, multiobjective and parametric optimization, computational geometry, and graphics. We analyze the performance of the Chord algorithm, as compared to the optimal approximation that achieves a desired accuracy with the minimum number of points. We prove sharp upper and lower bounds, both in the worst case and average case setting.',
	 'authors': u'Constantinos Daskalakis, Ilias Diakonikolas, Mihalis Yannakakis,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.7084',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nHow good is the Chord algorithm?',
	 'urllink': u'http://arxiv.org/abs/1309.7084'}
2015-03-24 10:37:09+0000 [xxu46_7] INFO: Crawled 468 pages (at 1 pages/min), scraped 461 items (at 1 items/min)
2015-03-24 10:38:03+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6485> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 10:38:03+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6485>
	{'abstract': u'Polar codes are a new class of error correcting linear block codes, whose generator matrix is specified by the knowledge of transmission channel parameters, code length and code dimension. Moreover, regarding computational security, it is assumed that an attacker with a restricted processing power has unlimited access to the transmission media. Therefore, the attacker can construct the generator matrix of polar codes, especially in the case of Binary Erasure Channels, on which this matrix can be easily constructed. In this paper, we introduce a novel method to keep the generator matrix of polar codes in secret in a way that the attacker cannot access the required information to decode the intended polar code. With the help of this method, a secret key cryptosystem is proposed based on non-systematic polar codes. In fact, the main objective of this study is to achieve an acceptable level of security and reliability through taking advantage of the special properties of polar codes. The analyses revealed that our scheme resists the typical attacks on the secret key cryptosystems based on linear block codes. In addition, by employing some efficient methods, the key length of the proposed scheme is decreased compared to that of the previous cryptosystems. Moreover, this scheme enjoys other advantages including high code rate, and proper error performance as well.',
	 'authors': u'Reza Hooshmand,',
	 'category': u'Computer Science ',
	 'date': '2013-10-24',
	 'pdflink': u'http://arxiv.org/pdf/1310.6485',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nSecret Key Cryptosystem based on Non-Systematic Polar Codes',
	 'urllink': u'http://arxiv.org/abs/1310.6485'}
2015-03-24 10:38:09+0000 [xxu46_7] INFO: Crawled 469 pages (at 1 pages/min), scraped 462 items (at 1 items/min)
2015-03-24 10:39:09+0000 [xxu46_7] INFO: Crawled 469 pages (at 0 pages/min), scraped 462 items (at 0 items/min)
2015-03-24 10:40:03+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5444> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 10:40:03+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5444>
	{'abstract': u'We present a unified framework for designing and analyzing algorithms for online budgeted allocation problems (including online matching) and their generalization, the Online Generalized Assignment Problem (OnGAP). These problems have been intensively studied as models of how to allocate impressions for online advertising. In contrast to previous analyses of online budgeted allocation algorithms (the so-called "balance" or "water-filling" family of algorithms) our analysis is based on the method of randomized dual fitting, analogous to the recent analysis of the RANKING algorithm for online matching due to Devanur et al. Our main contribution is thus to provide a unified method of proof that simultaneously derives the optimal competitive ratio bounds for online matching and online fractional budgeted allocation. The same method of proof also supplies competitive ratio bounds for greedy algorithms for both problems, in the random order arrival model; this simplifies existing analyses of greedy online allocation algorithms with random order of arrivals, while also strengthening them to apply to a larger family of greedy algorithms. Finally, for the more general OnGAP problem, we show that no algorithm can be constant-competitive; instead we present an algorithm whose competitive ratio depends logarithmically on a certain parameter of the problem instance, and we show that this dependence cannot be improved.',
	 'authors': u'Rad Niazadeh, Robert D. Kleinberg,',
	 'category': u'Computer Science ',
	 'date': '2013-8-25',
	 'pdflink': u'http://arxiv.org/pdf/1308.5444',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nA Unified Approach to Online Allocation Algorithms via Randomized Dual  Fitting',
	 'urllink': u'http://arxiv.org/abs/1308.5444'}
2015-03-24 10:40:09+0000 [xxu46_7] INFO: Crawled 470 pages (at 1 pages/min), scraped 463 items (at 1 items/min)
2015-03-24 10:41:09+0000 [xxu46_7] INFO: Crawled 470 pages (at 0 pages/min), scraped 463 items (at 0 items/min)
2015-03-24 10:41:56+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7082> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 10:41:56+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7082>
	{'abstract': u'In recent years, the size and leakage energy consumption of large last level caches (LLCs) has increased. To address this, embedded DRAM (eDRAM) caches have been considered which have lower leakage energy consumption; however eDRAM caches consume a significant amount of energy in the form of refresh energy. In this paper, we present a technique for saving both leakage and refresh energy in eDRAM caches. We use dynamic cache reconfiguration approach to intelligently turn-off part of the cache to save leakage energy and refresh only valid data of the active (i.e. not turned-off) cache to save refresh energy. We evaluate our technique using an x86-64 simulator and SPEC2006 benchmarks and compare it with a recently proposed technique for saving refresh energy, named Refrint. The experiments have shown that our technique provides better performance and energy efficiency than Refrint. Using our technique, for a 2MB LLC and 40 micro-seconds eDRAM refresh period, the average saving in energy over eDRAM baseline (which periodically refreshes all cache lines) is 22.8%.',
	 'authors': u'Sparsh Mittal,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.7082',
	 'subjects': u'Hardware Architecture (cs.AR)',
	 'title': u'\nA Cache Reconfiguration Approach for Saving Leakage and Refresh Energy  in Embedded DRAM Caches',
	 'urllink': u'http://arxiv.org/abs/1309.7082'}
2015-03-24 10:42:09+0000 [xxu46_7] INFO: Crawled 471 pages (at 1 pages/min), scraped 464 items (at 1 items/min)
2015-03-24 10:43:09+0000 [xxu46_7] INFO: Crawled 471 pages (at 0 pages/min), scraped 464 items (at 0 items/min)
2015-03-24 10:43:19+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6481> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 10:43:19+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6481>
	{'abstract': u'A barrier certificate can separate the state space of a con- sidered hybrid system (HS) into safe and unsafe parts ac- cording to the safety property to be verified. Therefore this notion has been widely used in the verification of HSs. A stronger condition on barrier certificates means that less expressive barrier certificates can be synthesized. On the other hand, synthesizing more expressive barrier certificates often means high complexity. In [9], Kong et al consid- ered how to relax the condition of barrier certificates while still keeping their convexity so that one can synthesize more expressive barrier certificates efficiently using semi-definite programming (SDP). In this paper, we first discuss how to relax the condition of barrier certificates in a general way, while still keeping their convexity. Particularly, one can then utilize different weaker conditions flexibly to synthesize dif- ferent kinds of barrier certificates with more expressiveness efficiently using SDP. These barriers give more opportuni- ties to verify the considered system. We also show how to combine two functions together to form a combined barrier certificate in order to prove a safety property under consid- eration, whereas neither of them can be used as a barrier certificate separately, even according to any relaxed condi- tion. Another contribution of this paper is that we discuss how to discover certificates from the general relaxed condi- tion by SDP. In particular, we focus on how to avoid the unsoundness because of numeric error caused by SDP with symbolic checking',
	 'authors': u'Liyun Dai, Ting Gan, Bican Xia, Naijun Zhan,',
	 'category': u'Computer Science ',
	 'date': '2013-10-24',
	 'pdflink': u'http://arxiv.org/pdf/1310.6481',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nBarrier Certificates Revisited',
	 'urllink': u'http://arxiv.org/abs/1310.6481'}
2015-03-24 10:44:09+0000 [xxu46_7] INFO: Crawled 472 pages (at 1 pages/min), scraped 465 items (at 1 items/min)
2015-03-24 10:45:01+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5434> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 10:45:01+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5434>
	{'abstract': u'The robust principles of treating interference as noise (TIN) when it is sufficiently weak, and avoiding it when it is not, form the background for this work. Combining TIN with the topological interference management (TIM) framework that identifies optimal interference avoidance schemes, a baseline TIM-TIN approach is proposed which decomposes a network into TIN and TIM components, allocates the signal power levels to each user in the TIN component, allocates signal vector space dimensions to each user in the TIM component, and guarantees that the product of the two is an achievable number of signal dimensions available to each user in the original network.',
	 'authors': u'Chunhua Geng, Hua Sun, Syed A. Jafar,',
	 'category': u'Computer Science ',
	 'date': '2013-8-25',
	 'pdflink': u'http://arxiv.org/pdf/1308.5434',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nMultilevel Topological Interference Management',
	 'urllink': u'http://arxiv.org/abs/1308.5434'}
2015-03-24 10:45:09+0000 [xxu46_7] INFO: Crawled 473 pages (at 1 pages/min), scraped 466 items (at 1 items/min)
2015-03-24 10:46:09+0000 [xxu46_7] INFO: Crawled 473 pages (at 0 pages/min), scraped 466 items (at 0 items/min)
2015-03-24 10:46:38+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7068> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 10:46:38+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7068>
	{'abstract': u'Graphical Models have various applications in science and engineering which include physics, bioinformatics, telecommunication and etc. Usage of graphical models needs complex computations in order to evaluation of marginal functions,so there are some powerful methods including mean field approximation, belief propagation algorithm and etc. Quantum graphical models have been recently developed in context of quantum information and computation, and quantum statistical physics, which is possible by generalization of classical probability theory to quantum theory. The main goal of this paper is preparing a primary generalization of Markov network, as a type of graphical models, to quantum case and applying in quantum statistical physics.We have investigated the Markov network and the role of commuting Hamiltonian terms in conditional independence with simple examples of quantum statistical physics.',
	 'authors': u'Farzad Ghafari Jouneghani, Mohammad Babazadeh, Rogayeh Bayramzadeh, Hossein Movla,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.7068',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nInvestigation of commuting Hamiltonian in quantum Markov network',
	 'urllink': u'http://arxiv.org/abs/1309.7068'}
2015-03-24 10:47:09+0000 [xxu46_7] INFO: Crawled 474 pages (at 1 pages/min), scraped 467 items (at 1 items/min)
2015-03-24 10:48:09+0000 [xxu46_7] INFO: Crawled 474 pages (at 0 pages/min), scraped 467 items (at 0 items/min)
2015-03-24 10:48:18+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6443> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 10:48:18+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6443>
	{'abstract': u"In most wireless networks, nodes have only limited local information about the state of the network, which includes connectivity and channel state information. With limited local information about the network, each node's knowledge is mismatched; therefore, they must make distributed decisions. In this paper, we pose the following question - if every node has network state information only about a small neighborhood, how and when should nodes choose to transmit? While link scheduling answers the above question for point-to-point physical layers which are designed for an interference-avoidance paradigm, we look for answers in cases when interference can be embraced by advanced PHY layer design, as suggested by results in network information theory. To make progress on this challenging problem, we propose a constructive distributed algorithm that achieves rates higher than link scheduling based on interference avoidance, especially if each node knows more than one hop of network state information. We compare our new aggressive algorithm to a conservative algorithm we have presented in [1]. Both algorithms schedule sub-networks such that each sub-network can employ advanced interference-embracing coding schemes to achieve higher rates. Our innovation is in the identification, selection and scheduling of sub-networks, especially when sub-networks are larger than a single link.",
	 'authors': u'Pedro E. Santacruz, Vaneet Aggarwal, Ashutosh Sabharwal,',
	 'category': u'Computer Science ',
	 'date': '2013-10-24',
	 'pdflink': u'http://arxiv.org/pdf/1310.6443',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nLeveraging Physical Layer Capabilites: Distributed Scheduling in  Interference Networks with Local Views',
	 'urllink': u'http://arxiv.org/abs/1310.6443'}
2015-03-24 10:49:09+0000 [xxu46_7] INFO: Crawled 475 pages (at 1 pages/min), scraped 468 items (at 1 items/min)
2015-03-24 10:50:08+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5423> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 10:50:08+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5423>
	{'abstract': u'Stemming is the process of extracting root word from the given inflection word. It also plays significant role in numerous application of Natural Language Processing (NLP). The stemming problem has addressed in many contexts and by researchers in many disciplines. This expository paper presents survey of some of the latest developments on stemming algorithms in data mining and also presents with some of the solutions for various Indian language stemming algorithms along with the results.',
	 'authors': u'M.Thangarasu, R.Manavalan,',
	 'category': u'Computer Science ',
	 'date': '2013-8-25',
	 'pdflink': u'http://arxiv.org/pdf/1308.5423',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nA Literature Review: Stemming Algorithms for Indian Languages',
	 'urllink': u'http://arxiv.org/abs/1308.5423'}
2015-03-24 10:50:09+0000 [xxu46_7] INFO: Crawled 476 pages (at 1 pages/min), scraped 469 items (at 1 items/min)
2015-03-24 10:51:09+0000 [xxu46_7] INFO: Crawled 476 pages (at 0 pages/min), scraped 469 items (at 0 items/min)
2015-03-24 10:52:01+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7066> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 10:52:01+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7066>
	{'abstract': u'With high throughput networks acquiring a crucial role in supporting data-intensive applications, a variety of data center network topologies have been proposed to achieve high capacity at low cost. While this literature explores a large number of design points, even in the limited case of a network of identical switches, no proposal has been able to claim any notion of optimality. The case of heterogeneous networks, incorporating multiple line-speeds and port-counts as data centers grow over time, introduces even greater complexity. In this paper, we present the first non-trivial upper-bound on network throughput under uniform traffic patterns for any topology with identical switches. We then show that random graphs achieve throughput surprisingly close to this bound, within a few percent at the scale of a few thousand servers. Apart from demonstrating that homogeneous topology design may be reaching its limits, this result also motivates our use of random graphs as building blocks to explore the design of heterogeneous networks. Given a heterogeneous pool of network switches, through experiments and analysis, we explore how the distribution of servers across switches and the interconnection of switches affect network throughput. We apply these insights to a real-world heterogeneous data center topology, VL2, demonstrating as much as 43% higher throughput with the same equipment.',
	 'authors': u'Ankit Singla, P. Brighten Godfrey, Alexandra Kolla,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.7066',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nHigh Throughput Data Center Topology Design',
	 'urllink': u'http://arxiv.org/abs/1309.7066'}
2015-03-24 10:52:09+0000 [xxu46_7] INFO: Crawled 477 pages (at 1 pages/min), scraped 470 items (at 1 items/min)
2015-03-24 10:53:09+0000 [xxu46_7] INFO: Crawled 477 pages (at 0 pages/min), scraped 470 items (at 0 items/min)
2015-03-24 10:53:13+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6441> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 10:53:13+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6441>
	{'abstract': u'In this paper, we present an epistemic logic approach to the compositionality of several privacy-related informationhiding/ disclosure properties. The properties considered here are anonymity, privacy, onymity, and identity. Our initial observation reveals that anonymity and privacy are not necessarily sequentially compositional; this means that even though a system comprising several sequential phases satisfies a certain unlinkability property in each phase, the entire system does not always enjoy a desired unlinkability property. We show that the compositionality can be guaranteed provided that the phases of the system satisfy what we call the independence assumptions. More specifically, we develop a series of theoretical case studies of what assumptions are sufficient to guarantee the sequential compositionality of various degrees of anonymity, privacy, onymity, and/or identity properties. Similar results for parallel composition are also discussed.',
	 'authors': u'Yasuyuki Tsukada, Hideki Sakurada, Ken Mano, Yoshifumi Manabe,',
	 'category': u'Computer Science ',
	 'date': '2013-10-24',
	 'pdflink': u'http://arxiv.org/pdf/1310.6441',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nAn Epistemic Approach to Compositional Reasoning about Anonymity and  Privacy',
	 'urllink': u'http://arxiv.org/abs/1310.6441'}
2015-03-24 10:54:09+0000 [xxu46_7] INFO: Crawled 478 pages (at 1 pages/min), scraped 471 items (at 1 items/min)
2015-03-24 10:55:04+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5421> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 10:55:04+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5421>
	{'abstract': u'This paper proposes a measurement approach for estimating the privacy leakage from Intrusion Detection System (IDS) alarms. Quantitative information flow analysis is used to build a theoretical model of privacy leakage from IDS rules, based on information entropy. This theoretical model is subsequently verified empirically both based on simulations and in an experimental study. The analysis shows that the metric is able to distinguish between IDS rules that have no or low expected privacy leakage and IDS rules with a significant risk of leaking sensitive information, for example on user behaviour. The analysis is based on measurements of number of IDS alarms, data length and data entropy for relevant parts of IDS rules (for example payload). This is a promising approach that opens up for privacy benchmarking of Managed Security Service providers.',
	 'authors': u'Nils Ulltveit-Moe, Vladimir Oleshchuk,',
	 'category': u'Computer Science ',
	 'date': '2013-8-25',
	 'pdflink': u'http://arxiv.org/pdf/1308.5421',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nMeasuring Privacy Leakage for IDS Rules',
	 'urllink': u'http://arxiv.org/abs/1308.5421'}
2015-03-24 10:55:09+0000 [xxu46_7] INFO: Crawled 479 pages (at 1 pages/min), scraped 472 items (at 1 items/min)
2015-03-24 10:56:09+0000 [xxu46_7] INFO: Crawled 479 pages (at 0 pages/min), scraped 472 items (at 0 items/min)
2015-03-24 10:57:02+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7063> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 10:57:02+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7063>
	{'abstract': u'Being an emerging business practice, gamification is going to the mainstream to enable and transform social business initiatives across enterprises. With the consistent focus on customer behavior and experience, there is a paradigm shift in thinking about how Gamification and Social initiatives together help to increase the engagement level of knowledge worker, yielding better business results. Business scenarios for gamification are wide spread ranging from customer service and support to communities and collaboration. The Paper discusses the characteristics &amp; mechanism to learn from games that are important for businesses to understand and apply. It also gives insights on gamification trends, real-world business challenges and also describes on how game thinking can revolutionize the business and create an engaging experience.',
	 'authors': u'Jitendra Maan,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.7063',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nSocial Business Transformation through Gamification',
	 'urllink': u'http://arxiv.org/abs/1309.7063'}
2015-03-24 10:57:09+0000 [xxu46_7] INFO: Crawled 480 pages (at 1 pages/min), scraped 473 items (at 1 items/min)
2015-03-24 10:58:09+0000 [xxu46_7] INFO: Crawled 480 pages (at 0 pages/min), scraped 473 items (at 0 items/min)
2015-03-24 10:58:57+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6440> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 10:58:58+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6440>
	{'abstract': u"This paper presents a two-dimensional modal logic for reasoning about the changing patterns of knowledge and social relationships in networks organised on the basis of a symmetric 'friendship' relation, providing a precise language for exploring 'logic in the community' [11]. Agents are placed in the model, allowing us to express such indexical facts as 'I am your friend' and 'You, my friends, are in danger'. The technical framework for this work is general dynamic dynamic logic (GDDL) [4], which provides a general method for extending modal logics with dynamic operators for reasoning about a wide range of model-transformations, starting with those definable in propositional dynamic logic (PDL) and extended to allow for the more subtle operators involved in, for example, private communication, as represented in dynamic epistemic logic (DEL) and related systems. We provide a hands-on introduction to GDDL, introducing elements of the formalism as we go, but leave the reader to consult [4] for technical details. Instead, the purpose of this paper is to investigate a number of conceptual issues that arise when considering communication between agents in such networks, both from one agent to another, and broadcasts to socially-defined groups of agents, such as the group of my friends.",
	 'authors': u'Jeremy Seligman, Fenrong Liu, Patrick Girard,',
	 'category': u'Computer Science ',
	 'date': '2013-10-24',
	 'pdflink': u'http://arxiv.org/pdf/1310.6440',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nFacebook and the Epistemic Logic of Friendship',
	 'urllink': u'http://arxiv.org/abs/1310.6440'}
2015-03-24 10:59:09+0000 [xxu46_7] INFO: Crawled 481 pages (at 1 pages/min), scraped 474 items (at 1 items/min)
2015-03-24 11:00:09+0000 [xxu46_7] INFO: Crawled 481 pages (at 0 pages/min), scraped 474 items (at 0 items/min)
2015-03-24 11:00:20+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5409> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 11:00:20+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5409>
	{'abstract': u'Fiore and Hur recently introduced a conservative extension of universal algebra and equational logic from first to second order. Second-order universal algebra and second-order equational logic respectively provide a model theory and a formal deductive system for languages with variable binding and parameterised metavariables. This work completes the foundations of the subject from the viewpoint of categorical algebra. Specifically, the paper introduces the notion of second-order algebraic theory and develops its basic theory. Two categorical equivalences are established: at the syntactic level, that of second-order equational presentations and second-order algebraic theories; at the semantic level, that of second-order algebras and second-order functorial models. Our development includes a mathematical definition of syntactic translation between second-order equational presentations. This gives the first formalisation of notions such as encodings and transforms in the context of languages with variable binding.',
	 'authors': u'Marcelo Fiore, Ola Mahmoud,',
	 'category': u'Computer Science ',
	 'date': '2013-8-25',
	 'pdflink': u'http://arxiv.org/pdf/1308.5409',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nSecond-Order Algebraic Theories',
	 'urllink': u'http://arxiv.org/abs/1308.5409'}
2015-03-24 11:01:09+0000 [xxu46_7] INFO: Crawled 482 pages (at 1 pages/min), scraped 475 items (at 1 items/min)
2015-03-24 11:02:09+0000 [xxu46_7] INFO: Crawled 482 pages (at 0 pages/min), scraped 475 items (at 0 items/min)
2015-03-24 11:02:10+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7009> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 11:02:10+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7009>
	{'abstract': u'In this paper we investigate the benefit of base station (BS) cooperation in the uplink of coordinated multi-point (CoMP) networks. Our figure of merit is the required BS density required to meet a chosen rate coverage. Our model assumes a 2-D network of BSs on a regular hexagonal lattice in which path loss, lognormal shadowing and Rayleigh fading affect the signal received from users. Accurate closed-form expressions are first presented for the sum-rate coverage probability and ergodic sum-rate at each point of the cooperation region. Then, for a chosen quality of user rate, the required density of BS is derived based on the minimum value of rate coverage probability in the cooperation region. The approach guarantees that the achievable rate in the entire coverage region is above a target rate with chosen probability. The formulation allows comparison between different orders of BS cooperation, quantifying the reduced required BS density from higher orders of cooperation.',
	 'authors': u'S. Alireza Banani, Raviraj Adve,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.7009',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nAnalyzing the Reduced Required BS Density due to CoMP in Cellular  Networks',
	 'urllink': u'http://arxiv.org/abs/1309.7009'}
2015-03-24 11:03:09+0000 [xxu46_7] INFO: Crawled 483 pages (at 1 pages/min), scraped 476 items (at 1 items/min)
2015-03-24 11:03:55+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6439> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 11:03:55+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6439>
	{'abstract': u'We propose modal Markov logic as an extension of propositional Markov logic to reason under the principle of maximum entropy for modal logics K45, KD45, and S5. Analogous to propositional Markov logic, the knowledge base consists of weighted formulas, whose weights are learned from data. However, in contrast to Markov logic, in our framework we use the knowledge base to define a probability distribution over non-equivalent epistemic situations (pointed Kripke structures) rather than over atoms, and use this distribution to assign probabilities to modal formulas. As in all probabilistic representations, the central task in our framework is inference. Although the size of the state space grows doubly exponentially in the number of propositions in the domain, we provide an algorithm that scales only exponentially in the size of the knowledge base. Finally, we briefly discuss the case of languages with an infinite number of propositions.',
	 'authors': u'Tivadar Papai, Henry Kautz, Daniel Stefankovic,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6439',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nReasoning Under the Principle of Maximum Entropy for Modal Logics K45,  KD45, and S5',
	 'urllink': u'http://arxiv.org/abs/1310.6439'}
2015-03-24 11:04:09+0000 [xxu46_7] INFO: Crawled 484 pages (at 1 pages/min), scraped 477 items (at 1 items/min)
2015-03-24 11:05:09+0000 [xxu46_7] INFO: Crawled 484 pages (at 0 pages/min), scraped 477 items (at 0 items/min)
2015-03-24 11:05:33+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5397> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 11:05:33+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5397>
	{'abstract': u"Traffic shaping is a mechanism used by Internet Service Providers (ISPs) to limit subscribers' traffic based on their service contracts. This paper investigates the current implementation of traffic shaping based on the token bucket filter (TBF), discusses its advantages and disadvantages, and proposes a cooperative TBF that can improve subscribers' quality of service (QoS)/quality of experience (QoE) without compromising business aspects of the service contract model by proportionally allocating excess bandwidth from inactive subscribers to active ones based on the long-term bandwidths per their service contracts.",
	 'authors': u'Luke Farmer, Kyeong Soo Kim,',
	 'category': u'Computer Science ',
	 'date': '2013-8-25',
	 'pdflink': u'http://arxiv.org/pdf/1308.5397',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nCooperative ISP Traffic Shaping Schemes in Broadband Shared Access  Networks',
	 'urllink': u'http://arxiv.org/abs/1308.5397'}
2015-03-24 11:06:09+0000 [xxu46_7] INFO: Crawled 485 pages (at 1 pages/min), scraped 478 items (at 1 items/min)
2015-03-24 11:07:09+0000 [xxu46_7] INFO: Crawled 485 pages (at 0 pages/min), scraped 478 items (at 0 items/min)
2015-03-24 11:07:26+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7004> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 11:07:26+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7004>
	{'abstract': u'The Trek Separation Theorem (Sullivant et al. 2010) states necessary and sufficient conditions for a linear directed acyclic graphical model to entail for all possible values of its linear coefficients that the rank of various sub-matrices of the covariance matrix is less than or equal to n, for any given n. In this paper, I extend the Trek Separation Theorem in two ways: I prove that the same necessary and sufficient conditions apply even when the generating model is partially non-linear and contains some cycles. This justifies application of constraint-based causal search algorithms such as the BuildPureClusters algorithm (Silva et al. 2006) for discovering the causal structure of latent variable models to data generated by a wider class of causal models that may contain non-linear and cyclic relations among the latent variables.',
	 'authors': u'Peter L. Spirtes,',
	 'category': u'Computer Science ',
	 'date': '2013-9-17',
	 'pdflink': u'http://arxiv.org/pdf/1309.7004',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nCalculation of Entailed Rank Constraints in Partially Non-Linear and  Cyclic Models',
	 'urllink': u'http://arxiv.org/abs/1309.7004'}
2015-03-24 11:08:09+0000 [xxu46_7] INFO: Crawled 486 pages (at 1 pages/min), scraped 479 items (at 1 items/min)
2015-03-24 11:09:04+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6438> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 11:09:04+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6438>
	{'abstract': u"A traditional assumption in game theory is that players are opaque to one another -- if a player changes strategies, then this change in strategies does not affect the choice of other players' strategies. In many situations this is an unrealistic assumption. We develop a framework for reasoning about games where the players may be translucent to one another; in particular, a player may believe that if she were to change strategies, then the other player would also change strategies. Translucent players may achieve significantly more efficient outcomes than opaque ones. Our main result is a characterization of strategies consistent with appropriate analogues of common belief of rationality. Common Counterfactual Belief of Rationality (CCBR) holds if (1) everyone is rational, (2) everyone counterfactually believes that everyone else is rational (i.e., all players i believe that everyone else would still be rational even if i were to switch strategies), (3) everyone counterfactually believes that everyone else is rational, and counterfactually believes that everyone else is rational, and so on. CCBR characterizes the set of strategies surviving iterated removal of minimax dominated strategies: a strategy is minimax dominated for i if there exists a strategy for i such that .",
	 'authors': u'Joseph Y. Halpern, Rafael Pass,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6438',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nGame Theory with Translucent Players',
	 'urllink': u'http://arxiv.org/abs/1310.6438'}
2015-03-24 11:09:09+0000 [xxu46_7] INFO: Crawled 487 pages (at 1 pages/min), scraped 480 items (at 1 items/min)
2015-03-24 11:10:09+0000 [xxu46_7] INFO: Crawled 487 pages (at 0 pages/min), scraped 480 items (at 0 items/min)
2015-03-24 11:11:05+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5395> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 11:11:05+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5395>
	{'abstract': u'We describe steps toward an interactive directory for the town of Norfolk, Nebraska for the years 1899 and 1900. This directory would extend the traditional city directory by including a wider range of entities being described, much richer information about the entities mentioned and linkages to mentions of the entities in material such as digitized historical newspapers. Such a directory would be useful to readers who browse the historical newspapers by providing structured summaries of the entities mentioned. We describe the occurrence of entities in two years of the Norfolk Weekly News, focusing on several individuals to better understand the types of information which can be gleaned from historical newspapers and other historical materials. We also describe a prototype program which coordinates information about entities from the traditional city directories, the federal census, and from newspapers. We discuss the structured coding for these entities, noting that richer coding would increasingly include descriptions of events and scenarios. We propose that rich content about individuals and communities could eventually be modeled with agents and woven into historical narratives.',
	 'authors': u'Robert B. Allen,',
	 'category': u'Computer Science ',
	 'date': '2013-8-25',
	 'pdflink': u'http://arxiv.org/pdf/1308.5395',
	 'subjects': u'Digital Libraries (cs.DL)',
	 'title': u'\nToward an Interactive Directory for Norfolk, Nebraska: 1899-1900',
	 'urllink': u'http://arxiv.org/abs/1308.5395'}
2015-03-24 11:11:09+0000 [xxu46_7] INFO: Crawled 488 pages (at 1 pages/min), scraped 481 items (at 1 items/min)
2015-03-24 11:12:09+0000 [xxu46_7] INFO: Crawled 488 pages (at 0 pages/min), scraped 481 items (at 0 items/min)
2015-03-24 11:13:06+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.7001> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 11:13:06+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.7001>
	{'abstract': u"The Kaczmarz method is an iterative method for solving large systems of equations that projects iterates orthogonally onto the solution space of each equation. In contrast to direct methods such as Gaussian elimination or QR-factorization, this algorithm is efficient for problems with sparse matrices, as they appear in constraint-based user interface (UI) layout specifications. However, the Kaczmarz method as described in the literature has its limitations: it considers only equality constraints and does not support soft constraints, which makes it inapplicable to the UI layout problem. In this paper we extend the Kaczmarz method for solving specifications containing soft constraints, using the prioritized IIS detection algorithm. Furthermore, the performance and convergence of the proposed algorithms are evaluated empirically using randomly generated UI layout specifications of various sizes. The results show that these methods offer improvements in performance over standard methods like Matlab's LINPROG, a well-known efficient linear programming solver.",
	 'authors': u'Noreen Jamil, Deanna Needell, Johannes Muller, Christof Lutteroth, Gerald Weber,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.7001',
	 'subjects': u'Numerical Analysis (cs.NA)',
	 'title': u'\nKaczmarz Algorithm with Soft Constraints for User Interface Layout',
	 'urllink': u'http://arxiv.org/abs/1309.7001'}
2015-03-24 11:13:09+0000 [xxu46_7] INFO: Crawled 489 pages (at 1 pages/min), scraped 482 items (at 1 items/min)
2015-03-24 11:14:09+0000 [xxu46_7] INFO: Crawled 489 pages (at 0 pages/min), scraped 482 items (at 0 items/min)
2015-03-24 11:14:56+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6437> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 11:14:56+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6437>
	{'abstract': u'Propositional Dynamic Logic or PDL was invented as a logic for reasoning about regular programming constructs. We propose a new perspective on PDL as a multi-agent strategic logic (MASL). This logic for strategic reasoning has group strategies as first class citizens, and brings game logic closer to standard modal logic. We demonstrate that MASL can express key notions of game theory, social choice theory and voting theory in a natural way, we give a sound and complete proof system for MASL, and we show that MASL encodes coalition logic. Next, we extend the language to epistemic multi-agent strategic logic (EMASL), we give examples of what it can express, we propose to use it for posing new questions in epistemic social choice theory, and we give a calculus for reasoning about a natural class of epistemic game models. We end by listing avenues for future research and by tracing connections to a number of other logics for reasoning about strategies.',
	 'authors': u'Jan van Eijck,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6437',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nPDL as a Multi-Agent Strategy Logic',
	 'urllink': u'http://arxiv.org/abs/1310.6437'}
2015-03-24 11:15:09+0000 [xxu46_7] INFO: Crawled 490 pages (at 1 pages/min), scraped 483 items (at 1 items/min)
2015-03-24 11:16:08+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5380> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 11:16:08+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5380>
	{'abstract': u'Pedestrian behavior has much more complicated characteristics in a dense crowd and thus attracts the widespread interest of scientists and engineers. However, even successful modeling approaches such as pedestrian models based on particle systems are still not fully considered the perceptive mechanism underlying collective pedestrian behavior. This paper extends a behavioral heuristics-based pedestrian model to an adaptive agent-based model, which explicitly considers the crowding effect of neighboring individuals and perception anisotropy on the representation of a pedestrians visual information. The adaptive agents with crowding perception are constructed to investigate complex, selforganized collective dynamics of pedestrian motion. The proposed model simulates selforganized pedestrian flows in good quantitative agreement with empirical data. The selforganized phenomena include lane formation in bidirectional flow and fundamental diagrams of unidirectional flow. Simulation results show that the emergence of lane formation in bidirectional flow can be well reproduced. To investigate this further, increasing view distance has a significant effect on reducing the number of lanes, increasing lane width, and stabilizing the self-organized lanes. The paper also discusses phase transitions of fundamental diagrams of pedestrian crowds with unidirectional flow. It is found that the heterogeneity of how pedestrians perceive crowding in the population has a remarkable impact on the flow quality, which results in the buildup of congestion and rapidly decreases the efficiency of pedestrian flows. It also indicates that the concept of heterogeneity may be used to explain the instability of phase transitions.',
	 'authors': u'Qi Xu, Baohua Mao, Xujie Feng, Jia Feng,',
	 'category': u'Computer Science ',
	 'date': '2013-8-25',
	 'pdflink': u'http://arxiv.org/e-print/1308.5380',
	 'subjects': u'Multiagent Systems (cs.MA)',
	 'title': u'\nEffects of Crowding Perception on Self-organized Pedestrian Flows Using  Adaptive Agent-based Model',
	 'urllink': u'http://arxiv.org/abs/1308.5380'}
2015-03-24 11:16:09+0000 [xxu46_7] INFO: Crawled 491 pages (at 1 pages/min), scraped 484 items (at 1 items/min)
2015-03-24 11:17:09+0000 [xxu46_7] INFO: Crawled 491 pages (at 0 pages/min), scraped 484 items (at 0 items/min)
2015-03-24 11:17:53+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6989> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 11:17:53+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6989>
	{'abstract': u'One of the main challenges in the field of embodied artificial intelligence is the open-ended autonomous learning of complex behaviours. Our approach is to use task-independent, information-driven intrinsic motivation(s) to support task-dependent learning. The work presented here is a preliminary step in which we investigate the predictive information (the mutual information of the past and future of the sensor stream) as an intrinsic drive, ideally supporting any kind of task acquisition. Previous experiments have shown that the predictive information (PI) is a good candidate to support autonomous, open-ended learning of complex behaviours, because a maximisation of the PI corresponds to an exploration of morphology- and environment-dependent behavioural regularities. The idea is that these regularities can then be exploited in order to solve any given task. Three different experiments are presented and their results lead to the conclusion that the linear combination of the one-step PI with an external reward function is not generally recommended in an episodic policy gradient setting. Only for hard tasks a great speed-up can be achieved at the cost of an asymptotic performance lost.',
	 'authors': u'Keyan Zahedi, Georg Martius, Nihat Ay,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6989',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nLinear combination of one-step predictive information with an external  reward in an episodic policy gradient setting: a critical analysis',
	 'urllink': u'http://arxiv.org/abs/1309.6989'}
2015-03-24 11:18:09+0000 [xxu46_7] INFO: Crawled 492 pages (at 1 pages/min), scraped 485 items (at 1 items/min)
2015-03-24 11:19:09+0000 [xxu46_7] INFO: Crawled 492 pages (at 0 pages/min), scraped 485 items (at 0 items/min)
2015-03-24 11:19:53+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6436> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 11:19:53+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6436>
	{'abstract': u"We propose a general framework for strategic voting when a voter may lack knowledge about other votes or about other voters' knowledge about her own vote. In this setting we define notions of manipulation and equilibrium. We also model action changing knowledge about votes, such as a voter revealing its preference or as a central authority performing a voting poll. Some forms of manipulation are preserved under such updates and others not. Another form of knowledge dynamics is the effect of a voter declaring its vote. We envisage Stackelberg games for uncertain profiles. The purpose of this investigation is to provide the epistemic background for the analysis and design of voting rules that incorporate uncertainty.",
	 'authors': u'Hans van Ditmarsch, Jerome Lang, Abdallah Saffidine,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6436',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nStrategic Voting and the Logic of Knowledge',
	 'urllink': u'http://arxiv.org/abs/1310.6436'}
2015-03-24 11:20:09+0000 [xxu46_7] INFO: Crawled 493 pages (at 1 pages/min), scraped 486 items (at 1 items/min)
2015-03-24 11:21:09+0000 [xxu46_7] INFO: Crawled 493 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2015-03-24 11:21:47+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5374> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 11:21:47+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5374>
	{'abstract': u'A (DRS) is an adaptation of a conventional formal logical system that explicitly portrays reasoning as a temporal activity, with each extralogical input to the system and each inference rule application being viewed as occurring at a distinct time step. Every DRS incorporates some well-defined logic together with a controller that serves to guide the reasoning process in response to user inputs. Logics are generic, whereas controllers are application-specific. Every controller does, nonetheless, provide an algorithm for nonmonotonic belief revision. The general notion of a DRS comprises a framework within which one can formulate the logic and algorithms for a given application and prove that the algorithms are correct, i.e., that they serve to (i) derive all salient information and (ii) preserve the consistency of the belief set. This paper illustrates the idea with ordinary first-order predicate calculus, suitably modified for the present purpose, and two examples. The latter example revisits some classic nonmonotonic reasoning puzzles (Opus the Penguin, Nixon Diamond) and shows how these can be resolved in the context of a DRS, using an expanded version of first-order logic that incorporates typed predicate symbols. All concepts are rigorously defined and effectively computable, thereby providing the foundation for a future software implementation.',
	 'authors': u'Daniel G. Schwartz,',
	 'category': u'Computer Science ',
	 'date': '2013-8-25',
	 'pdflink': u'http://arxiv.org/pdf/1308.5374',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nDynamic Reasoning Systems',
	 'urllink': u'http://arxiv.org/abs/1308.5374'}
2015-03-24 11:22:09+0000 [xxu46_7] INFO: Crawled 494 pages (at 1 pages/min), scraped 487 items (at 1 items/min)
2015-03-24 11:23:09+0000 [xxu46_7] INFO: Crawled 494 pages (at 0 pages/min), scraped 487 items (at 0 items/min)
2015-03-24 11:23:21+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6978> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 11:23:21+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6978>
	{'abstract': u'In this work, we study protocols so that populations of distributed processes can construct networks. In order to highlight the basic principles of distributed network construction we keep the model minimal in all respects. In particular, we assume finite-state processes that all begin from the same initial state and all execute the same protocol (i.e. the system is homogeneous). Moreover, we assume pairwise interactions between the processes that are scheduled by an adversary. The only constraint on the adversary scheduler is that it must be fair. In order to allow processes to construct networks, we let them activate and deactivate their pairwise connections. When two processes interact, the protocol takes as input the states of the processes and the state of the their connection and updates all of them. Initially all connections are inactive and the goal is for the processes, after interacting and activating/deactivating connections for a while, to end up with a desired stable network. We give protocols (optimal in some cases) and lower bounds for several basic network construction problems such as spanning line, spanning ring, spanning star, and regular network. We provide proofs of correctness for all of our protocols and analyze the expected time to convergence of most of them under a uniform random scheduler that selects the next pair of interacting processes uniformly at random from all such pairs. Finally, we prove several universality results by presenting generic protocols that are capable of simulating a Turing Machine (TM) and exploiting it in order to construct a large class of networks.',
	 'authors': u'Othon Michail, Paul G. Spirakis,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6978',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nSimple and Efficient Local Codes for Distributed Stable Network  Construction',
	 'urllink': u'http://arxiv.org/abs/1309.6978'}
2015-03-24 11:24:09+0000 [xxu46_7] INFO: Crawled 495 pages (at 1 pages/min), scraped 488 items (at 1 items/min)
2015-03-24 11:24:46+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6435> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 11:24:46+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6435>
	{'abstract': u'The main aim of the present paper is to use a proof system for hybrid modal logic to formalize what are called falsebelief tasks in cognitive psychology, thereby investigating the interplay between cognition and logical reasoning about belief. We consider two different versions of the Smarties task, involving respectively a shift of perspective to another person and to another time. Our formalizations disclose that despite this difference, the two versions of the Smarties task have exactly the same underlying logical structure. We also consider the Sally-Anne task, having a somewhat more complicated logical structure, presupposing a "principle of inertia" saying that a belief is preserved over time, unless there is belief to the contrary.',
	 'authors': u'Torben Brauner,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6435',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nHybrid-Logical Reasoning in False-Belief Tasks',
	 'urllink': u'http://arxiv.org/abs/1310.6435'}
2015-03-24 11:25:09+0000 [xxu46_7] INFO: Crawled 496 pages (at 1 pages/min), scraped 489 items (at 1 items/min)
2015-03-24 11:26:09+0000 [xxu46_7] INFO: Crawled 496 pages (at 0 pages/min), scraped 489 items (at 0 items/min)
2015-03-24 11:26:22+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5373> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 11:26:22+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5373>
	{'abstract': u'As a subclass of linear codes, cyclic codes have applications in consumer electronics, data storage systems, and communication systems as they have efficient encoding and decoding algorithms. In this paper, five families of three-weight ternary cyclic codes whose duals have two zeros are presented. The weight distributions of the five families of cyclic codes are settled. The duals of two families of the cyclic codes are optimal.',
	 'authors': u'Cunsheng Ding, Ying Gao, Zhengchun Zhou,',
	 'category': u'Computer Science ',
	 'date': '2013-8-25',
	 'pdflink': u'http://arxiv.org/pdf/1308.5373',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nFive Families of Three-Weight Ternary Cyclic Codes and Their Duals',
	 'urllink': u'http://arxiv.org/abs/1308.5373'}
2015-03-24 11:27:09+0000 [xxu46_7] INFO: Crawled 497 pages (at 1 pages/min), scraped 490 items (at 1 items/min)
2015-03-24 11:28:06+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6964> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 11:28:06+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6964>
	{'abstract': u'We present a family of online algorithms for real-time factorization-based structure from motion, leveraging a relationship between incremental singular value decomposition and recently proposed methods for online matrix completion. Our methods are orders of magnitude faster than previous state of the art, can handle missing data and a variable number of feature points, and are robust to noise and sparse outliers. We demonstrate our methods on both real and synthetic sequences and show that they perform well in both online and batch settings. We also provide an implementation which is able to produce 3D models in real time using a laptop with a webcam.',
	 'authors': u'Ryan Kennedy, Laura Balzano, Stephen J. Wright, Camillo J. Taylor,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6964',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nOnline Algorithms for Factorization-Based Structure from Motion',
	 'urllink': u'http://arxiv.org/abs/1309.6964'}
2015-03-24 11:28:09+0000 [xxu46_7] INFO: Crawled 498 pages (at 1 pages/min), scraped 491 items (at 1 items/min)
2015-03-24 11:29:09+0000 [xxu46_7] INFO: Crawled 498 pages (at 0 pages/min), scraped 491 items (at 0 items/min)
2015-03-24 11:30:04+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6434> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 11:30:04+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6434>
	{'abstract': u'We identify a subproblem of the model-checking problem for the epistemic mu-calculus which is decidable. Formulas in the instances of this subproblem allow free variables within the scope of epistemic modalities in a restricted form that avoids embodying any form of common knowledge. Our subproblem subsumes known decidable fragments of epistemic CTL/LTL, may express winning strategies in two-player games with one player having imperfect information and non-observable objectives, and, with a suitable encoding, decidable instances of the model-checking problem for ATLiR.',
	 'authors': u'Rodica Bozianu, Catalin Dima, Constantin Enea,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6434',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nModel Checking an Epistemic mu-calculus with Synchronous and Perfect  Recall Semantics',
	 'urllink': u'http://arxiv.org/abs/1310.6434'}
2015-03-24 11:30:09+0000 [xxu46_7] INFO: Crawled 499 pages (at 1 pages/min), scraped 492 items (at 1 items/min)
2015-03-24 11:31:09+0000 [xxu46_7] INFO: Crawled 499 pages (at 0 pages/min), scraped 492 items (at 0 items/min)
2015-03-24 11:31:32+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5360> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 11:31:32+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5360>
	{'abstract': u'As a result of the recent advances in physical (PHY) layer communication techniques, it is possible to receive multiple packets at the receiver concurrently. This capability of a receiver to decode multiple simultaneous transmissions is known as multi-packet reception (MPR). In this paper, we propose a simple Medium Access Control (MAC) protocol for an MPR wireless channel, where we modify the backoff procedure as a function of number of ongoing transmissions in the channel. Our protocol is backward compatible with the IEEE 802.11 DCF protocol. The performance analysis of the proposed protocol is carried out using extensive simulations and it is compared with some of the existing MPR MAC protocols. The proposed mechanism improves the throughput and delay performance of the IEEE 802.11 DCF.',
	 'authors': u'Arun I B, T.G. Venkatesh,',
	 'category': u'Computer Science ',
	 'date': '2013-8-24',
	 'pdflink': u'http://arxiv.org/pdf/1308.5360',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nAdaptive Backoff Algorithm for IEEE 802.11 DCF under MPR Wireless  Channels',
	 'urllink': u'http://arxiv.org/abs/1308.5360'}
2015-03-24 11:32:09+0000 [xxu46_7] INFO: Crawled 500 pages (at 1 pages/min), scraped 493 items (at 1 items/min)
2015-03-24 11:33:09+0000 [xxu46_7] INFO: Crawled 500 pages (at 0 pages/min), scraped 493 items (at 0 items/min)
2015-03-24 11:33:33+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6947> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 11:33:33+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6947>
	{'abstract': u'Partial model checking was proposed by Andersen in 1995 to verify a temporal logic formula compositionally on a composition of processes. It consists in incrementally incorporating into the formula the behavioural information taken from one process - an operation called quotienting - to obtain a new formula that can be verified on a smaller composition from which the incorporated process has been removed. Simplifications of the formula must be applied at each step, so as to maintain the formula at a tractable size. In this paper, we revisit partial model checking. First, we extend quotienting to the network of labelled transition systems model, which subsumes most parallel composition operators, including m-among-n synchronisation and parallel composition using synchronisation interfaces, available in the ELOTOS standard. Second, we reformulate quotienting in terms of a simple synchronous product between a graph representation of the formula (called formula graph) and a process, thus enabling quotienting to be implemented efficiently and easily, by reusing existing tools dedicated to graph compositions. Third, we propose simplifications of the formula as a combination of bisimulations and reductions using Boolean equation systems applied directly to the formula graph, thus enabling formula simplifications also to be implemented efficiently. Finally, we describe an implementation in the CADP (Construction and Analysis of Distributed Processes) toolbox and present some experimental results in which partial model checking uses hundreds of times less memory than on-the-fly model checking.',
	 'authors': u'Fr\xe9d\xe9ric Lang, Radu Mateescu,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6947',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nPartial Model Checking using Networks of Labelled Transition Systems and  Boole an Equation Systems',
	 'urllink': u'http://arxiv.org/abs/1309.6947'}
2015-03-24 11:34:09+0000 [xxu46_7] INFO: Crawled 501 pages (at 1 pages/min), scraped 494 items (at 1 items/min)
2015-03-24 11:35:05+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6433> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 11:35:05+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6433>
	{'abstract': u'Moses &amp; Nachum ([7]) identify conceptual flaws in Bacharach\'s generalization ([3]) of Aumann\'s seminal "agreeing to disagree" result ([1]). Essentially, Bacharach\'s framework requires agents\' decision functions to be defined over events that are informationally meaningless for the agents. In this paper, we argue that the analysis of the agreement theorem should be carried out in information structures that can accommodate for counterfactual states. We therefore develop a method for constructing such "counterfactual structures" (starting from partitional structures), and prove a new agreement theorem within such structures. Furthermore, we show that our approach also resolves the conceptual flaws in the sense that, within our framework, decision functions are always only defined over events that are informationally meaningful for the agents.',
	 'authors': u'Bassel Tarbush,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6433',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nAgreeing on Decisions: An Analysis with Counterfactuals',
	 'urllink': u'http://arxiv.org/abs/1310.6433'}
2015-03-24 11:35:09+0000 [xxu46_7] INFO: Crawled 502 pages (at 1 pages/min), scraped 495 items (at 1 items/min)
2015-03-24 11:36:09+0000 [xxu46_7] INFO: Crawled 502 pages (at 0 pages/min), scraped 495 items (at 0 items/min)
2015-03-24 11:36:30+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5356> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 11:36:30+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5356>
	{'abstract': u'This paper discusses the key principles of Gigabit Passive Optical Network (GPON) which is based on Time Division Multiplexing Passive Optical Network (TDM PON) and Wavelength Division Multiplexing Passive Optical Network (WDM PON), which is considered to be next generation passive optical network. In the present day scenario, access to broad- band is increasing at a rapid pace. Because of the advantages of fiber access in terms of capacity and cost, most of the countries have started deploying GPON access as an important part of national strategy. Though GPON is promising, it has few limitations. On the other hand WDM PON, a next generation network, is quite promising unlike GPON, it is easily scalable and interoperable with different vendors. This paper provides an overview of GPON, WDM PON and its key dissimilarities based on technicalities and cost.',
	 'authors': u'Satyanarayana Katla, Abhinov Balagoni,',
	 'category': u'Computer Science ',
	 'date': '2013-8-24',
	 'pdflink': u'http://arxiv.org/e-print/1308.5356',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nTechnological and Cost based Analysis of Future-Proof Fiber Access  Passive Networks: GPON and WDM PON',
	 'urllink': u'http://arxiv.org/abs/1308.5356'}
2015-03-24 11:37:09+0000 [xxu46_7] INFO: Crawled 503 pages (at 1 pages/min), scraped 496 items (at 1 items/min)
2015-03-24 11:38:04+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6927> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 11:38:04+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6927>
	{'abstract': u'Some "principle of exclusion" (POE) has been introduced and investigated by the author in previous publications. In particular the POE often outperforms the familiar principle of inclusion-exclusion (IE), provided both are applicable. In the present article we argue that sometimes the two can join hands. That is, POE doesn\'t replace IE but rather accelerates the otherwise infeasible IE calculations. The ideas are applied to count (a) constrained permutations (constrained in a way more general than by forbidden positions), (b) integer partitions, and (c) models of a Boolean function given in DNF. Concerning (c), for several choices of parameters binary decision diagrams are not competitive, and they never are competitive when only models (=bitstrings) of fixed weight need to be counted.',
	 'authors': u'Marcel Wild,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6927',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nInclusion-exclusion meets exclusion',
	 'urllink': u'http://arxiv.org/abs/1309.6927'}
2015-03-24 11:38:09+0000 [xxu46_7] INFO: Crawled 504 pages (at 1 pages/min), scraped 497 items (at 1 items/min)
2015-03-24 11:39:09+0000 [xxu46_7] INFO: Crawled 504 pages (at 0 pages/min), scraped 497 items (at 0 items/min)
2015-03-24 11:40:03+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6432> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 11:40:03+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6432>
	{'abstract': u'In this extended abstract, we carefully examine a purported counterexample to a postulate of iterated belief revision. We suggest that the example is better seen as a failure to apply the theory of belief revision in sufficient detail. The main contribution is conceptual aiming at the literature on the philosophical foundations of the AGM theory of belief revision [1]. Our discussion is centered around the observation that it is often unclear whether a specific example is a "genuine" counterexample to an abstract theory or a misapplication of that theory to a concrete case.',
	 'authors': u'Eric Pacuit, Arthur Paul Pedersen, Jan-Willem Romeijn,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6432',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nWhen is an Example a Counterexample?',
	 'urllink': u'http://arxiv.org/abs/1310.6432'}
2015-03-24 11:40:09+0000 [xxu46_7] INFO: Crawled 505 pages (at 1 pages/min), scraped 498 items (at 1 items/min)
2015-03-24 11:41:09+0000 [xxu46_7] INFO: Crawled 505 pages (at 0 pages/min), scraped 498 items (at 0 items/min)
2015-03-24 11:42:04+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5354> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 11:42:04+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5354>
	{'abstract': u'We investigate a compressive sensing framework in which the sensors introduce a distortion to the measurements in the form of unknown gains. We focus on blind calibration, using measures performed on multiple unknown (but sparse) signals and formulate the joint recovery of the gains and the sparse signals as a convex optimization problem. We divide this problem in 3 subproblems with different conditions on the gains, specifially (i) gains with different amplitude and the same phase, (ii) gains with the same amplitude and different phase and (iii) gains with different amplitude and phase. In order to solve the first case, we propose an extension to the basis pursuit optimization which can estimate the unknown gains along with the unknown sparse signals. For the second case, we formulate a quadratic approach that eliminates the unknown phase shifts and retrieves the unknown sparse signals. An alternative form of this approach is also formulated to reduce complexity and memory requirements and provide scalability with respect to the number of input signals. Finally for the third case, we propose a formulation that combines the earlier two approaches to solve the problem. The performance of the proposed algorithms is investigated extensively through numerical simulations, which demonstrates that simultaneous signal recovery and calibration is possible with convex methods when sufficiently many (unknown, but sparse) calibrating signals are provided.',
	 'authors': u'Cagdas Bilen, Gilles Puy, R\xe9mi Gribonval, Laurent Daudet,',
	 'category': u'Computer Science ',
	 'date': '2013-8-24',
	 'pdflink': u'http://arxiv.org/pdf/1308.5354',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nConvex Optimization Approaches for Blind Sensor Calibration using  Sparsity',
	 'urllink': u'http://arxiv.org/abs/1308.5354'}
2015-03-24 11:42:09+0000 [xxu46_7] INFO: Crawled 506 pages (at 1 pages/min), scraped 499 items (at 1 items/min)
2015-03-24 11:43:09+0000 [xxu46_7] INFO: Crawled 506 pages (at 0 pages/min), scraped 499 items (at 0 items/min)
2015-03-24 11:43:46+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6919> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 11:43:46+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6919>
	{'abstract': u'We describe the Microbial Community Reconstruction () Problem, which is fundamental for microbiome analysis. In this problem, the goal is to reconstruct the identity and frequency of species comprising a microbial community, using short sequence reads from Massively Parallel Sequencing (MPS) data obtained for specified genomic regions. We formulate the problem mathematically as a convex optimization problem and provide sufficient conditions for identifiability, namely the ability to reconstruct species identity and frequency correctly when the data size (number of reads) grows to infinity. We discuss different metrics for assessing the quality of the reconstructed solution, including a novel phylogenetically-aware metric based on the Mahalanobis distance, and give upper-bounds on the reconstruction error for a finite number of reads under different metrics. We propose a scalable divide-and-conquer algorithm for the problem using convex optimization, which enables us to handle large problems (with species). We show using numerical simulations that for realistic scenarios, where the microbial communities are sparse, our algorithm gives solutions with high accuracy, both in terms of obtaining accurate frequency, and in terms of species phylogenetic resolution.',
	 'authors': u'Or Zuk, Amnon Amir, Amit Zeisel, Ohad Shamir, Noam Shental,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6919',
	 'subjects': u'Computational Engineering, Finance, and Science (cs.CE)',
	 'title': u'\nAccurate Profiling of Microbial Communities from Massively Parallel  Sequencing using Convex Optimization',
	 'urllink': u'http://arxiv.org/abs/1309.6919'}
2015-03-24 11:44:09+0000 [xxu46_7] INFO: Crawled 507 pages (at 1 pages/min), scraped 500 items (at 1 items/min)
2015-03-24 11:45:09+0000 [xxu46_7] INFO: Crawled 507 pages (at 0 pages/min), scraped 500 items (at 0 items/min)
2015-03-24 11:45:45+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6430> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 11:45:45+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6430>
	{'abstract': u'The paper investigates properties of the conditional independence relation between pieces of information. This relation is also known in the database theory as embedded multivalued dependency. In 1980, Parker and Parsaye-Ghomi established that the properties of this relation can not be described by a finite system of inference rules. In 1995, Herrmann proved that the propositional theory of this relation is undecidable. The main result of this paper is a complete recursively enumerable axiomatization of this theory.',
	 'authors': u'Pavel Naumov, Brittany Nicholls,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6430',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nR.E. Axiomatization of Conditional Independence',
	 'urllink': u'http://arxiv.org/abs/1310.6430'}
2015-03-24 11:46:09+0000 [xxu46_7] INFO: Crawled 508 pages (at 1 pages/min), scraped 501 items (at 1 items/min)
2015-03-24 11:47:09+0000 [xxu46_7] INFO: Crawled 508 pages (at 0 pages/min), scraped 501 items (at 0 items/min)
2015-03-24 11:47:40+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5339> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 11:47:40+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5339>
	{'abstract': u'In this paper we study solutions to stochastic differential equations (SDEs) with discontinuous drift. We apply two approaches: The Euler-Maruyama method and the Fokker-Planck equation and show that a candidate density function based on the Euler-Maruyama method approximates a candidate density function based on the stationary Fokker-Planck equation. Furthermore, we introduce a smooth function which approximates the discontinuous drift and apply the Euler-Maruyama method and the Fokker-Planck equation with this input. The point of departure for this work is a particular SDE with discontinuous drift.',
	 'authors': u'Maria Simonsen, John Leth, Henrik Schioler, Horia Cornean,',
	 'category': u'Computer Science ',
	 'date': '2013-8-24',
	 'pdflink': u'http://arxiv.org/pdf/1308.5339',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nA Simple Stochastic Differential Equation with Discontinuous Drift',
	 'urllink': u'http://arxiv.org/abs/1308.5339'}
2015-03-24 11:48:09+0000 [xxu46_7] INFO: Crawled 509 pages (at 1 pages/min), scraped 502 items (at 1 items/min)
2015-03-24 11:49:09+0000 [xxu46_7] INFO: Crawled 509 pages (at 0 pages/min), scraped 502 items (at 0 items/min)
2015-03-24 11:49:32+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6914> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 11:49:32+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6914>
	{'abstract': u'The chemical concrete machine is a graph rewriting system which uses only local moves (rewrites), seen as chemical reactions involving molecules which are graphs made up by 4 trivalent nodes. It is Turing complete, therefore it might be used as a model of computation in algorithmic chemistry.',
	 'authors': u'Marius Buliga,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6914',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nChemical concrete machine',
	 'urllink': u'http://arxiv.org/abs/1309.6914'}
2015-03-24 11:50:09+0000 [xxu46_7] INFO: Crawled 510 pages (at 1 pages/min), scraped 503 items (at 1 items/min)
2015-03-24 11:51:08+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6429> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 11:51:08+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6429>
	{'abstract': u'Knowledge-based programs (KBPs) are high-level protocols describing the course of action an agent should perform as a function of its knowledge. The use of KBPs for expressing action policies in AI planning has been surprisingly overlooked. Given that to each KBP corresponds an equivalent plan and vice versa, KBPs are typically more succinct than standard plans, but imply more on-line computation time. Here we make this argument formal, and prove that there exists an exponential succinctness gap between knowledge-based programs and standard plans. Then we address the complexity of plan existence. Some results trivially follow from results already known from the literature on planning under incomplete knowledge, but many were unknown so far.',
	 'authors': u'Jerome Lang, Bruno Zanuttini,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6429',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nKnowledge-Based Programs as Plans: Succinctness and the Complexity of  Plan Existence',
	 'urllink': u'http://arxiv.org/abs/1310.6429'}
2015-03-24 11:51:09+0000 [xxu46_7] INFO: Crawled 511 pages (at 1 pages/min), scraped 504 items (at 1 items/min)
2015-03-24 11:52:09+0000 [xxu46_7] INFO: Crawled 511 pages (at 0 pages/min), scraped 504 items (at 0 items/min)
2015-03-24 11:52:58+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5338> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 11:52:58+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5338>
	{'abstract': u"We present a hybrid model of a biological filter, a genetic circuit which removes fast fluctuations in the cell's internal representation of the extra cellular environment. The model takes the classic feed-forward loop (FFL) motif and represents it as a network of continuous protein concentrations and binary, unobserved gene promoter states. We address the problem of statistical inference and parameter learning for this class of models from partial, discrete time observations. We show that the hybrid representation leads to an efficient algorithm for approximate statistical inference in this circuit, and show its effectiveness on a simulated data set.",
	 'authors': u'Andrea Ocone, Guido Sanguinetti,',
	 'category': u'Computer Science ',
	 'date': '2013-8-24',
	 'pdflink': u'http://arxiv.org/pdf/1308.5338',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nA stochastic hybrid model of a biological filter',
	 'urllink': u'http://arxiv.org/abs/1308.5338'}
2015-03-24 11:53:09+0000 [xxu46_7] INFO: Crawled 512 pages (at 1 pages/min), scraped 505 items (at 1 items/min)
2015-03-24 11:53:50+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6908> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 11:53:50+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6908>
	{'abstract': u'In management education programmes today, students face a difficult time in choosing electives as the number of electives available are many. As the range and diversity of different elective courses available for selection have increased, course recommendation systems that help students in making choices about courses have become more relevant. In this paper we extend the concept of collaborative filtering approach to develop a course recommendation system. The proposed approach provides student an accurate prediction of the grade they may get if they choose a particular course, which will be helpful when they decide on selecting elective courses, as grade is an important parameter for a student while deciding on an elective course. We experimentally evaluate the collaborative filtering approach on a real life data set and show that the proposed system is effective in terms of accuracy.',
	 'authors': u'Sanjog Ray, Anuj Sharma,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6908',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nA Collaborative Filtering Based Approach for Recommending Elective  Courses',
	 'urllink': u'http://arxiv.org/abs/1309.6908'}
2015-03-24 11:54:09+0000 [xxu46_7] INFO: Crawled 513 pages (at 1 pages/min), scraped 506 items (at 1 items/min)
2015-03-24 11:55:09+0000 [xxu46_7] INFO: Crawled 513 pages (at 0 pages/min), scraped 506 items (at 0 items/min)
2015-03-24 11:55:33+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6427> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 11:55:33+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6427>
	{'abstract': u"In this letter, we analyse the properties of a maximum likelihood channel estimator based on the syndrome of a linear code. For the two examples of a binary symmetric channel and a binary input additive white Gaussian noise channel, we derive expressions for the bias and the mean squared error and compare them to the Cram 'er-Rao bound. The analytical expressions show the relationship between the estimator properties and the parameters of the linear code, i.e., the number of check nodes and the check node degree.",
	 'authors': u'Gottfried Lechner, Christoph Pacher,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6427',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nEstimating Channel Parameters from the Syndrome of a Linear Code',
	 'urllink': u'http://arxiv.org/abs/1310.6427'}
2015-03-24 11:56:09+0000 [xxu46_7] INFO: Crawled 514 pages (at 1 pages/min), scraped 507 items (at 1 items/min)
2015-03-24 11:57:09+0000 [xxu46_7] INFO: Crawled 514 pages (at 0 pages/min), scraped 507 items (at 0 items/min)
2015-03-24 11:57:11+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5337> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 11:57:11+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5337>
	{'abstract': u'Decentralized monitoring (DM) refers to a monitoring technique, where each component must infer, based on a set of partial observations if the global property is satisfied. Our work is inspired by the theoretical results presented by Baurer and Falcone at FM 2012, where the authors introduced an algorithm for distributing and monitoring LTL formulae, such that satisfaction or violation of specifications can be detected by local monitors alone. However, their work is based on the main assumption that neither the computation nor communication take time, hence it does not take into account how to set a sampling time among the components such that their local traces are consistent. In this work we provide a timed model in UPPAAL and we show a case study on a networked embedded systems board.',
	 'authors': u'Ezio Bartocci,',
	 'category': u'Computer Science ',
	 'date': '2013-8-24',
	 'pdflink': u'http://arxiv.org/pdf/1308.5337',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nSampling-based Decentralized Monitoring for Networked Embedded Systems',
	 'urllink': u'http://arxiv.org/abs/1308.5337'}
2015-03-24 11:58:09+0000 [xxu46_7] INFO: Crawled 515 pages (at 1 pages/min), scraped 508 items (at 1 items/min)
2015-03-24 11:58:23+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6883> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 11:58:23+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6883>
	{'abstract': u'This paper provides a gentle introduction to problem solving with the IDP3 system. The core of IDP3 is a finite model generator that supports first order logic enriched with types, inductive definitions, aggregates and partial functions. It offers its users a modeling language that is a slight extension of predicate logic and allows them to solve a wide range of search problems. Apart from a small introductory example, applications are selected from problems that arose within machine learning and data mining research. These research areas have recently shown a strong interest in declarative modeling and constraint solving as opposed to algorithmic approaches. The paper illustrates that the IDP3 system can be a valuable tool for researchers with such an interest. The first problem is in the domain of stemmatology, a domain of philology concerned with the relationship between surviving variant versions of text. The second problem is about a somewhat related problem within biology where phylogenetic trees are used to represent the evolution of species. The third and final problem concerns the classical problem of learning a minimal automaton consistent with a given set of strings. For this last problem, we show that the performance of our solution comes very close to that of a state-of-the art solution. For each of these applications, we analyze the problem, illustrate the development of a logic-based model and explore how alternatives can affect the performance.',
	 'authors': u'Maurice Bruynooghe, Hendrik Blockeel, Bart Bogaerts, Broes De Cat, Stef De Pooter, Joachim Jansen, Anthony Labarre, Jan Ramon, Marc Denecker, Sicco Verwer,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6883',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nPredicate Logic as a Modeling Language: Modeling and Solving some  Machine Learning and Data Mining Problems with IDP3',
	 'urllink': u'http://arxiv.org/abs/1309.6883'}
2015-03-24 11:59:09+0000 [xxu46_7] INFO: Crawled 516 pages (at 1 pages/min), scraped 509 items (at 1 items/min)
2015-03-24 11:59:52+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6424> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 11:59:52+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6424>
	{'abstract': u'The paper considers epistemic properties of linear communication chains. It describes a sound and complete logical system that, in addition to the standard axioms of S5 in a multi-modal language, contains two non-trivial axioms that capture the linear structure of communication chains.',
	 'authors': u'Jeffrey Kane, Pavel Naumov,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6424',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nEpistemic Logic for Communication Chains',
	 'urllink': u'http://arxiv.org/abs/1310.6424'}
2015-03-24 12:00:09+0000 [xxu46_7] INFO: Crawled 517 pages (at 1 pages/min), scraped 510 items (at 1 items/min)
2015-03-24 12:01:09+0000 [xxu46_7] INFO: Crawled 517 pages (at 0 pages/min), scraped 510 items (at 0 items/min)
2015-03-24 12:01:50+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5336> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 12:01:50+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5336>
	{'abstract': u'The model-checking problem for hybrid systems is a well known challenge in the scientific community. Most of the existing approaches and tools are limited to safety properties only, or operates by transforming the hybrid system to be verified into a discrete one, thus loosing information on the continuous dynamics of the system. In this paper we present a logic for specifying complex properties of hybrid systems called HyLTL, and we show how it is possible to solve the model checking problem by translating the formula into an equivalent hybrid automaton. In this way the problem is reduced to a reachability problem on hybrid automata that can be solved by using existing tools.',
	 'authors': u'Davide Bresolin,',
	 'category': u'Computer Science ',
	 'date': '2013-8-24',
	 'pdflink': u'http://arxiv.org/pdf/1308.5336',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nHyLTL: a temporal logic for model checking hybrid systems',
	 'urllink': u'http://arxiv.org/abs/1308.5336'}
2015-03-24 12:02:09+0000 [xxu46_7] INFO: Crawled 518 pages (at 1 pages/min), scraped 511 items (at 1 items/min)
2015-03-24 12:03:09+0000 [xxu46_7] INFO: Crawled 518 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2015-03-24 12:03:39+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6875> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 12:03:39+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6875>
	{'abstract': u'Conventional learning with expert advice methods assumes a learner is always receiving the outcome (e.g., class labels) of every incoming training instance at the end of each trial. In real applications, acquiring the outcome from oracle can be costly or time consuming. In this paper, we address a new problem of active learning with expert advice, where the outcome of an instance is disclosed only when it is requested by the online learner. Our goal is to learn an accurate prediction model by asking the oracle the number of questions as small as possible. To address this challenge, we propose a framework of active forecasters for online active learning with expert advice, which attempts to extend two regular forecasters, i.e., Exponentially Weighted Average Forecaster and Greedy Forecaster, to tackle the task of active learning with expert advice. We prove that the proposed algorithms satisfy the Hannan consistency under some proper assumptions, and validate the efficacy of our technique by an extensive set of experiments.',
	 'authors': u'Peilin Zhao, Steven Hoi, Jinfeng Zhuang,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6875',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nActive Learning with Expert Advice',
	 'urllink': u'http://arxiv.org/abs/1309.6875'}
2015-03-24 12:04:09+0000 [xxu46_7] INFO: Crawled 519 pages (at 1 pages/min), scraped 512 items (at 1 items/min)
2015-03-24 12:05:09+0000 [xxu46_7] INFO: Crawled 519 pages (at 0 pages/min), scraped 512 items (at 0 items/min)
2015-03-24 12:05:39+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6423> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 12:05:39+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6423>
	{'abstract': u'This paper deals with the automated synthesis of implementations of knowledge-based programs with respect to two synchronous semantics (clock and synchronous perfect recall). An approach to the synthesis problem based on the use of symbolic representations is described. The method has been implemented as an extension to the model checker MCK. Two applications of the implemented synthesis system are presented: the muddy children puzzle (where performance is compared to an explicit state method for a related problem implemented in the model checker DEMO), and a knowledge-based program for a dynamic leader election problem in a ring of processes.',
	 'authors': u'X. Huang, R. van der Meyden,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6423',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nSymbolic Synthesis of Knowledge-based Program Implementations with  Synchronous Semantics',
	 'urllink': u'http://arxiv.org/abs/1310.6423'}
2015-03-24 12:06:09+0000 [xxu46_7] INFO: Crawled 520 pages (at 1 pages/min), scraped 513 items (at 1 items/min)
2015-03-24 12:07:09+0000 [xxu46_7] INFO: Crawled 520 pages (at 0 pages/min), scraped 513 items (at 0 items/min)
2015-03-24 12:07:16+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5335> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 12:07:16+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5335>
	{'abstract': u'We propose an extension of Hybrid I/O Automata (HIOAs) to model agent systems and their implicit communication through perturbation of the environment, like localization of objects or radio signals diffusion and detection. The new object, called World Automaton (WA), is built in such a way to preserve as much as possible of the compositional properties of HIOAs and its underlying theory. From the formal point of view we enrich classical HIOAs with a set of world variables whose values are functions both of time and space. World variables are treated similarly to local variables of HIOAs, except in parallel composition, where the perturbations produced by world variables are summed. In such way, we obtain a structure able to model both agents and environments, thus inducing a hierarchy in the model and leading to the introduction of a new operator. Indeed this operator, called inplacement, is needed to represent the possibility of an object (WA) of living inside another object/environment (WA).',
	 'authors': u'Marta Capiluppi, Roberto Segala,',
	 'category': u'Computer Science ',
	 'date': '2013-8-24',
	 'pdflink': u'http://arxiv.org/pdf/1308.5335',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nWorld Automata: a compositional approach to model implicit communication  in hierarchical Hybrid Systems',
	 'urllink': u'http://arxiv.org/abs/1308.5335'}
2015-03-24 12:08:09+0000 [xxu46_7] INFO: Crawled 521 pages (at 1 pages/min), scraped 514 items (at 1 items/min)
2015-03-24 12:08:44+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6874> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 12:08:44+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6874>
	{'abstract': u'Document clustering and topic modeling are two closely related tasks which can mutually benefit each other. Topic modeling can project documents into a topic space which facilitates effective document clustering. Cluster labels discovered by document clustering can be incorporated into topic models to extract local topics specific to each cluster and global topics shared by all clusters. In this paper, we propose a multi-grain clustering topic model (MGCTM) which integrates document clustering and topic modeling into a unified framework and jointly performs the two tasks to achieve the overall best performance. Our model tightly couples two components: a mixture component used for discovering latent groups in document collection and a topic model component used for mining multi-grain topics including local topics specific to each cluster and global topics shared across clusters.We employ variational inference to approximate the posterior of hidden variables and learn model parameters. Experiments on two datasets demonstrate the effectiveness of our model.',
	 'authors': u'Pengtao Xie, Eric P. Xing,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6874',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nIntegrating Document Clustering and Topic Modeling',
	 'urllink': u'http://arxiv.org/abs/1309.6874'}
2015-03-24 12:09:09+0000 [xxu46_7] INFO: Crawled 522 pages (at 1 pages/min), scraped 515 items (at 1 items/min)
2015-03-24 12:10:09+0000 [xxu46_7] INFO: Crawled 522 pages (at 0 pages/min), scraped 515 items (at 0 items/min)
2015-03-24 12:10:20+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6422> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 12:10:20+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6422>
	{'abstract': u"Dynamic ID-based remote user authentication schemes ensure efficient and anonymous mutual authentication between entities. In 2013, Khan et al. proposed an improved dynamic ID-based authentication scheme to overcome the security flaws of Wang et al.'s authentication scheme. Recently, Sun and Cao showed that Khan et al. does not satisfies the claim of the user's privacy and proposed an efficient authentication scheme with user anonymity. The Sun and Cao's scheme achieve improvement over Khan et al.'s scheme in both privacy and performance point of view. Unfortunately, we identify that Sun and Cao's scheme does not resist password guessing attack. Additionally, Sun and Cao's scheme does not achieve forward secrecy.",
	 'authors': u'Dheerendra Mishra,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6422',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u"\nCryptanalysis of Sun and Cao's Remote Authentication Scheme with User  Anonymity",
	 'urllink': u'http://arxiv.org/abs/1310.6422'}
2015-03-24 12:11:09+0000 [xxu46_7] INFO: Crawled 523 pages (at 1 pages/min), scraped 516 items (at 1 items/min)
2015-03-24 12:12:06+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5334> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 12:12:06+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5334>
	{'abstract': u'Hybrid automata are a natural framework for modeling and analyzing systems which exhibit a mixed discrete continuous behaviour. However, the standard operational semantics defined over such models implicitly assume perfect knowledge of the real systems and infinite precision measurements. Such assumptions are not only unrealistic, but often lead to the construction of misleading models. For these reasons we believe that it is necessary to introduce more flexible semantics able to manage with noise, partial information, and finite precision instruments. In particular, in this paper we integrate in a single framework based on approximated semantics different over and under-approximation techniques for hybrid automata. Our framework allows to both compare, mix, and generalize such techniques obtaining different approximated reachability algorithms.',
	 'authors': u'Alberto Casagrande, Tommaso Dreossi, Carla Piazza,',
	 'category': u'Computer Science ',
	 'date': '2013-8-24',
	 'pdflink': u'http://arxiv.org/pdf/1308.5334',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nApproximated Symbolic Computations over Hybrid Automata',
	 'urllink': u'http://arxiv.org/abs/1308.5334'}
2015-03-24 12:12:09+0000 [xxu46_7] INFO: Crawled 524 pages (at 1 pages/min), scraped 517 items (at 1 items/min)
2015-03-24 12:13:09+0000 [xxu46_7] INFO: Crawled 524 pages (at 0 pages/min), scraped 517 items (at 0 items/min)
2015-03-24 12:13:28+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6872> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 12:13:28+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6872>
	{'abstract': u'Finding the most likely (MAP) configuration of a Markov random field (MRF) is NP-hard in general. A promising, recent technique is to reduce the problem to finding a maximum weight stable set (MWSS) on a derived weighted graph, which if perfect, allows inference in polynomial time. We derive new results for this approach, including a general decomposition theorem for MRFs of any order and number of labels, extensions of results for binary pairwise models with submodular cost functions to higher order, and an exact characterization of which binary pairwise MRFs can be efficiently solved with this method. This defines the power of the approach on this class of models, improves our toolbox and expands the range of tractable models.',
	 'authors': u'Adrian Weller, Tony S. Jebara,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6872',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nOn MAP Inference by MWSS on Perfect Graphs',
	 'urllink': u'http://arxiv.org/abs/1309.6872'}
2015-03-24 12:14:09+0000 [xxu46_7] INFO: Crawled 525 pages (at 1 pages/min), scraped 518 items (at 1 items/min)
2015-03-24 12:15:09+0000 [xxu46_7] INFO: Crawled 525 pages (at 0 pages/min), scraped 518 items (at 0 items/min)
2015-03-24 12:15:19+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6418> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 12:15:19+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6418>
	{'abstract': u'We study conditions relating to the impossibility of agreeing to disagree in models of interactive KD45 belief (in contrast to models of S5 knowledge, which are used in nearly all the agreements literature). We show that even when the truth axiom is not assumed it turns out that players will find it impossible to agree to disagree under fairly broad conditions.',
	 'authors': u'Ziv Hellman,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6418',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nDeludedly Agreeing to Agree',
	 'urllink': u'http://arxiv.org/abs/1310.6418'}
2015-03-24 12:16:09+0000 [xxu46_7] INFO: Crawled 526 pages (at 1 pages/min), scraped 519 items (at 1 items/min)
2015-03-24 12:16:56+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5333> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 12:16:56+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5333>
	{'abstract': u'In this work, we continue our study on discrete abstractions of dynamical systems. To this end, we use a family of partitioning functions to generate an abstraction. The intersection of sub-level sets of the partitioning functions defines cells, which are regarded as discrete objects. The union of cells makes up the state space of the dynamical systems. Our construction gives rise to a combinatorial object - a timed automaton. We examine sound and complete abstractions. An abstraction is said to be sound when the flow of the time automata covers the flow lines of the dynamical systems. If the dynamics of the dynamical system and the time automaton are equivalent, the abstraction is complete. The commonly accepted paradigm for partitioning functions is that they ought to be transversal to the studied vector field. We show that there is no complete partitioning with transversal functions, even for particular dynamical systems whose critical sets are isolated critical points. Therefore, we allow the directional derivative along the vector field to be non-positive in this work. This considerably complicates the abstraction technique. For understanding dynamical systems, it is vital to study stable and unstable manifolds and their intersections. These objects appear naturally in this work. Indeed, we show that for an abstraction to be complete, the set of critical points of an abstraction function shall contain either the stable or unstable manifold of the dynamical system.',
	 'authors': u'Rafael Wisniewski, Christoffer Sloth,',
	 'category': u'Computer Science ',
	 'date': '2013-8-24',
	 'pdflink': u'http://arxiv.org/pdf/1308.5333',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nCompleteness of Lyapunov Abstraction',
	 'urllink': u'http://arxiv.org/abs/1308.5333'}
2015-03-24 12:17:09+0000 [xxu46_7] INFO: Crawled 527 pages (at 1 pages/min), scraped 520 items (at 1 items/min)
2015-03-24 12:18:09+0000 [xxu46_7] INFO: Crawled 527 pages (at 0 pages/min), scraped 520 items (at 0 items/min)
2015-03-24 12:18:46+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6871> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 12:18:46+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6871>
	{'abstract': u'Recent advances in symbolic dynamic programming (SDP) combined with the extended algebraic decision diagram (XADD) data structure have provided exact solutions for mixed discrete and continuous (hybrid) MDPs with piecewise linear dynamics and continuous actions. Since XADD-based exact solutions may grow intractably large for many problems, we propose a bounded error compression technique for XADDs that involves the solution of a constrained bilinear saddle point problem. Fortuitously, we show that given the special structure of this problem, it can be expressed as a bilevel linear programming problem and solved to optimality in finite time via constraint generation, despite having an infinite set of constraints. This solution permits the use of efficient linear program solvers for XADD compression and enables a novel class of bounded approximate SDP algorithms for hybrid MDPs that empirically offers order-of-magnitude speedups over the exact solution in exchange for a small approximation error.',
	 'authors': u'Luis Gustavo Vianna, Scott Sanner, Leliane Nunes de Barros,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6871',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nBounded Approximate Symbolic Dynamic Programming for Hybrid MDPs',
	 'urllink': u'http://arxiv.org/abs/1309.6871'}
2015-03-24 12:19:09+0000 [xxu46_7] INFO: Crawled 528 pages (at 1 pages/min), scraped 521 items (at 1 items/min)
2015-03-24 12:20:03+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6416> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 12:20:03+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6416>
	{'abstract': u'The article introduces a ceteris paribus modal logic interpreted on the equivalence classes induced by sets of propositional atoms. This logic is used to embed two logics of agency and games, namely atemporal STIT and the coalition logic of propositional control (CL-PC). The embeddings highlight a common ceteris paribus structure underpinning the key modal operators of both logics, they clarify the relationship between STIT and CL-PC, and enable the transfer of complexity results to the ceteris paribus logic.',
	 'authors': u'Davide Grossi, Emiliano Lorini, Francois Schwarzentruber,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6416',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nCeteris Paribus Structure in Logics of Game Forms',
	 'urllink': u'http://arxiv.org/abs/1310.6416'}
2015-03-24 12:20:09+0000 [xxu46_7] INFO: Crawled 529 pages (at 1 pages/min), scraped 522 items (at 1 items/min)
2015-03-24 12:21:09+0000 [xxu46_7] INFO: Crawled 529 pages (at 0 pages/min), scraped 522 items (at 0 items/min)
2015-03-24 12:21:36+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5332> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 12:21:36+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5332>
	{'abstract': u'Complex systems are naturally hybrid: their dynamic behavior is both continuous and discrete. For these systems, maintenance and repair are an increasing part of the total cost of final product. Efficient diagnosis and prognosis techniques have to be adopted to detect, isolate and anticipate faults. This paper presents an original integrated theoretical framework for diagnosis and prognosis of hybrid systems. The formalism used for hybrid diagnosis is enriched in order to be able to follow the evolution of an aging law for each fault of the system. The paper presents a methodology for interleaving diagnosis and prognosis in a hybrid framework.',
	 'authors': u'Elodie Chanthery, Pauline Ribot,',
	 'category': u'Computer Science ',
	 'date': '2013-8-24',
	 'pdflink': u'http://arxiv.org/pdf/1308.5332',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nAn Integrated Framework for Diagnosis and Prognosis of Hybrid Systems',
	 'urllink': u'http://arxiv.org/abs/1308.5332'}
2015-03-24 12:22:09+0000 [xxu46_7] INFO: Crawled 530 pages (at 1 pages/min), scraped 523 items (at 1 items/min)
2015-03-24 12:22:59+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6870> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 12:22:59+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6870>
	{'abstract': u'In this paper, we investigate combining blocking and collapsing -- two widely used strategies for improving the accuracy of Gibbs sampling -- in the context of probabilistic graphical models (PGMs). We show that combining them is not straight-forward because collapsing (or eliminating variables) introduces new dependencies in the PGM and in computation-limited settings, this may adversely affect blocking. We therefore propose a principled approach for tackling this problem. Specifically, we develop two scoring functions, one each for blocking and collapsing, and formulate the problem of partitioning the variables in the PGM into blocked and collapsed subsets as simultaneously maximizing both scoring functions (i.e., a multi-objective optimization problem). We propose a dynamic, greedy algorithm for approximately solving this intractable optimization problem. Our dynamic algorithm periodically updates the partitioning into blocked and collapsed variables by leveraging correlation statistics gathered from the generated samples and enables rapid mixing by blocking together and collapsing highly correlated variables. We demonstrate experimentally the clear benefit of our dynamic approach: as more samples are drawn, our dynamic approach significantly outperforms static graph-based approaches by an order of magnitude in terms of accuracy.',
	 'authors': u'Deepak Venugopal, Vibhav Gogate,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6870',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nDynamic Blocking and Collapsing for Gibbs Sampling',
	 'urllink': u'http://arxiv.org/abs/1309.6870'}
2015-03-24 12:23:09+0000 [xxu46_7] INFO: Crawled 531 pages (at 1 pages/min), scraped 524 items (at 1 items/min)
2015-03-24 12:24:09+0000 [xxu46_7] INFO: Crawled 531 pages (at 0 pages/min), scraped 524 items (at 0 items/min)
2015-03-24 12:24:36+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6414> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 12:24:36+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6414>
	{'abstract': u'Coordinating activities at different sites of a multi-agent system typically imposes epistemic constraints on the participants. Specifying explicit bounds on the relative times at which actions are performed induces combined temporal and epistemic constraints on when agents can perform their actions. This paper characterises the interactive epistemic state that arises when actions must meet particular temporal constraints. The new state, called timely common knowledge, generalizes common knowledge, as well as other variants of common knowledge. While known variants of common knowledge are defined in terms of a fixed point of an epistemic formula, timely common knowledge is defined in terms of a vectorial fixed point of temporal-epistemic formulae. A general class of coordination tasks with timing constraints is defined, and timely common knowledge is used to characterise both solvability and optimal solutions of such tasks. Moreover, it is shown that under natural conditions, timely common knowledge is equivalent to an infinite conjunction of temporal-epistemic formulae, in analogy to the popular definition of common knowledge.',
	 'authors': u'Yannai A. Gonczarowski, Yoram Moses,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6414',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nTimely Common Knowledge',
	 'urllink': u'http://arxiv.org/abs/1310.6414'}
2015-03-24 12:25:09+0000 [xxu46_7] INFO: Crawled 532 pages (at 1 pages/min), scraped 525 items (at 1 items/min)
2015-03-24 12:26:09+0000 [xxu46_7] INFO: Crawled 532 pages (at 0 pages/min), scraped 525 items (at 0 items/min)
2015-03-24 12:26:10+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5331> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 12:26:10+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5331>
	{'abstract': u'Networked Embedded Control Systems are distributed control systems where the communication among plants, sensors, actuators and controllers occurs in a shared network. They have been the subject of intensive study in the last few years. In this paper we survey our contribution to this research topic.',
	 'authors': u'Maria Domenica Di Benedetto, Giordano Pola,',
	 'category': u'Computer Science ',
	 'date': '2013-8-24',
	 'pdflink': u'http://arxiv.org/pdf/1308.5331',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nNetworked Embedded Control Systems: from Modelling to Implementation',
	 'urllink': u'http://arxiv.org/abs/1308.5331'}
2015-03-24 12:27:09+0000 [xxu46_7] INFO: Crawled 533 pages (at 1 pages/min), scraped 526 items (at 1 items/min)
2015-03-24 12:27:27+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6869> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 12:27:27+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6869>
	{'abstract': u"We tackle the problem of online reward maximisation over a large finite set of actions described by their contexts. We focus on the case when the number of actions is too big to sample all of them even once. However we assume that we have access to the similarities between actions' contexts and that the expected reward is an arbitrary linear function of the contexts' images in the related reproducing kernel Hilbert space (RKHS). We propose KernelUCB, a kernelised UCB algorithm, and give a cumulative regret bound through a frequentist analysis. For contextual bandits, the related algorithm GP-UCB turns out to be a special case of our algorithm, and our finite-time analysis improves the regret bound of GP-UCB for the agnostic case, both in the terms of the kernel-dependent quantity and the RKHS norm of the reward function. Moreover, for the linear kernel, our regret bound matches the lower bound for contextual linear bandits.",
	 'authors': u'Michal Valko, Nathaniel Korda, Remi Munos, Ilias Flaounas, Nelo Cristianini,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6869',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nFinite-Time Analysis of Kernelised Contextual Bandits',
	 'urllink': u'http://arxiv.org/abs/1309.6869'}
2015-03-24 12:28:09+0000 [xxu46_7] INFO: Crawled 534 pages (at 1 pages/min), scraped 527 items (at 1 items/min)
2015-03-24 12:29:05+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6413> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 12:29:05+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6413>
	{'abstract': u'We describe a randomized algorithm that, given a set of points in the plane, computes the best location to insert a new point , such that the Delaunay triangulation of has the largest possible minimum angle. The expected running time of our algorithm is at most cubic, improving the roughly quartic time of the best previously known algorithm. It slows down to slightly super-cubic if we also specify a set of non-crossing segments with endpoints in and insist that the triangulation respect these segments, i.e., is the constrained Delaunay triangulation of the points and segments.',
	 'authors': u'Boris Aronov, Mark V. Yagnatinsky,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6413',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nHow To Place a Point to Maximize Angles',
	 'urllink': u'http://arxiv.org/abs/1310.6413'}
2015-03-24 12:29:09+0000 [xxu46_7] INFO: Crawled 535 pages (at 1 pages/min), scraped 528 items (at 1 items/min)
2015-03-24 12:30:09+0000 [xxu46_7] INFO: Crawled 535 pages (at 0 pages/min), scraped 528 items (at 0 items/min)
2015-03-24 12:31:05+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5330> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 12:31:05+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5330>
	{'abstract': u'Formal verification has been successfully developed in computer science for verifying combinatorial classes of models and specifications. In like manner, formal verification methods have been developed for dynamical systems. However, the verification of system properties, such as safety, is based on reachability calculations, which are the sources of insurmountable complexity. This talk addresses indirect verification methods, which are based on abstracting the dynamical systems by models of reduced complexity and preserving central properties of the original systems.',
	 'authors': u'Rafael Wisniewski,',
	 'category': u'Computer Science ',
	 'date': '2013-8-24',
	 'pdflink': u'http://arxiv.org/pdf/1308.5330',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nCombinatorial Abstractions of Dynamical Systems',
	 'urllink': u'http://arxiv.org/abs/1308.5330'}
2015-03-24 12:31:09+0000 [xxu46_7] INFO: Crawled 536 pages (at 1 pages/min), scraped 529 items (at 1 items/min)
2015-03-24 12:32:09+0000 [xxu46_7] INFO: Crawled 536 pages (at 0 pages/min), scraped 529 items (at 0 items/min)
2015-03-24 12:32:45+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6868> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 12:32:45+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6868>
	{'abstract': u'We seek to learn an effective policy for a Markov Decision Process (MDP) with continuous states via Q-Learning. Given a set of basis functions over state action pairs we search for a corresponding set of linear weights that minimizes the mean Bellman residual. Our algorithm uses a Kalman filter model to estimate those weights and we have developed a simpler approximate Kalman filter model that outperforms the current state of the art projected TD-Learning methods on several standard benchmark problems.',
	 'authors': u'Charles Tripp, Ross D. Shachter,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6868',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nApproximate Kalman Filter Q-Learning for Continuous State-Space MDPs',
	 'urllink': u'http://arxiv.org/abs/1309.6868'}
2015-03-24 12:33:09+0000 [xxu46_7] INFO: Crawled 537 pages (at 1 pages/min), scraped 530 items (at 1 items/min)
2015-03-24 12:33:54+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6411> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 12:33:54+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6411>
	{'abstract': u'From the standpoint of game theory, dominoes is a game that has not received much attention (specially the variety known as draw). It is usually thought that this game is already solved, given general results in game theory. However, the determination of equilibria is not feasible for the general case because of the well known problem of node explosion in the tree expressing the game. We propose a new model based in limited forecast as a kind of bounded rationality for dynamic alternate games.',
	 'authors': u'Eduardo Espinosa-Avila, Francisco Hernandez-Quiroz,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6411',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nBounded rationality in a dynamic alternate game',
	 'urllink': u'http://arxiv.org/abs/1310.6411'}
2015-03-24 12:34:09+0000 [xxu46_7] INFO: Crawled 538 pages (at 1 pages/min), scraped 531 items (at 1 items/min)
2015-03-24 12:35:09+0000 [xxu46_7] INFO: Crawled 538 pages (at 0 pages/min), scraped 531 items (at 0 items/min)
2015-03-24 12:35:19+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5329> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 12:35:19+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5329>
	{'abstract': u'We discuss the problem of runtime verification of an instrumented program that misses to emit and to monitor some events. These gaps can occur when a monitoring overhead control mechanism is introduced to disable the monitor of an application with real-time constraints. We show how to use statistical models to learn the application behavior and to "fill in" the introduced gaps. Finally, we present and discuss some techniques developed in the last three years to estimate the probability that a property of interest is violated in the presence of an incomplete trace.',
	 'authors': u'Ezio Bartocci, Radu Grosu,',
	 'category': u'Computer Science ',
	 'date': '2013-8-24',
	 'pdflink': u'http://arxiv.org/pdf/1308.5329',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nMonitoring with uncertainty',
	 'urllink': u'http://arxiv.org/abs/1308.5329'}
2015-03-24 12:36:09+0000 [xxu46_7] INFO: Crawled 539 pages (at 1 pages/min), scraped 532 items (at 1 items/min)
2015-03-24 12:36:35+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6867> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 12:36:35+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6867>
	{'abstract': u"We tackle the challenge of efficiently learning the structure of expressive multivariate real-valued densities of copula graphical models. We start by theoretically substantiating the conjecture that for many copula families the magnitude of Spearman's rank correlation coefficient is monotone in the expected contribution of an edge in network, namely the negative copula entropy. We then build on this theory and suggest a novel Bayesian approach that makes use of a prior over values of Spearman's rho for learning copula-based models that involve a mix of copula families. We demonstrate the generalization effectiveness of our highly efficient approach on sizable and varied real-life datasets.",
	 'authors': u'Yaniv Tenzer, Gal Elidan,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6867',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nSpeedy Model Selection (SMS) for Copula Models',
	 'urllink': u'http://arxiv.org/abs/1309.6867'}
2015-03-24 12:37:09+0000 [xxu46_7] INFO: Crawled 540 pages (at 1 pages/min), scraped 533 items (at 1 items/min)
2015-03-24 12:38:09+0000 [xxu46_7] INFO: Crawled 540 pages (at 0 pages/min), scraped 533 items (at 0 items/min)
2015-03-24 12:38:28+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6410> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 12:38:28+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6410>
	{'abstract': u'We compare different epistemic notions in the presence of awareness of propositional variables: the logics of implicit knowledge (in which explicit knowledge is definable), explicit knowledge, and speculative knowledge. Different notions of bisimulation are suitable for these logics. We provide correspondence between bisimulation and modal equivalence on image-finite models for these logics. The logic of speculative knowledge is equally expressive as the logic of explicit knowledge, and the logic of implicit knowledge is more expressive than both. We also provide axiomatizations for the three logics -- only the one for speculative knowledge is novel. Then we move to the study of dynamics by recalling action models incorporating awareness. We show that any conceivable change of knowledge or awareness can be modelled in this setting, we give a complete axiomatization for the dynamic logic of implicit knowledge. The dynamic versions of all three logics are, surprising, equally expressive.',
	 'authors': u'Hans van Ditmarsch, Tim French, Fernando R. Velazquez-Quesada, Yi N. Wang,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6410',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nKnowledge, Awareness, and Bisimulation',
	 'urllink': u'http://arxiv.org/abs/1310.6410'}
2015-03-24 12:39:09+0000 [xxu46_7] INFO: Crawled 541 pages (at 1 pages/min), scraped 534 items (at 1 items/min)
2015-03-24 12:40:09+0000 [xxu46_7] INFO: Crawled 541 pages (at 0 pages/min), scraped 534 items (at 0 items/min)
2015-03-24 12:40:16+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5326> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 12:40:16+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5326>
	{'abstract': u"Based on fixed point theory, this paper proposes a simple but efficient method for image integrity authentication, which is different from Digital Signature and Fragile Watermarking. By this method, any given image can be transformed into a fixed point of a well-chosen function, which can be constructed with periodic functions. The authentication can be realized due to the fragility of the fixed points. The experiments show that 'Fixed Point Image' performs well in security, transparence, fragility and tampering localization.",
	 'authors': u'Xu Li, Xingming Sun, Quansheng Liu, Beijing Chen,',
	 'category': u'Computer Science ',
	 'date': '2013-8-24',
	 'pdflink': u'http://arxiv.org/pdf/1308.5326',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nA Novel Method for Image Integrity Authentication Based on Fixed Point  Theory',
	 'urllink': u'http://arxiv.org/abs/1308.5326'}
2015-03-24 12:41:09+0000 [xxu46_7] INFO: Crawled 542 pages (at 1 pages/min), scraped 535 items (at 1 items/min)
2015-03-24 12:41:48+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6865> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 12:41:48+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6865>
	{'abstract': u'We introduce a Deep Boltzmann Machine model suitable for modeling and extracting latent semantic representations from a large unstructured collection of documents. We overcome the apparent difficulty of training a DBM with judicious parameter tying. This parameter tying enables an efficient pretraining algorithm and a state initialization scheme that aids inference. The model can be trained just as efficiently as a standard Restricted Boltzmann Machine. Our experiments show that the model assigns better log probability to unseen data than the Replicated Softmax model. Features extracted from our model outperform LDA, Replicated Softmax, and DocNADE models on document retrieval and document classification tasks.',
	 'authors': u'Nitish Srivastava, Ruslan R Salakhutdinov, Geoffrey E. Hinton,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6865',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nModeling Documents with Deep Boltzmann Machines',
	 'urllink': u'http://arxiv.org/abs/1309.6865'}
2015-03-24 12:42:09+0000 [xxu46_7] INFO: Crawled 543 pages (at 1 pages/min), scraped 536 items (at 1 items/min)
2015-03-24 12:43:09+0000 [xxu46_7] INFO: Crawled 543 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2015-03-24 12:43:24+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6409> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 12:43:24+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6409>
	{'abstract': u"Nonmonotonic logics are usually characterized by the presence of some notion of 'conditional' that fails monotonicity. Research on nonmonotonic logics is therefore largely concerned with the defeasibility of argument forms and the associated normality (or abnormality) of its constituents. In contrast, defeasible modes of inference aim to formalize the defeasible aspects of modal notions such as actions, obligations and knowledge. In this work we enrich the standard possible worlds semantics with a preference ordering on worlds in Kripke models. The resulting family of modal logics allow for the elegant expression of defeasible modalities. We also propose a tableau calculus which is sound and complete with respect to our preferential semantics.",
	 'authors': u'Katarina Britz, Ivan Varzinczak,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6409',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nDefeasible Modalities',
	 'urllink': u'http://arxiv.org/abs/1310.6409'}
2015-03-24 12:44:09+0000 [xxu46_7] INFO: Crawled 544 pages (at 1 pages/min), scraped 537 items (at 1 items/min)
2015-03-24 12:45:09+0000 [xxu46_7] INFO: Crawled 544 pages (at 0 pages/min), scraped 537 items (at 0 items/min)
2015-03-24 12:45:17+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5321> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 12:45:17+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5321>
	{'abstract': u'The present study gives a mathematical framework for self-evolution within autonomous problem solving systems. Special attention is set on universal abstraction, thereof generation by net block homomorphism, consequently multiple order solving systems and the overall decidability of the set of the solutions. By overlapping presentation of nets new abstraction relation among nets is formulated alongside with consequent alphabetical net block renetting system proportional to normal forms of renetting systems regarding the operational power. A new structure in self-evolving problem solving is established via saturation by groups of equivalence relations and iterative closures of generated quotient transducer algebras over the whole evolution.',
	 'authors': u'Seppo Ilari Tirri,',
	 'category': u'Computer Science ',
	 'date': '2013-8-24',
	 'pdflink': u'http://arxiv.org/pdf/1308.5321',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nEvolution Theory of Self-Evolving Autonomous Problem Solving Systems',
	 'urllink': u'http://arxiv.org/abs/1308.5321'}
2015-03-24 12:46:09+0000 [xxu46_7] INFO: Crawled 545 pages (at 1 pages/min), scraped 538 items (at 1 items/min)
2015-03-24 12:47:09+0000 [xxu46_7] INFO: Crawled 545 pages (at 0 pages/min), scraped 538 items (at 0 items/min)
2015-03-24 12:47:13+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6864> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 12:47:13+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6864>
	{'abstract': u'This paper discusses . These are a class of parametric models that generate partial ranks over alternatives given attributes of agents and alternatives. We propose two preference elicitation scheme for GRUMs developed from principles in Bayesian experimental design, one for social choice and the other for personalized choice. We couple this with a general Monte-Carlo-Expectation-Maximization (MC-EM) based algorithm for MAP inference under GRUMs. We also prove uni-modality of the likelihood functions for a class of GRUMs. We examine the performance of various criteria by experimental studies, which show that the proposed elicitation scheme increases the precision of estimation.',
	 'authors': u'Hossein Azari Soufiani, David C. Parkes, Lirong Xia,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6864',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nPreference Elicitation For General Random Utility Models',
	 'urllink': u'http://arxiv.org/abs/1309.6864'}
2015-03-24 12:48:09+0000 [xxu46_7] INFO: Crawled 546 pages (at 1 pages/min), scraped 539 items (at 1 items/min)
2015-03-24 12:48:42+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6408> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 12:48:42+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6408>
	{'abstract': u'We introduce language-based games, a generalization of psychological games [6] that can also capture reference-dependent preferences [7]. The idea is to extend the domain of the utility function to situations, maximal consistent sets in some language. The role of the underlying language in this framework is thus particularly critical. Of special interest are languages that can express only coarse beliefs [9]. Despite the expressive power of the approach, we show that it can describe games in a simple, natural way. Nash equilibrium and rationalizability are generalized to this setting; Nash equilibrium is shown not to exist in general, while the existence of rationalizable strategies is proved under mild conditions.',
	 'authors': u'Adam Bjorndahl, Joseph Y. Halpern, Rafael Pass,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6408',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nLanguage-based Games',
	 'urllink': u'http://arxiv.org/abs/1310.6408'}
2015-03-24 12:49:09+0000 [xxu46_7] INFO: Crawled 547 pages (at 1 pages/min), scraped 540 items (at 1 items/min)
2015-03-24 12:50:09+0000 [xxu46_7] INFO: Crawled 547 pages (at 0 pages/min), scraped 540 items (at 0 items/min)
2015-03-24 12:50:42+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5315> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 12:50:42+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5315>
	{'abstract': u'Here we discuss the application of an edge detection filter, the Sobel filter of GIMP, to the recently discovered motion of some sand dunes on Mars. The filter allows a good comparison of an image HiRISE of 2007 and an image of 1999 recorded by the Mars Global Surveyor of the dunes in the Nili Patera caldera, measuring therefore the motion of the dunes on a longer period of time than that previously investigated.',
	 'authors': u'Amelia Carolina Sparavigna,',
	 'category': u'Computer Science ',
	 'date': '2013-8-24',
	 'pdflink': u'http://arxiv.org/pdf/1308.5315',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nEdge-detection applied to moving sand dunes on Mars',
	 'urllink': u'http://arxiv.org/abs/1308.5315'}
2015-03-24 12:51:09+0000 [xxu46_7] INFO: Crawled 548 pages (at 1 pages/min), scraped 541 items (at 1 items/min)
2015-03-24 12:52:09+0000 [xxu46_7] INFO: Crawled 548 pages (at 0 pages/min), scraped 541 items (at 0 items/min)
2015-03-24 12:52:20+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6863> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 12:52:20+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6863>
	{'abstract': u"Hidden variables are ubiquitous in practical data analysis, and therefore modeling marginal densities and doing inference with the resulting models is an important problem in statistics, machine learning, and causal inference. Recently, a new type of graphical model, called the nested Markov model, was developed which captures equality constraints found in marginals of directed acyclic graph (DAG) models. Some of these constraints, such as the so called `Verma constraint', strictly generalize conditional independence. To make modeling and inference with nested Markov models practical, it is necessary to limit the number of parameters in the model, while still correctly capturing the constraints in the marginal of a DAG model. Placing such limits is similar in spirit to sparsity methods for undirected graphical models, and regression models. In this paper, we give a log-linear parameterization which allows sparse modeling with nested Markov models. We illustrate the advantages of this parameterization with a simulation study.",
	 'authors': u'Ilya Shpitser, Robin J. Evans, Thomas S. Richardson, James M. Robins,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6863',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nSparse Nested Markov models with Log-linear Parameters',
	 'urllink': u'http://arxiv.org/abs/1309.6863'}
2015-03-24 12:53:09+0000 [xxu46_7] INFO: Crawled 549 pages (at 1 pages/min), scraped 542 items (at 1 items/min)
2015-03-24 12:54:09+0000 [xxu46_7] INFO: Crawled 549 pages (at 0 pages/min), scraped 542 items (at 0 items/min)
2015-03-24 12:54:21+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6407> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 12:54:21+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6407>
	{'abstract': u'This paper studies the interaction between knowledge, time and coordination in systems in which timing information is available. Necessary conditions are given for the causal structure in coordination problems consisting of orchestrating a set of actions in a manner that satisfies a variety of temporal ordering assumptions. Results are obtained in two main steps: A specification of coordination is shown to require epistemic properties, and the causal structure required to obtain these properties is characterised via "knowledge gain" theorems. A new causal structure called a centibroom structure is presented, generalising previous causal structures for this model. It is shown to capture coordination tasks in which a sequence of clusters of events is performed in linear order, while within each cluster all actions must take place simultaneously. This form of coordination is shown to require the agents to gain a nested common knowledge of particular facts, which in turn requires a centibroom. Altogether, the results presented provide a broad view of the causal shape underlying partially ordered coordinated actions. This, in turn, provides insight into and can enable the design of efficient solutions to the coordination tasks in question.',
	 'authors': u'Ido Ben-Zvi, Yoram Moses,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6407',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nThe Shape of Reactive Coordination Tasks',
	 'urllink': u'http://arxiv.org/abs/1310.6407'}
2015-03-24 12:55:09+0000 [xxu46_7] INFO: Crawled 550 pages (at 1 pages/min), scraped 543 items (at 1 items/min)
2015-03-24 12:56:09+0000 [xxu46_7] INFO: Crawled 550 pages (at 0 pages/min), scraped 543 items (at 0 items/min)
2015-03-24 12:56:14+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5310> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 12:56:14+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5310>
	{'abstract': u'Introducing Internet traffic anomaly detection mechanism based on large deviations results for empirical measures. Using past traffic traces we characterize network traffic during various time-of-day intervals, assuming that it is anomaly-free. Throughout, we compare the two approaches presenting their advantages and disadvantages to identify and classify temporal network anomalies. We also demonstrate how our framework can be used to monitor traffic from multiple network elements in order to identify both spatial and temporal anomalies. We validate our techniques by analyzing real traffic traces with time-stamped anomalies.',
	 'authors': u'A.S.Syed Navaz, S.Gopalakrishnan, R.Meena,',
	 'category': u'Computer Science ',
	 'date': '2013-8-24',
	 'pdflink': u'http://arxiv.org/pdf/1308.5310',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nAnomaly Detections in Internet traffic Using Empirical Measures',
	 'urllink': u'http://arxiv.org/abs/1308.5310'}
2015-03-24 12:57:09+0000 [xxu46_7] INFO: Crawled 551 pages (at 1 pages/min), scraped 544 items (at 1 items/min)
2015-03-24 12:58:09+0000 [xxu46_7] INFO: Crawled 551 pages (at 0 pages/min), scraped 544 items (at 0 items/min)
2015-03-24 12:58:09+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6862> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 12:58:09+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6862>
	{'abstract': u'Semi-supervised clustering is the task of clustering data points into clusters where only a fraction of the points are labelled. The true number of clusters in the data is often unknown and most models require this parameter as an input. Dirichlet process mixture models are appealing as they can infer the number of clusters from the data. However, these models do not deal with high dimensional data well and can encounter difficulties in inference. We present a novel nonparameteric Bayesian kernel based method to cluster data points without the need to prespecify the number of clusters or to model complicated densities from which data points are assumed to be generated from. The key insight is to use determinants of submatrices of a kernel matrix as a measure of how close together a set of points are. We explore some theoretical properties of the model and derive a natural Gibbs based algorithm with MCMC hyperparameter learning. The model is implemented on a variety of synthetic and real world data sets.',
	 'authors': u'Amar Shah, Zoubin Ghahramani,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6862',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nDeterminantal Clustering Processes - A Nonparametric Bayesian Approach  to Kernel Based Semi-Supervised Clustering',
	 'urllink': u'http://arxiv.org/abs/1309.6862'}
2015-03-24 12:59:09+0000 [xxu46_7] INFO: Crawled 552 pages (at 1 pages/min), scraped 545 items (at 1 items/min)
2015-03-24 12:59:53+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6406> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 12:59:53+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6406>
	{'abstract': u'Although Dynamic Epistemic Logic (DEL) is an influential logical framework for representing and reasoning about information change, little is known about the computational complexity of its associated decision problems. In fact, we only know that for public announcement logic, a fragment of DEL, the satisfiability problem and the model-checking problem are respectively PSPACE-complete and in P. We contribute to fill this gap by proving that for the DEL language with event models, the model-checking problem is, surprisingly, PSPACE-complete. Also, we prove that the satisfiability problem is NEXPTIME-complete. In doing so, we provide a sound and complete tableau method deciding the satisfiability problem.',
	 'authors': u'Guillaume Aucher, Francois Schwarzentruber,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6406',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nOn the Complexity of Dynamic Epistemic Logic',
	 'urllink': u'http://arxiv.org/abs/1310.6406'}
2015-03-24 13:00:09+0000 [xxu46_7] INFO: Crawled 553 pages (at 1 pages/min), scraped 546 items (at 1 items/min)
2015-03-24 13:01:09+0000 [xxu46_7] INFO: Crawled 553 pages (at 0 pages/min), scraped 546 items (at 0 items/min)
2015-03-24 13:01:33+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5304> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 13:01:33+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5304>
	{'abstract': u'We study physical-layer security in wireless ad hoc networks and investigate two types of multi-antenna transmission schemes for providing secrecy enhancements. To establish secure transmission against malicious eavesdroppers, we consider the generation of artificial noise with either sectoring or beamforming. For both approaches, we provide a statistical characterization and tradeoff analysis of the outage performance of the legitimate communication and the eavesdropping links. We then investigate the networkwide secrecy throughput performance of both schemes in terms of the secrecy transmission capacity, and study the optimal power allocation between the information signal and the artificial noise. Our analysis indicates that, under transmit power optimization, the beamforming scheme outperforms the sectoring scheme, except for the case where the number of transmit antennas are sufficiently large. Our study also reveals some interesting differences between the optimal power allocation for the sectoring and beamforming schemes.',
	 'authors': u'Xi Zhang, Xiangyun Zhou, Matthew R. McKay,',
	 'category': u'Computer Science ',
	 'date': '2013-8-24',
	 'pdflink': u'http://arxiv.org/pdf/1308.5304',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nEnhancing Secrecy with Multi-Antenna Transmission in Wireless Ad Hoc  Networks',
	 'urllink': u'http://arxiv.org/abs/1308.5304'}
2015-03-24 13:02:09+0000 [xxu46_7] INFO: Crawled 554 pages (at 1 pages/min), scraped 547 items (at 1 items/min)
2015-03-24 13:03:09+0000 [xxu46_7] INFO: Crawled 554 pages (at 0 pages/min), scraped 547 items (at 0 items/min)
2015-03-24 13:03:30+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6860> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 13:03:30+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6860>
	{'abstract': u'We propose a kernel method to identify finite mixtures of nonparametric product distributions. It is based on a Hilbert space embedding of the joint distribution. The rank of the constructed tensor is equal to the number of mixture components. We present an algorithm to recover the components by partitioning the data points into clusters such that the variables are jointly conditionally independent given the cluster. This method can be used to identify finite confounders.',
	 'authors': u'Eleni Sgouritsa, Dominik Janzing, Jonas Peters, Bernhard Schoelkopf,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6860',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nIdentifying Finite Mixtures of Nonparametric Product Distributions and  Causal Inference of Confounders',
	 'urllink': u'http://arxiv.org/abs/1309.6860'}
2015-03-24 13:04:09+0000 [xxu46_7] INFO: Crawled 555 pages (at 1 pages/min), scraped 548 items (at 1 items/min)
2015-03-24 13:05:01+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6405> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 13:05:01+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6405>
	{'abstract': u"We consider a calculus of resources and processes as a basis for modelling decision-making in multi-agent systems. The calculus represents the regulation of agents' choices using utility functions that take account of context. Associated with the calculus is a (Hennessy Milner-style) context sensitive modal logic of state. As an application, we show how a notion of `trust domain' can be defined for multi-agent systems.",
	 'authors': u'Gabrielle Anderson, Matthew Collinson, David Pym,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6405',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nUtility-based Decision-making in Distributed Systems Modelling',
	 'urllink': u'http://arxiv.org/abs/1310.6405'}
2015-03-24 13:05:09+0000 [xxu46_7] INFO: Crawled 556 pages (at 1 pages/min), scraped 549 items (at 1 items/min)
2015-03-24 13:06:09+0000 [xxu46_7] INFO: Crawled 556 pages (at 0 pages/min), scraped 549 items (at 0 items/min)
2015-03-24 13:06:22+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5286> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 13:06:22+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5286>
	{'abstract': u'To manage the problem of having a higher demand for resources than availability of funds, research funding agencies usually rank the major research groups in their area of knowledge. This ranking relies on a careful analysis of the research groups in terms of their size, number of PhDs graduated, research results and their impact, among other variables. While research results are not the only variable to consider, they are frequently given special attention because of the notoriety they confer to the researchers and the programs they are affiliated with. In here we introduce a new metric for quantifying publication output, called R-Score for reputation-based score, which can be used in support to the ranking of research groups or programs. The novelty is that the metric depends solely on the listings of the publications of the members of a group, with no dependency on citation counts. R-Score has some interesting properties: (a) it does not require access to the contents of published material, (b) it can be curated to produce highly accurate results, and (c) it can be naturally used to compare publication output of research groups (e.g., graduate programs) inside a same country, geographical area, or across the world. An experiment comparing the publication output of 25 CS graduate programs from Brazil suggests that R-Score can be quite useful for providing early insights into the publication patterns of the various research groups one wants to compare.',
	 'authors': u'Sabir Ribas, Berthier Ribeiro-Neto, Edmundo de Souza e Silva, Nivio Ziviani,',
	 'category': u'Computer Science ',
	 'date': '2013-8-24',
	 'pdflink': u'http://arxiv.org/pdf/1308.5286',
	 'subjects': u'Digital Libraries (cs.DL)',
	 'title': u'\nR-Score: Reputation-based Scoring of Research Groups',
	 'urllink': u'http://arxiv.org/abs/1308.5286'}
2015-03-24 13:07:09+0000 [xxu46_7] INFO: Crawled 557 pages (at 1 pages/min), scraped 550 items (at 1 items/min)
2015-03-24 13:08:07+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6859> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 13:08:07+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6859>
	{'abstract': u'A recent result has demonstrated that the Bethe partition function always lower bounds the true partition function of binary, log-supermodular graphical models. We demonstrate that these results can be extended to other interesting classes of graphical models that are not necessarily binary or log-supermodular: the ferromagnetic Potts model with a uniform external field and its generalizations and special classes of weighted graph homomorphism problems.',
	 'authors': u'Nicholas Ruozzi,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6859',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nBeyond Log-Supermodularity: Lower Bounds and the Bethe Partition  Function',
	 'urllink': u'http://arxiv.org/abs/1309.6859'}
2015-03-24 13:08:09+0000 [xxu46_7] INFO: Crawled 558 pages (at 1 pages/min), scraped 551 items (at 1 items/min)
2015-03-24 13:09:03+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6398> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 13:09:03+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6398>
	{'abstract': u'We first give an improved lower bound for the deterministic online-simulation of tapes or pushdown stores by queues. Then we inspect some proofs in a classical work on queue machines in the area of Formal Languages and outline why a main argument in the proofs is incomplete.',
	 'authors': u'Holger Petersen,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6398',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nSome Remarks on Lower Bounds for Queue Machines (Preliminary Report)',
	 'urllink': u'http://arxiv.org/abs/1310.6398'}
2015-03-24 13:09:09+0000 [xxu46_7] INFO: Crawled 559 pages (at 1 pages/min), scraped 552 items (at 1 items/min)
2015-03-24 13:10:09+0000 [xxu46_7] INFO: Crawled 559 pages (at 0 pages/min), scraped 552 items (at 0 items/min)
2015-03-24 13:10:52+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5281> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 13:10:52+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5281>
	{'abstract': u'We present an efficient distributed online learning scheme to classify data captured from distributed, heterogeneous, and dynamic data sources. Our scheme consists of multiple distributed local learners, that analyze different streams of data that are correlated to a common event that needs to be classified. Each learner uses a local classifier to make a local prediction. The local predictions are then collected by each learner and combined using a weighted majority rule to output the final prediction. We propose a novel online ensemble learning algorithm to update the aggregation rule in order to adapt to the underlying data dynamics. We rigorously determine a bound for the worst case misclassification probability of our algorithm which depends on the misclassification probabilities of the best static aggregation rule, and of the best local classifier. Importantly, the worst case misclassification probability of our algorithm tends asymptotically to 0 if the misclassification probability of the best static aggregation rule or the misclassification probability of the best local classifier tend to 0. Then we extend our algorithm to address challenges specific to the distributed implementation and we prove new bounds that apply to these settings. Finally, we test our scheme by performing an evaluation study on several data sets. When applied to data sets widely used by the literature dealing with dynamic data streams and concept drift, our scheme exhibits performance gains ranging from 34% to 71% with respect to state of the art solutions.',
	 'authors': u'Luca Canzian, Yu Zhang, Mihaela van der Schaar,',
	 'category': u'Computer Science ',
	 'date': '2013-8-24',
	 'pdflink': u'http://arxiv.org/pdf/1308.5281',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nEnsemble of Distributed Learners for Online Classification of Dynamic  Data Streams',
	 'urllink': u'http://arxiv.org/abs/1308.5281'}
2015-03-24 13:11:09+0000 [xxu46_7] INFO: Crawled 560 pages (at 1 pages/min), scraped 553 items (at 1 items/min)
2015-03-24 13:12:08+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6858> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 13:12:08+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6858>
	{'abstract': u'We propose a probabilistic model to infer supervised latent variables in the Hamming space from observed data. Our model allows simultaneous inference of the number of binary latent variables, and their values. The latent variables preserve neighbourhood structure of the data in a sense that objects in the same semantic concept have similar latent values, and objects in different concepts have dissimilar latent values. We formulate the supervised infinite latent variable problem based on an intuitive principle of pulling objects together if they are of the same type, and pushing them apart if they are not. We then combine this principle with a flexible Indian Buffet Process prior on the latent variables. We show that the inferred supervised latent variables can be directly used to perform a nearest neighbour search for the purpose of retrieval. We introduce a new application of dynamically extending hash codes, and show how to effectively couple the structure of the hash codes with continuously growing structure of the neighbourhood preserving infinite latent feature space.',
	 'authors': u'Novi Quadrianto, Viktoriia Sharmanska, David A. Knowles, Zoubin Ghahramani,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6858',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nThe Supervised IBP: Neighbourhood Preserving Infinite Latent Feature  Models',
	 'urllink': u'http://arxiv.org/abs/1309.6858'}
2015-03-24 13:12:09+0000 [xxu46_7] INFO: Crawled 561 pages (at 1 pages/min), scraped 554 items (at 1 items/min)
2015-03-24 13:13:09+0000 [xxu46_7] INFO: Crawled 561 pages (at 0 pages/min), scraped 554 items (at 0 items/min)
2015-03-24 13:14:09+0000 [xxu46_7] INFO: Crawled 561 pages (at 0 pages/min), scraped 554 items (at 0 items/min)
2015-03-24 13:14:10+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6397> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 13:14:10+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6397>
	{'abstract': u'Nowadays the radio interface of several standards is enhanced with advanced technologies such as OFDMA and extension technology such as relay. By using those promising transmission technology for the next generation wireless communications, scheduling problem becomes more crucial and challenging. In our work, we aim to maximize the overall system capacity while selecting the most suitable relay station under fairness constraint among both users and relay station by proposing a Gap- based scheduling. This one considers the channel state information and the unbalanced rate capacity of the two hops links. Simulations results show the effectiveness of our approach in terms of fairness and the overall system performance.',
	 'authors': u'Maryam Basly, Hedia Kochkar, Ammar Bouallegue,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6397',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nVariance Based Scheduling Algorithm with Relay Selection and Resource  Allocation in Cooperative OFDMA Networks',
	 'urllink': u'http://arxiv.org/abs/1310.6397'}
2015-03-24 13:15:09+0000 [xxu46_7] INFO: Crawled 562 pages (at 1 pages/min), scraped 555 items (at 1 items/min)
2015-03-24 13:16:02+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5275> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 13:16:02+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5275>
	{'abstract': u'We extend the recently introduced theory of Lovasz-Bregman (LB) divergences (Iyer &amp; Bilmes, 2012) in several ways. We show that they represent a distortion between a \'score\' and an \'ordering\', thus providing a new view of rank aggregation and order based clustering with interesting connections to web ranking. We show how the LB divergences have a number of properties akin to many permutation based metrics, and in fact have as special cases forms very similar to the Kendall- metric. We also show how the LB divergences subsume a number of commonly used ranking measures in information retrieval, like the NDCG and AUC. Unlike the traditional permutation based metrics, however, the LB divergence naturally captures a notion of "confidence" in the orderings, thus providing a new representation to applications involving aggregating scores as opposed to just orderings. We show how a number of recently used web ranking models are forms of Lovasz-Bregman rank aggregation and also observe that a natural form of Mallow\'s model using the LB divergence has been used as conditional ranking models for the \'Learning to Rank\' problem.',
	 'authors': u'Rishabh Iyer, Jeff Bilmes,',
	 'category': u'Computer Science ',
	 'date': '2013-8-24',
	 'pdflink': u'http://arxiv.org/pdf/1308.5275',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nThe Lovasz-Bregman Divergence and connections to rank aggregation,  clustering, and web ranking',
	 'urllink': u'http://arxiv.org/abs/1308.5275'}
2015-03-24 13:16:09+0000 [xxu46_7] INFO: Crawled 563 pages (at 1 pages/min), scraped 556 items (at 1 items/min)
2015-03-24 13:17:09+0000 [xxu46_7] INFO: Crawled 563 pages (at 0 pages/min), scraped 556 items (at 0 items/min)
2015-03-24 13:17:45+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6857> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 13:17:45+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6857>
	{'abstract': u'We propose solution methods for previously-unsolved constrained MDPs in which actions can continuously modify the transition probabilities within some acceptable sets. While many methods have been proposed to solve regular MDPs with large state sets, there are few practical approaches for solving constrained MDPs with large action sets. In particular, we show that the continuous action sets can be replaced by their extreme points when the rewards are linear in the modulation. We also develop a tractable optimization formulation for concave reward functions and, surprisingly, also extend it to non- concave reward functions by using their concave envelopes. We evaluate the effectiveness of the approach on the problem of managing delinquencies in a portfolio of loans.',
	 'authors': u'Marek Petrik, Dharmashankar Subramanian, Janusz Marecki,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6857',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nSolution Methods for Constrained Markov Decision Process with Continuous  Probability Modulation',
	 'urllink': u'http://arxiv.org/abs/1309.6857'}
2015-03-24 13:18:09+0000 [xxu46_7] INFO: Crawled 564 pages (at 1 pages/min), scraped 557 items (at 1 items/min)
2015-03-24 13:18:55+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6383> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 13:18:55+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6383>
	{'abstract': u'A 1976 theorem of Chaitin can be used to show that arbitrarily dense sets of lengths n have a paucity of trivial strings (only a bounded number of strings of length n having trivially low plain Kolmogorov complexities). We use the probabilistic method to give a new proof of this fact. This proof is much simpler than previously published proofs, and it gives a tighter paucity bound.',
	 'authors': u'Jack H. Lutz,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6383',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nThe Frequent Paucity of Trivial Strings',
	 'urllink': u'http://arxiv.org/abs/1310.6383'}
2015-03-24 13:19:09+0000 [xxu46_7] INFO: Crawled 565 pages (at 1 pages/min), scraped 558 items (at 1 items/min)
2015-03-24 13:20:09+0000 [xxu46_7] INFO: Crawled 565 pages (at 0 pages/min), scraped 558 items (at 0 items/min)
2015-03-24 13:20:50+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5273> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 13:20:50+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5273>
	{'abstract': u'Crowdsourcing offers a practical method for ranking and scoring large amounts of items. To investigate the algorithms and incentives that can be used in crowdsourcing quality evaluations, we built CrowdGrader, a tool that lets students submit and collaboratively grade solutions to homework assignments. We present the algorithms and techniques used in CrowdGrader, and we describe our results and experience in using the tool for several computer-science assignments. CrowdGrader combines the student-provided grades into a consensus grade for each submission using a novel crowdsourcing algorithm that relies on a reputation system. The algorithm iterativerly refines inter-dependent estimates of the consensus grades, and of the grading accuracy of each student. On synthetic data, the algorithm performs better than alternatives not based on reputation. On our preliminary experimental data, the performance seems dependent on the nature of review errors, with errors that can be ascribed to the reviewer being more tractable than those arising from random external events. To provide an incentive for reviewers, the grade each student receives in an assignment is a combination of the consensus grade received by their submissions, and of a reviewing grade capturing their reviewing effort and accuracy. This incentive worked well in practice.',
	 'authors': u'Luca de Alfaro, Michael Shavlovsky,',
	 'category': u'Computer Science ',
	 'date': '2013-8-24',
	 'pdflink': u'http://arxiv.org/pdf/1308.5273',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nCrowdGrader: Crowdsourcing the Evaluation of Homework Assignments',
	 'urllink': u'http://arxiv.org/abs/1308.5273'}
2015-03-24 13:21:09+0000 [xxu46_7] INFO: Crawled 566 pages (at 1 pages/min), scraped 559 items (at 1 items/min)
2015-03-24 13:22:09+0000 [xxu46_7] INFO: Crawled 566 pages (at 0 pages/min), scraped 559 items (at 0 items/min)
2015-03-24 13:22:43+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6856> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 13:22:43+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6856>
	{'abstract': u'This paper is devoted to fair optimization in Multiobjective Markov Decision Processes (MOMDPs). A MOMDP is an extension of the MDP model for planning under uncertainty while trying to optimize several reward functions simultaneously. This applies to multiagent problems when rewards define individual utility functions, or in multicriteria problems when rewards refer to different features. In this setting, we study the determination of policies leading to Lorenz-non-dominated tradeoffs. Lorenz dominance is a refinement of Pareto dominance that was introduced in Social Choice for the measurement of inequalities. In this paper, we introduce methods to efficiently approximate the sets of Lorenz-non-dominated solutions of infinite-horizon, discounted MOMDPs. The approximations are polynomial-sized subsets of those solutions.',
	 'authors': u'Patrice Perny, Paul Weng, Judy Goldsmith, Josiah Hanna,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6856',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nApproximation of Lorenz-Optimal Solutions in Multiobjective Markov  Decision Processes',
	 'urllink': u'http://arxiv.org/abs/1309.6856'}
2015-03-24 13:23:09+0000 [xxu46_7] INFO: Crawled 567 pages (at 1 pages/min), scraped 560 items (at 1 items/min)
2015-03-24 13:24:09+0000 [xxu46_7] INFO: Crawled 567 pages (at 0 pages/min), scraped 560 items (at 0 items/min)
2015-03-24 13:24:36+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6382> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 13:24:36+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6382>
	{'abstract': u"The biannual TARK conferences bring together researchers from a wide variety of fields sharing a common interest in reasoning about rationality and knowledge. The impact of this tradition, going back to 1986, is apparent in many of today's research trends and in the growth of an intellectual community beyond traditional disciplinary boundaries. This volume documents the 14th TARK conference, held at the Institute of Mathematical Sciences, Chennai, India on January 7 to 9, 2013. It includes 18 contributed talks, 8 poster presentations, and 3 invited talks given at the conference. Like earlier volumes in this series, it gives a sense of the state of the art in studies of knowledge and rationality in areas such as game theory, decision theory, belief revision, language analysis, and computation. It should be of value to researchers, teachers, and students.",
	 'authors': u'Burkhard C. Schipper,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/html/1310.6382',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nTARK 2013 - Proceedings of the 14. Conference on Theoretical Aspects of  Rationality and Knowledge',
	 'urllink': u'http://arxiv.org/abs/1310.6382'}
2015-03-24 13:25:09+0000 [xxu46_7] INFO: Crawled 568 pages (at 1 pages/min), scraped 561 items (at 1 items/min)
2015-03-24 13:26:09+0000 [xxu46_7] INFO: Crawled 568 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2015-03-24 13:26:17+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5272> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 13:26:17+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5272>
	{'abstract': u'Although production is an integral part of the Arrow-Debreu market model, most of the work in theoretical computer science has so far concentrated on markets without production, i.e., the exchange economy. This paper takes a significant step towards understanding computational aspects of markets with production. We first define the notion of separable, piecewise-linear concave (SPLC) production by analogy with SPLC utility functions. We then obtain a linear complementarity problem (LCP) formulation that captures exactly the set of equilibria for Arrow-Debreu markets with SPLC utilities and SPLC production, and we give a complementary pivot algorithm for finding an equilibrium. This settles a question asked by Eaves in 1975 of extending his complementary pivot algorithm to markets with production. Since this is a path-following algorithm, we obtain a proof of membership of this problem in PPAD, using Todd, 1976. We also obtain an elementary proof of existence of equilibrium (i.e., without using a fixed point theorem), rationality, and oddness of the number of equilibria. We further give a proof of PPAD-hardness for this problem and also for its restriction to markets with linear utilities and SPLC production. Experiments show that our algorithm runs fast on randomly chosen examples, and unlike previous approaches, it does not suffer from issues of numerical instability. Additionally, it is strongly polynomial when the number of goods or the number of agents and firms is constant. This extends the result of Devanur and Kannan (2008) to markets with production. Finally, we show that an LCP-based approach cannot be extended to PLC (non-separable) production, by constructing an example which has only irrational equilibria.',
	 'authors': u'Jugal Garg, Vijay V. Vazirani,',
	 'category': u'Computer Science ',
	 'date': '2013-8-24',
	 'pdflink': u'http://arxiv.org/pdf/1308.5272',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nOn Computability of Equilibria in Markets with Production',
	 'urllink': u'http://arxiv.org/abs/1308.5272'}
2015-03-24 13:27:09+0000 [xxu46_7] INFO: Crawled 569 pages (at 1 pages/min), scraped 562 items (at 1 items/min)
2015-03-24 13:27:58+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6855> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 13:27:58+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6855>
	{'abstract': u'We evaluate four computational models of explanation in Bayesian networks by comparing model predictions to human judgments. In two experiments, we present human participants with causal structures for which the models make divergent predictions and either solicit the best explanation for an observed event (Experiment 1) or have participants rate provided explanations for an observed event (Experiment 2). Across two versions of two causal structures and across both experiments, we find that the Causal Explanation Tree and Most Relevant Explanation models provide better fits to human data than either Most Probable Explanation or Explanation Tree models. We identify strengths and shortcomings of these models and what they can reveal about human explanation. We conclude by suggesting the value of pursuing computational and psychological investigations of explanation in parallel.',
	 'authors': u'Michael Pacer, Joseph Williams, Xi Chen, Tania Lombrozo, Thomas Griffiths,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6855',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nEvaluating computational models of explanation using human judgments',
	 'urllink': u'http://arxiv.org/abs/1309.6855'}
2015-03-24 13:28:09+0000 [xxu46_7] INFO: Crawled 570 pages (at 1 pages/min), scraped 563 items (at 1 items/min)
2015-03-24 13:29:09+0000 [xxu46_7] INFO: Crawled 570 pages (at 0 pages/min), scraped 563 items (at 0 items/min)
2015-03-24 13:29:23+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6377> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 13:29:23+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6377>
	{'abstract': u'Emerging applications in multiview streaming look for providing interactive navigation services to video players. The user can ask for information from any viewpoint with a minimum transmission delay. The purpose is to provide user with as much information as possible with least number of redundancies. The recent concept of navigation segment representation consists of regrouping a given number of viewpoints in one signal and transmitting them to the users according to their navigation path. The question of the best description strategy of these navigation segments is however still open. In this paper, we propose to represent and code navigation segments by a method that extends the recent layered depth image (LDI) format. It consists of describing the scene from a viewpoint with multiple images organized in layers corresponding to the different levels of occluded objects. The notion of extended LDI comes from the fact that the size of this image is adapted to take into account the sides of the scene also, in contrary to classical LDI. The obtained results show a significant rate-distortion gain compared to classical multiview compression approaches in navigation scenario.',
	 'authors': u'Uday Takyar, Thomas Maugey, Pascal Frossard,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.6377',
	 'subjects': u'Multimedia (cs.MM)',
	 'title': u'\nMultiview Navigation based on Extended Layered Depth Image  Representation',
	 'urllink': u'http://arxiv.org/abs/1310.6377'}
2015-03-24 13:30:09+0000 [xxu46_7] INFO: Crawled 571 pages (at 1 pages/min), scraped 564 items (at 1 items/min)
2015-03-24 13:31:09+0000 [xxu46_7] INFO: Crawled 571 pages (at 0 pages/min), scraped 564 items (at 0 items/min)
2015-03-24 13:31:23+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5269> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 13:31:23+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5269>
	{'abstract': u'The importance of studying the brain microstructure is described and the existing and state of the art non-invasive methods for the investigation of the brain microstructure using Diffusion Weighted Magnetic Resonance Imaging (DWI) is studied. In the next step, Cramer-Rao Lower Bound (CRLB) analysis is described and utilised for assessment of the minimum estimation error and uncertainty level of different Diffusion Weighted Magnetic Resonance (DWMR) signal decay models. The analyses are performed considering the best scenario through which, we assume that the models are the appropriate representation of the measured phenomena. This includes the study of the sensitivity of the estimations to the measurement and model parameters. It is demonstrated that none of the existing models can achieve a reasonable minimum uncertainty level under typical measurement setup. At the end, the practical obstacles for achieving higher performance in clinical and experimental environments are studied and their effects on feasibility of the methods are discussed.',
	 'authors': u'Hamed Yousefi Mesri,',
	 'category': u'Computer Science ',
	 'date': '2013-8-24',
	 'pdflink': u'http://arxiv.org/e-print/1308.5269',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nA comparative analysis of methods for estimating axon diameter using DWI',
	 'urllink': u'http://arxiv.org/abs/1308.5269'}
2015-03-24 13:32:09+0000 [xxu46_7] INFO: Crawled 572 pages (at 1 pages/min), scraped 565 items (at 1 items/min)
2015-03-24 13:32:52+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6854> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 13:32:52+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6854>
	{'abstract': u"We introduce the class of pay or play games, which captures scenarios in which each decision maker is faced with a choice between two actions: one with a fixed payoff and an- other with a payoff dependent on others' selected actions. This is, arguably, the simplest setting that models selection among certain and uncertain outcomes in a multi-agent system. We study the properties of equilibria in such games from both a game-theoretic perspective and a computational perspective. Our main positive result establishes the existence of a semi-strong equilibrium in every such game. We show that although simple, pay of play games contain a large variety of well-studied environments, e.g., vaccination games. We discuss the interesting implications of our results for these environments.",
	 'authors': u'Sigal Oren, Michael Schapira, Moshe Tennenholtz,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6854',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nPay or Play',
	 'urllink': u'http://arxiv.org/abs/1309.6854'}
2015-03-24 13:33:09+0000 [xxu46_7] INFO: Crawled 573 pages (at 1 pages/min), scraped 566 items (at 1 items/min)
2015-03-24 13:34:04+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6376> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 13:34:04+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6376>
	{'abstract': u'In Biometrics, facial uniqueness is commonly inferred from impostor similarity scores. In this paper, we show that such uniqueness measures are highly unstable in the presence of image quality variations like pose, noise and blur. We also experimentally demonstrate the instability of a recently introduced impostor-based uniqueness measure of [Klare and Jain 2013] when subject to poor quality facial images.',
	 'authors': u'Abhishek Dutta, Raymond Veldhuis, Luuk Spreeuwers,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6376',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nCan Facial Uniqueness be Inferred from Impostor Scores?',
	 'urllink': u'http://arxiv.org/abs/1310.6376'}
2015-03-24 13:34:09+0000 [xxu46_7] INFO: Crawled 574 pages (at 1 pages/min), scraped 567 items (at 1 items/min)
2015-03-24 13:35:09+0000 [xxu46_7] INFO: Crawled 574 pages (at 0 pages/min), scraped 567 items (at 0 items/min)
2015-03-24 13:35:47+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5256> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 13:35:47+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5256>
	{'abstract': u'The multireference alignment problem consists of estimating a signal from multiple noisy shifted observations. Inspired by existing Unique-Games approximation algorithms, we provide a semidefinite program (SDP) based relaxation which approximates the maximum likelihood estimator (MLE) for the multireference alignment problem. Although we show that the MLE problem is Unique-Games hard to approximate within any constant, we observe that our poly-time approximation algorithm for the MLE appears to perform quite well in typical instances, outperforming existing methods. In an attempt to explain this behavior we provide stability guarantees for our SDP under a random noise model on the observations. This case is more challenging to analyze than traditional semi-random instances of Unique-Games: the noise model is on vertices of a graph and translates into dependent noise on the edges. Interestingly, we show that if certain positivity constraints in the SDP are dropped, its solution becomes equivalent to performing phase correlation, a popular method used for pairwise alignment in imaging applications. Finally, we show how symmetry reduction techniques from matrix representation theory can simplify the analysis and computation of the SDP, greatly decreasing its computational cost.',
	 'authors': u'Afonso S. Bandeira, Moses Charikar, Amit Singer, Andy Zhu,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5256',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nMultireference Alignment using Semidefinite Programming',
	 'urllink': u'http://arxiv.org/abs/1308.5256'}
2015-03-24 13:36:09+0000 [xxu46_7] INFO: Crawled 575 pages (at 1 pages/min), scraped 568 items (at 1 items/min)
2015-03-24 13:37:09+0000 [xxu46_7] INFO: Crawled 575 pages (at 0 pages/min), scraped 568 items (at 0 items/min)
2015-03-24 13:37:09+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6852> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 13:37:09+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6852>
	{'abstract': u'This paper addresses the problem of rank aggregation, which aims to find a consensus ranking among multiple ranking inputs. Traditional rank aggregation methods are deterministic, and can be categorized into explicit and implicit methods depending on whether rank information is explicitly or implicitly utilized. Surprisingly, experimental results on real data sets show that explicit rank aggregation methods would not work as well as implicit methods, although rank information is critical for the task. Our analysis indicates that the major reason might be the unreliable rank information from incomplete ranking inputs. To solve this problem, we propose to incorporate uncertainty into rank aggregation and tackle the problem in both unsupervised and supervised scenario. We call this novel framework (St.Agg for short). Specifically, we introduce a prior distribution on ranks, and transform the ranking functions or objectives in traditional explicit methods to their expectations over this distribution. Our experiments on benchmark data sets show that the proposed St.Agg outperforms the baselines in both unsupervised and supervised scenarios.',
	 'authors': u'Shuzi Niu, Yanyan Lan, Jiafeng Guo, Xueqi Cheng,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6852',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nStochastic Rank Aggregation',
	 'urllink': u'http://arxiv.org/abs/1309.6852'}
2015-03-24 13:38:09+0000 [xxu46_7] INFO: Crawled 576 pages (at 1 pages/min), scraped 569 items (at 1 items/min)
2015-03-24 13:39:05+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6349> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 13:39:05+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6349>
	{'abstract': u'Modern processors are increasingly featuring multiple cores, as well as support for hardware virtualization. While these processors are common in desktop and server-class computing, they are less prevalent in embedded and real-time systems. However, smartphones and tablet PCs are starting to feature multicore processors with hardware virtualization. If the trend continues, it is possible that future real-time systems will feature more sophisticated processor architectures. Future automotive or avionics systems, for example, could replace complex networks of uniprocessors with consolidated services on a smaller number of multicore processors. Likewise, virtualization could be used to isolate services and increase the availability of a system even when failures occur. This paper investigates whether advances in modern processor technologies offer new opportunities to rethink the design of real-time operating systems. We describe some of the design principles behind Quest-V, which is being used as an exploratory vehicle for real-time system design on multicore processors with hardware virtualization capabilities. While not all embedded systems should assume such features, a case can be made that more robust, safety-critical systems can be built to use hardware virtualization without incurring significant overheads.',
	 'authors': u'Richard West, Ye Li, Eric Missimer,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6349',
	 'subjects': u'Operating Systems (cs.OS)',
	 'title': u'\nQuest-V: A Virtualized Multikernel for Safety-Critical Real-Time Systems',
	 'urllink': u'http://arxiv.org/abs/1310.6349'}
2015-03-24 13:39:09+0000 [xxu46_7] INFO: Crawled 577 pages (at 1 pages/min), scraped 570 items (at 1 items/min)
2015-03-24 13:40:09+0000 [xxu46_7] INFO: Crawled 577 pages (at 0 pages/min), scraped 570 items (at 0 items/min)
2015-03-24 13:40:52+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5249> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 13:40:52+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5249>
	{'abstract': u'The purpose of this note is to establish a new generalized Dictionary-Restricted Isometry Property (D-RIP) sparsity bound constant for compressed sensing. For fulfilling D-RIP, the constant is used in the definition: . We prove that signals with -sparse -representation can be reconstructed if . The approach in this note can be extended to obtain other D-RIP bounds (i.e., ).',
	 'authors': u'Christopher A. Baker,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5249',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nA Note on Sparsification by Frames',
	 'urllink': u'http://arxiv.org/abs/1308.5249'}
2015-03-24 13:41:09+0000 [xxu46_7] INFO: Crawled 578 pages (at 1 pages/min), scraped 571 items (at 1 items/min)
2015-03-24 13:42:09+0000 [xxu46_7] INFO: Crawled 578 pages (at 0 pages/min), scraped 571 items (at 0 items/min)
2015-03-24 13:42:49+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6851> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 13:42:49+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6851>
	{'abstract': u'Consider a collection of weighted subsets of a ground set N. Given a query subset Q of N, how fast can one (1) find the weighted sum over all subsets of Q, and (2) sample a subset of Q proportionally to the weights? We present a tree-based greedy heuristic, Treedy, that for a given positive tolerance d answers such counting and sampling queries to within a guaranteed relative error d and total variation distance d, respectively. Experimental results on artificial instances and in application to Bayesian structure discovery in Bayesian networks show that approximations yield dramatic savings in running time compared to exact computation, and that Treedy typically outperforms a previously proposed sorting-based heuristic.',
	 'authors': u'Teppo Niinimaki, Mikko Koivisto,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6851',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nTreedy: A Heuristic for Counting and Sampling Subsets',
	 'urllink': u'http://arxiv.org/abs/1309.6851'}
2015-03-24 13:43:09+0000 [xxu46_7] INFO: Crawled 579 pages (at 1 pages/min), scraped 572 items (at 1 items/min)
2015-03-24 13:44:09+0000 [xxu46_7] INFO: Crawled 579 pages (at 0 pages/min), scraped 572 items (at 0 items/min)
2015-03-24 13:44:41+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6343> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 13:44:41+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6343>
	{'abstract': u'We give algorithms with provable guarantees that learn a class of deep nets in the generative model view popularized by Hinton and others. Our generative model is an node multilayer neural net that has degree at most for some and each edge has a random edge weight in . Our algorithm learns networks in this class with polynomial running time. The sample complexity is quadratic or cubic depending upon the details of the model. The algorithm uses layerwise learning. It is based upon a novel idea of observing correlations among features and using these to infer the underlying edge structure via a global graph recovery procedure. The analysis of the algorithm reveals interesting structure of neural networks with random edge weights.',
	 'authors': u'Sanjeev Arora, Aditya Bhaskara, Rong Ge, Tengyu Ma,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6343',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nProvable Bounds for Learning Some Deep Representations',
	 'urllink': u'http://arxiv.org/abs/1310.6343'}
2015-03-24 13:45:09+0000 [xxu46_7] INFO: Crawled 580 pages (at 1 pages/min), scraped 573 items (at 1 items/min)
2015-03-24 13:45:42+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5239> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 13:45:42+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5239>
	{'abstract': u'Locally decodable channel codes form a special class of error-correcting codes with the property that the decoder is able to reconstruct any bit of the input message from querying only a few bits of a noisy codeword. It is well known that such codes require significantly more redundancy (in particular have vanishing rate) compared to their non-local counterparts. In this paper, we define a dual problem, i.e. locally decodable source codes (LDSC). We consider both almost lossless (block error) and lossy (bit error) cases. In almost lossless case, we show that optimal compression (to entropy) is possible with O(log n) queries to compressed string by the decompressor. We also show the following converse bounds: 1) linear LDSC cannot achieve any rate below one, with a bounded number of queries, 2) rate of any source coding with linear decoder (not necessarily local) in one, 3) for 2 queries, any code construction cannot have a rate below one. In lossy case, we show that any rate above rate distortion is achievable with a bounded number of queries. We also show that, rate distortion is achievable with any scaling number of queries. We provide an achievability bound in the finite block-length regime and compare it with the existing bounds in succinct data structures literature.',
	 'authors': u'Ali Makhdoumi, Shao-Lun Huang, Muriel Medard, Yury Polyanskiy,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5239',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOn Locally Decodable Source Coding',
	 'urllink': u'http://arxiv.org/abs/1308.5239'}
2015-03-24 13:46:09+0000 [xxu46_7] INFO: Crawled 581 pages (at 1 pages/min), scraped 574 items (at 1 items/min)
2015-03-24 13:47:09+0000 [xxu46_7] INFO: Crawled 581 pages (at 0 pages/min), scraped 574 items (at 0 items/min)
2015-03-24 13:47:09+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6850> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 13:47:09+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6850>
	{'abstract': u'A number of discrete and continuous optimization problems in machine learning are related to convex minimization problems under submodular constraints. In this paper, we deal with a submodular function with a directed graph structure, and we show that a wide range of convex optimization problems under submodular constraints can be solved much more efficiently than general submodular optimization methods by a reduction to a maximum flow problem. Furthermore, we give some applications, including sparse optimization methods, in which the proposed methods are effective. Additionally, we evaluate the performance of the proposed method through computational experiments.',
	 'authors': u'Kiyohito Nagano, Yoshinobu Kawahara,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6850',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nStructured Convex Optimization under Submodular Constraints',
	 'urllink': u'http://arxiv.org/abs/1309.6850'}
2015-03-24 13:48:09+0000 [xxu46_7] INFO: Crawled 582 pages (at 1 pages/min), scraped 575 items (at 1 items/min)
2015-03-24 13:48:29+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6342> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 13:48:29+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6342>
	{'abstract': u'The speed and transformative power of human cultural evolution is evident from the change it has wrought on our planet. This chapter proposes a human computation program aimed at (1) distinguishing algorithmic from non-algorithmic components of cultural evolution, (2) computationally modeling the algorithmic components, and amassing human solutions to the non-algorithmic (generally, creative) components, and (3) combining them to develop human-machine hybrids with previously unforeseen computational power that can be used to solve real problems. Drawing on recent insights into the origins of evolutionary processes from biology and complexity theory, human minds are modeled as self-organizing, interacting, autopoietic networks that evolve through a Lamarckian (non-Darwinian) process of communal exchange. Existing computational models as well as directions for future research are discussed.',
	 'authors': u'Liane Gabora,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6342',
	 'subjects': u'Multiagent Systems (cs.MA)',
	 'title': u'\nCultural Evolution as Distributed Computation',
	 'urllink': u'http://arxiv.org/abs/1310.6342'}
2015-03-24 13:49:09+0000 [xxu46_7] INFO: Crawled 583 pages (at 1 pages/min), scraped 576 items (at 1 items/min)
2015-03-24 13:50:09+0000 [xxu46_7] INFO: Crawled 583 pages (at 0 pages/min), scraped 576 items (at 0 items/min)
2015-03-24 13:50:26+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5218> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 13:50:26+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5218>
	{'abstract': u'Visualizing graphs using virtual physical models is probably the most heavily used technique for drawing graphs in practice. There are many algorithms that are efficient and produce high-quality layouts. If one requires that the layout also respect a given set of non-uniform edge lengths, however, force-based approaches become problematic while energy-based layouts become intractable. In this paper, we propose a reformulation of the stress function into a two-part convex objective function to which we can apply semi-definite programming (SDP). We avoid the high computational cost associated with SDP by a novel, compact re-parameterization of the objective function using the eigenvectors of the graph Laplacian. This sparse representation makes our approach scalable. We provide experimental results to show that this method scales well and produces reasonable layouts while dealing with the edge length constraints.',
	 'authors': u'Emden R. Gansner, Yifan Hu, Shankar Krishnan,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5218',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nCOAST: A Convex Optimization Approach to Stress-Based Embedding',
	 'urllink': u'http://arxiv.org/abs/1308.5218'}
2015-03-24 13:51:09+0000 [xxu46_7] INFO: Crawled 584 pages (at 1 pages/min), scraped 577 items (at 1 items/min)
2015-03-24 13:52:09+0000 [xxu46_7] INFO: Crawled 584 pages (at 0 pages/min), scraped 577 items (at 0 items/min)
2015-03-24 13:52:11+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6849> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 13:52:11+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6849>
	{'abstract': u'We propose a method for learning cyclic causal models from a combination of observational and interventional equilibrium data. Novel aspects of the proposed method are its ability to work with continuous data (without assuming linearity) and to deal with feedback loops. Within the context of biochemical reactions, we also propose a novel way of modeling interventions that modify the activity of compounds instead of their abundance. For computational reasons, we approximate the nonlinear causal mechanisms by (coupled) local linearizations, one for each experimental condition. We apply the method to reconstruct a cellular signaling network from the flow cytometry data measured by Sachs et al. (2005). We show that our method finds evidence in the data for feedback loops and that it gives a more accurate quantitative description of the data at comparable model complexity.',
	 'authors': u'Joris Mooij, Tom Heskes,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6849',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nCyclic Causal Discovery from Continuous Equilibrium Data',
	 'urllink': u'http://arxiv.org/abs/1309.6849'}
2015-03-24 13:53:09+0000 [xxu46_7] INFO: Crawled 585 pages (at 1 pages/min), scraped 578 items (at 1 items/min)
2015-03-24 13:53:41+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6323> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 13:53:41+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6323>
	{'abstract': u'This file summarizes the plenary talk on laboratory experiments on logic at the TARK 2013 - 14th Conference on Theoretical Aspects of Rationality and Knowledge.',
	 'authors': u'Rineke Verbrugge,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6323',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nLogic in the Lab',
	 'urllink': u'http://arxiv.org/abs/1310.6323'}
2015-03-24 13:54:09+0000 [xxu46_7] INFO: Crawled 586 pages (at 1 pages/min), scraped 579 items (at 1 items/min)
2015-03-24 13:54:59+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5211> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 13:54:59+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5211>
	{'abstract': u'In this paper, we propose locally repairable codes (LRCs) with optimal minimum distance for distributed storage systems (DSS). A two-layer encoding structure is employed to ensure data reconstruction and the designated repair locality. The data is first encoded in the first layer by any existing maximum distance separable (MDS) codes, and then the encoded symbols are divided into non-overlapping groups and encoded by an MDS array code in the second layer. The encoding in the second layer provides enough redundancy for local repair, while the overall code performs recovery of the data based on redundancy from both layers. Our codes can be constructed over a finite field with size growing linearly with the total number of nodes in the DSS, and facilitate efficient degraded reads.',
	 'authors': u'Hongmei Xie, Zhiyuan Yan,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/e-print/1308.5211',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nTwo-layer Locally Repairable Codes for Distributed Storage Systems',
	 'urllink': u'http://arxiv.org/abs/1308.5211'}
2015-03-24 13:55:09+0000 [xxu46_7] INFO: Crawled 587 pages (at 1 pages/min), scraped 580 items (at 1 items/min)
2015-03-24 13:56:09+0000 [xxu46_7] INFO: Crawled 587 pages (at 0 pages/min), scraped 580 items (at 0 items/min)
2015-03-24 13:56:39+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6848> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 13:56:39+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6848>
	{'abstract': u'Graphical models with High Order Potentials (HOPs) have received considerable interest in recent years. While there are a variety of approaches to inference in these models, nearly all of them amount to solving a linear program (LP) relaxation with unary consistency constraints between the HOP and the individual variables. In many cases, the resulting relaxations are loose, and in these cases the results of inference can be poor. It is thus desirable to look for more accurate ways of performing inference in these models. In this work, we study the LP relaxations that result from enforcing additional consistency constraints between the HOP and the rest of the model. We address theoretical questions about the strength of the resulting relaxations compared to the relaxations that arise in standard approaches, and we develop practical and efficient message passing algorithms for optimizing the LPs. Empirically, we show that the LPs with additional consistency constraints lead to more accurate inference on some challenging problems that include a combination of low order and high order terms.',
	 'authors': u'Elad Mezuman, Daniel Tarlow, Amir Globerson, Yair Weiss,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6848',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nTighter Linear Program Relaxations for High Order Graphical Models',
	 'urllink': u'http://arxiv.org/abs/1309.6848'}
2015-03-24 13:57:09+0000 [xxu46_7] INFO: Crawled 588 pages (at 1 pages/min), scraped 581 items (at 1 items/min)
2015-03-24 13:58:09+0000 [xxu46_7] INFO: Crawled 588 pages (at 0 pages/min), scraped 581 items (at 0 items/min)
2015-03-24 13:58:38+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6311> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 13:58:38+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6311>
	{'abstract': u"As of today, the main business application of onomastics is naming, or branding: finding the proper name for your company or your product to stand out in the world. Meaningfully, Onoma, the Greek root for name, is also a registered trademark of Nomen, the naming agency founded by Marcel Botton in 1981. Nomen initially licensed one of Roland Moreno's inventions, the Radoteur name generator, and created many distinctive and global brand names such as: Vinci, Clio or Amundi. But once your business has a name, should you forget about onomastics? Not anymore. Globalization, digitalization and the Big Data open new fields to experiment disruptive applications in Sales and Marketing, Communication, HR and Risk Management. Though discriminating names carries a high risk of abuse, it can also drive new, unexpected ways for developing poor areas.",
	 'authors': u'Elian Carsenat,',
	 'category': u'Computer Science ',
	 'date': '2013-10-20',
	 'pdflink': u'http://arxiv.org/pdf/1310.6311',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nOnomastics and Big Data Mining',
	 'urllink': u'http://arxiv.org/abs/1310.6311'}
2015-03-24 13:59:09+0000 [xxu46_7] INFO: Crawled 589 pages (at 1 pages/min), scraped 582 items (at 1 items/min)
2015-03-24 14:00:09+0000 [xxu46_7] INFO: Crawled 589 pages (at 0 pages/min), scraped 582 items (at 0 items/min)
2015-03-24 14:00:27+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5207> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 14:00:27+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5207>
	{'abstract': u'The little Grothendieck problem consists of maximizing over binary variables , where C is a positive semidefinite matrix. In this paper we focus on a natural generalization of this problem, the little Grothendieck problem over the orthogonal group. Given C a dn x dn positive semidefinite matrix, the objective is to maximize restricting to take values in the group of orthogonal matrices, where denotes the (ij)-th d x d block of C. We propose an approximation algorithm, which we refer to as Orthogonal-Cut, to solve this problem and show a constant approximation ratio. Our method is based on semidefinite programming. For a given , we show a constant approximation ratio of , where is the expected average singular value of a d x d matrix with random Gaussian i.i.d. entries. For d=1 we recover the known approximation guarantee for the classical little Grothendieck problem. Our algorithm and analysis naturally extends to the complex valued case also providing a constant approximation ratio for the analogous problem over the Unitary Group. Orthogonal-Cut also serves as an approximation algorithm for several applications, including the Procrustes problem where it improves over the best previously known approximation ratio of~. The little Grothendieck problem falls under the class of problems approximated by a recent algorithm proposed in the context of the non-commutative Grothendieck inequality. Nonetheless, our approach is simpler and it provides a more efficient algorithm with better approximation ratios and matching integrality gaps. Finally, we also provide an improved approximation algorithm for the more general little Grothendieck problem over the orthogonal (or unitary) group with rank constraints.',
	 'authors': u'Afonso S. Bandeira, Christopher Kennedy, Amit Singer,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5207',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nApproximating the Little Grothendieck Problem over the Orthogonal and  Unitary Groups',
	 'urllink': u'http://arxiv.org/abs/1308.5207'}
2015-03-24 14:01:09+0000 [xxu46_7] INFO: Crawled 590 pages (at 1 pages/min), scraped 583 items (at 1 items/min)
2015-03-24 14:02:09+0000 [xxu46_7] INFO: Crawled 590 pages (at 0 pages/min), scraped 583 items (at 0 items/min)
2015-03-24 14:02:22+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6847> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 14:02:22+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6847>
	{'abstract': u'Structured prediction is a powerful framework for coping with joint prediction of interacting outputs. A central difficulty in using this framework is that often the correct label dependence structure is unknown. At the same time, we would like to avoid an overly complex structure that will lead to intractable prediction. In this work we address the challenge of learning tree structured predictive models that achieve high accuracy while at the same time facilitate efficient (linear time) inference. We start by proving that this task is in general NP-hard, and then suggest an approximate alternative. Briefly, our CRANK approach relies on a novel Circuit-RANK regularizer that penalizes non-tree structures and that can be optimized using a CCCP procedure. We demonstrate the effectiveness of our approach on several domains and show that, despite the relative simplicity of the structure, prediction accuracy is competitive with a fully connected model that is computationally costly at prediction time.',
	 'authors': u'Ofer Meshi, Elad Eban, Gal Elidan, Amir Globerson,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6847',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nLearning Max-Margin Tree Predictors',
	 'urllink': u'http://arxiv.org/abs/1309.6847'}
2015-03-24 14:03:09+0000 [xxu46_7] INFO: Crawled 591 pages (at 1 pages/min), scraped 584 items (at 1 items/min)
2015-03-24 14:04:03+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6304> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 14:04:03+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6304>
	{'abstract': u'Principal Component Analysis (PCA) is a ubiquitous tool with many applications in machine learning including feature construction, subspace embedding, and outlier detection. In this paper, we present an algorithm for computing the top principal components of a dataset with a large number of rows (examples) and columns (features). Our algorithm leverages both structured and unstructured random projections to retain good accuracy while being computationally efficient. We demonstrate the technique on the winning submission the KDD 2010 Cup.',
	 'authors': u'Nikos Karampatziakis, Paul Mineiro,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6304',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nCombining Structured and Unstructured Randomness in Large Scale PCA',
	 'urllink': u'http://arxiv.org/abs/1310.6304'}
2015-03-24 14:04:09+0000 [xxu46_7] INFO: Crawled 592 pages (at 1 pages/min), scraped 585 items (at 1 items/min)
2015-03-24 14:05:09+0000 [xxu46_7] INFO: Crawled 592 pages (at 0 pages/min), scraped 585 items (at 0 items/min)
2015-03-24 14:05:32+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5202> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 14:05:32+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5202>
	{'abstract': u"In this paper, throughput achieved in cognitive radio channels with finite blocklength codes under buffer limitations is studied. Cognitive users first determine the activity of the primary users' through channel sensing and then initiate data transmission at a power level that depends on the channel sensing decisions. It is assumed that finite blocklength codes are employed in the data transmission phase. Hence, errors can occur in reception and retransmissions can be required. Primary users' activities are modeled as a two-state Markov chain and an eight-state Markov chain is constructed in order to model the cognitive radio channel. Channel state information (CSI) is assumed to be perfectly known by either the secondary receiver only or both the secondary transmitter and receiver. In the absence of CSI at the transmitter, fixed-rate transmission is performed whereas under perfect CSI knowledge, for a given target error probability, the transmitter varies the rate according to the channel conditions. Under these assumptions, throughput in the presence of buffer constraints is determined by characterizing the maximum constant arrival rates that can be supported by the cognitive radio channel while satisfying certain limits on buffer violation probabilities. Tradeoffs between throughput, buffer constraints, coding blocklength, and sensing duration for both fixed-rate and variable-rate transmissions are analyzed numerically. The relations between average error probability, sensing threshold and sensing duration are studied in the case of variable-rate transmissions.",
	 'authors': u'Gozde Ozcan, M. Cenk Gursoy,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5202',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nThroughput of Cognitive Radio Systems with Finite Blocklength Codes',
	 'urllink': u'http://arxiv.org/abs/1308.5202'}
2015-03-24 14:06:09+0000 [xxu46_7] INFO: Crawled 593 pages (at 1 pages/min), scraped 586 items (at 1 items/min)
2015-03-24 14:07:09+0000 [xxu46_7] INFO: Crawled 593 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2015-03-24 14:07:13+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6846> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 14:07:13+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6846>
	{'abstract': u'In many developing countries, half the population lives in rural locations, where access to essentials such as school materials, mosquito nets, and medical supplies is restricted. We propose an alternative method of distribution (to standard road delivery) in which the existing mobility habits of a local population are leveraged to deliver aid, which raises two technical challenges in the areas optimisation and learning. For optimisation, a standard Markov decision process applied to this problem is intractable, so we provide an exact formulation that takes advantage of the periodicities in human location behaviour. To learn such behaviour models from sparse data (i.e., cell tower observations), we develop a Bayesian model of human mobility. Using real cell tower data of the mobility behaviour of 50,000 individuals in Ivory Coast, we find that our model outperforms the state of the art approaches in mobility prediction by at least 25% (in held-out data likelihood). Furthermore, when incorporating mobility prediction with our MDP approach, we find a 81.3% reduction in total delivery time versus routine planning that minimises just the number of participants in the solution path.',
	 'authors': u'James McInerney, Alex Rogers, Nicholas R. Jennings,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6846',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nLearning Periodic Human Behaviour Models from Sparse Data for  Crowdsourcing Aid Delivery in Developing Countries',
	 'urllink': u'http://arxiv.org/abs/1309.6846'}
2015-03-24 14:08:09+0000 [xxu46_7] INFO: Crawled 594 pages (at 1 pages/min), scraped 587 items (at 1 items/min)
2015-03-24 14:08:38+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6303> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 14:08:38+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6303>
	{'abstract': u'One-counter nets (OCN) are Petri nets with exactly one unbounded place. They are equivalent to a subclass of one-counter automata with just a weak test for zero. Unlike many other semantic equivalences, strong and weak simulation preorder are decidable for OCN, but the computational complexity was an open problem. We show that both strong and weak simulation preorder on OCN are PSPACE-complete.',
	 'authors': u'Piotr Hofman, Slawomir Lasota, Richard Mayr, Patrick Totzke,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6303',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nSimulation Over One-counter Nets is PSPACE-Complete',
	 'urllink': u'http://arxiv.org/abs/1310.6303'}
2015-03-24 14:09:09+0000 [xxu46_7] INFO: Crawled 595 pages (at 1 pages/min), scraped 588 items (at 1 items/min)
2015-03-24 14:10:09+0000 [xxu46_7] INFO: Crawled 595 pages (at 0 pages/min), scraped 588 items (at 0 items/min)
2015-03-24 14:10:34+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5200> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 14:10:34+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5200>
	{'abstract': u'Optimization on manifolds is a rapidly developing branch of nonlinear optimization. Its focus is on problems where the smooth geometry of the search space can be leveraged to design efficient numerical algorithms. In particular, optimization on manifolds is well-suited to deal with rank and orthogonality constraints. Such structured constraints appear pervasively in machine learning applications, including low-rank matrix completion, sensor network localization, camera network registration, independent component analysis, metric learning, dimensionality reduction and so on. The Manopt toolbox, available at www.manopt.org, is a user-friendly, documented piece of software dedicated to simplify experimenting with state of the art Riemannian optimization algorithms. We aim particularly at reaching practitioners outside our field.',
	 'authors': u'Nicolas Boumal, Bamdev Mishra, P.-A. Absil, Rodolphe Sepulchre,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5200',
	 'subjects': u'Mathematical Software (cs.MS)',
	 'title': u'\nManopt, a Matlab toolbox for optimization on manifolds',
	 'urllink': u'http://arxiv.org/abs/1308.5200'}
2015-03-24 14:11:09+0000 [xxu46_7] INFO: Crawled 596 pages (at 1 pages/min), scraped 589 items (at 1 items/min)
2015-03-24 14:12:09+0000 [xxu46_7] INFO: Crawled 596 pages (at 0 pages/min), scraped 589 items (at 0 items/min)
2015-03-24 14:12:21+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6845> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 14:12:21+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6845>
	{'abstract': u'Credal networks are graph-based statistical models whose parameters take values in a set, instead of being sharply specified as in traditional statistical models (e.g., Bayesian networks). The computational complexity of inferences on such models depends on the irrelevance/independence concept adopted. In this paper, we study inferential complexity under the concepts of epistemic irrelevance and strong independence. We show that inferences under strong independence are NP-hard even in trees with ternary variables. We prove that under epistemic irrelevance the polynomial time complexity of inferences in credal trees is not likely to extend to more general models (e.g. singly connected networks). These results clearly distinguish networks that admit efficient inferences and those where inferences are most likely hard, and settle several open questions regarding computational complexity.',
	 'authors': u'Denis D. Maua, Cassio Polpo de Campos, Alessio Benavoli, Alessandro Antonucci,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6845',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nOn the Complexity of Strong and Epistemic Credal Networks',
	 'urllink': u'http://arxiv.org/abs/1309.6845'}
2015-03-24 14:13:09+0000 [xxu46_7] INFO: Crawled 597 pages (at 1 pages/min), scraped 590 items (at 1 items/min)
2015-03-24 14:14:09+0000 [xxu46_7] INFO: Crawled 597 pages (at 0 pages/min), scraped 590 items (at 0 items/min)
2015-03-24 14:14:22+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6301> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 14:14:22+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6301>
	{'abstract': u'Quest-V is a system we have been developing from the ground up, with objectives focusing on safety, predictability and efficiency. It is designed to work on emerging multicore processors with hardware virtualization support. Quest-V is implemented as a "distributed system on a chip" and comprises multiple sandbox kernels. Sandbox kernels are isolated from one another in separate regions of physical memory, having access to a subset of processing cores and I/O devices. This partitioning prevents system failures in one sandbox affecting the operation of other sandboxes. Shared memory channels managed by system monitors enable inter-sandbox communication. The distributed nature of Quest-V means each sandbox has a separate physical clock, with all event timings being managed by per-core local timers. Each sandbox is responsible for its own scheduling and I/O management, without requiring intervention of a hypervisor. In this paper, we formulate bounds on inter-sandbox communication in the absence of a global scheduler or global system clock. We also describe how address space migration between sandboxes can be guaranteed without violating service constraints. Experimental results on a working system show the conditions under which Quest-V performs real-time communication and migration.',
	 'authors': u'Ye Li, Eric Missimer, Richard West,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6301',
	 'subjects': u'Operating Systems (cs.OS)',
	 'title': u'\nPredictable Migration and Communication in the Quest-V Multikernel',
	 'urllink': u'http://arxiv.org/abs/1310.6301'}
2015-03-24 14:15:09+0000 [xxu46_7] INFO: Crawled 598 pages (at 1 pages/min), scraped 591 items (at 1 items/min)
2015-03-24 14:15:22+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5177> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 14:15:22+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5177>
	{'abstract': u"Cloud Computing is a set of IT Services that are provided to a customer over a network and these services are delivered by third party provider who owns the infrastructure and reduce the burden at user's end. Nowadays researchers devoted their work access control method to enhance the security on Cloud. RBAC is attractive access model because the number of roles is significantly less hence users can be easily classified according to their roles. The Role-based Access Control (RBAC) model provides efficient way to manage access to information while reducing the cost of security administration and complexity in large networked applications. This paper specify various policies in RBAC on clouds such as migration policy which helps the user to migrate the database schema and roles easily to the Cloud using XML with more security. Restriction policy provide the security enhancement in Role Based Access Model by restricting the number of transaction per user and if the number of transactions will increase the admin will come to know through its monitoring system that unauthorized access has been made and it would be easier to take action against such happening. This paper proposes backup and restoration policy in Role Based Access Model in which if the main cloud is crashed or not working properly then the backup and restoration facility will be available to avoid the lost of important data. In this case chances of loss of data are very less so enhance more security on Cloud Computing.",
	 'authors': u'Gitanjali, Sukhjit Singh Sehra, Jaiteg Singh,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5177',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nPolicy Specification in Role based Access Control on Clouds',
	 'urllink': u'http://arxiv.org/abs/1308.5177'}
2015-03-24 14:16:09+0000 [xxu46_7] INFO: Crawled 599 pages (at 1 pages/min), scraped 592 items (at 1 items/min)
2015-03-24 14:17:09+0000 [xxu46_7] INFO: Crawled 599 pages (at 0 pages/min), scraped 592 items (at 0 items/min)
2015-03-24 14:17:19+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6844> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 14:17:19+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6844>
	{'abstract': u'Exact algorithms for learning Bayesian networks guarantee to find provably optimal networks. However, they may fail in difficult learning tasks due to limited time or memory. In this research we adapt several anytime heuristic search-based algorithms to learn Bayesian networks. These algorithms find high-quality solutions quickly, and continually improve the incumbent solution or prove its optimality before resources are exhausted. Empirical results show that the anytime window A* algorithm usually finds higher-quality, often optimal, networks more quickly than other approaches. The results also show that, surprisingly, while generating networks with few parents per variable are structurally simpler, they are harder to learn than complex generating networks with more parents per variable.',
	 'authors': u'Brandon Malone, Changhe Yuan,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6844',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nEvaluating Anytime Algorithms for Learning Optimal Bayesian Networks',
	 'urllink': u'http://arxiv.org/abs/1309.6844'}
2015-03-24 14:18:09+0000 [xxu46_7] INFO: Crawled 600 pages (at 1 pages/min), scraped 593 items (at 1 items/min)
2015-03-24 14:18:48+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6299> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 14:18:48+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6299>
	{'abstract': u'Provenance is an increasing concern due to the ongoing revolution in sharing and processing scientific data on the Web and in other computer systems. It is proposed that many computer systems will need to become provenance-aware in order to provide satisfactory accountability, reproducibility, and trust for scientific or other high-value data. To date, there is not a consensus concerning appropriate formal models or security properties for provenance. In previous work, we introduced a formal framework for provenance security and proposed formal definitions of properties called disclosure and obfuscation. In this article, we study refined notions of positive and negative disclosure and obfuscation in a concrete setting, that of a general-purpose programing language. Previous models of provenance have focused on special-purpose languages such as workflows and database queries. We consider a higher-order, functional language with sums, products, and recursive types and functions, and equip it with a tracing semantics in which traces themselves can be replayed as computations. We present an annotation-propagation framework that supports many provenance views over traces, including standard forms of provenance studied previously. We investigate some relationships among provenance views and develop some partial solutions to the disclosure and obfuscation problems, including correct algorithms for disclosure and positive obfuscation based on trace slicing.',
	 'authors': u'Umut A. Acar, Amal Ahmed, James Cheney, Roly Perera,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6299',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nA Core Calculus for Provenance',
	 'urllink': u'http://arxiv.org/abs/1310.6299'}
2015-03-24 14:19:09+0000 [xxu46_7] INFO: Crawled 601 pages (at 1 pages/min), scraped 594 items (at 1 items/min)
2015-03-24 14:20:09+0000 [xxu46_7] INFO: Crawled 601 pages (at 0 pages/min), scraped 594 items (at 0 items/min)
2015-03-24 14:20:09+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5174> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 14:20:09+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5174>
	{'abstract': u'This paper presents and justifies an open benchmark suite named BEEBS, targeted at evaluating the energy consumption of embedded processors. We explore the possible sources of energy consumption, then select individual benchmarks from contemporary suites to cover these areas. Version one of BEEBS is presented here and contains 10 benchmarks that cover a wide range of typical embedded applications. The benchmark suite is portable across diverse architectures and is freely available. The benchmark suite is extensively evaluated, and the properties of its constituent programs are analysed. Using real hardware platforms we show case examples which illustrate the difference in power dissipation between three processor architectures and their related ISAs. We observe significant differences in the average instruction dissipation between the architectures of 4.4x, specifically 170uW/MHz (ARM Cortex-M0), 65uW/MHz (Adapteva Epiphany) and 88uW/MHz (XMOS XS1-L1).',
	 'authors': u'James Pallister, Simon Hollis, Jeremy Bennett,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5174',
	 'subjects': u'Performance (cs.PF)',
	 'title': u'\nBEEBS: Open Benchmarks for Energy Measurements on Embedded Platforms',
	 'urllink': u'http://arxiv.org/abs/1308.5174'}
2015-03-24 14:21:09+0000 [xxu46_7] INFO: Crawled 602 pages (at 1 pages/min), scraped 595 items (at 1 items/min)
2015-03-24 14:21:32+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6843> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 14:21:32+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6843>
	{'abstract': u'The PC algorithm learns maximally oriented causal Bayesian networks. However, there is no equivalent complete algorithm for learning the structure of relational models, a more expressive generalization of Bayesian networks. Recent developments in the theory and representation of relational models support lifted reasoning about conditional independence. This enables a powerful constraint for orienting bivariate dependencies and forms the basis of a new algorithm for learning structure. We present the relational causal discovery (RCD) algorithm that learns causal relational models. We prove that RCD is sound and complete, and we present empirical results that demonstrate effectiveness.',
	 'authors': u'Marc Maier, Katerina Marazopoulou, David Arbour, David Jensen,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6843',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nA Sound and Complete Algorithm for Learning Causal Models from  Relational Data',
	 'urllink': u'http://arxiv.org/abs/1309.6843'}
2015-03-24 14:22:09+0000 [xxu46_7] INFO: Crawled 603 pages (at 1 pages/min), scraped 596 items (at 1 items/min)
2015-03-24 14:23:09+0000 [xxu46_7] INFO: Crawled 603 pages (at 0 pages/min), scraped 596 items (at 0 items/min)
2015-03-24 14:23:14+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6298> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 14:23:14+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6298>
	{'abstract': u'Multi- and many-core processors are becoming increasingly popular in embedded systems. Many of these processors now feature hardware virtualization capabilities, such as the ARM Cortex A15, and x86 processors with Intel VT-x or AMD-V support. Hardware virtualization offers opportunities to partition physical resources, including processor cores, memory and I/O devices amongst guest virtual machines. Mixed criticality systems and services can then co-exist on the same platform in separate virtual machines. However, traditional virtual machine systems are too expensive because of the costs of trapping into hypervisors to multiplex and manage machine physical resources on behalf of separate guests. For example, hypervisors are needed to schedule separate VMs on physical processor cores. In this paper, we discuss the design of the Quest-V separation kernel, that partitions services of different criticalities in separate virtual machines, or sandboxes. Each sandbox encapsulates a subset of machine physical resources that it manages without requiring intervention of a hypervisor. Moreover, a hypervisor is not needed for normal operation, except to bootstrap the system and establish communication channels between sandboxes.',
	 'authors': u'Ye Li, Richard West, Eric Missimer,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6298',
	 'subjects': u'Operating Systems (cs.OS)',
	 'title': u'\nThe Quest-V Separation Kernel for Mixed Criticality Systems',
	 'urllink': u'http://arxiv.org/abs/1310.6298'}
2015-03-24 14:24:09+0000 [xxu46_7] INFO: Crawled 604 pages (at 1 pages/min), scraped 597 items (at 1 items/min)
2015-03-24 14:24:48+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5168> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 14:24:48+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5168>
	{'abstract': u"With the popularity of Social Networking Services (SNS), more and more sensitive information are stored online and associated with SNS accounts. The obvious value of SNS accounts motivates the usage stealing problem -- unauthorized, stealthy use of SNS accounts on the devices owned/used by account owners without any technology hacks. For example, anxious parents may use their kids' SNS accounts to inspect the kids' social status; husbands/wives may use their spouses' SNS accounts to spot possible affairs. Usage stealing could happen anywhere in any form, and seriously invades the privacy of account owners. However, there is no any currently known defense against such usage stealing. To an SNS operator (e.g., Facebook Inc.), usage stealing is hard to detect using traditional methods because such attackers come from the same IP addresses/devices, use the same credentials, and share the same accounts as the owners do. In this paper, we propose a novel continuous authentication approach that analyzes user browsing behavior to detect SNS usage stealing incidents. We use Facebook as a case study and show that it is possible to detect such incidents by analyzing SNS browsing behavior. Our experiment results show that our proposal can achieve higher than 80% detection accuracy within 2 minutes, and higher than 90% detection accuracy after 7 minutes of observation time.",
	 'authors': u'Shan-Hung Wu, Man-Ju Chou, Ming-Hung Wang, Chun-Hsiung Tseng, Yuh-Jye Lee, Kuan-Ta Chen,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5168',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nIs Somebody Watching Your Facebook Newsfeed?',
	 'urllink': u'http://arxiv.org/abs/1308.5168'}
2015-03-24 14:25:09+0000 [xxu46_7] INFO: Crawled 605 pages (at 1 pages/min), scraped 598 items (at 1 items/min)
2015-03-24 14:26:09+0000 [xxu46_7] INFO: Crawled 605 pages (at 0 pages/min), scraped 598 items (at 0 items/min)
2015-03-24 14:26:19+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6842> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 14:26:19+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6842>
	{'abstract': u'We introduce z-transportability, the problem of estimating the causal effect of a set of variables X on another set of variables Y in a target domain from experiments on any subset of controllable variables Z where Z is an arbitrary subset of observable variables V in a source domain. z-Transportability generalizes z-identifiability, the problem of estimating in a given domain the causal effect of X on Y from surrogate experiments on a set of variables Z such that Z is disjoint from X;. z-Transportability also generalizes transportability which requires that the causal effect of X on Y in the target domain be estimable from experiments on any subset of all observable variables in the source domain. We first generalize z-identifiability to allow cases where Z is not necessarily disjoint from X. Then, we establish a necessary and sufficient condition for z-transportability in terms of generalized z-identifiability and transportability. We provide a correct and complete algorithm that determines whether a causal effect is z-transportable; and if it is, produces a transport formula, that is, a recipe for estimating the causal effect of X on Y in the target domain using information elicited from the results of experimental manipulations of Z in the source domain and observational data from the target domain. Our results also show that do-calculus is complete for z-transportability.',
	 'authors': u'Sanghack Lee, Vasant Honavar,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6842',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nCausal Transportability of Experiments on Controllable Subsets of  Variables: z-Transportability',
	 'urllink': u'http://arxiv.org/abs/1309.6842'}
2015-03-24 14:27:09+0000 [xxu46_7] INFO: Crawled 606 pages (at 1 pages/min), scraped 599 items (at 1 items/min)
2015-03-24 14:28:09+0000 [xxu46_7] INFO: Crawled 606 pages (at 0 pages/min), scraped 599 items (at 0 items/min)
2015-03-24 14:28:16+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6283> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 14:28:16+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6283>
	{'abstract': u'In this article we provide a new perspective on the word problem of a group by using languages of nested words. These were introduced by Alur and Madhusudan as a way to model programming languages such as HTML. We demonstrate how a class of nested word languages called visibly pushdown can be used to study the word problem of virtually free groups in a natural way.',
	 'authors': u'Christopher S. Henry,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6283',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nThe (Nested) Word Problem',
	 'urllink': u'http://arxiv.org/abs/1310.6283'}
2015-03-24 14:29:09+0000 [xxu46_7] INFO: Crawled 607 pages (at 1 pages/min), scraped 600 items (at 1 items/min)
2015-03-24 14:30:09+0000 [xxu46_7] INFO: Crawled 607 pages (at 0 pages/min), scraped 600 items (at 0 items/min)
2015-03-24 14:30:15+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5165> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 14:30:15+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5165>
	{'abstract': u'The satisfiability problem for branching-time temporal logics like CTL*, CTL and CTL+ has important applications in program specification and verification. Their computational complexities are known: CTL* and CTL+ are complete for doubly exponential time, CTL is complete for single exponential time. Some decision procedures for these logics are known; they use tree automata, tableaux or axiom systems. In this paper we present a uniform game-theoretic framework for the satisfiability problem of these branching-time temporal logics. We define satisfiability games for the full branching-time temporal logic CTL* using a high-level definition of winning condition that captures the essence of well-foundedness of least fixpoint unfoldings. These winning conditions form formal languages of omega-words. We analyse which kinds of deterministic -automata are needed in which case in order to recognise these languages. We then obtain a reduction to the problem of solving parity or B "uchi games. The worst-case complexity of the obtained algorithms matches the known lower bounds for these logics. This approach provides a uniform, yet complexity-theoretically optimal treatment of satisfiability for branching-time temporal logics. It separates the use of temporal logic machinery from the use of automata thus preserving a syntactical relationship between the input formula and the object that represents satisfiability, i.e. a winning strategy in a parity or B "uchi game. The games presented here work on a Fischer-Ladner closure of the input formula only. Last but not least, the games presented here come with an attempt at providing tool support for the satisfiability problem of complex branching-time logics like CTL* and CTL+.',
	 'authors': u'Oliver Friedmann, Martin Lange, Markus Latte,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5165',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nSatisfiability Games for Branching-Time Logics',
	 'urllink': u'http://arxiv.org/abs/1308.5165'}
2015-03-24 14:31:09+0000 [xxu46_7] INFO: Crawled 608 pages (at 1 pages/min), scraped 601 items (at 1 items/min)
2015-03-24 14:31:37+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6841> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 14:31:37+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6841>
	{'abstract': u'Diffusion processes in networks are increasingly used to model the spread of information and social influence. In several applications in computational sustainability such as the spread of wildlife, infectious diseases and traffic mobility pattern, the observed data often consists of only aggregate information. In this work, we present new models that generalize standard diffusion processes to such collective settings. We also present optimization based techniques that can accurately learn the underlying dynamics of the given contagion process, including the hidden network structure, by only observing the time a node becomes active and the associated aggregate information. Empirically, our technique is highly robust and accurately learns network structure with more than 90% recall and precision. Results on real-world flu spread data in the US confirm that our technique can also accurately model infectious disease spread.',
	 'authors': u'Akshat Kumar, Daniel Sheldon, Biplav Srivastava,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6841',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nCollective Diffusion Over Networks: Models and Inference',
	 'urllink': u'http://arxiv.org/abs/1309.6841'}
2015-03-24 14:32:09+0000 [xxu46_7] INFO: Crawled 609 pages (at 1 pages/min), scraped 602 items (at 1 items/min)
2015-03-24 14:33:09+0000 [xxu46_7] INFO: Crawled 609 pages (at 0 pages/min), scraped 602 items (at 0 items/min)
2015-03-24 14:33:11+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6271> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 14:33:11+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6271>
	{'abstract': u'This paper settles the optimality of sorting networks given in The Art of Computer Programming vol. 3 more than 40 years ago. The book lists efficient sorting networks with n &lt;= 16 inputs. In this paper we give general combinatorial arguments showing that if a sorting network with a given depth exists then there exists one with a special form. We then construct propositional formulas whose satisfiability is necessary for the existence of such a network. Using a SAT solver we conclude that the listed networks have optimal depth. For n &lt;= 10 inputs where optimality was known previously, our algorithm is four orders of magnitude faster than those in prior work.',
	 'authors': u'Daniel Bundala, Jakub Z\xe1vodn\xfd,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6271',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nOptimal Sorting Networks',
	 'urllink': u'http://arxiv.org/abs/1310.6271'}
2015-03-24 14:34:09+0000 [xxu46_7] INFO: Crawled 610 pages (at 1 pages/min), scraped 603 items (at 1 items/min)
2015-03-24 14:35:02+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5158> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 14:35:02+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5158>
	{'abstract': u'We give two new characterizations of (-linear) locally testable error-correcting codes in terms of Cayley graphs over : begin item A locally testable code is equivalent to a Cayley graph over whose set of generators is significantly larger than and has no short linear dependencies, but yields a shortest-path metric that embeds into with constant distortion. This extends and gives a converse to a result of Khot and Naor (2006), which showed that codes with large dual distance imply Cayley graphs that have no low-distortion embeddings into . item A locally testable code is equivalent to a Cayley graph over that has significantly more than eigenvalues near 1, which have no short linear dependencies among them and which "explain" all of the large eigenvalues. This extends and gives a converse to a recent construction of Barak et al. (2012), which showed that locally testable codes imply Cayley graphs that are small-set expanders but have many large eigenvalues. end',
	 'authors': u'Parikshit Gopalan, Salil Vadhan, Yuan Zhou,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5158',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nLocally Testable Codes and Cayley Graphs',
	 'urllink': u'http://arxiv.org/abs/1308.5158'}
2015-03-24 14:35:09+0000 [xxu46_7] INFO: Crawled 611 pages (at 1 pages/min), scraped 604 items (at 1 items/min)
2015-03-24 14:36:09+0000 [xxu46_7] INFO: Crawled 611 pages (at 0 pages/min), scraped 604 items (at 0 items/min)
2015-03-24 14:36:57+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6840> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 14:36:57+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6840>
	{'abstract': u'We present a novel approach for constrained Bayesian inference. Unlike current methods, our approach does not require convexity of the constraint set. We reduce the constrained variational inference to a parametric optimization over the feasible set of densities and propose a general recipe for such problems. We apply the proposed constrained Bayesian inference approach to multitask learning subject to rank constraints on the weight matrix. Further, constrained parameter estimation is applied to recover the sparse conditional independence structure encoded by prior precision matrices. Our approach is motivated by reverse inference for high dimensional functional neuroimaging, a domain where the high dimensionality and small number of examples requires the use of constraints to ensure meaningful and effective models. For this application, we propose a model that jointly learns a weight matrix and the prior inverse covariance structure between different tasks. We present experimental validation showing that the proposed approach outperforms strong baseline models in terms of predictive performance and structure recovery.',
	 'authors': u'Oluwasanmi Koyejo, Joydeep Ghosh,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6840',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nConstrained Bayesian Inference for Low Rank Multitask Learning',
	 'urllink': u'http://arxiv.org/abs/1309.6840'}
2015-03-24 14:37:09+0000 [xxu46_7] INFO: Crawled 612 pages (at 1 pages/min), scraped 605 items (at 1 items/min)
2015-03-24 14:37:49+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6265> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 14:37:49+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6265>
	{'abstract': u'We consider channels affected by intersymbol interference with reduced-complexity, mutual information optimized, channel-shortening detection. For such settings, we optimize the transmit filter, taking into consideration the reduced receiver complexity constraint. As figure of merit, we consider the achievable information rate of the entire system and with functional analysis, we establish a general form of the optimal transmit filter, which can then be optimized by standard numerical methods. As a corollary to our main result, we obtain some insight of the behavior of the standard waterfilling algorithm for intersymbol interference channels. With only some minor changes, the general form we derive can be applied to multiple-input multiple-output channels with intersymbol interference. To illuminate the practical use of our results, we provide applications of our theoretical results by deriving the optimal shaping pulse of a linear modulation transmitted over a bandlimited additive white Gaussian noise channel which has possible applications in the faster-than-Nyquist/time packing technique.',
	 'authors': u'Andrea Modenini, Fredrik Rusek, Giulio Colavolpe,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6265',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOptimal Transmit Filters for ISI Channels under Channel Shortening  Detection',
	 'urllink': u'http://arxiv.org/abs/1310.6265'}
2015-03-24 14:38:09+0000 [xxu46_7] INFO: Crawled 613 pages (at 1 pages/min), scraped 606 items (at 1 items/min)
2015-03-24 14:39:09+0000 [xxu46_7] INFO: Crawled 613 pages (at 0 pages/min), scraped 606 items (at 0 items/min)
2015-03-24 14:39:22+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5149> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 14:39:22+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5149>
	{'abstract': u"In light of the ever-increasing demand for new spectral bands and the underutilization of those already allocated, the concept of Cognitive Radio (CR) has emerged. Opportunistic users could exploit temporarily vacant bands after detecting the absence of activity of their owners. One of the crucial tasks in the CR cycle is therefore spectrum sensing and detection which has to be precise and efficient. Yet, CRs typically deal with wideband signals whose Nyquist rates are very high. In this paper, we propose to reconstruct the power spectrum of such signals from sub-Nyquist samples, rather than the signal itself as done in previous work, in order to perform detection. We consider both sparse and non sparse signals as well as blind and non blind detection in the sparse case. For each one of those scenarii, we derive the minimal sampling rate allowing perfect reconstruction of the signal's power spectrum in a noise-free environment and provide power spectrum recovery techniques that achieve those rates. The analysis is performed for two different signal models considered in the literature, which we refer to as the analog and digital models, and shows that both lead to similar results. Simulations demonstrate power spectrum recovery at the minimal rate in noise-free settings and show the impact of several parameters on the detector performance, including signal-to-noise ratio (SNR), sensing time and sampling rate.",
	 'authors': u'Deborah Cohen, Yonina C. Eldar,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5149',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nSub-Nyquist Sampling for Power Spectrum Sensing in Cognitive Radios: A  Unified Approach',
	 'urllink': u'http://arxiv.org/abs/1308.5149'}
2015-03-24 14:40:09+0000 [xxu46_7] INFO: Crawled 614 pages (at 1 pages/min), scraped 607 items (at 1 items/min)
2015-03-24 14:41:06+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6839> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 14:41:06+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6839>
	{'abstract': u'A limited-memory influence diagram (LIMID) generalizes a traditional influence diagram by relaxing the assumptions of regularity and no-forgetting, allowing a wider range of decision problems to be modeled. Algorithms for solving traditional influence diagrams are not easily generalized to solve LIMIDs, however, and only recently have exact algorithms for solving LIMIDs been developed. In this paper, we introduce an exact algorithm for solving LIMIDs that is based on branch-and-bound search. Our approach is related to the approach of solving an influence diagram by converting it to an equivalent decision tree, with the difference that the LIMID is converted to a much smaller decision graph that can be searched more efficiently.',
	 'authors': u'Arindam Khaled, Eric A. Hansen, Changhe Yuan,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6839',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nSolving Limited-Memory Influence Diagrams Using Branch-and-Bound Search',
	 'urllink': u'http://arxiv.org/abs/1309.6839'}
2015-03-24 14:41:09+0000 [xxu46_7] INFO: Crawled 615 pages (at 1 pages/min), scraped 608 items (at 1 items/min)
2015-03-24 14:42:09+0000 [xxu46_7] INFO: Crawled 615 pages (at 0 pages/min), scraped 608 items (at 0 items/min)
2015-03-24 14:42:53+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6259> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 14:42:53+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6259>
	{'abstract': u'A cross slotted electronic band gap (EBG) with stacked rectangular patches shorted with a shorting pin is proposed in this paper. The study is being done on how the various parameters are varied by changing the probe feed location. The design is constructed by using stacking of patches, shorting pin and cross slotted EBG to form an optimized antenna design with antenna efficiency of approximately 99.06%. The radiation patterns are given at 2.586 GHz which can be used for wireless communications.',
	 'authors': u'N.S Raghava, Asok De, Nitish Kataria, Sarthak Chatterjee,',
	 'category': u'Computer Science ',
	 'date': '2013-10-16',
	 'pdflink': u'http://arxiv.org/pdf/1310.6259',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nStacked Patch Antenna With Cross Slot Electronic Band Gap Structure',
	 'urllink': u'http://arxiv.org/abs/1310.6259'}
2015-03-24 14:43:09+0000 [xxu46_7] INFO: Crawled 616 pages (at 1 pages/min), scraped 609 items (at 1 items/min)
2015-03-24 14:44:09+0000 [xxu46_7] INFO: Crawled 616 pages (at 0 pages/min), scraped 609 items (at 0 items/min)
2015-03-24 14:44:48+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5146> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 14:44:48+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5146>
	{'abstract': u'We present a general architecture for the acquisition of ensembles of correlated signals. The signals are multiplexed onto a single line by mixing each one against a different code and then adding them together, and the resulting signal is sampled at a high rate. We show that if the signals, each bandlimited to Hz, can be approximated by a superposition of underlying signals, then the ensemble can be recovered by sampling at a rate within a logarithmic factor of (as compared to the Nyquist rate of ). This sampling theorem shows that the correlation structure of the signal ensemble can be exploited in the acquisition process even though it is unknown a priori. The reconstruction of the ensemble is recast as a low-rank matrix recovery problem from linear measurements. The architectures we are considering impose a certain type of structure on the linear operators. Although our results depend on the mixing forms being random, this imposed structure results in a very different type of random projection than those analyzed in the low-rank recovery literature to date.',
	 'authors': u'Ali Ahmed, Justin Romberg,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5146',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nCompressive Multiplexing of Correlated Signals',
	 'urllink': u'http://arxiv.org/abs/1308.5146'}
2015-03-24 14:45:09+0000 [xxu46_7] INFO: Crawled 617 pages (at 1 pages/min), scraped 610 items (at 1 items/min)
2015-03-24 14:46:09+0000 [xxu46_7] INFO: Crawled 617 pages (at 0 pages/min), scraped 610 items (at 0 items/min)
2015-03-24 14:46:40+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6838> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 14:46:40+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6838>
	{'abstract': u'We propose maximum likelihood estimation for learning Gaussian graphical models with a Gaussian (ell_2^2) prior on the parameters. This is in contrast to the commonly used Laplace (ell_1) prior for encouraging sparseness. We show that our optimization problem leads to a Riccati matrix equation, which has a closed form solution. We propose an efficient algorithm that performs a singular value decomposition of the training data. Our algorithm is O(NT^2)-time and O(NT)-space for N variables and T samples. Our method is tailored to high-dimensional problems (N gg T), in which sparseness promoting methods become intractable. Furthermore, instead of obtaining a single solution for a specific regularization parameter, our algorithm finds the whole solution path. We show that the method has logarithmic sample complexity under the spiked covariance model. We also propose sparsification of the dense solution with provable performance guarantees. We provide techniques for using our learnt models, such as removing unimportant variables, computing likelihoods and conditional distributions. Finally, we show promising results in several gene expressions datasets.',
	 'authors': u'Jean Honorio, Tommi S. Jaakkola,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6838',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nInverse Covariance Estimation for High-Dimensional Data in Linear Time  and Space: Spectral Methods for Riccati and Sparse Models',
	 'urllink': u'http://arxiv.org/abs/1309.6838'}
2015-03-24 14:47:09+0000 [xxu46_7] INFO: Crawled 618 pages (at 1 pages/min), scraped 611 items (at 1 items/min)
2015-03-24 14:48:09+0000 [xxu46_7] INFO: Crawled 618 pages (at 0 pages/min), scraped 611 items (at 0 items/min)
2015-03-24 14:48:32+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6257> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 14:48:32+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6257>
	{'abstract': u'Probabilistic inference over large data sets is an increasingly important data management challenge. The central problem is that exact inference is generally #P-hard, which limits the size of data that can be efficiently queried. This paper proposes a new approach for approximate evaluation of queries over probabilistic databases: in this approach, every query is evaluated entirely in the database engine by evaluating a fixed number of query plans, each providing an upper bound on the true probability, then taking their minimum. We provide an algorithm that takes into account important schema information to enumerate only the minimal necessary plans among all possible plans. Importantly, this algorithm is a strict generalization of all known results of PTIME self-join free conjunctive queries: the query is safe if and only if our algorithm returns one single plan. Furthermore, our approach is a generalization of a family of efficient network ranking functions from graphs to hypergraphs. We also describe three relational query optimization techniques that allow us to evaluate all minimal safe plans in a single query and very fast. We give a detailed experimental evaluation of our approach and, in the process, provide new way of thinking about the value of probabilistic methods over non-probabilistic methods for ranking query answers. We also note that the techniques developed in this paper apply immediately to lifted inference from statistical relational models since lifted inference corresponds to safe plans in probabilistic databases.',
	 'authors': u'Wolfgang Gatterbauer, Dan Suciu,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6257',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nDissociation and Propagation for Efficient Query Evaluation over  Probabilistic Databases',
	 'urllink': u'http://arxiv.org/abs/1310.6257'}
2015-03-24 14:49:09+0000 [xxu46_7] INFO: Crawled 619 pages (at 1 pages/min), scraped 612 items (at 1 items/min)
2015-03-24 14:49:57+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5144> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 14:49:57+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5144>
	{'abstract': u"In this study we propose a novel method to successfully detect the ADRs using feature matrix and feature selection. A feature matrix, which characterizes the medical events before patients take drugs or after patients take drugs, is created from THIN database. The feature selection method of Student's t-test is used to detect the significant features from thousands of medical events. The significant ADRs, which are corresponding to significant features, are detected. Experiments are performed on the drug Pioglitazone. Compared to other computerized methods, our proposed method achieves good performance.",
	 'authors': u'Yihui Liu, Uwe Aickelin,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5144',
	 'subjects': u'Computational Engineering, Finance, and Science (cs.CE)',
	 'title': u'\nDetect adverse drug reactions for drug Pioglitazone',
	 'urllink': u'http://arxiv.org/abs/1308.5144'}
2015-03-24 14:50:09+0000 [xxu46_7] INFO: Crawled 620 pages (at 1 pages/min), scraped 613 items (at 1 items/min)
2015-03-24 14:51:09+0000 [xxu46_7] INFO: Crawled 620 pages (at 0 pages/min), scraped 613 items (at 0 items/min)
2015-03-24 14:51:40+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6836> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 14:51:40+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6836>
	{'abstract': u'We present a very general approach to learning the structure of causal models based on d-separation constraints, obtained from any given set of overlapping passive observational or experimental data sets. The procedure allows for both directed cycles (feedback loops) and the presence of latent variables. Our approach is based on a logical representation of causal pathways, which permits the integration of quite general background knowledge, and inference is performed using a Boolean satisfiability (SAT) solver. The procedure is complete in that it exhausts the available information on whether any given edge can be determined to be present or absent, and returns "unknown" otherwise. Many existing constraint-based causal discovery algorithms can be seen as special cases, tailored to circumstances in which one or more restricting assumptions apply. Simulations illustrate the effect of these assumptions on discovery and how the present algorithm scales.',
	 'authors': u'Antti Hyttinen, Patrik O. Hoyer, Frederick Eberhardt, Matti Jarvisalo,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6836',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nDiscovering Cyclic Causal Models with Latent Variables: A General  SAT-Based Procedure',
	 'urllink': u'http://arxiv.org/abs/1309.6836'}
2015-03-24 14:52:09+0000 [xxu46_7] INFO: Crawled 621 pages (at 1 pages/min), scraped 614 items (at 1 items/min)
2015-03-24 14:53:09+0000 [xxu46_7] INFO: Crawled 621 pages (at 0 pages/min), scraped 614 items (at 0 items/min)
2015-03-24 14:53:25+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6205> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 14:53:25+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6205>
	{'abstract': u'The maximum stable set problem is NP-hard, even when restricted to triangle-free graphs. In particular, one cannot expect a polynomial time algorithm deciding if a bull-free graph has a stable set of size , when is part of the instance. Our main result in this paper is to show the existence of an FPT algorithm when we parameterize the problem by the solution size . A polynomial kernel is unlikely to exist for this problem. We show however that our problem has a polynomial size Turing-kernel. More precisely, the hard cases are instances of size . As a byproduct, if we forbid odd holes in addition to the bull, we show the existence of a polynomial time algorithm for the stable set problem. We also prove that the chromatic number of a bull-free graph is bounded by a function of its clique number and the maximum chromatic number of its triangle-free induced subgraphs. All our results rely on a decomposition theorem of bull-free graphs due to Chudnovsky which is modified here, allowing us to provide extreme decompositions, adapted to our computational purpose.',
	 'authors': u'St\xe9phan Thomass\xe9, Nicolas Trotignon, Kristina Vuskovi\u0107,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6205',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nParameterized algorithm for weighted independent set problem in  bull-free graphs',
	 'urllink': u'http://arxiv.org/abs/1310.6205'}
2015-03-24 14:54:09+0000 [xxu46_7] INFO: Crawled 622 pages (at 1 pages/min), scraped 615 items (at 1 items/min)
2015-03-24 14:55:09+0000 [xxu46_7] INFO: Crawled 622 pages (at 0 pages/min), scraped 615 items (at 0 items/min)
2015-03-24 14:55:17+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5138> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 14:55:17+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5138>
	{'abstract': u'The biological immune system is a robust, complex, adaptive system that defends the body from foreign pathogens. It is able to categorize all cells (or molecules) within the body as self or non-self substances. It does this with the help of a distributed task force that has the intelligence to take action from a local and also a global perspective using its network of chemical messengers for communication. There are two major branches of the immune system. The innate immune system is an unchanging mechanism that detects and destroys certain invading organisms, whilst the adaptive immune system responds to previously unknown foreign cells and builds a response to them that can remain in the body over a long period of time. This remarkable information processing biological system has caught the attention of computer science in recent years. A novel computational intelligence technique, inspired by immunology, has emerged, called Artificial Immune Systems. Several concepts from the immune system have been extracted and applied for solution to real world science and engineering problems. In this tutorial, we briefly describe the immune system metaphors that are relevant to existing Artificial Immune Systems methods. We will then show illustrative real-world problems suitable for Artificial Immune Systems and give a step-by-step algorithm walkthrough for one such problem. A comparison of the Artificial Immune Systems to other well-known algorithms, areas for future work, tips &amp; tricks and a list of resources will round this tutorial off. It should be noted that as Artificial Immune Systems is still a young and evolving field, there is not yet a fixed algorithm template and hence actual implementations might differ somewhat from time to time and from those examples given here.',
	 'authors': u'Uwe Aickelin, Dipankar Dasgupta, Feng Gu,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5138',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nArtificial Immune Systems (INTROS 2)',
	 'urllink': u'http://arxiv.org/abs/1308.5138'}
2015-03-24 14:56:09+0000 [xxu46_7] INFO: Crawled 623 pages (at 1 pages/min), scraped 616 items (at 1 items/min)
2015-03-24 14:57:02+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6835> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 14:57:02+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6835>
	{'abstract': u'We introduce stochastic variational inference for Gaussian process models. This enables the application of Gaussian process (GP) models to data sets containing millions of data points. We show how GPs can be vari- ationally decomposed to depend on a set of globally relevant inducing variables which factorize the model in the necessary manner to perform variational inference. Our ap- proach is readily extended to models with non-Gaussian likelihoods and latent variable models based around Gaussian processes. We demonstrate the approach on a simple toy problem and two real world data sets.',
	 'authors': u'James Hensman, Nicolo Fusi, Neil D. Lawrence,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6835',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nGaussian Processes for Big Data',
	 'urllink': u'http://arxiv.org/abs/1309.6835'}
2015-03-24 14:57:09+0000 [xxu46_7] INFO: Crawled 624 pages (at 1 pages/min), scraped 617 items (at 1 items/min)
2015-03-24 14:58:09+0000 [xxu46_7] INFO: Crawled 624 pages (at 0 pages/min), scraped 617 items (at 0 items/min)
2015-03-24 14:58:52+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6176> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 14:58:52+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6176>
	{'abstract': u'Session types are used to describe and structure interactions between independent processes in distributed systems. Higher-order types are needed in order to properly structure delegation of responsibility between processes. In this paper we show that higher-order web-service contracts can be used to provide a fully-abstract model of recursive higher-order session types. The model is set-theoretic, in the sense that the meaning of a contract is given in terms of the set of contracts with which it complies. The proof of full-abstraction depends on a novel notion of the complement of a contract. This in turn gives rise to an alternative to the type duality commonly used in systems for type-checking session types. We believe that the notion of complement captures more faithfully the behavioural intuition underlying type duality.',
	 'authors': u'Giovanni Bernardi, Matthew Hennessy,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6176',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nUsing higher-order contracts to model session types',
	 'urllink': u'http://arxiv.org/abs/1310.6176'}
2015-03-24 14:59:09+0000 [xxu46_7] INFO: Crawled 625 pages (at 1 pages/min), scraped 618 items (at 1 items/min)
2015-03-24 15:00:09+0000 [xxu46_7] INFO: Crawled 625 pages (at 0 pages/min), scraped 618 items (at 0 items/min)
2015-03-24 15:00:38+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5137> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 15:00:38+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5137>
	{'abstract': u'The measure of distance between two fuzzy sets is a fundamental tool within fuzzy set theory. However, current distance measures within the literature do not account for the direction of change between fuzzy sets; a useful concept in a variety of applications, such as Computing With Words. In this paper, we highlight this utility and introduce a distance measure which takes the direction between sets into account. We provide details of its application for normal and non-normal, as well as convex and non-convex fuzzy sets. We demonstrate the new distance measure using real data from the MovieLens dataset and establish the benefits of measuring the direction between fuzzy sets.',
	 'authors': u'Josie McCulloch, Christian Wagner, Uwe Aickelin,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5137',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nMeasuring the Directional Distance Between Fuzzy Sets',
	 'urllink': u'http://arxiv.org/abs/1308.5137'}
2015-03-24 15:01:09+0000 [xxu46_7] INFO: Crawled 626 pages (at 1 pages/min), scraped 619 items (at 1 items/min)
2015-03-24 15:02:09+0000 [xxu46_7] INFO: Crawled 626 pages (at 0 pages/min), scraped 619 items (at 0 items/min)
2015-03-24 15:02:33+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6834> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 15:02:33+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6834>
	{'abstract': u'This paper considers the problem of learning the parameters in Bayesian networks of discrete variables with known structure and hidden variables. Previous approaches in these settings typically use expectation maximization; when the network has high treewidth, the required expectations might be approximated using Monte Carlo or variational methods. We show how to avoid inference altogether during learning by giving a polynomial-time algorithm based on the method-of-moments, building upon recent work on learning discrete-valued mixture models. In particular, we show how to learn the parameters for a family of bipartite noisy-or Bayesian networks. In our experimental results, we demonstrate an application of our algorithm to learning QMR-DT, a large Bayesian network used for medical diagnosis. We show that it is possible to fully learn the parameters of QMR-DT even when only the findings are observed in the training data (ground truth diseases unknown).',
	 'authors': u'Yonatan Halpern, David Sontag,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6834',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nUnsupervised Learning of Noisy-Or Bayesian Networks',
	 'urllink': u'http://arxiv.org/abs/1309.6834'}
2015-03-24 15:03:09+0000 [xxu46_7] INFO: Crawled 627 pages (at 1 pages/min), scraped 620 items (at 1 items/min)
2015-03-24 15:03:26+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6173> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 15:03:26+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6173>
	{'abstract': u'We address the problem of Mobility Robustness Optimization (MRO) and describe centralized Self Organizing Network (SON) solutions that can optimize connected-mode mobility Key Performance Indicators (KPIs). Our solution extends the earlier work of eICIC parameter optimization [7], to heterogeneous networks with mobility, and outline methods of progressive complexity that optimize the Retaining/Offloading Bias which are macro/pico views of Cell Individual Offset parameters. Simulation results under real LTE network deployment assumptions of a US metropolitan area demonstrate the effects of such solutions on the mobility KPIs. To our knowledge, this solution is the first that demonstrates the joint optimization of eICIC and MRO.',
	 'authors': u'Carl Weaver, Pantelis Monogioudis,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6173',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nSelf-Organizing Mobility Robustness Optimization in LTE Networks with  eICIC',
	 'urllink': u'http://arxiv.org/abs/1310.6173'}
2015-03-24 15:04:09+0000 [xxu46_7] INFO: Crawled 628 pages (at 1 pages/min), scraped 621 items (at 1 items/min)
2015-03-24 15:04:56+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5136> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 15:04:56+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5136>
	{'abstract': u'Similarity measures provide one of the core tools that enable reasoning about fuzzy sets. While many types of similarity measures exist for type-1 and interval type-2 fuzzy sets, there are very few similarity measures that enable the comparison of general type-2 fuzzy sets. In this paper, we introduce a general method for extending existing interval type-2 similarity measures to similarity measures for general type-2 fuzzy sets. Specifically, we show how similarity measures for interval type-2 fuzzy sets can be employed in conjunction with the zSlices based general type-2 representation for fuzzy sets to provide measures of similarity which preserve all the common properties (i.e. reflexivity, symmetry, transitivity and overlapping) of the original interval type-2 similarity measure. We demonstrate examples of such extended fuzzy measures and provide comparisons between (different types of) interval and general type-2 fuzzy measures.',
	 'authors': u'Josie McCulloch, Christian Wagner, Uwe Aickelin,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5136',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nExtending Similarity Measures of Interval Type-2 Fuzzy Sets to General  Type-2 Fuzzy Sets',
	 'urllink': u'http://arxiv.org/abs/1308.5136'}
2015-03-24 15:05:09+0000 [xxu46_7] INFO: Crawled 629 pages (at 1 pages/min), scraped 622 items (at 1 items/min)
2015-03-24 15:06:09+0000 [xxu46_7] INFO: Crawled 629 pages (at 0 pages/min), scraped 622 items (at 0 items/min)
2015-03-24 15:06:47+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6833> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 15:06:47+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6833>
	{'abstract': u'We introduce a graphical framework for multiple instance learning (MIL) based on Markov networks. This framework can be used to model the traditional MIL definition as well as more general MIL definitions. Different levels of ambiguity -- the portion of positive instances in a bag -- can be explored in weakly supervised data. To train these models, we propose a discriminative max-margin learning algorithm leveraging efficient inference for cardinality-based cliques. The efficacy of the proposed framework is evaluated on a variety of data sets. Experimental results verify that encoding or learning the degree of ambiguity can improve classification performance.',
	 'authors': u'Hossein Hajimirsadeghi, Jinling Li, Greg Mori, Mohammad Zaki, Tarek Sayed,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6833',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nMultiple Instance Learning by Discriminative Training of Markov Networks',
	 'urllink': u'http://arxiv.org/abs/1309.6833'}
2015-03-24 15:07:09+0000 [xxu46_7] INFO: Crawled 630 pages (at 1 pages/min), scraped 623 items (at 1 items/min)
2015-03-24 15:08:09+0000 [xxu46_7] INFO: Crawled 630 pages (at 0 pages/min), scraped 623 items (at 0 items/min)
2015-03-24 15:08:15+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6171> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 15:08:15+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6171>
	{'abstract': u"We present and evaluate a procedure that utilizes mobility and throughput prediction to prefetch video streaming data in integrated cellular and WiFi networks. The effective integration of such heterogeneous wireless technologies will be significant for supporting high performance and energy efficient video streaming in ubiquitous networking environments. Our evaluation is based on trace-driven simulation considering empirical measurements and shows how various system parameters influence the performance, in terms of the number of paused video frames and the energy consumption; these parameters include the number of video streams, the mobile, WiFi, and ADSL backhaul throughput, and the number of WiFi hotspots. Also, we assess the procedure's robustness to time and throughput variability. Finally, we present our initial prototype that implements the proposed approach.",
	 'authors': u'Vasilios A. Siris, Maria Anagnostopoulou, Dimitris Dimopoulos,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6171',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nImproving Mobile Video Streaming with Mobility Prediction and  Prefetching in Integrated Cellular-WiFi Networks',
	 'urllink': u'http://arxiv.org/abs/1310.6171'}
2015-03-24 15:09:09+0000 [xxu46_7] INFO: Crawled 631 pages (at 1 pages/min), scraped 624 items (at 1 items/min)
2015-03-24 15:09:41+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5133> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 15:09:41+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5133>
	{'abstract': u'Performance measurement of robotic controllers based on fuzzy logic, operating under uncertainty, is a subject area which has been somewhat ignored in the current literature. In this paper standard measures such as RMSE are shown to be inappropriate for use under conditions where the environmental uncertainty changes significantly between experiments. An overview of current methods which have been applied by other authors is presented, followed by a design of a more sophisticated method of comparison. This method is then applied to a robotic control problem to observe its outcome compared with a single measure. Results show that the technique described provides a more robust method of performance comparison than less complex methods allowing better comparisons to be drawn.',
	 'authors': u'Naisan Benatar, Uwe Aickelin, Jonathan M. Garibald,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5133',
	 'subjects': u'Robotics (cs.RO)',
	 'title': u'\nPerformance Measurement Under Increasing Environmental Uncertainty In  The Context of Interval Type-2 Fuzzy Logic Based Robotic Sailing',
	 'urllink': u'http://arxiv.org/abs/1308.5133'}
2015-03-24 15:10:09+0000 [xxu46_7] INFO: Crawled 632 pages (at 1 pages/min), scraped 625 items (at 1 items/min)
2015-03-24 15:11:09+0000 [xxu46_7] INFO: Crawled 632 pages (at 0 pages/min), scraped 625 items (at 0 items/min)
2015-03-24 15:11:14+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6832> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 15:11:14+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6832>
	{'abstract': u'In this paper, we present structured message passing (SMP), a unifying framework for approximate inference algorithms that take advantage of structured representations such as algebraic decision diagrams and sparse hash tables. These representations can yield significant time and space savings over the conventional tabular representation when the message has several identical values (context-specific independence) or zeros (determinism) or both in its range. Therefore, in order to fully exploit the power of structured representations, we propose to artificially introduce context-specific independence and determinism in the messages. This yields a new class of powerful approximate inference algorithms which includes popular algorithms such as cluster-graph Belief propagation (BP), expectation propagation and particle BP as special cases. We show that our new algorithms introduce several interesting bias-variance trade-offs. We evaluate these trade-offs empirically and demonstrate that our new algorithms are more accurate and scalable than state-of-the-art techniques.',
	 'authors': u'Vibhav Gogate, Pedro Domingos,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6832',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nStructured Message Passing',
	 'urllink': u'http://arxiv.org/abs/1309.6832'}
2015-03-24 15:12:09+0000 [xxu46_7] INFO: Crawled 633 pages (at 1 pages/min), scraped 626 items (at 1 items/min)
2015-03-24 15:13:08+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6162> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 15:13:08+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6162>
	{'abstract': u'In November 2012 the Google Scholar Metrics (GSM) journal rankings were updated, making it possible to compare bibliometric indicators in the 10 languages indexed and their stability with the April 2012 version. The h-index and h 5 median of 1000 journals were analysed, comparing their averages, maximum and minimum values and the correlation coefficient within rankings. The bibliometric figures grew significantly. In just seven and a half months the h index of the journals increased by 15% and the median h-index by 17%. This growth was observed for all the bibliometric indicators analysed and for practically every journal. However, we found significant differences in growth rates depending on the language in which the journal is published. Moreover, the journal rankings seem to be stable between April and November, reinforcing the credibility of the data held by Google Scholar and the reliability of the GSM journal rankings, despite the uncontrolled growth of Google Scholar. Based on the findings of this study we suggest, firstly, that Google should upgrade its rankings at least semiannually and, secondly, that the results should be displayed in each ranking proportionally to the number of journals indexed by language',
	 'authors': u'Enrique Orduna-Malea, Emilio Delgado Lopez-Cozar,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6162',
	 'subjects': u'Digital Libraries (cs.DL)',
	 'title': u'\nGoogle Scholar Metrics evolution: an analysis according to languages',
	 'urllink': u'http://arxiv.org/abs/1310.6162'}
2015-03-24 15:13:09+0000 [xxu46_7] INFO: Crawled 634 pages (at 1 pages/min), scraped 627 items (at 1 items/min)
2015-03-24 15:14:09+0000 [xxu46_7] INFO: Crawled 634 pages (at 0 pages/min), scraped 627 items (at 0 items/min)
2015-03-24 15:14:39+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5125> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 15:14:39+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5125>
	{'abstract': u'User content curation is becoming an important source of preference data, as well as providing information regarding the items being curated. One popular approach involves the creation of lists. On Twitter, these lists might contain accounts relevant to a particular topic, whereas on a community site such as the Internet Movie Database (IMDb), this might take the form of lists of movies sharing common characteristics. While list curation involves substantial combined effort on the part of users, researchers have rarely looked at mining the outputs of this kind of crowdsourcing activity. Here we study a large collection of movie lists from IMDb. We apply network analysis methods to a graph that reflects the degree to which pairs of movies are "co-listed", that is, assigned to the same lists. This allows us to uncover a more nuanced grouping of movies that goes beyond categorisation schemes based on attributes such as genre or director.',
	 'authors': u'Derek Greene, P\xe1draig Cunningham,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5125',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nDiscovering Latent Patterns from the Analysis of User-Curated Movie  Lists',
	 'urllink': u'http://arxiv.org/abs/1308.5125'}
2015-03-24 15:15:09+0000 [xxu46_7] INFO: Crawled 635 pages (at 1 pages/min), scraped 628 items (at 1 items/min)
2015-03-24 15:16:03+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6831> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 15:16:03+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6831>
	{'abstract': u'Matching pursuit (MP) methods are a promising class of feature construction algorithms for value function approximation. Yet existing MP methods require creating a pool of potential features, mandating expert knowledge or enumeration of a large feature pool, both of which hinder scalability. This paper introduces batch incremental feature dependency discovery (Batch-iFDD) as an MP method that inherits a provable convergence property. Additionally, Batch-iFDD does not require a large pool of features, leading to lower computational complexity. Empirical policy evaluation results across three domains with up to one million states highlight the scalability of Batch-iFDD over the previous state of the art MP algorithm.',
	 'authors': u'Alborz Geramifard, Thomas J. Walsh, Nicholas Roy, Jonathan How,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6831',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nBatch-iFDD for Representation Expansion in Large MDPs',
	 'urllink': u'http://arxiv.org/abs/1309.6831'}
2015-03-24 15:16:09+0000 [xxu46_7] INFO: Crawled 636 pages (at 1 pages/min), scraped 629 items (at 1 items/min)
2015-03-24 15:17:09+0000 [xxu46_7] INFO: Crawled 636 pages (at 0 pages/min), scraped 629 items (at 0 items/min)
2015-03-24 15:17:50+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6139> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 15:17:50+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6139>
	{'abstract': u'We propose a practical network code for the wireless two-way relay channel where all nodes communicate in full duplex (FD) mode. The physical layer network coding (PNC) operation is applied with the FD operating nodes, reducing the transmission time to a single time slot, hence doubling the spectral efficiency when compared to classical PNC systems. In our system model, binary phase shift keying modulated signals are transmitted over Rayleigh fading channels. We derive the theoretical error rates at relay and end nodes according to the maximum likelihood detection rule, in case of non-ideal self-interference cancellation. Theoretical results are also verified via simulations.',
	 'authors': u'Semiha Tedik, G\xfcne\u015f Karabulut Kurt,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6139',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nPractical Full Duplex Physical Layer Network Coding',
	 'urllink': u'http://arxiv.org/abs/1310.6139'}
2015-03-24 15:18:09+0000 [xxu46_7] INFO: Crawled 637 pages (at 1 pages/min), scraped 630 items (at 1 items/min)
2015-03-24 15:19:09+0000 [xxu46_7] INFO: Crawled 637 pages (at 0 pages/min), scraped 630 items (at 0 items/min)
2015-03-24 15:19:19+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5092> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 15:19:19+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5092>
	{'abstract': u"In this paper we propose and investigate the performance of a multi-channel scheduling algorithm based on the well-known deficit round-robin (DRR), which we call multi-channel DRR (MCDRR). We extend the original DRR to the case of multiple channels with tunable transmitters and fixed receivers to provide efficient fair queueing in hybrid time division multiplexing (TDM)/wavelength division multiplexing (WDM) optical networks. We take into account the availability of channels and tunable transmitters in extending the DRR and allow the overlap of `rounds' in scheduling to efficiently utilize channels and tunable transmitters. Simulation results show that the proposed MCDRR can provide nearly perfect fairness with ill-behaved flows for different sets of conditions for interframe times and frame sizes in hybrid TDM/WDM optical networks with tunable transmitters and fixed receivers.",
	 'authors': u'Mithileysh Sathiyanarayanan, Kyeong Soo Kim,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5092',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nMulti-Channel Deficit Round-Robin Scheduling for Hybrid TDM/WDM Optical  Networks',
	 'urllink': u'http://arxiv.org/abs/1308.5092'}
2015-03-24 15:20:09+0000 [xxu46_7] INFO: Crawled 638 pages (at 1 pages/min), scraped 631 items (at 1 items/min)
2015-03-24 15:21:09+0000 [xxu46_7] INFO: Crawled 638 pages (at 0 pages/min), scraped 631 items (at 0 items/min)
2015-03-24 15:21:20+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6830> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 15:21:20+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6830>
	{'abstract': u'In this paper we propose a multi-armed bandit inspired, pool based active learning algorithm for the problem of binary classification. By carefully constructing an analogy between active learning and multi-armed bandits, we utilize ideas such as lower confidence bounds, and self-concordant regularization from the multi-armed bandit literature to design our proposed algorithm. Our algorithm is a sequential algorithm, which in each round assigns a sampling distribution on the pool, samples one point from this distribution, and queries the oracle for the label of this sampled point. The design of this sampling distribution is also inspired by the analogy between active learning and multi-armed bandits. We show how to derive lower confidence bounds required by our algorithm. Experimental comparisons to previously proposed active learning algorithms show superior performance on some standard UCI datasets.',
	 'authors': u'Ravi Ganti, Alexander G. Gray,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6830',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nBuilding Bridges: Viewing Active Learning from the Multi-Armed Bandit  Lens',
	 'urllink': u'http://arxiv.org/abs/1309.6830'}
2015-03-24 15:22:09+0000 [xxu46_7] INFO: Crawled 639 pages (at 1 pages/min), scraped 632 items (at 1 items/min)
2015-03-24 15:23:04+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6129> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 15:23:04+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6129>
	{'abstract': u'Land use classification is essential for urban planning. Urban land use types can be differentiated either by their physical characteristics (such as reflectivity and texture) or social functions. Remote sensing techniques have been recognized as a vital method for urban land use classification because of their ability to capture the physical characteristics of land use. Although significant progress has been achieved in remote sensing methods designed for urban land use classification, most techniques focus on physical characteristics, whereas knowledge of social functions is not adequately used. Owing to the wide usage of mobile phones, the activities of residents, which can be retrieved from the mobile phone data, can be determined in order to indicate the social function of land use. This could bring about the opportunity to derive land use information from mobile phone data. To verify the application of this new data source to urban land use classification, we first construct a time series of aggregated mobile phone data to characterize land use types. This time series is composed of two aspects: the hourly relative pattern, and the total call volume. A semi-supervised fuzzy c-means clustering approach is then applied to infer the land use types. The method is validated using mobile phone data collected in Singapore. Land use is determined with a detection rate of 58.03%. An analysis of the land use classification results shows that the accuracy decreases as the heterogeneity of land use increases, and increases as the density of cell phone towers increases.',
	 'authors': u'Tao Pei, Stanislav Sobolevsky, Carlo Ratti, Shih-Lung Shaw, Chenghu Zhou,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6129',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nA New Insight into Land Use Classification Based on Aggregated Mobile  Phone Data',
	 'urllink': u'http://arxiv.org/abs/1310.6129'}
2015-03-24 15:23:09+0000 [xxu46_7] INFO: Crawled 640 pages (at 1 pages/min), scraped 633 items (at 1 items/min)
2015-03-24 15:24:09+0000 [xxu46_7] INFO: Crawled 640 pages (at 0 pages/min), scraped 633 items (at 0 items/min)
2015-03-24 15:24:53+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5091> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 15:24:53+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5091>
	{'abstract': u'This Paper is designed using J2EE (JSP, SERVLET), HTML as front end and a Oracle 9i is back end. SPRMAN is been developed for the client British Telecom (BT) UK., Telecom company. Actually the requirement of BT is, they are providing Network Security Related Products to their IT customers like Virtusa,Wipro,HCL etc., This product is framed out by set of protocols and these protocols are been associated with set of components. By grouping all these protocols and components together, product is been developed. After framing out the product, it is been subscribed to their individual customers. Once a customer subscribed the product, then he will be raising a request to the client (BT) for updating any policy or component in the product. The customer has been given read/write access to the subscribed product. The customer user having read/write access is only allowed to raise a request for the product, but not the user having only the read access. The group of request is been managed as manage work queue in client area. Management of this protocol inside the product is considering as Security Protocol Review Method Analyzer. SPRMAN helps BT to overcome all the hurdles faced by them while processing the requests of their various clients using their already existing software applications. SPRMAN emphasizes on nature of the request and gives priority to issues based on their degree of future consequences. Thus SPRMAN builds a good relationship between BT and its customers.',
	 'authors': u'A.S.Syed Navaz, H.Iyyappa Narayanan, R.Vinoth,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5091',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nSecurity Protocol Review Method Analyzer(SPRMAN)',
	 'urllink': u'http://arxiv.org/abs/1308.5091'}
2015-03-24 15:25:09+0000 [xxu46_7] INFO: Crawled 641 pages (at 1 pages/min), scraped 634 items (at 1 items/min)
2015-03-24 15:25:58+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6829> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 15:25:58+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6829>
	{'abstract': u'We consider the problem of maximum a posteriori (MAP) inference in discrete graphical models. We present a parallel MAP inference algorithm called Bethe-ADMM based on two ideas: tree-decomposition of the graph and the alternating direction method of multipliers (ADMM). However, unlike the standard ADMM, we use an inexact ADMM augmented with a Bethe-divergence based proximal function, which makes each subproblem in ADMM easy to solve in parallel using the sum-product algorithm. We rigorously prove global convergence of Bethe-ADMM. The proposed algorithm is extensively evaluated on both synthetic and real datasets to illustrate its effectiveness. Further, the parallel Bethe-ADMM is shown to scale almost linearly with increasing number of cores.',
	 'authors': u'Qiang Fu, Huahua Wang, Arindam Banerjee,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6829',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nBethe-ADMM for Tree Decomposition based Parallel MAP Inference',
	 'urllink': u'http://arxiv.org/abs/1309.6829'}
2015-03-24 15:26:09+0000 [xxu46_7] INFO: Crawled 642 pages (at 1 pages/min), scraped 635 items (at 1 items/min)
2015-03-24 15:27:09+0000 [xxu46_7] INFO: Crawled 642 pages (at 0 pages/min), scraped 635 items (at 0 items/min)
2015-03-24 15:27:45+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6119> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 15:27:45+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6119>
	{'abstract': u"In this paper, we present an experimental analysis of the asynchronous push &amp; pull rumour spreading protocol. This protocol is, to date, the best-performing rumour spreading protocol for simple, scalable, and robust information dissemination in distributed systems. We analyse the effect that multiple parameters have on the protocol's performance, such as using memory to avoid contacting the same neighbor twice in a row, varying the stopping criteria used by nodes to decide when to stop spreading the rumour, employing more sophisticated neighbor selection policies instead of the standard uniform random choice, and others. Prior work has focused on either providing theoretical upper bounds regarding the number of rounds needed to spread the rumour to all nodes, or, proposes improvements by adjusting isolated parameters. To our knowledge, our work is the first to study how multiple parameters affect system behaviour both in isolation and combination and under a wide range of values. Our analysis is based on experimental simulations using real-world social network datasets, thus complementing prior theoretical work to shed light on how the protocol behaves in practical, real-world systems. We also study the behaviour of the protocol on a special type of social graph, called signed networks (e.g., Slashdot and Epinions), whose links indicate stronger trust relationships. Finally, through our detailed analysis, we demonstrate how a few simple additions to the protocol can improve the total time required to inform 100% of the nodes by a maximum of 99.69% and an average of 82.37%.",
	 'authors': u'Christos Patsonakis, Mema Roussopoulos,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6119',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nAsynchronous Rumour Spreading in Social and Signed Topologies',
	 'urllink': u'http://arxiv.org/abs/1310.6119'}
2015-03-24 15:28:09+0000 [xxu46_7] INFO: Crawled 643 pages (at 1 pages/min), scraped 636 items (at 1 items/min)
2015-03-24 15:29:09+0000 [xxu46_7] INFO: Crawled 643 pages (at 0 pages/min), scraped 636 items (at 0 items/min)
2015-03-24 15:29:16+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5079> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 15:29:16+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5079>
	{'abstract': u'A visibility representation is a classical drawing style of planar graphs. It displays the vertices of a graph as horizontal vertex-segments, and each edge is represented by a vertical edge-segment touching the segments of its end vertices; beyond that segments do not intersect. We generalize visibility to 1-visibility, where each edge- (vertex-) segment crosses at most one vertex- (edge-) segment. In other words, a vertex is crossed by at most one edge, and vice-versa. We show that 1-visibility properly extends 1-planarity and develop a linear time algorithm to compute a 1-visibility representation of an embedded 1-planar graph on O(n^2) area. A graph is 1-planar if it can be drawn in the plane such that each edge is crossed at most once. Concerning density, both 1-visible and 1-planar graphs of size have at most 4n-8 edges. However, for every n &gt;= 7 there are 1-visible graphs with 4n-8 edge which are not 1-planar.',
	 'authors': u'Franz J. Brandenburg,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5079',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\n1-Visibility Representations of 1-Planar Graphs',
	 'urllink': u'http://arxiv.org/abs/1308.5079'}
2015-03-24 15:30:09+0000 [xxu46_7] INFO: Crawled 644 pages (at 1 pages/min), scraped 637 items (at 1 items/min)
2015-03-24 15:31:09+0000 [xxu46_7] INFO: Crawled 644 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2015-03-24 15:31:16+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6828> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 15:31:16+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6828>
	{'abstract': u'Popular Monte-Carlo tree search (MCTS) algorithms for online planning, such as epsilon-greedy tree search and UCT, aim at rapidly identifying a reasonably good action, but provide rather poor worst-case guarantees on performance improvement over time. In contrast, a recently introduced MCTS algorithm BRUE guarantees exponential-rate improvement over time, yet it is not geared towards identifying reasonably good choices right at the go. We take a stand on the individual strengths of these two classes of algorithms, and show how they can be effectively connected. We then rationalize a principle of "selective tree expansion", and suggest a concrete implementation of this principle within MCTS. The resulting algorithm,s favorably compete with other MCTS algorithms under short planning times, while preserving the attractive convergence properties of BRUE.',
	 'authors': u'Zohar Feldman, Carmel Domshlak,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6828',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nMonte-Carlo Planning: Theoretically Fast Convergence Meets Practical  Efficiency',
	 'urllink': u'http://arxiv.org/abs/1309.6828'}
2015-03-24 15:32:09+0000 [xxu46_7] INFO: Crawled 645 pages (at 1 pages/min), scraped 638 items (at 1 items/min)
2015-03-24 15:32:32+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6110> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 15:32:32+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6110>
	{'abstract': u'When a user finds an interesting recommendation in a recommender system, the user may want to recall related items recommended in the past to reconsider or to enjoy them again. If the system can pick up such "recalled" items at each user\'s request, it must deepen the user experience. We propose a model and the algorithm for such personalized "recalling" in conventional recommender systems, which is an application of neural networks for associative memory. In our model, the "recalled" items can reflect each user\'s personality beyond naive similarities between items.',
	 'authors': u'Keisuke Hara, Tomihisa Kamada,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6110',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nA two-step model and the algorithm for recalling in recommender systems',
	 'urllink': u'http://arxiv.org/abs/1310.6110'}
2015-03-24 15:33:09+0000 [xxu46_7] INFO: Crawled 646 pages (at 1 pages/min), scraped 639 items (at 1 items/min)
2015-03-24 15:33:31+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5063> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 15:33:31+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5063>
	{'abstract': u'We propose a state of the art method for intelligent object recognition and video surveillance based on human visual attention. Bottom up and top down attention are applied respectively in the process of acquiring interested object(saliency map) and object recognition. The revision of 4 channel PFT method is proposed for bottom up attention and enhances the speed and accuracy. Inhibit of return (IOR) is applied in judging the sequence of saliency object pop out. Euclidean distance of color distribution, object center coordinates and speed are considered in judging whether the target is match and suspicious. The extensive tests on videos and images show that our method in video analysis has high accuracy and fast speed compared with traditional method. The method can be applied into many fields such as video surveillance and security.',
	 'authors': u'Panqu Wang, Yan Zhang,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5063',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nSuspicious Object Recognition Method in Video Stream Based on Visual  Attention',
	 'urllink': u'http://arxiv.org/abs/1308.5063'}
2015-03-24 15:34:09+0000 [xxu46_7] INFO: Crawled 647 pages (at 1 pages/min), scraped 640 items (at 1 items/min)
2015-03-24 15:35:09+0000 [xxu46_7] INFO: Crawled 647 pages (at 0 pages/min), scraped 640 items (at 0 items/min)
2015-03-24 15:35:17+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6827> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 15:35:17+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6827>
	{'abstract': u'Many probabilistic inference tasks involve summations over exponentially large sets. Recently, it has been shown that these problems can be reduced to solving a polynomial number of MAP inference queries for a model augmented with randomly generated parity constraints. By exploiting a connection with max-likelihood decoding of binary codes, we show that these optimizations are computationally hard. Inspired by iterative message passing decoding algorithms, we propose an Integer Linear Programming (ILP) formulation for the problem, enhanced with new sparsification techniques to improve decoding performance. By solving the ILP through a sequence of LP relaxations, we get both lower and upper bounds on the partition function, which hold with high probability and are much tighter than those obtained with variational methods.',
	 'authors': u'Stefano Ermon, Carla P. Gomes, Ashish Sabharwal, Bart Selman,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6827',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nOptimization With Parity Constraints: From Binary Codes to Discrete  Integration',
	 'urllink': u'http://arxiv.org/abs/1309.6827'}
2015-03-24 15:36:09+0000 [xxu46_7] INFO: Crawled 648 pages (at 1 pages/min), scraped 641 items (at 1 items/min)
2015-03-24 15:36:38+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6092> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 15:36:38+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6092>
	{'abstract': u'Diffusion Tensor Imaging (DTI) is a non-invasive imaging technique that allows estimation of the location of white matter tracts in-vivo, based on the measurement of water diffusion properties. For each voxel, a second-order tensor can be calculated by using diffusion-weighted sequences (DWI) that are sensitive to the random motion of water molecules. Given at least 6 diffusion-weighted images with different gradients and one unweighted image, the coefficients of the symmetric diffusion tensor matrix can be calculated. Deriving the eigensystem of the tensor, the eigenvectors and eigenvalues can be calculated to describe the three main directions of diffusion and its magnitude. Using DTI data, fiber bundles can be determined, to gain information about eloquent brain structures. Especially in neurosurgery, information about location and dimension of eloquent structures like the corticospinal tract or the visual pathways is of major interest. Therefore, the fiber bundle boundary has to be determined. In this paper, a novel ray-based approach for boundary estimation of tubular structures is presented.',
	 'authors': u'Miriam H. A. Bauer, Sebastiano Barbieri, Jan Klein, Jan Egger, Daniela Kuhnt, Bernd Freisleben, Horst K. Hahn, Christopher Nimsky,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6092',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nA Ray-based Approach for Boundary Estimation of Fiber Bundles Derived  from Diffusion Tensor Imaging',
	 'urllink': u'http://arxiv.org/abs/1310.6092'}
2015-03-24 15:37:09+0000 [xxu46_7] INFO: Crawled 649 pages (at 1 pages/min), scraped 642 items (at 1 items/min)
2015-03-24 15:38:09+0000 [xxu46_7] INFO: Crawled 649 pages (at 0 pages/min), scraped 642 items (at 0 items/min)
2015-03-24 15:38:10+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5053> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 15:38:10+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5053>
	{'abstract': u'Green communication attracts increasing research interest recently. Equipped with a rechargeable battery, a source node can harvest energy from ambient environments and rely on this free and regenerative energy supply to transmit packets. Due to the uncertainty of available energy from harvesting, however, intolerably large latency and packet loss could be induced, if the source always waits for harvested energy. To overcome this problem, one Reliable Energy Source (RES) can be resorted to for a prompt delivery of backlogged packets. Naturally, there exists a tradeoff between the packet delivery delay and power consumption from the RES. In this paper, we address the delay optimal scheduling problem for a bursty communication link powered by a capacity-limited battery storing harvested energy together with one RES. The proposed scheduling scheme gives priority to the usage of harvested energy, and resorts to the RES when necessary based on the data and energy queueing processes, with an average power constraint from the RES. Through twodimensional Markov chain modeling and linear programming formulation, we derive the optimal threshold-based scheduling policy together with the corresponding transmission parameters. Our study includes three exemplary cases that capture some important relations between the data packet arrival process and energy harvesting capability. Our theoretical analysis is corroborated by simulation results.',
	 'authors': u'Juan Liu, Huaiyu Dai, Wei Chen,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5053',
	 'subjects': u'Emerging Technologies (cs.ET)',
	 'title': u'\nDelay Optimal Scheduling for Energy Harvesting Based Communications',
	 'urllink': u'http://arxiv.org/abs/1308.5053'}
2015-03-24 15:39:09+0000 [xxu46_7] INFO: Crawled 650 pages (at 1 pages/min), scraped 643 items (at 1 items/min)
2015-03-24 15:39:54+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6826> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 15:39:54+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6826>
	{'abstract': u'Possibilistic and qualitative POMDPs (pi-POMDPs) are counterparts of POMDPs used to model situations where the agent\'s initial belief or observation probabilities are imprecise due to lack of past experiences or insufficient data collection. However, like probabilistic POMDPs, optimally solving pi-POMDPs is intractable: the finite belief state space exponentially grows with the number of system\'s states. In this paper, a possibilistic version of Mixed-Observable MDPs is presented to get around this issue: the complexity of solving pi-POMDPs, some state variables of which are fully observable, can be then dramatically reduced. A value iteration algorithm for this new formulation under infinite horizon is next proposed and the optimality of the returned policy (for a specified criterion) is shown assuming the existence of a "stay" action in some goal states. Experimental work finally shows that this possibilistic model outperforms probabilistic POMDPs commonly used in robotics, for a target recognition problem where the agent\'s observations are imprecise.',
	 'authors': u'Nicolas Drougard, Florent Teichteil-Konigsbuch, Jean-Loup Farges, Didier Dubois,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6826',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nQualitative Possibilistic Mixed-Observable MDPs',
	 'urllink': u'http://arxiv.org/abs/1309.6826'}
2015-03-24 15:40:09+0000 [xxu46_7] INFO: Crawled 651 pages (at 1 pages/min), scraped 644 items (at 1 items/min)
2015-03-24 15:41:09+0000 [xxu46_7] INFO: Crawled 651 pages (at 0 pages/min), scraped 644 items (at 0 items/min)
2015-03-24 15:41:10+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6084> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 15:41:10+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6084>
	{'abstract': u'A monotone drawing of a planar graph is a planar straight-line drawing of where a monotone path exists between every pair of vertices of in some direction. Recently monotone drawings of planar graphs have been proposed as a new standard for visualizing graphs. A monotone drawing of a planar graph is a monotone grid drawing if every vertex in the drawing is drawn on a grid point. In this paper we study monotone grid drawings of planar graphs in a variable embedding setting. We show that every connected planar graph of vertices has a monotone grid drawing on a grid of size , and such a drawing can be found in O(n) time.',
	 'authors': u'Md. Iqbal Hossain, Md. Saidur Rahman,',
	 'category': u'Computer Science ',
	 'date': '2013-10-23',
	 'pdflink': u'http://arxiv.org/pdf/1310.6084',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nMonotone Grid Drawings of Planar Graphs',
	 'urllink': u'http://arxiv.org/abs/1310.6084'}
2015-03-24 15:42:09+0000 [xxu46_7] INFO: Crawled 652 pages (at 1 pages/min), scraped 645 items (at 1 items/min)
2015-03-24 15:42:55+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5046> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 15:42:55+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5046>
	{'abstract': u'Modern SAT solvers have experienced a remarkable progress on solving industrial instances. Most of the techniques have been developed after an intensive experimental testing process. Recently, there have been some attempts to analyze the structure of these formulas in terms of complex networks, with the long-term aim of explaining the success of these SAT solving techniques, and possibly improving them. We study the fractal dimension of SAT formulas, and show that most industrial families of formulas are self-similar, with a small fractal dimension. We also show that this dimension is not affected by the addition of learnt clauses. We explore how the dimension of a formula, together with other graph properties can be used to characterize SAT instances. Finally, we give empirical evidence that these graph properties can be used in state-of-the-art portfolios.',
	 'authors': u'C. Ans\xf3tegui, M. L. Bonet, J. Gir\xe1ldez-Cru, J. Levy,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5046',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nThe Fractal Dimension of SAT Formulas',
	 'urllink': u'http://arxiv.org/abs/1308.5046'}
2015-03-24 15:43:09+0000 [xxu46_7] INFO: Crawled 653 pages (at 1 pages/min), scraped 646 items (at 1 items/min)
2015-03-24 15:44:09+0000 [xxu46_7] INFO: Crawled 653 pages (at 0 pages/min), scraped 646 items (at 0 items/min)
2015-03-24 15:44:25+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6825> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 15:44:25+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6825>
	{'abstract': u'We consider the problem of learning Bayesian networks (BNs) from complete discrete data. This problem of discrete optimisation is formulated as an integer program (IP). We describe the various steps we have taken to allow efficient solving of this IP. These are (i) efficient search for cutting planes, (ii) a fast greedy algorithm to find high-scoring (perhaps not optimal) BNs and (iii) tightening the linear relaxation of the IP. After relating this BN learning problem to set covering and the multidimensional 0-1 knapsack problem, we present our empirical results. These show improvements, sometimes dramatic, over earlier results.',
	 'authors': u'Mark Bartlett, James Cussens,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6825',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nAdvances in Bayesian Network Learning using Integer Programming',
	 'urllink': u'http://arxiv.org/abs/1309.6825'}
2015-03-24 15:45:09+0000 [xxu46_7] INFO: Crawled 654 pages (at 1 pages/min), scraped 647 items (at 1 items/min)
2015-03-24 15:46:09+0000 [xxu46_7] INFO: Crawled 654 pages (at 0 pages/min), scraped 647 items (at 0 items/min)
2015-03-24 15:46:27+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6078> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 15:46:27+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6078>
	{'abstract': u'The plasmodium of Physarum polycephalum is a large single cell visible with the naked eye. When inoculated on a substrate with attractants and repellents the plasmodium develops optimal networks of protoplasmic tubes which span sites of attractants (i.e. nutrients) yet avoid domains with a high nutrient concentration. It should therefore be possible to program the plasmodium towards deterministic adaptive transformation of internalised nano- and micro-scale materials. In laboratory experiments with magnetite nanoparticles and glass micro-spheres coated with silver metal we demonstrate that the plasmodium of P. polycephalum can propagate the nano-scale objects using a number of distinct mechanisms including endocytosis, transcytosis and dragging. The results of our experiments could be used in the development of novel techniques targeted towards the growth of metallised biological wires and hybrid nano- and micro-circuits.',
	 'authors': u'Richard Mayne, David Patton, Ben de Lacy Costello, Andrew Adamatzky, Rosemary Camilla Patton,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.6078',
	 'subjects': u'Emerging Technologies (cs.ET)',
	 'title': u'\nOn the internalisation, intraplasmodial carriage and excretion of  metallic nanoparticles in the slime mould Physarum polycephalum',
	 'urllink': u'http://arxiv.org/abs/1310.6078'}
2015-03-24 15:47:09+0000 [xxu46_7] INFO: Crawled 655 pages (at 1 pages/min), scraped 648 items (at 1 items/min)
2015-03-24 15:48:09+0000 [xxu46_7] INFO: Crawled 655 pages (at 0 pages/min), scraped 648 items (at 0 items/min)
2015-03-24 15:48:23+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5038> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 15:48:23+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5038>
	{'abstract': u"Convex optimization with sparsity-promoting convex regularization is a standard approach for estimating sparse signals in noise. In order to promote sparsity more strongly than convex regularization, it is also standard practice to employ non-convex optimization. In this paper, we take a third approach. We utilize a non-convex regularization term chosen such that the total cost function (consisting of data consistency and regularization terms) is convex. Therefore, sparsity is more strongly promoted than in the standard convex formulation, but without sacrificing the attractive aspects of convex optimization (unique minimum, robust algorithms, etc.). We use this idea to improve the recently developed 'overlapping group shrinkage' (OGS) algorithm for the denoising of group-sparse signals. The algorithm is applied to the problem of speech enhancement with favorable results in terms of both SNR and perceptual quality.",
	 'authors': u'Po-Yu Chen, Ivan W. Selesnick,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5038',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nGroup-Sparse Signal Denoising: Non-Convex Regularization, Convex  Optimization',
	 'urllink': u'http://arxiv.org/abs/1308.5038'}
2015-03-24 15:49:09+0000 [xxu46_7] INFO: Crawled 656 pages (at 1 pages/min), scraped 649 items (at 1 items/min)
2015-03-24 15:49:56+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6824> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 15:49:56+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6824>
	{'abstract': u'This paper shows that causal model discovery is not an NP-hard problem, in the sense that for sparse graphs bounded by node degree k the sound and complete causal model can be obtained in worst case order N^ independence tests, even when latent variables and selection bias may be present. We present a modification of the well-known FCI algorithm that implements the method for an independence oracle, and suggest improvements for sample/real-world data versions. It does not contradict any known hardness results, and does not solve an NP-hard problem: it just proves that sparse causal discovery is perhaps more complicated, but not as hard as learning minimal Bayesian networks.',
	 'authors': u'Tom Claassen, Joris Mooij, Tom Heskes,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6824',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nLearning Sparse Causal Models is not NP-hard',
	 'urllink': u'http://arxiv.org/abs/1309.6824'}
2015-03-24 15:50:09+0000 [xxu46_7] INFO: Crawled 657 pages (at 1 pages/min), scraped 650 items (at 1 items/min)
2015-03-24 15:50:59+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6066> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 15:50:59+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6066>
	{'abstract': u'This paper is aimed at developing and combining different algorithms for face detection and face recognition to generate an efficient mechanism that can detect and recognize the facial regions of input image. For the detection of face from complex region, skin segmentation isolates the face-like regions in a complex image and following operations of morphology and template matching rejects false matches to extract facial region. For the recognition of the face, the image database is now converted into a database of facial segments. Hence, implementing the technique of Elastic Bunch Graph matching (EBGM) after skin segmentation generates Face Bunch Graphs that acutely represents the features of an individual face enhances the quality of the training set. This increases the matching probability significantly.',
	 'authors': u'Sayantan Sarkar,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.6066',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nSkin Segmentation based Elastic Bunch Graph Matching for efficient  multiple Face Recognition',
	 'urllink': u'http://arxiv.org/abs/1310.6066'}
2015-03-24 15:51:09+0000 [xxu46_7] INFO: Crawled 658 pages (at 1 pages/min), scraped 651 items (at 1 items/min)
2015-03-24 15:52:09+0000 [xxu46_7] INFO: Crawled 658 pages (at 0 pages/min), scraped 651 items (at 0 items/min)
2015-03-24 15:52:17+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5033> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 15:52:17+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5033>
	{'abstract': u'A hybrid evolutionary algorithm with importance sampling method is proposed for multi-dimensional optimization problems in this paper. In order to make use of the information provided in the search process, a set of visited solutions is selected to give scores for intervals in each dimension, and they are updated as algorithm proceeds. Those intervals with higher scores are regarded as good intervals, which are used to estimate the joint distribution of optimal solutions through an interaction between the pool of good genetics, which are the individuals with smaller fitness values. And the sampling probabilities for good genetics are determined through an interaction between those estimated good intervals. It is a cross validation mechanism which determines the sampling probabilities for good intervals and genetics, and the resulted probabilities are used to design crossover, mutation and other stochastic operators with importance sampling method. As the selection of genetics and intervals is not directly dependent on the values of fitness, the resulted offsprings may avoid the trap of local optima. And a purely random EA is also combined into the proposed algorithm to maintain the diversity of population. 30 benchmark test functions are used to evaluate the performance of the proposed algorithm, and it is found that the proposed hybrid algorithm is an efficient algorithm for multi-dimensional optimization problems considered in this paper.',
	 'authors': u'Guanghui Huang, Zhifeng Pan,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5033',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nA hybrid evolutionary algorithm with importance sampling for  multi-dimensional optimization',
	 'urllink': u'http://arxiv.org/abs/1308.5033'}
2015-03-24 15:53:09+0000 [xxu46_7] INFO: Crawled 659 pages (at 1 pages/min), scraped 652 items (at 1 items/min)
2015-03-24 15:53:48+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6823> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 15:53:48+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6823>
	{'abstract': u'Although many convex relaxations of clustering have been proposed in the past decade, current formulations remain restricted to spherical Gaussian or discriminative models and are susceptible to imbalanced clusters. To address these shortcomings, we propose a new class of convex relaxations that can be flexibly applied to more general forms of Bregman divergence clustering. By basing these new formulations on normalized equivalence relations we retain additional control on relaxation quality, which allows improvement in clustering quality. We furthermore develop optimization methods that improve scalability by exploiting recent implicit matrix norm methods. In practice, we find that the new formulations are able to efficiently produce tighter clusterings that improve the accuracy of state of the art methods.',
	 'authors': u'Hao Cheng, Xinhua Zhang, Dale Schuurmans,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6823',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nConvex Relaxations of Bregman Divergence Clustering',
	 'urllink': u'http://arxiv.org/abs/1309.6823'}
2015-03-24 15:54:09+0000 [xxu46_7] INFO: Crawled 660 pages (at 1 pages/min), scraped 653 items (at 1 items/min)
2015-03-24 15:55:09+0000 [xxu46_7] INFO: Crawled 660 pages (at 0 pages/min), scraped 653 items (at 0 items/min)
2015-03-24 15:55:22+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6063> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 15:55:22+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6063>
	{'abstract': u'There is a large collection of Handwritten English paper documents of Historical and Scientific importance. But paper documents are not recognized directly by computer. Hence the closest way of indexing these documents is by storing their document digital image. Hence a large database of document images can replace the paper documents. But the document and data corresponding to each image cannot be directly recognized by the computer. This paper applies the technique of word spotting using Modified Character Shape Code to Handwritten English document images for quick and efficient query search of words on a database of document images. It is different from other Word Spotting techniques as it implements two level of selection for word segments to match search query. First based on word size and then based on character shape code of query. It makes the process faster and more efficient and reduces the need of multiple pre-processing.',
	 'authors': u'Sayantan Sarkar,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.6063',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nWord Spotting in Cursive Handwritten Documents using Modified Character  Shape Codes',
	 'urllink': u'http://arxiv.org/abs/1310.6063'}
2015-03-24 15:56:09+0000 [xxu46_7] INFO: Crawled 661 pages (at 1 pages/min), scraped 654 items (at 1 items/min)
2015-03-24 15:57:09+0000 [xxu46_7] INFO: Crawled 661 pages (at 0 pages/min), scraped 654 items (at 0 items/min)
2015-03-24 15:57:15+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5032> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 15:57:15+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5032>
	{'abstract': u"This paper summarizes efforts to computationally model two transitions in the evolution of human creativity: its origins about two million years ago, and the 'big bang' of creativity about 50,000 years ago. Using a computational model of cultural evolution in which neural network based agents evolve ideas for actions through invention and imitation, we tested the hypothesis that human creativity began with onset of the capacity for recursive recall. We compared runs in which agents were limited to single-step actions to runs in which they used recursive recall to chain simple actions into complex ones. Chaining resulted in higher diversity, open-ended novelty, no ceiling on the mean fitness of actions, and greater ability to make use of learning. Using a computational model of portrait painting, we tested the hypothesis that the explosion of creativity in the Middle/Upper Paleolithic was due to onset of con-textual focus: the capacity to shift between associative and analytic thought. This resulted in faster convergence on portraits that resembled the sitter, employed painterly techniques, and were rated as preferable. We conclude that recursive recall and contextual focus provide a computationally plausible explanation of how humans evolved the means to transform this planet.",
	 'authors': u'Liane Gabora, Steve DiPaola,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5032',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nHow Did Humans Become So Creative? A Computational Approach',
	 'urllink': u'http://arxiv.org/abs/1308.5032'}
2015-03-24 15:58:09+0000 [xxu46_7] INFO: Crawled 662 pages (at 1 pages/min), scraped 655 items (at 1 items/min)
2015-03-24 15:59:03+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6822> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 15:59:03+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6822>
	{'abstract': u'Using the theory of group action, we first introduce the concept of the automorphism group of an exponential family or a graphical model, thus formalizing the general notion of symmetry of a probabilistic model. This automorphism group provides a precise mathematical framework for lifted inference in the general exponential family. Its group action partitions the set of random variables and feature functions into equivalent classes (called orbits) having identical marginals and expectations. Then the inference problem is effectively reduced to that of computing marginals or expectations for each class, thus avoiding the need to deal with each individual variable or feature. We demonstrate the usefulness of this general framework in lifting two classes of variational approximation for maximum a posteriori (MAP) inference: local linear programming (LP) relaxation and local LP relaxation with cycle constraints; the latter yields the first lifted variational inference algorithm that operates on a bound tighter than the local constraints.',
	 'authors': u'Hung Bui, Tuyen Huynh, Sebastian Riedel,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6822',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nAutomorphism Groups of Graphical Models and Lifted Variational Inference',
	 'urllink': u'http://arxiv.org/abs/1309.6822'}
2015-03-24 15:59:09+0000 [xxu46_7] INFO: Crawled 663 pages (at 1 pages/min), scraped 656 items (at 1 items/min)
2015-03-24 16:00:09+0000 [xxu46_7] INFO: Crawled 663 pages (at 0 pages/min), scraped 656 items (at 0 items/min)
2015-03-24 16:00:53+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6055> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 16:00:53+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6055>
	{'abstract': u'This work constructs a new class of multirate schemes based on the recently developed generalized additive Runge-Kutta (GARK) methods (Sandu and Guenther, 2013). Multirate schemes use different step sizes for different components and for different partitions of the right-hand side based on the local activity levels. We show that the new multirate GARK family includes many well-known multirate schemes as special cases. The order conditions theory follows directly from the GARK accuracy theory. Nonlinear stability and monotonicity investigations show that these properties are inherited from the base schemes provided that additional coupling conditions hold.',
	 'authors': u'Michael Guenther, Adrian Sandu,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.6055',
	 'subjects': u'Numerical Analysis (cs.NA)',
	 'title': u'\nMultirate generalized additive Runge Kutta methods',
	 'urllink': u'http://arxiv.org/abs/1310.6055'}
2015-03-24 16:01:09+0000 [xxu46_7] INFO: Crawled 664 pages (at 1 pages/min), scraped 657 items (at 1 items/min)
2015-03-24 16:02:09+0000 [xxu46_7] INFO: Crawled 664 pages (at 0 pages/min), scraped 657 items (at 0 items/min)
2015-03-24 16:02:54+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5029> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 16:02:54+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5029>
	{'abstract': u'In this paper, we are concerned with the problem of determining the existence of multiple equilibria in economic models. We propose a general and complete approach for identifying multiplicities of equilibria in semi-algebraic economies, which may be expressed as semi-algebraic systems. The approach is based on triangular decomposition and real solution classification, two powerful tools of algebraic computation. Its effectiveness is illustrated by two examples of application.',
	 'authors': u'Xiaoliang Li, Dongming Wang,',
	 'category': u'Computer Science ',
	 'date': '2013-8-23',
	 'pdflink': u'http://arxiv.org/pdf/1308.5029',
	 'subjects': u'Symbolic Computation (cs.SC)',
	 'title': u'\nComputing Equilibria of Semi-algebraic Economies Using Triangular  Decomposition and Real Solution Classification',
	 'urllink': u'http://arxiv.org/abs/1308.5029'}
2015-03-24 16:03:09+0000 [xxu46_7] INFO: Crawled 665 pages (at 1 pages/min), scraped 658 items (at 1 items/min)
2015-03-24 16:04:09+0000 [xxu46_7] INFO: Crawled 665 pages (at 0 pages/min), scraped 658 items (at 0 items/min)
2015-03-24 16:04:31+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6821> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 16:04:31+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6821>
	{'abstract': u'Transferring knowledge across a sequence of reinforcement-learning tasks is challenging, and has a number of important applications. Though there is encouraging empirical evidence that transfer can improve performance in subsequent reinforcement-learning tasks, there has been very little theoretical analysis. In this paper, we introduce a new multi-task algorithm for a sequence of reinforcement-learning tasks when each task is sampled independently from (an unknown) distribution over a finite set of Markov decision processes whose parameters are initially unknown. For this setting, we prove under certain assumptions that the per-task sample complexity of exploration is reduced significantly due to transfer compared to standard single-task algorithms. Our multi-task algorithm also has the desired characteristic that it is guaranteed not to exhibit negative transfer: in the worst case its per-task sample complexity is comparable to the corresponding single-task algorithm.',
	 'authors': u'Emma Brunskill, Lihong Li,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6821',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nSample Complexity of Multi-task Reinforcement Learning',
	 'urllink': u'http://arxiv.org/abs/1309.6821'}
2015-03-24 16:05:09+0000 [xxu46_7] INFO: Crawled 666 pages (at 1 pages/min), scraped 659 items (at 1 items/min)
2015-03-24 16:05:39+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6019> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 16:05:39+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6019>
	{'abstract': u'Clustering graphs based on a comparison of the number of links within clusters and the expected value of this quantity in a random graph has gained a lot of attention and popularity in the last decade. Recently, Aldecoa and Marin proposed a related, but slightly different approach leading to the quality measure surprise, and reported good behavior in the context of synthetic and real world benchmarks. We show that the problem of finding a clustering with optimum surprise is NP-hard. Moreover, a bicriterial view on the problem permits to compute optimum solutions for small instances by solving a small number of integer linear programs, and leads to a polynomial time algorithm on trees.',
	 'authors': u'Tobias Fleck, Andrea Kappes, Dorothea Wagner,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.6019',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nGraph Clustering with Surprise: Complexity and Exact Solutions',
	 'urllink': u'http://arxiv.org/abs/1310.6019'}
2015-03-24 16:06:09+0000 [xxu46_7] INFO: Crawled 667 pages (at 1 pages/min), scraped 660 items (at 1 items/min)
2015-03-24 16:07:09+0000 [xxu46_7] INFO: Crawled 667 pages (at 0 pages/min), scraped 660 items (at 0 items/min)
2015-03-24 16:07:37+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.5015> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 16:07:37+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.5015>
	{'abstract': u'It is commonly believed that information spreads between individuals like a pathogen, with each exposure by an informed friend potentially resulting in a naive individual becoming infected. However, empirical studies of social media suggest that individual response to repeated exposure to information is significantly more complex than the prediction of the pathogen model. As a proxy for intervention experiments, we compare user responses to multiple exposures on two different social media sites, Twitter and Digg. We show that the position of the exposing messages on the user-interface strongly affects social contagion. Accounting for this visibility significantly simplifies the dynamics of social contagion. The likelihood an individual will spread information increases monotonically with exposure, while explicit feedback about how many friends have previously spread it increases the likelihood of a response. We apply our model to real-time forecasting of user behavior.',
	 'authors': u'Nathan O. Hodas, Kristina Lerman,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.5015',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nThe Simple Rules of Social Contagion',
	 'urllink': u'http://arxiv.org/abs/1308.5015'}
2015-03-24 16:08:09+0000 [xxu46_7] INFO: Crawled 668 pages (at 1 pages/min), scraped 661 items (at 1 items/min)
2015-03-24 16:08:40+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6820> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 16:08:40+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6820>
	{'abstract': u'We give a new consistent scoring function for structure learning of Bayesian networks. In contrast to traditional approaches to scorebased structure learning, such as BDeu or MDL, the complexity penalty that we propose is data-dependent and is given by the probability that a conditional independence test correctly shows that an edge cannot exist. What really distinguishes this new scoring function from earlier work is that it has the property of becoming computationally easier to maximize as the amount of data increases. We prove a polynomial sample complexity result, showing that maximizing this score is guaranteed to correctly learn a structure with no false edges and a distribution close to the generating distribution, whenever there exists a Bayesian network which is a perfect map for the data generating distribution. Although the new score can be used with any search algorithm, we give empirical results showing that it is particularly effective when used together with a linear programming relaxation approach to Bayesian network structure learning.',
	 'authors': u'Eliot Brenner, David Sontag,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6820',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nSparsityBoost: A New Scoring Function for Learning Bayesian Network  Structure',
	 'urllink': u'http://arxiv.org/abs/1309.6820'}
2015-03-24 16:09:09+0000 [xxu46_7] INFO: Crawled 669 pages (at 1 pages/min), scraped 662 items (at 1 items/min)
2015-03-24 16:10:09+0000 [xxu46_7] INFO: Crawled 669 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2015-03-24 16:10:25+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6011> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 16:10:25+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6011>
	{'abstract': u'We consider the classical problem of finding the sparse representation of a signal in a pair of bases. When both bases are orthogonal, it is known that the sparse representation is unique when the sparsity of the signal satisfies , where is the mutual coherence of the dictionary. Furthermore, the sparse representation can be obtained in polynomial time by Basis Pursuit (BP), when . Therefore, there is a gap between the unicity condition and the one required to use the polynomial-complexity BP formulation. For the case of general dictionaries, it is also well known that finding the sparse representation under the only constraint of unicity is NP-hard. In this paper, we introduce, for the case of Fourier and canonical bases, a polynomial complexity algorithm that finds all the possible -sparse representations of a signal under the weaker condition that . Consequently, when , the proposed algorithm solves the unique sparse representation problem for this structured dictionary in polynomial time. We further show that the same method can be extended to many other pairs of bases, one of which must have local atoms. Examples include the union of Fourier and local Fourier bases, the union of discrete cosine transform and canonical bases, and the union of random Gaussian and canonical bases.',
	 'authors': u'Pier Luigi Dragotti, Yue M. Lu,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.6011',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOn Sparse Representation in Fourier and Local Bases',
	 'urllink': u'http://arxiv.org/abs/1310.6011'}
2015-03-24 16:11:09+0000 [xxu46_7] INFO: Crawled 670 pages (at 1 pages/min), scraped 663 items (at 1 items/min)
2015-03-24 16:11:37+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4999> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 16:11:37+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4999>
	{'abstract': u'Data reflecting social and business relations has often form of network of connections between entities (called social network). In such network important and influential users can be identified as well as groups of strongly connected users. Finding such groups and observing their evolution becomes an increasingly important research problem. One of the significant problems is to develop method incorporating not only information about connections between entities but also information obtained from text written by the users. Method presented in this paper combine social network analysis and text mining in order to understand groups evolution.',
	 'authors': u'Bogdan Gliwa, Anna Zygmunt, Stanis\u0142aw Podg\xf3rski,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4999',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nIncorporating Text Analysis into Evolution of Social Groups in  Blogosphere',
	 'urllink': u'http://arxiv.org/abs/1308.4999'}
2015-03-24 16:12:09+0000 [xxu46_7] INFO: Crawled 671 pages (at 1 pages/min), scraped 664 items (at 1 items/min)
2015-03-24 16:13:09+0000 [xxu46_7] INFO: Crawled 671 pages (at 0 pages/min), scraped 664 items (at 0 items/min)
2015-03-24 16:13:30+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6819> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 16:13:30+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6819>
	{'abstract': u'Predictive State Representations (PSRs) are an expressive class of models for controlled stochastic processes. PSRs represent state as a set of predictions of future observable events. Because PSRs are defined entirely in terms of observable data, statistically consistent estimates of PSR parameters can be learned efficiently by manipulating moments of observed training data. Most learning algorithms for PSRs have assumed that actions and observations are finite with low cardinality. In this paper, we generalize PSRs to infinite sets of observations and actions, using the recent concept of Hilbert space embeddings of distributions. The essence is to represent the state as a nonparametric conditional embedding operator in a Reproducing Kernel Hilbert Space (RKHS) and leverage recent work in kernel methods to estimate, predict, and update the representation. We show that these Hilbert space embeddings of PSRs are able to gracefully handle continuous actions and observations, and that our learned models outperform competing system identification algorithms on several prediction benchmarks.',
	 'authors': u'Byron Boots, Geoffrey Gordon, Arthur Gretton,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6819',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nHilbert Space Embeddings of Predictive State Representations',
	 'urllink': u'http://arxiv.org/abs/1309.6819'}
2015-03-24 16:14:09+0000 [xxu46_7] INFO: Crawled 672 pages (at 1 pages/min), scraped 665 items (at 1 items/min)
2015-03-24 16:15:09+0000 [xxu46_7] INFO: Crawled 672 pages (at 0 pages/min), scraped 665 items (at 0 items/min)
2015-03-24 16:15:30+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6009> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 16:15:30+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6009>
	{'abstract': u'Memoryless computation is a novel means of computing any function of a set of registers by updating one register at a time while using no memory. We aim to emulate how computations are performed on modern cores, since they typically involve updates of single registers. The computation model of memoryless computation can be fully expressed in terms of transformation semigroups, or in the case of bijective functions, permutation groups. In this paper, we view registers as elements of a finite field and we compute linear permutations without memory. We first determine the maximum complexity of a linear function when only linear instructions are allowed. We also determine which linear functions are hardest to compute when the field in question is the binary field and the number of registers is even. Secondly, we investigate some matrix groups, thus showing that the special linear group is internally computable but not fast. Thirdly, we determine the smallest set of instructions required to generate the special and general linear groups. These results are important for memoryless computation, for they show that linear functions can be computed very fast or that very few instructions are needed to compute any linear function. They thus indicate new advantages of using memoryless computation.',
	 'authors': u'Peter J. Cameron, Ben Fairbairn, Maximilien Gadouleau,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.6009',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nComputing in matrix groups without memory',
	 'urllink': u'http://arxiv.org/abs/1310.6009'}
2015-03-24 16:16:09+0000 [xxu46_7] INFO: Crawled 673 pages (at 1 pages/min), scraped 666 items (at 1 items/min)
2015-03-24 16:17:09+0000 [xxu46_7] INFO: Crawled 673 pages (at 0 pages/min), scraped 666 items (at 0 items/min)
2015-03-24 16:17:24+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4996> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 16:17:24+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4996>
	{'abstract': u'A major open problem in the field of metric embedding is the existence of dimension reduction for -point subsets of Euclidean space, such that both distortion and dimension depend only on the of the pointset, and not on its cardinality. In this paper, we negate this possibility for spaces with . In particular, we introduce an -point subset of with doubling constant O(1), and demonstrate that any embedding of the set into with distortion must have .',
	 'authors': u'Yair Bartal, Lee-Ad Gottlieb, Ofer Neiman,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4996',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nOn the Impossibility of Dimension Reduction for Doubling Subsets of  $\\ell_p$, $p>2$',
	 'urllink': u'http://arxiv.org/abs/1308.4996'}
2015-03-24 16:18:09+0000 [xxu46_7] INFO: Crawled 674 pages (at 1 pages/min), scraped 667 items (at 1 items/min)
2015-03-24 16:19:09+0000 [xxu46_7] INFO: Crawled 674 pages (at 0 pages/min), scraped 667 items (at 0 items/min)
2015-03-24 16:19:10+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6818> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 16:19:10+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6818>
	{'abstract': u"Boosting is known to be sensitive to label noise. We studied two approaches to improve AdaBoost's robustness against labelling errors. One is to employ a label-noise robust classifier as a base learner, while the other is to modify the AdaBoost algorithm to be more robust. Empirical evaluation shows that a committee of robust classifiers, although converges faster than non label-noise aware AdaBoost, is still susceptible to label noise. However, pairing it with the new robust Boosting algorithm we propose here results in a more resilient algorithm under mislabelling.",
	 'authors': u'Jakramate Bootkrajang, Ata Kaban,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6818',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nBoosting in the presence of label noise',
	 'urllink': u'http://arxiv.org/abs/1309.6818'}
2015-03-24 16:20:09+0000 [xxu46_7] INFO: Crawled 675 pages (at 1 pages/min), scraped 668 items (at 1 items/min)
2015-03-24 16:20:29+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6008> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 16:20:29+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6008>
	{'abstract': u'Memoryless computation is a new technique to compute any function of a set of registers by updating one register at a time while using no memory. Its aim is to emulate how computations are performed in modern cores, since they typically involve updates of single registers. The memoryless computation model can be fully expressed in terms of transformation semigroups, or in the case of bijective functions, permutation groups. In this paper, we consider how efficiently permutations can be computed without memory. We determine the minimum number of basic updates required to compute any permutation, or any even permutation. The small number of required instructions shows that very small instruction sets could be encoded on cores to perform memoryless computation. We then start looking at a possible compromise between the size of the instruction set and the length of the resulting programs. We consider updates only involving a limited number of registers. In particular, we show that binary instructions are not enough to compute all permutations without memory when the alphabet size is even. These results, though expressed as properties of special generating sets of the symmetric or alternating groups, provide guidelines on the implementation of memoryless computation.',
	 'authors': u'Peter J. Cameron, Ben Fairbairn, Maximilien Gadouleau,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.6008',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nComputing in permutation groups without memory',
	 'urllink': u'http://arxiv.org/abs/1310.6008'}
2015-03-24 16:21:09+0000 [xxu46_7] INFO: Crawled 676 pages (at 1 pages/min), scraped 669 items (at 1 items/min)
2015-03-24 16:22:09+0000 [xxu46_7] INFO: Crawled 676 pages (at 0 pages/min), scraped 669 items (at 0 items/min)
2015-03-24 16:22:23+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4994> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 16:22:23+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4994>
	{'abstract': u'It was recently shown that low rank matrix completion theory can be employed for designing new sampling schemes in the context of MIMO radars, which can lead to the reduction of the high volume of data typically required for accurate target detection and estimation. Employing random samplers at each reception antenna, a partially observed version of the received data matrix is formulated at the fusion center, which, under certain conditions, can be recovered using convex optimization. This paper presents the theoretical analysis regarding the performance of matrix completion in colocated MIMO radar systems, exploiting the particular structure of the data matrix. Both Uniform Linear Arrays (ULAs) and arbitrary 2-dimensional arrays are considered for transmission and reception. Especially for the ULA case, under some mild assumptions on the directions of arrival of the targets, it is explicitly shown that the coherence of the data matrix is both asymptotically and approximately optimal with respect to the number of antennas of the arrays involved and further, the data matrix is recoverable using a subset of its entries with minimal cardinality. Sufficient conditions guaranteeing low matrix coherence and consequently satisfactory matrix completion performance are also presented, including the arbitrary 2-dimensional array case.',
	 'authors': u'Dionysios S. Kalogerias, Athina P. Petropulu,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4994',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nMatrix Completion in Colocated MIMO Radar: Recoverability, Bounds &  Theoretical Guarantees',
	 'urllink': u'http://arxiv.org/abs/1308.4994'}
2015-03-24 16:23:09+0000 [xxu46_7] INFO: Crawled 677 pages (at 1 pages/min), scraped 670 items (at 1 items/min)
2015-03-24 16:23:49+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6817> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 16:23:49+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6817>
	{'abstract': u'In order to represent the preferences of a group of individuals, we introduce Probabilistic CP-nets (PCP-nets). PCP-nets provide a compact language for representing probability distributions over preference orderings. We argue that they are useful for aggregating preferences or modelling noisy preferences. Then we give efficient algorithms for the main reasoning problems, namely for computing the probability that a given outcome is preferred to another one, and the probability that a given outcome is optimal. As a by-product, we obtain an unexpected linear-time algorithm for checking dominance in a standard, tree-structured CP-net.',
	 'authors': u'Damien Bigot, Bruno Zanuttini, Helene Fargier, Jerome Mengin,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6817',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nProbabilistic Conditional Preference Networks',
	 'urllink': u'http://arxiv.org/abs/1309.6817'}
2015-03-24 16:24:09+0000 [xxu46_7] INFO: Crawled 678 pages (at 1 pages/min), scraped 671 items (at 1 items/min)
2015-03-24 16:24:52+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.6007> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 16:24:52+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.6007>
	{'abstract': u'We propose an efficient optimization algorithm for selecting a subset of training data to induce sparsity for Gaussian process regression. The algorithm estimates an inducing set and the hyperparameters using a single objective, either the marginal likelihood or a variational free energy. The space and time complexity are linear in training set size, and the algorithm can be applied to large regression problems on discrete or continuous domains. Empirical evaluation shows state-of-art performance in discrete cases and competitive results in the continuous case.',
	 'authors': u'Yanshuai Cao, Marcus A. Brubaker, David J. Fleet, Aaron Hertzmann,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.6007',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nEfficient Optimization for Sparse Gaussian Process Regression',
	 'urllink': u'http://arxiv.org/abs/1310.6007'}
2015-03-24 16:25:09+0000 [xxu46_7] INFO: Crawled 679 pages (at 1 pages/min), scraped 672 items (at 1 items/min)
2015-03-24 16:26:09+0000 [xxu46_7] INFO: Crawled 679 pages (at 0 pages/min), scraped 672 items (at 0 items/min)
2015-03-24 16:26:33+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4978> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 16:26:33+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4978>
	{'abstract': u'Group brainstorming is a well-known idea generation technique, which plays a key role in software development processes. Despite this, the relevant literature has had little to offer in advancing our understanding of the effectiveness of group brainstorming sessions. In this paper we present a research-in-progress on brainstorming while walking, which is a practice built upon the relationship between thinking and walking. The objective is to better understand how to conduct group brainstorming effectively. We compared two brainstorming sessions, one performed during a mountain walk, the other traditionally in a room. Three preliminary findings are obtained: walking can lead to an effective idea generation session; brainstorming while walking can encourage team members to participate in and contribute to the session in an equal manner; and it can help a team to maintain sustainable mental energy. Our study opens up an avenue for future exploration of effective group brainstorming practices.',
	 'authors': u'Xiaofeng Wang, Daniel Graziotin, Juha Rikkil\xe4, Pekka Abrahamsson,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4978',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nTraverse the landscape of the mind by walking: an exploration of a new  brainstorming practice',
	 'urllink': u'http://arxiv.org/abs/1308.4978'}
2015-03-24 16:27:09+0000 [xxu46_7] INFO: Crawled 680 pages (at 1 pages/min), scraped 673 items (at 1 items/min)
2015-03-24 16:28:02+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6816> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 16:28:02+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6816>
	{'abstract': u'Reasoning about degrees of belief in uncertain dynamic worlds is fundamental to many applications, such as robotics and planning, where actions modify state properties and sensors provide measurements, both of which are prone to noise. With the exception of limited cases such as Gaussian processes over linear phenomena, belief state evolution can be complex and hard to reason with in a general way. This paper proposes a framework with new results that allows the reduction of subjective probabilities after sensing and acting to questions about the initial state only. We build on an expressive probabilistic first-order logical account by Bacchus, Halpern and Levesque, resulting in a methodology that, in principle, can be coupled with a variety of existing inference solutions.',
	 'authors': u'Vaishak Belle, Hector Levesque,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6816',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nReasoning about Probabilities in Dynamic Systems using Goal Regression',
	 'urllink': u'http://arxiv.org/abs/1309.6816'}
2015-03-24 16:28:09+0000 [xxu46_7] INFO: Crawled 681 pages (at 1 pages/min), scraped 674 items (at 1 items/min)
2015-03-24 16:29:09+0000 [xxu46_7] INFO: Crawled 681 pages (at 0 pages/min), scraped 674 items (at 0 items/min)
2015-03-24 16:29:34+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5999> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 16:29:34+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5999>
	{'abstract': u'Diabetic Retinopathy is a medical condition where the retina is damaged because fluid leaks from blood vessels into the retina. The presence of hemorrhages in the retina is the earliest symptom of diabetic retinopathy. The number and shape of hemorrhages is used to indicate the severity of the disease. Early automated hemorrhage detection can help reduce the incidence of blindness. This paper introduced new method depending on the hemorrhage shape to detect the dot hemorrhage (DH), its number, and size at early stage, this can be achieved by reducing the retinal image details. Detection and recognize the DH by following three sequential steps, removing the fovea, removing the vasculature and recognize DH by determining the circularity for all the objects in the image, finally determine the shape factor which is related to DH recognition, this stage strengthens the recognition process. The proposed method recognizes and separates all the DH.',
	 'authors': u'Nidhal Khdhair El Abbadi, Enas Hamood Al Saadi,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5999',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nImprovement of Automatic Hemorrhages Detection Methods Using Shapes  Recognition',
	 'urllink': u'http://arxiv.org/abs/1310.5999'}
2015-03-24 16:30:09+0000 [xxu46_7] INFO: Crawled 682 pages (at 1 pages/min), scraped 675 items (at 1 items/min)
2015-03-24 16:30:48+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4965> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 16:30:48+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4965>
	{'abstract': u'In this paper, we investigate the possibility to use two tilings of the hyperbolic plane as basic frame for devising a way to input texts in Chinese characters into messages of cellphones, smartphones, ipads and tablets.',
	 'authors': u'Maurice Margenstern, Lan Wu,',
	 'category': u'Computer Science ',
	 'date': '2013-8-21',
	 'pdflink': u'http://arxiv.org/pdf/1308.4965',
	 'subjects': u'Human-Computer Interaction (cs.HC)',
	 'title': u'\nA proposal for a Chinese keyboard for cellphones, smartphones, ipads and  tablets',
	 'urllink': u'http://arxiv.org/abs/1308.4965'}
2015-03-24 16:31:09+0000 [xxu46_7] INFO: Crawled 683 pages (at 1 pages/min), scraped 676 items (at 1 items/min)
2015-03-24 16:32:09+0000 [xxu46_7] INFO: Crawled 683 pages (at 0 pages/min), scraped 676 items (at 0 items/min)
2015-03-24 16:32:49+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6815> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 16:32:49+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6815>
	{'abstract': u"The best current methods for exactly computing the number of satisfying assignments, or the satisfying probability, of Boolean formulas can be seen, either directly or indirectly, as building 'decision-DNNF' (decision decomposable negation normal form) representations of the input Boolean formulas. Decision-DNNFs are a special case of 'd-DNNF's where 'd' stands for 'deterministic'. We show that any decision-DNNF can be converted into an equivalent 'FBDD' (free binary decision diagram) -- also known as a 'read-once branching program' (ROBP or 1-BP) -- with only a quasipolynomial increase in representation size in general, and with only a polynomial increase in size in the special case of monotone k-DNF formulas. Leveraging known exponential lower bounds for FBDDs, we then obtain similar exponential lower bounds for decision-DNNFs which provide lower bounds for the recent algorithms. We also separate the power of decision-DNNFs from d-DNNFs and a generalization of decision-DNNFs known as AND-FBDDs. Finally we show how these imply exponential lower bounds for natural problems associated with probabilistic databases.",
	 'authors': u'Paul Beame, Jerry Li, Sudeepa Roy, Dan Suciu,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6815',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nLower Bounds for Exact Model Counting and Applications in Probabilistic  Databases',
	 'urllink': u'http://arxiv.org/abs/1309.6815'}
2015-03-24 16:33:09+0000 [xxu46_7] INFO: Crawled 684 pages (at 1 pages/min), scraped 677 items (at 1 items/min)
2015-03-24 16:34:09+0000 [xxu46_7] INFO: Crawled 684 pages (at 0 pages/min), scraped 677 items (at 0 items/min)
2015-03-24 16:34:45+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5988> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 16:34:45+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5988>
	{'abstract': u'Many of quality approaches are described in hundreds of textual pages. Manual processing of information consumes plenty of resources. In this report we present a text mining approach applied on CMMI, one well known and widely known quality approach. The text mining analysis can provide a quick overview on the scope of a quality approaches. The result of the analysis could accelerate the understanding and the selection of quality approaches.',
	 'authors': u'Z\xe1dor D\xe1niel Kelemen, Rob Kusters, Jos Trienekens, Katalin Balla,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/e-print/1310.5988',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nTowards Applying Text Mining Techniques on Software Quality Standards  and Models',
	 'urllink': u'http://arxiv.org/abs/1310.5988'}
2015-03-24 16:35:09+0000 [xxu46_7] INFO: Crawled 685 pages (at 1 pages/min), scraped 678 items (at 1 items/min)
2015-03-24 16:36:09+0000 [xxu46_7] INFO: Crawled 685 pages (at 0 pages/min), scraped 678 items (at 0 items/min)
2015-03-24 16:36:43+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4943> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 16:36:43+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4943>
	{'abstract': u"In the middle of the 1980s, David Poole introduced a semantical, model-theoretic notion of specificity to the artificial-intelligence community. Since then it has found further applications in non-monotonic reasoning, in particular in defeasible reasoning. Poole tried to approximate the intuitive human concept of specificity, which seems to be essential for reasoning in everyday life with its partial and inconsistent information. His notion, however, turns out to be intricate and problematic, which --- as we show --- can be overcome to some extent by a closer approximation of the intuitive human concept of specificity. Besides the intuitive advantages of our novel specificity ordering over Poole's specificity relation in the classical examples of the literature, we also report some hard mathematical facts: Contrary to what was claimed before, we show that Poole's relation is not transitive. The present means to decide our novel specificity relation, however, show only a slight improvement over the known ones for Poole's relation, and further work is needed in this aspect.",
	 'authors': u'Claus-Peter Wirth, Frieder Stolzenburg,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4943',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u"\nDavid Poole's Specificity Revised",
	 'urllink': u'http://arxiv.org/abs/1308.4943'}
2015-03-24 16:37:09+0000 [xxu46_7] INFO: Crawled 686 pages (at 1 pages/min), scraped 679 items (at 1 items/min)
2015-03-24 16:37:48+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6814> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 16:37:48+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6814>
	{'abstract': u'Joint sparsity regularization in multi-task learning has attracted much attention in recent years. The traditional convex formulation employs the group Lasso relaxation to achieve joint sparsity across tasks. Although this approach leads to a simple convex formulation, it suffers from several issues due to the looseness of the relaxation. To remedy this problem, we view jointly sparse multi-task learning as a specialized random effects model, and derive a convex relaxation approach that involves two steps. The first step learns the covariance matrix of the coefficients using a convex formulation which we refer to as sparse covariance coding; the second step solves a ridge regression problem with a sparse quadratic regularizer based on the covariance matrix obtained in the first step. It is shown that this approach produces an asymptotically optimal quadratic regularizer in the multitask learning setting when the number of tasks approaches infinity. Experimental results demonstrate that the convex formulation obtained via the proposed model significantly outperforms group Lasso (and related multi-stage formulations',
	 'authors': u'Krishnakumar Balasubramanian, Kai Yu, Tong Zhang,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6814',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nHigh-dimensional Joint Sparsity Random Effects Model for Multi-task  Learning',
	 'urllink': u'http://arxiv.org/abs/1309.6814'}
2015-03-24 16:38:09+0000 [xxu46_7] INFO: Crawled 687 pages (at 1 pages/min), scraped 680 items (at 1 items/min)
2015-03-24 16:38:53+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5985> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 16:38:53+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5985>
	{'abstract': u'Real life networks are generally modelled as scale free networks. Information diffusion in such networks in decentralised environment is a difficult and resource consuming affair. Gossip algorithms have come up as a good solution to this problem. In this paper, we have proposed Adaptive First Push Then Pull gossip algorithm. We show that algorithm works with minimum cost when the transition round to switch from Adaptive Push to Adaptive Pull is close to Round(log(N)). Furthermore, we compare our algorithm with Push, Pull and First Push Then Pull and show that the proposed algorithm is the most cost efficient in Scale Free networks.',
	 'authors': u'Ruchir Gupta, Abhijeet C. Maali, Yatindra Nath Singh,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5985',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nAdaptive Push-Then-Pull Gossip Algorithm for Scale-free Networks',
	 'urllink': u'http://arxiv.org/abs/1310.5985'}
2015-03-24 16:39:09+0000 [xxu46_7] INFO: Crawled 688 pages (at 1 pages/min), scraped 681 items (at 1 items/min)
2015-03-24 16:40:09+0000 [xxu46_7] INFO: Crawled 688 pages (at 0 pages/min), scraped 681 items (at 0 items/min)
2015-03-24 16:40:35+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4942> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 16:40:35+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4942>
	{'abstract': u'Multiscale transforms designed to process analog and discrete-time signals and images cannot be directly applied to analyze high-dimensional data residing on the vertices of a weighted graph, as they do not capture the intrinsic geometric structure of the underlying graph data domain. In this paper, we adapt the Laplacian pyramid transform for signals on Euclidean domains so that it can be used to analyze high-dimensional data residing on the vertices of a weighted graph. Our approach is to study existing methods and develop new methods for the four fundamental operations of graph downsampling, graph reduction, and filtering and interpolation of signals on graphs. Equipped with appropriate notions of these operations, we leverage the basic multiscale constructs and intuitions from classical signal processing to generate a transform that yields both a multiresolution of graphs and an associated multiresolution of a graph signal on the underlying sequence of graphs.',
	 'authors': u'David I Shuman, Mohammad Javad Faraji, Pierre Vandergheynst,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4942',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nA Multiscale Pyramid Transform for Graph Signals',
	 'urllink': u'http://arxiv.org/abs/1308.4942'}
2015-03-24 16:41:09+0000 [xxu46_7] INFO: Crawled 689 pages (at 1 pages/min), scraped 682 items (at 1 items/min)
2015-03-24 16:42:09+0000 [xxu46_7] INFO: Crawled 689 pages (at 0 pages/min), scraped 682 items (at 0 items/min)
2015-03-24 16:42:28+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6813> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 16:42:28+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6813>
	{'abstract': u'Graphical models for structured domains are powerful tools, but the computational complexities of combinatorial prediction spaces can force restrictions on models, or require approximate inference in order to be tractable. Instead of working in a combinatorial space, we use hinge-loss Markov random fields (HL-MRFs), an expressive class of graphical models with log-concave density functions over continuous variables, which can represent confidences in discrete predictions. This paper demonstrates that HL-MRFs are general tools for fast and accurate structured prediction. We introduce the first inference algorithm that is both scalable and applicable to the full class of HL-MRFs, and show how to train HL-MRFs with several learning algorithms. Our experiments show that HL-MRFs match or surpass the predictive performance of state-of-the-art methods, including discrete models, in four application domains.',
	 'authors': u'Stephen Bach, Bert Huang, Ben London, Lise Getoor,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6813',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nHinge-loss Markov Random Fields: Convex Inference for Structured  Prediction',
	 'urllink': u'http://arxiv.org/abs/1309.6813'}
2015-03-24 16:43:09+0000 [xxu46_7] INFO: Crawled 690 pages (at 1 pages/min), scraped 683 items (at 1 items/min)
2015-03-24 16:44:09+0000 [xxu46_7] INFO: Crawled 690 pages (at 0 pages/min), scraped 683 items (at 0 items/min)
2015-03-24 16:44:11+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5980> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 16:44:11+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5980>
	{'abstract': u"In this paper we apply the Named Data Networking, a newly proposed Internet architecture, to networking vehicles on the run. Our initial design, dubbed V-NDN, illustrates NDN's promising potential in providing a unifying architecture that enables networking among all computing devices independent from whether they are connected through wired infrastructure, ad hoc, or intermittent DTN. This paper describes the prototype implementation of V-NDN and its preliminary performance assessment.",
	 'authors': u'Giulio Grassi, Davide Pesavento, Lucas Wang, Giovanni Pau, Rama Vuyyuru, Ryuji Wakikawa, Lixia Zhang,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5980',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nVehicular Inter-Networking via Named Data',
	 'urllink': u'http://arxiv.org/abs/1310.5980'}
2015-03-24 16:45:09+0000 [xxu46_7] INFO: Crawled 691 pages (at 1 pages/min), scraped 684 items (at 1 items/min)
2015-03-24 16:46:09+0000 [xxu46_7] INFO: Crawled 691 pages (at 0 pages/min), scraped 684 items (at 0 items/min)
2015-03-24 16:46:10+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4941> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 16:46:10+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4941>
	{'abstract': u'Timely analysis of cyber-security information necessitates automated information extraction from unstructured text. While state-of-the-art extraction methods produce extremely accurate results, they require ample training data, which is generally unavailable for specialized applications, such as detecting security related entities; moreover, manual annotation of corpora is very costly and often not a viable solution. In response, we develop a very precise method to automatically label text from several data sources by leveraging related, domain-specific, structured data and provide public access to a corpus annotated with cyber-security entities. Next, we implement a Maximum Entropy Model trained with the average perceptron on a portion of our corpus (750,000 words) and achieve near perfect precision, recall, and accuracy, with training times under 17 seconds.',
	 'authors': u'Robert A. Bridges, Corinne L. Jones, Michael D. Iannacone, Kelly M. Testa, John R. Goodall,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4941',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nAutomatic Labeling for Entity Extraction in Cyber Security',
	 'urllink': u'http://arxiv.org/abs/1308.4941'}
2015-03-24 16:47:09+0000 [xxu46_7] INFO: Crawled 692 pages (at 1 pages/min), scraped 685 items (at 1 items/min)
2015-03-24 16:47:59+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6812> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 16:47:59+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6812>
	{'abstract': u'Graph-based methods provide a powerful tool set for many non-parametric frameworks in Machine Learning. In general, the memory and computational complexity of these methods is quadratic in the number of examples in the data which makes them quickly infeasible for moderate to large scale datasets. A significant effort to find more efficient solutions to the problem has been made in the literature. One of the state-of-the-art methods that has been recently introduced is the Variational Dual-Tree (VDT) framework. Despite some of its unique features, VDT is currently restricted only to Euclidean spaces where the Euclidean distance quantifies the similarity. In this paper, we extend the VDT framework beyond the Euclidean distance to more general Bregman divergences that include the Euclidean distance as a special case. By exploiting the properties of the general Bregman divergence, we show how the new framework can maintain all the pivotal features of the VDT framework and yet significantly improve its performance in non-Euclidean domains. We apply the proposed framework to different text categorization problems and demonstrate its benefits over the original VDT.',
	 'authors': u'Saeed Amizadeh, Bo Thiesson, Milos Hauskrecht,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6812',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nThe Bregman Variational Dual-Tree Framework',
	 'urllink': u'http://arxiv.org/abs/1309.6812'}
2015-03-24 16:48:09+0000 [xxu46_7] INFO: Crawled 693 pages (at 1 pages/min), scraped 686 items (at 1 items/min)
2015-03-24 16:49:09+0000 [xxu46_7] INFO: Crawled 693 pages (at 0 pages/min), scraped 686 items (at 0 items/min)
2015-03-24 16:49:39+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5965> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 16:49:39+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5965>
	{'abstract': u'Hyperspectral imaging, due to providing high spectral resolution images, is one of the most important tools in the remote sensing field. Because of technological restrictions hyperspectral sensors has a limited spatial resolution. On the other hand panchromatic image has a better spatial resolution. Combining this information together can provide a better understanding of the target scene. Spectral unmixing of mixed pixels in hyperspectral images results in spectral signature and abundance fractions of endmembers but gives no information about their location in a mixed pixel. In this paper we have used spectral unmixing results of hyperspectral images and segmentation results of panchromatic image for data fusion. The proposed method has been applied on simulated data using AVRIS Indian Pines datasets. Results show that this method can effectively combine information in hyperspectral and panchromatic images.',
	 'authors': u'Roozbeh Rajabi, Hassan Ghassemian,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5965',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nFusion of Hyperspectral and Panchromatic Images using Spectral Uumixing  Results',
	 'urllink': u'http://arxiv.org/abs/1310.5965'}
2015-03-24 16:50:09+0000 [xxu46_7] INFO: Crawled 694 pages (at 1 pages/min), scraped 687 items (at 1 items/min)
2015-03-24 16:51:08+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4922> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 16:51:08+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4922>
	{'abstract': u'Unsupervised deep learning is one of the most powerful representation learning techniques. Restricted Boltzman machine, sparse coding, regularized auto-encoders, and convolutional neural networks are pioneering building blocks of deep learning. In this paper, we propose a new building block -- distributed random models. The proposed method is a special full implementation of the product of experts: (i) each expert owns multiple hidden units and different experts have different numbers of hidden units; (ii) the model of each expert is a k-center clustering, whose k-centers are only uniformly sampled examples, and whose output (i.e. the hidden units) is a sparse code that only the similarity values from a few nearest neighbors are reserved. The relationship between the pioneering building blocks, several notable research branches and the proposed method is analyzed. Experimental results show that the proposed deep model can learn better representations than deep belief networks and meanwhile can train a much larger network with much less time than deep belief networks.',
	 'authors': u'Xiao-Lei Zhang,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/e-print/1308.4922',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nLearning Deep Representation Without Parameter Inference for Nonlinear  Dimensionality Reduction',
	 'urllink': u'http://arxiv.org/abs/1308.4922'}
2015-03-24 16:51:09+0000 [xxu46_7] INFO: Crawled 695 pages (at 1 pages/min), scraped 688 items (at 1 items/min)
2015-03-24 16:52:09+0000 [xxu46_7] INFO: Crawled 695 pages (at 0 pages/min), scraped 688 items (at 0 items/min)
2015-03-24 16:53:00+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6811> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 16:53:00+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6811>
	{'abstract': u'We present a comprehensive study of the use of generative modeling approaches for Multiple-Instance Learning (MIL) problems. In MIL a learner receives training instances grouped together into bags with labels for the bags only (which might not be correct for the comprised instances). Our work was motivated by the task of facilitating the diagnosis of neuromuscular disorders using sets of motor unit potential trains (MUPTs) detected within a muscle which can be cast as a MIL problem. Our approach leads to a state-of-the-art solution to the problem of muscle classification. By introducing and analyzing generative models for MIL in a general framework and examining a variety of model structures and components, our work also serves as a methodological guide to modelling MIL tasks. We evaluate our proposed methods both on MUPT datasets and on the MUSK1 dataset, one of the most widely used benchmarks for MIL.',
	 'authors': u'Tameem Adel, Benn Smith, Ruth Urner, Daniel Stashuk, Daniel J. Lizotte,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6811',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nGenerative Multiple-Instance Learning Models For Quantitative  Electromyography',
	 'urllink': u'http://arxiv.org/abs/1309.6811'}
2015-03-24 16:53:09+0000 [xxu46_7] INFO: Crawled 696 pages (at 1 pages/min), scraped 689 items (at 1 items/min)
2015-03-24 16:54:09+0000 [xxu46_7] INFO: Crawled 696 pages (at 0 pages/min), scraped 689 items (at 0 items/min)
2015-03-24 16:54:59+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5963> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 16:54:59+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5963>
	{'abstract': u"The Internet has dramatically changed the relationship among people and their relationships with others people and made the valuable information available for the users. Email is the service, which the Internet provides today for its own users; this service has attracted most of the users' attention due to the low cost. Along with the numerous benefits of Email, one of the weaknesses of this service is that the number of received emails is continually being enhanced, thus the ways are needed to automatically filter these disturbing letters. Most of these filters utilize a combination of several techniques such as the Black or white List, using the keywords and so on in order to identify the spam more accurately In this paper, we introduce a new method to classify the spam. We are seeking to increase the accuracy of Email classification by combining the output of several decision trees and the concept of ontology.",
	 'authors': u'Foruzan Kiamarzpour, Rouhollah Dianat, Mohammad bahrani, Mehdi Sadeghzadeh,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5963',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nImproving the methods of email classification based on words ontology',
	 'urllink': u'http://arxiv.org/abs/1310.5963'}
2015-03-24 16:55:09+0000 [xxu46_7] INFO: Crawled 697 pages (at 1 pages/min), scraped 690 items (at 1 items/min)
2015-03-24 16:56:09+0000 [xxu46_7] INFO: Crawled 697 pages (at 0 pages/min), scraped 690 items (at 0 items/min)
2015-03-24 16:56:14+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4908> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 16:56:14+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4908>
	{'abstract': u'One of the most successful approaches to modern high quality HDR-video capture is to use camera setups with multiple sensors imaging the scene through a common optical system. However, such systems pose several challenges for HDR reconstruction algorithms. Previous reconstruction techniques have considered debayering, denoising, resampling (align- ment) and exposure fusion as separate problems. In contrast, in this paper we present a unifying approach, performing HDR assembly directly from raw sensor data. Our framework includes a camera noise model adapted to HDR video and an algorithm for spatially adaptive HDR reconstruction based on fitting of local polynomial approximations to observed sensor data. The method is easy to implement and allows reconstruction to an arbitrary resolution and output mapping. We present an implementation in CUDA and show real-time performance for an experimental 4 Mpixel multi-sensor HDR video system. We further show that our algorithm has clear advantages over existing methods, both in terms of flexibility and reconstruction quality.',
	 'authors': u'Joel Kronander, Stefan Gustavson, Gerhard Bonnet, Anders Ynnerman, Jonas Unger,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4908',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nA Unified Framework for Multi-Sensor HDR Video Reconstruction',
	 'urllink': u'http://arxiv.org/abs/1308.4908'}
2015-03-24 16:57:09+0000 [xxu46_7] INFO: Crawled 698 pages (at 1 pages/min), scraped 691 items (at 1 items/min)
2015-03-24 16:57:45+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6806> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 16:57:45+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6806>
	{'abstract': u'A subspace projection to improve channel estimation in massive multi-antenna systems is proposed and analyzed. Together with power-controlled hand-off, it can mitigate the pilot contamination problem without the need for coordination among cells. The proposed method is blind in the sense that it does not require pilot data to find the appropriate subspace. It is based on the theory of large random matrices that predicts that the eigenvalue spectra of large sample covariance matrices can asymptotically decompose into disjoint bulks as the matrix size grows large. Random matrix and free probability theory are utilized to predict under which system parameters such a bulk decomposition takes place. Simulation results are provided to confirm that the proposed method outperforms conventional linear channel estimation if bulk separation occurs.',
	 'authors': u'Ralf M\xfcller, Laura Cottatellucci, Mikko Vehkaper\xe4,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6806',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nBlind pilot decontamination',
	 'urllink': u'http://arxiv.org/abs/1309.6806'}
2015-03-24 16:58:09+0000 [xxu46_7] INFO: Crawled 699 pages (at 1 pages/min), scraped 692 items (at 1 items/min)
2015-03-24 16:59:09+0000 [xxu46_7] INFO: Crawled 699 pages (at 0 pages/min), scraped 692 items (at 0 items/min)
2015-03-24 16:59:32+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5962> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 16:59:32+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5962>
	{'abstract': u'Institutional collaborative systems focus on providing the fast, and secure connections to students, teaching and non-teaching staff members. Access control is more important in these types of systems because different kind of users access the system on different levels. So a proper architecture must be there for these kinds of systems, for providing an efficient and secure system. As lot of work was done in RBAC like for grouping, securing the system, ease of use, and for enterprise etc but no one apply all these concepts as a whole on institution level. So, this paper will be a step towards administrative load sharing, securing the system, and ease of use.',
	 'authors': u'Muhammad Umar Aftab, Amna Nisar, Dr. Asif, Adeel Ashraf, Burhan Gill,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5962',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nRBAC Architecture Design Issues in Institutions Collaborative  Environment',
	 'urllink': u'http://arxiv.org/abs/1310.5962'}
2015-03-24 17:00:09+0000 [xxu46_7] INFO: Crawled 700 pages (at 1 pages/min), scraped 693 items (at 1 items/min)
2015-03-24 17:01:09+0000 [xxu46_7] INFO: Crawled 700 pages (at 0 pages/min), scraped 693 items (at 0 items/min)
2015-03-24 17:01:21+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4904> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 17:01:21+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4904>
	{'abstract': u'The interest on autonomous systems is increasing both in industry and academia. Such systems must operate with limited human intervention in a changing environment and must be able to compensate for significant system failures without external intervention. The most appropriate models of autonomous systems can be found in the class of hybrid systems (which study continuous-state dynamic processes via discrete-state controllers) that interact with their environment. This workshop brings together researchers interested in all aspects of autonomy and resilience of hybrid systems.',
	 'authors': u'Luca Bortolussi, Manuela L. Bujorianu, Giordano Pola,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/html/1308.4904',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nProceedings Third International Workshop on Hybrid Autonomous Systems',
	 'urllink': u'http://arxiv.org/abs/1308.4904'}
2015-03-24 17:02:09+0000 [xxu46_7] INFO: Crawled 701 pages (at 1 pages/min), scraped 694 items (at 1 items/min)
2015-03-24 17:03:09+0000 [xxu46_7] INFO: Crawled 701 pages (at 0 pages/min), scraped 694 items (at 0 items/min)
2015-03-24 17:03:20+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6797> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 17:03:20+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6797>
	{'abstract': u'A multicast game is a network design game modelling how selfish non-cooperative agents build and maintain one-to-many network communication. There is a special source node and a collection of agents located at corresponding terminals. Each agent is interested in selecting a route from the special source to its terminal minimizing the cost. The mutual influence of the agents is determined by a cost sharing mechanism, which evenly splits the cost of an edge among all the agents using it for routing. In this paper we provide several algorithmic and complexity results on finding a Nash equilibrium minimizing the value of Rosenthal potential. Let n be the number of agents and G be the communication network. We show that - For a given strategy profile s and integer k&gt;=1, there is a local search algorithm which in time n^|G|^ finds a better strategy profile, if there is any, in a k-exchange neighbourhood of s. In other words, the algorithm decides if Rosenthal potential can be decreased by changing strategies of at most k agents; - The running time of our local search algorithm is essentially tight: unless FPT= W[1], for any function f(k), searching of the k-neighbourhood cannot be done in time f(k)|G|^. The key ingredient of our algorithmic result is a subroutine that finds an equilibrium with minimum potential in 3^n|G|^ time. In other words, finding an equilibrium with minimum potential is fixed-parameter tractable when parameterized by the number of agents.',
	 'authors': u'Fedor V. Fomin, Petr A. Golovach, Jesper Nederlof, Micha\u0142 Pilipczuk,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6797',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nMinimizing Rosenthal Potential in Multicast Games',
	 'urllink': u'http://arxiv.org/abs/1309.6797'}
2015-03-24 17:04:09+0000 [xxu46_7] INFO: Crawled 702 pages (at 1 pages/min), scraped 695 items (at 1 items/min)
2015-03-24 17:05:08+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5960> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 17:05:08+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5960>
	{'abstract': u"In this report, we consider how to dynamically select transmission bands and multi-hop routes for device-to-device (D2D) communications in co-existence with a cellular network overlay. Firstly, we consider different wireless routing algorithms, i.e. broadcasting-routing (BR) method, and shortest-path-routing (SPR) method. The results show that depending on the co-existence cellular users' outage constraint, different routing strategies have different merits. BR is acceptable at the low D2D user density but is terrible at high density. We also consider the channel band performance (Uplink band and Downlink band). The results show that the multi-hop D2D can achieve a low outage probability using the uplink band (approximately 5%), and D2D in the downlink band performs a little poorly (approximately 12%) outage with SPR.",
	 'authors': u'Yuan Hu,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5960',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nOptimizing Device-to-Device Communications in Cellular Networks',
	 'urllink': u'http://arxiv.org/abs/1310.5960'}
2015-03-24 17:05:09+0000 [xxu46_7] INFO: Crawled 703 pages (at 1 pages/min), scraped 696 items (at 1 items/min)
2015-03-24 17:06:09+0000 [xxu46_7] INFO: Crawled 703 pages (at 0 pages/min), scraped 696 items (at 0 items/min)
2015-03-24 17:07:02+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4902> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 17:07:02+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4902>
	{'abstract': u'There are a lot of intensive researches on handwritten character recognition (HCR) for almost past four decades. The research has been done on some of popular scripts such as Roman, Arabic, Chinese and Indian. In this paper we present a review on HCR work on the four popular scripts. We have summarized most of the published paper from 2005 to recent and also analyzed the various methods in creating a robust HCR system. We also added some future direction of research on HCR.',
	 'authors': u'Aini Najwa Azmi, Dewi Nasien, Siti Mariyam Shamsuddin,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4902',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nA review on handwritten character and numeral recognition for Roman,  Arabic, Chinese and Indian scripts',
	 'urllink': u'http://arxiv.org/abs/1308.4902'}
2015-03-24 17:07:09+0000 [xxu46_7] INFO: Crawled 704 pages (at 1 pages/min), scraped 697 items (at 1 items/min)
2015-03-24 17:08:09+0000 [xxu46_7] INFO: Crawled 704 pages (at 0 pages/min), scraped 697 items (at 0 items/min)
2015-03-24 17:08:46+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6788> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 17:08:46+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6788>
	{'abstract': u'At present, operators address the explosive growth of mobile data demand by densification of the cellular network so as to reduce the transmitter-receiver distance and to achieve higher spectral efficiency. Due to such network densification and the intense proliferation of wireless devices, modern wireless networks are interference-limited, which motivates the use of interference mitigation and coordination techniques. In this work, we develop a statistical framework to evaluate the performance of multi-tier heterogeneous networks with successive interference cancellation (SIC) capabilities, accounting for the computational complexity of the cancellation scheme and relevant network related parameters such as random location of the access points (APs) and mobile users, and the characteristics of the wireless propagation channel. We explicitly model the consecutive events of canceling interferers and we derive the success probability to cancel the n-th strongest signal and to decode the signal of interest after n cancellations. When users are connected to the AP which provides the maximum average received signal power, the analysis indicates that the performance gains of SIC diminish quickly with n and the benefits are modest for realistic values of the signal-to-interference ratio (SIR). We extend the statistical model to include several association policies where distinct gains of SIC are expected: (i) minimum load association, (ii) maxi- mum instantaneous SIR association, and (iii) range expansion. Numerical results show the effectiveness of SIC for the considered association policies. This work deepens the understanding of SIC by defining the achievable gains for different association policies in multi-tier heterogeneous networks.',
	 'authors': u'Matthias Wildemeersch, Tony Q. S. Quek, Marios Kountouris, Alberto Rabbachin, Cornelis H. Slump,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6788',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nSuccessive Interference Cancellation in Heterogeneous Cellular Networks',
	 'urllink': u'http://arxiv.org/abs/1309.6788'}
2015-03-24 17:09:09+0000 [xxu46_7] INFO: Crawled 705 pages (at 1 pages/min), scraped 698 items (at 1 items/min)
2015-03-24 17:10:09+0000 [xxu46_7] INFO: Crawled 705 pages (at 0 pages/min), scraped 698 items (at 0 items/min)
2015-03-24 17:10:35+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5957> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 17:10:35+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5957>
	{'abstract': u'The entropy region is constructed from vectors of random variables by collecting Shannon entropies of all subvectors. Its shape is studied here by means of polymatroidal constructions, notably by convolution. The closure of the region is decomposed into the direct sum of tight and modular parts, reducing the study to the tight part. The relative interior of the reduction belongs to the entropy region. Behavior of the decomposition under selfadhesivity is clarified. Results are specialized to and completed for the region of four random variables. This and computer experiments help to visualize approximations of a symmetrized part of the entropy region. Four-atom conjecture on the minimization of Ingleton score is refuted.',
	 'authors': u'Franti\u0161ek Mat\xfa\u0161, L\xe1szlo Csirmaz,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5957',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nEntropy region and convolution',
	 'urllink': u'http://arxiv.org/abs/1310.5957'}
2015-03-24 17:11:09+0000 [xxu46_7] INFO: Crawled 706 pages (at 1 pages/min), scraped 699 items (at 1 items/min)
2015-03-24 17:12:09+0000 [xxu46_7] INFO: Crawled 706 pages (at 0 pages/min), scraped 699 items (at 0 items/min)
2015-03-24 17:12:34+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4895> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 17:12:34+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4895>
	{'abstract': u'Peer to peer network architecture introduces many desired features including self-scalability that led to achieving higher efficiency rate than the traditional server-client architecture. This was contributed to the highly distributed architecture of peer to peer network. Meanwhile, the lack of a centralized control unit in peer to peer network introduces some challenge. One of these challenges is key distribution and management in such an architecture. This research will explore the possibility of developing a novel scheme for distributing and managing keys in peer to peer network architecture efficiently.',
	 'authors': u'Abdulrahman Aldhaheri, Hammoud Alshammari, Majid Alshammari,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4895',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nOptimizing Key Distribution in Peer to Peer Network Using B-Trees',
	 'urllink': u'http://arxiv.org/abs/1308.4895'}
2015-03-24 17:13:09+0000 [xxu46_7] INFO: Crawled 707 pages (at 1 pages/min), scraped 700 items (at 1 items/min)
2015-03-24 17:14:09+0000 [xxu46_7] INFO: Crawled 707 pages (at 0 pages/min), scraped 700 items (at 0 items/min)
2015-03-24 17:14:32+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6772> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 17:14:32+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6772>
	{'abstract': u'A -uniform hypergraph is called -orientable, if there is an assignment of each edge to one of its vertices such that no vertex is assigned more than edges. Let be a hypergraph, drawn uniformly at random from the set of all -uniform hypergraphs with vertices and edges. In this paper we establish the threshold for the -orientability of for all and , i.e., we determine a critical quantity such that with probability the graph has an -orientation if , but fails doing so if . Our result has various applications including sharp load thresholds for cuckoo hashing, load balancing with guaranteed maximum load, and massive parallel access to hard disk arrays.',
	 'authors': u'Nikolaos Fountoulakis, Megha Khosla, Konstantinos Panagiotou,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6772',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nThe Multiple-orientability Thresholds for Random Hypergraphs',
	 'urllink': u'http://arxiv.org/abs/1309.6772'}
2015-03-24 17:15:09+0000 [xxu46_7] INFO: Crawled 708 pages (at 1 pages/min), scraped 701 items (at 1 items/min)
2015-03-24 17:15:59+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5949> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 17:15:59+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5949>
	{'abstract': u'Mobile social networks (MSNs) are specific types of social media which consolidate the ability of omnipresent connection for mobile users/devices to share user-centric data objects among interested users. Taking advantage of the characteristics of both social networks and opportunistic networks, MSNs are capable of providing an efficient and effective mobile environment for users to access, share, and distribute data. However, lack of a protective infrastructure in these networks has turned them in to convenient targets for various perils. This is the main impulse why MSNs carry disparate and intricate safety concerns and embrace divergent safety challenging problems. In this paper, we aim to provide a clear categorization on safety challenges and a deep exploration over some recent solutions in MSNs. This work narrows the safety challenges and solution techniques down from opportunistic networks (OppNets) and delay tolerant networks (DTNs) to MSNs with the hope of covering all the work proposed around security, privacy and trust in MSNs. To conclude, several major open research issues are discussed and future research directions are outlined.',
	 'authors': u'Yashar Najaflou, Behrouz Jedari, Feng Xia, Laurence T. Yang, Mohammad S. Obaidat,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5949',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nSafety Challenges and Solutions in Mobile Social Networks',
	 'urllink': u'http://arxiv.org/abs/1310.5949'}
2015-03-24 17:16:09+0000 [xxu46_7] INFO: Crawled 709 pages (at 1 pages/min), scraped 702 items (at 1 items/min)
2015-03-24 17:17:09+0000 [xxu46_7] INFO: Crawled 709 pages (at 0 pages/min), scraped 702 items (at 0 items/min)
2015-03-24 17:17:12+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4894> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 17:17:12+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4894>
	{'abstract': u'The purpose of this research is to develop a model that would close the gap between marketing plans and strategies from one side and the advanced online collaboration applications platforms known as WEB 2.0 in order to implement marketing 2.0 smoothly without disrupting the working environment. We started by examining published articles related to marketing, Web 2.0, Customer Relationship Management Systems, CRM, and social media in a step to conduct an extensive review of the available literature. Then, we presented critique of the articles we have examined. After that, we have been able to develop the model we are proposing in this research. As this paper shows, the proposed model will help in transforming marketing plans and strategies from its traditional approach into, what we would like to call, marketing 2.0 approach smoothly. There are some unavoidable limitations due to the given time and scope constrains. The factors included in the proposed model does not cover every related aspect, however, they cover the most important ones.',
	 'authors': u'Abdulrahman Aldhaheri, Christian Bach,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4894',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nHow to implement Marketing 2.0 Successfully',
	 'urllink': u'http://arxiv.org/abs/1308.4894'}
2015-03-24 17:18:09+0000 [xxu46_7] INFO: Crawled 710 pages (at 1 pages/min), scraped 703 items (at 1 items/min)
2015-03-24 17:18:18+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6732> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 17:18:18+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6732>
	{'abstract': u'This paper studies the outage capacity of a network consisting of a multitude of heterogenous mobile users, and operating according to the classical opportunistic beamforming framework. The base station is located at the center of the cell, which is modeled as a disk of finite radius. The random user locations are modeled using a homogenous spatial Poisson point process. The received signals are impaired by both fading and location dependent path loss. For this system, we first derive an expression for the beam outage probability. This expression holds for all path loss models that satisfy some mild conditions. Then, we focus on two specific path loss models (i.e., an unbounded model and a more realistic bounded one) to illustrate the applications of our results. In the large system limit where the cell radius tends to infinity, the beam outage capacity and its scaling behavior are derived for the selected specific path loss models. It is shown that the beam outage capacity scales logarithmically for the unbounded model. On the other hand, this scaling behavior becomes double logarithmic for the bounded model. Intuitive explanations are provided as to why we observe different scaling behavior for different path loss models. Numerical evaluations are performed to give further insights, and to illustrate the applicability of the outage capacity results even to a cell having a small finite radius.',
	 'authors': u'Tharaka Samarasinghe, Hazer Inaltekin, Jamie Evans,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6732',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOutage Capacity of Opportunistic Beamforming with Random User Locations',
	 'urllink': u'http://arxiv.org/abs/1309.6732'}
2015-03-24 17:19:09+0000 [xxu46_7] INFO: Crawled 711 pages (at 1 pages/min), scraped 704 items (at 1 items/min)
2015-03-24 17:20:09+0000 [xxu46_7] INFO: Crawled 711 pages (at 0 pages/min), scraped 704 items (at 0 items/min)
2015-03-24 17:20:18+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5930> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 17:20:18+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5930>
	{'abstract': u'This paper considers the impact of external noise sources, including interfering transmitters, on a diffusive molecular communication system, where the impact is measured as the number of noise molecules expected to be observed at a passive receiver. A unifying model for noise, multiuser interference, and intersymbol interference is presented, where, under certain circumstances, interference can be approximated as a noise source that is emitting continuously. The model includes the presence of advection and molecule degradation. The time-varying and asymptotic impact is derived for a series of special cases, some of which facilitate closed-form solutions. Simulation results show the accuracy of the expressions derived for the impact of a continuously-emitting noise source, and show how approximating intersymbol interference as a noise source can simplify the calculation of the expected bit error probability of a weighted sum detector.',
	 'authors': u'Adam Noel, Karen C. Cheung, Robert Schober,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5930',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nA Unifying Model for External Noise Sources and ISI in Diffusive  Molecular Communication',
	 'urllink': u'http://arxiv.org/abs/1310.5930'}
2015-03-24 17:21:09+0000 [xxu46_7] INFO: Crawled 712 pages (at 1 pages/min), scraped 705 items (at 1 items/min)
2015-03-24 17:21:54+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4862> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 17:21:54+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4862>
	{'abstract': u'Bangladesh is an over populated developing country where crisis of food is a major issue, it faces different infrastructure problem in every sector. For Poverty Alleviation from the country we have to confirm cultivable land to increase the crop production for feeding the over population of the country. This paper focuses on the measurement of cultivable land for cultivation. The main purpose of this paper is to briefly describe how the GIS, Digital Mapping, Internet concepts and tools can effectively contribute in the modeling, analysis and visualization phases within an engineering or research project according to the crops by using object detection, object tracking and field mapping in Bangladesh. Through GIS mapping of the agricultural lands, the statistics can be made of how much land is cultivable and each year how much land we are losing. Mapping the cultivation land will tell us how much crop we have to import from other countries. Enabling real-time GIS analysis anytime, anywhere, the implementation of the GIS information to a wider aspect. Automation is the indicator of the modern civilizations. The system will benefit the food stock of the country according to the harvest. For this research we developed a new interactive system. The system will integrate with GIS project data in Google Earth, first finds highly accurate cluster images and partial images, obtains user feedback to merge or correct these digests, and then the supplementary visual analysis complete the partitioning of the data. This study was conducted at the software laboratory, Computer Science and Engineering department, Jahangirnagar University, Dhaka, Bangladesh in 2013.',
	 'authors': u'Yeasir Fathah Rumi, Uzzal Kumar Prodhan, Mohammed Ibrahim Hussain, A.H.M. Shahariar Parvez, Md. Ali Hossain,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4862',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nStrategy For Assessment Of Land And Complex Fields Type Analysis Through  GIS In Bangladesh',
	 'urllink': u'http://arxiv.org/abs/1308.4862'}
2015-03-24 17:22:09+0000 [xxu46_7] INFO: Crawled 713 pages (at 1 pages/min), scraped 706 items (at 1 items/min)
2015-03-24 17:23:09+0000 [xxu46_7] INFO: Crawled 713 pages (at 0 pages/min), scraped 706 items (at 0 items/min)
2015-03-24 17:23:32+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6730> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 17:23:32+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6730>
	{'abstract': u'This paper is about mu-limit sets of cellular automata, i.e. sets of configurations made of words which have a positive probability to appear arbitrarily late in the evolution, starting from an initial mu-random confi guration. More precisely, we investigate the computational complexity of these sets and of decision problems concerning them. Our main results are: first, that such a set can have a Signma_3-hard language, second that it can contain only alpha-complex confi gurations and third that any non-trivial property concerning these sets is at least Pi_3-hard. We also prove various complexity upper bounds, study some restriction of these questions to particular classes of cellular automata, and study different types of (non-)convergence of the probability of appearance of a word in the evolution.',
	 'authors': u'Laurent Boyer, Martin Delacourt, Victor Poupet, Mathieu Sablik, Guillaume Theyssier,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6730',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\n\u03bc-Limit Sets of Cellular Automata from a Computational Complexity  Perspective',
	 'urllink': u'http://arxiv.org/abs/1309.6730'}
2015-03-24 17:24:09+0000 [xxu46_7] INFO: Crawled 714 pages (at 1 pages/min), scraped 707 items (at 1 items/min)
2015-03-24 17:24:43+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5902> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 17:24:43+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5902>
	{'abstract': u'Until now the discussion on perfect security for steganographic systems has remained confined within the realm of mathematicians and information theory experts whose concise and symbolic representation of their philosophies, postulates, and inference thereafter has made it hard for the na "ive academics to have an insight of the concepts. This paper is an endeavor not only to appraise on the limitations of one of such pioneer comprehensions but also to illustrate a pitfall in another scheme that asserts on having perfect security without the use of public or secret key. Goals set are accomplished through contrasting test results of a steganographic scheme that exploits English words with corresponding acronyms for hiding bits of secret information in chat - a preferred way to exchange messages these days. The misapprehension about perfect security and reign in characteristic of stego key in bit embedding process are unfolded respectively by launching elementary chosen-message and chosen-cover attack, and through proposed enhancement of target scheme.',
	 'authors': u'Khan Farhan Rafat, M. Sher,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5902',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nOn The Limits Of Perfect Security For Steganographic System',
	 'urllink': u'http://arxiv.org/abs/1310.5902'}
2015-03-24 17:25:09+0000 [xxu46_7] INFO: Crawled 715 pages (at 1 pages/min), scraped 708 items (at 1 items/min)
2015-03-24 17:25:29+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4846> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 17:25:29+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4846>
	{'abstract': u'We consider partially observable Markov decision processes (POMDPs) with limit-average payoff, where a reward value in the interval [0,1] is associated to every transition, and the payoff of an infinite path is the long-run average of the rewards. We consider two types of path constraints: (i) quantitative constraint defines the set of paths where the payoff is at least a given threshold in (0, 1]; and (ii) qualitative constraint which is a special case of quantitative constraint with = 1. We consider the computation of the almost-sure winning set, where the controller needs to ensure that the path constraint is satisfied with probability 1. Our main results for qualitative path constraint are as follows: (i) the problem of deciding the existence of a finite-memory controller is EXPTIME-complete; and (ii) the problem of deciding the existence of an infinite-memory controller is undecidable. For quantitative path constraint we show that the problem of deciding the existence of a finite-memory controller is undecidable.',
	 'authors': u'Krishnendu Chatterjee, Martin Chmel\xedk,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4846',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nPOMDPs under Probabilistic Semantics',
	 'urllink': u'http://arxiv.org/abs/1308.4846'}
2015-03-24 17:26:09+0000 [xxu46_7] INFO: Crawled 716 pages (at 1 pages/min), scraped 709 items (at 1 items/min)
2015-03-24 17:27:09+0000 [xxu46_7] INFO: Crawled 716 pages (at 0 pages/min), scraped 709 items (at 0 items/min)
2015-03-24 17:27:29+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6727> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 17:27:29+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6727>
	{'abstract': u'In this paper, we study the information theoretic degrees of freedom (DoF) for symmetric multi-input-multi-output interference broadcast channel (MIMO-IBC) with arbitrary configuration. We find the maximal DoF achieved by linear interference alignment (IA), and prove when linear IA can achieve the information theoretic maximal DoF. Specifically, we find that the information theoretic DoF can be divided into two regions according to the ratio of the number of antennas at each base station (BS) to that at each user. In Region I, the sum DoF of the system linearly increases with the number of cells, which can be achieved by asymptotic IA but not by linear IA, where infinite time/frequency extension is necessary. In Region II, the DoF is a piecewise linear function, depending on the number of antennas at each BS or that at each user alternately, which can be achieved by linear IA without the need of infinite time/frequency extension, and the sum DoF cannot exceed the sum number of antennas at each BS and each user. We propose and prove the information theoretic DoF upper-bound for general MIMO-IBC including the system settings in Regions I and II, by constructing a useful and smart genie chain. We prove the achievability of the upper-bound in Region II by proposing a unified way to design closed-form linear IA. From the proof we reveal when proper systems are feasible or infeasible and explain why. The approach of the proof can be extended to more general asymmetric MIMO-IBC.',
	 'authors': u'Tingting Liu, Chenyang Yang,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6727',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nGenie Chain and Degrees of Freedom of Symmetric MIMO Interference  Broadcast Channels',
	 'urllink': u'http://arxiv.org/abs/1309.6727'}
2015-03-24 17:28:09+0000 [xxu46_7] INFO: Crawled 717 pages (at 1 pages/min), scraped 710 items (at 1 items/min)
2015-03-24 17:28:54+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5896> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 17:28:54+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5896>
	{'abstract': u"The Telecare medicine information system (TMIS) is developed to provide Telecare services to the remote user. A user can access remote medical servers using internet without moving from his place. Although remote user and server exchange their messages/data via public networks. An adversary is considered to be enough powerful that he may have full control over the public network. This makes these Telecare services vulnerable to attacks. To ensure secure communication between the user and server many password based authentication schemes have been proposed. In 2013, Hao et al. presented chaotic maps-based password authentication scheme for TMIS. Recently, Lee identified that Hao et al.'s scheme fails to satisfy key agreement property, such that a malicious server can predetermine the session key. Lee also presented an efficient chaotic map-based password authentication and key agreement scheme using Smart cards for TMIS. In this article, we briefly review Lee's scheme and demonstrates the weakness of Lee's scheme. The study shows that the Lee's scheme inefficiency of password change phase causes denial of service attack and login phase results extra computation and communication overhead.",
	 'authors': u'Dheerendra MIshra,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5896',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u"\nThe Cryptanalysis of Lee's Chaotic Maps-Based Authentication and Key  Agreement Scheme using Smart card for Telecare Medicine Information Systems",
	 'urllink': u'http://arxiv.org/abs/1310.5896'}
2015-03-24 17:29:09+0000 [xxu46_7] INFO: Crawled 718 pages (at 1 pages/min), scraped 711 items (at 1 items/min)
2015-03-24 17:30:09+0000 [xxu46_7] INFO: Crawled 718 pages (at 0 pages/min), scraped 711 items (at 0 items/min)
2015-03-24 17:30:54+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4840> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 17:30:54+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4840>
	{'abstract': u"This work deals with the power allocation problem in a multipoint-to-multipoint network, which is heterogenous in the sense that each transmit and receiver pair can arbitrarily choose whether to selfishly maximize its own rate or energy efficiency. This is achieved by modeling the transmit and receiver pairs as rational players that engage in a non-cooperative game in which the utility function changes according to each player's nature. The underlying game is reformulated as a quasi variational inequality (QVI) problem using convex fractional program theory. The equivalence between the QVI and the non-cooperative game provides us with all the mathematical tools to study the uniqueness of its Nash equilibrium (NE) points and to derive novel algorithms that allow the network to converge to these points in an iterative manner both with and without the need for a centralized processing. A small-cell network is considered as a possible case study of this heterogeneous scenario. Numerical results are used to validate the proposed solutions in different operating conditions.",
	 'authors': u'Ivan Stupia, Luca Sanguinetti, Giacomo Bacci, Luc Vandendorpe,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4840',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nEnergy-Efficient Power Optimization in Heterogeneous Networks: A  Quasi-Variational Inequality Approach',
	 'urllink': u'http://arxiv.org/abs/1308.4840'}
2015-03-24 17:31:09+0000 [xxu46_7] INFO: Crawled 719 pages (at 1 pages/min), scraped 712 items (at 1 items/min)
2015-03-24 17:32:09+0000 [xxu46_7] INFO: Crawled 719 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2015-03-24 17:32:21+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6723> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 17:32:21+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6723>
	{'abstract': u'Grid Computing is a type of parallel and distributed systems that is designed to provide reliable access to data and computational resources in wide area networks. These resources are distributed in different geographical locations, however are organized to provide an integrated service. Effective data management in today`s enterprise environment is an important issue. Also, Performance is one of the challenges of using these environments. For improving the performance of file access and easing the sharing amongst distributed systems, replication techniques are used. Data replication is a common method used in distributed environments, where essential data is stored in multiple locations, so that a user can access the data from a site in his area. In this paper, we present a survey on basic and new replication techniques that have been proposed by other researchers. After that, we have a full comparative study on these replication strategies. Also, at the end of the paper, we summarize the results and points of these replication techniques.',
	 'authors': u'Sheida Dayyani, Mohammad Reza Khayyambashi,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6723',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nA Comparative Study of Replication Techniques in Grid Computing Systems',
	 'urllink': u'http://arxiv.org/abs/1309.6723'}
2015-03-24 17:33:09+0000 [xxu46_7] INFO: Crawled 720 pages (at 1 pages/min), scraped 713 items (at 1 items/min)
2015-03-24 17:34:09+0000 [xxu46_7] INFO: Crawled 720 pages (at 0 pages/min), scraped 713 items (at 0 items/min)
2015-03-24 17:34:19+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5895> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 17:34:19+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5895>
	{'abstract': u'In this note we show that stable recovery of complex-valued signals up to global sign can be achieved from the magnitudes of Fourier measurements when a certain "symmetrization and zero-padding" is performed before measurement ( is possible in certain cases). For real signals, symmetrization itself is linear and therefore our result is in this case a statement on uniform phase retrieval. Since complex conjugation is involved, such measurement procedure is not complex-linear but recovery is still possible from magnitudes of linear measurements on, for example, .',
	 'authors': u'Philipp Walk, Peter Jung,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5895',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nStable Recovery from the Magnitude of Symmetrized Fourier Measurements',
	 'urllink': u'http://arxiv.org/abs/1310.5895'}
2015-03-24 17:35:09+0000 [xxu46_7] INFO: Crawled 721 pages (at 1 pages/min), scraped 714 items (at 1 items/min)
2015-03-24 17:36:05+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4839> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 17:36:05+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4839>
	{'abstract': u'Nowadays, web archives preserve the history of large portions of the web. As medias are shifting from printed to digital editions, accessing these huge information sources is drawing increasingly more attention from national and international institutions, as well as from the research community. These collections are intrinsically big, leading to index files that do not fit into the memory and an increase query response time. Decreasing the index size is a direct way to decrease this query response time. Static index pruning methods reduce the size of indexes by removing a part of the postings. In the context of web archives, it is necessary to remove postings while preserving the temporal diversity of the archive. None of the existing pruning approaches take (temporal) diversification into account. In this paper, we propose a diversification-based static index pruning method. It differs from the existing pruning approaches by integrating diversification within the pruning context. We aim at pruning the index while preserving retrieval effectiveness and diversity by pruning while maximizing a given IR evaluation metric like DCG. We show how to apply this approach in the context of web archives. Finally, we show on two collections that search effectiveness in temporal collections after pruning can be improved using our approach rather than diversity oblivious approaches.',
	 'authors': u'Zeynep Pehlivan, Benjamin Piwowarski, St\xe9phane Gan\xe7arski,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4839',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nDiversification Based Static Index Pruning - Application to Temporal  Collections',
	 'urllink': u'http://arxiv.org/abs/1308.4839'}
2015-03-24 17:36:09+0000 [xxu46_7] INFO: Crawled 722 pages (at 1 pages/min), scraped 715 items (at 1 items/min)
2015-03-24 17:36:51+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6722> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 17:36:51+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6722>
	{'abstract': u'This paper focuses on the automatic extraction of domain-specific sentiment word (DSSW), which is a fundamental subtask of sentiment analysis. Most previous work utilizes manual patterns for this task. However, the performance of those methods highly relies on the labelled patterns or selected seeds. In order to overcome the above problem, this paper presents an automatic framework to detect large-scale domain-specific patterns for DSSW extraction. To this end, sentiment seeds are extracted from massive dataset of user comments. Subsequently, these sentiment seeds are expanded by synonyms using a bootstrapping mechanism. Simultaneously, a synonymy graph is built and the graph propagation algorithm is applied on the built synonymy graph. Afterwards, syntactic and sequential relations between target words and high-ranked sentiment words are extracted automatically to construct large-scale patterns, which are further used to extracte DSSWs. The experimental results in three domains reveal the effectiveness of our method.',
	 'authors': u'Tang Duyu, Qin Bing, Zhou LanJun, Wong KamFai, Zhao Yanyan, Liu Ting,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6722',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nDomain-Specific Sentiment Word Extraction by Seed Expansion and Pattern  Generation',
	 'urllink': u'http://arxiv.org/abs/1309.6722'}
2015-03-24 17:37:09+0000 [xxu46_7] INFO: Crawled 723 pages (at 1 pages/min), scraped 716 items (at 1 items/min)
2015-03-24 17:38:09+0000 [xxu46_7] INFO: Crawled 723 pages (at 0 pages/min), scraped 716 items (at 0 items/min)
2015-03-24 17:38:23+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5892> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 17:38:23+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5892>
	{'abstract': u'University rankings by fields are usually based on the research output of universities. However, research managers and rankings consumers expect to see in such fields a reflection of the structure of their own organizational institution. In this study we address such misinterpretation by developing the research profile of the organizational units of two Spanish universities: University of Granada and Pompeu Fabra University. We use two classification systems, the subject categories offered by Thomson Scientific which are commonly used on bibliometric studies, and the 37 disciplines displayed by the Spanish I-UGR Rankings which are constructed from an aggregation of the former. We also describe in detail problems encountered when working with address data from a top down approach and we show differences between universities structures derived from the interdisciplinary organizational forms of new managerialism at universities. We conclude by highlighting that rankings by fields should clearly state the methodology for the construction of such fields. We indicate that the construction of research profiles may be a good solution for universities for finding out levels of discrepancy between organizational units and subject fields.',
	 'authors': u'Nicolas Robinson-Garcia, Clara Calero-Medina,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5892',
	 'subjects': u'Digital Libraries (cs.DL)',
	 'title': u'\nWhat do university rankings by fields rank? Exploring discrepancies  between the organizational structure of universities and bibliometric  classifications',
	 'urllink': u'http://arxiv.org/abs/1310.5892'}
2015-03-24 17:39:09+0000 [xxu46_7] INFO: Crawled 724 pages (at 1 pages/min), scraped 717 items (at 1 items/min)
2015-03-24 17:40:09+0000 [xxu46_7] INFO: Crawled 724 pages (at 0 pages/min), scraped 717 items (at 0 items/min)
2015-03-24 17:40:16+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4828> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 17:40:16+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4828>
	{'abstract': u'We present a new algorithm for general reinforcement learning where the true environment is known to belong to a finite class of N arbitrary models. The algorithm is shown to be near-optimal for all but O(N log^2 N) time-steps with high probability. Infinite classes are also considered where we show that compactness is a key criterion for determining the existence of uniform sample-complexity bounds. A matching lower bound is given for the finite case.',
	 'authors': u'Tor Lattimore, Marcus Hutter, Peter Sunehag,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4828',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nThe Sample-Complexity of General Reinforcement Learning',
	 'urllink': u'http://arxiv.org/abs/1308.4828'}
2015-03-24 17:41:09+0000 [xxu46_7] INFO: Crawled 725 pages (at 1 pages/min), scraped 718 items (at 1 items/min)
2015-03-24 17:41:49+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6707> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 17:41:49+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6707>
	{'abstract': u'In this paper, we consider decentralized sequential decision making in distributed online recommender systems, where items are recommended to users based on their search query as well as their specific background including history of bought items, gender and age, all of which comprise the context information of the user. In contrast to centralized recommender systems, in which there is a single centralized seller who has access to the complete inventory of items as well as the complete record of sales and user information, in decentralized recommender systems each seller/learner only has access to the inventory of items and user information for its own products and not the products and user information of other sellers, but can get commission if it sells an item of another seller. Therefore the sellers must distributedly find out for an incoming user which items to recommend (from the set of own items or items of another seller), in order to maximize the revenue from own sales and commissions. We formulate this problem as a cooperative contextual bandit problem, analytically bound the performance of the sellers compared to the best recommendation strategy given the complete realization of user arrivals and the inventory of items, as well as the context-dependent purchase probabilities of each item, and verify our results via numerical examples on a distributed data set adapted based on Amazon data. We evaluate the dependence of the performance of a seller on the inventory of items the seller has, the number of connections it has with the other sellers, and the commissions which the seller gets by selling items of other sellers to its users.',
	 'authors': u'Cem Tekin, Simpson Zhang, Mihaela van der Schaar,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6707',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nDistributed Online Learning in Social Recommender Systems',
	 'urllink': u'http://arxiv.org/abs/1309.6707'}
2015-03-24 17:42:09+0000 [xxu46_7] INFO: Crawled 726 pages (at 1 pages/min), scraped 719 items (at 1 items/min)
2015-03-24 17:43:09+0000 [xxu46_7] INFO: Crawled 726 pages (at 0 pages/min), scraped 719 items (at 0 items/min)
2015-03-24 17:43:26+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5884> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 17:43:26+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5884>
	{'abstract': u'Vocabulary learning by children can be characterized by many biases. When encountering a new word, children as well as adults, are biased towards assuming that it means something totally different from the words that they already know. To the best of our knowledge, the 1st mathematical proof of the optimality of this bias is presented here. First, it is shown that this bias is a particular case of the maximization of mutual information between words and meanings. Second, the optimality is proven within a more general information theoretic framework where mutual information maximization competes with other information theoretic principles. The bias is a prediction from modern information theory. The relationship between information theoretic principles and the principles of contrast and mutual exclusivity is also shown.',
	 'authors': u'Ramon Ferrer-i-Cancho,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5884',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nThe optimality of attaching unlinked labels to unlinked meanings',
	 'urllink': u'http://arxiv.org/abs/1310.5884'}
2015-03-24 17:44:09+0000 [xxu46_7] INFO: Crawled 727 pages (at 1 pages/min), scraped 720 items (at 1 items/min)
2015-03-24 17:44:58+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4826> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 17:44:58+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4826>
	{'abstract': u'A comprehensive research framework for a comparative analysis of candidate network architectures and protocols in the clean-slate design of next-generation optical access is proposed. The proposed research framework consists of a comparative analysis framework based on multivariate non-inferiority testing and a notion of equivalent circuit rate taking into account user-perceived performances, and a virtual test bed providing a complete experimental platform for the comparative analysis. The capability of the research framework is demonstrated through numerical results from the study of the elasticity of hybrid TDM/WDM-PON based on tunable transceivers.',
	 'authors': u'Kyeong Soo Kim,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4826',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nA Research Framework for the Clean-Slate Design of Next-Generation  Optical Access',
	 'urllink': u'http://arxiv.org/abs/1308.4826'}
2015-03-24 17:45:09+0000 [xxu46_7] INFO: Crawled 728 pages (at 1 pages/min), scraped 721 items (at 1 items/min)
2015-03-24 17:46:09+0000 [xxu46_7] INFO: Crawled 728 pages (at 0 pages/min), scraped 721 items (at 0 items/min)
2015-03-24 17:46:41+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6701> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 17:46:41+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6701>
	{'abstract': u'In this paper, we propose a generalized version of the Rashmi-Shah-Kumar Minimum-Storage-Regenerating(RSK-MSR) codes based on the product-matrix framework. For any such that and , we can directly construct an MSR code without constructing a larger MSR code and shortening of the larger MSR code. As a result, the size of a finite field over which the proposed code is defined is smaller than or equal to the size of a finite field over which the RSK-MSR code is defined. In addition, the secure codes based on the generalized RSK-MSR codes can be obtained by applying the construction method of secure codes proposed by Shah, Rashmi and Kumar. Furthermore, the message matrix of the generalized RSK-MSR code is derived from that of the RSK-MSR code by using the construction method of the secure code.',
	 'authors': u'Masazumi Kurihara, Hidenori Kuwakado,',
	 'category': u'Computer Science ',
	 'date': '2013-9-26',
	 'pdflink': u'http://arxiv.org/pdf/1309.6701',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nGeneralization of Rashmi-Shah-Kumar Minimum-Storage-Regenerating Codes',
	 'urllink': u'http://arxiv.org/abs/1309.6701'}
2015-03-24 17:47:09+0000 [xxu46_7] INFO: Crawled 729 pages (at 1 pages/min), scraped 722 items (at 1 items/min)
2015-03-24 17:48:09+0000 [xxu46_7] INFO: Crawled 729 pages (at 0 pages/min), scraped 722 items (at 0 items/min)
2015-03-24 17:48:21+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5850> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 17:48:21+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5850>
	{'abstract': u'Remote control systems are a very useful element to control and monitor devices quickly and easily. This paper proposes a new architecture for remote control of Android mobile devices, analyzing the different alternatives and seeking the optimal solution in each case. Although the area of remote control, in case of mobile devices, is little explored, it may provide important advantages for testing software and hardware developments in several real devices. It can also allow an efficient management of various devices of different types for performing different tasks, related for example to security or forensic tasks. The main idea behind the proposed architecture was the design of a system to use it as a platform which provides the services needed to perform remote control of mobile devices. As a result of this research, a proof of concept was implemented. An Android application running a group of server programs on the device, connected to the network or USB interface, depending on availability. This servers can be controlled through a small client written in Java and runnable both on desktop and web systems.',
	 'authors': u'Angel Gonzalez Villan, Josep Jorba,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5850',
	 'subjects': u'Human-Computer Interaction (cs.HC)',
	 'title': u'\nRemote Control of Mobile Devices in Android Platform',
	 'urllink': u'http://arxiv.org/abs/1310.5850'}
2015-03-24 17:49:09+0000 [xxu46_7] INFO: Crawled 730 pages (at 1 pages/min), scraped 723 items (at 1 items/min)
2015-03-24 17:49:10+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4820> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 17:49:10+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4820>
	{'abstract': u'Information and communication technologies brought-in tools and techniques in the field of education that introduced new concepts of teaching and learning. Learning management system is one of the key tools used in educational institutes to facilitate e-learning. There is remarkable digital divide among urban and rural areas. In this paper, we present a model for providing e-learning services to remote/rural areas in order to promote and facilitate modern education. A dedicated resource center, hosting the learning management system, facilitates e-learning centers through Internet. The overall goal of this model is to have a cost-effective learning environment equipped with latest technologies to provide learners an opportunity to get insight into new information and communication technologies and e-learning environment. The model offers new teaching methodology with enhance utilization of learning management system in teaching and learning. Basic characteristics and technical aspects will be considered as well. The study will also promote development and usage of open-source technologies.',
	 'authors': u'Shariq Hussain, Zhaoshun Wang, Sabit Rahim,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4820',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nE-learning Services for Rural Communities',
	 'urllink': u'http://arxiv.org/abs/1308.4820'}
2015-03-24 17:50:09+0000 [xxu46_7] INFO: Crawled 731 pages (at 1 pages/min), scraped 724 items (at 1 items/min)
2015-03-24 17:50:53+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6691> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 17:50:53+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6691>
	{'abstract': u"Text in an image provides vital information for interpreting its contents, and text in a scene can aide with a variety of tasks from navigation, to obstacle avoidance, and odometry. Despite its value, however, identifying general text in images remains a challenging research problem. Motivated by the need to consider the widely varying forms of natural text, we propose a bottom-up approach to the problem which reflects the `characterness' of an image region. In this sense our approach mirrors the move from saliency detection methods to measures of `objectness'. In order to measure the characterness we develop three novel cues that are tailored for character detection, and a Bayesian method for their integration. Because text is made up of sets of characters, we then design a Markov random field (MRF) model so as to exploit the inherent dependencies between characters. We experimentally demonstrate the effectiveness of our characterness cues as well as the advantage of Bayesian multi-cue integration. The proposed text detector outperforms state-of-the-art methods on a few benchmark scene text detection datasets. We also show that our measurement of `characterness' is superior than state-of-the-art saliency detection models when applied to the same task.",
	 'authors': u'Yao Li, Wenjing Jia, Chunhua Shen, Anton van den Hengel,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6691',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nCharacterness: An Indicator of Text in the Wild',
	 'urllink': u'http://arxiv.org/abs/1309.6691'}
2015-03-24 17:51:09+0000 [xxu46_7] INFO: Crawled 732 pages (at 1 pages/min), scraped 725 items (at 1 items/min)
2015-03-24 17:52:09+0000 [xxu46_7] INFO: Crawled 732 pages (at 0 pages/min), scraped 725 items (at 0 items/min)
2015-03-24 17:52:13+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5848> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 17:52:13+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5848>
	{'abstract': u"A Mobile Ad-hoc Network (MANET) is a self-motivated wireless network which has no centralized point. It is an independent network that is connected by wireless link so, in which every point or device work as a router. In this network every node forward the packets to the destination as a router and it's not operating as an ending point. In this network every node adjusts them self by on his way in any direction because they are independent and change their position regularly. There are exist three main types of routing protocols which are reactive, proactive and final is hybrid protocols. This whole work compares the performance of some reactive protocols which also known as on - demand protocols, which are DSR, AODV and the final is AOMDV. DSR and AODV are reactive protocols which connected the devices on the network when needed by a doorway. The AOMDV protocol was designed for ad hoc networks whenever any route or link fail and also maintain routes with sequence numbers to avoid looping.",
	 'authors': u'Naveed Anjum Imran Shafi, Sohail Abidi,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5848',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nEvaluation and Performance of Reactive Protocols Using Mobility Model',
	 'urllink': u'http://arxiv.org/abs/1310.5848'}
2015-03-24 17:53:09+0000 [xxu46_7] INFO: Crawled 733 pages (at 1 pages/min), scraped 726 items (at 1 items/min)
2015-03-24 17:53:48+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4816> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 17:53:48+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4816>
	{'abstract': u'In recent wireless networking optical communication is an emerging field. Another novel approach of optical communication using Narrow Line of Sight technique is discussed. Array of trans receivers are placed on the ceiling to communicate with the mobile nodes (users / trans receivers) instead of a single transmitter. An intelligent position tracking technique based on the informations available from prepositioned sensors and using them in simple geometric equations is described. Intelligent cell concept is used to facilitate the tracking system. The whole wide area is divided into several sub areas and some of the sub areas are designated as boundary sub areas which hold the data regarding the movement of the mobile nodes. The Diffie Hellman simple authenticated key agreement is used for secure communication.',
	 'authors': u'Swapan Bhattachrya, Devmalya Banerjee, Abirlal Biswas, Pijush Biswas,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4816',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nA secured communication link design using narrow line of sight technique',
	 'urllink': u'http://arxiv.org/abs/1308.4816'}
2015-03-24 17:54:09+0000 [xxu46_7] INFO: Crawled 734 pages (at 1 pages/min), scraped 727 items (at 1 items/min)
2015-03-24 17:55:09+0000 [xxu46_7] INFO: Crawled 734 pages (at 0 pages/min), scraped 727 items (at 0 items/min)
2015-03-24 17:55:48+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6690> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 17:55:48+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6690>
	{'abstract': u"Two-way relaying networks (TWRNs) allow for more bandwidth efficient use of the available spectrum since they allow for simultaneous information exchange between two users with the assistance of an intermediate relay node. However, due to superposition of signals at the relay node, the received signal at the user terminals is affected by emph, i.e., channel gains, timing offsets, and carrier frequency offsets, that need to be jointly estimated and compensated. This paper presents a training-based system model for amplify-and-forward (AF) TWRNs in the presence of multiple impairments and proposes maximum likelihood and differential evolution based algorithms for joint estimation of these impairments. The Cramer-Rao lower bounds (CRLBs) for the joint estimation of multiple impairments are derived. A minimum mean-square error based receiver is then proposed to compensate the effect of multiple impairments and decode each user's signal. Simulation results show that the performance of the proposed estimators is very close to the derived CRLBs at moderate-to-high signal-to-noise-ratios. It is also shown that the bit-error rate performance of the overall AF TWRN is close to a TWRN that is based on assumption of perfect knowledge of the synchronization parameters.",
	 'authors': u'Ali Arshad Nasir, Hani Mehrpouyan, Salman Durrani, Steven D. Blostein, Rodney A. Kennedy,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6690',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nTraining-Based Synchronization and Channel Estimation in AF Two-Way  Relaying Networks',
	 'urllink': u'http://arxiv.org/abs/1309.6690'}
2015-03-24 17:56:09+0000 [xxu46_7] INFO: Crawled 735 pages (at 1 pages/min), scraped 728 items (at 1 items/min)
2015-03-24 17:57:09+0000 [xxu46_7] INFO: Crawled 735 pages (at 0 pages/min), scraped 728 items (at 0 items/min)
2015-03-24 17:57:21+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5842> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 17:57:21+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5842>
	{'abstract': u"With at least 50 cores, Intel Xeon Phi is a true many-core architecture. Featuring fairly powerful cores, two cache levels, and very fast interconnections, the Xeon Phi can get a theoretical peak of 1000 GFLOPs and over 240 GB/s. These numbers, as well as its flexibility - it can be used both as a coprocessor or as a stand-alone processor - are very tempting for parallel applications looking for new performance records. In this paper, we present an empirical study of Xeon Phi, stressing its performance limits and relevant performance factors, ultimately aiming to present a simplified view of the machine for regular programmers in search for performance. To do so, we have micro-benchmarked the main hardware components of the processor - the cores, the memory hierarchies, the ring interconnect, and the PCIe connection. We show that, in ideal microbenchmarking conditions, the performance that can be achieved is very close to the theoretical peak, as given in the official programmer's guide. We have also identified and quantified several causes for significant performance penalties. Our findings have been captured in four optimization guidelines, and used to build a simplified programmer's view of Xeon Phi, eventually enable the design and prototyping of applications on a functionality-based model of the architecture.",
	 'authors': u'Jianbin Fang, Ana Lucia Varbanescu, Henk Sips, Lilun Zhang, Yonggang Che, Chuanfu Xu,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5842',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nAn Empirical Study of Intel Xeon Phi',
	 'urllink': u'http://arxiv.org/abs/1310.5842'}
2015-03-24 17:58:09+0000 [xxu46_7] INFO: Crawled 736 pages (at 1 pages/min), scraped 729 items (at 1 items/min)
2015-03-24 17:58:43+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4815> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 17:58:43+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4815>
	{'abstract': u'This dissertation explores classes of compiler optimization techniques that are applicable late in the compilation process, after all executable code for a program has been linked. I concentrate on techniques which, for various reasons, cannot be applied earlier in the compilation process. In addition to a theoretical treatment of this class of optimization techniques, this dissertation reports on an implementation of these techniques in a production environment. I describe the details of the implementation which allows these techniques to be re-targeted easily and report on improvements gained when optimizing production software.',
	 'authors': u'Clinton F. Goss,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4815',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nMachine Code Optimization - Improving Executable Object Code',
	 'urllink': u'http://arxiv.org/abs/1308.4815'}
2015-03-24 17:59:09+0000 [xxu46_7] INFO: Crawled 737 pages (at 1 pages/min), scraped 730 items (at 1 items/min)
2015-03-24 18:00:09+0000 [xxu46_7] INFO: Crawled 737 pages (at 0 pages/min), scraped 730 items (at 0 items/min)
2015-03-24 18:00:12+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6689> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 18:00:12+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6689>
	{'abstract': u'In this paper, we study a generalization of the classical minimum cut prob- lem, called Connectivity Preserving Minimum Cut (CPMC) problem, which seeks a minimum cut to separate a pair (or pairs) of source and destination nodes and meanwhile ensure the connectivity between the source and its partner node(s). The CPMC problem is a rather powerful formulation for a set of problems and finds applications in many other areas, such as network security, image processing, data mining, pattern recognition, and machine learning. For this important problem, we consider two variants, connectiv- ity preserving minimum node cut (CPMNC) and connectivity preserving minimum edge cut (CPMEC). For CPMNC, we show that it cannot be ap- proximated within logn for some constant unless P=NP, and cannot be approximated within any poly(logn) unless NP has quasi-polynomial time algorithms. The hardness results hold even for graphs with unit weight and bipartite graphs. Particularly, we show that polynomial time solutions exist for CPMEC in planar graphs and for CPMNC in some special planar graphs. The hardness of CPMEC in general graphs remains open, but the polynomial time algorithm in planar graphs still has important practical applications.',
	 'authors': u'Qi Duan, Jinhui Xu,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6689',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nOn the Connectivity Preserving Minimum Cut Problem',
	 'urllink': u'http://arxiv.org/abs/1309.6689'}
2015-03-24 18:01:09+0000 [xxu46_7] INFO: Crawled 738 pages (at 1 pages/min), scraped 731 items (at 1 items/min)
2015-03-24 18:01:24+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5841> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 18:01:24+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5841>
	{'abstract': u"Data warehouses are nowadays an important component in every competitive system, it's one of the main components on which business intelligence is based. We can even say that many companies are climbing to the next level and use a set of Data warehouses to provide the complete information or it's generally due to fusion of two or many companies. these Data warehouses can be heterogeneous and geographically separated, this structure is what we call federation, and even if the components are physically separated, they are logically seen as a single component. generally, these items are heterogeneous which make it difficult to create the logical federation schema,and the execution of user queries a complicated mission. In this paper, we will fill this gap by proposing an extension of an existent algorithm in order to treat different schema types (star, snow flack) including the treatment of hierarchies dimension using ontology",
	 'authors': u'Naoual Mouhni, Abderrafiaa Elkalay,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5841',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nOntology based data warehouses federation management system',
	 'urllink': u'http://arxiv.org/abs/1310.5841'}
2015-03-24 18:02:09+0000 [xxu46_7] INFO: Crawled 739 pages (at 1 pages/min), scraped 732 items (at 1 items/min)
2015-03-24 18:03:09+0000 [xxu46_7] INFO: Crawled 739 pages (at 0 pages/min), scraped 732 items (at 0 items/min)
2015-03-24 18:03:22+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4809> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 18:03:22+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4809>
	{'abstract': u'A construction of big convolutional codes from short codes called block Markov superposition transmission (BMST) is proposed. The BMST is very similar to superposition blockMarkov encoding (SBME), which has been widely used to prove multiuser coding theorems. The encoding process of BMST can be as fast as that of the involved short code, while the decoding process can be implemented as an iterative sliding-window decoding algorithm with a tunable delay. More importantly, the performance of BMST can be simply lower-bounded in terms of the transmission memory given that the performance of the short code is available. Numerical results show that, 1) the lower bounds can be matched with a moderate decoding delay in the low bit-error-rate (BER) region, implying that the iterative slidingwindow decoding algorithm is near optimal; 2) BMST with repetition codes and single parity-check codes can approach the Shannon limit within 0.5 dB at BER of 10^ for a wide range of code rates; and 3) BMST can also be applied to nonlinear codes.',
	 'authors': u'Xiao Ma, Chulong Liang, Kechao Huang, Qiutao Zhuang,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4809',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nBlock Markov Superposition Transmission: Construction of Big  Convolutional Codes from Short Codes',
	 'urllink': u'http://arxiv.org/abs/1308.4809'}
2015-03-24 18:04:09+0000 [xxu46_7] INFO: Crawled 740 pages (at 1 pages/min), scraped 733 items (at 1 items/min)
2015-03-24 18:05:09+0000 [xxu46_7] INFO: Crawled 740 pages (at 0 pages/min), scraped 733 items (at 0 items/min)
2015-03-24 18:05:12+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6687> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 18:05:12+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6687>
	{'abstract': u"Motivated by online reputation systems, we investigate social learning in a network where agents interact on a time dependent graph to estimate an underlying state of nature. Agents record their own private observations, then update their private beliefs about the state of nature using Bayes' rule. Based on their belief, each agent then chooses an action (rating) from a finite set and transmits this action over the social network. An important consequence of such social learning over a network is the ruinous multiple re-use of information known as data incest (or mis-information propagation). In this paper, the data incest management problem in social learning context is formulated on a directed acyclic graph. We give necessary and sufficient conditions on the graph topology of social interactions to eliminate data incest. A data incest removal algorithm is proposed such that the public belief of social learning (and hence the actions of agents) is not affected by data incest propagation. This results in an online reputation system with a higher trust rating. Numerical examples are provided to illustrate the performance of the proposed optimal data incest removal algorithm.",
	 'authors': u'Maziyar Hamdi, Vikram Krishnamurthy,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6687',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nRemoval of Data Incest in Multi-agent Social Learning in Social Networks',
	 'urllink': u'http://arxiv.org/abs/1309.6687'}
2015-03-24 18:06:09+0000 [xxu46_7] INFO: Crawled 741 pages (at 1 pages/min), scraped 734 items (at 1 items/min)
2015-03-24 18:06:39+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5839> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 18:06:39+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5839>
	{'abstract': u'As the complexity and size of challenges in science and engineering are continually increasing, it is highly important that applications are able to scale strongly to very large numbers of cores (&gt;100,000 cores) to enable HPC systems to be utilised efficiently. This paper presents results of strong scaling tests performed with an MPI only and a hybrid MPI + OpenMP version of the Lattice QCD application BQCD on the European Tier-0 system SuperMUC at LRZ.',
	 'authors': u'David Brayford, Momme Allalen, Volker Weinberg,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5839',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nExtreme Scaling of Lattice Quantum Chromodynamics',
	 'urllink': u'http://arxiv.org/abs/1310.5839'}
2015-03-24 18:07:09+0000 [xxu46_7] INFO: Crawled 742 pages (at 1 pages/min), scraped 735 items (at 1 items/min)
2015-03-24 18:08:09+0000 [xxu46_7] INFO: Crawled 742 pages (at 0 pages/min), scraped 735 items (at 0 items/min)
2015-03-24 18:08:19+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4801> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 18:08:19+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4801>
	{'abstract': u'Performances of building energy innovations are most of the time dependent on the external climate conditions. This means a high performance of a specific innovation in a certain part of Europe, does not imply the same performances in other regions. The mapping of simulated building performances at the EU scale could prevent the waste of potential good ideas by identifying the best region for a specific innovation. This paper presents a methodology for obtaining maps of performances of building innovations that are virtually spread over whole Europe. It is concluded that these maps are useful for finding regions at the EU where innovations have the highest expected performances.',
	 'authors': u'A.W.M. van Schijndel,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4801',
	 'subjects': u'Computational Engineering, Finance, and Science (cs.CE)',
	 'title': u'\nThe Mapping of Simulated Climate-Dependent Building Innovations',
	 'urllink': u'http://arxiv.org/abs/1308.4801'}
2015-03-24 18:09:09+0000 [xxu46_7] INFO: Crawled 743 pages (at 1 pages/min), scraped 736 items (at 1 items/min)
2015-03-24 18:10:09+0000 [xxu46_7] INFO: Crawled 743 pages (at 0 pages/min), scraped 736 items (at 0 items/min)
2015-03-24 18:10:17+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6683> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 18:10:17+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6683>
	{'abstract': u'Many real-world processes evolve in cascades over complex networks, whose topologies are often unobservable and change over time. However, the so-termed adoption times when blogs mention popular news items, individuals in a community catch an infectious disease, or consumers adopt a trendy electronics product are typically known, and are implicitly dependent on the underlying network. To infer the network topology, a textit structural equation model is adopted to capture the relationship between observed adoption times and the unknown edge weights. Assuming a slowly time-varying topology and leveraging the sparse connectivity inherent to social networks, edge weights are estimated by minimizing a sparsity-regularized exponentially-weighted least-squares criterion. To this end, solvers with complementary strengths are developed by leveraging (pseudo) real-time sparsity-promoting proximal gradient iterations, the improved convergence rate of accelerated variants, or reduced computational complexity of stochastic gradient descent. Numerical tests with both synthetic and real data demonstrate the effectiveness of the novel algorithms in unveiling sparse dynamically-evolving topologies, while accounting for external influences in the adoption times. Key events in the recent succession of political leadership in North Korea, explain connectivity changes observed in the associated network inferred from global cascades of online media.',
	 'authors': u'Brian Baingana, Gonzalo Mateos, Georgios B. Giannakis,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6683',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nDynamic Structural Equation Models for Social Network Topology Inference',
	 'urllink': u'http://arxiv.org/abs/1309.6683'}
2015-03-24 18:11:09+0000 [xxu46_7] INFO: Crawled 744 pages (at 1 pages/min), scraped 737 items (at 1 items/min)
2015-03-24 18:12:05+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5828> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 18:12:05+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5828>
	{'abstract': u'We consider the problem of coordinating a collection of robots at an intersection area taking into account dynamical constraints due to actuator limitations. We adopt the coordination space approach, which is standard in multiple robot motion planning. Assuming the priorities between robots are assigned in advance and the existence of a collision-free trajectory respecting those priorities, we propose a provably safe trajectory planner satisfying kinodynamic constraints. The algorithm is shown to run in real time and to return safe (collision-free) trajectories. Simulation results on synthetic data illustrate the benefits of the approach.',
	 'authors': u'Jean Gregoire, Silv\xe8re Bonnabel, Arnaud de La Fortelle,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5828',
	 'subjects': u'Robotics (cs.RO)',
	 'title': u'\nPriority-based intersection management with kinodynamic constraints',
	 'urllink': u'http://arxiv.org/abs/1310.5828'}
2015-03-24 18:12:09+0000 [xxu46_7] INFO: Crawled 745 pages (at 1 pages/min), scraped 738 items (at 1 items/min)
2015-03-24 18:13:09+0000 [xxu46_7] INFO: Crawled 745 pages (at 0 pages/min), scraped 738 items (at 0 items/min)
2015-03-24 18:13:59+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4791> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 18:13:59+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4791>
	{'abstract': u'In this paper, we propose an algorithm referred to as multipath matching pursuit that investigates multiple promising candidates to recover sparse signals from compressed measurements. Our method is inspired by the fact that the problem to find the candidate that minimizes the residual is readily modeled as a combinatoric tree search problem and the greedy search strategy is a good fit for solving this problem. In the empirical results as well as the restricted isometry property (RIP) based performance guarantee, we show that the proposed MMP algorithm is effective in reconstructing original sparse signals for both noiseless and noisy scenarios.',
	 'authors': u'Suhyuk, Kwon, Jian Wang, Byonghyo Shim,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4791',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nMultipath Matching Pursuit',
	 'urllink': u'http://arxiv.org/abs/1308.4791'}
2015-03-24 18:14:09+0000 [xxu46_7] INFO: Crawled 746 pages (at 1 pages/min), scraped 739 items (at 1 items/min)
2015-03-24 18:15:09+0000 [xxu46_7] INFO: Crawled 746 pages (at 0 pages/min), scraped 739 items (at 0 items/min)
2015-03-24 18:15:56+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6659> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 18:15:56+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6659>
	{'abstract': u'Finding a maximum independent set (MIS) of a given fam- ily of axis-parallel rectangles is a basic problem in computational geom- etry and combinatorics. This problem has attracted signi?cant atten- tion since the sixties, when Wegner conjectured that the corresponding duality gap, i.e., the maximum possible ratio between the maximum independent set and the minimum hitting set (MHS), is bounded by a universal constant. An interesting special case, that may prove use- ful to tackling the general problem, is the diagonal-intersecting case, in which the given family of rectangles is intersected by a diagonal. Indeed, Chepoi and Felsner recently gave a factor 6 approximation algorithm for MHS in this setting, and showed that the duality gap is between 3/2 and 6. In this paper we improve upon these results. First we show that MIS in diagonal-intersecting families is NP-complete, providing one smallest subclass for which MIS is provably hard. Then, we derive an -time algorithm for the maximum weight independent set when, in addition the rectangles intersect below the diagonal. This improves and extends a classic result of Lubiw, and amounts to obtain a 2-approximation algo- rithm for the maximum weight independent set of rectangles intersecting a diagonal. Finally, we prove that for diagonal-intersecting families the duality gap is between 2 and 4. The upper bound, which implies an approximation algorithm of the same factor, follows from a simple com- binatorial argument, while the lower bound represents the best known lower bound on the duality gap, even in the general case.',
	 'authors': u'Jos\xe9 R. Correa, Laurent Feuilloley, Pablo P\xe9rez-Lantero, Jos\xe9 A. Soto,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6659',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nIndependent and Hitting Sets of Rectangles Intersecting a Diagonal Line  : Algorithms and Complexity',
	 'urllink': u'http://arxiv.org/abs/1309.6659'}
2015-03-24 18:16:09+0000 [xxu46_7] INFO: Crawled 747 pages (at 1 pages/min), scraped 740 items (at 1 items/min)
2015-03-24 18:17:09+0000 [xxu46_7] INFO: Crawled 747 pages (at 0 pages/min), scraped 740 items (at 0 items/min)
2015-03-24 18:17:18+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5816> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 18:17:18+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5816>
	{'abstract': u'University online seats have gradually become complex systems of dynamic information where all their institutions and services are linked and potentially accessible. These online seats now constitute a central node around which universities construct and document their main activities and services. This information can be quantitative measured by cybermetric techniques in order to design university web rankings, taking the university as a global reference unit. However, previous research into web subunits shows that it is possible to carry out systemic web analyses, which open up the possibility of carrying out studies which address university diversity, necessary for both describing the university in greater detail and for establishing comparable ranking units. To address this issue, a multilevel university cybermetric analysis model is proposed, based on parts (core and satellite), levels (institutional and external) and sublevels (contour and internal), providing a deeper analysis of institutions. Finally the model is integrated into another which is independent of the technique used, and applied by analysing Harvard University as an example of use.',
	 'authors': u'Enrique Ordu\xf1a-Malea, Jos\xe9-Antonio Ontalba-Ruip\xe9rez,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5816',
	 'subjects': u'Digital Libraries (cs.DL)',
	 'title': u'\nProposal for a multilevel university cybermetric analysis model',
	 'urllink': u'http://arxiv.org/abs/1310.5816'}
2015-03-24 18:18:09+0000 [xxu46_7] INFO: Crawled 748 pages (at 1 pages/min), scraped 741 items (at 1 items/min)
2015-03-24 18:19:09+0000 [xxu46_7] INFO: Crawled 748 pages (at 0 pages/min), scraped 741 items (at 0 items/min)
2015-03-24 18:19:19+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4786> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 18:19:19+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4786>
	{'abstract': u'The concept of controlling non-linear systems is one the significant fields in scientific researches for the purpose of which intelligent approaches can provide desirable applicability. Fuzzy systems are systems with ambiguous definition and fuzzy control is an especial type of non-linear control. Inverse pendulum system is one the most widely popular non-linear systems which is known for its specific characteristics such as being intrinsically non-linear and unsteady. Therefore, a controller is required for maintaining stability of the system Present study tries to compare the obtained results from designing fuzzy intelligent controllers in similar conditions and also identify the appropriate controller for holding the inverse pendulum in vertical position on the cart.',
	 'authors': u'Qasem Abdollah Nezhad, Javad Palizvan Zand, Samira Shah Hoseini,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4786',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nAn Investigation On Fuzzy Logic Controllers (TAKAGI-SUGENO & MAMDANI) In  Inverse Pendulum System',
	 'urllink': u'http://arxiv.org/abs/1308.4786'}
2015-03-24 18:20:09+0000 [xxu46_7] INFO: Crawled 749 pages (at 1 pages/min), scraped 742 items (at 1 items/min)
2015-03-24 18:20:52+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6655> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 18:20:52+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6655>
	{'abstract': u'Symbolic integration is an important module of a typical Computer Algebra System. As for now, Mathematica, Matlab, Maple and Sage are all mainstream CAS. They share the same framework for symbolic integration at some points. In this book first we review the state of the art in the field of CAS. Then we focus on typical frameworks of the current symbolic integration systems and summarize the main mathematical theories behind these frameworks. Based on the open-source computer algebra system maTHmU developed by our team in our university, we propose a potential framework to improve the performance of the current symbolic integration system.',
	 'authors': u'Weiguang Mao,',
	 'category': u'Computer Science ',
	 'date': '2013-9-23',
	 'pdflink': u'http://arxiv.org/pdf/1309.6655',
	 'subjects': u'Symbolic Computation (cs.SC)',
	 'title': u'\nIntroduction to the Symbolic Integration System',
	 'urllink': u'http://arxiv.org/abs/1309.6655'}
2015-03-24 18:21:09+0000 [xxu46_7] INFO: Crawled 750 pages (at 1 pages/min), scraped 743 items (at 1 items/min)
2015-03-24 18:22:09+0000 [xxu46_7] INFO: Crawled 750 pages (at 0 pages/min), scraped 743 items (at 0 items/min)
2015-03-24 18:22:43+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5815> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 18:22:43+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5815>
	{'abstract': u'Mention indicators have frequently been used in Webometric studies because they provide a powerful tool for determining the degree of visibility and impact of web resources. Among mention indicators, hypertextual links were a central part of many studies until Yahoo discontinued the linkdomain command in 2011. Selective links constitute a variant of external links where both the source and target of the link can be selected. This paper intends to study the influence of social platforms (measured through the number of selective external links) on academic environments, in order to ascertain both the percentage that they constitute and whether some of them can be used as substitutes of total external links. For this purpose, 141 URLs belonging to 76 Spanish universities were compiled in 2010 (before Yahoo! stopped their link services), and the number of links from 13 selected social platforms to these universities were calculated. Results confirm a good correlation between total external links and links that come from social platforms, with the exception of some applications (such as Digg and Technorati). For those universities with a higher number of total external links, the high correlation is only maintained on Delicious and Wikipedia, which can be utilized as substitutes of total external links in the context analyzed. Notwithstanding, the global percentage of links from social platforms constitute only a small fraction of total links, although a positive trend is detected, especially in services such as Twitter, Youtube, and Facebook.',
	 'authors': u'Enrique Orduna-Malea, Jose-Antonio Ontalba-Ruiperez,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5815',
	 'subjects': u'Digital Libraries (cs.DL)',
	 'title': u'\nSelective linking from social platforms to university websites: a case  study of the Spanish academic system',
	 'urllink': u'http://arxiv.org/abs/1310.5815'}
2015-03-24 18:23:09+0000 [xxu46_7] INFO: Crawled 751 pages (at 1 pages/min), scraped 744 items (at 1 items/min)
2015-03-24 18:23:33+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4777> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 18:23:33+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4777>
	{'abstract': u'In this paper, we investigate the distributed power allocation for multi-cell OFDMA networks taking both energy efficiency and inter-cell interference (ICI) mitigation into account. A performance metric termed as throughput contribution is exploited to measure how ICI is effectively coordinated. To achieve a distributed power allocation scheme for each base station (BS), the throughput contribution of each BS to the network is first given based on a pricing mechanism. Different from existing works, a biobjective problem is formulated based on multi-objective optimization theory, which aims at maximizing the throughput contribution of the BS to the network and minimizing its total power consumption at the same time. Using the method of Pascoletti and Serafini scalarization, the relationship between the varying parameters and minimal solutions is revealed. Furthermore, to exploit the relationship an algorithm is proposed based on which all the solutions on the boundary of the efficient set can be achieved by adaptively adjusting the involved parameters. With the obtained solution set, the decision maker has more choices on power allocation schemes in terms of both energy consumption and throughput. Finally, the performance of the algorithm is assessed by the simulation results.',
	 'authors': u'Zesong Fei, Chengwen Xing, Na Li, Jingming Kuang,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4777',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nAdaptive Multi-objective Optimization for Energy Efficient Interference  Coordination in Multi-Cell Networks',
	 'urllink': u'http://arxiv.org/abs/1308.4777'}
2015-03-24 18:24:09+0000 [xxu46_7] INFO: Crawled 752 pages (at 1 pages/min), scraped 745 items (at 1 items/min)
2015-03-24 18:25:09+0000 [xxu46_7] INFO: Crawled 752 pages (at 0 pages/min), scraped 745 items (at 0 items/min)
2015-03-24 18:25:31+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6651> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 18:25:31+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6651>
	{'abstract': u'We study a random system of linear equations over variables in GF(2), where each equation contains exactly variables; this is equivalent to -XORSAT. cite determined the clustering threshold, : if for any constant , then aas the solutions partition into well-connected, well-separated (with probability tending to 1 as ). This is part of a general clustering phenomenon which is hypothesized to arise in most of the commonly studied models of random constraint satisfaction problems, via sophisticated but mostly non-rigorous techniques from statistical physics. We extend that study to the range , showing that if , then the connectivity parameter of each -XORSAT cluster is , as compared to when . This means that one can move between any two solutions in the same cluster via a sequence of solutions where consecutive solutions differ on at most variables; this is tight up to the implicit constant. In contrast, moving to a solution in another cluster requires that some pair of consecutive solutions differ in at least variables. Along the way, we prove that in a random -uniform hypergraph with edge-density above the -core threshold, aas every vertex not in the -core can be removed by a sequence of vertex-deletions in which the deleted vertex has degree less than ; again, this is tight up to the implicit constant.',
	 'authors': u'Pu Gao, Michael Molloy,',
	 'category': u'Computer Science ',
	 'date': '2013-9-19',
	 'pdflink': u'http://arxiv.org/pdf/1309.6651',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nInside the clustering threshold for random linear equations',
	 'urllink': u'http://arxiv.org/abs/1309.6651'}
2015-03-24 18:26:09+0000 [xxu46_7] INFO: Crawled 753 pages (at 1 pages/min), scraped 746 items (at 1 items/min)
2015-03-24 18:27:01+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5814> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 18:27:01+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5814>
	{'abstract': u'The aggregation of web performance (page count and visibility) of internal university units could constitute a more precise indicator than the overall web performance of the universities and, therefore, be of use in the design of university web rankings. In order to test this hypothesis, a longitudinal analysis of the internal units of the Spanish university system was conducted over the course of 2010. For the 13800 URLs identified, page count and visibility was calculated using the Yahoo API. The internal values obtained were aggregated by university and compared with the values obtained from the analysis of the university general URLs. The results indicate that, although the correlations between general and internal values are high, internal performance is low in comparison to general performance, and that they give rise to different performance rankings. The conclusion is that the aggregation of unit performance is of limited use due to the low levels of internal development of the websites, and so its use is not recommended for the design of rankings. Despite this, the internal analysis enabled the detection of, amongst other things, a low correlation between page count and visibility due to the widespread use of subdirectories and problems accessing certain content.',
	 'authors': u'Enrique Ordu\xf1a-Malea,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5814',
	 'subjects': u'Digital Libraries (cs.DL)',
	 'title': u'\nAggregation of the web performance of internal university units as a  method of quantitative analysis of a university system: the case of Spain',
	 'urllink': u'http://arxiv.org/abs/1310.5814'}
2015-03-24 18:27:09+0000 [xxu46_7] INFO: Crawled 754 pages (at 1 pages/min), scraped 747 items (at 1 items/min)
2015-03-24 18:28:09+0000 [xxu46_7] INFO: Crawled 754 pages (at 0 pages/min), scraped 747 items (at 0 items/min)
2015-03-24 18:28:55+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4774> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 18:28:55+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4774>
	{'abstract': u"A program can be considered as a device that generates discrete time signals, where a signal is an execution. Shannon information rate, or bit rate, of the signals may not be uniformly distributed. When the program is specified by a finite state transition system, algorithms are provided in identifying information-rich components. For a black-box program that has a partial specification or does not even have a specification, a bit rate signal and its spectrum are studied, which make use of data compression and the Fourier transform. The signal provides a bit-rate coverage for testing the black-box while its spectrum indicates a visual representation for execution's information characteristics.",
	 'authors': u'Cewei Cui, Zhe Dang, Thomas R. Fischer,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4774',
	 'subjects': u'Software Engineering (cs.SE)',
	 'title': u'\nBit Rate of Programs',
	 'urllink': u'http://arxiv.org/abs/1308.4774'}
2015-03-24 18:29:09+0000 [xxu46_7] INFO: Crawled 755 pages (at 1 pages/min), scraped 748 items (at 1 items/min)
2015-03-24 18:30:09+0000 [xxu46_7] INFO: Crawled 755 pages (at 0 pages/min), scraped 748 items (at 0 items/min)
2015-03-24 18:30:42+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6650> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 18:30:42+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6650>
	{'abstract': u'Ontologies are considered as the backbone of the Semantic Web. With the rising success of the Semantic Web, the number of participating communities from different countries is constantly increasing. The growing number of ontologies available in different natural languages leads to an interoperability problem. In this paper, we discuss several approaches for ontology matching; examine similarities and differences, identify weaknesses, and compare the existing automated approaches with the manual approaches for integrating multilingual ontologies. In addition to that, we propose a new architecture for a multilingual ontology matching service. As a case study we used an example of two multilingual enterprise ontologies - the university ontology of Freie Universitaet Berlin and the ontology for Fayoum University in Egypt.',
	 'authors': u'Haytham Al-Feel, Ralph Schafermeier, Adrian Paschke,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6650',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nAn Inter-lingual Reference Approach For Multi-Lingual Ontology Matching',
	 'urllink': u'http://arxiv.org/abs/1309.6650'}
2015-03-24 18:31:09+0000 [xxu46_7] INFO: Crawled 756 pages (at 1 pages/min), scraped 749 items (at 1 items/min)
2015-03-24 18:32:09+0000 [xxu46_7] INFO: Crawled 756 pages (at 0 pages/min), scraped 749 items (at 0 items/min)
2015-03-24 18:32:32+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5812> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 18:32:32+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5812>
	{'abstract': u'The main goal of this research is to analyze the web structure and performance of units and services belonging to U.S. academic libraries in order to check their suitability for webometric studies. Our objectives include studying their possible correlation with economic data and assessing their use for complementary evaluation purposes. We conducted a survey of library homepages, institutional repositories, digital collections, and online catalogs (a total of 374 URLs) belonging to the 100 U.S. universities with the highest total expenditures in academic libraries according to data provided by the National Center for Education Statistics (NCES). Several data points were taken and analyzed, including web variables (page count, external links, and visits) and economic variables (total expenditures, expenditures on printed and electronic books, and physical visits). The results indicate that the variety of URL syntaxes is wide, diverse and complex, which produces a misrepresentation of academic library web resources and reduces the accuracy of web analysis. On the other hand, institutional and web data indicators are not highly correlated. Better results are obtained by correlating total library expenditures with URL mentions measured by Google (r= 0.546) and visits measured by Compete (r= 0.573), respectively. Because correlation values obtained are not highly significant, we estimate such correlations will increase if users can avoid linkage problems (due to the complexity of URLs) and gain direct access to log files (for more accurate data about visits).',
	 'authors': u'Enrique Ordu\xf1a-Malea, John J. Regazzi,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5812',
	 'subjects': u'Digital Libraries (cs.DL)',
	 'title': u'\nU.S. academic libraries: understanding their web presence and their  relationship with economic indicators',
	 'urllink': u'http://arxiv.org/abs/1310.5812'}
2015-03-24 18:33:09+0000 [xxu46_7] INFO: Crawled 757 pages (at 1 pages/min), scraped 750 items (at 1 items/min)
2015-03-24 18:33:58+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4767> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 18:33:58+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4767>
	{'abstract': u'It is often difficult to correctly implement a Boolean controller for a complex system, especially when concurrency is involved. Yet, it may be easy to formally specify a controller. For instance, for a pipelined processor it suffices to state that the visible behavior of the pipelined system should be identical to a non-pipelined reference system (Burch-Dill paradigm). We present a novel procedure to efficiently synthesize multiple Boolean control signals from a specification given as a quantified first-order formula (with a specific quantifier structure). Our approach uses uninterpreted functions to abstract details of the design. We construct an unsatisfiable SMT formula from the given specification. Then, from just one proof of unsatisfiability, we use a variant of Craig interpolation to compute multiple coordinated interpolants that implement the Boolean control signals. Our method avoids iterative learning and back-substitution of the control functions. We applied our approach to synthesize a controller for a simple two-stage pipelined processor, and present first experimental results.',
	 'authors': u'Georg Hofferek, Ashutosh Gupta, Bettina K\xf6nighofer, Jie-Hong Roland Jiang, Roderick Bloem,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4767',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nSynthesizing Multiple Boolean Functions using Interpolation on a Single  Proof',
	 'urllink': u'http://arxiv.org/abs/1308.4767'}
2015-03-24 18:34:09+0000 [xxu46_7] INFO: Crawled 758 pages (at 1 pages/min), scraped 751 items (at 1 items/min)
2015-03-24 18:35:09+0000 [xxu46_7] INFO: Crawled 758 pages (at 0 pages/min), scraped 751 items (at 0 items/min)
2015-03-24 18:35:38+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6628> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 18:35:38+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6628>
	{'abstract': u'This paper lays the foundations of an approach to applying Gromov\'s ideas on quantitative topology to topological data analysis. We introduce the "contiguity complex", a simplicial complex of maps between simplicial complexes defined in terms of the combinatorial notion of contiguity. We generalize the Simplicial Approximation Theorem to show that the contiguity complex approximates the homotopy type of the mapping space as we subdivide the domain. We describe algorithms for approximating the rate of growth of the components of the contiguity complex under subdivision of the domain; this procedure allows us to computationally distinguish spaces with isomorphic homology but different homotopy types.',
	 'authors': u'Andrew J. Blumberg, Michael A. Mandell,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6628',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nQuantitative Homotopy Theory in Topological Data Analysis',
	 'urllink': u'http://arxiv.org/abs/1309.6628'}
2015-03-24 18:36:09+0000 [xxu46_7] INFO: Crawled 759 pages (at 1 pages/min), scraped 752 items (at 1 items/min)
2015-03-24 18:37:07+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5805> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 18:37:07+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5805>
	{'abstract': u'Nowadays, Voice over IP (VoIP) constitutes a privileged field of service innovation. One benefit of the VoIP technology is that it may be deployed using a centralized or a distributed architecture. One of the most efficient approaches used in the deployment of centralized VoIP systems is based on the use of IAX (Inter-Asterisk Exchange), an open-source signaling/data exchange protocol. Even though they are currently widely used, client-server VoIP systems suffer from many weaknesses such as the presence of single points of failure, an inefficient resources management, and system non-scalability. In order to help the development of scalable and reliable VoIP systems, the development community starts tending towards the deployment of the VoIP service using a peer-to-peer distributed architecture. The aim of this paper is to develop an IAX-based peer-to-peer VoIP architecture, an optimized VoIP architecture that takes advantage of the benefits of the IAX protocol and those of the peer-to-peer distribution model.',
	 'authors': u'Amor Lazzez, Ouissem Ben Fredj, Thabet Slimani,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5805',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nIAX-Based Peer-to-Peer VoIP Architecture',
	 'urllink': u'http://arxiv.org/abs/1310.5805'}
2015-03-24 18:37:09+0000 [xxu46_7] INFO: Crawled 760 pages (at 1 pages/min), scraped 753 items (at 1 items/min)
2015-03-24 18:38:09+0000 [xxu46_7] INFO: Crawled 760 pages (at 0 pages/min), scraped 753 items (at 0 items/min)
2015-03-24 18:38:47+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4764> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 18:38:47+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4764>
	{'abstract': u'In this paper, tall discrete-time linear systems with multirate outputs are studied. In particular, we focus on their zeros. In systems and control literature zeros of multirate systems are defined as those of their corresponding time-invariant blocked systems. Hence, the zeros of tall blocked systems resulting from blocking of linear systems with multirate outputs are mainly explored in this work. We specifically investigate zeros of tall blocked systems formed by blocking tall multirate linear systems with generic parameter matrices. It is demonstrated that tall blocked systems generically have no finite nonzero zeros; however, they may have zeros at the origin or at infinity depending on the choice of blocking delay and the input, state and output dimensions.',
	 'authors': u'Mohsen Zamani, Giulio Bottegal, Brian D. O. Anderson,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4764',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nOn the Zero-freeness of Tall Multirate Linear Systems',
	 'urllink': u'http://arxiv.org/abs/1308.4764'}
2015-03-24 18:39:09+0000 [xxu46_7] INFO: Crawled 761 pages (at 1 pages/min), scraped 754 items (at 1 items/min)
2015-03-24 18:40:09+0000 [xxu46_7] INFO: Crawled 761 pages (at 0 pages/min), scraped 754 items (at 0 items/min)
2015-03-24 18:40:17+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6613> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 18:40:17+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6613>
	{'abstract': u'In this paper we explore the relationship between dual decomposition and the consensus-based method for distributed optimization. The relationship is developed by examining the similarities between the two approaches and their relationship to gradient-based constrained optimization. By formulating each algorithm in continuous-time, it is seen that both approaches use a gradient method for optimization with one using a proportional control term and the other using an integral control term to drive the system to the constraint set. Therefore, a significant contribution of this paper is to combine these methods to develop a continuous-time proportional-integral distributed optimization method. Furthermore, we establish convergence using Lyapunov stability techniques and utilizing properties from the network structure of the multi-agent system.',
	 'authors': u'Greg Droge, Hiroaki Kawashima, Magnus Egerstedt,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6613',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nContinuous-time Proportional-Integral Distributed Optimization for  Networked Systems',
	 'urllink': u'http://arxiv.org/abs/1309.6613'}
2015-03-24 18:41:09+0000 [xxu46_7] INFO: Crawled 762 pages (at 1 pages/min), scraped 755 items (at 1 items/min)
2015-03-24 18:41:45+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5796> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 18:41:45+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5796>
	{'abstract': u'We present an extensive analysis of relative deviation bounds, including detailed proofs of two-sided inequalities and their implications. We also give detailed proofs of two-sided generalization bounds that hold in the general case of unbounded loss functions, under the assumption that a moment of the loss is bounded. These bounds are useful in the analysis of importance weighting and other learning tasks such as unbounded regression.',
	 'authors': u'Corinna Cortes, Spencer Greenberg, Mehryar Mohri,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5796',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nRelative Deviation Learning Bounds and Generalization with Unbounded  Loss Functions',
	 'urllink': u'http://arxiv.org/abs/1310.5796'}
2015-03-24 18:42:09+0000 [xxu46_7] INFO: Crawled 763 pages (at 1 pages/min), scraped 756 items (at 1 items/min)
2015-03-24 18:43:09+0000 [xxu46_7] INFO: Crawled 763 pages (at 0 pages/min), scraped 756 items (at 0 items/min)
2015-03-24 18:43:28+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4761> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 18:43:28+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4761>
	{'abstract': u"Recent work has suggested reducing electricity generation cost by cutting the peak to average ratio (PAR) without reducing the total amount of the loads. However, most of these proposals rely on consumer's willingness to act. In this paper, we propose an approach to cut PAR explicitly from the supply side. The resulting cut loads are then distributed among consumers by the means of a multiunit auction which is done by an intelligent agent on behalf of the consumer. This approach is also in line with the future vision of the smart grid to have the demand side matched with the supply side. Experiments suggest that our approach reduces overall system cost and gives benefit to both consumers and the energy provider.",
	 'authors': u'Tri Kurniawan Wijaya, Kate Larson, Karl Aberer,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4761',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nMatching Demand with Supply in the Smart Grid using Agent-Based  Multiunit Auction',
	 'urllink': u'http://arxiv.org/abs/1308.4761'}
2015-03-24 18:44:09+0000 [xxu46_7] INFO: Crawled 764 pages (at 1 pages/min), scraped 757 items (at 1 items/min)
2015-03-24 18:45:09+0000 [xxu46_7] INFO: Crawled 764 pages (at 0 pages/min), scraped 757 items (at 0 items/min)
2015-03-24 18:45:24+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6610> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 18:45:24+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6610>
	{'abstract': u'We study deterministic distributed broadcasting in synchronous multiple-access channels. Packets are injected into nodes by a window-type adversary that is constrained by a window and injection rates individually assigned to all nodes. We investigate what queue size and packet latency can be achieved with the maximum aggregate injection rate of one packet per round, depending on properties of channels and algorithms. We give a non-adaptive algorithm for channels with collision detection and an adaptive algorithm for channels without collision detection that achieve packet latency. We show that packet latency has to be either , when , or , when , as a matching lower bound to these algorithms. We develop a non-adaptive algorithm for channels without collision detection that achieves queue size and packet latency. This is in contrast with the adversarial model of global injection rates, in which non-adaptive algorithms with bounded packet latency do not exist [18]. Our algorithm avoids collisions produced by simultaneous transmissions; we show that any algorithm with this property must have packet latency.',
	 'authors': u'Lakshmi Anantharamu, Bogdan S. Chlebus, Mariusz A. Rokicki,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6610',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nAdversarial Multiple Access Channels with Individual Injection Rates',
	 'urllink': u'http://arxiv.org/abs/1309.6610'}
2015-03-24 18:46:09+0000 [xxu46_7] INFO: Crawled 765 pages (at 1 pages/min), scraped 758 items (at 1 items/min)
2015-03-24 18:47:09+0000 [xxu46_7] INFO: Crawled 765 pages (at 0 pages/min), scraped 758 items (at 0 items/min)
2015-03-24 18:47:09+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5794> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 18:47:09+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5794>
	{'abstract': u'WiMax is a promising network of today industry. It provides P2P and P2MP point to multipoint broadband services up to thirty miles. Its operational frequency range is 10 GHz to 60 GHz. It provides data rate of 75Mbps per channel; with an end-to-end encryption called CCMP (Counter Mode with Cipher Block Chaining Message Authentication Code Protocol). CCMP is an Advanced Encryption Standard AES based encryption method, which delivers secure communication. Telecom industry seeks secure, cheaper, wireless metro area network, that full fill the today internet demand in most efficient way. Our research explores the new dimension of WiMax with HEMT High Electron Mobility Transistor using un-licensed Band. The Aim of this paper is to simulate 60GHz unlicensed WiMax band in Matlab. This research explores millimeter waves, related electronics, mathematics of WiMax and simulated graph comparison. It determines available capacity verses coverage area and transmission bit error probability. Further it highlights the ideal modulation condition in different terrains. Research proofs that WiMax will be the future promising wireless network.',
	 'authors': u'Safeeullah Soomro, Adnan Alam Khan, Abdul Ghafoor Memon, Asim Iftikhar, Maree Mujeeb-u-Rehman,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5794',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nAn Operational Approach For Wimax At Ultra High Bandwidth With Spectrum  60 Ghz',
	 'urllink': u'http://arxiv.org/abs/1310.5794'}
2015-03-24 18:48:09+0000 [xxu46_7] INFO: Crawled 766 pages (at 1 pages/min), scraped 759 items (at 1 items/min)
2015-03-24 18:49:09+0000 [xxu46_7] INFO: Crawled 766 pages (at 0 pages/min), scraped 759 items (at 0 items/min)
2015-03-24 18:49:10+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4757> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 18:49:10+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4757>
	{'abstract': u'Online learning has emerged as powerful tool in large scale optimization. In this work, we generalize the Douglas-Rachford splitting method for minimizing composite functions to online settings.',
	 'authors': u'Ziqiang Shi,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4757',
	 'subjects': u'Numerical Analysis (cs.NA)',
	 'title': u'\nOnline Douglas-Rachford splitting method',
	 'urllink': u'http://arxiv.org/abs/1308.4757'}
2015-03-24 18:50:09+0000 [xxu46_7] INFO: Crawled 767 pages (at 1 pages/min), scraped 760 items (at 1 items/min)
2015-03-24 18:50:42+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6608> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 18:50:42+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6608>
	{'abstract': u'The meaning and purposes of web has been changing and evolving day by day. Web 2. 0 encouraged more contribution by the end users. This movement provided revolutionary methods of sharing and computing data by crowdsourcing such as OpenStreetmap, also called "the wikification of maps" by some researchers. When crowdsourcing collects huge data with help of general public with varying level of mapping experience, the focus of researcher should be on analysing the data rather than collecting it. Researchers have assessed the quality of OpenStreetMap data by comparing it with proprietary data or data of governmental map agencies. This study reviews the research work for assessment of Open- StreetMap Data and also discusses about the future directions.',
	 'authors': u'Sukhjit Singh Sehra, Jaiteg Singh, Hardeep Singh Rai,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6608',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nAssessment of OpenStreetMap Data - A Review',
	 'urllink': u'http://arxiv.org/abs/1309.6608'}
2015-03-24 18:51:09+0000 [xxu46_7] INFO: Crawled 768 pages (at 1 pages/min), scraped 761 items (at 1 items/min)
2015-03-24 18:51:57+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5793> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 18:51:57+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5793>
	{'abstract': u'Intelligent Transportation System in case of cities is controlling traffic congestion and regulating the traffic flow. This paper presents three modules that will help in managing city traffic issues and ultimately gives advanced development in transportation system. First module, Congestion Detection and Management will provide user real time information about congestion on the road towards his destination, Second module, Intelligent Public Transport System will provide user real time public transport information,i.e, local buses, and the third module, Signal Synchronization will help in controlling congestion at signals, with real time adjustments of signal timers according to the congestion. All the information that user is getting about the traffic or public transportation will be provided on users day to day device that is mobile through Android application or SMS. Moreover, communication can also be done via Website for Clients having internet access. And all these modules will be fully automated without any human intervention at server side.',
	 'authors': u'Snehal Mulay, Chinmay Dhekne, Rucha Bapat, Tanmay Budukh, Soham Gadgil,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5793',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nIntelligent City Traffic Management and Public Transportation System',
	 'urllink': u'http://arxiv.org/abs/1310.5793'}
2015-03-24 18:52:09+0000 [xxu46_7] INFO: Crawled 769 pages (at 1 pages/min), scraped 762 items (at 1 items/min)
2015-03-24 18:53:09+0000 [xxu46_7] INFO: Crawled 769 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2015-03-24 18:53:24+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4751> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 18:53:24+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4751>
	{'abstract': u'We consider distributed channel access in multi-hop cognitive radio networks. Previous works on opportunistic channel access using multi-armed bandits (MAB) mainly focus on single-hop networks that assume complete conflicts among all secondary users. In the multi-hop multi-channel network settings studied here, there is more general competition among different communication pairs. We formulate the problem as a linearly combinatorial MAB problem that involves a maximum weighted independent set (MWIS) problem with unknown weights which need to learn. Existing methods for MAB where each of nodes chooses from channels have exponential time and space complexity , and poor theoretical guarantee on throughput performance. We propose a distributed channel access algorithm that can achieve of the optimum averaged throughput where each node has communication complexity and space complexity in the learning process, and time complexity in strategy decision process for an arbitrary wireless network. Here is the approximation ratio to MWIS for a local -hop network with nodes,and is the number of mini-rounds inside each round of strategy decision. For randomly located networks with an average degree , the time complexity is .',
	 'authors': u'Yaqin Zhou, Xiang-yang Li, Fan Li, Min Liu, Zhongcheng Li, Zhiyuan Yin,',
	 'category': u'Computer Science ',
	 'date': '2013-8-22',
	 'pdflink': u'http://arxiv.org/pdf/1308.4751',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nAlmost Optimal Channel Access in Multi-Hop Networks With Unknown Channel  Variables',
	 'urllink': u'http://arxiv.org/abs/1308.4751'}
2015-03-24 18:54:09+0000 [xxu46_7] INFO: Crawled 770 pages (at 1 pages/min), scraped 763 items (at 1 items/min)
2015-03-24 18:54:12+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6603> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 18:54:12+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6603>
	{'abstract': u'We consider the problem of scattering robots in a two dimensional continuous space. As this problem is impossible to solve in a deterministic manner, all solutions must be probabilistic. We investigate the amount of randomness (that is, the number of random bits used by the robots) that is required to achieve scattering. We first prove that random bits are necessary to scatter robots in any setting. Also, we give a sufficient condition for a scattering algorithm to be random bit optimal. As it turns out that previous solutions for scattering satisfy our condition, they are hence proved random bit optimal for the scattering problem. Then, we investigate the time complexity of scattering when strong multiplicity detection is not available. We prove that such algorithms cannot converge in constant time in the general case and in rounds for random bits optimal scattering algorithms. However, we present a family of scattering algorithms that converge as fast as needed without using multiplicity detection. Also, we put forward a specific protocol of this family that is random bit optimal ( random bits are used) and time optimal ( rounds are used). This improves the time complexity of previous results in the same setting by a factor. Aside from characterizing the random bit complexity of mobile robot scattering, our study also closes its time complexity gap with and without strong multiplicity detection (that is, time complexity is only achievable when strong multiplicity detection is available, and it is possible to approach it as needed otherwise).',
	 'authors': u'Quentin Bramas, S\xe9bastien Tixeuil,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6603',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nThe Random Bit Complexity of Mobile Robots Scattering',
	 'urllink': u'http://arxiv.org/abs/1309.6603'}
2015-03-24 18:55:09+0000 [xxu46_7] INFO: Crawled 771 pages (at 1 pages/min), scraped 764 items (at 1 items/min)
2015-03-24 18:55:38+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5786> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 18:55:38+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5786>
	{'abstract': u'We study the parameterized complexity of Split Contraction and Threshold Contraction. In these problems we are given a graph G and an integer k and asked whether G can be modified into a split graph or a threshold graph, respectively, by contracting at most k edges. We present an FPT algorithm for Split Contraction, and prove that Threshold Contraction on split graphs, i.e., contracting an input split graph to a threshold graph, is FPT when parameterized by the number of contractions. To give a complete picture, we show that these two problems admit no polynomial kernels unless NP subseteq coNP/poly.',
	 'authors': u'Leizhen Cai, Chengwei Guo,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5786',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nContracting Graphs to Split Graphs and Threshold Graphs',
	 'urllink': u'http://arxiv.org/abs/1310.5786'}
2015-03-24 18:56:09+0000 [xxu46_7] INFO: Crawled 772 pages (at 1 pages/min), scraped 765 items (at 1 items/min)
2015-03-24 18:57:09+0000 [xxu46_7] INFO: Crawled 772 pages (at 0 pages/min), scraped 765 items (at 0 items/min)
2015-03-24 18:57:20+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4687> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 18:57:20+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4687>
	{'abstract': u"Data is the central asset of today's dynamically operating organization and their business. This data is usually stored in database. A major consideration is applied on the security of that data from the unauthorized access and intruders. Data encryption is a strong option for security of data in database and especially in those organizations where security risks are high. But there is a potential disadvantage of performance degradation. When we apply encryption on database then we should compromise between the security and efficient query processing. The work of this paper tries to fill this gap. It allows the users to query over the encrypted column directly without decrypting all the records. It's improves the performance of the system. The proposed algorithm works well in the case of range and fuzzy match queries.",
	 'authors': u'Manish Sharma, Atul Chaudhary, Santosh Kumar,',
	 'category': u'Computer Science ',
	 'date': '2013-8-21',
	 'pdflink': u'http://arxiv.org/pdf/1308.4687',
	 'subjects': u'Databases (cs.DB)',
	 'title': u'\nQuery Processing Performance and Searching Over Encrypted Data By Using  An Efficient Algorithm',
	 'urllink': u'http://arxiv.org/abs/1308.4687'}
2015-03-24 18:58:09+0000 [xxu46_7] INFO: Crawled 773 pages (at 1 pages/min), scraped 766 items (at 1 items/min)
2015-03-24 18:59:06+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6584> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 18:59:06+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6584>
	{'abstract': u'This paper presents Wanderer, a model of how autonomous adaptive systems coordinate internal biological needs with moment-by-moment assessments of the probabilities of events in the external world. The extent to which Wanderer moves about or explores its environment reflects the relative activations of two competing motivational sub-systems: one represents the need to acquire energy and it excites exploration, and the other represents the need to avoid predators and it inhibits exploration. The environment contains food, predators, and neutral stimuli. Wanderer responds to these events in a way that is adaptive in the short turn, and reassesses the probabilities of these events so that it can modify its long term behaviour appropriately. When food appears, Wanderer be-comes satiated and exploration temporarily decreases. When a predator appears, Wanderer both decreases exploration in the short term, and becomes more "cautious" about exploring in the future. Wanderer also forms associations between neutral features and salient ones (food and predators) when they are present at the same time, and uses these associations to guide its behaviour.',
	 'authors': u'Liane Gabora,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6584',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nShould I Stay or Should I Go: Coordinating Biological Needs with  Continuously-updated Assessments of the Environment',
	 'urllink': u'http://arxiv.org/abs/1309.6584'}
2015-03-24 18:59:09+0000 [xxu46_7] INFO: Crawled 774 pages (at 1 pages/min), scraped 767 items (at 1 items/min)
2015-03-24 19:00:09+0000 [xxu46_7] INFO: Crawled 774 pages (at 0 pages/min), scraped 767 items (at 0 items/min)
2015-03-24 19:00:51+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5781> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 19:00:51+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5781>
	{'abstract': u'The ability for an autonomous agent to self-localise is directly proportional to the accuracy and precision with which it can perceive salient features within its local environment. The identification of such features by recognising geometric profile allows robustness against lighting variations, which is necessary in most industrial robotics applications. This paper details a framework by which the random sample consensus (RANSAC) algorithm, often applied to parameter fitting in linear models, can be extended to identify higher-order geometric features. Goalpost identification within humanoid robot soccer is investigated as an application, with the developed system yielding an order-of-magnitude improvement in classification performance relative to a traditional histogramming methodology.',
	 'authors': u'Madison Flannery, Shannon Fenn, David Budden,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5781',
	 'subjects': u'Robotics (cs.RO)',
	 'title': u'\nRANSAC: Identification of Higher-Order Geometric Features and  Applications in Humanoid Robot Soccer',
	 'urllink': u'http://arxiv.org/abs/1310.5781'}
2015-03-24 19:01:09+0000 [xxu46_7] INFO: Crawled 775 pages (at 1 pages/min), scraped 768 items (at 1 items/min)
2015-03-24 19:02:09+0000 [xxu46_7] INFO: Crawled 775 pages (at 0 pages/min), scraped 768 items (at 0 items/min)
2015-03-24 19:02:36+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4675> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 19:02:36+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4675>
	{'abstract': u'This paper explains genetic algorithm for novice in this field. Basic philosophy of genetic algorithm and its flowchart are described. Step by step numerical computation of genetic algorithm for solving simple mathematical equality problem will be briefly explained',
	 'authors': u'Denny Hermawanto,',
	 'category': u'Computer Science ',
	 'date': '2013-8-16',
	 'pdflink': u'http://arxiv.org/pdf/1308.4675',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nGenetic Algorithm for Solving Simple Mathematical Equality Problem',
	 'urllink': u'http://arxiv.org/abs/1308.4675'}
2015-03-24 19:03:09+0000 [xxu46_7] INFO: Crawled 776 pages (at 1 pages/min), scraped 769 items (at 1 items/min)
2015-03-24 19:04:09+0000 [xxu46_7] INFO: Crawled 776 pages (at 0 pages/min), scraped 769 items (at 0 items/min)
2015-03-24 19:04:31+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6576> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 19:04:31+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6576>
	{'abstract': u'While a number of data privacy techniques have been proposed in the recent years, a few frameworks have been suggested for the implementation of the data privacy process. Most of the proposed approaches are tailored towards implementing a specific data privacy algorithm but not the overall data privacy engineering and design process. Therefore, as a contribution, this study proposes SIED (Specification, Implementation, Evaluation, and Dissemination), a conceptual framework that takes a holistic approach to the data privacy engineering procedure by looking at the specifications, implementation, evaluation, and finally, dissemination of the privatized data sets.',
	 'authors': u'Kato Mivule,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6576',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nSIED, a Data Privacy Engineering Framework',
	 'urllink': u'http://arxiv.org/abs/1309.6576'}
2015-03-24 19:05:09+0000 [xxu46_7] INFO: Crawled 777 pages (at 1 pages/min), scraped 770 items (at 1 items/min)
2015-03-24 19:05:42+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5777> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 19:05:42+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5777>
	{'abstract': u"In our previous study (Wang et al., 2012), we analyzed scientists' working timetable of 3 countries, using realtime downloading data of scientific literatures. In this paper, we make a through analysis about global scientists' working habits. Top 30 countries/territories from Europe, Asia, Australia, North America, Latin America and Africa are selected as representatives and analyzed in detail. Regional differences for scientists' working habits exists in different countries. Besides different working cultures, social factors could affect scientists' research activities and working patterns. Nevertheless, a common conclusion is that scientists today are often working overtime. Although scientists may feel engaged and fulfilled about their hard working, working too much still warns us to reconsider the work - life balance.",
	 'authors': u'Xianwen Wang, Lian Peng, Chunbo Zhang, Shenmeng Xu, Zhi Wang, Chuanli Wang, Xianbing Wang,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5777',
	 'subjects': u'Digital Libraries (cs.DL)',
	 'title': u"\nExploring Scientists' Working Timetable: A Global Survey",
	 'urllink': u'http://arxiv.org/abs/1310.5777'}
2015-03-24 19:06:09+0000 [xxu46_7] INFO: Crawled 778 pages (at 1 pages/min), scraped 771 items (at 1 items/min)
2015-03-24 19:07:05+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4672> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 19:07:05+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4672>
	{'abstract': u'We propose dynamic resistive threshold-logic (DRTL) design based on non-volatile resistive memory. A threshold logic gate (TLG) performs summation of multiple inputs multiplied by a fixed set of weights and compares the sum with a threshold. DRTL employs resistive memory elements to implement the weights and the thresholds, while a compact dynamic CMOS latch is used for the comparison operation. The resulting DRTL gate acts as a low-power, configurable dynamic logic unit and can be used to build fully pipelined, high-performance programmable computing blocks. Multiple stages in such a DRTL design can be connected using energy-efficient low swing programmable interconnect networks based on resistive switches. Owing to memory-based compact logic and interconnect design and highspeed dynamic-pipelined operation, DRTL can achieve more than two orders of magnitude improvement in energy-delay product as compared to look-up table based CMOS FPGA.',
	 'authors': u'Mrigank Sharad, Deliang Fan, Kaushik Roy,',
	 'category': u'Computer Science ',
	 'date': '2013-8-8',
	 'pdflink': u'http://arxiv.org/pdf/1308.4672',
	 'subjects': u'Emerging Technologies (cs.ET)',
	 'title': u'\nUltra-low Energy, High-Performance Dynamic Resistive Threshold Logic',
	 'urllink': u'http://arxiv.org/abs/1308.4672'}
2015-03-24 19:07:09+0000 [xxu46_7] INFO: Crawled 779 pages (at 1 pages/min), scraped 772 items (at 1 items/min)
2015-03-24 19:08:09+0000 [xxu46_7] INFO: Crawled 779 pages (at 0 pages/min), scraped 772 items (at 0 items/min)
2015-03-24 19:09:00+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6550> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 19:09:00+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6550>
	{'abstract': u'The Bethe approximation is a well-known approximation of the partition function used in statistical physics. Recently, an equality relating the partition function and its Bethe approximation was obtained for graphical models with binary variables by Chertkov and Chernyak. In this equality, the multiplicative error in the Bethe approximation is represented as a weighted sum over all generalized loops in the graphical model. In this paper, the equality is generalized to graphical models with non-binary alphabet using concepts from information geometry.',
	 'authors': u'Ryuhei Mori,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6550',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nLoop Calculus for Non-Binary Alphabets using Concepts from Information  Geometry',
	 'urllink': u'http://arxiv.org/abs/1309.6550'}
2015-03-24 19:09:09+0000 [xxu46_7] INFO: Crawled 780 pages (at 1 pages/min), scraped 773 items (at 1 items/min)
2015-03-24 19:10:09+0000 [xxu46_7] INFO: Crawled 780 pages (at 0 pages/min), scraped 773 items (at 0 items/min)
2015-03-24 19:10:18+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5767> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 19:10:18+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5767>
	{'abstract': u"Salient object detection aims to locate objects that capture human attention within images. Previous approaches often pose this as a problem of image contrast analysis. In this work, we model an image as a hypergraph that utilizes a set of hyperedges to capture the contextual properties of image pixels or regions. As a result, the problem of salient object detection becomes one of finding salient vertices and hyperedges in the hypergraph. The main advantage of hypergraph modeling is that it takes into account each pixel's (or region's) affinity with its neighborhood as well as its separation from image background. Furthermore, we propose an alternative approach based on center-versus-surround contextual contrast analysis, which performs salient object detection by optimizing a cost-sensitive support vector machine (SVM) objective function. Experimental results on four challenging datasets demonstrate the effectiveness of the proposed approaches against the state-of-the-art approaches to salient object detection.",
	 'authors': u'Xi Li, Yao Li, Chunhua Shen, Anthony Dick, Anton van den Hengel,',
	 'category': u'Computer Science ',
	 'date': '2013-10-22',
	 'pdflink': u'http://arxiv.org/pdf/1310.5767',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nContextual Hypergraph Modelling for Salient Object Detection',
	 'urllink': u'http://arxiv.org/abs/1310.5767'}
2015-03-24 19:11:09+0000 [xxu46_7] INFO: Crawled 781 pages (at 1 pages/min), scraped 774 items (at 1 items/min)
2015-03-24 19:12:08+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4670> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 19:12:08+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4670>
	{'abstract': u'The Art Gallery Problem (AGP) asks for placing a minimum number of stationary guards in a polygonal region P, such that all points in P are guarded. The problem is known to be NP-hard, and its inherent continuous structure (with both the set of points that need to be guarded and the set of points that can be used for guarding being uncountably infinite) makes it difficult to apply a straightforward formulation as an Integer Linear Program. We use an iterative primal-dual relaxation approach for solving AGP instances to optimality. At each stage, a pair of LP relaxations for a finite candidate subset of primal covering and dual packing constraints and variables is considered; these correspond to possible guard positions and points that are to be guarded. Particularly useful are cutting planes for eliminating fractional solutions. We identify two classes of facets, based on Edge Cover and Set Cover (SC) inequalities. Solving the separation problem for the latter is NP-complete, but exploiting the underlying geometric structure, we show that large subclasses of fractional SC solutions cannot occur for the AGP. This allows us to separate the relevant subset of facets in polynomial time. We also characterize all facets for finite AGP relaxations with coefficients in . Finally, we demonstrate the practical usefulness of our approach. Our cutting plane technique yields a significant improvement in terms of speed and solution quality due to considerably reduced integrality gaps as compared to the approach by Kr "oller et al.',
	 'authors': u'S\xe1ndor P. Fekete, Stephan Friedrichs, Alexander Kr\xf6ller, Christiane Schmidt,',
	 'category': u'Computer Science ',
	 'date': '2013-8-21',
	 'pdflink': u'http://arxiv.org/pdf/1308.4670',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nFacets for Art Gallery Problems',
	 'urllink': u'http://arxiv.org/abs/1308.4670'}
2015-03-24 19:12:09+0000 [xxu46_7] INFO: Crawled 782 pages (at 1 pages/min), scraped 775 items (at 1 items/min)
2015-03-24 19:13:09+0000 [xxu46_7] INFO: Crawled 782 pages (at 0 pages/min), scraped 775 items (at 0 items/min)
2015-03-24 19:14:01+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6545> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 19:14:01+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6545>
	{'abstract': u'The history of infections and epidemics holds famous examples where understanding, containing and ultimately treating an outbreak began with understanding its mode of spread. Influenza, HIV and most computer viruses, spread person to person, device to device, through contact networks; Cholera, Cancer, and seasonal allergies, on the other hand, do not. In this paper we study two fundamental questions of detection: first, given a snapshot view of a (perhaps vanishingly small) fraction of those infected, under what conditions is an epidemic spreading via contact (e.g., Influenza), distinguishable from a "random illness" operating independently of any contact network (e.g., seasonal allergies); second, if we do have an epidemic, under what conditions is it possible to determine which network of interactions is the main cause of the spread -- the causative network -- without any knowledge of the epidemic, other than the identity of a minuscule subsample of infected nodes? The core, therefore, of this paper, is to obtain an understanding of the diagnostic power of network information. We derive sufficient conditions networks must satisfy for these problems to be identifiable, and produce efficient, highly scalable algorithms that solve these problems. We show that the identifiability condition we give is fairly mild, and in particular, is satisfied by two common graph topologies: the grid, and the Erdos-Renyi graphs.',
	 'authors': u'Chris Milling, Constantine Caramanis, Shie Mannor, Sanjay Shakkottai,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6545',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nDistinguishing Infections on Different Graph Topologies',
	 'urllink': u'http://arxiv.org/abs/1309.6545'}
2015-03-24 19:14:09+0000 [xxu46_7] INFO: Crawled 783 pages (at 1 pages/min), scraped 776 items (at 1 items/min)
2015-03-24 19:15:09+0000 [xxu46_7] INFO: Crawled 783 pages (at 0 pages/min), scraped 776 items (at 0 items/min)
2015-03-24 19:15:47+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5755> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 19:15:47+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5755>
	{'abstract': u'In this contribution, a novel method for stent simulation in preoperative computed tomography angiography (CTA) acquisitions of patients is presented where the sealing zones are automatically calculated and visualized. The method is eligible for non-bifurcated and bifurcated stents (Y-stents). Results of the proposed stent simulation with an automatic calculation of the sealing zones for specific diseases (abdominal aortic aneurysms (AAA), thoracic aortic aneurysms (TAA), iliac aneurysms) are presented. The contribution is organized as follows. Section 2 presents the proposed approach. In Section 3, experimental results are discussed. Section 4 concludes the contribution and outlines areas for future work.',
	 'authors': u'Jan Egger, Miriam H. A. Bauer, Stefan Gro\xdfkopf, Christina Biermann, Bernd Freisleben, Christopher Nimsky,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5755',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nDetermination, Calculation and Representation of the Upper and Lower  Sealing Zones During Virtual Stenting of Aneurysms',
	 'urllink': u'http://arxiv.org/abs/1310.5755'}
2015-03-24 19:16:09+0000 [xxu46_7] INFO: Crawled 784 pages (at 1 pages/min), scraped 777 items (at 1 items/min)
2015-03-24 19:17:09+0000 [xxu46_7] INFO: Crawled 784 pages (at 0 pages/min), scraped 777 items (at 0 items/min)
2015-03-24 19:17:47+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4648> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 19:17:47+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4648>
	{'abstract': u'Public disclosure of important security information, such as knowledge of vulnerabilities or exploits, often occurs in blogs, tweets, mailing lists, and other online sources months before proper classification into structured databases. In order to facilitate timely discovery of such knowledge, we propose a novel semi-supervised learning algorithm, PACE, for identifying and classifying relevant entities in text sources. The main contribution of this paper is an enhancement of the traditional bootstrapping method for entity extraction by employing a time-memory trade-off that simultaneously circumvents a costly corpus search while strengthening pattern nomination, which should increase accuracy. An implementation in the cyber-security domain is discussed as well as challenges to Natural Language Processing imposed by the security domain.',
	 'authors': u'Nikki McNeil, Robert A. Bridges, Michael D. Iannacone, Bogdan Czejdo, Nicolas Perez, John R. Goodall,',
	 'category': u'Computer Science ',
	 'date': '2013-8-21',
	 'pdflink': u'http://arxiv.org/pdf/1308.4648',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nPACE: Pattern Accurate Computationally Efficient Bootstrapping for  Timely Discovery of Cyber-Security Concepts',
	 'urllink': u'http://arxiv.org/abs/1308.4648'}
2015-03-24 19:18:09+0000 [xxu46_7] INFO: Crawled 785 pages (at 1 pages/min), scraped 778 items (at 1 items/min)
2015-03-24 19:19:09+0000 [xxu46_7] INFO: Crawled 785 pages (at 0 pages/min), scraped 778 items (at 0 items/min)
2015-03-24 19:19:44+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6527> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 19:19:44+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6527>
	{'abstract': u"This article focuses on the importance of the precise calculation of similarity factors between papers and reviewers for performing a fair and accurate automatic assignment of reviewers to papers. It suggests that papers and reviewers' competences should be described by taxonomy of keywords so that the implied hierarchical structure allows similarity measures to take into account not only the number of exactly matching keywords, but in case of non-matching ones to calculate how semantically close they are. The paper also suggests a similarity measure derived from the well-known and widely-used Dice's coefficient, but adapted in a way it could be also applied between sets whose elements are semantically related to each other (as concepts in taxonomy are). It allows a non-zero similarity factor to be accurately calculated between a paper and a reviewer even if they do not share any keyword in common.",
	 'authors': u'Yordan Kalmukov,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6527',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u"\nDescribing Papers and Reviewers' Competences by Taxonomy of Keywords",
	 'urllink': u'http://arxiv.org/abs/1309.6527'}
2015-03-24 19:20:09+0000 [xxu46_7] INFO: Crawled 786 pages (at 1 pages/min), scraped 779 items (at 1 items/min)
2015-03-24 19:21:09+0000 [xxu46_7] INFO: Crawled 786 pages (at 0 pages/min), scraped 779 items (at 0 items/min)
2015-03-24 19:21:45+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5747> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 19:21:45+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5747>
	{'abstract': u'The understanding of Boolean automata networks dynamics takes an important place in various domains of computer science such as computability, complexity and discrete dynamical systems. In this paper, we make a step further in this understanding by focusing on their cycles, whose necessity in networks is known as the brick of their complexity. We present new results that provide a characterisation of the transient and asymptotic dynamics, i.e. of the computational abilities, of asynchronous Boolean automata networks composed of two cycles that intersect at one automaton, the so-called double-cycles. To do so, we introduce an efficient formalism inspired by algorithms to define long sequences of updates, that allows a better description of their dynamics than previous works in this area.',
	 'authors': u'Tarek Melliti, Mathilde Noual, Damien Regnault, Sylvain Sen\xe9, J\xe9r\xe9my Sobieraj,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5747',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nFull characterisation of attractors of two intersected asynchronous  Boolean automata cycles',
	 'urllink': u'http://arxiv.org/abs/1310.5747'}
2015-03-24 19:22:09+0000 [xxu46_7] INFO: Crawled 787 pages (at 1 pages/min), scraped 780 items (at 1 items/min)
2015-03-24 19:23:09+0000 [xxu46_7] INFO: Crawled 787 pages (at 0 pages/min), scraped 780 items (at 0 items/min)
2015-03-24 19:23:44+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4643> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 19:23:44+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4643>
	{'abstract': u"The spreading of dangerous malware or faults in inter-dependent networks of electronics devices has raised deep concern, because from the ICT networks infections may propagate to other Critical Infrastructures producing the well-known domino or cascading effect. Researchers are attempting to develop a high level analysis of malware propagation discarding software details, in order to generalize to the maximum extent the defensive strategies. For example, it has been suggested that the maximum eigenvalue of the network adjacency matrix could act as a threshold for the malware's spreading. This leads naturally to use the spectral graph theory to identify the most critical and influential nodes in technological networks. Many well-known graph parameters have been studied in the past years to accomplish the task. Here we test our AV11 algorithm showing that outperforms degree, closeness, betweenness centrality and the dynamical importance",
	 'authors': u'Enzo Fioriti, Marta Chnnici, Andrea Arbore,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/pdf/1308.4643',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nTopological security assessment of technological networks',
	 'urllink': u'http://arxiv.org/abs/1308.4643'}
2015-03-24 19:24:09+0000 [xxu46_7] INFO: Crawled 788 pages (at 1 pages/min), scraped 781 items (at 1 items/min)
2015-03-24 19:25:09+0000 [xxu46_7] INFO: Crawled 788 pages (at 0 pages/min), scraped 781 items (at 0 items/min)
2015-03-24 19:25:45+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6504> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 19:25:45+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6504>
	{'abstract': u'The game of SET is a popular card game in which the objective is to form Sets using cards from a special deck. In this paper we study single- and multi-round variations of this game from the computational complexity point of view and establish interesting connections with other classical computational problems. Specifically, we first show that a natural generalization of the problem of finding a single Set, parameterized by the size of the sought Set is W-hard; our reduction applies also to a natural parameterization of Perfect Multi-Dimensional Matching, a result which may be of independent interest. Second, we observe that a version of the game where one seeks to find the largest possible number of disjoint Sets from a given set of cards is a special case of 3-Set Packing; we establish that this restriction remains NP-complete. Similarly, the version where one seeks to find the smallest number of disjoint Sets that overlap all possible Sets is shown to be NP-complete, through a close connection to the Independent Edge Dominating Set problem. Finally, we study a 2-player version of the game, for which we show a close connection to Arc Kayles, as well as fixed-parameter tractability when parameterized by the number of rounds played.',
	 'authors': u'Michael Lampis, Valia Mitsou,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6504',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nThe Computational Complexity of the Game of Set and its Theoretical  Applications',
	 'urllink': u'http://arxiv.org/abs/1309.6504'}
2015-03-24 19:26:09+0000 [xxu46_7] INFO: Crawled 789 pages (at 1 pages/min), scraped 782 items (at 1 items/min)
2015-03-24 19:26:52+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5746> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 19:26:52+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5746>
	{'abstract': u'Knowledge Compilation (KC) studies compilation of boolean functions f into some formalism F, which allows to answer all queries of a certain kind in polynomial time. Due to its relevance for SAT solving, we concentrate on the query type "clausal entailment" (CE), i.e., whether a clause C follows from f or not, and we consider subclasses of CNF, i.e., clause-sets F with special properties. In this report we do not allow auxiliary variables (except of the Outlook), and thus F needs to be equivalent to f. We consider the hierarchies UC_k &lt;= WC_k, which were introduced by the authors in 2012. Each level allows CE queries. The first two levels are well-known classes for KC. Namely UC_0 = WC_0 is the same as PI as studied in KC, that is, f is represented by the set of all prime implicates, while UC_1 = WC_1 is the same as UC, the class of unit-refutation complete clause-sets introduced by del Val 1994. We show that for each k there are (sequences of) boolean functions with polysize representations in UC_, but with an exponential lower bound on representations in WC_k. Such a separation was previously only know for k=0. We also consider PC &lt; UC, the class of propagation-complete clause-sets. We show that there are (sequences of) boolean functions with polysize representations in UC, while there is an exponential lower bound for representations in PC. These separations are steps towards a general conjecture determining the representation power of the hierarchies PC_k &lt; UC_k &lt;= WC_k. The strong form of this conjecture also allows auxiliary variables, as discussed in depth in the Outlook.',
	 'authors': u'Matthew Gwynne, Oliver Kullmann,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5746',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nTrading inference effort versus size in CNF Knowledge Compilation',
	 'urllink': u'http://arxiv.org/abs/1310.5746'}
2015-03-24 19:27:09+0000 [xxu46_7] INFO: Crawled 790 pages (at 1 pages/min), scraped 783 items (at 1 items/min)
2015-03-24 19:28:09+0000 [xxu46_7] INFO: Crawled 790 pages (at 0 pages/min), scraped 783 items (at 0 items/min)
2015-03-24 19:28:10+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4618> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 19:28:10+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4618>
	{'abstract': u'A constant influx of new data poses a challenge in keeping the annotation in biological databases current. Most biological databases contain significant quantities of textual annotation, which often contains the richest source of knowledge. Many databases reuse existing knowledge, during the curation process annotations are often propagated between entries. However, this is often not made explicit. Therefore, it can be hard, potentially impossible, for a reader to identify where an annotation originated from. Within this work we attempt to identify annotation provenance and track its subsequent propagation. Specifically, we exploit annotation reuse within the UniProt Knowledgebase (UniProtKB), at the level of individual sentences. We describe a visualisation approach for the provenance and propagation of sentences in UniProtKB which enables a large-scale statistical analysis. Initially levels of sentence reuse within UniProtKB were analysed, showing that reuse is heavily prevalent, which enables the tracking of provenance and propagation. By analysing sentences throughout UniProtKB, a number of interesting propagation patterns were identified, covering over 100, 000 sentences. Over 8000 sentences remain in the database after they have been removed from the entries where they originally occurred. Analysing a subset of these sentences suggest that approximately 30% are erroneous, whilst 35% appear to be inconsistent. These results suggest that being able to visualise sentence propagation and provenance can aid in the determination of the accuracy and quality of textual annotation. Source code and supplementary data are available from the authors website.',
	 'authors': u'Michael J. Bell, Matthew Collison, Phillip Lord,',
	 'category': u'Computer Science ',
	 'date': '2013-8-21',
	 'pdflink': u'http://arxiv.org/pdf/1308.4618',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nCan inferred provenance and its visualisation be used to detect  erroneous annotation? A case study using UniProtKB',
	 'urllink': u'http://arxiv.org/abs/1308.4618'}
2015-03-24 19:29:09+0000 [xxu46_7] INFO: Crawled 791 pages (at 1 pages/min), scraped 784 items (at 1 items/min)
2015-03-24 19:29:46+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6487> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 19:29:46+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6487>
	{'abstract': u'In this paper, we propose a general framework to address two problems in Sparse Subspace Clustering (SSC) and Low Rank Representation (LRR), i.e., scalability issue and out-of-sample problem. SSC and LRR are two recently proposed subspace clustering algorithms which construct a similarity graph for spectral clustering by using the sparsest and the lowest-rank coefficients, respectively. SSC and LRR have achieved state-of-the-art results in data clustering. However, their time complexities are very high so that it is inefficient to apply them to large scale data set. Moreover, SSC and LRR cannot cope with out-of-sample data that are not used to construct the similarity graph. For each new datum, they must recalculate the sparsest/lowest-rank coefficients and membership assignment matrix of the whole data set. This makes SSC and LRR not competitive to fast online learning algorithm. To overcome these problems, we propose a simple but effective method which makes SSC and LRR feasible to grouping new data and large scale data. The solution of our method adopts a "sampling, clustering, coding, and classifying" strategy. Specifically, we split the data into two parts, in-sample data and out-of-sample data, where out-of-sample data are located at the subspaces spanned by in-sample data; and obtain the cluster membership of in-sample data; after that, assign each out-of-sample datum to the nearest subspace that produces the minimal reconstruction error. Both theoretical analysis and experimental results show the efficacy of our methods.',
	 'authors': u'Xi Peng, Lei Zhang, Zhang Yi,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6487',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nAn Out-of-sample Extension of Sparse Subspace Clustering and Low Rank  Representation for Clustering Large Scale Data Sets',
	 'urllink': u'http://arxiv.org/abs/1309.6487'}
2015-03-24 19:30:09+0000 [xxu46_7] INFO: Crawled 792 pages (at 1 pages/min), scraped 785 items (at 1 items/min)
2015-03-24 19:31:09+0000 [xxu46_7] INFO: Crawled 792 pages (at 0 pages/min), scraped 785 items (at 0 items/min)
2015-03-24 19:31:36+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5714> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 19:31:36+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5714>
	{'abstract': u'In this note we show that any -CNF which can be refuted by a quasi-polynomial refutation has a "narrow" refutation in (i.e., of poly-logarithmic width). We also show the converse implication: a narrow Resolution refutation can be simulated by a short refutation. The author does not claim priority on this result. The technical part of this note bears similarity with the relation between -depth Frege refutations and tree-like -depth Frege refutations outlined in (Kraj \'i vek 1994, Journal of Symbolic Logic 59, 73). Part of it had already been specialized to and in (Esteban et al. 2004, Theor. Comput. Sci. 321, 347).',
	 'authors': u'Massimo Lauria,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5714',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nShort $\\mathsf{Res}^*(\\mathsf{polylog})$ refutations if and only if  narrow $\\mathsf{Res}$ refutations',
	 'urllink': u'http://arxiv.org/abs/1310.5714'}
2015-03-24 19:32:09+0000 [xxu46_7] INFO: Crawled 793 pages (at 1 pages/min), scraped 786 items (at 1 items/min)
2015-03-24 19:33:09+0000 [xxu46_7] INFO: Crawled 793 pages (at 0 pages/min), scraped 786 items (at 0 items/min)
2015-03-24 19:33:31+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4572> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 19:33:31+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4572>
	{'abstract': u'We consider the problem of slotted asynchronous coded communication, where in each time frame (slot), the transmitter is either silent or transmits a codeword from a given (randomly selected) codebook. The task of the decoder is to decide whether transmission has taken place, and if so, to decode the message. We derive the optimum detection/decoding rule in the sense of the best trade-off among the probabilities of decoding error, false alarm, and misdetection. For this detection/decoding rule, we then derive single-letter characterizations of the exact exponential rates of these three probabilities for the average code in the ensemble.',
	 'authors': u'Neri Merhav,',
	 'category': u'Computer Science ',
	 'date': '2013-8-21',
	 'pdflink': u'http://arxiv.org/pdf/1308.4572',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nCodeword or noise? Exact random coding exponents for slotted  asynchronism',
	 'urllink': u'http://arxiv.org/abs/1308.4572'}
2015-03-24 19:34:09+0000 [xxu46_7] INFO: Crawled 794 pages (at 1 pages/min), scraped 787 items (at 1 items/min)
2015-03-24 19:35:06+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6484> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 19:35:06+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6484>
	{'abstract': u'The control of a network of signalized intersections is considered. Previous work demonstrates that the so-called back-pressure control provides stability guarantees, assuming infinite queues capacities. In this paper, we highlight the failing of current back-pressure control under finite capacities by identifying sources of non work-conservation and congestion propagation. We propose the use of a normalized pressure which guarantees work conservation and mitigates congestion propagation, while ensuring fairness at low traffic densities, and recovering original back-pressure as capacities grow to infinity. This capacity-aware back-pressure control allows to improve performance as congestion increases, as indicated by simulation results, and keeps the key benefits of back-pressure: ability to be distributed over intersections and O(1) complexity.',
	 'authors': u'Jean Gregoire, Xiangjun Qian, Emilio Frazzoli, Arnaud de La Fortelle, Tichakorn Wongpiromsarn,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6484',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nCapacity-aware back-pressure traffic signal control',
	 'urllink': u'http://arxiv.org/abs/1309.6484'}
2015-03-24 19:35:09+0000 [xxu46_7] INFO: Crawled 795 pages (at 1 pages/min), scraped 788 items (at 1 items/min)
2015-03-24 19:35:55+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5698> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 19:35:55+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5698>
	{'abstract': u"Keyword based search engines have problems with term ambiguity and vocabulary mismatch. In this paper, we propose a query expansion technique that enriches queries expressed as keywords and short natural language descriptions. We present a new massive query expansion strategy that enriches queries using a knowledge base by identifying the query concepts, and adding relevant synonyms and semantically related terms. We propose two approaches: (i) lexical expansion that locates the relevant concepts in the knowledge base; and, (ii) topological expansion that analyzes the network of relations among the concepts, and suggests semantically related terms by path and community analysis of the knowledge graph. We perform our expansions by using two versions of the Wikipedia as knowledge base, concluding that the combination of both lexical and topological expansion provides improvements of the system's precision up to more than 27%.",
	 'authors': u'Joan Guisado-G\xe1mez, David Dominguez-Sal, Josep-LLuis Larriba-Pey,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5698',
	 'subjects': u'Information Retrieval (cs.IR)',
	 'title': u'\nMassive Query Expansion by Exploiting Graph Knowledge Bases',
	 'urllink': u'http://arxiv.org/abs/1310.5698'}
2015-03-24 19:36:09+0000 [xxu46_7] INFO: Crawled 796 pages (at 1 pages/min), scraped 789 items (at 1 items/min)
2015-03-24 19:37:09+0000 [xxu46_7] INFO: Crawled 796 pages (at 0 pages/min), scraped 789 items (at 0 items/min)
2015-03-24 19:37:24+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4568> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 19:37:24+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4568>
	{'abstract': u'In this paper we propose a novel framework for decentralized, online learning by many learners. At each moment of time, an instance characterized by a certain context may arrive to each learner; based on the context, the learner can select one of its own actions (which gives a reward and provides information) or request assistance from another learner. In the latter case, the requester pays a cost and receives the reward but the provider learns the information. In our framework, learners are modeled as cooperative contextual bandits. Each learner seeks to maximize the expected reward from its arrivals, which involves trading off the reward received from its own actions, the information learned from its own actions, the reward received from the actions requested of others and the cost paid for these actions - taking into account what it has learned about the value of assistance from each other learner. We develop distributed online learning algorithms and provide analytic bounds to compare the efficiency of these with algorithms with the complete knowledge (oracle) benchmark (in which the expected reward of every action in every context is known by every learner). Our estimates show that regret - the loss incurred by the algorithm - is sublinear in time. Our theoretical framework can be used in many practical applications including Big Data mining, event detection in surveillance sensor networks and distributed online recommendation systems.',
	 'authors': u'Cem Tekin, Mihaela van der Schaar,',
	 'category': u'Computer Science ',
	 'date': '2013-8-21',
	 'pdflink': u'http://arxiv.org/pdf/1308.4568',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nDistributed Online Learning via Cooperative Contextual Bandits',
	 'urllink': u'http://arxiv.org/abs/1308.4568'}
2015-03-24 19:38:09+0000 [xxu46_7] INFO: Crawled 797 pages (at 1 pages/min), scraped 790 items (at 1 items/min)
2015-03-24 19:38:22+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6477> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 19:38:22+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6477>
	{'abstract': u'Bin covering is a dual version of classic bin packing. Thus, the goal is to cover as many bins as possible, where covering a bin means packing items of total size at least one in the bin. For online bin covering, competitive analysis fails to distinguish between most algorithms of interest; all "reasonable" algorithms have a competitive ratio of 1/2. Thus, in order to get a better understanding of the combinatorial difficulties in solving this problem, we turn to other performance measures, namely relative worst order, random order, and max/max analysis, as well as analyzing input with restricted or uniformly distributed item sizes. In this way, our study also supplements the ongoing systematic studies of the relative strengths of various performance measures. Two classic algorithms for online bin packing that have natural dual versions are Harmonic and Next-Fit. Even though the algorithms are quite different in nature, the dual versions are not separated by competitive analysis. We make the case that when guarantees are needed, even under restricted input sequences, dual Harmonic is preferable. In addition, we establish quite robust theoretical results showing that if items come from a uniform distribution or even if just the ordering of items is uniformly random, then dual Next-Fit is the right choice.',
	 'authors': u'Marie G. Christ, Lene M. Favrholdt, Kim S. Larsen,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6477',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nOnline Bin Covering: Expectations vs. Guarantees',
	 'urllink': u'http://arxiv.org/abs/1309.6477'}
2015-03-24 19:39:09+0000 [xxu46_7] INFO: Crawled 798 pages (at 1 pages/min), scraped 791 items (at 1 items/min)
2015-03-24 19:40:05+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5697> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 19:40:05+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5697>
	{'abstract': u'Binary logic and devices have been in used since inception with advancement and technology and millennium gate design era. The development in binary logic has become tedious and cumbersome. Multivalued logic enables significant more information to be packed within a single digit. The design and development of logic circuit becomes very compact and easier. Attempts are being made to fabricate multivalued logic based devices. Since present devices can be implemented only in binary system,it is necessary to evolve a system that can built the circuit in multivalued logic system and convert in binary logic system. In multivalued logic system logic gates differ in different logic system, a quaternary has become mature in terms of logic algebra and gates. Hence logic design based on above system can be done using standard procedure. In this dissertation a logic circuit design entry based on multivalued logic system has been taken up that can provide the ease of circuit design in multivalued system and output as binary valued circuit. The named "MVL-DEV" offers editing, storage and conversion into binary facility.',
	 'authors': u'Hitesh Gupta, Dr. S.C. Jain,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5697',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nMultivalued Logic Circuit Design for Binary Logic Interface',
	 'urllink': u'http://arxiv.org/abs/1310.5697'}
2015-03-24 19:40:09+0000 [xxu46_7] INFO: Crawled 799 pages (at 1 pages/min), scraped 792 items (at 1 items/min)
2015-03-24 19:41:09+0000 [xxu46_7] INFO: Crawled 799 pages (at 0 pages/min), scraped 792 items (at 0 items/min)
2015-03-24 19:41:49+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4565> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 19:41:49+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4565>
	{'abstract': u"Distributed, online data mining systems have emerged as a result of applications requiring analysis of large amounts of correlated and high-dimensional data produced by multiple distributed data sources. We propose a distributed online data classification framework where data is gathered by distributed data sources and processed by a heterogeneous set of distributed learners which learn online, at run-time, how to classify the different data streams either by using their locally available classification functions or by helping each other by classifying each other's data. Importantly, since the data is gathered at different locations, sending the data to another learner to process incurs additional costs such as delays, and hence this will be only beneficial if the benefits obtained from a better classification will exceed the costs. We assume that the classification functions available to each processing element are fixed, but their prediction accuracy for various types of incoming data are unknown and can change dynamically over time, and thus they need to be learned online. We model the problem of joint classification by the distributed and heterogeneous learners from multiple data sources as a distributed contextual bandit problem where each data is characterized by a specific context. We develop distributed online learning algorithms for which we can prove that they have sublinear regret. Compared to prior work in distributed online data mining, our work is the first to provide analytic regret results characterizing the performance of the proposed algorithms.",
	 'authors': u'Cem Tekin, Mihaela van der Schaar,',
	 'category': u'Computer Science ',
	 'date': '2013-8-21',
	 'pdflink': u'http://arxiv.org/pdf/1308.4565',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nDecentralized Online Big Data Classification - a Bandit Framework',
	 'urllink': u'http://arxiv.org/abs/1308.4565'}
2015-03-24 19:42:09+0000 [xxu46_7] INFO: Crawled 800 pages (at 1 pages/min), scraped 793 items (at 1 items/min)
2015-03-24 19:43:09+0000 [xxu46_7] INFO: Crawled 800 pages (at 0 pages/min), scraped 793 items (at 0 items/min)
2015-03-24 19:43:36+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6474> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 19:43:36+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6474>
	{'abstract': u'The Generalized Second Price (GSP) auction used typically to model sponsored search auctions does not include the notion of budget constraints, which is present in practice. Motivated by this, we introduce the different variants of GSP auctions that take budgets into account in natural ways. We examine their stability by focusing on the existence of Nash equilibria and envy-free assignments. We highlight the differences between these mechanisms and find that only some of them exhibit both notions of stability. This shows the importance of carefully picking the right mechanism to ensure stable outcomes in the presence of budgets',
	 'authors': u'Josep Diaz, Ioannis Giotis, Lefteris Kirousis, Evangelos Markakis, Maria Serna,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6474',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nOn the Stability of Generalized Second Price Auctions with Budgets',
	 'urllink': u'http://arxiv.org/abs/1309.6474'}
2015-03-24 19:44:09+0000 [xxu46_7] INFO: Crawled 801 pages (at 1 pages/min), scraped 794 items (at 1 items/min)
2015-03-24 19:45:09+0000 [xxu46_7] INFO: Crawled 801 pages (at 0 pages/min), scraped 794 items (at 0 items/min)
2015-03-24 19:45:21+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5695> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 19:45:21+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5695>
	{'abstract': u'Crowd sensing is a new paradigm which leverages a large number of sensor-equipped mobile phones to collect sensing data. To attract more participants to provide good quality, bidding mechanisms that solicit the Vickrey-Clarke-Groves (VCG) mechanism and its variants are natural fits for crowd sensing applications in mobile social networks. However, in practical continuous crowd sensing applications, where bids cannot be solicited and only posted pricing mechanisms can be implemented. Obviously, these mechanisms for continuous crowd sensing are not applicable. To tackle the issue, we propose a collection-behavior based multi-parameter posted pricing mechanism, not only to consider extensive user participating and sensing data submission quality under given budget constraints by applying all-pay auctions and posted pricing mechanisms, but also to maximize the coverage utilities by applying crowd aversion. Simulation results indicate that incentive mechanisms in our proposed framework outperform the best existing solution.',
	 'authors': u'Jiajun Sun,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/e-print/1310.5695',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nCollection-behavior based Multi-parameter Posted Pricing Mechanism for  Crowd Sensing',
	 'urllink': u'http://arxiv.org/abs/1310.5695'}
2015-03-24 19:46:09+0000 [xxu46_7] INFO: Crawled 802 pages (at 1 pages/min), scraped 795 items (at 1 items/min)
2015-03-24 19:46:52+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4560> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 19:46:52+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4560>
	{'abstract': u'In this paper, throughput and energy efficiency of cognitive multiple-input multiple-output (MIMO) systems operating under quality-of-service (QoS) constraints, interference limitations, and imperfect channel sensing, are studied. It is assumed that transmission power and covariance of the input signal vectors are varied depending on the sensed activities of primary users (PUs) in the system. Interference constraints are applied on the transmission power levels of cognitive radios (CRs) to provide protection for the PUs whose activities are modeled as a Markov chain. Considering the reliability of the transmissions and channel sensing results, a state-transition model is provided. Throughput is determined by formulating the effective capacity. First derivative of the effective capacity is derived in the low-power regime and the minimum bit energy requirements in the presence of QoS limitations and imperfect sensing results are identified. Minimum energy per bit is shown to be achieved by beamforming in the maximal-eigenvalue eigenspace of certain matrices related to the channel matrix. In a special case, wideband slope is determined for more refined analysis of energy efficiency. Numerical results are provided for the throughput for various levels of buffer constraints and different number of transmit and receive antennas. The impact of interference constraints and benefits of multiple-antenna transmissions are determined. It is shown that increasing the number of antennas when the interference power constraint is stringent is generally beneficial. On the other hand, it is shown that under relatively loose interference constraints, increasing the number of antennas beyond a certain level does not lead to much increase in the throughput.',
	 'authors': u'Sami Akin, Mustafa Cenk Gursoy,',
	 'category': u'Computer Science ',
	 'date': '2013-8-21',
	 'pdflink': u'http://arxiv.org/pdf/1308.4560',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOn the Throughput and Energy Efficiency of Cognitive MIMO Transmissions',
	 'urllink': u'http://arxiv.org/abs/1308.4560'}
2015-03-24 19:47:09+0000 [xxu46_7] INFO: Crawled 803 pages (at 1 pages/min), scraped 796 items (at 1 items/min)
2015-03-24 19:48:09+0000 [xxu46_7] INFO: Crawled 803 pages (at 0 pages/min), scraped 796 items (at 0 items/min)
2015-03-24 19:48:44+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6471> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 19:48:44+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6471>
	{'abstract': u'Given a tree and a set P of non-trivial simple paths on it, VPT(P) is the VPT graph (i.e. the vertex intersection graph) of the paths P, and EPT(P) is the EPT graph (i.e. the edge intersection graph) of P. These graphs have been extensively studied in the literature. Given two (edge) intersecting paths in a graph, their split vertices is the set of vertices having degree at least 3 in their union. A pair of (edge) intersecting paths is termed non-splitting if they do not have split vertices (namely if their union is a path). We define the graph ENPT(P) of edge intersecting non-splitting paths of a tree, termed the ENPT graph, as the graph having a vertex for each path in P, and an edge between every pair of vertices representing two paths that are both edge-intersecting and non-splitting. A graph G is an ENPT graph if there is a tree T and a set of paths P of T such that G=ENPT(P), and we say that &lt;T,P&gt; is a representation of G. Our goal is to characterize the representation of chordless ENPT cycles (holes). To achieve this goal, we first assume that the EPT graph induced by the vertices of an ENPT hole is given. In [2] we introduce three assumptions (P1), (P2), (P3) defined on EPT, ENPT pairs of graphs. In the same study, we define two problems HamiltonianPairRec, P3-HamiltonianPairRec and characterize the representations of ENPT holes that satisfy (P1), (P2), (P3). In this work, we continue our work by relaxing these three assumptions one by one. We characterize the representations of ENPT holes satisfying (P3) by providing a polynomial-time algorithm to solve P3-HamiltonianPairRec. We also show that there does not exist a polynomial-time algorithm to solve HamiltonianPairRec, unless P=NP.',
	 'authors': u'Arman Boyac\u0131, T\\inaz Ekim, Mordechai Shalom, Shmuel Zaks,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6471',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nGraphs of Edge-Intersecting Non-Splitting Paths in a Tree:  Representations of Holes-Part II',
	 'urllink': u'http://arxiv.org/abs/1309.6471'}
2015-03-24 19:49:09+0000 [xxu46_7] INFO: Crawled 804 pages (at 1 pages/min), scraped 797 items (at 1 items/min)
2015-03-24 19:50:09+0000 [xxu46_7] INFO: Crawled 804 pages (at 0 pages/min), scraped 797 items (at 0 items/min)
2015-03-24 19:50:32+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5684> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 19:50:32+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5684>
	{'abstract': u'We reduce the problem of constructing asymptotically good tree codes to the construction of triangular totally positive matrices over fields with polynomially many elements. We show a connection of this problem to Birkhoff interpolation in finite fields.',
	 'authors': u'Pavel Pudl\xe1k,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5684',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nLinear tree codes and the problem of explicit constructions',
	 'urllink': u'http://arxiv.org/abs/1310.5684'}
2015-03-24 19:51:09+0000 [xxu46_7] INFO: Crawled 805 pages (at 1 pages/min), scraped 798 items (at 1 items/min)
2015-03-24 19:52:09+0000 [xxu46_7] INFO: Crawled 805 pages (at 0 pages/min), scraped 798 items (at 0 items/min)
2015-03-24 19:52:20+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4534> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 19:52:20+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4534>
	{'abstract': u'The Hospitals / Residents problem with Couples (HRC) is a generalisation of the classical Hospitals / Resident problem (HR) that is important in practical applications because it models the case where couples submit joint preference lists over pairs of (typically geographically close) hospitals. In this paper we give a new NP-completeness result for the problem of deciding whether a stable matching exists, in highly restricted instances of HRC. Further, we present an Integer Programming (IP) model for HRC and extend it the case where preference lists can include ties. Also, we describe an empirical study of an IP model or HRC and its extension to the case where preference lists can include ties. This model was applied to randomly generated instances and also real-world instances arising from previous matching runs of the Scottish Foundation Allocation Scheme, used to allocate junior doctors to hospitals in Scotland.',
	 'authors': u'P. Biro, D. F. Manlove, I. McBride,',
	 'category': u'Computer Science ',
	 'date': '2013-8-21',
	 'pdflink': u'http://arxiv.org/pdf/1308.4534',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nThe Hospitals / Residents Problem with Couples: Complexity and Integer  Programming Models',
	 'urllink': u'http://arxiv.org/abs/1308.4534'}
2015-03-24 19:53:09+0000 [xxu46_7] INFO: Crawled 806 pages (at 1 pages/min), scraped 799 items (at 1 items/min)
2015-03-24 19:54:03+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6468> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 19:54:03+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6468>
	{'abstract': u"In this paper, we explore new area/throughput trade- offs for the Girault, Poupard and Stern authentication protocol (GPS). This authentication protocol was selected in the NESSIE competition and is even part of the standard ISO/IEC 9798. The originality of our work comes from the fact that we exploit a fixed key to increase the throughput. It leads us to implement GPS using the Chapman constant multiplier. This parallel implementation is 40 times faster but 10 times bigger than the reference serial one. We propose to serialize this multiplier to reduce its area at the cost of lower throughput. Our hybrid Chapman's multiplier is 8 times faster but only twice bigger than the reference. Results presented here allow designers to adapt the performance of GPS authentication to their hardware resources. The complete GPS prover side is also integrated in the network stack of the PowWow sensor which contains an Actel IGLOO AGL250 FPGA as a proof of concept.",
	 'authors': u'Micka\xebl Dardaillon, C\xe9dric Lauradoux, Tanguy Risset,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6468',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nHardware Implementation of the GPS authentication',
	 'urllink': u'http://arxiv.org/abs/1309.6468'}
2015-03-24 19:54:09+0000 [xxu46_7] INFO: Crawled 807 pages (at 1 pages/min), scraped 800 items (at 1 items/min)
2015-03-24 19:55:09+0000 [xxu46_7] INFO: Crawled 807 pages (at 0 pages/min), scraped 800 items (at 0 items/min)
2015-03-24 19:56:00+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5670> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 19:56:00+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5670>
	{'abstract': u'It was the problem of finding the minimum value of the sum of the distances of the path through all cities Overview TSP. We propose an authentication with the problem that the deformation sum of the distances of the path to be a constant value. In this document, it is intended to construct an authentication function robust implementation is easy and the Blog. After it was shown that the first, to determine the replacement group and path are the same, we propose the authentication method to consider the deformation of the traveling salesman problem in the directed graph, using a sequence of bytes. Instead of providing illumination mathematically rigorous, describes a verifiable algorithm.',
	 'authors': u'Yoshihiro Terasawa,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5670',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nA simple authentication by common strings',
	 'urllink': u'http://arxiv.org/abs/1310.5670'}
2015-03-24 19:56:09+0000 [xxu46_7] INFO: Crawled 808 pages (at 1 pages/min), scraped 801 items (at 1 items/min)
2015-03-24 19:57:09+0000 [xxu46_7] INFO: Crawled 808 pages (at 0 pages/min), scraped 801 items (at 0 items/min)
2015-03-24 19:58:01+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4526> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 19:58:01+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4526>
	{'abstract': u"Goedel's ontological proof has been analysed for the first-time with an unprecedent degree of detail and formality with the help of higher-order theorem provers. The following has been done (and in this order): A detailed natural deduction proof. A formalization of the axioms, definitions and theorems in the TPTP THF syntax. Automatic verification of the consistency of the axioms and definitions with Nitpick. Automatic demonstration of the theorems with the provers LEO-II and Satallax. A step-by-step formalization using the Coq proof assistant. A formalization using the Isabelle proof assistant, where the theorems (and some additional lemmata) have been automated with Sledgehammer and Metis.",
	 'authors': u'Christoph Benzm\xfcller, Bruno Woltzenlogel Paleo,',
	 'category': u'Computer Science ',
	 'date': '2013-8-21',
	 'pdflink': u'http://arxiv.org/pdf/1308.4526',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u"\nFormalization, Mechanization and Automation of G\xf6del's Proof of God's  Existence",
	 'urllink': u'http://arxiv.org/abs/1308.4526'}
2015-03-24 19:58:09+0000 [xxu46_7] INFO: Crawled 809 pages (at 1 pages/min), scraped 802 items (at 1 items/min)
2015-03-24 19:59:09+0000 [xxu46_7] INFO: Crawled 809 pages (at 0 pages/min), scraped 802 items (at 0 items/min)
2015-03-24 19:59:55+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6466> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 19:59:55+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6466>
	{'abstract': u'In this paper we present a survey of existing prototypes dedicated to software defined radio. We propose a classification related to the architectural organization of the pro- totypes and provide some conclusions about the most promising architectures. This study should be useful for cognitive radio testbed designers who have to choose between many possible computing platforms. We also introduce a new cognitive radio testbed currently under construction and explain how this study have influenced the test-bed designers choices.',
	 'authors': u'Micka\xebl Dardaillon, Kevin Marquet, Tanguy Risset, Antoine Scherrer,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6466',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nSoftware Defined Radio Architecture Survey for Cognitive Testbeds',
	 'urllink': u'http://arxiv.org/abs/1309.6466'}
2015-03-24 20:00:09+0000 [xxu46_7] INFO: Crawled 810 pages (at 1 pages/min), scraped 803 items (at 1 items/min)
2015-03-24 20:00:53+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5665> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 20:00:53+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5665>
	{'abstract': u'Second-price auctions with reserve play a critical role for modern search engine and popular online sites since the revenue of these companies often directly de- pends on the outcome of such auctions. The choice of the reserve price is the main mechanism through which the auction revenue can be influenced in these electronic markets. We cast the problem of selecting the reserve price to optimize revenue as a learning problem and present a full theoretical analysis dealing with the complex properties of the corresponding loss function. We further give novel algorithms for solving this problem and report the results of several experiments in both synthetic and real data demonstrating their effectiveness.',
	 'authors': u'Mehryar Mohri, Andres Mu\xf1oz Medina,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5665',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nLearning Theory and Algorithms for Revenue Optimization in Second-Price  Auctions with Reserve',
	 'urllink': u'http://arxiv.org/abs/1310.5665'}
2015-03-24 20:01:09+0000 [xxu46_7] INFO: Crawled 811 pages (at 1 pages/min), scraped 804 items (at 1 items/min)
2015-03-24 20:02:09+0000 [xxu46_7] INFO: Crawled 811 pages (at 0 pages/min), scraped 804 items (at 0 items/min)
2015-03-24 20:02:10+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4516> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 20:02:10+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4516>
	{'abstract': u'An omega-grammar is a formal grammar used to generate omega-words (i.e. infinite length words), while an omega-automaton is an automaton used to recognize omega-words. This paper gives clean and uniform definitions for omega-grammars and omega-automata, provides a systematic study of the generative power of omega-grammars with respect to omega-automata, and presents a complete set of results for various types of omega-grammars and acceptance modes. We use the tuple ( sigma, rho, pi) to denote various acceptance modes, where sigma denotes that some designated elements should appear at least once or infinitely often, rho denotes some binary relation between two sets, and pi denotes normal or leftmost derivations. Technically, we propose ( sigma, rho, pi)-accepting omega-grammars, and systematically study their relative generative power with respect to ( sigma, rho)-accepting omega-automata. We show how to construct some special forms of omega-grammars, such as epsilon-production-free omega-grammars. We study the equivalence or inclusion relations between omega',
	 'authors': u'Zhe Chen,',
	 'category': u'Computer Science ',
	 'date': '2013-8-21',
	 'pdflink': u'http://arxiv.org/pdf/1308.4516',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nOn the Generative Power of Omega-Grammars and Omega-Automata',
	 'urllink': u'http://arxiv.org/abs/1308.4516'}
2015-03-24 20:03:09+0000 [xxu46_7] INFO: Crawled 812 pages (at 1 pages/min), scraped 805 items (at 1 items/min)
2015-03-24 20:04:07+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6455> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 20:04:07+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6455>
	{'abstract': u'In an effort to understand why individuals choose to participate in personally-expensive pro-environmental behaviors, environmental and behavioral economists have examined a moral-motivation model in which the decision to adopt a pro-environmental behavior depends on the society-wide market share of that behavior. An increasing body of practical research on adoption of pro-environmental behavior emphasizes the importance of encouragement from local social contacts and messaging about locally-embraced norms: we respond by extending the moral-motivation model to a social networks setting. We obtain a new decision rule: an individual adopts a pro-environmental behavior if he or she observes a certain threshold of adoption within their local social neighborhood. This gives rise to a concurrent update process which describes adoption of a pro-environmental behavior spreading through a network. The original moral-motivation model corresponds to the special case of our network version in a complete graph. By improving convergence results, we formulate modest-size Integer Programs that accurately (but not efficiently) find minimum-size sets of nodes that convert the entire network, or alternately that maximize long-term adoption in the network given a limited number of nodes which may be temporarily converted. Issues of stability in determining long-term adoption are key. We give hardness of approximation results for these optimization problems. We demonstrate that there exist classes of networks which qualitatively have severely different behavior than the non-networked version, and provide preliminary computational results in in modestly-sized highly-clustered small-world networks related to the famous small-world networks of Watts and Strogatz.',
	 'authors': u'Gwen Spencer, Richard Howarth,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6455',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nMaximizing the Spread of Stable Influence: Leveraging Norm-driven  Moral-Motivation for Green Behavior Change in Networks',
	 'urllink': u'http://arxiv.org/abs/1309.6455'}
2015-03-24 20:04:09+0000 [xxu46_7] INFO: Crawled 813 pages (at 1 pages/min), scraped 806 items (at 1 items/min)
2015-03-24 20:05:09+0000 [xxu46_7] INFO: Crawled 813 pages (at 0 pages/min), scraped 806 items (at 0 items/min)
2015-03-24 20:05:35+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5660> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 20:05:35+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5660>
	{'abstract': u'In this note, we consider repeated play of a finite game using learning rules whose period-by-period behavior probabilities or empirical distributions converge to some notion of equilibria of the stage game. Our primary focus is on uncoupled and completely uncoupled learning rules. While the former relies on players being aware of only their own payoff functions and able to monitor the action taken by the others, the latter assumes that players only know their own past realized payoffs. We highlight the border between possible and impossible results using these rules. We also overview several uncoupled and completely uncoupled learning rules, most of which leverage notions of regret as the solution concept to seek payoff-improving action profiles.',
	 'authors': u'M. Sadegh Talebi,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5660',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nUncoupled Learning Rules for Seeking Equilibria in Repeated Plays: An  Overview',
	 'urllink': u'http://arxiv.org/abs/1310.5660'}
2015-03-24 20:06:09+0000 [xxu46_7] INFO: Crawled 814 pages (at 1 pages/min), scraped 807 items (at 1 items/min)
2015-03-24 20:07:09+0000 [xxu46_7] INFO: Crawled 814 pages (at 0 pages/min), scraped 807 items (at 0 items/min)
2015-03-24 20:07:13+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4506> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 20:07:13+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4506>
	{'abstract': u'Associative memories are data structures addressed using part of the content rather than an index. They offer good fault reliability and biological plausibility. Among different families of associative memories, sparse ones are known to offer the best efficiency (ratio of the amount of bits stored to that of bits used by the network itself). Their retrieval process performance has been shown to benefit from the use of iterations. However classical algorithms require having prior knowledge about the data to retrieve such as the number of nonzero symbols. We introduce several families of algorithms to enhance the retrieval process performance in recently proposed sparse associative memories based on binary neural networks. We show that these algorithms provide better performance, along with better plausibility than existing techniques. We also analyze the required number of iterations and derive corresponding curves.',
	 'authors': u'Ala Aboudib, Vincent Gripon, Xiaoran Jiang,',
	 'category': u'Computer Science ',
	 'date': '2013-8-21',
	 'pdflink': u'http://arxiv.org/pdf/1308.4506',
	 'subjects': u'Neural and Evolutionary Computing (cs.NE)',
	 'title': u'\nA study of retrieval algorithms of sparse messages in networks of neural  cliques',
	 'urllink': u'http://arxiv.org/abs/1308.4506'}
2015-03-24 20:08:09+0000 [xxu46_7] INFO: Crawled 815 pages (at 1 pages/min), scraped 808 items (at 1 items/min)
2015-03-24 20:08:54+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6453> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 20:08:54+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6453>
	{'abstract': u'We study a generalization of the recently introduced order-preserving pattern matching, where instead of looking for an exact copy of the pattern, we only require that the relative order between the elements is the same. In our variant, we additionally allow up to k mismatches between the pattern and the text, and the goal is to construct an efficient algorithm for small values of k. For a pattern of length m and a text of length n, our algorithm detects an order-preserving occurrence with up to k mismatches in O(n(loglogm + kloglogk)) time.',
	 'authors': u'Pawel Gawrychowski, Przemyslaw Uznanski,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6453',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nOrder-preserving pattern matching with k mismatches',
	 'urllink': u'http://arxiv.org/abs/1309.6453'}
2015-03-24 20:09:09+0000 [xxu46_7] INFO: Crawled 816 pages (at 1 pages/min), scraped 809 items (at 1 items/min)
2015-03-24 20:10:09+0000 [xxu46_7] INFO: Crawled 816 pages (at 0 pages/min), scraped 809 items (at 0 items/min)
2015-03-24 20:10:46+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5656> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 20:10:46+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5656>
	{'abstract': u'A notable feature of the TTE approach to computability is the representation of the argument values and the corresponding function values by means of infinitistic names. Two ways to eliminate the using of such names in certain cases are indicated in the paper. The first one is intended for the case of topological spaces with selected indexed denumerable bases. Suppose a partial function is given from one such space into another one whose selected base has a recursively enumerable index set, and suppose that the intersection of base open sets in the first space is computable in the sense of Weihrauch-Grubba. Then the ordinary TTE computability of the function is characterized by the existence of an appropriate recursively enumerable relation between indices of base sets containing the argument value and indices of base sets containing the corresponding function value.This result can be regarded as an improvement of a result of Korovina and Kudinov. The second way is applicable to metric spaces with selected indexed denumerable dense subsets. If a partial function is given from one such space into another one, then, under a semi-computability assumption concerning these spaces, the ordinary TTE computability of the function is characterized by the existence of an appropriate recursively enumerable set of quadruples. Any of them consists of an index of element from the selected dense subset in the first space, a natural number encoding a rational bound for the distance between this element and the argument value, an index of element from the selected dense subset in the second space and a natural number encoding a rational bound for the distance between this element and the function value. One of the examples in the paper indicates that the computability of real functions can be characterized in a simple way by using the first way of elimination of the infinitistic names.',
	 'authors': u'Dimiter Skordev,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5656',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nApproximation systems for functions in topological and in metric spaces',
	 'urllink': u'http://arxiv.org/abs/1310.5656'}
2015-03-24 20:11:09+0000 [xxu46_7] INFO: Crawled 817 pages (at 1 pages/min), scraped 810 items (at 1 items/min)
2015-03-24 20:12:09+0000 [xxu46_7] INFO: Crawled 817 pages (at 0 pages/min), scraped 810 items (at 0 items/min)
2015-03-24 20:12:38+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4501> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 20:12:38+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4501>
	{'abstract': u'Mobile crowdsensing leverages mobile devices (e.g., smart phones) and human mobility for pervasive information exploration and collection; it has been deemed as a promising paradigm that will revolutionize various research and application domains. Unfortunately, the practicality of mobile crowdsensing can be crippled due to the lack of incentive mechanisms that stimulate human participation. In this paper, we study incentive mechanisms for a novel Mobile Crowdsensing Scheduling (MCS) problem, where a mobile crowdsensing application owner announces a set of sensing tasks, then human users (carrying mobile devices) compete for the tasks based on their respective sensing costs and available time periods, and finally the owner schedules as well as pays the users to maximize its own sensing revenue under a certain budget. We prove that the MCS problem is NP-hard and propose polynomial-time approximation mechanisms for it. We also show that our approximation mechanisms (including both offline and online versions) achieve desirable game-theoretic properties, namely truthfulness and individual rationality, as well as O(1) performance ratios. Finally, we conduct extensive simulations to demonstrate the correctness and effectiveness of our approach.',
	 'authors': u'Kai Han, Chi Zhang, Jun Luo,',
	 'category': u'Computer Science ',
	 'date': '2013-8-21',
	 'pdflink': u'http://arxiv.org/pdf/1308.4501',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nTruthful Scheduling Mechanisms for Powering Mobile Crowdsensing',
	 'urllink': u'http://arxiv.org/abs/1308.4501'}
2015-03-24 20:13:09+0000 [xxu46_7] INFO: Crawled 818 pages (at 1 pages/min), scraped 811 items (at 1 items/min)
2015-03-24 20:14:09+0000 [xxu46_7] INFO: Crawled 818 pages (at 0 pages/min), scraped 811 items (at 0 items/min)
2015-03-24 20:14:34+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6452> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 20:14:34+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6452>
	{'abstract': u"When orchestrating highly distributed and data-intensive Web service workflows the geographical placement of the orchestration engine can greatly affect the overall performance of a workflow. Orchestration engines are typically run from within an organisations' network, and may have to transfer data across long geographical distances, which in turn increases execution time and degrades the overall performance of a workflow. In this paper we present CloudForecast: a Web service framework and analysis tool which given a workflow specification, computes the optimal Amazon EC2 Cloud region to automatically deploy the orchestration engine and execute the workflow. We use geographical distance of the workflow, network latency and HTTP round-trip time between Amazon Cloud regions and the workflow nodes to find a ranking of Cloud regions. This combined set of simple metrics effectively predicts where the workflow orchestration engine should be deployed in order to reduce overall execution time. We evaluate our approach by executing randomly generated data-intensive workflows deployed on the PlanetLab platform in order to rank Amazon EC2 Cloud regions. Our experimental results show that our proposed optimisation strategy, depending on the particular workflow, can speed up execution time on average by 82.25% compared to local execution. We also show that the standard deviation of execution time is reduced by an average of almost 65% using the optimisation strategy.",
	 'authors': u'Michael Luckeneder, Adam Barker,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6452',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nLocation, Location, Location: Data-Intensive Distributed Computing in  the Cloud',
	 'urllink': u'http://arxiv.org/abs/1309.6452'}
2015-03-24 20:15:09+0000 [xxu46_7] INFO: Crawled 819 pages (at 1 pages/min), scraped 812 items (at 1 items/min)
2015-03-24 20:16:09+0000 [xxu46_7] INFO: Crawled 819 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2015-03-24 20:16:21+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5653> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 20:16:21+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5653>
	{'abstract': u'This paper gives a new scheme of watermarking technique related to insert the mark by adding edge in HH sub-band of the host image after wavelet decomposition. Contrary to most of the watermarking algorithms in wavelet domain, our method is blind and results show that it is robust against the JPEG and GIF compression, histogram and spectrum spreading, noise adding and small rotation. Its robustness against compression is better than others watermarking algorithms reported in the literature. The algorithm is flexible because its capacity or robustness can be improved by modifying some parameters.',
	 'authors': u'Henri Bruno Razafindradina, Attoumani Mohamed Karim,',
	 'category': u'Computer Science ',
	 'date': '2013-10-9',
	 'pdflink': u'http://arxiv.org/pdf/1310.5653',
	 'subjects': u'Multimedia (cs.MM)',
	 'title': u'\nBlind and robust images watermarking based on wavelet and edge insertion',
	 'urllink': u'http://arxiv.org/abs/1310.5653'}
2015-03-24 20:17:09+0000 [xxu46_7] INFO: Crawled 820 pages (at 1 pages/min), scraped 813 items (at 1 items/min)
2015-03-24 20:18:02+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4499> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 20:18:02+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4499>
	{'abstract': u'In this paper we continue to study a question proposed by Babadi and Tarokh cite on the mysterious randomness of Gold sequences. Upon improving their result, we establish the randomness of product of pseudorandom matrices formed from two linear block codes with respect to the empirical spectral distribution, if the dual distance of both codes is at least 5, hence providing an affirmative answer to the question.',
	 'authors': u'Jing Xia, Liuquan Wang, Maosheng Xiong,',
	 'category': u'Computer Science ',
	 'date': '2013-8-21',
	 'pdflink': u'http://arxiv.org/pdf/1308.4499',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nOn a question of Babadi and Tarokh II',
	 'urllink': u'http://arxiv.org/abs/1308.4499'}
2015-03-24 20:18:09+0000 [xxu46_7] INFO: Crawled 821 pages (at 1 pages/min), scraped 814 items (at 1 items/min)
2015-03-24 20:19:09+0000 [xxu46_7] INFO: Crawled 821 pages (at 0 pages/min), scraped 814 items (at 0 items/min)
2015-03-24 20:19:40+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6450> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 20:19:40+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6450>
	{'abstract': u'Along with the USA and Russia, China is often considered one of the leading cyber-powers in the world. In this excerpt, we explore how Chinese military thought, developed in the 1990s, influenced their cyber-operations in the early 2000s. In particular, we examine the ideas of "Unrestricted Warfare" and "Active Offense" and discuss how they can permit for the theft of intellectual property. We then specifically look at how the case study of Operation Aurora, a cyber-operation directed against many major U.S. technology and defense firms, reflects some of these ideas.',
	 'authors': u'Paulo Shakarian, Jana Shakarian, Andrew Ruef,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6450',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nThe Dragon and the Computer: Why Intellectual Property Theft is  Compatible with Chinese Cyber-Warfare Doctrine',
	 'urllink': u'http://arxiv.org/abs/1309.6450'}
2015-03-24 20:20:09+0000 [xxu46_7] INFO: Crawled 822 pages (at 1 pages/min), scraped 815 items (at 1 items/min)
2015-03-24 20:21:09+0000 [xxu46_7] INFO: Crawled 822 pages (at 0 pages/min), scraped 815 items (at 0 items/min)
2015-03-24 20:21:13+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5647> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 20:21:13+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5647>
	{'abstract': u'Let be a set of pairwise-disjoint convex sets of constant description complexity, and let be a probability density function (pdf for short) over the non-negative reals. For each , let be the Minkowski sum of with a disk of radius , where each is a random non-negative number drawn independently from the distribution determined by . We show that the expected complexity of the union of is for any ; here the constant of proportionality depends on and on the description complexity of the sets in , but not on . If each is a convex polygon with at most vertices, then we show that the expected complexity of the union is . Our bounds hold in the stronger model in which we are given an arbitrary multi-set of expansion radii, each a non-negative real number. We assign them to the members of by a random permutation, where all permutations are equally likely to be chosen; the expectations are now with respect to these permutations. We also present an application of our results to a problem that arises in analyzing the vulnerability of a network to a physical attack. %',
	 'authors': u'Pankaj Agarwal, Sariel Har-Peled, Haim Kaplan, Micha Sharir,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5647',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nUnion of Random Minkowski Sums and Network Vulnerability Analysis',
	 'urllink': u'http://arxiv.org/abs/1310.5647'}
2015-03-24 20:22:09+0000 [xxu46_7] INFO: Crawled 823 pages (at 1 pages/min), scraped 816 items (at 1 items/min)
2015-03-24 20:22:50+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4486> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 20:22:50+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4486>
	{'abstract': u'Mobile phones have traveled a very long journey in a very short span of time since its inception in 1973.This wonderful toy of 20th century has started playing significant role in daily life.More than 5 billion mobile users are there around the world and almost 90 percent of the entire earth is under the mobile coverage now.These days smart phones are equipped with numerous features,faster processors and high storage capacity.Android is a latest trend in this series whose popularity is growing by leaps and bounds.Android has a number of components which helps Application developers to embed distinguish features in applications.This paper explains how the Service component of Android can share your personal information to others without users interaction.',
	 'authors': u'Manoj Kumar, Sheshendra Rathi,',
	 'category': u'Computer Science ',
	 'date': '2013-8-21',
	 'pdflink': u'http://arxiv.org/pdf/1308.4486',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nServices in Android can Share Your Personal Information in Background',
	 'urllink': u'http://arxiv.org/abs/1308.4486'}
2015-03-24 20:23:09+0000 [xxu46_7] INFO: Crawled 824 pages (at 1 pages/min), scraped 817 items (at 1 items/min)
2015-03-24 20:24:09+0000 [xxu46_7] INFO: Crawled 824 pages (at 0 pages/min), scraped 817 items (at 0 items/min)
2015-03-24 20:24:36+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6449> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 20:24:36+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6449>
	{'abstract': u'Self-assembly is a phenomenon observed in nature at all scales where autonomous entities build complex structures, without external influences nor centralised master plan. Modelling such entities and programming correct interactions among them is crucial for controlling the manufacture of desired complex structures at the molecular and supramolecular scale. This work focuses on a programmability model for non DNA-based molecules and complex behaviour analysis of their self-assembled conformations. In particular, we look into modelling, programming and simulation of porphyrin molecules self-assembly and apply Kolgomorov complexity-based techniques to classify and assess simulation results in terms of information content. The analysis focuses on phase transition, clustering, variability and parameter discovery which as a whole pave the way to the notion of complex systems programmability.',
	 'authors': u'German Terrazas, Hector Zenil, Natalio Krasnogor,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6449',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nExploring Programmable Self-Assembly in Non-DNA based Molecular  Computing',
	 'urllink': u'http://arxiv.org/abs/1309.6449'}
2015-03-24 20:25:09+0000 [xxu46_7] INFO: Crawled 825 pages (at 1 pages/min), scraped 818 items (at 1 items/min)
2015-03-24 20:26:09+0000 [xxu46_7] INFO: Crawled 825 pages (at 0 pages/min), scraped 818 items (at 0 items/min)
2015-03-24 20:26:10+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5620> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 20:26:10+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5620>
	{'abstract': u'The small medium large system (SMLSystem) is a house built at the Universidad CEU Cardenal Herrera (CEU-UCH) for participation in the Solar Decathlon 2013 competition. Several technologies have been integrated to reduce power consumption. One of these is a forecasting system based on artificial neural networks (ANNs), which is able to predict indoor temperature in the near future using captured data by a complex monitoring system as the input. A study of the impact on forecasting performance of different covariate combinations is presented in this paper. Additionally, a comparison of ANNs with the standard statistical forecasting methods is shown. The research in this paper has been focused on forecasting the indoor temperature of a house, as it is directly related to HVAC---heating, ventilation and air conditioning---system consumption. HVAC systems at the SMLSystem house represent 53.9% of the overall power consumption. The energy used to maintain temperature was measured to be 30--38.9% of the energy needed to lower it. Hence, these forecasting measures allow the house to adapt itself to future temperature conditions by using home automation in an energy-efficient manner. Experimental results show a high forecasting accuracy and therefore, they might be used to efficiently control an HVAC system.',
	 'authors': u'Francisco Zamora-Martiinez, Pablo Romeu, Paloma Botella-Rocamora, Juan Pardo,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5620',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nTowards Energy Efficiency: Forecasting Indoor Temperature via  Multivariate Analysis',
	 'urllink': u'http://arxiv.org/abs/1310.5620'}
2015-03-24 20:27:09+0000 [xxu46_7] INFO: Crawled 826 pages (at 1 pages/min), scraped 819 items (at 1 items/min)
2015-03-24 20:28:05+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4485> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 20:28:05+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4485>
	{'abstract': u'The subscribers base of mobile phones is increasing globally with a rapid rate.The sale of mobile phones has exceeded those of personal computers.India is the second largest telecommunication network in the world in terms of number of wireless connections after China.Telecom companies are ready to tap a large unexplored market in India with lucrative offerings.Smart phones sale are at its peak.3G technology is also ready to play a lead role in mobile revolution.Due to the low average life of the mobile phones,lack of awareness among users and in absence of government policies,mobile waste is accumulating in vast amount in India.Without a proper system of recycling,the unsafe disposal is causing a variety of environmental and health problems.This paper discusses the various issues related to the worldwide growth of mobile phones,the insecure methods of disposal and the regulations and policies in India.We intend to put forward some challenges and advices.',
	 'authors': u'Neeta Sharma, Manoj Kumar,',
	 'category': u'Computer Science ',
	 'date': '2013-8-21',
	 'pdflink': u'http://arxiv.org/pdf/1308.4485',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nThe Wonderful Toy of 20th Century can be a Disaster in 21st  Century:Scenario and Policies Regarding Mobile Waste in India',
	 'urllink': u'http://arxiv.org/abs/1308.4485'}
2015-03-24 20:28:09+0000 [xxu46_7] INFO: Crawled 827 pages (at 1 pages/min), scraped 820 items (at 1 items/min)
2015-03-24 20:29:09+0000 [xxu46_7] INFO: Crawled 827 pages (at 0 pages/min), scraped 820 items (at 0 items/min)
2015-03-24 20:29:50+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6433> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 20:29:50+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6433>
	{'abstract': u'Goalkeeper (GK) is an expert in soccer and goalkeeping is a complete professional job. In fact, achieving success seems impossible without a reliable GK. His effect in successes and failures is more dominant than other players. The most visible mistakes in a game are those of goalkeeper\'s. In this paper the expert fuzzy system is used as a suitable tool to study the quality of a goalkeeper and compare it with others. Previously done researches are used to find the goalkeepers\' indexes in soccer. Soccer experts have found that a successful GK should have some qualifications. A new pattern is offered here which is called "Soccer goalkeeper quality recognition using fuzzy expert systems". This pattern has some important capabilities. Firstly, among some goalkeepers the one with the best quality for the main team arrange can be chosen. Secondly, the need to expert coaches for choosing a GK using their senses and experiences decreases a lot. Thirdly, in the survey of a GK, quantitative criteria can be included, and finally this pattern is simple and easy to understand.',
	 'authors': u'Mohammad Bazmara, Shahram Jafari, Fatemeh Pasand,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6433',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nA Fuzzy expert system for goalkeeper quality recognition',
	 'urllink': u'http://arxiv.org/abs/1309.6433'}
2015-03-24 20:30:09+0000 [xxu46_7] INFO: Crawled 828 pages (at 1 pages/min), scraped 821 items (at 1 items/min)
2015-03-24 20:31:09+0000 [xxu46_7] INFO: Crawled 828 pages (at 0 pages/min), scraped 821 items (at 0 items/min)
2015-03-24 20:31:26+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5619> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 20:31:26+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5619>
	{'abstract': u'This paper presents a Devnagari Numerical recognition method based on statistical discriminant functions. 17 geometric features based on pixel connectivity, lines, line directions, holes, image area, perimeter, eccentricity, solidity, orientation etc. are used for representing the numerals. Five discriminant functions viz. Linear, Quadratic, Diaglinear, Diagquadratic and Mahalanobis distance are used for classification. 1500 handwritten numerals are used for training. Another 1500 handwritten numerals are used for testing. Experimental results show that Linear, Quadratic and Mahalanobis discriminant functions provide better results. Results of these three Discriminants are fed to a majority voting type Combination classifier. It is found that Combination classifier offers better results over individual classifiers.',
	 'authors': u'Vikas J. Dongre, Vijay H. Mankar,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5619',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nDevnagari Handwritten Numeral Recognition using Geometric Features and  Statistical Combination Classifier',
	 'urllink': u'http://arxiv.org/abs/1310.5619'}
2015-03-24 20:32:09+0000 [xxu46_7] INFO: Crawled 829 pages (at 1 pages/min), scraped 822 items (at 1 items/min)
2015-03-24 20:33:09+0000 [xxu46_7] INFO: Crawled 829 pages (at 0 pages/min), scraped 822 items (at 0 items/min)
2015-03-24 20:33:27+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4479> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 20:33:27+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4479>
	{'abstract': u'By investigating the distribution of phrase pairs in phrase translation tables, the work in this paper describes an approach to increase the number of n-gram alignments in phrase translation tables output by a sampling-based alignment method. This approach consists in enforcing the alignment of n-grams in distinct translation subtables so as to increase the number of n-grams. Standard normal distribution is used to allot alignment time among translation subtables, which results in adjustment of the distribution of n- grams. This leads to better evaluation results on statistical machine translation tasks than the original sampling-based alignment approach. Furthermore, the translation quality obtained by merging phrase translation tables computed from the sampling-based alignment method and from MGIZA++ is examined.',
	 'authors': u'Juan Luo, Yves Lepage,',
	 'category': u'Computer Science ',
	 'date': '2013-8-21',
	 'pdflink': u'http://arxiv.org/pdf/1308.4479',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nAn Investigation of the Sampling-Based Alignment Method and Its  Contributions',
	 'urllink': u'http://arxiv.org/abs/1308.4479'}
2015-03-24 20:34:09+0000 [xxu46_7] INFO: Crawled 830 pages (at 1 pages/min), scraped 823 items (at 1 items/min)
2015-03-24 20:35:09+0000 [xxu46_7] INFO: Crawled 830 pages (at 0 pages/min), scraped 823 items (at 0 items/min)
2015-03-24 20:35:25+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6422> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 20:35:25+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6422>
	{'abstract': u'We advocate to create a emph Internet transit market, where transit is sold using the under-utilized backbone capacity at a lower price. The providers can improve profit by capitalizing the perishable capacity, and customers can buy transit on-demand without a minimum commitment level for elastic traffic, and as a result improve its surplus (i.e. utility gains). We conduct a systematic study of the economical benefits of spot transit both theoretically and empirically. We propose a simple analytical framework with a general demand function, and solve the pricing problem of maximizing the expected profit, taking into account the revenue loss of regular transit when spot transit traffic hikes. We rigorously prove the price advantage of spot transit, as well as profit and surplus improvements for tier-1 ISPs and customers, respectively. Using real-world price data and traffic statistics of 6 IXPs with more than 1000 ISPs, we quantitatively evaluate spot transit and show that significant financial benefits can be achieved in both absolute and relative terms, robust to parameter values.',
	 'authors': u'Hong Xu, Baochun Li,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6422',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nSpot Transit: Cheaper Internet Transit for Elastic Traffic',
	 'urllink': u'http://arxiv.org/abs/1309.6422'}
2015-03-24 20:36:09+0000 [xxu46_7] INFO: Crawled 831 pages (at 1 pages/min), scraped 824 items (at 1 items/min)
2015-03-24 20:37:05+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5603> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 20:37:05+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5603>
	{'abstract': u'Large-scale distributed graph-parallel computing is challenging. On one hand, due to the irregular computation pattern and lack of locality, it is hard to express parallelism efficiently. On the other hand, due to the scale-free nature, real-world graphs are hard to partition in balance with low cut. To address these challenges, several graph-parallel frameworks including Pregel and GraphLab (PowerGraph) have been developed recently. In this paper, we present an alternative framework, Graph Runtime Engine (GRE). While retaining the vertex-centric programming model, GRE proposes two new abstractions: 1) a Scatter-Combine computation model based on active message to exploit massive fined-grained edge-level parallelism, and 2) a Agent-Graph data model based on vertex factorization to partition and represent directed graphs. GRE is implemented on commercial off-the-shelf multi-core cluster. We experimentally evaluate GRE with three benchmark programs (PageRank, Single Source Shortest Path and Connected Components) on real-world and synthetic graphs of millions billion of vertices. Compared to PowerGraph, GRE shows 2.5~17 times better performance on 8~16 machines (192 cores). Specifically, the PageRank in GRE is the fastest when comparing to counterparts of other frameworks (PowerGraph, Spark,Twister) reported in public literatures. Besides, GRE significantly optimizes memory usage so that it can process a large graph of 1 billion vertices and 17 billion edges on our cluster with totally 768GB memory, while PowerGraph can only process less than half of this graph scale.',
	 'authors': u'Jie Yan, Guangming Tan, Ninghui Sun,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5603',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nGRE: A Graph Runtime Engine for Large-Scale Distributed Graph-Parallel  Applications',
	 'urllink': u'http://arxiv.org/abs/1310.5603'}
2015-03-24 20:37:09+0000 [xxu46_7] INFO: Crawled 832 pages (at 1 pages/min), scraped 825 items (at 1 items/min)
2015-03-24 20:38:09+0000 [xxu46_7] INFO: Crawled 832 pages (at 0 pages/min), scraped 825 items (at 0 items/min)
2015-03-24 20:38:34+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4477> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 20:38:34+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4477>
	{'abstract': u'The three-stage Clos networks remain the most popular solution to many practical switching systems to date. The aim of this paper is to show that the modular structure of Clos networks is invariant with respect to the technological changes. Due to the wavelength routing property of arrayed-waveguide gratings (AWGs), non-blocking and contention-free wavelength-division-multiplexing (WDM) switches require that two calls carried by the same wavelength must be connected by separated links; otherwise, they must be carried by different wavelengths. Thus, in addition to the non-blocking condition, the challenge of the design of AWG-based multistage switching networks is to scale down the wavelength granularity and to reduce the conversion range of tunable wavelength converters (TWCs). We devise a logic scheme to partition the WDM switch network into wavelength autonomous cells, and show that the wavelength scalability problem can be solved by recursively reusing similar, but smaller, set of wavelengths in different cells. Furthermore, we prove that the rearrangeably non-blocking (RNB) condition and route assignments in these AWG-based three-stage networks are consistent with that of classical Clos networks. Thus, the optimal AWG-based non-blocking Clos networks also can achieve 100% utilization when all input and output wavelength channels are busy.',
	 'authors': u'Tong Ye, Tony T. Lee, Weisheng Hu,',
	 'category': u'Computer Science ',
	 'date': '2013-8-21',
	 'pdflink': u'http://arxiv.org/pdf/1308.4477',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nAWG-based Non-blocking Clos Networks',
	 'urllink': u'http://arxiv.org/abs/1308.4477'}
2015-03-24 20:39:09+0000 [xxu46_7] INFO: Crawled 833 pages (at 1 pages/min), scraped 826 items (at 1 items/min)
2015-03-24 20:40:09+0000 [xxu46_7] INFO: Crawled 833 pages (at 0 pages/min), scraped 826 items (at 0 items/min)
2015-03-24 20:40:11+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6395> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 20:40:11+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6395>
	{'abstract': u'In this paper, we consider a time-slotted cognitive radio (CR) setting with buffered and energy harvesting primary and CR users. At the beginning of each time slot, the CR user probabilistically chooses the spectrum sensing duration from a predefined set. If the primary user (PU) is sensed to be inactive, the CR user accesses the channel immediately. The CR user optimizes the sensing duration probabilities in order to maximize its mean data service rate with constraints on the stability of the primary and cognitive queues. The optimization problem is split into two subproblems. The first is a linear-fractional program, and the other is a linear program. Both subproblems can be solved efficiently.',
	 'authors': u'Ahmed El Shafie, Ahmed Sultan,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6395',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nOptimal Selection of Spectrum Sensing Duration for an Energy Harvesting  Cognitive Radio',
	 'urllink': u'http://arxiv.org/abs/1309.6395'}
2015-03-24 20:41:09+0000 [xxu46_7] INFO: Crawled 834 pages (at 1 pages/min), scraped 827 items (at 1 items/min)
2015-03-24 20:41:46+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5597> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 20:41:46+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5597>
	{'abstract': u'This technical report presents a bibliometric analysis of the top 30 cited researchers from USA, UK and China. The analysis is based on Google Scholar data using CIDS. The researchers were identified using their email suffix: edu, uk and cn. This na "ve approach was able to produce rankings consistent with the SCImago country rankings using mininal resources in a fully automated way.',
	 'authors': u'Francisco M Couto,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5597',
	 'subjects': u'Digital Libraries (cs.DL)',
	 'title': u'\nCIDS country rankings: comparing documents and citations of USA, UK and  China top researchers',
	 'urllink': u'http://arxiv.org/abs/1310.5597'}
2015-03-24 20:42:09+0000 [xxu46_7] INFO: Crawled 835 pages (at 1 pages/min), scraped 828 items (at 1 items/min)
2015-03-24 20:43:09+0000 [xxu46_7] INFO: Crawled 835 pages (at 0 pages/min), scraped 828 items (at 0 items/min)
2015-03-24 20:43:30+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4469> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 20:43:30+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4469>
	{'abstract': u'This thesis presents a number of results related to path traversal in trees and graphs. In particular, we focus on data structures which allow such traversals to be performed efficiently in the external memory setting. In addition, for trees and planar graphs the data structures we present are succinct. Our tree structures permit efficient bottom-up path traversal in rooted trees of arbitrary degree and efficient top-down path traversal in binary trees. In the graph setting, we permit efficient traversal of an arbitrary path in bounded degree planar graphs. Our data structures for both trees and graphs match or slightly improve current best results for external memory path traversal in these settings while at the same time improving space bounds due to the succinct nature of our data structures. Employing our path traversal structure for bounded degree planar graphs, we describe a number of useful applications of this technique for triangular meshes in R^2. As an extension of the R^2 representation for triangular meshes we also present an efficient external memory representation for well-shaped tetrahedral meshes in R^3. The external memory representation we present is based on a partitioning scheme that matches the current best-known results for well-shaped tetrahedral meshes. We describe applications of path traversal in tetrahedral meshes which are made efficient in the external memory setting using our structure. Finally, we present a result on using jump-and-walk point location in well-shaped meshes in both R^2 and R^3. We demonstrate that, given an approximate nearest neighbour from among the vertices of a mesh, locating the simplex containing the query point involves a constant length walk (path traversal) in the mesh.',
	 'authors': u'Craig Dillabaugh,',
	 'category': u'Computer Science ',
	 'date': '2013-8-21',
	 'pdflink': u'http://arxiv.org/pdf/1308.4469',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nExternal Memory Algorithms For Path Traversal in Graphs',
	 'urllink': u'http://arxiv.org/abs/1308.4469'}
2015-03-24 20:44:09+0000 [xxu46_7] INFO: Crawled 836 pages (at 1 pages/min), scraped 829 items (at 1 items/min)
2015-03-24 20:45:09+0000 [xxu46_7] INFO: Crawled 836 pages (at 0 pages/min), scraped 829 items (at 0 items/min)
2015-03-24 20:45:25+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6391> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 20:45:25+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6391>
	{'abstract': u'This paper addresses the problem of tracking moving objects of variable appearance in challenging scenes rich with features and texture. Reliable tracking is of pivotal importance in surveillance applications. It is made particularly difficult by the nature of objects encountered in such scenes: these too change in appearance and scale, and are often articulated (e.g. humans). We propose a method which uses fast motion detection and segmentation as a constraint for both building appearance models and their robust propagation (matching) in time. The appearance model is based on sets of local appearances automatically clustered using spatio-kinetic similarity, and is updated with each new appearance seen. This integration of all seen appearances of a tracked object makes it extremely resilient to errors caused by occlusion and the lack of permanence of due to low data quality, appearance change or background clutter. These theoretical strengths of our algorithm are empirically demonstrated on two hour long video footage of a busy city marketplace.',
	 'authors': u'Rhys Martin, Ognjen Arandjelovi\u0107,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6391',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nMultiple-object tracking in cluttered and crowded public spaces',
	 'urllink': u'http://arxiv.org/abs/1309.6391'}
2015-03-24 20:46:09+0000 [xxu46_7] INFO: Crawled 837 pages (at 1 pages/min), scraped 830 items (at 1 items/min)
2015-03-24 20:47:08+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5576> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 20:47:08+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5576>
	{'abstract': u'We discuss approximability and inapproximability in FPT-time for a large class of subset problems where a feasible solution is a subset of the input data and the value of is . The class handled encompasses many well-known graph, set, or satisfiability problems such as Dominating Set, Vertex Cover, Set Cover, Independent Set, Feedback Vertex Set, etc. In a first time, we introduce the notion of intersective approximability that generalizes the one of safe approximability and show strong parameterized inapproximability results for many of the subset problems handled. Then, we study approximability of these problems with respect to the dual parameter where is the size of the instance and the standard parameter. More precisely, we show that under such a parameterization, many of these problems, while W[]-hard, admit parameterized approximation schemata.',
	 'authors': u'Edouard Bonnet, Vangelis Th. Paschos,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5576',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nParameterized (in)approximability of subset problems',
	 'urllink': u'http://arxiv.org/abs/1310.5576'}
2015-03-24 20:47:09+0000 [xxu46_7] INFO: Crawled 838 pages (at 1 pages/min), scraped 831 items (at 1 items/min)
2015-03-24 20:48:09+0000 [xxu46_7] INFO: Crawled 838 pages (at 0 pages/min), scraped 831 items (at 0 items/min)
2015-03-24 20:48:56+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1311.4419> (referer: http://arxiv.org/list/cs/13?skip=12000&show=1000)
2015-03-24 20:48:56+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1311.4419>
	{'abstract': u'Animals within groups need to coordinate their reactions to perceived environmental features and to each other in order to safely move from one point to another. This paper extends our previously published work on the flight patterns of Myotis velifer that have been observed in a habitat near Johnson City, Texas. Each evening, these bats emerge from a cave in sequences of small groups that typically contain no more than three or four individuals, and they thus provide ideal subjects for studying leader-follower behaviors. By analyzing the flight paths of a group of M. velifer, the data show that the flight behavior of a follower bat is influenced by the flight behavior of a leader bat in a way that is not well explained by existing pursuit laws, such as classical pursuit, constant bearing and motion camouflage. Thus we propose an alternative steering law based on virtual loom, a concept we introduce to capture the geometrical configuration of the leader-follower pair. It is shown that this law may be integrated with our previously proposed vision-enabled steering laws to synthesize trajectories, the statistics of which fit with those of the bats in our data set. The results suggest that bats use perceived information of both the environment and their neighbors for navigation.',
	 'authors': u'Zhaodan Kong, Kayhan Ozcimder, Nathan W. Fuller, John Baillieul,',
	 'category': u'Computer Science ',
	 'date': '2013-11-15',
	 'pdflink': u'http://arxiv.org/pdf/1311.4419',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nPerception and Steering Control in Paired Bat Flight',
	 'urllink': u'http://arxiv.org/abs/1311.4419'}
2015-03-24 20:49:09+0000 [xxu46_7] INFO: Crawled 839 pages (at 1 pages/min), scraped 832 items (at 1 items/min)
2015-03-24 20:50:09+0000 [xxu46_7] INFO: Crawled 839 pages (at 0 pages/min), scraped 832 items (at 0 items/min)
2015-03-24 20:50:38+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4465> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 20:50:38+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4465>
	{'abstract': u'Software Defined Networks (SDN) decouple the forwarding and control planes from each other. The control plane is assumed to have a global knowledge of the underlying physical and/or logical network topology so that it can monitor, abstract and control the forwarding plane. In our paper, we present solutions that install an optimal or near-optimal (i.e., within 14% of the optimal) number of static forwarding rules on switches/routers so that any controller can verify the topology connectivity and detect/locate link failures at data plane speeds without relying on state updates from other controllers. Our upper bounds on performance indicate that sub-second link failure localization is possible even at data-center scale networks. For networks with hundreds or few thousand links, tens of milliseconds of latency is achievable.',
	 'authors': u'Ulas C. Kozat, Guanfeng Liang, Koray Kokten,',
	 'category': u'Computer Science ',
	 'date': '2013-8-21',
	 'pdflink': u'http://arxiv.org/pdf/1308.4465',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nOn Diagnosis of Forwarding Plane via Static Forwarding Rules in Software  Defined Networks',
	 'urllink': u'http://arxiv.org/abs/1308.4465'}
2015-03-24 20:51:09+0000 [xxu46_7] INFO: Crawled 840 pages (at 1 pages/min), scraped 833 items (at 1 items/min)
2015-03-24 20:52:09+0000 [xxu46_7] INFO: Crawled 840 pages (at 0 pages/min), scraped 833 items (at 0 items/min)
2015-03-24 20:52:30+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6390> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 20:52:30+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6390>
	{'abstract': u'In this paper we are interested in analyzing behaviour in crowded public places at the level of holistic motion. Our aim is to learn, without user input, strong scene priors or labelled data, the scope of "normal behaviour" for a particular scene and thus alert to novelty in unseen footage. The first contribution is a low-level motion model based on what we term tracklet primitives, which are scene-specific elementary motions. We propose a clustering-based algorithm for tracklet estimation from local approximations to tracks of appearance features. This is followed by two methods for motion novelty inference from tracklet primitives: (a) we describe an approach based on a non-hierarchial ensemble of Markov chains as a means of capturing behavioural characteristics at different scales, and (b) a more flexible alternative which exhibits a higher generalizing power by accounting for constraints introduced by intentionality and goal-oriented planning of human motion in a particular scene. Evaluated on a 2h long video of a busy city marketplace, both algorithms are shown to be successful at inferring unusual behaviour, the latter model achieving better performance for novelties at a larger spatial scale.',
	 'authors': u'Ognjen Arandjelovi\u0107,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6390',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nContextually learnt detection of unusual motion-based behaviour in  crowded public spaces',
	 'urllink': u'http://arxiv.org/abs/1309.6390'}
2015-03-24 20:53:09+0000 [xxu46_7] INFO: Crawled 841 pages (at 1 pages/min), scraped 834 items (at 1 items/min)
2015-03-24 20:53:54+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5573> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 20:53:54+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5573>
	{'abstract': u'This work generalizes the additively partitioned Runge-Kutta methods by allowing for different stage values as arguments of different components of the right hand side. An order conditions theory is developed for the new family of generalized additive methods, and stability and monotonicity investigations are carried out. The paper discusses the construction and properties of implicit-explicit and implicit-implicit,methods in the new framework. The new family, named GARK, introduces additional flexibility when compared to traditional partitioned Runge-Kutta methods, and therefore offers additional opportunities for the development of flexible solvers for systems with multiple scales, or driven by multiple physical processes.',
	 'authors': u'Adrian Sandu, Michael Guenther,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5573',
	 'subjects': u'Numerical Analysis (cs.NA)',
	 'title': u'\nA class of generalized additive Runge-Kutta methods',
	 'urllink': u'http://arxiv.org/abs/1310.5573'}
2015-03-24 20:54:09+0000 [xxu46_7] INFO: Crawled 842 pages (at 1 pages/min), scraped 835 items (at 1 items/min)
2015-03-24 20:55:09+0000 [xxu46_7] INFO: Crawled 842 pages (at 0 pages/min), scraped 835 items (at 0 items/min)
2015-03-24 20:55:51+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1311.4394> (referer: http://arxiv.org/list/cs/13?skip=12000&show=1000)
2015-03-24 20:55:51+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1311.4394>
	{'abstract': u"We consider the problem of encoding range minimum queries (RMQs): given an array A[1..n] of distinct totally ordered values, to pre-process A and create a data structure that can answer the query RMQ(i,j), which returns the index containing the smallest element in A[i..j], without access to the array A at query time. We give a data structure whose space usage is 2n + o(n) bits, which is asymptotically optimal for worst-case data, and answers RMQs in O(1) worst-case time. This matches the previous result of Fischer and Heun [SICOMP, 2011], but is obtained in a more natural way. Furthermore, our result can encode the RMQs of a random array A in 1.919n + o(n) bits in expectation, which is not known to hold for Fischer and Heun's result. We then generalize our result to the encoding range top-2 query (RT2Q) problem, which is like the encoding RMQ problem except that the query RT2Q(i,j) returns the indices of both the smallest and second-smallest elements of A[i..j]. We introduce a data structure using 3.272n+o(n) bits that answers RT2Qs in constant time, and also give lower bounds on the effective entropy of RT2Q.",
	 'authors': u'Pooya Davoodi, Gonzalo Navarro, Rajeev Raman, S. Srinivasa Rao,',
	 'category': u'Computer Science ',
	 'date': '2013-11-18',
	 'pdflink': u'http://arxiv.org/pdf/1311.4394',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nEncoding Range Minimum Queries',
	 'urllink': u'http://arxiv.org/abs/1311.4394'}
2015-03-24 20:56:09+0000 [xxu46_7] INFO: Crawled 843 pages (at 1 pages/min), scraped 836 items (at 1 items/min)
2015-03-24 20:57:09+0000 [xxu46_7] INFO: Crawled 843 pages (at 0 pages/min), scraped 836 items (at 0 items/min)
2015-03-24 20:57:48+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4458> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 20:57:48+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4458>
	{'abstract': u'High frame video (HFV) is an important investigational tool in sciences, engineering and military. In ultra-high speed imaging, the obtainable temporal, spatial and spectral resolutions are limited by the sustainable throughput of in-camera mass memory, the lower bound of exposure time, and illumination conditions. In order to break these bottlenecks, we propose a new coded video acquisition framework that employs K &gt; 2 conventional cameras, each of which makes random measurements of the 3D video signal in both temporal and spatial domains. For each of the K cameras, this multi-camera strategy greatly relaxes the stringent requirements in memory speed, shutter speed, and illumination strength. The recovery of HFV from these random measurements is posed and solved as a large scale l1 minimization problem by exploiting joint temporal and spatial sparsities of the 3D signal. Three coded video acquisition techniques of varied trade offs between performance and hardware complexity are developed: frame-wise coded acquisition, pixel-wise coded acquisition, and column-row-wise coded acquisition. The performances of these techniques are analyzed in relation to the sparsity of the underlying video signal. Simulations of these new HFV capture techniques are carried out and experimental results are reported.',
	 'authors': u'Reza Pournaghi, Xiaolin Wu,',
	 'category': u'Computer Science ',
	 'date': '2013-8-21',
	 'pdflink': u'http://arxiv.org/pdf/1308.4458',
	 'subjects': u'Multimedia (cs.MM)',
	 'title': u'\nCoded Acquisition of High Frame Rate Video',
	 'urllink': u'http://arxiv.org/abs/1308.4458'}
2015-03-24 20:58:09+0000 [xxu46_7] INFO: Crawled 844 pages (at 1 pages/min), scraped 837 items (at 1 items/min)
2015-03-24 20:59:09+0000 [xxu46_7] INFO: Crawled 844 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2015-03-24 20:59:40+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6379> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 20:59:40+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6379>
	{'abstract': u'We propose a large deformation diffeomorphic metric mapping algorithm to align multiple b-value diffusion weighted imaging (mDWI) data, specifically acquired via hybrid diffusion imaging (HYDI), denoted as LDDMM-HYDI. We then propose a Bayesian model for estimating the white matter atlas from HYDIs. We adopt the work given in Hosseinbor et al. (2012) and represent the q-space diffusion signal with the Bessel Fourier orientation reconstruction (BFOR) signal basis. The BFOR framework provides the representation of mDWI in the q-space and thus reduces memory requirement. In addition, since the BFOR signal basis is orthonormal, the L2 norm that quantifies the differences in the q-space signals of any two mDWI datasets can be easily computed as the sum of the squared differences in the BFOR expansion coefficients. In this work, we show that the reorientation of the -space signal due to spatial transformation can be easily defined on the BFOR signal basis. We incorporate the BFOR signal basis into the LDDMM framework and derive the gradient descent algorithm for LDDMM-HYDI with explicit orientation optimization. Additionally, we extend the previous Bayesian atlas estimation framework for scalar-valued images to HYDIs and derive the expectation-maximization algorithm for solving the HYDI atlas estimation problem. Using real HYDI datasets, we show the Bayesian model generates the white matter atlas with anatomical details. Moreover, we show that it is important to consider the variation of mDWI reorientation due to a small change in diffeomorphic transformation in the LDDMM-HYDI optimization and to incorporate the full information of HYDI for aligning mDWI.',
	 'authors': u'Jia Du, A. Pasha Hosseinbor, Moo K. Chung, Barbara B. Bendlin, Gaurav Suryawanshi, Andrew L. Alexander, Anqi Qiu,',
	 'category': u'Computer Science ',
	 'date': '2013-9-25',
	 'pdflink': u'http://arxiv.org/pdf/1309.6379',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nDiffeomorphic Metric Mapping and Probabilistic Atlas Generation of  Hybrid Diffusion Imaging based on BFOR Signal Basis',
	 'urllink': u'http://arxiv.org/abs/1309.6379'}
2015-03-24 21:00:09+0000 [xxu46_7] INFO: Crawled 845 pages (at 1 pages/min), scraped 838 items (at 1 items/min)
2015-03-24 21:01:09+0000 [xxu46_7] INFO: Crawled 845 pages (at 0 pages/min), scraped 838 items (at 0 items/min)
2015-03-24 21:01:35+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5572> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 21:01:35+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5572>
	{'abstract': u'This article is a fundamental study in computable analysis. In the framework of Type-2 effectivity, TTE, we investigate computability aspects on finite and infinite products of effective topological spaces. For obtaining uniform results we introduce natural multi-representations of the class of all effective topological spaces, of their points, of their subsets and of their compact subsets. We show that the binary, finite and countable product operations on effective topological spaces are computable. For spaces with non-empty base sets the factors can be retrieved from the products. We study computability of the product operations on points, on arbitrary subsets and on compact subsets. For the case of compact sets the results are uniformly computable versions of Tychonoff\'s Theorem (stating that every Cartesian product of compact spaces is compact) for both, the cover multi-representation and the "minimal cover" multi-representation.',
	 'authors': u'Robert Rettinger, Klaus Weihrauch,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5572',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nProducts of effective topological spaces and a uniformly computable  Tychonoff Theorem',
	 'urllink': u'http://arxiv.org/abs/1310.5572'}
2015-03-24 21:02:09+0000 [xxu46_7] INFO: Crawled 846 pages (at 1 pages/min), scraped 839 items (at 1 items/min)
2015-03-24 21:03:09+0000 [xxu46_7] INFO: Crawled 846 pages (at 0 pages/min), scraped 839 items (at 0 items/min)
2015-03-24 21:03:23+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1311.4389> (referer: http://arxiv.org/list/cs/13?skip=12000&show=1000)
2015-03-24 21:03:23+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1311.4389>
	{'abstract': u"With the emergence and rapid growth of Social Media, a number of government departments in several countries have embraced Social Media as a privilege channel to interact with their constituency. We are exploring, in collaboration with the Australian Department of Human Services, the possibility to exploit the potential of social networks to support specific groups of citizens. To this end, we have developed Next Step, an online community to help people currently receiving welfare payments find a job and become financially self-sufficient. In this paper, we explore some ethical issues that arise when governments engage directly with citizens, in particular with communities in difficult situations, and when researchers are involved. We describe some of the challenges we faced and how we addressed them. Our work highlights the complexity of the problem, when an online community involves a government department and a welfare recipient group with a dependency relationship with that department. It becomes a balancing act, with the need to ensure privacy of the community members whilst still fulfilling the government's legal responsibilities. While difficult, these issues must be addressed if governments are to engage with their citizens using Social Media.",
	 'authors': u'C\xe9cile Paris, Nathalie Colineau, Surya Nepal, Sanat Bista, Gina Beschorner,',
	 'category': u'Computer Science ',
	 'date': '2013-11-15',
	 'pdflink': u'http://arxiv.org/pdf/1311.4389',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nEthical considerations in an online community: the balancing act',
	 'urllink': u'http://arxiv.org/abs/1311.4389'}
2015-03-24 21:04:09+0000 [xxu46_7] INFO: Crawled 847 pages (at 1 pages/min), scraped 840 items (at 1 items/min)
2015-03-24 21:04:25+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4452> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 21:04:25+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4452>
	{'abstract': u'Diverse selection statements -- if-then-else, switch and try-catch -- are commonly used in modern programming languages. To make things simple, we propose a unifying statement for selection. This statement turns out to have a simple syntax and semantics. Examples will be provided for this statement.',
	 'authors': u'Keehang Kwon,',
	 'category': u'Computer Science ',
	 'date': '2013-8-21',
	 'pdflink': u'http://arxiv.org/pdf/1308.4452',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nA New Statement for Selection and Exception Handling in Imperative  Languages',
	 'urllink': u'http://arxiv.org/abs/1308.4452'}
2015-03-24 21:05:09+0000 [xxu46_7] INFO: Crawled 848 pages (at 1 pages/min), scraped 841 items (at 1 items/min)
2015-03-24 21:06:09+0000 [xxu46_7] INFO: Crawled 848 pages (at 0 pages/min), scraped 841 items (at 0 items/min)
2015-03-24 21:06:22+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6369> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 21:06:22+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6369>
	{'abstract': u'In a social network, adoption probability refers to the probability that a social entity will adopt a product, service, or opinion in the foreseeable future. Such probabilities are central to fundamental issues in social network analysis, including the influence maximization problem. In practice, adoption probabilities have significant implications for applications ranging from social network-based target marketing to political campaigns; yet, predicting adoption probabilities has not received sufficient research attention. Building on relevant social network theories, we identify and operationalize key factors that affect adoption decisions: social influence, structural equivalence, entity similarity, and confounding factors. We then develop the locally-weighted expectation-maximization method for Na "ive Bayesian learning to predict adoption probabilities on the basis of these factors. The principal challenge addressed in this study is how to predict adoption probabilities in the presence of confounding factors that are generally unobserved. Using data from two large-scale social networks, we demonstrate the effectiveness of the proposed method. The empirical results also suggest that cascade methods primarily using social influence to predict adoption probabilities offer limited predictive power, and that confounding factors are critical to adoption probability predictions.',
	 'authors': u'Xiao Fang, Paul J. Hu, Zhepeng Li, Weiyu Tsai,',
	 'category': u'Computer Science ',
	 'date': '2013-9-24',
	 'pdflink': u'http://arxiv.org/pdf/1309.6369',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nPredicting Adoption Probabilities in Social Networks',
	 'urllink': u'http://arxiv.org/abs/1309.6369'}
2015-03-24 21:07:09+0000 [xxu46_7] INFO: Crawled 849 pages (at 1 pages/min), scraped 842 items (at 1 items/min)
2015-03-24 21:07:34+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5569> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 21:07:34+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5569>
	{'abstract': u'Emerging information-centric networking architectures seek to optimally utilize both bandwidth and storage for efficient content distribution. This highlights the need for joint design of traffic engineering and caching strategies, in order to optimize network performance in view of both current traffic loads and future traffic demands. We present a systematic framework for joint dynamic interest request forwarding and dynamic cache placement and eviction, within the context of the Named Data Networking (NDN) architecture. The framework employs a virtual control plane which operates on the user demand rate for data objects in the network, and an actual plane which handles Interest Packets and Data Packets. We develop distributed algorithms within the virtual plane to achieve network load balancing through dynamic forwarding and caching, thereby maximizing the user demand rate that the NDN network can satisfy. Numerical experiments within a number of network settings demonstrate the superior performance of the resulting algorithms for the actual plane in terms of low user delay and high rate of cache hits.',
	 'authors': u'Edmund Yeh, Tracey Ho, Ying Cui, Michael Burd, Ran Liu, Derek Leong,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5569',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nVIP: A Framework for Joint Dynamic Forwarding and Caching in Named Data  Networks',
	 'urllink': u'http://arxiv.org/abs/1310.5569'}
2015-03-24 21:08:09+0000 [xxu46_7] INFO: Crawled 850 pages (at 1 pages/min), scraped 843 items (at 1 items/min)
2015-03-24 21:08:42+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1311.4376> (referer: http://arxiv.org/list/cs/13?skip=12000&show=1000)
2015-03-24 21:08:42+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1311.4376>
	{'abstract': u'This article combines the vocabulary of semiotics and category theory to provide a formal analysis of visualization. It shows how familiar processes of visualization fit the semiotic frameworks of both Saussure and Peirce, and extends these structures using the tools of category theory to provide a general framework for understanding visualization in practice, including: relationships between systems, data collected from those systems, renderings of those data in the form of representations, the reading of those representations to create visualizations, and the use of those visualizations to create knowledge and understanding of the system under inspection. The resulting framework is validated by demonstrating how familiar information visualization concepts (such as literalness, sensitivity, redundancy, ambiguity, generalizability, and chart junk) arise naturally from it and can be defined formally and precisely. This article generalizes previous work on the formal characterization of visualization by, inter alia, Ziemkiewicz and Kosara and allows us to formally distinguish properties of the visualization process that previous work does not.',
	 'authors': u'Paul Vickers, Joe Faith, Nick Rossiter,',
	 'category': u'Computer Science ',
	 'date': '2013-11-18',
	 'pdflink': u'http://arxiv.org/pdf/1311.4376',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nUnderstanding Visualization: A Formal Approach using Category Theory and  Semiotics',
	 'urllink': u'http://arxiv.org/abs/1311.4376'}
2015-03-24 21:09:09+0000 [xxu46_7] INFO: Crawled 851 pages (at 1 pages/min), scraped 844 items (at 1 items/min)
2015-03-24 21:10:09+0000 [xxu46_7] INFO: Crawled 851 pages (at 0 pages/min), scraped 844 items (at 0 items/min)
2015-03-24 21:10:12+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4440> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 21:10:12+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4440>
	{'abstract': u'This paper focuses on two main issues; first one is the impact of combination of multi-sensor images on the supervised learning classification accuracy using segment Fusion (SF). The second issue attempts to undertake the study of supervised machine learning classification technique of remote sensing images by using four classifiers like Parallelepiped (Pp), Mahalanobis Distance (MD), Maximum-Likelihood (ML) and Euclidean Distance(ED) classifiers, and their accuracies have been evaluated on their respected classification to choose the best technique for classification of remote sensing images. QuickBird multispectral data (MS) and panchromatic data (PAN) have been used in this study to demonstrate the enhancement and accuracy assessment of fused image over the original images using ALwassaiProcess software. According to experimental result of this study, is that the test results indicate the supervised classification results of fusion image, which generated better than the MS did. As well as the result with Euclidean classifier is robust and provides better results than the other classifiers do, despite of the popular belief that the maximum-likelihood classifier is the most accurate classifier.',
	 'authors': u'AL-Wassai Firouz, N.V.Kalyankar,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/pdf/1308.4440',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nInfluences Combination of Multi-Sensor Images on Classification Accuracy',
	 'urllink': u'http://arxiv.org/abs/1308.4440'}
2015-03-24 21:11:09+0000 [xxu46_7] INFO: Crawled 852 pages (at 1 pages/min), scraped 845 items (at 1 items/min)
2015-03-24 21:11:35+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6352> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 21:11:35+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6352>
	{'abstract': u'Past work on personality detection has shown that frequency of lexical categories such as first person pronouns, past tense verbs, and sentiment words have significant correlations with personality traits. In this paper, for the first time, we show that fine affect (emotion) categories such as that of excitement, guilt, yearning, and admiration are significant indicators of personality. Additionally, we perform experiments to show that the gains provided by the fine affect categories are not obtained by using coarse affect categories alone or with specificity features alone. We employ these features in five SVM classifiers for detecting five personality traits through essays. We find that the use of fine emotion features leads to statistically significant improvement over a competitive baseline, whereas the use of coarse affect and specificity features does not.',
	 'authors': u'Saif M. Mohammad, Svetlana Kiritchenko,',
	 'category': u'Computer Science ',
	 'date': '2013-9-24',
	 'pdflink': u'http://arxiv.org/pdf/1309.6352',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nUsing Nuances of Emotion to Identify Personality',
	 'urllink': u'http://arxiv.org/abs/1309.6352'}
2015-03-24 21:12:09+0000 [xxu46_7] INFO: Crawled 853 pages (at 1 pages/min), scraped 846 items (at 1 items/min)
2015-03-24 21:12:59+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5568> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 21:12:59+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5568>
	{'abstract': u'The computational modeling of genetic regulatory networks is now common place, either by fitting a system to experimental data or by exploring the behaviour of abstract systems with the aim of identifying underlying principles. This paper presents an approach to the latter, considering the response to environmental changes of a well-known model placed upon tunable fitness landscapes. The effects on genome size and gene connectivity are explored.',
	 'authors': u'Larry Bull,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5568',
	 'subjects': u'Computational Engineering, Finance, and Science (cs.CE)',
	 'title': u'\nTowards Application of the RBNK Model',
	 'urllink': u'http://arxiv.org/abs/1310.5568'}
2015-03-24 21:13:09+0000 [xxu46_7] INFO: Crawled 854 pages (at 1 pages/min), scraped 847 items (at 1 items/min)
2015-03-24 21:14:09+0000 [xxu46_7] INFO: Crawled 854 pages (at 0 pages/min), scraped 847 items (at 0 items/min)
2015-03-24 21:14:22+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1311.4369> (referer: http://arxiv.org/list/cs/13?skip=12000&show=1000)
2015-03-24 21:14:22+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1311.4369>
	{'abstract': u'We introduce cooperative sequential state space estimation in the domain of augmented complex statistics, whereby nodes in a network collaborate locally to estimate noncircular complex signals. For rigour, a distributed augmented (widely linear) complex Kalman filter (D-ACKF) suited to the generality of complex signals is introduced, allowing for unified treatment of both proper (rotation invariant) and improper (rotation dependent) signal distributions. Its duality with the bivariate real-valued distributed Kalman filter, along with several issues of implementation are also illuminated. The analysis and simulations show that unlike existing distributed Kalman filter solutions, the D-ACKF caters for both the improper data and the correlations between nodal observation noises, thus providing enhanced performance in real-world scenarios.',
	 'authors': u'Dahir H. Dini, Sithan Kanna, Danilo P. Mandic,',
	 'category': u'Computer Science ',
	 'date': '2013-11-18',
	 'pdflink': u'http://arxiv.org/pdf/1311.4369',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nDistributed Widely Linear Complex Kalman Filtering',
	 'urllink': u'http://arxiv.org/abs/1311.4369'}
2015-03-24 21:15:09+0000 [xxu46_7] INFO: Crawled 855 pages (at 1 pages/min), scraped 848 items (at 1 items/min)
2015-03-24 21:15:37+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4434> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 21:15:37+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4434>
	{'abstract': u'Boolean operations of geometric models is an essential issue in computational geometry. In this paper, we develop a simple and robust approach to perform Boolean operations on closed and open triangulated surfaces. Our method mainly has two stages: (1) We firstly find out candidate intersected-triangles pairs based on Octree and then compute the inter-section lines for all pairs of triangles with parallel algorithm; (2) We form closed or open intersection-loops, sub-surfaces and sub-blocks quite robustly only according to the cleared and updated topology of meshes while without coordinate computations for geometric enti-ties. A novel technique instead of inside/outside classification is also proposed to distinguish the resulting union, subtraction and intersection. Several examples have been given to illus-trate the effectiveness of our approach.',
	 'authors': u'Gang Mei, John C. Tipper,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/pdf/1308.4434',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nSimple and Robust Boolean Operations for Triangulated Surfaces',
	 'urllink': u'http://arxiv.org/abs/1308.4434'}
2015-03-24 21:16:09+0000 [xxu46_7] INFO: Crawled 856 pages (at 1 pages/min), scraped 849 items (at 1 items/min)
2015-03-24 21:17:09+0000 [xxu46_7] INFO: Crawled 856 pages (at 0 pages/min), scraped 849 items (at 0 items/min)
2015-03-24 21:17:31+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6347> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 21:17:31+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6347>
	{'abstract': u'With the widespread use of email, we now have access to unprecedented amounts of text that we ourselves have written. In this paper, we show how sentiment analysis can be used in tandem with effective visualizations to quantify and track emotions in many types of mail. We create a large word--emotion association lexicon by crowdsourcing, and use it to compare emotions in love letters, hate mail, and suicide notes. We show that there are marked differences across genders in how they use emotion words in work-place email. For example, women use many words from the joy--sadness axis, whereas men prefer terms from the fear--trust axis. Finally, we show visualizations that can help people track emotions in their emails.',
	 'authors': u'Saif M. Mohammad, Tony, Yang,',
	 'category': u'Computer Science ',
	 'date': '2013-9-24',
	 'pdflink': u'http://arxiv.org/pdf/1309.6347',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nTracking Sentiment in Mail: How Genders Differ on Emotional Axes',
	 'urllink': u'http://arxiv.org/abs/1309.6347'}
2015-03-24 21:18:09+0000 [xxu46_7] INFO: Crawled 857 pages (at 1 pages/min), scraped 850 items (at 1 items/min)
2015-03-24 21:19:01+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5564> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 21:19:01+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5564>
	{'abstract': u'Energetic Reasoning (ER) is a powerful filtering algorithm for the Cumulative constraint. Unfortunately, ER is generally too costly to be used in practice. One reason of its bad behavior is that many intervals are considered as relevant by the checker of ER, although most of them should be ignored. In this paper, we provide a sharp characterization that allows to reduce the number of intervals by a factor seven. Our experiments show that associating this checker with a Time-Table filtering algorithm leads to promising results.',
	 'authors': u'Alban Derrien, Thierry Petit,',
	 'category': u'Computer Science ',
	 'date': '2013-10-16',
	 'pdflink': u'http://arxiv.org/pdf/1310.5564',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nThe Energetic Reasoning Checker Revisited',
	 'urllink': u'http://arxiv.org/abs/1310.5564'}
2015-03-24 21:19:09+0000 [xxu46_7] INFO: Crawled 858 pages (at 1 pages/min), scraped 851 items (at 1 items/min)
2015-03-24 21:20:09+0000 [xxu46_7] INFO: Crawled 858 pages (at 0 pages/min), scraped 851 items (at 0 items/min)
2015-03-24 21:21:00+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1311.4362> (referer: http://arxiv.org/list/cs/13?skip=12000&show=1000)
2015-03-24 21:21:00+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1311.4362>
	{'abstract': u"Posynomials are nonnegative combinations of monomials with possibly fractional and both positive and negative exponents. Posynomial models are widely used in various engineering design endeavors, such as circuits, aerospace and structural design, mainly due to the fact that design problems cast in terms of posynomial objectives and constraints can be solved efficiently by means of a convex optimization technique known as geometric programming (GP). However, while quite a vast literature exists on GP-based design, very few contributions can yet be found on the problem of identifying posynomial models from experimental data. Posynomial identification amounts to determining not only the coefficients of the combination, but also the exponents in the monomials, which renders the identification problem numerically hard. In this draft, we propose an approach to the identification of multivariate posynomial models, based on the expansion on a given large-scale basis of monomials. The model is then identified by seeking coefficients of the combination that minimize a mixed objective, composed by a term representing the fitting error and a term inducing sparsity in the representation, which results in a problem formulation of the ``square-root LASSO'' type, with nonnegativity constraints on the variables. We propose to solve the problem via a sequential coordinate-descent scheme, which is suitable for large-scale implementations.",
	 'authors': u'Giuseppe C. Calafiore, Laurent El Ghaoui, Carlo Novara,',
	 'category': u'Computer Science ',
	 'date': '2013-11-18',
	 'pdflink': u'http://arxiv.org/pdf/1311.4362',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nSparse Identification of Posynomial Models',
	 'urllink': u'http://arxiv.org/abs/1311.4362'}
2015-03-24 21:21:09+0000 [xxu46_7] INFO: Crawled 859 pages (at 1 pages/min), scraped 852 items (at 1 items/min)
2015-03-24 21:22:09+0000 [xxu46_7] INFO: Crawled 859 pages (at 0 pages/min), scraped 852 items (at 0 items/min)
2015-03-24 21:22:14+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4391> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 21:22:14+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4391>
	{'abstract': u'This paper studies the optimal and fair service allocation for a variety of mobile applications (single or group and collaborative mobile applications) in mobile cloud computing. We exploit the observation that using tiered clouds, i.e. clouds at multiple levels (local and public) can increase the performance and scalability of mobile applications. We proposed a novel framework to model mobile applications as a location-time workflows (LTW) of tasks; here users mobility patterns are translated to mobile service usage patterns. We show that an optimal mapping of LTWs to tiered cloud resources considering multiple QoS goals such application delay, device power consumption and user cost/price is an NP-hard problem for both single and group-based applications. We propose an efficient heuristic algorithm called MuSIC that is able to perform well (73% of optimal, 30% better than simple strategies), and scale well to a large number of users while ensuring high mobile application QoS. We evaluate MuSIC and the 2-tier mobile cloud approach via implementation (on real world clouds) and extensive simulations using rich mobile applications like intensive signal processing, video streaming and multimedia file sharing applications. Our experimental and simulation results indicate that MuSIC supports scalable operation (100+ concurrent users executing complex workflows) while improving QoS. We observe about 25% lower delays and power (under fixed price constraints) and about 35% decrease in price (considering fixed delay) in comparison to only using the public cloud. Our studies also show that MuSIC performs quite well under different mobility patterns, e.g. random waypoint and Manhattan models.',
	 'authors': u'M. Reza Rahimi, Nalini Venkatasubramanian, Sharad Mehrotra, Athanasios V. Vasilakos,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/pdf/1308.4391',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nOn Optimal and Fair Service Allocation in Mobile Cloud Computing',
	 'urllink': u'http://arxiv.org/abs/1308.4391'}
2015-03-24 21:23:09+0000 [xxu46_7] INFO: Crawled 860 pages (at 1 pages/min), scraped 853 items (at 1 items/min)
2015-03-24 21:24:07+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6311> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 21:24:07+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6311>
	{'abstract': u'In this paper, Bernstein piecewise polynomials are used to solve the integral equations numerically. A matrix formulation is given for a non-singular linear Fredholm Integral Equation by the technique of Galerkin method. In the Galerkin method, the Bernstein polynomials are used as the approximation of basis functions. Examples are considered to verify the effectiveness of the proposed derivations, and the numerical solutions guarantee the desired accuracy.',
	 'authors': u'Afroza Shirin, Md. Shafiqul Islam,',
	 'category': u'Computer Science ',
	 'date': '2013-9-24',
	 'pdflink': u'http://arxiv.org/pdf/1309.6311',
	 'subjects': u'Numerical Analysis (cs.NA)',
	 'title': u'\nNumerical Solutions of Fredholm Integral Equations Using Bernstein  Polynomials',
	 'urllink': u'http://arxiv.org/abs/1309.6311'}
2015-03-24 21:24:09+0000 [xxu46_7] INFO: Crawled 861 pages (at 1 pages/min), scraped 854 items (at 1 items/min)
2015-03-24 21:25:09+0000 [xxu46_7] INFO: Crawled 861 pages (at 0 pages/min), scraped 854 items (at 0 items/min)
2015-03-24 21:25:36+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5558> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 21:25:36+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5558>
	{'abstract': u"Networks of timed automata (NTA) are widely used to model distributed real-time systems. Quite often in the literature, the automata are allowed to share clocks, i.e. transitions of one automaton may be guarded by conditions on the value of clocks reset by another automaton. This is a problem when one considers implementing such model in a distributed architecture, since reading clocks a priori requires communications which are not explicitly described in the model. We focus on the following question: given an NTA A1 || A2 where A2 reads some clocks reset by A1, does there exist an NTA A'1 || A'2 without shared clocks with the same behavior as the initial NTA? For this, we allow the automata to exchange information during synchronizations only, in particular by copying the value of their neighbor's clocks. We discuss a formalization of the problem and define an appropriate behavioural equivalence. Then we give a criterion using the notion of contextual timed transition system, which represents the behavior of A2 when in parallel with A1. Finally, we effectively build A'1 || A'2 when it exists.",
	 'authors': u'Sandie Balaguer, Thomas Chatain,',
	 'category': u'Computer Science ',
	 'date': '2013-10-18',
	 'pdflink': u'http://arxiv.org/pdf/1310.5558',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nAvoiding Shared Clocks in Networks of Timed Automata',
	 'urllink': u'http://arxiv.org/abs/1310.5558'}
2015-03-24 21:26:09+0000 [xxu46_7] INFO: Crawled 862 pages (at 1 pages/min), scraped 855 items (at 1 items/min)
2015-03-24 21:26:47+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1311.4349> (referer: http://arxiv.org/list/cs/13?skip=12000&show=1000)
2015-03-24 21:26:47+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1311.4349>
	{'abstract': u'Early experiments have suggested that program auralization can convey information about program structure [8]. Languages like Pascal contain classes of construct that are similar in nature allowing hierarchical classification of their features. This taxonomy can be reflected in the design of musical signatures which are used within the CAITLIN program auralization system. Experiments using these hierarchical leitmotifs indicate whether or not their similarities can be put to good use in communicating information about program structure and state. (Note, at time of going to press experimental results could not be included. These will be presented at the conference and included later.)',
	 'authors': u'James L. Alty, Paul Vickers,',
	 'category': u'Computer Science ',
	 'date': '2013-11-18',
	 'pdflink': u'http://arxiv.org/pdf/1311.4349',
	 'subjects': u'Human-Computer Interaction (cs.HC)',
	 'title': u'\nThe CAITLIN Auralization System: Hierarchical Leitmotif Design as a Clue  to Program Comprehension',
	 'urllink': u'http://arxiv.org/abs/1311.4349'}
2015-03-24 21:27:09+0000 [xxu46_7] INFO: Crawled 863 pages (at 1 pages/min), scraped 856 items (at 1 items/min)
2015-03-24 21:28:09+0000 [xxu46_7] INFO: Crawled 863 pages (at 0 pages/min), scraped 856 items (at 0 items/min)
2015-03-24 21:28:44+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4371> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 21:28:44+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4371>
	{'abstract': u'A pay-TV consumer uses a decoder to access encrypted digital content. To this end, a decoder contains a chip capable of decrypting the content if provisioned with the appropriate content decryption keys. A key establishment protocol is used to secure the delivery of the content decryption keys to the chip. This paper presents a new key establishment protocol. The paper shows how the new protocol can be applied in a pay-TV system, and provides a comparison of the properties of the new protocol and existing protocols. In particular, it is shown that the new protocol offers a similar level of security as existing protocols against attacks in which content decryption keys are compromised and re-distributed. The main advantage of the new protocol is that it achieves the unique and desirable property of being able to restore security for future protocol executions without the need to replace any decoder in the event that all system components other than the content decryption chips have been compromised. By comparison, existing protocols necessitate the replacement of the entire decoder population in this scenario.',
	 'authors': u'Peter Roelse,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/pdf/1308.4371',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nA new key establishment protocol and its application in pay-TV systems',
	 'urllink': u'http://arxiv.org/abs/1308.4371'}
2015-03-24 21:29:09+0000 [xxu46_7] INFO: Crawled 864 pages (at 1 pages/min), scraped 857 items (at 1 items/min)
2015-03-24 21:30:09+0000 [xxu46_7] INFO: Crawled 864 pages (at 0 pages/min), scraped 857 items (at 0 items/min)
2015-03-24 21:30:36+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6307> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 21:30:36+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6307>
	{'abstract': u'We present a theorem for verification of optimality of controlled diffusions under the average cost criterion with near-monotone running cost, without invoking any blanket stability assumptions. The implications of this result to the policy iteration algorithm are also discussed.',
	 'authors': u'Ari Arapostathis,',
	 'category': u'Computer Science ',
	 'date': '2013-9-21',
	 'pdflink': u'http://arxiv.org/pdf/1309.6307',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nOn the Non-Uniqueness of Solutions to the Average Cost HJB for  Controlled Diffusions with Near-Monotone Costs',
	 'urllink': u'http://arxiv.org/abs/1309.6307'}
2015-03-24 21:31:09+0000 [xxu46_7] INFO: Crawled 865 pages (at 1 pages/min), scraped 858 items (at 1 items/min)
2015-03-24 21:31:56+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5557> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 21:31:56+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5557>
	{'abstract': u'During the last decade, we witnessed a rapid growth in deployment of pull-based P2P streaming applications. In these applications, each node selects some other nodes as its neighbors and requests streaming data from them. This scheme allows eliminating data redundancy and recovering from data loss, but it pushes the complexity to the receiver node side. In this paper, we theoretically study the scheduling problem in Pull-based P2P video streaming and we model it as an assignment problem. Then, we propose AsSched, new scheduling algorithm for layered streaming, in order to optimize the throughput and the delivery ratio of the system. In second time, we derive an optimal algorithm (NAsSched) for non layered streaming. The results of simulations show that our algorithms significantly outperform classic scheduling strategies especially in stern bandwidth constraints.',
	 'authors': u'Abbas Bradai, Toufik Ahmed,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5557',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nOn the Optimal Scheduling in Pull-based Real-Time P2P Streaming Systems:  Layered and Non-Layered Streaming',
	 'urllink': u'http://arxiv.org/abs/1310.5557'}
2015-03-24 21:32:09+0000 [xxu46_7] INFO: Crawled 866 pages (at 1 pages/min), scraped 859 items (at 1 items/min)
2015-03-24 21:32:56+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1311.4336> (referer: http://arxiv.org/list/cs/13?skip=12000&show=1000)
2015-03-24 21:32:56+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1311.4336>
	{'abstract': u'For the study of information propagation, one fundamental problem is uncovering universal laws governing the dynamics of information propagation. This problem, from the microscopic perspective, is formulated as estimating the propagation probability that a piece of information propagates from one individual to another. Such a propagation probability generally depends on two major classes of factors: the intrinsic attractiveness of information and the interactions between individuals. Despite the fact that the temporal effect of attractiveness is widely studied, temporal laws underlying individual interactions remain unclear, causing inaccurate prediction of information propagation on evolving social networks. In this report, we empirically study the dynamics of information propagation, using the dataset from a population-scale social media website. We discover a temporal scaling in information propagation: the probability a message propagates between two individuals decays with the length of time latency since their latest interaction, obeying a power-law rule. Leveraging the scaling law, we further propose a temporal model to estimate future propagation probabilities between individuals, reducing the error rate of information propagation prediction from 6.7% to 2.6% and improving viral marketing with 9.7% incremental customers.',
	 'authors': u'Junming Huang, Chao Li, Wen-Qiang Wang, Hua-Wei Shen, Guojie Li, Xue-Qi Cheng,',
	 'category': u'Computer Science ',
	 'date': '2013-11-18',
	 'pdflink': u'http://arxiv.org/pdf/1311.4336',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nTemporal scaling in information propagation',
	 'urllink': u'http://arxiv.org/abs/1311.4336'}
2015-03-24 21:33:09+0000 [xxu46_7] INFO: Crawled 867 pages (at 1 pages/min), scraped 860 items (at 1 items/min)
2015-03-24 21:34:09+0000 [xxu46_7] INFO: Crawled 867 pages (at 0 pages/min), scraped 860 items (at 0 items/min)
2015-03-24 21:34:35+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4368> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 21:34:35+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4368>
	{'abstract': u'The atoms of a regular language are non-empty intersections of complemented and uncomplemented quotients of the language. Tight upper bounds on the number of atoms of a language and on the quotient complexities of atoms are known. We introduce a new class of regular languages, called the maximally atomic languages, consisting of all languages meeting these bounds. We prove the following result: If L is a regular language of quotient complexity n and G is the subgroup of permutations in the transition semigroup T of the minimal DFA of L, then L is maximally atomic if and only if G is transitive on k-subsets of 1,...,n for 0 &lt;= k &lt;= n and T contains a transformation of rank n-1.',
	 'authors': u'Janusz Brzozowski, Gareth Davies,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/pdf/1308.4368',
	 'subjects': u'Formal Languages and Automata Theory (cs.FL)',
	 'title': u'\nMaximally Atomic Languages',
	 'urllink': u'http://arxiv.org/abs/1308.4368'}
2015-03-24 21:35:09+0000 [xxu46_7] INFO: Crawled 868 pages (at 1 pages/min), scraped 861 items (at 1 items/min)
2015-03-24 21:36:09+0000 [xxu46_7] INFO: Crawled 868 pages (at 0 pages/min), scraped 861 items (at 0 items/min)
2015-03-24 21:36:21+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6301> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 21:36:21+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6301>
	{'abstract': u'The OSCAR (octagonal selection and clustering algorithm for regression) regularizer consists of a L_1 norm plus a pair-wise L_inf norm (responsible for its grouping behavior) and was proposed to encourage group sparsity in scenarios where the groups are a priori unknown. The OSCAR regularizer has a non-trivial proximity operator, which limits its applicability. We reformulate this regularizer as a weighted sorted L_1 norm, and propose its grouping proximity operator (GPO) and approximate proximity operator (APO), thus making state-of-the-art proximal splitting algorithms (PSAs) available to solve inverse problems with OSCAR regularization. The GPO is in fact the APO followed by additional grouping and averaging operations, which are costly in time and storage, explaining the reason why algorithms with APO are much faster than that with GPO. The convergences of PSAs with GPO are guaranteed since GPO is an exact proximity operator. Although convergence of PSAs with APO is may not be guaranteed, we have experimentally found that APO behaves similarly to GPO when the regularization parameter of the pair-wise L_inf norm is set to an appropriately small value. Experiments on recovery of group-sparse signals (with unknown groups) show that PSAs with APO are very fast and accurate.',
	 'authors': u'Xiangrong Zeng, M\xe1rio A. T. Figueiredo,',
	 'category': u'Computer Science ',
	 'date': '2013-9-24',
	 'pdflink': u'http://arxiv.org/pdf/1309.6301',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nSolving OSCAR regularization problems by proximal splitting algorithms',
	 'urllink': u'http://arxiv.org/abs/1309.6301'}
2015-03-24 21:37:09+0000 [xxu46_7] INFO: Crawled 869 pages (at 1 pages/min), scraped 862 items (at 1 items/min)
2015-03-24 21:37:41+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5551> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 21:37:41+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5551>
	{'abstract': u'In this paper we will present SDeval, a software project that contains tools for creating and running benchmarks with a focus on problems in computer algebra. It is built on top of the Symbolic Data project, able to translate problems in the database into executable code for various computer algebra systems. The included tools are designed to be very flexible to use and to extend, such that they can be utilized even in contexts of other communities. With the presentation of SDEval, we will also address particularities of benchmarking in the field of computer algebra. Furthermore, with SDEval, we provide a feasible and automatizable way of reproducing benchmarks published in current research works, which appears to be a difficult task in general due to the customizability of the available programs. We will simultaneously present the current developments in the Symbolic Data project.',
	 'authors': u'Albert Heinle, Viktor Levandovskyy, Andreas Nareike,',
	 'category': u'Computer Science ',
	 'date': '2013-10-18',
	 'pdflink': u'http://arxiv.org/pdf/1310.5551',
	 'subjects': u'Symbolic Computation (cs.SC)',
	 'title': u'\nSymbolicData:SDEval - Benchmarking for Everyone',
	 'urllink': u'http://arxiv.org/abs/1310.5551'}
2015-03-24 21:38:09+0000 [xxu46_7] INFO: Crawled 870 pages (at 1 pages/min), scraped 863 items (at 1 items/min)
2015-03-24 21:39:09+0000 [xxu46_7] INFO: Crawled 870 pages (at 0 pages/min), scraped 863 items (at 0 items/min)
2015-03-24 21:39:12+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1311.4319> (referer: http://arxiv.org/list/cs/13?skip=12000&show=1000)
2015-03-24 21:39:12+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1311.4319>
	{'abstract': u'A common way of doing algorithm selection is to train a machine learning model and predict the best algorithm from a portfolio to solve a particular problem. While this method has been highly successful, choosing only a single algorithm has inherent limitations -- if the choice was bad, no remedial action can be taken and parallelism cannot be exploited, to name but a few problems. In this paper, we investigate how to predict the ranking of the portfolio algorithms on a particular problem. This information can be used to choose the single best algorithm, but also to allocate resources to the algorithms according to their rank. We evaluate a range of approaches to predict the ranking of a set of algorithms on a problem. We furthermore introduce a framework for categorizing ranking predictions that allows to judge the expressiveness of the predictive output. Our experimental evaluation demonstrates on a range of data sets from the literature that it is beneficial to consider the relationship between algorithms when predicting rankings. We furthermore show that relatively naive approaches deliver rankings of good quality already.',
	 'authors': u'Lars Kotthoff,',
	 'category': u'Computer Science ',
	 'date': '2013-11-18',
	 'pdflink': u'http://arxiv.org/pdf/1311.4319',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nRanking Algorithms by Performance',
	 'urllink': u'http://arxiv.org/abs/1311.4319'}
2015-03-24 21:40:09+0000 [xxu46_7] INFO: Crawled 871 pages (at 1 pages/min), scraped 864 items (at 1 items/min)
2015-03-24 21:40:45+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4338> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 21:40:45+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4338>
	{'abstract': u'This paper presents two approaches for filter design based on stochastic distances for intensity speckle reduction. A window is defined around each pixel, overlapping samples are compared and only those which pass a goodness-of-fit test are used to compute the filtered value. The tests stem from stochastic divergences within the Information Theory framework. The technique is applied to intensity Synthetic Aperture Radar (SAR) data with homogeneous regions using the Gamma model. The first approach uses a Nagao-Matsuyama-type procedure for setting the overlapping samples, and the second uses the nonlocal method. The proposals are compared with the Improved Sigma filter and with anisotropic diffusion for speckled data (SRAD) using a protocol based on Monte Carlo simulation. Among the criteria used to quantify the quality of filters, we employ the equivalent number of looks, and line and edge preservation. Moreover, we also assessed the filters by the Universal Image Quality Index and by the Pearson correlation between edges. Applications to real images are also discussed. The proposed methods show good results.',
	 'authors': u'Leonardo Torres, Alejandro C. Frery,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/pdf/1308.4338',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nSAR Image Despeckling Algorithms using Stochastic Distances and Nonlocal  Means',
	 'urllink': u'http://arxiv.org/abs/1308.4338'}
2015-03-24 21:41:09+0000 [xxu46_7] INFO: Crawled 872 pages (at 1 pages/min), scraped 865 items (at 1 items/min)
2015-03-24 21:42:09+0000 [xxu46_7] INFO: Crawled 872 pages (at 0 pages/min), scraped 865 items (at 0 items/min)
2015-03-24 21:42:30+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6297> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 21:42:30+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6297>
	{'abstract': u'We introduce novel mathematical models and algorithms to generate (shortest or k different) explanations for biomedical queries, using answer set programming. We implement these algorithms and integrate them in BIOQUERY-ASP. We illustrate the usefulness of these methods with some complex biomedical queries related to drug discovery, over the biomedical knowledge resources PHARMGKB, DRUGBANK, BIOGRID, CTD, SIDER, DISEASE ONTOLOGY and ORPHADATA. To appear in Theory and Practice of Logic Programming (TPLP).',
	 'authors': u'Esra Erdem, Umut Oztok,',
	 'category': u'Computer Science ',
	 'date': '2013-9-24',
	 'pdflink': u'http://arxiv.org/pdf/1309.6297',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nGenerating Explanations for Biomedical Queries',
	 'urllink': u'http://arxiv.org/abs/1309.6297'}
2015-03-24 21:43:09+0000 [xxu46_7] INFO: Crawled 873 pages (at 1 pages/min), scraped 866 items (at 1 items/min)
2015-03-24 21:43:58+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5542> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 21:43:58+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5542>
	{'abstract': u'There have been intensive research interests in ship detection and segmentation due to high demands on a wide range of civil applications in the last two decades. However, existing approaches, which are mainly based on statistical properties of images, fail to detect smaller ships and boats. Specifically, known techniques are not robust enough in view of inevitable small geometric and photometric changes in images consisting of ships. In this paper a novel approach for ship detection is proposed based on correlation of maritime images. The idea comes from the observation that a fine pattern of the sea surface changes considerably from time to time whereas the ship appearance basically keeps unchanged. We want to examine whether the images have a common unaltered part, a ship in this case. To this end, we developed a method - Focused Correlation (FC) to achieve robustness to geometric distortions of the image content. Various experiments have been conducted to evaluate the effectiveness of the proposed approach.',
	 'authors': u'Alexander Kadyrov, Hui Yu, Honghai Liu,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5542',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nShip Detection and Segmentation using Image Correlation',
	 'urllink': u'http://arxiv.org/abs/1310.5542'}
2015-03-24 21:44:09+0000 [xxu46_7] INFO: Crawled 874 pages (at 1 pages/min), scraped 867 items (at 1 items/min)
2015-03-24 21:45:09+0000 [xxu46_7] INFO: Crawled 874 pages (at 0 pages/min), scraped 867 items (at 0 items/min)
2015-03-24 21:45:58+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1311.4317> (referer: http://arxiv.org/list/cs/13?skip=12000&show=1000)
2015-03-24 21:45:58+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1311.4317>
	{'abstract': u'Multimedia streaming to mobile devices is challenging for two reasons. First, the way content is delivered to a client must ensure that the user does not experience a long initial playback delay or a distorted playback in the middle of a streaming session. Second, multimedia streaming applications are among the most energy hungry applications in smartphones. The energy consumption mostly depends on the delivery techniques and on the power management techniques of wireless access technologies (Wi-Fi, 3G, and 4G). In order to provide insights on what kind of streaming techniques exist, how they work on different mobile platforms, their efforts in providing smooth quality of experience, and their impact on energy consumption of mobile phones, we did a large set of active measurements with several smartphones having both Wi-Fi and cellular network access. Our analysis reveals five different techniques to deliver the content to the video players. The selection of a technique depends on the mobile platform, device, player, quality, and service. The results from our traffic and power measurements allow us to conclude that none of the identified techniques is optimal because they take none of the following facts into account: access technology used, user behavior, and user preferences concerning data waste. We point out the technique with optimal playback buffer configuration, which provides the most attractive trade-offs in particular situations.',
	 'authors': u'Mohammad Ashraful Hoque, Matti Siekkinen, Jukka K. Nurminen, Mika Aalto, Sasu Tarkoma,',
	 'category': u'Computer Science ',
	 'date': '2013-11-18',
	 'pdflink': u'http://arxiv.org/pdf/1311.4317',
	 'subjects': u'Multimedia (cs.MM)',
	 'title': u'\nMobile Multimedia Streaming Techniques : QoE and Energy Consumption  Perspective',
	 'urllink': u'http://arxiv.org/abs/1311.4317'}
2015-03-24 21:46:09+0000 [xxu46_7] INFO: Crawled 875 pages (at 1 pages/min), scraped 868 items (at 1 items/min)
2015-03-24 21:47:09+0000 [xxu46_7] INFO: Crawled 875 pages (at 0 pages/min), scraped 868 items (at 0 items/min)
2015-03-24 21:47:43+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4316> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 21:47:43+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4316>
	{'abstract': u'As the number of charging Plug-in Electric Vehicles (PEVs) increase, due to the limited power capacity of the distribution feeders and the sensitivity of the mid-way distribution transformers to the excessive load, it is crucial to control the amount of power through each specific distribution feeder to avoid system overloads that may lead to breakdowns. In this paper we develop, analyze and evaluate charging algorithms for PEVs with feeder overload constraints in the distribution grid. The algorithms we propose jointly minimize the variance of the aggregate load and prevent overloading of the distribution feeders.',
	 'authors': u'Abouzar Ghavami, Koushik Kar, Aparna Gupta,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/pdf/1308.4316',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nDecentralized Charging of Plug-In Electric Vehicles with Distribution  Feeder Overload Control',
	 'urllink': u'http://arxiv.org/abs/1308.4316'}
2015-03-24 21:48:09+0000 [xxu46_7] INFO: Crawled 876 pages (at 1 pages/min), scraped 869 items (at 1 items/min)
2015-03-24 21:49:09+0000 [xxu46_7] INFO: Crawled 876 pages (at 0 pages/min), scraped 869 items (at 0 items/min)
2015-03-24 21:49:39+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6290> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 21:49:39+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6290>
	{'abstract': u'In this paper we present the Large Inverse Cholesky (LIC) method, an efficient method for computing the coefficient matrices of a Structural Vector Autoregressive (SVAR) model.',
	 'authors': u'Aravindh Krishnamoorthy,',
	 'category': u'Computer Science ',
	 'date': '2013-9-23',
	 'pdflink': u'http://arxiv.org/pdf/1309.6290',
	 'subjects': u'Numerical Analysis (cs.NA)',
	 'title': u'\nCoefficient Matrices Computation of Structural Vector Autoregressive  Model',
	 'urllink': u'http://arxiv.org/abs/1309.6290'}
2015-03-24 21:50:09+0000 [xxu46_7] INFO: Crawled 877 pages (at 1 pages/min), scraped 870 items (at 1 items/min)
2015-03-24 21:51:00+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5538> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 21:51:00+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5538>
	{'abstract': u'Modern computer systems are awash in a sea of asynchronous events. There is an increasing need for a declarative language that can permit business users to specify complex event-processing rules. Such rules should be able to correlate different event streams, detect absence of events (negative information), permit aggregations over sliding windows, specify dependent sliding windows etc. For instance it should be possible to precisely state a rule such as "Every seventh trading session that DowJones has risen consecutively, and IBM\'s stock is off 3% over its average in this period, evaluate IBM position", "Declare the sensor as faulty if no reading has been received for 500 ms", etc. Further, the language should be implementable efficiently in an event-driven fashion. We propose the Timed (Default) Concurrent Constraint, TCC, programming framework as a foundation for such complex event processing. While very rich, the TCC framework "forgets" information from one instant to the next. We make two extensions. First, we extend the TCC model to carry the store from previous time instants as "past" information in the current time instant. This permits rules to to be written with rich queries over the past. Second, we show that many of the powerful properties of the agent language can be folded into the query language by permitting agents and queries to be defined mutually recursively, building on the testing interpretation of intuitionistic logic described in RCC cite. We show that this permits queries to move "back and forth" in the past, e.g. "Order a review if the last time that IBM stock price dropped by 10% in a day, there was more than 20% increase in trading volume for Oracle the following day." We provide a formal semantics for TCC + Histories and establish some basic properties.',
	 'authors': u'Vijay Saraswat, Radha Jagadeesan, Vineet Gupta,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5538',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nTCC, with History',
	 'urllink': u'http://arxiv.org/abs/1310.5538'}
2015-03-24 21:51:09+0000 [xxu46_7] INFO: Crawled 878 pages (at 1 pages/min), scraped 871 items (at 1 items/min)
2015-03-24 21:52:09+0000 [xxu46_7] INFO: Crawled 878 pages (at 0 pages/min), scraped 871 items (at 0 items/min)
2015-03-24 21:52:54+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1311.4310> (referer: http://arxiv.org/list/cs/13?skip=12000&show=1000)
2015-03-24 21:52:54+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1311.4310>
	{'abstract': u'The bidirectional relay channel, in which two users communicate with each other through a relay node, is a simple but fundamental and practical network architecture. In this paper, we consider the block fading bidirectional relay channel and propose efficient transmission strategies that exploit the block fading property of the channel. Thereby, we consider a decode-and-forward relay and assume that a direct link between the two users is not present. Our aim is to characterize the long-term achievable rate region and to develop protocols which achieve all points of the obtained rate region. Specifically, in the bidirectional relay channel, there exist six possible transmission modes: four point-to-point modes (user 1-to-relay, user 2-to-relay, relay-to-user 1, relay-to-user 2), a multiple-access mode (both users to the relay), and a broadcast mode (the relay to both users). Most existing protocols assume a fixed schedule for using a subset of the aforementioned transmission modes. Motivated by this limitation, we develop protocols which are not restricted to adhere to a predefined schedule for using the transmission modes. In fact, based on the instantaneous channel state information (CSI) of the involved links, the proposed protocol selects the optimal transmission mode in each time slot to maximize the long-term achievable rate region. Thereby, we consider two different types of transmit power constraints: 1) a joint long-term power constraint for all nodes, and 2) a fixed transmit power for each node. Furthermore, to enable the use of a non-predefined schedule for transmission mode selection, the relay has to be equipped with two buffers for storage of the information received from both users. As data buffering increases the end-to-end delay, we consider both delay-unconstrained and delay-constrained transmission in the paper.',
	 'authors': u'Vahid Jamali, Nikola Zlatanov, Aissa Ikhlef, Robert Schober,',
	 'category': u'Computer Science ',
	 'date': '2013-11-18',
	 'pdflink': u'http://arxiv.org/pdf/1311.4310',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nAchievable Rate Region of the Bidirectional Buffer-Aided Relay Channel  with Block Fading',
	 'urllink': u'http://arxiv.org/abs/1311.4310'}
2015-03-24 21:53:09+0000 [xxu46_7] INFO: Crawled 879 pages (at 1 pages/min), scraped 872 items (at 1 items/min)
2015-03-24 21:53:53+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4294> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 21:53:53+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4294>
	{'abstract': u'In this paper we study the time delays affecting the diffusion of information in an underwater heterogeneous robot swarm, considering a time-sensitive environment. In many situations each member of the swarm must update its knowledge about the environment as soon as possible, thus every effort to expand the knowledge horizon is useful. Otherwise critical information may not reach nodes far from the source causing dangerous misbehaviour of the swarm. We consider two extreme situations. In the first scenario we have an unique probabilistic delay distribution. In the second scenario, each agent is subject to a different truncated gaussian distribution, meaning local conditions are significantly different from link to link. We study how several swarm topologies react to the two scenarios and how to allocate the more efficient transmission resources in order to expand the horizon. Results show that significant time savings under a gossip-like protocol are possible properly allocating the resources. Moreover, methods to determine the fastest swarm topologies and the most important nodes are suggested.',
	 'authors': u'Enzo Fioriti, Stefano Chiesa, Fabio Fratichini,',
	 'category': u'Computer Science ',
	 'date': '2013-8-19',
	 'pdflink': u'http://arxiv.org/pdf/1308.4294',
	 'subjects': u'Robotics (cs.RO)',
	 'title': u'\nExpanding the Knowledge Horizon in Underwater Robot Swarms',
	 'urllink': u'http://arxiv.org/abs/1308.4294'}
2015-03-24 21:54:09+0000 [xxu46_7] INFO: Crawled 880 pages (at 1 pages/min), scraped 873 items (at 1 items/min)
2015-03-24 21:55:09+0000 [xxu46_7] INFO: Crawled 880 pages (at 0 pages/min), scraped 873 items (at 0 items/min)
2015-03-24 21:55:39+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6280> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 21:55:39+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6280>
	{'abstract': u'In this paper we consider a fragment of the first-order theory of the real numbers that includes systems of equations of continuous functions in bounded domains, and for which all functions are computable in the sense that it is possible to compute arbitrarily close piece-wise interval approximations. Even though this fragment is undecidable, we prove that there is a (possibly non-terminating) algorithm for checking satisfiability such that (1) whenever it terminates, it computes a correct answer, and (2) it always terminates when the input is robust. A formula is robust, if its satisfiability does not change under small perturbations. As a basic tool for our algorithm we use the notion of degree from the field of (differential) topology.',
	 'authors': u'Peter Franek, Stefan Ratschan, Piotr Zgliczynski,',
	 'category': u'Computer Science ',
	 'date': '2013-9-24',
	 'pdflink': u'http://arxiv.org/pdf/1309.6280',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nQuasi-decidability of a Fragment of the First-order Theory of Real  Numbers',
	 'urllink': u'http://arxiv.org/abs/1309.6280'}
2015-03-24 21:56:09+0000 [xxu46_7] INFO: Crawled 881 pages (at 1 pages/min), scraped 874 items (at 1 items/min)
2015-03-24 21:57:09+0000 [xxu46_7] INFO: Crawled 881 pages (at 0 pages/min), scraped 874 items (at 0 items/min)
2015-03-24 21:57:39+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5534> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 21:57:39+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5534>
	{'abstract': u"We introduce an atomic congestion game with two types of agents, cars and trucks, to model the traffic flow on a road over various time intervals of the day. Cars maximize their utility by finding a trade-off between the time they choose to use the road, the average velocity of the flow at that time, and the dynamic congestion tax that they pay for using the road. In addition to these terms, the trucks have an incentive for using the road at the same time as their peers because they have platooning capabilities, which allow them to save fuel. The dynamics and equilibria of this game-theoretic model for the interaction between car traffic and truck platooning incentives are investigated. We use traffic data from Stockholm to validate parts of the modeling assumptions and extract reasonable parameters for the simulations. We use joint strategy fictitious play and average strategy fictitious play to learn a pure strategy Nash equilibrium of this game. We perform a comprehensive simulation study to understand the influence of various factors, such as the drivers' value of time and the percentage of the trucks that are equipped with platooning devices, on the properties of the Nash equilibrium.",
	 'authors': u'Farhad Farokhi, Karl H. Johansson,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5534',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nA Study of Truck Platooning Incentives Using a Congestion Game',
	 'urllink': u'http://arxiv.org/abs/1310.5534'}
2015-03-24 21:58:09+0000 [xxu46_7] INFO: Crawled 882 pages (at 1 pages/min), scraped 875 items (at 1 items/min)
2015-03-24 21:59:09+0000 [xxu46_7] INFO: Crawled 882 pages (at 0 pages/min), scraped 875 items (at 0 items/min)
2015-03-24 21:59:36+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1311.4306> (referer: http://arxiv.org/list/cs/13?skip=12000&show=1000)
2015-03-24 21:59:36+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1311.4306>
	{'abstract': u'We propose a partition-based state estimator for linear discrete-time systems composed by coupled subsystems affected by bounded disturbances. The architecture is distributed in the sense that each subsystem is equipped with a local state estimator that exploits suitable pieces of information from parent subsystems. Moreover, differently from methods based on moving horizon estimation, our approach does not require the on-line solution to optimization problems. Our state-estimation scheme, that is based on the notion of practical robust positive invariance developed in Rakovic 2011, also guarantees satisfaction of constraints on local estimation errors and it can be updated with a limited computational effort when subsystems are added or removed.',
	 'authors': u'S. Riverso, D. Rubini, G. Ferrari-Trecate,',
	 'category': u'Computer Science ',
	 'date': '2013-11-18',
	 'pdflink': u'http://arxiv.org/pdf/1311.4306',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nDistributed bounded-error state estimation for partitioned systems based  on practical robust positive invariance',
	 'urllink': u'http://arxiv.org/abs/1311.4306'}
2015-03-24 22:00:09+0000 [xxu46_7] INFO: Crawled 883 pages (at 1 pages/min), scraped 876 items (at 1 items/min)
2015-03-24 22:01:09+0000 [xxu46_7] INFO: Crawled 883 pages (at 0 pages/min), scraped 876 items (at 0 items/min)
2015-03-24 22:01:30+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4291> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 22:01:30+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4291>
	{'abstract': u'A morph between two straight-line planar drawings of the same graph is a continuous transformation from the first to the second drawing such that planarity is preserved at all times. Each step of the morph moves each vertex at constant speed along a straight line. Although the existence of a morph between any two drawings was established several decades ago, only recently it has been proved that a polynomial number of steps suffices to morph any two planar straight-line drawings. Namely, at SODA 2013, Alamdari et al.[1] proved that any two planar straight-line drawings of a planar graph can be morphed in O(n^4) steps, while O(n^2) steps suffice if we restrict to maximal planar graphs. In this paper, we improve upon such results, by showing an algorithm to morph any two planar straight-line drawings of a planar graph in O(n^2) steps; further, we show that a morph with O(n) steps exists between any two planar straight-line drawings of a series-parallel graph.',
	 'authors': u'Patrizio Angelini, Fabrizio Frati, Maurizio Patrignani, Vincenzo Roselli,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/pdf/1308.4291',
	 'subjects': u'Computational Geometry (cs.CG)',
	 'title': u'\nMorphing Planar Graphs Drawings Efficiently',
	 'urllink': u'http://arxiv.org/abs/1308.4291'}
2015-03-24 22:02:09+0000 [xxu46_7] INFO: Crawled 884 pages (at 1 pages/min), scraped 877 items (at 1 items/min)
2015-03-24 22:02:42+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6226> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 22:02:42+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6226>
	{'abstract': u'We review the history of the automation of mathematical induction',
	 'authors': u'J Strother Moore, Claus-Peter Wirth,',
	 'category': u'Computer Science ',
	 'date': '2013-9-24',
	 'pdflink': u'http://arxiv.org/pdf/1309.6226',
	 'subjects': u'Artificial Intelligence (cs.AI)',
	 'title': u'\nAutomation of Mathematical Induction as part of the History of Logic',
	 'urllink': u'http://arxiv.org/abs/1309.6226'}
2015-03-24 22:03:09+0000 [xxu46_7] INFO: Crawled 885 pages (at 1 pages/min), scraped 878 items (at 1 items/min)
2015-03-24 22:04:09+0000 [xxu46_7] INFO: Crawled 885 pages (at 0 pages/min), scraped 878 items (at 0 items/min)
2015-03-24 22:04:31+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5515> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 22:04:31+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5515>
	{'abstract': u"The rank modulation scheme has been proposed for efficient writing and storing data in non-volatile memory storage. Error-correction in the rank modulation scheme is done by considering permutation codes. In this paper we consider codes in the set of all permutations on elements, , using the Kendall's -metric. We prove that there are no perfect single-error-correcting codes in , where is a prime or . We also prove that if such a code exists for which is not a prime then the code should have some uniform structure. We define some variations of the Kendall's -metric and consider the related codes and specifically we prove the existence of a perfect single-error-correcting code in . Finally, we examine the existence problem of diameter perfect codes in and obtain a new upper bound on the size of a code in with even minimum Kendall's -distance.",
	 'authors': u'Sarit Buzaglo, Tuvi Etzion,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5515',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u"\nPerfect Permutation Codes with the Kendall's $\u03c4$-Metric",
	 'urllink': u'http://arxiv.org/abs/1310.5515'}
2015-03-24 22:05:09+0000 [xxu46_7] INFO: Crawled 886 pages (at 1 pages/min), scraped 879 items (at 1 items/min)
2015-03-24 22:06:09+0000 [xxu46_7] INFO: Crawled 886 pages (at 0 pages/min), scraped 879 items (at 0 items/min)
2015-03-24 22:06:25+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1311.4305> (referer: http://arxiv.org/list/cs/13?skip=12000&show=1000)
2015-03-24 22:06:25+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1311.4305>
	{'abstract': u'One of many approaches to better take advantage of parallelism, which has now become mainstream, is the introduction of parallel programming languages. However, parallelism is by nature non-deterministic, and not all parallel bugs can be avoided by language design. This paper proposes a method for guaranteeing absence of data races in the polyhedral subset of clocked X10 programs. Clocks in X10 are similar to barriers, but are more dynamic; the subset of processes that participate in the synchronization can dynamically change at runtime. We construct the happens-before relation for clocked X10 programs, and show that the problem of race detection is undecidable. However, in many practical cases, modern tools are able to find solutions or disprove their existence. We present a set of benchmarks for which the analysis is possible and has an acceptable running time.',
	 'authors': u'Tomofumi Yuki, Paul Feautrier, Sanjay Rajopadhye, Vijay Saraswat,',
	 'category': u'Computer Science ',
	 'date': '2013-11-18',
	 'pdflink': u'http://arxiv.org/pdf/1311.4305',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nChecking Race Freedom of Clocked X10 Programs',
	 'urllink': u'http://arxiv.org/abs/1311.4305'}
2015-03-24 22:07:09+0000 [xxu46_7] INFO: Crawled 887 pages (at 1 pages/min), scraped 880 items (at 1 items/min)
2015-03-24 22:08:02+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4280> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 22:08:02+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4280>
	{'abstract': u'Despite the high throughput and low complexity achieved by input scheduling based on Birkhoff-von-Neumann (BvN) decomposition; the performance of the BvN switch becomes less predictable when the input traffic is bursty. In this paper, we propose a deflection-compensated BvN (D-BvN) switch architecture to enhance the quasi-static scheduling based on BvN decomposition. The D-BvN switches provide capacity guarantee for virtual circuits (VCs) and deflect bursty traffic when overflow occurs. The deflection scheme is devised to offset the excessive buffer requirement of each VC when input traffic is bursty. The design of our conditional deflection mechanism is based on the fact that it is unlikely that the traffic input to VCs is all bursty at the same time; most likely some starving VCs have spare capacities when some other VCs are in the overflow state. The proposed algorithm makes full use of the spare capacities of those starving VCs to deflect the overflow traffic to other inputs and provide bandwidth for the deflected traffic to re-access the desired VC. Our analysis and simulation show that this deflection-compensated mechanism can support BvN switches to achieve close to 100% throughput of offered load even with bursty input traffic, and reduces the average end-to-end delay and delay jitter. Also, our result indicates that the packet out-of-sequence probability due to deflection of overflow traffic is negligible, thus only a small re-sequencing buffer is needed at each output port.',
	 'authors': u'Jinghui Zhang, Tong Ye, Tony T. Lee, Fangfang Yan, Weisheng Hu,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/pdf/1308.4280',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nBirkhoff-von-Neumann Switches with Deflection-Compensated Mechanism',
	 'urllink': u'http://arxiv.org/abs/1308.4280'}
2015-03-24 22:08:09+0000 [xxu46_7] INFO: Crawled 888 pages (at 1 pages/min), scraped 881 items (at 1 items/min)
2015-03-24 22:09:09+0000 [xxu46_7] INFO: Crawled 888 pages (at 0 pages/min), scraped 881 items (at 0 items/min)
2015-03-24 22:09:19+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6204> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 22:09:19+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6204>
	{'abstract': u"In an undirected social graph, a friendship link involves two users and the friendship is visible in both the users' friend lists. Such a dual visibility of the friendship may raise privacy threats. This is because both users can separately control the visibility of a friendship link to other users and their privacy policies for the link may not be consistent. Even if one of them conceals the link from a third user, the third user may find such a friendship link from another user's friend list. In addition, as most users allow their friends to see their friend lists in most social network systems, an adversary can exploit the inconsistent policies to launch privacy attacks to identify and infer many of a targeted user's friends. In this paper, we propose, analyze and evaluate such an attack which is called Friendship Identification and Inference (FII) attack. In a FII attack scenario, we assume that an adversary can only see his friend list and the friend lists of his friends who do not hide the friend lists from him. Then, a FII attack contains two attack steps: 1) friend identification and 2) friend inference. In the friend identification step, the adversary tries to identify a target's friends based on his friend list and those of his friends. In the friend inference step, the adversary attempts to infer the target's friends by using the proposed random walk with restart approach. We present experimental results using three real social network datasets and show that FII attacks are generally efficient and effective when adversaries and targets are friends or 2-distant neighbors. We also comprehensively analyze the attack results in order to find what values of parameters and network features could promote FII attacks. Currently, most popular social network systems with an undirected friendship graph, such as Facebook, LinkedIn and Foursquare, are susceptible to FII attacks.",
	 'authors': u'Lei Jin, Xuelian Long, James Joshi,',
	 'category': u'Computer Science ',
	 'date': '2013-9-24',
	 'pdflink': u'http://arxiv.org/e-print/1309.6204',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nA Friendship Privacy Attack on Friends and 2-Distant Neighbors in Social  Networks',
	 'urllink': u'http://arxiv.org/abs/1309.6204'}
2015-03-24 22:10:09+0000 [xxu46_7] INFO: Crawled 889 pages (at 1 pages/min), scraped 882 items (at 1 items/min)
2015-03-24 22:11:05+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5497> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 22:11:05+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5497>
	{'abstract': u'Computer Assisted Medical Intervention (CAMI hereafter) is a complex multi-disciplinary field. CAMI research requires the collaboration of experts in several fields as diverse as medicine, computer science, mathematics, instrumentation, signal processing, mechanics, modeling, automatics, optics, etc.',
	 'authors': u'Emmanuel Promayon, Celine Fouard, Mathieu Bailet, Aurelien Deram, Gaelle Fiard, Nikolai Hungr, Vincent Luboz, Yohan Payan, Johan Sarrazin, Nicolas Saubat, Sonia Yuki Selmi, Sandrine Voros, Philippe Cinquin, Jocelyne Troccaz,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5497',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nUsing CamiTK for rapid prototyping of interactive Computer Assisted  Medical Intervention applications',
	 'urllink': u'http://arxiv.org/abs/1310.5497'}
2015-03-24 22:11:09+0000 [xxu46_7] INFO: Crawled 890 pages (at 1 pages/min), scraped 883 items (at 1 items/min)
2015-03-24 22:12:09+0000 [xxu46_7] INFO: Crawled 890 pages (at 0 pages/min), scraped 883 items (at 0 items/min)
2015-03-24 22:13:02+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1311.4303> (referer: http://arxiv.org/list/cs/13?skip=12000&show=1000)
2015-03-24 22:13:02+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1311.4303>
	{'abstract': u'Despite its great importance, modern network infrastructure is remarkable for the lack of rigor in its engineering. The Internet which began as a research experiment was never designed to handle the users and applications it hosts today. The lack of formalization of the Internet architecture meant limited abstractions and modularity, especially for the control and management planes, thus requiring for every new need a new protocol built from scratch. This led to an unwieldy ossified Internet architecture resistant to any attempts at formal verification, and an Internet culture where expediency and pragmatism are favored over formal correctness. Fortunately, recent work in the space of clean slate Internet design---especially, the software defined networking (SDN) paradigm---offers the Internet community another chance to develop the right kind of architecture and abstractions. This has also led to a great resurgence in interest of applying formal methods to specification, verification, and synthesis of networking protocols and applications. In this paper, we present a self-contained tutorial of the formidable amount of work that has been done in formal methods, and present a survey of its applications to networking.',
	 'authors': u'Junaid Qadir, Osman Hasan,',
	 'category': u'Computer Science ',
	 'date': '2013-11-18',
	 'pdflink': u'http://arxiv.org/pdf/1311.4303',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nApplying Formal Methods to Networking: Theory, Techniques and  Applications',
	 'urllink': u'http://arxiv.org/abs/1311.4303'}
2015-03-24 22:13:09+0000 [xxu46_7] INFO: Crawled 891 pages (at 1 pages/min), scraped 884 items (at 1 items/min)
2015-03-24 22:14:09+0000 [xxu46_7] INFO: Crawled 891 pages (at 0 pages/min), scraped 884 items (at 0 items/min)
2015-03-24 22:14:46+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4275> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 22:14:46+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4275>
	{'abstract': u'Estimating the number of eigenvalues located in a given interval of a large sparse Hermitian matrix is an important problem in certain applications and it is a prerequisite of eigensolvers based on a divide-and-conquer paradigm. Often an exact count is not necessary and methods based on stochastic estimates can be utilized to yield rough approximations. This paper examines a number of techniques tailored to this specific task. It reviews standard approaches and explores new ones based on polynomial and rational approximation filtering combined with a stochastic procedure.',
	 'authors': u'Edoardo Di Napoli, Eric Polizzi, Yousef Saad,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/pdf/1308.4275',
	 'subjects': u'Numerical Analysis (cs.NA)',
	 'title': u'\nEfficient estimation of eigenvalue counts in an interval',
	 'urllink': u'http://arxiv.org/abs/1308.4275'}
2015-03-24 22:15:09+0000 [xxu46_7] INFO: Crawled 892 pages (at 1 pages/min), scraped 885 items (at 1 items/min)
2015-03-24 22:15:44+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6202> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 22:15:44+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6202>
	{'abstract': u'Recent years have brought a significant growth in the volume of research in sentiment analysis, mostly on highly subjective text types (movie or product reviews). The main difference these texts have with news articles is that their target is clearly defined and unique across the text. Following different annotation efforts and the analysis of the issues encountered, we realised that news opinion mining is different from that of other text types. We identified three subtasks that need to be addressed: definition of the target; separation of the good and bad news content from the good and bad sentiment expressed on the target; and analysis of clearly marked opinion that is expressed explicitly, not needing interpretation or the use of world knowledge. Furthermore, we distinguish three different possible views on newspaper articles - author, reader and text, which have to be addressed differently at the time of analysing sentiment. Given these definitions, we present work on mining opinions about entities in English language news, in which (a) we test the relative suitability of various sentiment dictionaries and (b) we attempt to separate positive or negative opinion from good or bad news. In the experiments described here, we tested whether or not subject domain-defining vocabulary should be ignored. Results showed that this idea is more appropriate in the context of news opinion mining and that the approaches taking this into consideration produce a better performance.',
	 'authors': u'Alexandra Balahur, Ralf Steinberger, Mijail Kabadjov, Vanni Zavarella, Erik van der Goot, Matina Halkia, Bruno Pouliquen, Jenya Belyaeva,',
	 'category': u'Computer Science ',
	 'date': '2013-9-24',
	 'pdflink': u'http://arxiv.org/pdf/1309.6202',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nSentiment Analysis in the News',
	 'urllink': u'http://arxiv.org/abs/1309.6202'}
2015-03-24 22:16:09+0000 [xxu46_7] INFO: Crawled 893 pages (at 1 pages/min), scraped 886 items (at 1 items/min)
2015-03-24 22:16:58+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5493> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 22:16:58+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5493>
	{'abstract': u"We prove that for , the bound given by Brooks' theorem on the chromatic number of -th powers of graphs of maximum degree can be lowered by 1, even in the case of online list coloring.",
	 'authors': u'Marthe Bonamy, Nicolas Bousquet,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5493',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u"\nBrooks' theorem on powers of graphs",
	 'urllink': u'http://arxiv.org/abs/1310.5493'}
2015-03-24 22:17:09+0000 [xxu46_7] INFO: Crawled 894 pages (at 1 pages/min), scraped 887 items (at 1 items/min)
2015-03-24 22:18:09+0000 [xxu46_7] INFO: Crawled 894 pages (at 0 pages/min), scraped 887 items (at 0 items/min)
2015-03-24 22:18:46+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1311.4296> (referer: http://arxiv.org/list/cs/13?skip=12000&show=1000)
2015-03-24 22:18:46+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1311.4296>
	{'abstract': u'Recently, it has become evident that submodularity naturally captures widely occurring concepts in machine learning, signal processing and computer vision. Consequently, there is need for efficient optimization procedures for submodular functions, especially for minimization problems. While general submodular minimization is challenging, we propose a new method that exploits existing decomposability of submodular functions. In contrast to previous approaches, our method is neither approximate, nor impractical, nor does it need any cumbersome parameter tuning. Moreover, it is easy to implement and parallelize. A key component of our method is a formulation of the discrete submodular minimization problem as a continuous best approximation problem that is solved through a sequence of reflections, and its solution can be easily thresholded to obtain an optimal discrete solution. This method solves both the continuous and discrete formulations of the problem, and therefore has applications in learning, inference, and reconstruction. In our experiments, we illustrate the benefits of our method on two image segmentation tasks.',
	 'authors': u'Stefanie Jegelka, Francis Bach, Suvrit Sra,',
	 'category': u'Computer Science ',
	 'date': '2013-11-18',
	 'pdflink': u'http://arxiv.org/pdf/1311.4296',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nReflection methods for user-friendly submodular optimization',
	 'urllink': u'http://arxiv.org/abs/1311.4296'}
2015-03-24 22:19:09+0000 [xxu46_7] INFO: Crawled 895 pages (at 1 pages/min), scraped 888 items (at 1 items/min)
2015-03-24 22:20:09+0000 [xxu46_7] INFO: Crawled 895 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2015-03-24 22:20:29+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4274> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 22:20:29+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4274>
	{'abstract': u'In this paper, we study the fiber-chaos of switched linear dynamical systems.',
	 'authors': u'Xiongping Dai, Tingwen Huang, Yu Huang, Mingqing Xiao,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/pdf/1308.4274',
	 'subjects': u'Systems and Control (cs.SY)',
	 'title': u'\nChaotic Characteristic of Discrete-time Linear Inclusion Dynamical  Systems',
	 'urllink': u'http://arxiv.org/abs/1308.4274'}
2015-03-24 22:21:09+0000 [xxu46_7] INFO: Crawled 896 pages (at 1 pages/min), scraped 889 items (at 1 items/min)
2015-03-24 22:22:09+0000 [xxu46_7] INFO: Crawled 896 pages (at 0 pages/min), scraped 889 items (at 0 items/min)
2015-03-24 22:22:30+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6200> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 22:22:30+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6200>
	{'abstract': u'This paper studies second-order coding rates for memoryless channels with a state sequence known non-causally at the encoder. In the case of finite alphabets, an achievability result is obtained using constant-composition random coding, and by using a small fraction of the block to transmit the type of the state sequence. For error probabilities less than 1/2, it is shown that the second-order rate improves on an existing one based on i.i.d. random coding. In the Gaussian case (dirty paper coding) with an almost-sure power constraint, an achievability result is obtained used using random coding over the surface of a sphere, and using a small fraction of the block to transmit a quantized description of the state power. It is shown that the second-order asymptotics are identical to the single-user Gaussian channel of the same input power without a state.',
	 'authors': u'Jonathan Scarlett,',
	 'category': u'Computer Science ',
	 'date': '2013-9-24',
	 'pdflink': u'http://arxiv.org/pdf/1309.6200',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u"\nOn the Dispersions of the Gel'fand-Pinsker Channel and Dirty Paper  Coding",
	 'urllink': u'http://arxiv.org/abs/1309.6200'}
2015-03-24 22:23:09+0000 [xxu46_7] INFO: Crawled 897 pages (at 1 pages/min), scraped 890 items (at 1 items/min)
2015-03-24 22:24:03+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5485> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 22:24:03+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5485>
	{'abstract': u'Crowd sensing is a new paradigm which leverages the ubiquity of sensor-equipped mobile devices to collect data. To achieve good quality for crowd sensing, incentive mechanisms are indispensable to attract more participants. Most of existing mechanisms focus on the expected utility prior to sensing, ignoring the risk of low quality solution and privacy leakage. Traditional incentive mechanisms such as the Vickrey-Clarke-Groves (VCG) mechanism and its variants are not applicable here. In this paper, to address these challenges, we propose a behavior based incentive mechanism for crowd sensing applications with budget constraints by applying sequential all-pay auctions in mobile social networks (MSNs), not only to consider the effects of extensive user participation, but also to maximize high quality of the context based sensing content submission for crowd sensing platform under the budget constraints, where users arrive in a sequential order. Through an extensive simulation, results indicate that incentive mechanisms in our proposed framework outperform the best existing solution.',
	 'authors': u'Jiajun Sun,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5485',
	 'subjects': u'Computer Science and Game Theory (cs.GT)',
	 'title': u'\nBehavior-Based online Incentive Mechanism for Crowd Sensing with Budget  Constraints',
	 'urllink': u'http://arxiv.org/abs/1310.5485'}
2015-03-24 22:24:09+0000 [xxu46_7] INFO: Crawled 898 pages (at 1 pages/min), scraped 891 items (at 1 items/min)
2015-03-24 22:25:09+0000 [xxu46_7] INFO: Crawled 898 pages (at 0 pages/min), scraped 891 items (at 0 items/min)
2015-03-24 22:26:00+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1311.4294> (referer: http://arxiv.org/list/cs/13?skip=12000&show=1000)
2015-03-24 22:26:00+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1311.4294>
	{'abstract': u'Weighted average sampling is more practical and numerically more stable than sampling at single points as in the classical Shannon sampling framework. Using the frame theory, one can completely reconstruct a bandlimited function from its suitably-chosen average sample data. When only finitely many sample data are available, truncating the complete reconstruction series with the standard dual frame results in very slow convergence. We present in this note a method of reconstructing a bandlimited function from finite average oversampling with an exponentially-decaying approximation error.',
	 'authors': u'Haizhang Zhang,',
	 'category': u'Computer Science ',
	 'date': '2013-11-18',
	 'pdflink': u'http://arxiv.org/pdf/1311.4294',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nExponential Approximation of Bandlimited Functions from Average  Oversampling',
	 'urllink': u'http://arxiv.org/abs/1311.4294'}
2015-03-24 22:26:09+0000 [xxu46_7] INFO: Crawled 899 pages (at 1 pages/min), scraped 892 items (at 1 items/min)
2015-03-24 22:27:09+0000 [xxu46_7] INFO: Crawled 899 pages (at 0 pages/min), scraped 892 items (at 0 items/min)
2015-03-24 22:27:43+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4268> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 22:27:43+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4268>
	{'abstract': u'In this thesis, we present a new method for designing multirate signal processing and digital communication systems via sampled-data H-infinity control theory. The difference between our method and conventional ones is in the signal spaces. Conventional designs are executed in the discrete-time domain, while our design takes account of both the discrete-time and the continuous-time signals. Namely, our method can take account of the characteristic of the original analog signal and the influence of the A/D and D/A conversion. While the conventional method often indicates that an ideal digital low-pass filter is preferred, we show that the optimal solution need not be an ideal low-pass when the original analog signal is not completely band-limited. This fact can not be recognized only in the discrete-time domain. Moreover, we consider quantization effects. We discuss the stability and the performance of quantized sampled-data control systems. We justify H-infinity control to reduce distortion caused by the quantizer. Then we apply it to differential pulse code modulation. While the conventional Delta modulator is not optimal and besides not stable, our modulator is stable and optimal with respect to the H-infinity-norm. We also give an LMI (Linear Matrix Inequality) solution to the optimal H-infinity approximation of IIR (Infinite Impulse Response) filters via FIR (Finite Impulse Response) filters. A comparison with the Nehari shuffle is made with a numerical example, and it is observed that the LMI solution generally performs better. Another numerical study also indicates that there is a trade-off between the pass-band and stop-band approximation characteristics.',
	 'authors': u'Masaaki Nagahara,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/pdf/1308.4268',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nMultirate Digital Signal Processing via Sampled-Data H-infinity  Optimization',
	 'urllink': u'http://arxiv.org/abs/1308.4268'}
2015-03-24 22:28:09+0000 [xxu46_7] INFO: Crawled 900 pages (at 1 pages/min), scraped 893 items (at 1 items/min)
2015-03-24 22:29:09+0000 [xxu46_7] INFO: Crawled 900 pages (at 0 pages/min), scraped 893 items (at 0 items/min)
2015-03-24 22:29:36+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6195> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 22:29:36+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6195>
	{'abstract': u'Compressed Sensing based Terahertz imaging (CS-THz) is a computational imaging technique. It uses only one THz receiver to accumulate the random modulated image measurements where the original THz image is reconstruct from these measurements using compressed sensing solvers. The advantage of the CS-THz is its reduced acquisition time compared with the raster scan mode. However, when it applied to large-scale two-dimensional (2D) imaging, the increased dimension resulted in both high computational complexity and excessive memory usage. In this paper, we introduced a novel CS-based THz imaging system that progressively compressed the THz image column by column. Therefore, the CS-THz system could be simplified with a much smaller sized modulator and reduced dimension. In order to utilize the block structure and the correlation of adjacent columns of the THz image, a complex-valued block sparse Bayesian learning algorithm was proposed. We conducted systematic evaluation of state-of-the-art CS algorithms under the scan based CS-THz architecture. The compression ratios and the choices of the sensing matrices were analyzed in detail using both synthetic and real-life THz images. Simulation results showed that both the scan based architecture and the proposed recovery algorithm were superior and efficient for large scale CS-THz applications.',
	 'authors': u'Benyuan Liu, Hongqi Fan, Zaiqi Lu, Qiang Fu,',
	 'category': u'Computer Science ',
	 'date': '2013-9-20',
	 'pdflink': u'http://arxiv.org/pdf/1309.6195',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nScan-based Compressed Terahertz Imaging and Real-Time Reconstruction via  the Complex-valued Fast Block Sparse Bayesian Learning Algorithm',
	 'urllink': u'http://arxiv.org/abs/1309.6195'}
2015-03-24 22:30:09+0000 [xxu46_7] INFO: Crawled 901 pages (at 1 pages/min), scraped 894 items (at 1 items/min)
2015-03-24 22:31:02+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5479> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 22:31:02+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5479>
	{'abstract': u'This work gives an overview of analytic tools for the design, analysis, and modelling of communication systems which can be described by linear vector channels such as y = Hx+z where the number of components in each vector is large. Tools from probability theory, operator algebra, and statistical physics are reviewed. The survey of analytical tools is complemented by examples of applications in communications engineering. Asymptotic eigenvalue distributions of many classes of random matrices are given. The treatment includes the problem of moments and the introduction of the Stieltjes transform. Free probability theory, which evolved from non-commutative operator algebras, is explained from a probabilistic point of view in order to better fit the engineering community. For that purpose freeness is defined without reference to non-commutative algebras. The treatment includes additive and multiplicative free convolution, the R-transform, the S-transform, and the free central limit theorem. The replica method developed in statistical physics for the purpose of analyzing spin glasses is reviewed from the viewpoint of its applications in communications engineering. Correspondences between free energy and mutual information as well as energy functions and detector metrics are established. These analytic tools are applied to the design and the analysis of linear multiuser detectors, the modelling of scattering in communication channels with dual antennas arrays, and the analysis of optimal detection for communication via code-division multiple-access and/or dual antenna array channels.',
	 'authors': u'Ralf R. M\xfcller, Giusi Alfano, Benjamin M. Zaidel, Rodrigo de Miguel,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5479',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nApplications of Large Random Matrices in Communications Engineering',
	 'urllink': u'http://arxiv.org/abs/1310.5479'}
2015-03-24 22:31:09+0000 [xxu46_7] INFO: Crawled 902 pages (at 1 pages/min), scraped 895 items (at 1 items/min)
2015-03-24 22:32:09+0000 [xxu46_7] INFO: Crawled 902 pages (at 0 pages/min), scraped 895 items (at 0 items/min)
2015-03-24 22:33:02+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1311.4293> (referer: http://arxiv.org/list/cs/13?skip=12000&show=1000)
2015-03-24 22:33:02+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1311.4293>
	{'abstract': u'Internet of Things (IoT) grows quickly, and 50 billion of IoT devices will be interconnected by 2020. For the huge number of IoT devices, a high scalable discovery architecture is required to provide autonomous registration and look-up of IoT resources and services. The architecture should enable dynamic updates when new IoT devices are incorporated into Internet, and changes are made to the existing ones. Nowadays in Internet, the most used discovery architecture is the Domain Name System (DNS). DNS offers a scalable solution through two distributed mechanisms: multicast DNS (mDNS) and DNS Service Directory (DNS-SD). Both mechanisms have been applied to discover resources and services in local IoT domains. However, a full architecture has not still been designed to support global discovery, local directories and a search engine for ubiquitous IoT domains. Moreover, the architecture should provide other transversal functionalities such as a common semantic for describing services and resources, and a service layer for interconnecting with M2M platforms and mobile clients. This paper presents an oriented-service architecture based on DNS to support a global discovery, local directories and a distributed search engine to enable a scalable looking-up of IoT resources and services. The architecture provides two lightweight discovery mechanisms based on mDNS and DNS-SD that have been optimized for the constraints of IoT devices to allow autonomous registration. Moreover, we analyse and provide other relevant elements such semantic description and communications interfaces to support the heterogeneity of IoT devices and clients. All these elements contribute to build a scalable architecture for the discovery and access of heterogeneous and ubiquitous IoT domains.',
	 'authors': u'Pablo Lopez, David Fernandez, Rafael Marin-Perez, Antonio J. Jara, Antonio F. Gomez-Skarmeta,',
	 'category': u'Computer Science ',
	 'date': '2013-11-18',
	 'pdflink': u'http://arxiv.org/pdf/1311.4293',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nScalable Oriented-Service Architecture for Heterogeneous and Ubiquitous  IoT Domains',
	 'urllink': u'http://arxiv.org/abs/1311.4293'}
2015-03-24 22:33:09+0000 [xxu46_7] INFO: Crawled 903 pages (at 1 pages/min), scraped 896 items (at 1 items/min)
2015-03-24 22:34:09+0000 [xxu46_7] INFO: Crawled 903 pages (at 0 pages/min), scraped 896 items (at 0 items/min)
2015-03-24 22:34:56+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4263> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 22:34:56+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4263>
	{'abstract': u'The aim of this paper is to introduce a new schema, based on a Compressive Sampling technique, for the recovery of lost data in multimedia streaming. The audio streaming data are encapsuled in different packets by using an interleaving technique. The Compressive Sampling technique is used to recover audio information in case of lost packets. Experimental results are presented on speech and musical audio signals to illustrate the performances and the capabilities of the proposed methodology.',
	 'authors': u'Angelo Ciaramella, Giulio Giunta,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/pdf/1308.4263',
	 'subjects': u'Multimedia (cs.MM)',
	 'title': u'\nCompressive Sampling for the Packet Loss Recovery in Audio Multimedia  Streaming',
	 'urllink': u'http://arxiv.org/abs/1308.4263'}
2015-03-24 22:35:09+0000 [xxu46_7] INFO: Crawled 904 pages (at 1 pages/min), scraped 897 items (at 1 items/min)
2015-03-24 22:36:09+0000 [xxu46_7] INFO: Crawled 904 pages (at 0 pages/min), scraped 897 items (at 0 items/min)
2015-03-24 22:36:30+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6185> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 22:36:30+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6185>
	{'abstract': u'We are presenting work on recognising acronyms of the form Long-Form (Short-Form) such as "International Monetary Fund (IMF)" in millions of news articles in twenty-two languages, as part of our more general effort to recognise entities and their variants in news text and to use them for the automatic analysis of the news, including the linking of related news across languages. We show how the acronym recognition patterns, initially developed for medical terms, needed to be adapted to the more general news domain and we present evaluation results. We describe our effort to automatically merge the numerous long-form variants referring to the same short-form, while keeping non-related long-forms separate. Finally, we provide extensive statistics on the frequency and the distribution of short-form/long-form pairs across languages.',
	 'authors': u'Maud Ehrmann, Leonida della Rocca, Ralf Steinberger, Hristo Tanev,',
	 'category': u'Computer Science ',
	 'date': '2013-9-24',
	 'pdflink': u'http://arxiv.org/pdf/1309.6185',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nAcronym recognition and processing in 22 languages',
	 'urllink': u'http://arxiv.org/abs/1309.6185'}
2015-03-24 22:37:09+0000 [xxu46_7] INFO: Crawled 905 pages (at 1 pages/min), scraped 898 items (at 1 items/min)
2015-03-24 22:37:44+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5478> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 22:37:44+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5478>
	{'abstract': u'Videos are composed of sequence of interrelated frames. There is a minute difference among frames. Flicker is an error which is found in every video. It is like a checker box in a video, there are several reasons behind flickers generation, one of the main reasons is refresh rate of the monitor and second reason is number of frames per second in a video. The main objective of this study is to propose and develop a framework that identifies flicker location and minimizes the flickers rate. Analysis shows that flickers can be minimize by adjusting the persistence of pixel and higher refresh rate of CRT monitor. Further we have compared different isotopes of phosphorous pixels and generate its graphs. This paper highlighted the cause of flicker and its avoidance .Statistical research proves that proposed algorithm improves the video quality and reduce flickers ratio up to 90%.',
	 'authors': u'Adnan Alam Khan, Safeeullah Soomro, Abdul Ghafoor Memon,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5478',
	 'subjects': u'Other Computer Science (cs.OH)',
	 'title': u'\nFlickers Forecasting In CRT Using Stochastic Analysis',
	 'urllink': u'http://arxiv.org/abs/1310.5478'}
2015-03-24 22:38:09+0000 [xxu46_7] INFO: Crawled 906 pages (at 1 pages/min), scraped 899 items (at 1 items/min)
2015-03-24 22:39:09+0000 [xxu46_7] INFO: Crawled 906 pages (at 0 pages/min), scraped 899 items (at 0 items/min)
2015-03-24 22:39:25+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1311.4289> (referer: http://arxiv.org/list/cs/13?skip=12000&show=1000)
2015-03-24 22:39:25+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1311.4289>
	{'abstract': u'Propositional satisfiability (SAT) solvers, which typically operate using conjunctive normal form (CNF), have been successfully applied in many domains. However, in some application areas such as circuit verification, bounded model checking, and logical cryptanalysis, instances can have many parity (xor) constraints which may not be handled efficiently if translated to CNF. Thus, extensions to the CNF-driven search with various parity reasoning engines ranging from equivalence reasoning to incremental Gaussian elimination have been proposed. This paper studies how stronger parity reasoning techniques in the DPLL(XOR) framework can be simulated by simpler systems: resolution, unit propagation, and parity explanations. Such simulations are interesting, for example, for developing the next generation SAT solvers capable of handling parity constraints efficiently.',
	 'authors': u'Tero Laitinen, Tommi Junttila, Ilkka Niemel\xe4,',
	 'category': u'Computer Science ',
	 'date': '2013-11-18',
	 'pdflink': u'http://arxiv.org/pdf/1311.4289',
	 'subjects': u'Logic in Computer Science (cs.LO)',
	 'title': u'\nSimulating Parity Reasoning (extended version)',
	 'urllink': u'http://arxiv.org/abs/1311.4289'}
2015-03-24 22:40:09+0000 [xxu46_7] INFO: Crawled 907 pages (at 1 pages/min), scraped 900 items (at 1 items/min)
2015-03-24 22:41:09+0000 [xxu46_7] INFO: Crawled 907 pages (at 0 pages/min), scraped 900 items (at 0 items/min)
2015-03-24 22:41:13+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4218> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 22:41:13+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4218>
	{'abstract': u"(VC) allows a computationally weak client to outsource the evaluation of a function on many inputs to a powerful but untrusted server. The client invests a large amount of off-line computation and gives an encoding of its function to the server. The server returns both an evaluation of the function on the client's input and a proof such that the client can verify the evaluation using substantially less effort than doing the evaluation on its own. We consider how to privately outsource computations using VC schemes whose executions reveal no information on the client's input or function to the server. We construct VC schemes with for univariate polynomial evaluation and matrix multiplication and then extend them such that the is also achieved. Our tool is the recently developed . The proposed VC schemes can be used in outsourcing .",
	 'authors': u'Liang Feng Zhang, Rehanehi Safavi-Naini,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/pdf/1308.4218',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nPrivate Outsourcing of Polynomial Evaluation and Matrix Multiplication  using Multilinear Maps',
	 'urllink': u'http://arxiv.org/abs/1308.4218'}
2015-03-24 22:42:09+0000 [xxu46_7] INFO: Crawled 908 pages (at 1 pages/min), scraped 901 items (at 1 items/min)
2015-03-24 22:43:04+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6176> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 22:43:04+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6176>
	{'abstract': u'In this paper, we first present a new variant of Gaussian restricted Boltzmann machine (GRBM) called multivariate Gaussian restricted Boltzmann machine (MGRBM), with its definition and learning algorithm. Then we propose using a learned GRBM or MGRBM to extract better features for robust speech recognition. Our experiments on Aurora2 show that both GRBM-extracted and MGRBM-extracted feature performs much better than Mel-frequency cepstral coefficient (MFCC) with either HMM-GMM or hybrid HMM-deep neural network (DNN) acoustic model, and MGRBM-extracted feature is slightly better.',
	 'authors': u'Xin Zheng, Zhiyong Wu, Helen Meng, Weifeng Li, Lianhong Cai,',
	 'category': u'Computer Science ',
	 'date': '2013-9-23',
	 'pdflink': u'http://arxiv.org/pdf/1309.6176',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nFeature Learning with Gaussian Restricted Boltzmann Machine for Robust  Speech Recognition',
	 'urllink': u'http://arxiv.org/abs/1309.6176'}
2015-03-24 22:43:09+0000 [xxu46_7] INFO: Crawled 909 pages (at 1 pages/min), scraped 902 items (at 1 items/min)
2015-03-24 22:44:09+0000 [xxu46_7] INFO: Crawled 909 pages (at 0 pages/min), scraped 902 items (at 0 items/min)
2015-03-24 22:44:52+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5476> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 22:44:52+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5476>
	{'abstract': u"Radio Frequency Identification (RFID) is a technology aimed at eficiently identifying and tracking goods and assets. Such identification may be performed without requiring line-of-sight alignment or physical contact between the RFID tag and the RFID reader, whilst tracking is naturally achieved due to the short interrogation field of RFID readers. That is why the reduction in price of the RFID tags has been accompanied with an increasing attention paid to this technology. However, since tags are resource-constrained devices sending identification data wirelessly, designing secure and private RFID identification protocols is a challenging task. This scenario is even more complex when scalability must be met by those protocols. Assuming the existence of a lightweight, secure, private and scalable RFID identification protocol, there exist other concerns surrounding the RFID technology. Some of them arise from the technology itself, such as distance checking, but others are related to the potential of RFID systems to gather huge amount of tracking data. Publishing and mining such moving objects data is essential to improve efficiency of supervisory control, assets management and localisation, transportation, etc. However, obvious privacy threats arise if an individual can be linked with some of those published trajectories. The present dissertation contributes to the design of algorithms and protocols aimed at dealing with the issues explained above. First, we propose a set of protocols and heuristics based on a distributed architecture that improve the e?ciency of the identification process without compromising privacy or security. Moreover, we present a novel distance-bounding protocol based on graphs that is extremely low-resource consuming. Finally, we present two trajectory anonymisation methods aimed at preserving the individuals' privacy when their trajectories are released.",
	 'authors': u'Rolando Trujillo-Rasua,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5476',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nPrivacy in RFID and mobile objects',
	 'urllink': u'http://arxiv.org/abs/1310.5476'}
2015-03-24 22:45:09+0000 [xxu46_7] INFO: Crawled 910 pages (at 1 pages/min), scraped 903 items (at 1 items/min)
2015-03-24 22:46:09+0000 [xxu46_7] INFO: Crawled 910 pages (at 0 pages/min), scraped 903 items (at 0 items/min)
2015-03-24 22:46:37+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1311.4276> (referer: http://arxiv.org/list/cs/13?skip=12000&show=1000)
2015-03-24 22:46:37+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1311.4276>
	{'abstract': u"Online genealogy datasets contain extensive information about millions of people and their past and present family connections. This vast amount of data can assist in identifying various patterns in human population. In this study, we present methods and algorithms which can assist in identifying variations in lifespan distributions of human population in the past centuries, in detecting social and genetic features which correlate with human lifespan, and in constructing predictive models of human lifespan based on various features which can easily be extracted from genealogy datasets. We have evaluated the presented methods and algorithms on a large online genealogy dataset with over a million profiles and over 9 million connections, all of which were collected from the WikiTree website. Our findings indicate that significant but small positive correlations exist between the parents' lifespan and their children's lifespan. Additionally, we found slightly higher and significant correlations between the lifespans of spouses. We also discovered a very small positive and significant correlation between longevity and reproductive success in males, and a small and significant negative correlation between longevity and reproductive success in females. Moreover, our machine learning algorithms presented better than random classification results in predicting which people who outlive the age of 50 will also outlive the age of 80. We believe that this study will be the first of many studies which utilize the wealth of data on human populations, existing in online genealogy datasets, to better understand factors which influence human lifespan. Understanding these factors can assist scientists in providing solutions for successful aging.",
	 'authors': u'Michael Fire, Yuval Elovici,',
	 'category': u'Computer Science ',
	 'date': '2013-11-18',
	 'pdflink': u'http://arxiv.org/pdf/1311.4276',
	 'subjects': u'Social and Information Networks (cs.SI)',
	 'title': u'\nData Mining of Online Genealogy Datasets for Revealing Lifespan Patterns  in Human Population',
	 'urllink': u'http://arxiv.org/abs/1311.4276'}
2015-03-24 22:47:09+0000 [xxu46_7] INFO: Crawled 911 pages (at 1 pages/min), scraped 904 items (at 1 items/min)
2015-03-24 22:47:58+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4208> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 22:47:58+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4208>
	{'abstract': u'Cloud Computing emerges from the global economic crisis as an option to use computing resources from a more rational point of view. In other words, a cheaper way to have IT resources. However, issues as security and privacy, SLA (Service Layer Agreement), resource sharing, and billing has left open questions about the real gains of that model. This study aims to investigate state-of-the-art in Cloud Computing, identify gaps, challenges, synthesize available evidences both its use and development, and provides relevant information, clarifying open questions and common discussed issues about that model through literature. The good practices of systematic map- ping study methodology were adopted in order to reach those objectives. Al- though Cloud Computing is based on a business model with over 50 years of existence, evidences found in this study indicate that Cloud Computing still presents limitations that prevent the full use of the proposal on-demand.',
	 'authors': u'Jose Fernando S. Carvalho, Paulo Anselmo da Mota Silveira Neto, Vincius Cardoso Garcia, Rodrigo Elia Assad, Frederico Durao,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/pdf/1308.4208',
	 'subjects': u'Distributed, Parallel, and Cluster Computing (cs.DC)',
	 'title': u'\nA Systematic Mapping Study on Cloud Computing',
	 'urllink': u'http://arxiv.org/abs/1308.4208'}
2015-03-24 22:48:09+0000 [xxu46_7] INFO: Crawled 912 pages (at 1 pages/min), scraped 905 items (at 1 items/min)
2015-03-24 22:49:09+0000 [xxu46_7] INFO: Crawled 912 pages (at 0 pages/min), scraped 905 items (at 0 items/min)
2015-03-24 22:49:59+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6162> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 22:49:59+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6162>
	{'abstract': u'This paper describes a new, freely available, highly multilingual named entity resource for person and organisation names that has been compiled over seven years of large-scale multilingual news analysis combined with Wikipedia mining, resulting in 205,000 per-son and organisation names plus about the same number of spelling variants written in over 20 different scripts and in many more languages. This resource, produced as part of the Europe Media Monitor activity (EMM, this http URL), can be used for a number of purposes. These include improving name search in databases or on the internet, seeding machine learning systems to learn named entity recognition rules, improve machine translation results, and more. We describe here how this resource was created; we give statistics on its current size; we address the issue of morphological inflection; and we give details regarding its functionality. Updates to this resource will be made available daily.',
	 'authors': u'Ralf Steinberger, Bruno Pouliquen, Mijail Kabadjov, Erik van der Goot,',
	 'category': u'Computer Science ',
	 'date': '2013-9-24',
	 'pdflink': u'http://arxiv.org/pdf/1309.6162',
	 'subjects': u'Computation and Language (cs.CL)',
	 'title': u'\nJRC-Names: A freely available, highly multilingual named entity resource',
	 'urllink': u'http://arxiv.org/abs/1309.6162'}
2015-03-24 22:50:09+0000 [xxu46_7] INFO: Crawled 913 pages (at 1 pages/min), scraped 906 items (at 1 items/min)
2015-03-24 22:51:09+0000 [xxu46_7] INFO: Crawled 913 pages (at 0 pages/min), scraped 906 items (at 0 items/min)
2015-03-24 22:51:54+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5474> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 22:51:54+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5474>
	{'abstract': u'There are various types of disability egress in world like blindness, deafness, and Physical disabilities. It is quite difficult to deal with people with disability. Learning disability (LD) is types of disability totally different from general disability. To deal children with learning disability is difficult for both parents and teacher. As parent deal with only single child so it bit easy. But teacher deals with different students at a time so its more difficult to deal with group of students with learning disability. If there is more students with learning disability so it is necessary that first all identify the type of learning disability in group of students. Some students have learning disability of mathematics; some have learning disability of other subjects. By using theory of Automata it easy to analysis the level of disability among all students then deal with them accordingly. For these purpose deterministic automata is the best practice. Teacher deals with deterministic students in class and check there response. In this research deterministic automata is use to facilitated the teacher which help teacher in identification of students with learning disability.',
	 'authors': u'Syed Asif Ali, Safeeullah Soomro, Abdul Ghafoor Memon, Abdul Baqi,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5474',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nImplementation of Automata Theory to Improve the Learning Disability',
	 'urllink': u'http://arxiv.org/abs/1310.5474'}
2015-03-24 22:52:09+0000 [xxu46_7] INFO: Crawled 914 pages (at 1 pages/min), scraped 907 items (at 1 items/min)
2015-03-24 22:53:09+0000 [xxu46_7] INFO: Crawled 914 pages (at 0 pages/min), scraped 907 items (at 0 items/min)
2015-03-24 22:53:38+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1311.4268> (referer: http://arxiv.org/list/cs/13?skip=12000&show=1000)
2015-03-24 22:53:38+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1311.4268>
	{'abstract': u'In Multihop Wireless Networks, traffic forwarding capability of each node varies according to its level of contention. Each node can yield its channel access opportunity to its neighbouring nodes, so that all the nodes can evenly share the channel and have similar forwarding capability. In this manner the wireless channel is utilize d effectively, which is achieved using Contention Window Adaptation Mechanism (CWAM). This mechanism achieves a higher end to - end throughout but consumes the network power to a higher level. So, a newly proposed algorithm Quadrant Based Directional Routing Protocol (Q-DIR) is implemented as a cross - layer with CWAM, to reduce the total network power consumption through limited flooding and also reduce the routing overheads, which eventually increases overall network throughput. This algorithm limits the broadcast region to a quadrant where the source node and the destination nodes are located. Implementation of the algorithm is done in Linux based NS-2 simulator.',
	 'authors': u'V.Karthikeyan, V.J.Vijayalakshmi, P.Jeyakumar,',
	 'category': u'Computer Science ',
	 'date': '2013-11-18',
	 'pdflink': u'http://arxiv.org/pdf/1311.4268',
	 'subjects': u'Networking and Internet Architecture (cs.NI)',
	 'title': u'\nQuadrant Based DIR in CWin Adaptation Mechanism for Multihop Wireless  Network',
	 'urllink': u'http://arxiv.org/abs/1311.4268'}
2015-03-24 22:54:09+0000 [xxu46_7] INFO: Crawled 915 pages (at 1 pages/min), scraped 908 items (at 1 items/min)
2015-03-24 22:55:09+0000 [xxu46_7] INFO: Crawled 915 pages (at 0 pages/min), scraped 908 items (at 0 items/min)
2015-03-24 22:55:26+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4201> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 22:55:26+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4201>
	{'abstract': u'In multiple-input multiple-output (MIMO) fading channels, the design criterion for full-diversity space-time block codes (STBCs) is primarily determined by the decoding method at the receiver. Although constructions of STBCs have predominantly matched the maximum-likelihood (ML) decoder, design criteria and constructions of full-diversity STBCs have also been reported for low-complexity linear receivers. A new receiver architecture called Integer-Forcing (IF) linear receiver has been proposed by Zhan emph which showed promising results for the high-rate V-BLAST encoding scheme. In this work we address the design of full-diversity STBCs for IF linear receivers. We derive an upper bound on the probability of decoding error, and show that STBCs that satisfy the non-vanishing singular value (NVS) property provide full-diversity for the IF receiver. Further, we prove that all known STBCs with the non-vanishing determinant property are applicable for IF receivers, as they guarantee the NVS property. As a special case of our analysis on STBCs, we present an upper bound on the error probability for the V-BLAST architecture presented by Zhan emph, and demonstrate that the IF linear receivers provide full receive diversity. Our results supplement the existing outage probability based results for the IF receiver.',
	 'authors': u'J. Harshan, Amin Sakzad, Emanuele Viterbo,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/e-print/1308.4201',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nFull-Diversity Space-Time Block Codes for Integer-Forcing Linear  Receivers',
	 'urllink': u'http://arxiv.org/abs/1308.4201'}
2015-03-24 22:56:09+0000 [xxu46_7] INFO: Crawled 916 pages (at 1 pages/min), scraped 909 items (at 1 items/min)
2015-03-24 22:57:06+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6151> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 22:57:06+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6151>
	{'abstract': u'A design flow for modulators is illustrated, allowing quantization noise to be shaped according to an arbitrary weighting profile. Being based on FIR NTFs, possibly with high order, the flow is best suited for digital architectures. The work builds on a recent proposal where the modulator is matched to the reconstruction filter, showing that this type of optimization can benefit a wide range of applications where noise (including in-band noise) is known to have a different impact at different frequencies. The design of a multiband modulator, a modulator avoiding DC noise, and an audio modulator capable of distributing quantization artifacts according to a psychoacoustic model are discussed as examples. A software toolbox is provided as a general design aid and to replicate the proposed results.',
	 'authors': u'Sergio Callegari, Federico Bizzarri,',
	 'category': u'Computer Science ',
	 'date': '2013-9-24',
	 'pdflink': u'http://arxiv.org/pdf/1309.6151',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nNoise Weighting in the Design of \u0394\u03a3 Modulators (with a  Psychoacoustic Coder as an Example)',
	 'urllink': u'http://arxiv.org/abs/1309.6151'}
2015-03-24 22:57:09+0000 [xxu46_7] INFO: Crawled 917 pages (at 1 pages/min), scraped 910 items (at 1 items/min)
2015-03-24 22:58:09+0000 [xxu46_7] INFO: Crawled 917 pages (at 0 pages/min), scraped 910 items (at 0 items/min)
2015-03-24 22:58:52+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5472> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 22:58:52+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5472>
	{'abstract': u'The rate of disability is increase day by day all over the world .There are various type of Disabilities but the deaf persons are on second number among all types of disabilities.. In most of the countries disabled persons are supposed to be social liability on their family and in the society as awhile. Now days in developing countries it is difficult for normal persons to get suitable jobs. Whenever we are talking about disabled, it is more difficult to assimilate deaf persons in workplace. Threats of unemployment of disabled person are almost double that of people without disabilities. Number of able deaf persons is unable to get suitable job due to several reasons like lack of facilities for deaf persons and lack of awareness from normal persons side which create barrier in searching job for deaf persons. This research work emphasis on the special need and training required for the deaf individual sand to make and train them how to move in workplace with different social and technical barrier. In recent era technology play important role in each and every part of life. Using the facility of Information and communication Technology we can easily assimilate deaf in workplace. The proposed model helps deaf persons to adjust in their jobs.',
	 'authors': u'Syed Asif Ali, Safeeulah Soomro, Abdul Ghafoor Memon, Mashooque Ahmed,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5472',
	 'subjects': u'Computers and Society (cs.CY)',
	 'title': u'\nInteractive Employment Model to Assimilate the Deaf persons in workplace  by using ICT',
	 'urllink': u'http://arxiv.org/abs/1310.5472'}
2015-03-24 22:59:09+0000 [xxu46_7] INFO: Crawled 918 pages (at 1 pages/min), scraped 911 items (at 1 items/min)
2015-03-24 23:00:09+0000 [xxu46_7] INFO: Crawled 918 pages (at 0 pages/min), scraped 911 items (at 0 items/min)
2015-03-24 23:00:52+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1311.4235> (referer: http://arxiv.org/list/cs/13?skip=12000&show=1000)
2015-03-24 23:00:52+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1311.4235>
	{'abstract': u"In this paper, we push forward the idea of machine learning systems whose operators can be modified and fine-tuned for each problem. This allows us to propose a learning paradigm where users can write (or adapt) their operators, according to the problem, data representation and the way the information should be navigated. To achieve this goal, data instances, background knowledge, rules, programs and operators are all written in the same functional language, Erlang. Since changing operators affect how the search space needs to be explored, heuristics are learnt as a result of a decision process based on reinforcement learning where each action is defined as a choice of operator and rule. As a result, the architecture can be seen as a 'system for writing machine learning systems' or to explore new operators where the policy reuse (as a kind of transfer learning) is allowed. States and actions are represented in a Q matrix which is actually a table, from which a supervised model is learnt. This makes it possible to have a more flexible mapping between old and new problems, since we work with an abstraction of rules and actions. We include some examples sharing reuse and the application of the system gErl to IQ problems. In order to evaluate gErl, we will test it against some structured problems: a selection of IQ test tasks and some experiments on some structured prediction problems (list patterns).",
	 'authors': u'Fernando Mart\xednez-Plumed, C\xe8sar Ferri, Jos\xe9 Hern\xe1ndez-Orallo, Mar\xeda-Jos\xe9 Ram\xedrez-Quintana,',
	 'category': u'Computer Science ',
	 'date': '2013-11-18',
	 'pdflink': u'http://arxiv.org/pdf/1311.4235',
	 'subjects': u'Learning (cs.LG)',
	 'title': u'\nOn the definition of a general learning system with user-defined  operators',
	 'urllink': u'http://arxiv.org/abs/1311.4235'}
2015-03-24 23:01:09+0000 [xxu46_7] INFO: Crawled 919 pages (at 1 pages/min), scraped 912 items (at 1 items/min)
2015-03-24 23:02:09+0000 [xxu46_7] INFO: Crawled 919 pages (at 0 pages/min), scraped 912 items (at 0 items/min)
2015-03-24 23:02:45+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4200> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 23:02:45+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4200>
	{'abstract': u'Images seen during test time are often not from the same distribution as images used for learning. This problem, known as domain shift, occurs when training classifiers from object-centric internet image databases and trying to apply them directly to scene understanding tasks. The consequence is often severe performance degradation and is one of the major barriers for the application of classifiers in real-world systems. In this paper, we show how to learn transform-based domain adaptation classifiers in a scalable manner. The key idea is to exploit an implicit rank constraint, originated from a max-margin domain adaptation formulation, to make optimization tractable. Experiments show that the transformation between domains can be very efficiently learned from data and easily applied to new categories. This begins to bridge the gap between large-scale internet image collections and object images captured in everyday life environments.',
	 'authors': u'Erik Rodner, Judy Hoffman, Jeff Donahue, Trevor Darrell, Kate Saenko,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/pdf/1308.4200',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u'\nTowards Adapting ImageNet to Reality: Scalable Domain Adaptation with  Implicit Low-rank Transformations',
	 'urllink': u'http://arxiv.org/abs/1308.4200'}
2015-03-24 23:03:09+0000 [xxu46_7] INFO: Crawled 920 pages (at 1 pages/min), scraped 913 items (at 1 items/min)
2015-03-24 23:04:09+0000 [xxu46_7] INFO: Crawled 920 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2015-03-24 23:04:27+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6149> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 23:04:27+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6149>
	{'abstract': u'Security has become, nowadays, a major concern for the organizations as the majority of its applications are exposed to Internet, which increases the threats of security considerably. Thus, the solution is to improve tools and mechanisms to strengthen the protection of applications against attacks and ensure the different security objectives. Among solutions we will talking about, in this paper, there is Mutation Analysis which is a technique of test that evaluates the quality of software tests and their ability to detect errors, It also compares the criteria and test generation strategies. In this study we will use the Mutation Analysis as a mean to qualify the penetration tests, and then, apply this technique in the security mechanisms and exactly on the mechanisms of access control. At the end we will propose a method for the elimination of hidden mechanisms for access control that will allow the access control policy to evolve.',
	 'authors': u'Mohammed Ennahbaoui, Said Elhajji,',
	 'category': u'Computer Science ',
	 'date': '2013-9-24',
	 'pdflink': u'http://arxiv.org/pdf/1309.6149',
	 'subjects': u'Cryptography and Security (cs.CR)',
	 'title': u'\nMutation Analysis for Security',
	 'urllink': u'http://arxiv.org/abs/1309.6149'}
2015-03-24 23:05:09+0000 [xxu46_7] INFO: Crawled 921 pages (at 1 pages/min), scraped 914 items (at 1 items/min)
2015-03-24 23:06:07+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5469> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 23:06:07+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5469>
	{'abstract': u'We show that the following two problems are fixed-parameter tractable with parameter k: testing whether a connected n-vertex graph with m edges has a square root with at most n-1+k edges and testing whether such a graph has a square root with at least m-k edges. Our first result implies that squares of graphs obtained from trees by adding at most k edges can be recognized in polynomial time for every fixed k&gt;=0; previously this result was known only for k=0. Our second result is equivalent to stating that deciding whether a graph can be modified into a square root of itself by at most k edge deletions is fixed-parameter tractable with parameter k.',
	 'authors': u'Manfred Cochefert, Jean-Fran\xe7ois Couturier, Petr A. Golovach, Dieter Kratsch, Dani\xebl Paulusma,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5469',
	 'subjects': u'Data Structures and Algorithms (cs.DS)',
	 'title': u'\nParameterized Algorithms for Finding Square Roots',
	 'urllink': u'http://arxiv.org/abs/1310.5469'}
2015-03-24 23:06:09+0000 [xxu46_7] INFO: Crawled 922 pages (at 1 pages/min), scraped 915 items (at 1 items/min)
2015-03-24 23:07:09+0000 [xxu46_7] INFO: Crawled 922 pages (at 0 pages/min), scraped 915 items (at 0 items/min)
2015-03-24 23:07:31+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1311.4231> (referer: http://arxiv.org/list/cs/13?skip=12000&show=1000)
2015-03-24 23:07:31+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1311.4231>
	{'abstract': u'Low-level program analysis is a fundamental problem, taking the shape of "flow analysis" in functional languages and "points-to" analysis in imperative and object-oriented languages. Despite the similarities, the vocabulary and results in the two communities remain largely distinct, with limited cross-understanding. One of the few links is Shivers\'s -CFA work, which has advanced the concept of "context-sensitive analysis" and is widely known in both communities. Recent results indicate that the relationship between the functional and object-oriented incarnations of -CFA is not as well understood as thought. Van Horn and Mairson proved -CFA for to be EXPTIME-complete; hence, no polynomial-time algorithm can exist. Yet, there are several polynomial-time formulations of context-sensitive points-to analyses in object-oriented languages. Thus, it seems that functional -CFA may actually be a profoundly different analysis from object-oriented -CFA. We resolve this paradox by showing that the exact same specification of -CFA is polynomial-time for object-oriented languages yet exponential- time for functional ones: objects and closures are subtly different, in a way that interacts crucially with context-sensitivity and complexity. This illumination leads to an immediate payoff: by projecting the object-oriented treatment of objects onto closures, we derive a polynomial-time hierarchy of context-sensitive CFAs for functional programs.',
	 'authors': u'Matthew Might, Yannis Smaragdakis, David Van Horn,',
	 'category': u'Computer Science ',
	 'date': '2013-11-17',
	 'pdflink': u'http://arxiv.org/pdf/1311.4231',
	 'subjects': u'Programming Languages (cs.PL)',
	 'title': u'\nResolving and Exploiting the $k$-CFA Paradox',
	 'urllink': u'http://arxiv.org/abs/1311.4231'}
2015-03-24 23:08:09+0000 [xxu46_7] INFO: Crawled 923 pages (at 1 pages/min), scraped 916 items (at 1 items/min)
2015-03-24 23:09:09+0000 [xxu46_7] INFO: Crawled 923 pages (at 0 pages/min), scraped 916 items (at 0 items/min)
2015-03-24 23:09:29+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4197> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 23:09:29+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4197>
	{'abstract': u"We consider the problem of coloring the squares of graphs of bounded maximum average degree, that is, the problem of coloring the vertices while ensuring that two vertices that are adjacent or have a common neighbour receive different colors. Borodin et al. proved in 2004 and 2008 that the squares of planar graphs of girth at least seven and sufficiently large maximum degree are list -colorable, while the squares of some planar graphs of girth six and arbitrarily large maximum degree are not. By Euler's Formula, planar graphs of girth at least are of maximum average degree less than , and planar graphs of girth at least are of maximum average degree less than . We strengthen their result and prove that there exists a function such that the square of any graph with maximum average degree and maximum degree is list -colorable. This bound of is optimal in the sense that the above-mentioned planar graphs with girth have maximum average degree less than and arbitrarily large maximum degree, while their square cannot be -colored. The same holds for list injective -coloring.",
	 'authors': u'Marthe Bonamy, Benjamin L\xe9v\xeaque, Alexandre Pinlou,',
	 'category': u'Computer Science ',
	 'date': '2013-8-20',
	 'pdflink': u'http://arxiv.org/pdf/1308.4197',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nList coloring the square of sparse graphs with large degree',
	 'urllink': u'http://arxiv.org/abs/1308.4197'}
2015-03-24 23:10:09+0000 [xxu46_7] INFO: Crawled 924 pages (at 1 pages/min), scraped 917 items (at 1 items/min)
2015-03-24 23:11:09+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6148> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 23:11:09+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6148>
	{'abstract': u'The problem of optimal allocation of samples in surveys using a stratified sampling plan was first discussed by Neyman in 1934. Since then, many researchers have studied the problem of the sample allocation in multivariate surveys and several methods have been proposed. Basically, these methods are divided into two class: The first involves forming a weighted average of the stratum variances and finding the optimal allocation for the average variance. The second class is associated with methods that require that an acceptable coefficient of variation for each of the variables on which the allocation is to be done. Particularly, this paper proposes a new optimization approach to the second problem. This approach is based on an integer programming formulation. Several experiments showed that the proposed approach is efficient way to solve this problem, considering a comparison of this approach with the other approach from the literature.',
	 'authors': u'Jose Andre de Moura Brito, Gustavo Silva Semaan, Pedro Luis do Nascimento Silva, Nelson Maculan,',
	 'category': u'Computer Science ',
	 'date': '2013-9-24',
	 'pdflink': u'http://arxiv.org/pdf/1309.6148',
	 'subjects': u'Discrete Mathematics (cs.DM)',
	 'title': u'\nAn Integer Programming Formulation Applied to Optimum Allocation in  Multivariate Stratified Sampling',
	 'urllink': u'http://arxiv.org/abs/1309.6148'}
2015-03-24 23:11:09+0000 [xxu46_7] INFO: Crawled 925 pages (at 1 pages/min), scraped 918 items (at 1 items/min)
2015-03-24 23:12:09+0000 [xxu46_7] INFO: Crawled 925 pages (at 0 pages/min), scraped 918 items (at 0 items/min)
2015-03-24 23:12:21+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1310.5468> (referer: http://arxiv.org/list/cs/13?skip=11000&show=1000)
2015-03-24 23:12:21+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1310.5468>
	{'abstract': u'Cognitive Radio has been proposed as a key technology to significantly improve spectrum usage in wireless networks by enabling unlicensed users to access unused resource. We present new algorithms that are needed for the implementation of opportunistic scheduling policies that maximize the throughput utilization of resources by secondary users, under maximum interference constraints imposed by existing primary users. Our approach is based on the Belief Propagation (BP) algorithm, which is advantageous due to its simplicity and potential for distributed implementation. We examine convergence properties and evaluate the performance of the proposed BP algorithms via simulations and demonstrate that the results compare favorably with a benchmark greedy strategy.',
	 'authors': u'Hamed Mahmoudi, Georgios Rodolakis, Leonidas Georgiadis, David Saad,',
	 'category': u'Computer Science ',
	 'date': '2013-10-21',
	 'pdflink': u'http://arxiv.org/pdf/1310.5468',
	 'subjects': u'Information Theory (cs.IT)',
	 'title': u'\nMessage-Passing Algorithms for Optimal Utilization of Cognitive Radio  Networks',
	 'urllink': u'http://arxiv.org/abs/1310.5468'}
2015-03-24 23:13:09+0000 [xxu46_7] INFO: Crawled 926 pages (at 1 pages/min), scraped 919 items (at 1 items/min)
2015-03-24 23:13:48+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1311.4227> (referer: http://arxiv.org/list/cs/13?skip=12000&show=1000)
2015-03-24 23:13:48+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1311.4227>
	{'abstract': u'Recent years have seen an explosion in wireless video communication systems. Optimization in such systems is crucial - but most existing methods intended to optimize the performance of multi-user wireless video transmission are inefficient. Some works (e.g. Network Utility Maximization (NUM)) are myopic: they choose actions to maximize instantaneous video quality while ignoring the future impact of these actions. Such myopic solutions are known to be inferior to foresighted solutions that optimize the long-term video quality. Alternatively, foresighted solutions such as rate-distortion optimized packet scheduling focus on single-user wireless video transmission, while ignoring the resource allocation among the users. In this paper, we propose an optimal solution for performing joint foresighted resource allocation and packet scheduling among multiple users transmitting video over a shared wireless network. A key challenge in developing foresighted solutions for multiple video users is that the users\' decisions are coupled. To decouple the users\' decisions, we adopt a novel dual decomposition approach, which differs from the conventional optimization solutions such as NUM, and determines foresighted policies. Specifically, we propose an informationally-decentralized algorithm in which the network manager updates resource "prices" (i.e. the dual variables associated with the resource constraints), and the users make individual video packet scheduling decisions based on these prices. Because a priori knowledge of the system dynamics is almost never available at run-time, the proposed solution can learn online, concurrently with performing the foresighted optimization. Simulation results show 7 dB and 3 dB improvements in Peak Signal-to-Noise Ratio (PSNR) over myopic solutions and existing foresighted solutions, respectively.',
	 'authors': u'Yuanzhang Xiao, Mihaela van der Schaar,',
	 'category': u'Computer Science ',
	 'date': '2013-11-17',
	 'pdflink': u'http://arxiv.org/pdf/1311.4227',
	 'subjects': u'Multimedia (cs.MM)',
	 'title': u'\nOptimal Foresighted Multi-User Wireless Video',
	 'urllink': u'http://arxiv.org/abs/1311.4227'}
2015-03-24 23:14:09+0000 [xxu46_7] INFO: Crawled 927 pages (at 1 pages/min), scraped 920 items (at 1 items/min)
2015-03-24 23:15:09+0000 [xxu46_7] INFO: Crawled 927 pages (at 0 pages/min), scraped 920 items (at 0 items/min)
2015-03-24 23:15:35+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1308.4189> (referer: http://arxiv.org/list/cs/13?skip=9000&show=1000)
2015-03-24 23:15:35+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1308.4189>
	{'abstract': u'We present a system that demonstrates how the compositional structure of events, in concert with the compositional structure of language, can interplay with the underlying focusing mechanisms in video action recognition, thereby providing a medium, not only for top-down and bottom-up integration, but also for multi-modal integration between vision and language. We show how the roles played by participants (nouns), their characteristics (adjectives), the actions performed (verbs), the manner of such actions (adverbs), and changing spatial relations between participants (prepositions) in the form of whole sentential descriptions mediated by a grammar, guides the activity-recognition process. Further, the utility and expressiveness of our framework is demonstrated by performing three separate tasks in the domain of multi-activity videos: sentence-guided focus of attention, generation of sentential descriptions of video, and query-based video search, simply by leveraging the framework in different manners.',
	 'authors': u'N. Siddharth, Andrei Barbu, Jeffrey Mark Siskind,',
	 'category': u'Computer Science ',
	 'date': '2013-8-19',
	 'pdflink': u'http://arxiv.org/pdf/1308.4189',
	 'subjects': u'Computer Vision and Pattern Recognition (cs.CV)',
	 'title': u"\nSeeing What You're Told: Sentence-Guided Activity Recognition In Video",
	 'urllink': u'http://arxiv.org/abs/1308.4189'}
2015-03-24 23:16:09+0000 [xxu46_7] INFO: Crawled 928 pages (at 1 pages/min), scraped 921 items (at 1 items/min)
2015-03-24 23:17:09+0000 [xxu46_7] INFO: Crawled 928 pages (at 0 pages/min), scraped 921 items (at 0 items/min)
2015-03-24 23:17:23+0000 [xxu46_7] DEBUG: Crawled (200) <GET http://arxiv.org/abs/1309.6144> (referer: http://arxiv.org/list/cs/13?skip=10000&show=1000)
2015-03-24 23:17:23+0000 [xxu46_7] DEBUG: Scraped from <200 http://arxiv.org/abs/1309.6144>
	{'abstract': u'When considering a graph problem from a parameterized point of view, the parameter chosen is often the size of an optimal solution of this problem (the "standard" parameter). A natural subject for investigation is what happens when we parameterize such a problem by various other parameters, some of which may be the values of optimal solutions to different problems. Such research is known as parameterized ecology. In this paper, we investigate seven natural vertex problems, along with their respective parameters: the size of a maximum independent set, the size of a minimum vertex cover, the size of a maximum clique, the chromatic number, the size of a minimum dominating set, the size of a minimum independent dominating set and the size of a minimum feedback vertex set. We study the parameterized complexity of each of these problems with respect to the standard parameter of the others.',
	 'authors': u'Nicolas Bourgeois, Konrad K. Dabrowski, Marc Demange, Vangelis Th. Paschos,',
	 'category': u'Computer Science ',
	 'date': '2013-9-24',
	 'pdflink': u'http://arxiv.org/pdf/1309.6144',
	 'subjects': u'Computational Complexity (cs.CC)',
	 'title': u'\nPlaying with parameters: structural parameterization in graphs',
	 'urllink': u'http://arxiv.org/abs/1309.6144'}
